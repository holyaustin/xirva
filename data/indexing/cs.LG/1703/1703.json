[{"id": "1703.00039", "submitter": "Hiromitsu Mizutani", "authors": "Hiromitsu Mizutani (1) and Ryota Kanai (1) ((1) Araya Inc.)", "title": "A description length approach to determining the number of k-means\n  clusters", "comments": "27 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an asymptotic criterion to determine the optimal number of\nclusters in k-means. We consider k-means as data compression, and propose to\nadopt the number of clusters that minimizes the estimated description length\nafter compression. Here we report two types of compression ratio based on two\nways to quantify the description length of data after compression. This\napproach further offers a way to evaluate whether clusters obtained with\nk-means have a hierarchical structure by examining whether multi-stage\ncompression can further reduce the description length. We applied our criteria\nto determine the number of clusters to synthetic data and empirical\nneuroimaging data to observe the behavior of the criteria across different\ntypes of data set and suitability of the two types of criteria for different\ndatasets. We found that our method can offer reasonable clustering results that\nare useful for dimension reduction. While our numerical results revealed\ndependency of our criteria on the various aspects of dataset such as the\ndimensionality, the description length approach proposed here provides a useful\nguidance to determine the number of clusters in a principled manner when\nunderlying properties of the data are unknown and only inferred from\nobservation of data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 20:05:08 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Mizutani", "Hiromitsu", "", "Araya Inc"], ["Kanai", "Ryota", "", "Araya Inc"]]}, {"id": "1703.00048", "submitter": "Lihong Li", "authors": "Lihong Li and Yu Lu and Dengyong Zhou", "title": "Provably Optimal Algorithms for Generalized Linear Contextual Bandits", "comments": "Published at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits are widely used in Internet services from news\nrecommendation to advertising, and to Web search. Generalized linear models\n(logistical regression in particular) have demonstrated stronger performance\nthan linear models in many applications where rewards are binary. However, most\ntheoretical analyses on contextual bandits so far are on linear bandits. In\nthis work, we propose an upper confidence bound based algorithm for generalized\nlinear contextual bandits, which achieves an $\\tilde{O}(\\sqrt{dT})$ regret over\n$T$ rounds with $d$ dimensional feature vectors. This regret matches the\nminimax lower bound, up to logarithmic terms, and improves on the best previous\nresult by a $\\sqrt{d}$ factor, assuming the number of arms is fixed. A key\ncomponent in our analysis is to establish a new, sharp finite-sample confidence\nbound for maximum-likelihood estimates in generalized linear models, which may\nbe of independent interest. We also analyze a simpler upper confidence bound\nalgorithm, which is useful in practice, and prove it to have optimal regret for\ncertain cases.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 20:39:44 GMT"}, {"version": "v2", "created": "Sun, 18 Jun 2017 04:07:45 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Li", "Lihong", ""], ["Lu", "Yu", ""], ["Zhou", "Dengyong", ""]]}, {"id": "1703.00060", "submitter": "Lu Zhang", "authors": "Lu Zhang (1), Yongkai Wu (1), Xintao Wu (1) ((1) University of\n  Arkansas)", "title": "Achieving non-discrimination in prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrimination-aware classification is receiving an increasing attention in\ndata science fields. The pre-process methods for constructing a\ndiscrimination-free classifier first remove discrimination from the training\ndata, and then learn the classifier from the cleaned data. However, they lack a\ntheoretical guarantee for the potential discrimination when the classifier is\ndeployed for prediction. In this paper, we fill this gap by mathematically\nbounding the probability of the discrimination in prediction being within a\ngiven interval in terms of the training data and classifier. We adopt the\ncausal model for modeling the data generation mechanism, and formally defining\ndiscrimination in population, in a dataset, and in prediction. We obtain two\nimportant theoretical results: (1) the discrimination in prediction can still\nexist even if the discrimination in the training data is completely removed;\nand (2) not all pre-process methods can ensure non-discrimination in prediction\neven though they can achieve non-discrimination in the modified training data.\nBased on the results, we develop a two-phase framework for constructing a\ndiscrimination-free classifier with a theoretical guarantee. The experiments\ndemonstrate the theoretical results and show the effectiveness of our two-phase\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 21:20:19 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 19:59:00 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Zhang", "Lu", ""], ["Wu", "Yongkai", ""], ["Wu", "Xintao", ""]]}, {"id": "1703.00066", "submitter": "Badih Ghazi", "authors": "Vitaly Feldman, Badih Ghazi", "title": "On the Power of Learning from $k$-Wise Queries", "comments": "32 pages, Appeared in Innovations in Theoretical Computer Science\n  (ITCS) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several well-studied models of access to data samples, including statistical\nqueries, local differential privacy and low-communication algorithms rely on\nqueries that provide information about a function of a single sample. (For\nexample, a statistical query (SQ) gives an estimate of $Ex_{x \\sim D}[q(x)]$\nfor any choice of the query function $q$ mapping $X$ to the reals, where $D$ is\nan unknown data distribution over $X$.) Yet some data analysis algorithms rely\non properties of functions that depend on multiple samples. Such algorithms\nwould be naturally implemented using $k$-wise queries each of which is\nspecified by a function $q$ mapping $X^k$ to the reals. Hence it is natural to\nask whether algorithms using $k$-wise queries can solve learning problems more\nefficiently and by how much.\n  Blum, Kalai and Wasserman (2003) showed that for any weak PAC learning\nproblem over a fixed distribution, the complexity of learning with $k$-wise SQs\nis smaller than the (unary) SQ complexity by a factor of at most $2^k$. We show\nthat for more general problems over distributions the picture is substantially\nricher. For every $k$, the complexity of distribution-independent PAC learning\nwith $k$-wise queries can be exponentially larger than learning with\n$(k+1)$-wise queries. We then give two approaches for simulating a $k$-wise\nquery using unary queries. The first approach exploits the structure of the\nproblem that needs to be solved. It generalizes and strengthens (exponentially)\nthe results of Blum et al.. It allows us to derive strong lower bounds for\nlearning DNF formulas and stochastic constraint satisfaction problems that hold\nagainst algorithms using $k$-wise queries. The second approach exploits the\n$k$-party communication complexity of the $k$-wise query function.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 21:41:09 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Feldman", "Vitaly", ""], ["Ghazi", "Badih", ""]]}, {"id": "1703.00084", "submitter": "Yongcan Cao", "authors": "Kasthurirengan Suresh, Samuel Silva, Johnathan Votion, and Yongcan Cao", "title": "Multi-Sensor Data Pattern Recognition for Multi-Target Localization: A\n  Machine Learning Approach", "comments": "submitted for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-target pairing is an important step towards multi-target localization\nfor the intelligent operation of unmanned systems. Target localization plays a\ncrucial role in numerous applications, such as search, and rescue missions,\ntraffic management and surveillance. The objective of this paper is to present\nan innovative target location learning approach, where numerous machine\nlearning approaches, including K-means clustering and supported vector machines\n(SVM), are used to learn the data pattern across a list of spatially\ndistributed sensors. To enable the accurate data association from different\nsensors for accurate target localization, appropriate data pre-processing is\nessential, which is then followed by the application of different machine\nlearning algorithms to appropriately group data from different sensors for the\naccurate localization of multiple targets. Through simulation examples, the\nperformance of these machine learning algorithms is quantified and compared.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 23:16:19 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Suresh", "Kasthurirengan", ""], ["Silva", "Samuel", ""], ["Votion", "Johnathan", ""], ["Cao", "Yongcan", ""]]}, {"id": "1703.00096", "submitter": "Zhenyao Zhu", "authors": "Hairong Liu, Zhenyao Zhu, Xiangang Li, Sanjeev Satheesh", "title": "Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence\n  Labelling", "comments": "Published at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing sequence labelling models rely on a fixed decomposition of a\ntarget sequence into a sequence of basic units. These methods suffer from two\nmajor drawbacks: 1) the set of basic units is fixed, such as the set of words,\ncharacters or phonemes in speech recognition, and 2) the decomposition of\ntarget sequences is fixed. These drawbacks usually result in sub-optimal\nperformance of modeling sequences. In this pa- per, we extend the popular CTC\nloss criterion to alleviate these limitations, and propose a new loss function\ncalled Gram-CTC. While preserving the advantages of CTC, Gram-CTC automatically\nlearns the best set of basic units (grams), as well as the most suitable\ndecomposition of tar- get sequences. Unlike CTC, Gram-CTC allows the model to\noutput variable number of characters at each time step, which enables the model\nto capture longer term dependency and improves the computational efficiency. We\ndemonstrate that the proposed Gram-CTC improves CTC in terms of both\nperformance and efficiency on the large vocabulary speech recognition task at\nmultiple scales of data, and that with Gram-CTC we can outperform the\nstate-of-the-art on a standard speech benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 00:59:17 GMT"}, {"version": "v2", "created": "Sat, 12 Aug 2017 00:02:26 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Liu", "Hairong", ""], ["Zhu", "Zhenyao", ""], ["Li", "Xiangang", ""], ["Satheesh", "Sanjeev", ""]]}, {"id": "1703.00102", "submitter": "Lam Nguyen", "authors": "Lam M. Nguyen, Jie Liu, Katya Scheinberg, Martin Tak\\'a\\v{c}", "title": "SARAH: A Novel Method for Machine Learning Problems Using Stochastic\n  Recursive Gradient", "comments": null, "journal-ref": "Proceedings of the 34th International Conference on Machine\n  Learning, PMLR 70:2613-2621, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a StochAstic Recursive grAdient algoritHm (SARAH),\nas well as its practical variant SARAH+, as a novel approach to the finite-sum\nminimization problems. Different from the vanilla SGD and other modern\nstochastic methods such as SVRG, S2GD, SAG and SAGA, SARAH admits a simple\nrecursive framework for updating stochastic gradient estimates; when comparing\nto SAG/SAGA, SARAH does not require a storage of past gradients. The linear\nconvergence rate of SARAH is proven under strong convexity assumption. We also\nprove a linear convergence rate (in the strongly convex case) for an inner loop\nof SARAH, the property that SVRG does not possess. Numerical experiments\ndemonstrate the efficiency of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 02:08:32 GMT"}, {"version": "v2", "created": "Sat, 3 Jun 2017 07:30:20 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Nguyen", "Lam M.", ""], ["Liu", "Jie", ""], ["Scheinberg", "Katya", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1703.00119", "submitter": "Bo Liu", "authors": "Bo Liu, Xiao-Tong Yuan, Lezi Wang, Qingshan Liu, Dimitris N. Metaxas", "title": "Dual Iterative Hard Thresholding: From Non-convex Sparse Minimization to\n  Non-smooth Concave Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative Hard Thresholding (IHT) is a class of projected gradient descent\nmethods for optimizing sparsity-constrained minimization models, with the best\nknown efficiency and scalability in practice. As far as we know, the existing\nIHT-style methods are designed for sparse minimization in primal form. It\nremains open to explore duality theory and algorithms in such a non-convex and\nNP-hard problem setting. In this paper, we bridge this gap by establishing a\nduality theory for sparsity-constrained minimization with $\\ell_2$-regularized\nloss function and proposing an IHT-style algorithm for dual maximization. Our\nsparse duality theory provides a set of sufficient and necessary conditions\nunder which the original NP-hard/non-convex problem can be equivalently solved\nin a dual formulation. The proposed dual IHT algorithm is a super-gradient\nmethod for maximizing the non-smooth dual objective. An interesting finding is\nthat the sparse recovery performance of dual IHT is invariant to the Restricted\nIsometry Property (RIP), which is required by virtually all the existing primal\nIHT algorithms without sparsity relaxation. Moreover, a stochastic variant of\ndual IHT is proposed for large-scale stochastic optimization. Numerical results\ndemonstrate the superiority of dual IHT algorithms to the state-of-the-art\nprimal IHT-style algorithms in model estimation accuracy and computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 03:30:47 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 02:14:17 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Liu", "Bo", ""], ["Yuan", "Xiao-Tong", ""], ["Wang", "Lezi", ""], ["Liu", "Qingshan", ""], ["Metaxas", "Dimitris N.", ""]]}, {"id": "1703.00132", "submitter": "Wei Fu", "authors": "Wei Fu, Tim Menzies", "title": "Revisiting Unsupervised Learning for Defect Prediction", "comments": "11 pages, 5 figures. Accepted at FSE2017", "journal-ref": null, "doi": "10.1145/3106237.3106257", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collecting quality data from software projects can be time-consuming and\nexpensive. Hence, some researchers explore \"unsupervised\" approaches to quality\nprediction that does not require labelled data. An alternate technique is to\nuse \"supervised\" approaches that learn models from project data labelled with,\nsay, \"defective\" or \"not-defective\". Most researchers use these supervised\nmodels since, it is argued, they can exploit more knowledge of the projects.\n  At FSE'16, Yang et al. reported startling results where unsupervised defect\npredictors outperformed supervised predictors for effort-aware just-in-time\ndefect prediction. If confirmed, these results would lead to a dramatic\nsimplification of a seemingly complex task (data mining) that is widely\nexplored in the software engineering literature.\n  This paper repeats and refutes those results as follows. (1) There is much\nvariability in the efficacy of the Yang et al. predictors so even with their\napproach, some supervised data is required to prune weaker predictors away.\n(2)Their findings were grouped across $N$ projects. When we repeat their\nanalysis on a project-by-project basis, supervised predictors are seen to work\nbetter.\n  Even though this paper rejects the specific conclusions of Yang et al., we\nstill endorse their general goal. In our our experiments, supervised predictors\ndid not perform outstandingly better than unsupervised ones for effort-aware\njust-in-time defect prediction. Hence, they may indeed be some combination of\nunsupervised learners to achieve comparable performance to supervised ones. We\ntherefore encourage others to work in this promising area.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 04:36:06 GMT"}, {"version": "v2", "created": "Sat, 24 Jun 2017 17:00:52 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Fu", "Wei", ""], ["Menzies", "Tim", ""]]}, {"id": "1703.00133", "submitter": "Wei Fu", "authors": "Wei Fu, Tim Menzies", "title": "Easy over Hard: A Case Study on Deep Learning", "comments": "12 pages, 6 figures, accepted at FSE2017", "journal-ref": null, "doi": "10.1145/3106237.3106256", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning is an exciting new technique, the benefits of this method\nneed to be assessed with respect to its computational cost. This is\nparticularly important for deep learning since these learners need hours (to\nweeks) to train the model. Such long training time limits the ability of (a)~a\nresearcher to test the stability of their conclusion via repeated runs with\ndifferent random seeds; and (b)~other researchers to repeat, improve, or even\nrefute that original work.\n  For example, recently, deep learning was used to find which questions in the\nStack Overflow programmer discussion forum can be linked together. That deep\nlearning system took 14 hours to execute. We show here that applying a very\nsimple optimizer called DE to fine tune SVM, it can achieve similar (and\nsometimes better) results. The DE approach terminated in 10 minutes; i.e. 84\ntimes faster hours than deep learning method.\n  We offer these results as a cautionary tale to the software analytics\ncommunity and suggest that not every new innovation should be applied without\ncritical analysis. If researchers deploy some new and expensive process, that\nwork should be baselined against some simpler and faster alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 04:38:35 GMT"}, {"version": "v2", "created": "Sat, 24 Jun 2017 16:43:01 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Fu", "Wei", ""], ["Menzies", "Tim", ""]]}, {"id": "1703.00144", "submitter": "Liang Zhao", "authors": "Liang Zhao, Siyu Liao, Yanzhi Wang, Zhe Li, Jian Tang, Victor Pan and\n  Bo Yuan", "title": "Theoretical Properties for Neural Networks with Weight Matrices of Low\n  Displacement Rank", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently low displacement rank (LDR) matrices, or so-called structured\nmatrices, have been proposed to compress large-scale neural networks. Empirical\nresults have shown that neural networks with weight matrices of LDR matrices,\nreferred as LDR neural networks, can achieve significant reduction in space and\ncomputational complexity while retaining high accuracy. We formally study LDR\nmatrices in deep learning. First, we prove the universal approximation property\nof LDR neural networks with a mild condition on the displacement operators. We\nthen show that the error bounds of LDR neural networks are as efficient as\ngeneral neural networks with both single-layer and multiple-layer structure.\nFinally, we propose back-propagation based training algorithm for general LDR\nneural networks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 05:38:16 GMT"}, {"version": "v2", "created": "Mon, 1 May 2017 16:15:40 GMT"}, {"version": "v3", "created": "Fri, 19 May 2017 15:57:19 GMT"}, {"version": "v4", "created": "Fri, 22 Sep 2017 01:53:39 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Zhao", "Liang", ""], ["Liao", "Siyu", ""], ["Wang", "Yanzhi", ""], ["Li", "Zhe", ""], ["Tang", "Jian", ""], ["Pan", "Victor", ""], ["Yuan", "Bo", ""]]}, {"id": "1703.00168", "submitter": "Chihiro Watanabe", "authors": "Chihiro Watanabe, Kaoru Hiramatsu, Kunio Kashino", "title": "Modular Representation of Layered Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layered neural networks have greatly improved the performance of various\napplications including image processing, speech recognition, natural language\nprocessing, and bioinformatics. However, it is still difficult to discover or\ninterpret knowledge from the inference provided by a layered neural network,\nsince its internal representation has many nonlinear and complex parameters\nembedded in hierarchical layers. Therefore, it becomes important to establish a\nnew methodology by which layered neural networks can be understood.\n  In this paper, we propose a new method for extracting a global and simplified\nstructure from a layered neural network. Based on network analysis, the\nproposed method detects communities or clusters of units with similar\nconnection patterns. We show its effectiveness by applying it to three use\ncases. (1) Network decomposition: it can decompose a trained neural network\ninto multiple small independent networks thus dividing the problem and reducing\nthe computation time. (2) Training assessment: the appropriateness of a trained\nresult with a given hyperparameter or randomly chosen initial parameters can be\nevaluated by using a modularity index. And (3) data analysis: in practical data\nit reveals the community structure in the input, hidden, and output layers,\nwhich serves as a clue for discovering knowledge from a trained neural network.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 07:58:29 GMT"}, {"version": "v2", "created": "Wed, 4 Oct 2017 06:55:48 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Watanabe", "Chihiro", ""], ["Hiramatsu", "Kaoru", ""], ["Kashino", "Kunio", ""]]}, {"id": "1703.00284", "submitter": "Valentina Zantedeschi", "authors": "Valentina Zantedeschi, R\\'emi Emonet, Marc Sebban", "title": "L$^3$-SVMs: Landmarks-based Linear Local Support Vectors Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For their ability to capture non-linearities in the data and to scale to\nlarge training sets, local Support Vector Machines (SVMs) have received a\nspecial attention during the past decade. In this paper, we introduce a new\nlocal SVM method, called L$^3$-SVMs, which clusters the input space, carries\nout dimensionality reduction by projecting the data on landmarks, and jointly\nlearns a linear combination of local models. Simple and effective, our\nalgorithm is also theoretically well-founded. Using the framework of Uniform\nStability, we show that our SVM formulation comes with generalization\nguarantees on the true risk. The experiments based on the simplest\nconfiguration of our model (i.e. landmarks randomly selected, linear\nprojection, linear kernel) show that L$^3$-SVMs is very competitive w.r.t. the\nstate of the art and opens the door to new exciting lines of research.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 13:22:43 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 11:58:57 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Zantedeschi", "Valentina", ""], ["Emonet", "R\u00e9mi", ""], ["Sebban", "Marc", ""]]}, {"id": "1703.00356", "submitter": "Renata Khasanova", "authors": "Renata Khasanova and Pascal Frossard", "title": "Graph-based Isometry Invariant Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning transformation invariant representations of visual data is an\nimportant problem in computer vision. Deep convolutional networks have\ndemonstrated remarkable results for image and video classification tasks.\nHowever, they have achieved only limited success in the classification of\nimages that undergo geometric transformations. In this work we present a novel\nTransformation Invariant Graph-based Network (TIGraNet), which learns\ngraph-based features that are inherently invariant to isometric transformations\nsuch as rotation and translation of input images. In particular, images are\nrepresented as signals on graphs, which permits to replace classical\nconvolution and pooling layers in deep networks with graph spectral convolution\nand dynamic graph pooling layers that together contribute to invariance to\nisometric transformations. Our experiments show high performance on rotated and\ntranslated images from the test set compared to classical architectures that\nare very sensitive to transformations in the data. The inherent invariance\nproperties of our framework provide key advantages, such as increased\nresiliency to data variability and sustained performance with limited training\nsets.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 15:51:13 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Khasanova", "Renata", ""], ["Frossard", "Pascal", ""]]}, {"id": "1703.00368", "submitter": "Gabriel Terejanu", "authors": "Xiao Lin, Asif Chowdhury, Xiaofan Wang, Gabriel Terejanu", "title": "Approximate Computational Approaches for Bayesian Sensor Placement in\n  High Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the cost of installing and maintaining sensors is usually high, sensor\nlocations are always strategically selected. For those aiming at inferring\ncertain quantities of interest (QoI), it is desirable to explore the dependency\nbetween sensor measurements and QoI. One of the most popular metric for the\ndependency is mutual information which naturally measures how much information\nabout one variable can be obtained given the other. However, computing mutual\ninformation is always challenging, and the result is unreliable in high\ndimension. In this paper, we propose an approach to find an approximate lower\nbound of mutual information and compute it in a lower dimension. Then, sensors\nare placed where highest mutual information (lower bound) is achieved and QoI\nis inferred via Bayes rule given sensor measurements. In addition, Bayesian\noptimization is introduced to provide a continuous mutual information surface\nover the domain and thus reduce the number of evaluations. A chemical release\naccident is simulated where multiple sensors are placed to locate the source of\nthe release. The result shows that the proposed approach is both effective and\nefficient in inferring QoI.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 16:29:12 GMT"}, {"version": "v2", "created": "Sun, 19 Mar 2017 16:03:04 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Lin", "Xiao", ""], ["Chowdhury", "Asif", ""], ["Wang", "Xiaofan", ""], ["Terejanu", "Gabriel", ""]]}, {"id": "1703.00377", "submitter": "Hanzhang Hu", "authors": "Hanzhang Hu and Wen Sun and Arun Venkatraman and Martial Hebert and J.\n  Andrew Bagnell", "title": "Gradient Boosting on Stochastic Data Streams", "comments": "To appear in AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a popular ensemble algorithm that generates more powerful\nlearners by linearly combining base models from a simpler hypothesis class. In\nthis work, we investigate the problem of adapting batch gradient boosting for\nminimizing convex loss functions to online setting where the loss at each\niteration is i.i.d sampled from an unknown distribution. To generalize from\nbatch to online, we first introduce the definition of online weak learning edge\nwith which for strongly convex and smooth loss functions, we present an\nalgorithm, Streaming Gradient Boosting (SGB) with exponential shrinkage\nguarantees in the number of weak learners. We further present an adaptation of\nSGB to optimize non-smooth loss functions, for which we derive a O(ln N/N)\nconvergence rate. We also show that our analysis can extend to adversarial\nonline learning setting under a stronger assumption that the online weak\nlearning edge will hold in adversarial setting. We finally demonstrate\nexperimental results showing that in practice our algorithms can achieve\ncompetitive results as classic gradient boosting while using less computation.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 16:46:54 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Hu", "Hanzhang", ""], ["Sun", "Wen", ""], ["Venkatraman", "Arun", ""], ["Hebert", "Martial", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1703.00380", "submitter": "Sandra Servia-Rodr\\'iguez", "authors": "Sandra Servia-Rodriguez, Liang Wang, Jianxin R. Zhao, Richard Mortier,\n  Hamed Haddadi", "title": "Privacy-Preserving Personal Model Training", "comments": null, "journal-ref": "The 3rd ACM/IEEE International Conference on Internet of Things\n  Design and Implementation (IoTDI 2018)", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many current Internet services rely on inferences from models trained on user\ndata. Commonly, both the training and inference tasks are carried out using\ncloud resources fed by personal data collected at scale from users. Holding and\nusing such large collections of personal data in the cloud creates privacy\nrisks to the data subjects, but is currently required for users to benefit from\nsuch services. We explore how to provide for model training and inference in a\nsystem where computation is pushed to the data in preference to moving data to\nthe cloud, obviating many current privacy risks. Specifically, we take an\ninitial model learnt from a small set of users and retrain it locally using\ndata from a single user. We evaluate on two tasks: one supervised learning\ntask, using a neural network to recognise users' current activity from\naccelerometer traces; and one unsupervised learning task, identifying topics in\na large set of documents. In both cases the accuracy is improved. We also\nanalyse the robustness of our approach against adversarial attacks, as well as\nits feasibility by presenting a performance evaluation on a representative\nresource-constrained device (a Raspberry Pi).\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 16:50:44 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 15:02:12 GMT"}, {"version": "v3", "created": "Tue, 3 Apr 2018 16:18:15 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Servia-Rodriguez", "Sandra", ""], ["Wang", "Liang", ""], ["Zhao", "Jianxin R.", ""], ["Mortier", "Richard", ""], ["Haddadi", "Hamed", ""]]}, {"id": "1703.00381", "submitter": "Junier Oliva", "authors": "Junier B. Oliva, Barnabas Poczos, Jeff Schneider", "title": "The Statistical Recurrent Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sophisticated gated recurrent neural network architectures like LSTMs and\nGRUs have been shown to be highly effective in a myriad of applications. We\ndevelop an un-gated unit, the statistical recurrent unit (SRU), that is able to\nlearn long term dependencies in data by only keeping moving averages of\nstatistics. The SRU's architecture is simple, un-gated, and contains a\ncomparable number of parameters to LSTMs; yet, SRUs perform favorably to more\nsophisticated LSTM and GRU alternatives, often outperforming one or both in\nvarious tasks. We show the efficacy of SRUs as compared to LSTMs and GRUs in an\nunbiased manner by optimizing respective architectures' hyperparameters in a\nBayesian optimization scheme for both synthetic and real-world tasks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 16:50:54 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Oliva", "Junier B.", ""], ["Poczos", "Barnabas", ""], ["Schneider", "Jeff", ""]]}, {"id": "1703.00403", "submitter": "Brian McWilliams", "authors": "Christina Heinze-Deml, Brian McWilliams, Nicolai Meinshausen", "title": "Preserving Differential Privacy Between Features in Distributed\n  Estimation", "comments": null, "journal-ref": "Stat 7 (1), 2018", "doi": "10.1002/sta4.189", "report-no": null, "categories": "stat.ML cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy is crucial in many applications of machine learning. Legal, ethical\nand societal issues restrict the sharing of sensitive data making it difficult\nto learn from datasets that are partitioned between many parties. One important\ninstance of such a distributed setting arises when information about each\nrecord in the dataset is held by different data owners (the design matrix is\n\"vertically-partitioned\").\n  In this setting few approaches exist for private data sharing for the\npurposes of statistical estimation and the classical setup of differential\nprivacy with a \"trusted curator\" preparing the data does not apply. We work\nwith the notion of $(\\epsilon,\\delta)$-distributed differential privacy which\nextends single-party differential privacy to the distributed,\nvertically-partitioned case. We propose PriDE, a scalable framework for\ndistributed estimation where each party communicates perturbed random\nprojections of their locally held features ensuring\n$(\\epsilon,\\delta)$-distributed differential privacy is preserved. For\n$\\ell_2$-penalized supervised learning problems PriDE has bounded estimation\nerror compared with the optimal estimates obtained without privacy constraints\nin the non-distributed setting. We confirm this empirically on real world and\nsynthetic datasets.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 17:30:14 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 08:59:48 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Heinze-Deml", "Christina", ""], ["McWilliams", "Brian", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1703.00410", "submitter": "Reuben Feinman", "authors": "Reuben Feinman, Ryan R. Curtin, Saurabh Shintre, Andrew B. Gardner", "title": "Detecting Adversarial Samples from Artifacts", "comments": "Submitted to ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are powerful nonlinear architectures that are\nknown to be robust to random perturbations of the input. However, these models\nare vulnerable to adversarial perturbations--small input changes crafted\nexplicitly to fool the model. In this paper, we ask whether a DNN can\ndistinguish adversarial samples from their normal and noisy counterparts. We\ninvestigate model confidence on adversarial samples by looking at Bayesian\nuncertainty estimates, available in dropout neural networks, and by performing\ndensity estimation in the subspace of deep features learned by the model. The\nresult is a method for implicit adversarial detection that is oblivious to the\nattack algorithm. We evaluate this method on a variety of standard datasets\nincluding MNIST and CIFAR-10 and show that it generalizes well across different\narchitectures and attacks. Our findings report that 85-93% ROC-AUC can be\nachieved on a number of standard classification tasks with a negative class\nthat consists of both normal and noisy samples.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 17:43:10 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 12:51:12 GMT"}, {"version": "v3", "created": "Wed, 15 Nov 2017 23:31:59 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Feinman", "Reuben", ""], ["Curtin", "Ryan R.", ""], ["Shintre", "Saurabh", ""], ["Gardner", "Andrew B.", ""]]}, {"id": "1703.00420", "submitter": "Lei Tai", "authors": "Lei Tai, Giuseppe Paolo and Ming Liu", "title": "Virtual-to-real Deep Reinforcement Learning: Continuous Control of\n  Mobile Robots for Mapless Navigation", "comments": "video: https://www.youtube.com/watch?v=9AOIwBYIBbs, 6 pages, 9\n  figures, to appear in he 2017 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2017), final submission version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learning-based mapless motion planner by taking the sparse\n10-dimensional range findings and the target position with respect to the\nmobile robot coordinate frame as input and the continuous steering commands as\noutput. Traditional motion planners for mobile ground robots with a laser range\nsensor mostly depend on the obstacle map of the navigation environment where\nboth the highly precise laser sensor and the obstacle map building work of the\nenvironment are indispensable. We show that, through an asynchronous deep\nreinforcement learning method, a mapless motion planner can be trained\nend-to-end without any manually designed features and prior demonstrations. The\ntrained planner can be directly applied in unseen virtual and real\nenvironments. The experiments show that the proposed mapless motion planner can\nnavigate the nonholonomic mobile robot to the desired targets without colliding\nwith any obstacles.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 18:10:20 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 08:09:19 GMT"}, {"version": "v3", "created": "Tue, 4 Jul 2017 09:56:05 GMT"}, {"version": "v4", "created": "Fri, 21 Jul 2017 17:26:00 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Tai", "Lei", ""], ["Paolo", "Giuseppe", ""], ["Liu", "Ming", ""]]}, {"id": "1703.00439", "submitter": "Tomoya Murata", "authors": "Tomoya Murata and Taiji Suzuki", "title": "Doubly Accelerated Stochastic Variance Reduced Dual Averaging Method for\n  Regularized Empirical Risk Minimization", "comments": "27 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a new accelerated stochastic gradient method for\nefficiently solving the convex regularized empirical risk minimization problem\nin mini-batch settings. The use of mini-batches is becoming a golden standard\nin the machine learning community, because mini-batch settings stabilize the\ngradient estimate and can easily make good use of parallel computing. The core\nof our proposed method is the incorporation of our new \"double acceleration\"\ntechnique and variance reduction technique. We theoretically analyze our\nproposed method and show that our method much improves the mini-batch\nefficiencies of previous accelerated stochastic methods, and essentially only\nneeds size $\\sqrt{n}$ mini-batches for achieving the optimal iteration\ncomplexities for both non-strongly and strongly convex objectives, where $n$ is\nthe training set size. Further, we show that even in non-mini-batch settings,\nour method achieves the best known convergence rate for both non-strongly and\nstrongly convex objectives.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 18:49:35 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 02:11:18 GMT"}, {"version": "v3", "created": "Sun, 16 Apr 2017 11:11:48 GMT"}, {"version": "v4", "created": "Tue, 19 Sep 2017 12:48:00 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Murata", "Tomoya", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1703.00440", "submitter": "Ke Li", "authors": "Ke Li and Jitendra Malik", "title": "Fast k-Nearest Neighbour Search via Prioritized DCI", "comments": "14 pages, 6 figures; International Conference on Machine Learning\n  (ICML), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most exact methods for k-nearest neighbour search suffer from the curse of\ndimensionality; that is, their query times exhibit exponential dependence on\neither the ambient or the intrinsic dimensionality. Dynamic Continuous Indexing\n(DCI) offers a promising way of circumventing the curse and successfully\nreduces the dependence of query time on intrinsic dimensionality from\nexponential to sublinear. In this paper, we propose a variant of DCI, which we\ncall Prioritized DCI, and show a remarkable improvement in the dependence of\nquery time on intrinsic dimensionality. In particular, a linear increase in\nintrinsic dimensionality, or equivalently, an exponential increase in the\nnumber of points near a query, can be mostly counteracted with just a linear\nincrease in space. We also demonstrate empirically that Prioritized DCI\nsignificantly outperforms prior methods. In particular, relative to\nLocality-Sensitive Hashing (LSH), Prioritized DCI reduces the number of\ndistance evaluations by a factor of 14 to 116 and the memory consumption by a\nfactor of 21.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 18:51:13 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 17:46:04 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Li", "Ke", ""], ["Malik", "Jitendra", ""]]}, {"id": "1703.00441", "submitter": "Ke Li", "authors": "Ke Li and Jitendra Malik", "title": "Learning to Optimize Neural Nets", "comments": "10 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to Optimize is a recently proposed framework for learning\noptimization algorithms using reinforcement learning. In this paper, we explore\nlearning an optimization algorithm for training shallow neural nets. Such\nhigh-dimensional stochastic optimization problems present interesting\nchallenges for existing reinforcement learning algorithms. We develop an\nextension that is suited to learning optimization algorithms in this setting\nand demonstrate that the learned optimization algorithm consistently\noutperforms other known optimization algorithms even on unseen tasks and is\nrobust to changes in stochasticity of gradients and the neural net\narchitecture. More specifically, we show that an optimization algorithm trained\nwith the proposed method on the problem of training a neural net on MNIST\ngeneralizes to the problems of training neural nets on the Toronto Faces\nDataset, CIFAR-10 and CIFAR-100.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 18:52:23 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 18:59:01 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Li", "Ke", ""], ["Malik", "Jitendra", ""]]}, {"id": "1703.00443", "submitter": "Brandon Amos", "authors": "Brandon Amos, J. Zico Kolter", "title": "OptNet: Differentiable Optimization as a Layer in Neural Networks", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents OptNet, a network architecture that integrates\noptimization problems (here, specifically in the form of quadratic programs) as\nindividual layers in larger end-to-end trainable deep networks. These layers\nencode constraints and complex dependencies between the hidden states that\ntraditional convolutional and fully-connected layers often cannot capture. In\nthis paper, we explore the foundations for such an architecture: we show how\ntechniques from sensitivity analysis, bilevel optimization, and implicit\ndifferentiation can be used to exactly differentiate through these layers and\nwith respect to layer parameters; we develop a highly efficient solver for\nthese layers that exploits fast GPU-based batch solves within a primal-dual\ninterior point method, and which provides backpropagation gradients with\nvirtually no additional cost on top of the solve; and we highlight the\napplication of these approaches in several problems. In one notable example, we\nshow that the method is capable of learning to play mini-Sudoku (4x4) given\njust input and output games, with no a priori information about the rules of\nthe game; this highlights the ability of our architecture to learn hard\nconstraints better than other neural architectures.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 18:58:48 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 17:59:07 GMT"}, {"version": "v3", "created": "Fri, 12 Jan 2018 19:44:25 GMT"}, {"version": "v4", "created": "Mon, 14 Oct 2019 18:03:26 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Amos", "Brandon", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1703.00472", "submitter": "Rika Antonova", "authors": "Rika Antonova, Silvia Cruciani, Christian Smith, Danica Kragic", "title": "Reinforcement Learning for Pivoting Task", "comments": "(Rika Antonova and Silvia Cruciani contributed equally)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose an approach to learn a robust policy for solving the\npivoting task. Recently, several model-free continuous control algorithms were\nshown to learn successful policies without prior knowledge of the dynamics of\nthe task. However, obtaining successful policies required thousands to millions\nof training episodes, limiting the applicability of these approaches to real\nhardware. We developed a training procedure that allows us to use a simple\ncustom simulator to learn policies robust to the mismatch of simulation vs\nrobot. In our experiments, we demonstrate that the policy learned in the\nsimulator is able to pivot the object to the desired target angle on the real\nrobot. We also show generalization to an object with different inertia, shape,\nmass and friction properties than those used during training. This result is a\nstep towards making model-free reinforcement learning available for solving\nrobotics tasks via pre-training in simulators that offer only an imprecise\nmatch to the real-world dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 19:25:55 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Antonova", "Rika", ""], ["Cruciani", "Silvia", ""], ["Smith", "Christian", ""], ["Kragic", "Danica", ""]]}, {"id": "1703.00484", "submitter": "Rad Niazadeh", "authors": "Shuchi Chawla, Nikhil Devanur, Janardhan Kulkarni, Rad Niazadeh", "title": "Truth and Regret in Online Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a scheduling problem where a cloud service provider has multiple\nunits of a resource available over time. Selfish clients submit jobs, each with\nan arrival time, deadline, length, and value. The service provider's goal is to\nimplement a truthful online mechanism for scheduling jobs so as to maximize the\nsocial welfare of the schedule. Recent work shows that under a stochastic\nassumption on job arrivals, there is a single-parameter family of mechanisms\nthat achieves near-optimal social welfare. We show that given any such family\nof near-optimal online mechanisms, there exists an online mechanism that in the\nworst case performs nearly as well as the best of the given mechanisms. Our\nmechanism is truthful whenever the mechanisms in the given family are truthful\nand prompt, and achieves optimal (within constant factors) regret.\n  We model the problem of competing against a family of online scheduling\nmechanisms as one of learning from expert advice. A primary challenge is that\nany scheduling decisions we make affect not only the payoff at the current\nstep, but also the resource availability and payoffs in future steps.\nFurthermore, switching from one algorithm (a.k.a. expert) to another in an\nonline fashion is challenging both because it requires synchronization with the\nstate of the latter algorithm as well as because it affects the incentive\nstructure of the algorithms. We further show how to adapt our algorithm to a\nnon-clairvoyant setting where job lengths are unknown until jobs are run to\ncompletion. Once again, in this setting, we obtain truthfulness along with\nasymptotically optimal regret (within poly-logarithmic factors).\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 20:09:43 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Chawla", "Shuchi", ""], ["Devanur", "Nikhil", ""], ["Kulkarni", "Janardhan", ""], ["Niazadeh", "Rad", ""]]}, {"id": "1703.00512", "submitter": "Randal Olson", "authors": "Randal S. Olson, William La Cava, Patryk Orzechowski, Ryan J.\n  Urbanowicz, Jason H. Moore", "title": "PMLB: A Large Benchmark Suite for Machine Learning Evaluation and\n  Comparison", "comments": "14 pages, 5 figures, submitted for review to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The selection, development, or comparison of machine learning methods in data\nmining can be a difficult task based on the target problem and goals of a\nparticular study. Numerous publicly available real-world and simulated\nbenchmark datasets have emerged from different sources, but their organization\nand adoption as standards have been inconsistent. As such, selecting and\ncurating specific benchmarks remains an unnecessary burden on machine learning\npractitioners and data scientists. The present study introduces an accessible,\ncurated, and developing public benchmark resource to facilitate identification\nof the strengths and weaknesses of different machine learning methodologies. We\ncompare meta-features among the current set of benchmark datasets in this\nresource to characterize the diversity of available data. Finally, we apply a\nnumber of established machine learning methods to the entire benchmark suite\nand analyze how datasets and algorithms cluster in terms of performance. This\nwork is an important first step towards understanding the limitations of\npopular benchmarking suites and developing a resource that connects existing\nbenchmarking standards to more diverse and efficient standards in the future.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 21:20:11 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Olson", "Randal S.", ""], ["La Cava", "William", ""], ["Orzechowski", "Patryk", ""], ["Urbanowicz", "Ryan J.", ""], ["Moore", "Jason H.", ""]]}, {"id": "1703.00522", "submitter": "Wojciech Czarnecki", "authors": "Wojciech Marian Czarnecki, Grzegorz \\'Swirszcz, Max Jaderberg, Simon\n  Osindero, Oriol Vinyals, Koray Kavukcuoglu", "title": "Understanding Synthetic Gradients and Decoupled Neural Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training neural networks, the use of Synthetic Gradients (SG) allows\nlayers or modules to be trained without update locking - without waiting for a\ntrue error gradient to be backpropagated - resulting in Decoupled Neural\nInterfaces (DNIs). This unlocked ability of being able to update parts of a\nneural network asynchronously and with only local information was demonstrated\nto work empirically in Jaderberg et al (2016). However, there has been very\nlittle demonstration of what changes DNIs and SGs impose from a functional,\nrepresentational, and learning dynamics point of view. In this paper, we study\nDNIs through the use of synthetic gradients on feed-forward networks to better\nunderstand their behaviour and elucidate their effect on optimisation. We show\nthat the incorporation of SGs does not affect the representational strength of\nthe learning system for a neural network, and prove the convergence of the\nlearning system for linear and deep linear models. On practical problems we\ninvestigate the mechanism by which synthetic gradient estimators approximate\nthe true loss, and, surprisingly, how that leads to drastically different\nlayer-wise representations. Finally, we also expose the relationship of using\nsynthetic gradients to other error approximation techniques and find a unifying\nlanguage for discussion and comparison.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 21:41:09 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Czarnecki", "Wojciech Marian", ""], ["\u015awirszcz", "Grzegorz", ""], ["Jaderberg", "Max", ""], ["Osindero", "Simon", ""], ["Vinyals", "Oriol", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1703.00535", "submitter": "Sven Schmit", "authors": "Sven Schmit and Carlos Riquelme", "title": "Human Interaction with Recommendation Systems", "comments": "Accepted to AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recommendation algorithms rely on user data to generate recommendations.\nHowever, these recommendations also affect the data obtained from future users.\nThis work aims to understand the effects of this dynamic interaction. We\npropose a simple model where users with heterogeneous preferences arrive over\ntime. Based on this model, we prove that naive estimators, i.e. those which\nignore this feedback loop, are not consistent. We show that consistent\nestimators are efficient in the presence of myopic agents. Our results are\nvalidated using extensive simulations.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 22:28:42 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 01:25:51 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 17:40:02 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Schmit", "Sven", ""], ["Riquelme", "Carlos", ""]]}, {"id": "1703.00557", "submitter": "Sharan Vaswani", "authors": "Sharan Vaswani, Branislav Kveton, Zheng Wen, Mohammad Ghavamzadeh,\n  Laks Lakshmanan, Mark Schmidt", "title": "Model-Independent Online Learning for Influence Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider influence maximization (IM) in social networks, which is the\nproblem of maximizing the number of users that become aware of a product by\nselecting a set of \"seed\" users to expose the product to. While prior work\nassumes a known model of information diffusion, we propose a novel\nparametrization that not only makes our framework agnostic to the underlying\ndiffusion model, but also statistically efficient to learn from data. We give a\ncorresponding monotone, submodular surrogate function, and show that it is a\ngood approximation to the original IM objective. We also consider the case of a\nnew marketer looking to exploit an existing social network, while\nsimultaneously learning the factors governing information propagation. For\nthis, we propose a pairwise-influence semi-bandit feedback model and develop a\nLinUCB-based bandit algorithm. Our model-independent analysis shows that our\nregret bound has a better (as compared to previous work) dependence on the size\nof the network. Experimental evaluation suggests that our framework is robust\nto the underlying diffusion model and can efficiently learn a near-optimal\nsolution.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 23:54:40 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 17:52:19 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Vaswani", "Sharan", ""], ["Kveton", "Branislav", ""], ["Wen", "Zheng", ""], ["Ghavamzadeh", "Mohammad", ""], ["Lakshmanan", "Laks", ""], ["Schmidt", "Mark", ""]]}, {"id": "1703.00560", "submitter": "Yuandong Tian", "authors": "Yuandong Tian", "title": "An Analytical Formula of Population Gradient for two-layered ReLU\n  network and its Applications in Convergence and Critical Point Analysis", "comments": "International Conference on Machine Learning (ICML) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore theoretical properties of training a two-layered\nReLU network $g(\\mathbf{x}; \\mathbf{w}) = \\sum_{j=1}^K\n\\sigma(\\mathbf{w}_j^T\\mathbf{x})$ with centered $d$-dimensional spherical\nGaussian input $\\mathbf{x}$ ($\\sigma$=ReLU). We train our network with gradient\ndescent on $\\mathbf{w}$ to mimic the output of a teacher network with the same\narchitecture and fixed parameters $\\mathbf{w}^*$. We show that its population\ngradient has an analytical formula, leading to interesting theoretical analysis\nof critical points and convergence behaviors. First, we prove that critical\npoints outside the hyperplane spanned by the teacher parameters\n(\"out-of-plane\") are not isolated and form manifolds, and characterize in-plane\ncritical-point-free regions for two ReLU case. On the other hand, convergence\nto $\\mathbf{w}^*$ for one ReLU node is guaranteed with at least\n$(1-\\epsilon)/2$ probability, if weights are initialized randomly with standard\ndeviation upper-bounded by $O(\\epsilon/\\sqrt{d})$, consistent with empirical\npractice. For network with many ReLU nodes, we prove that an infinitesimal\nperturbation of weight initialization results in convergence towards\n$\\mathbf{w}^*$ (or its permutation), a phenomenon known as spontaneous\nsymmetric-breaking (SSB) in physics. We assume no independence of ReLU\nactivations. Simulation verifies our findings.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 00:15:00 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 18:42:08 GMT"}], "update_date": "2017-05-26", "authors_parsed": [["Tian", "Yuandong", ""]]}, {"id": "1703.00561", "submitter": "David Moore", "authors": "David A. Moore and Stuart J. Russell", "title": "Signal-based Bayesian Seismic Monitoring", "comments": "Appearing at AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting weak seismic events from noisy sensors is a difficult perceptual\ntask. We formulate this task as Bayesian inference and propose a generative\nmodel of seismic events and signals across a network of spatially distributed\nstations. Our system, SIGVISA, is the first to directly model seismic\nwaveforms, allowing it to incorporate a rich representation of the physics\nunderlying the signal generation process. We use Gaussian processes over\nwavelet parameters to predict detailed waveform fluctuations based on\nhistorical events, while degrading smoothly to simple parametric envelopes in\nregions with no historical seismicity. Evaluating on data from the western US,\nwe recover three times as many events as previous work, and reduce mean\nlocation errors by a factor of four while greatly increasing sensitivity to\nlow-magnitude events.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 00:19:12 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Moore", "David A.", ""], ["Russell", "Stuart J.", ""]]}, {"id": "1703.00564", "submitter": "Zhenqin Wu", "authors": "Zhenqin Wu, Bharath Ramsundar, Evan N. Feinberg, Joseph Gomes, Caleb\n  Geniesse, Aneesh S. Pappu, Karl Leswing and Vijay Pande", "title": "MoleculeNet: A Benchmark for Molecular Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular machine learning has been maturing rapidly over the last few years.\nImproved methods and the presence of larger datasets have enabled machine\nlearning algorithms to make increasingly accurate predictions about molecular\nproperties. However, algorithmic progress has been limited due to the lack of a\nstandard benchmark to compare the efficacy of proposed methods; most new\nalgorithms are benchmarked on different datasets making it challenging to gauge\nthe quality of proposed methods. This work introduces MoleculeNet, a large\nscale benchmark for molecular machine learning. MoleculeNet curates multiple\npublic datasets, establishes metrics for evaluation, and offers high quality\nopen-source implementations of multiple previously proposed molecular\nfeaturization and learning algorithms (released as part of the DeepChem open\nsource library). MoleculeNet benchmarks demonstrate that learnable\nrepresentations are powerful tools for molecular machine learning and broadly\noffer the best performance. However, this result comes with caveats. Learnable\nrepresentations still struggle to deal with complex tasks under data scarcity\nand highly imbalanced classification. For quantum mechanical and biophysical\ndatasets, the use of physics-aware featurizations can be more important than\nchoice of particular learning algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 00:39:53 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 08:05:38 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 00:52:38 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Wu", "Zhenqin", ""], ["Ramsundar", "Bharath", ""], ["Feinberg", "Evan N.", ""], ["Gomes", "Joseph", ""], ["Geniesse", "Caleb", ""], ["Pappu", "Aneesh S.", ""], ["Leswing", "Karl", ""], ["Pande", "Vijay", ""]]}, {"id": "1703.00573", "submitter": "Rong Ge", "authors": "Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, Yi Zhang", "title": "Generalization and Equilibrium in Generative Adversarial Nets (GANs)", "comments": "This is an updated version of an ICML'17 paper with the same title.\n  The main difference is that in the ICML'17 version the pure equilibrium\n  result was only proved for Wasserstein GAN. In the current version the result\n  applies to most reasonable training objectives. In particular, Theorem 4.3\n  now applies to both original GAN and Wasserstein GAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that training of generative adversarial network (GAN) may not have\ngood generalization properties; e.g., training may appear successful but the\ntrained distribution may be far from target distribution in standard metrics.\nHowever, generalization does occur for a weaker metric called neural net\ndistance. It is also shown that an approximate pure equilibrium exists in the\ndiscriminator/generator game for a special class of generators with natural\ntraining objectives when generator capacity and training set sizes are\nmoderate.\n  This existence of equilibrium inspires MIX+GAN protocol, which can be\ncombined with any existing GAN training, and empirically shown to improve some\nof them.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 01:14:03 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 16:19:00 GMT"}, {"version": "v3", "created": "Tue, 4 Apr 2017 00:41:13 GMT"}, {"version": "v4", "created": "Sat, 17 Jun 2017 22:04:07 GMT"}, {"version": "v5", "created": "Tue, 1 Aug 2017 19:51:56 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Arora", "Sanjeev", ""], ["Ge", "Rong", ""], ["Liang", "Yingyu", ""], ["Ma", "Tengyu", ""], ["Zhang", "Yi", ""]]}, {"id": "1703.00579", "submitter": "Carlos Riquelme Ruiz", "authors": "Carlos Riquelme, Mohammad Ghavamzadeh, Alessandro Lazaric", "title": "Active Learning for Accurate Estimation of Linear Models", "comments": "37 pages, 8 figures, International Conference on Machine Learning,\n  ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the sequential decision making problem where the goal is to\nestimate uniformly well a number of linear models, given a shared budget of\nrandom contexts independently sampled from a known distribution. The decision\nmaker must query one of the linear models for each incoming context, and\nreceives an observation corrupted by noise levels that are unknown, and depend\non the model instance. We present Trace-UCB, an adaptive allocation algorithm\nthat learns the noise levels while balancing contexts accordingly across the\ndifferent linear functions, and derive guarantees for simple regret in both\nexpectation and high-probability. Finally, we extend the algorithm and its\nguarantees to high dimensional settings, where the number of linear models\ntimes the dimension of the contextual space is higher than the total budget of\nsamples. Simulations with real data suggest that Trace-UCB is remarkably\nrobust, outperforming a number of baselines even when its assumptions are\nviolated.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 01:29:57 GMT"}, {"version": "v2", "created": "Sat, 29 Jul 2017 19:41:29 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Riquelme", "Carlos", ""], ["Ghavamzadeh", "Mohammad", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "1703.00593", "submitter": "Gang Niu", "authors": "Ryuichi Kiryo, Gang Niu, Marthinus C. du Plessis, and Masashi Sugiyama", "title": "Positive-Unlabeled Learning with Non-Negative Risk Estimator", "comments": "NIPS 2017 camera-ready version (this paper was selected for oral\n  presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From only positive (P) and unlabeled (U) data, a binary classifier could be\ntrained with PU learning, in which the state of the art is unbiased PU\nlearning. However, if its model is very flexible, empirical risks on training\ndata will go negative, and we will suffer from serious overfitting. In this\npaper, we propose a non-negative risk estimator for PU learning: when getting\nminimized, it is more robust against overfitting, and thus we are able to use\nvery flexible models (such as deep neural networks) given limited P data.\nMoreover, we analyze the bias, consistency, and mean-squared-error reduction of\nthe proposed risk estimator, and bound the estimation error of the resulting\nempirical risk minimizer. Experiments demonstrate that our risk estimator fixes\nthe overfitting problem of its unbiased counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 02:49:33 GMT"}, {"version": "v2", "created": "Sat, 4 Nov 2017 11:18:21 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Kiryo", "Ryuichi", ""], ["Niu", "Gang", ""], ["Plessis", "Marthinus C. du", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1703.00617", "submitter": "Benjamin Rubinstein", "authors": "Neil G. Marchant and Benjamin I. P. Rubinstein", "title": "In Search of an Entity Resolution OASIS: Optimal Asymptotic Sequential\n  Importance Sampling", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity resolution (ER) presents unique challenges for evaluation methodology.\nWhile crowdsourcing platforms acquire ground truth, sound approaches to\nsampling must drive labelling efforts. In ER, extreme class imbalance between\nmatching and non-matching records can lead to enormous labelling requirements\nwhen seeking statistically consistent estimates for rigorous evaluation. This\npaper addresses this important challenge with the OASIS algorithm: a sampler\nand F-measure estimator for ER evaluation. OASIS draws samples from a (biased)\ninstrumental distribution, chosen to ensure estimators with optimal asymptotic\nvariance. As new labels are collected OASIS updates this instrumental\ndistribution via a Bayesian latent variable model of the annotator oracle, to\nquickly focus on unlabelled items providing more information. We prove that\nresulting estimates of F-measure, precision, recall converge to the true\npopulation values. Thorough comparisons of sampling methods on a variety of ER\ndatasets demonstrate significant labelling reductions of up to 83% without loss\nto estimate accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 04:49:22 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 07:34:10 GMT"}, {"version": "v3", "created": "Mon, 26 Jun 2017 01:28:50 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Marchant", "Neil G.", ""], ["Rubinstein", "Benjamin I. P.", ""]]}, {"id": "1703.00660", "submitter": "Yiling Yuan", "authors": "Yiling Yuan, Tao Yang, Hui Feng, Bo Hu, Jianqiu Zhang, Bin Wang and\n  Qiyong Lu", "title": "Traffic-Aware Transmission Mode Selection in D2D-enabled Cellular\n  Networks with Token System", "comments": "7 pages, 6 figures. A shorter version is submitted to EUSIPCO", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a D2D-enabled cellular network where user equipments (UEs) owned\nby rational users are incentivized to form D2D pairs using tokens. They\nexchange tokens electronically to \"buy\" and \"sell\" D2D services. Meanwhile the\ndevices have the ability to choose the transmission mode, i.e. receiving data\nvia cellular links or D2D links. Thus taking the different benefits brought by\ndiverse traffic types as a prior, the UEs can utilize their tokens more\nefficiently via transmission mode selection. In this paper, the optimal\ntransmission mode selection strategy as well as token collection policy are\ninvestigated to maximize the long-term utility in the dynamic network\nenvironment. The optimal policy is proved to be a threshold strategy, and the\nthresholds have a monotonicity property. Numerical simulations verify our\nobservations and the gain from transmission mode selection is observed.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 08:18:50 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 15:26:26 GMT"}, {"version": "v3", "created": "Tue, 13 Jun 2017 06:43:01 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Yuan", "Yiling", ""], ["Yang", "Tao", ""], ["Feng", "Hui", ""], ["Hu", "Bo", ""], ["Zhang", "Jianqiu", ""], ["Wang", "Bin", ""], ["Lu", "Qiyong", ""]]}, {"id": "1703.00663", "submitter": "Nicolas Gillis", "authors": "Nicolas Gillis", "title": "Introduction to Nonnegative Matrix Factorization", "comments": "18 pages, 4 figures", "journal-ref": "SIAG/OPT Views and News 25 (1), pp. 7-16 (2017)", "doi": null, "report-no": null, "categories": "cs.NA cs.CV cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce and provide a short overview of nonnegative\nmatrix factorization (NMF). Several aspects of NMF are discussed, namely, the\napplication in hyperspectral imaging, geometry and uniqueness of NMF solutions,\ncomplexity, algorithms, and its link with extended formulations of polyhedra.\nIn order to put NMF into perspective, the more general problem class of\nconstrained low-rank matrix approximation problems is first briefly introduced.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 08:23:04 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Gillis", "Nicolas", ""]]}, {"id": "1703.00674", "submitter": "Virag Shah", "authors": "Virag Shah, Lennart Gulikers, Laurent Massoulie, Milan Vojnovic", "title": "Adaptive Matching for Expert Systems with Uncertain Task Types", "comments": "A part of it presented at Allerton Conference 2017, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A matching in a two-sided market often incurs an externality: a matched\nresource may become unavailable to the other side of the market, at least for a\nwhile. This is especially an issue in online platforms involving human experts\nas the expert resources are often scarce. The efficient utilization of experts\nin these platforms is made challenging by the fact that the information\navailable about the parties involved is usually limited.\n  To address this challenge, we develop a model of a task-expert matching\nsystem where a task is matched to an expert using not only the prior\ninformation about the task but also the feedback obtained from the past\nmatches. In our model the tasks arrive online while the experts are fixed and\nconstrained by a finite service capacity. For this model, we characterize the\nmaximum task resolution throughput a platform can achieve. We show that the\nnatural greedy approaches where each expert is assigned a task most suitable to\nher skill is suboptimal, as it does not internalize the above externality. We\ndevelop a throughput optimal backpressure algorithm which does so by accounting\nfor the `congestion' among different task types. Finally, we validate our model\nand confirm our theoretical findings with data-driven simulations via logs of\nMath.StackExchange, a StackOverflow forum dedicated to mathematics.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 09:11:32 GMT"}, {"version": "v2", "created": "Sat, 21 Oct 2017 13:04:57 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 22:59:52 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Shah", "Virag", ""], ["Gulikers", "Lennart", ""], ["Massoulie", "Laurent", ""], ["Vojnovic", "Milan", ""]]}, {"id": "1703.00676", "submitter": "Nils Kriege", "authors": "Nils M. Kriege, Marion Neumann, Christopher Morris, Kristian Kersting,\n  Petra Mutzel", "title": "A Unifying View of Explicit and Implicit Feature Maps of Graph Kernels", "comments": null, "journal-ref": "Data Mining and Knowledge Discovery 33 (2019) 1505-1547", "doi": "10.1007/s10618-019-00652-0", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-linear kernel methods can be approximated by fast linear ones using\nsuitable explicit feature maps allowing their application to large scale\nproblems. We investigate how convolution kernels for structured data are\ncomposed from base kernels and construct corresponding feature maps. On this\nbasis we propose exact and approximative feature maps for widely used graph\nkernels based on the kernel trick. We analyze for which kernels and graph\nproperties computation by explicit feature maps is feasible and actually more\nefficient. In particular, we derive approximative, explicit feature maps for\nstate-of-the-art kernels supporting real-valued attributes including the\nGraphHopper and graph invariant kernels. In extensive experiments we show that\nour approaches often achieve a classification accuracy close to the exact\nmethods based on the kernel trick, but require only a fraction of their running\ntime. Moreover, we propose and analyze algorithms for computing random walk,\nshortest-path and subgraph matching kernels by explicit and implicit feature\nmaps. Our theoretical results are confirmed experimentally by observing a phase\ntransition when comparing running time with respect to label diversity, walk\nlengths and subgraph size, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 09:20:31 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 10:22:48 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 20:50:50 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Kriege", "Nils M.", ""], ["Neumann", "Marion", ""], ["Morris", "Christopher", ""], ["Kersting", "Kristian", ""], ["Mutzel", "Petra", ""]]}, {"id": "1703.00729", "submitter": "Michal Moshkovitz", "authors": "Michal Moshkovitz, Naftali Tishby", "title": "Mixing Complexity and its Applications to Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest analyzing neural networks through the prism of space constraints.\nWe observe that most training algorithms applied in practice use bounded\nmemory, which enables us to use a new notion introduced in the study of\nspace-time tradeoffs that we call mixing complexity. This notion was devised in\norder to measure the (in)ability to learn using a bounded-memory algorithm. In\nthis paper we describe how we use mixing complexity to obtain new results on\nwhat can and cannot be learned using neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 11:34:38 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Moshkovitz", "Michal", ""], ["Tishby", "Naftali", ""]]}, {"id": "1703.00734", "submitter": "Xiangju Qin", "authors": "Xiangju Qin, Paul Blomstedt, Eemeli Lepp\\\"aaho, Pekka Parviainen,\n  Samuel Kaski", "title": "Distributed Bayesian Matrix Factorization with Limited Communication", "comments": "28 pages, 8 figures. The paper is published in Machine Learning\n  journal. An implementation of the method is is available in SMURFF software\n  on github (bmfpp branch): https://github.com/ExaScience/smurff", "journal-ref": "Machine Learning, 2019", "doi": "10.1007/s10994-019-05778-2", "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian matrix factorization (BMF) is a powerful tool for producing low-rank\nrepresentations of matrices and for predicting missing values and providing\nconfidence intervals. Scaling up the posterior inference for massive-scale\nmatrices is challenging and requires distributing both data and computation\nover many workers, making communication the main computational bottleneck.\nEmbarrassingly parallel inference would remove the communication needed, by\nusing completely independent computations on different data subsets, but it\nsuffers from the inherent unidentifiability of BMF solutions. We introduce a\nhierarchical decomposition of the joint posterior distribution, which couples\nthe subset inferences, allowing for embarrassingly parallel computations in a\nsequence of at most three stages. Using an efficient approximate\nimplementation, we show improvements empirically on both real and simulated\ndata. Our distributed approach is able to achieve a speed-up of almost an order\nof magnitude over the full posterior, with a negligible effect on predictive\naccuracy. Our method outperforms state-of-the-art embarrassingly parallel MCMC\nmethods in accuracy, and achieves results competitive to other available\ndistributed and parallel implementations of BMF.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 11:48:24 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 09:47:09 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 18:58:59 GMT"}, {"version": "v4", "created": "Wed, 27 Feb 2019 17:07:21 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Qin", "Xiangju", ""], ["Blomstedt", "Paul", ""], ["Lepp\u00e4aho", "Eemeli", ""], ["Parviainen", "Pekka", ""], ["Kaski", "Samuel", ""]]}, {"id": "1703.00737", "submitter": "Dimitri Block", "authors": "Malte Schmidt, Dimitri Block, Uwe Meier", "title": "Wireless Interference Identification with Convolutional Neural Networks", "comments": null, "journal-ref": "IEEE 15th International Conference on Industrial Informatics\n  (INDIN)", "doi": "10.1109/indin.2017.8104767", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The steadily growing use of license-free frequency bands requires reliable\ncoexistence management for deterministic medium utilization. For interference\nmitigation, proper wireless interference identification (WII) is essential. In\nthis work we propose the first WII approach based upon deep convolutional\nneural networks (CNNs). The CNN naively learns its features through\nself-optimization during an extensive data-driven GPU-based training process.\nWe propose a CNN example which is based upon sensing snapshots with a limited\nduration of 12.8 {\\mu}s and an acquisition bandwidth of 10 MHz. The CNN differs\nbetween 15 classes. They represent packet transmissions of IEEE 802.11 b/g,\nIEEE 802.15.4 and IEEE 802.15.1 with overlapping frequency channels within the\n2.4 GHz ISM band. We show that the CNN outperforms state-of-the-art WII\napproaches and has a classification accuracy greater than 95% for\nsignal-to-noise ratio of at least -5 dB.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 11:52:47 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Schmidt", "Malte", ""], ["Block", "Dimitri", ""], ["Meier", "Uwe", ""]]}, {"id": "1703.00757", "submitter": "Marie-Christine Jakobs", "authors": "Mike Czech, Eyke H\\\"ullermeier, Marie-Christine Jakobs, Heike Wehrheim", "title": "Predicting Rankings of Software Verification Competitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software verification competitions, such as the annual SV-COMP, evaluate\nsoftware verification tools with respect to their effectivity and efficiency.\nTypically, the outcome of a competition is a (possibly category-specific)\nranking of the tools. For many applications, such as building portfolio\nsolvers, it would be desirable to have an idea of the (relative) performance of\nverification tools on a given verification task beforehand, i.e., prior to\nactually running all tools on the task.\n  In this paper, we present a machine learning approach to predicting rankings\nof tools on verification tasks. The method builds upon so-called label ranking\nalgorithms, which we complement with appropriate kernels providing a similarity\nmeasure for verification tasks. Our kernels employ a graph representation for\nsoftware source code that mixes elements of control flow and program dependence\ngraphs with abstract syntax trees. Using data sets from SV-COMP, we demonstrate\nour rank prediction technique to generalize well and achieve a rather high\npredictive accuracy. In particular, our method outperforms a recently proposed\nfeature-based approach of Demyanova et al. (when applied to rank predictions).\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 12:28:12 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Czech", "Mike", ""], ["H\u00fcllermeier", "Eyke", ""], ["Jakobs", "Marie-Christine", ""], ["Wehrheim", "Heike", ""]]}, {"id": "1703.00767", "submitter": "Ambedkar Dukkipati", "authors": "Pranav Shyam and Shubham Gupta and Ambedkar Dukkipati", "title": "Attentive Recurrent Comparators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid learning requires flexible representations to quickly adopt to new\nevidence. We develop a novel class of models called Attentive Recurrent\nComparators (ARCs) that form representations of objects by cycling through them\nand making observations. Using the representations extracted by ARCs, we\ndevelop a way of approximating a \\textit{dynamic representation space} and use\nit for one-shot learning. In the task of one-shot classification on the\nOmniglot dataset, we achieve the state of the art performance with an error\nrate of 1.5\\%. This represents the first super-human result achieved for this\ntask with a generic model that uses only pixel information.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 12:47:40 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 12:23:16 GMT"}, {"version": "v3", "created": "Fri, 30 Jun 2017 07:37:56 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Shyam", "Pranav", ""], ["Gupta", "Shubham", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1703.00786", "submitter": "Shuming Ma", "authors": "Shuming Ma and Xu Sun", "title": "A Generic Online Parallel Learning Framework for Large Margin Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To speed up the training process, many existing systems use parallel\ntechnology for online learning algorithms. However, most research mainly focus\non stochastic gradient descent (SGD) instead of other algorithms. We propose a\ngeneric online parallel learning framework for large margin models, and also\nanalyze our framework on popular large margin algorithms, including MIRA and\nStructured Perceptron. Our framework is lock-free and easy to implement on\nexisting systems. Experiments show that systems with our framework can gain\nnear linear speed up by increasing running threads, and with no loss in\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 13:52:47 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Ma", "Shuming", ""], ["Sun", "Xu", ""]]}, {"id": "1703.00788", "submitter": "\\c{C}a\\u{g}lar G\\\"ul\\c{c}ehre", "authors": "Caglar Gulcehre, Jose Sotelo, Marcin Moczulski, Yoshua Bengio", "title": "A Robust Adaptive Stochastic Gradient Method for Deep Learning", "comments": "IJCNN 2017 Accepted Paper, An extension of our paper, \"ADASECANT:\n  Robust Adaptive Secant Method for Stochastic Gradient\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient algorithms are the main focus of large-scale optimization\nproblems and led to important successes in the recent advancement of the deep\nlearning algorithms. The convergence of SGD depends on the careful choice of\nlearning rate and the amount of the noise in stochastic estimates of the\ngradients. In this paper, we propose an adaptive learning rate algorithm, which\nutilizes stochastic curvature information of the loss function for\nautomatically tuning the learning rates. The information about the element-wise\ncurvature of the loss function is estimated from the local statistics of the\nstochastic first order gradients. We further propose a new variance reduction\ntechnique to speed up the convergence. In our experiments with deep neural\nnetworks, we obtained better performance compared to the popular stochastic\ngradient algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 14:03:48 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Gulcehre", "Caglar", ""], ["Sotelo", "Jose", ""], ["Moczulski", "Marcin", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.00796", "submitter": "Daniel Lerch Hostalot", "authors": "Daniel Lerch-Hostalot and David Meg\\'ias", "title": "Unsupervised Steganalysis Based on Artificial Training Sets", "comments": null, "journal-ref": null, "doi": "10.1016/j.engappai.2015.12.013", "report-no": null, "categories": "cs.MM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an unsupervised steganalysis method that combines artificial\ntraining setsand supervised classification is proposed. We provide a formal\nframework for unsupervisedclassification of stego and cover images in the\ntypical situation of targeted steganalysis (i.e.,for a known algorithm and\napproximate embedding bit rate). We also present a completeset of experiments\nusing 1) eight different image databases, 2) image features based on\nRichModels, and 3) three different embedding algorithms: Least Significant Bit\n(LSB) matching,Highly undetectable steganography (HUGO) and Wavelet Obtained\nWeights (WOW). Weshow that the experimental results outperform previous methods\nbased on Rich Models inthe majority of the tested cases. At the same time, the\nproposed approach bypasses theproblem of Cover Source Mismatch -when the\nembedding algorithm and bit rate are known-, since it removes the need of a\ntraining database when we have a large enough testing set.Furthermore, we\nprovide a generic proof of the proposed framework in the machine\nlearningcontext. Hence, the results of this paper could be extended to other\nclassification problemssimilar to steganalysis.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 14:25:13 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Lerch-Hostalot", "Daniel", ""], ["Meg\u00edas", "David", ""]]}, {"id": "1703.00810", "submitter": "Naftali Tishby", "authors": "Ravid Shwartz-Ziv and Naftali Tishby", "title": "Opening the Black Box of Deep Neural Networks via Information", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their great success, there is still no comprehensive theoretical\nunderstanding of learning with Deep Neural Networks (DNNs) or their inner\norganization. Previous work proposed to analyze DNNs in the \\textit{Information\nPlane}; i.e., the plane of the Mutual Information values that each layer\npreserves on the input and output variables. They suggested that the goal of\nthe network is to optimize the Information Bottleneck (IB) tradeoff between\ncompression and prediction, successively, for each layer.\n  In this work we follow up on this idea and demonstrate the effectiveness of\nthe Information-Plane visualization of DNNs. Our main results are: (i) most of\nthe training epochs in standard DL are spent on {\\emph compression} of the\ninput to efficient representation and not on fitting the training labels. (ii)\nThe representation compression phase begins when the training errors becomes\nsmall and the Stochastic Gradient Decent (SGD) epochs change from a fast drift\nto smaller training error into a stochastic relaxation, or random diffusion,\nconstrained by the training error value. (iii) The converged layers lie on or\nvery close to the Information Bottleneck (IB) theoretical bound, and the maps\nfrom the input to any hidden layer and from this hidden layer to the output\nsatisfy the IB self-consistent equations. This generalization through noise\nmechanism is unique to Deep Neural Networks and absent in one layer networks.\n(iv) The training time is dramatically reduced when adding more hidden layers.\nThus the main advantage of the hidden layers is computational. This can be\nexplained by the reduced relaxation time, as this it scales super-linearly\n(exponentially for simple diffusion) with the information compression from the\nprevious layer.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 14:53:14 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 10:00:24 GMT"}, {"version": "v3", "created": "Sat, 29 Apr 2017 17:32:47 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Shwartz-Ziv", "Ravid", ""], ["Tishby", "Naftali", ""]]}, {"id": "1703.00830", "submitter": "Colin White", "authors": "Pranjal Awasthi, Ainesh Bakshi, Maria-Florina Balcan, Colin White, and\n  David Woodruff", "title": "Robust Communication-Optimal Distributed Clustering Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the $k$-median and $k$-means clustering problems when\nthe data is distributed across many servers and can contain outliers. While\nthere has been a lot of work on these problems for worst-case instances, we\nfocus on gaining a finer understanding through the lens of beyond worst-case\nanalysis. Our main motivation is the following: for many applications such as\nclustering proteins by function or clustering communities in a social network,\nthere is some unknown target clustering, and the hope is that running a\n$k$-median or $k$-means algorithm will produce clusterings which are close to\nmatching the target clustering. Worst-case results can guarantee constant\nfactor approximations to the optimal $k$-median or $k$-means objective value,\nbut not closeness to the target clustering.\n  Our first result is a distributed algorithm which returns a near-optimal\nclustering assuming a natural notion of stability, namely, approximation\nstability [Balcan et. al 2013], even when a constant fraction of the data are\noutliers. The communication complexity is $\\tilde O(sk+z)$ where $s$ is the\nnumber of machines, $k$ is the number of clusters, and $z$ is the number of\noutliers.\n  Next, we show this amount of communication cannot be improved even in the\nsetting when the input satisfies various non-worst-case assumptions. We give a\nmatching $\\Omega(sk+z)$ lower bound on the communication required both for\napproximating the optimal $k$-means or $k$-median cost up to any constant, and\nfor returning a clustering that is close to the target clustering in Hamming\ndistance. These lower bounds hold even when the data satisfies approximation\nstability or other common notions of stability, and the cluster sizes are\nbalanced. Therefore, $\\Omega(sk+z)$ is a communication bottleneck, even for\nreal-world instances.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 15:27:14 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 19:08:04 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 19:18:19 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Bakshi", "Ainesh", ""], ["Balcan", "Maria-Florina", ""], ["White", "Colin", ""], ["Woodruff", "David", ""]]}, {"id": "1703.00837", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai and Hong Yu", "title": "Meta Networks", "comments": "Accepted at ICML 2017 - rewrote: the main section; added: MetaNet\n  algorithmic procedure; performed: Mini-ImageNet evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been successfully applied in applications with a large\namount of labeled data. However, the task of rapid generalization on new\nconcepts with small training data while preserving performances on previously\nlearned ones still presents a significant challenge to neural network models.\nIn this work, we introduce a novel meta learning method, Meta Networks\n(MetaNet), that learns a meta-level knowledge across tasks and shifts its\ninductive biases via fast parameterization for rapid generalization. When\nevaluated on Omniglot and Mini-ImageNet benchmarks, our MetaNet models achieve\na near human-level performance and outperform the baseline approaches by up to\n6% accuracy. We demonstrate several appealing properties of MetaNet relating to\ngeneralization and continual learning.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 15:52:55 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 16:12:40 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""], ["Yu", "Hong", ""]]}, {"id": "1703.00839", "submitter": "Louis Aslett", "authors": "Pedro M. Esperan\\c{c}a, Louis J. M. Aslett, Chris C. Holmes", "title": "Encrypted accelerated least squares regression", "comments": "Accepted for AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information that is stored in an encrypted format is, by definition, usually\nnot amenable to statistical analysis or machine learning methods. In this paper\nwe present detailed analysis of coordinate and accelerated gradient descent\nalgorithms which are capable of fitting least squares and penalised ridge\nregression models, using data encrypted under a fully homomorphic encryption\nscheme. Gradient descent is shown to dominate in terms of encrypted\ncomputational speed, and theoretical results are proven to give parameter\nbounds which ensure correctness of decryption. The characteristics of encrypted\ncomputation are empirically shown to favour a non-standard acceleration\ntechnique. This demonstrates the possibility of approximating conventional\nstatistical regression methods using encrypted data without compromising\nprivacy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 15:53:52 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Esperan\u00e7a", "Pedro M.", ""], ["Aslett", "Louis J. M.", ""], ["Holmes", "Chris C.", ""]]}, {"id": "1703.00847", "submitter": "Saurav Talukdar", "authors": "Saurav Talukdar, Deepjyoti Deka, Donatello Materassi and Murti V.\n  Salapaka", "title": "Exact Topology Reconstruction of Radial Dynamical Systems with\n  Applications to Distribution System of the Power Grid", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present a method to reconstruct the interconnectedness of\ndynamically related stochastic processes, where the interactions are\nbi-directional and the underlying topology is a tree. Our approach is based on\nmultivariate Wiener filtering which recovers spurious edges apart from the true\nedges in the topology reconstruction. The main contribution of this work is to\nshow that all spurious links obtained using Wiener filtering can be eliminated\nif the underlying topology is a tree based on which we present a three stage\nnetwork reconstruction procedure for trees. We illustrate the effectiveness of\nthe method developed by applying it on a typical distribution system of the\nelectric grid.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 16:15:49 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Talukdar", "Saurav", ""], ["Deka", "Deepjyoti", ""], ["Materassi", "Donatello", ""], ["Salapaka", "Murti V.", ""]]}, {"id": "1703.00854", "submitter": "Stephen Bach", "authors": "Stephen H. Bach, Bryan He, Alexander Ratner, Christopher R\\'e", "title": "Learning the Structure of Generative Models without Labeled Data", "comments": null, "journal-ref": "Proceedings of the 34th International Conference on Machine\n  Learning, Sydney, Australia, PMLR 70, 2017", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curating labeled training data has become the primary bottleneck in machine\nlearning. Recent frameworks address this bottleneck with generative models to\nsynthesize labels at scale from weak supervision sources. The generative\nmodel's dependency structure directly affects the quality of the estimated\nlabels, but selecting a structure automatically without any labeled data is a\ndistinct challenge. We propose a structure estimation method that maximizes the\n$\\ell_1$-regularized marginal pseudolikelihood of the observed data. Our\nanalysis shows that the amount of unlabeled data required to identify the true\nstructure scales sublinearly in the number of possible dependencies for a broad\nclass of models. Simulations show that our method is 100$\\times$ faster than a\nmaximum likelihood approach and selects $1/4$ as many extraneous dependencies.\nWe also show that our method provides an average of 1.5 F1 points of\nimprovement over existing, user-developed information extraction applications\non real-world data such as PubMed journal abstracts.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 16:52:09 GMT"}, {"version": "v2", "created": "Sat, 9 Sep 2017 21:22:57 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Bach", "Stephen H.", ""], ["He", "Bryan", ""], ["Ratner", "Alexander", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1703.00862", "submitter": "Adrian Bulat", "authors": "Adrian Bulat and Georgios Tzimiropoulos", "title": "Binarized Convolutional Landmark Localizers for Human Pose Estimation\n  and Face Alignment with Limited Resources", "comments": "ICCV 2017 Oral", "journal-ref": null, "doi": "10.1109/ICCV.2017.400", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to design architectures that retain the groundbreaking\nperformance of CNNs for landmark localization and at the same time are\nlightweight, compact and suitable for applications with limited computational\nresources. To this end, we make the following contributions: (a) we are the\nfirst to study the effect of neural network binarization on localization tasks,\nnamely human pose estimation and face alignment. We exhaustively evaluate\nvarious design choices, identify performance bottlenecks, and more importantly\npropose multiple orthogonal ways to boost performance. (b) Based on our\nanalysis, we propose a novel hierarchical, parallel and multi-scale residual\narchitecture that yields large performance improvement over the standard\nbottleneck block while having the same number of parameters, thus bridging the\ngap between the original network and its binarized counterpart. (c) We perform\na large number of ablation studies that shed light on the properties and the\nperformance of the proposed block. (d) We present results for experiments on\nthe most challenging datasets for human pose estimation and face alignment,\nreporting in many cases state-of-the-art performance. Code can be downloaded\nfrom https://www.adrianbulat.com/binary-cnn-landmarks\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 17:26:46 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 15:35:04 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Bulat", "Adrian", ""], ["Tzimiropoulos", "Georgios", ""]]}, {"id": "1703.00868", "submitter": "Atilim Gunes Baydin", "authors": "Tuan Anh Le, Atilim Gunes Baydin, Robert Zinkov, Frank Wood", "title": "Using Synthetic Data to Train Neural Networks is Model-Based Reasoning", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We draw a formal connection between using synthetic training data to optimize\nneural network parameters and approximate, Bayesian, model-based reasoning. In\nparticular, training a neural network using synthetic data can be viewed as\nlearning a proposal distribution generator for approximate inference in the\nsynthetic-data generative model. We demonstrate this connection in a\nrecognition task where we develop a novel Captcha-breaking architecture and\ntrain it using synthetic data, demonstrating both state-of-the-art performance\nand a way of computing task-specific posterior uncertainty. Using a neural\nnetwork trained this way, we also demonstrate successful breaking of real-world\nCaptchas currently used by Facebook and Wikipedia. Reasoning from these\nempirical results and drawing connections with Bayesian modeling, we discuss\nthe robustness of synthetic data results and suggest important considerations\nfor ensuring good neural network generalization when training with synthetic\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 17:43:19 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Le", "Tuan Anh", ""], ["Baydin", "Atilim Gunes", ""], ["Zinkov", "Robert", ""], ["Wood", "Frank", ""]]}, {"id": "1703.00887", "submitter": "Chi Jin", "authors": "Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M. Kakade, Michael I.\n  Jordan", "title": "How to Escape Saddle Points Efficiently", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that a perturbed form of gradient descent converges to a\nsecond-order stationary point in a number iterations which depends only\npoly-logarithmically on dimension (i.e., it is almost \"dimension-free\"). The\nconvergence rate of this procedure matches the well-known convergence rate of\ngradient descent to first-order stationary points, up to log factors. When all\nsaddle points are non-degenerate, all second-order stationary points are local\nminima, and our result thus shows that perturbed gradient descent can escape\nsaddle points almost for free. Our results can be directly applied to many\nmachine learning applications, including deep learning. As a particular\nconcrete example of such an application, we show that our results can be used\ndirectly to establish sharp global convergence rates for matrix factorization.\nOur results rely on a novel characterization of the geometry around saddle\npoints, which may be of independent interest to the non-convex optimization\ncommunity.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 18:35:24 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Jin", "Chi", ""], ["Ge", "Rong", ""], ["Netrapalli", "Praneeth", ""], ["Kakade", "Sham M.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1703.00893", "submitter": "Gautam Kamath", "authors": "Ilias Diakonikolas, Gautam Kamath, Daniel M. Kane, Jerry Li, Ankur\n  Moitra, Alistair Stewart", "title": "Being Robust (in High Dimensions) Can Be Practical", "comments": "Appeared in ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust estimation is much more challenging in high dimensions than it is in\none dimension: Most techniques either lead to intractable optimization problems\nor estimators that can tolerate only a tiny fraction of errors. Recent work in\ntheoretical computer science has shown that, in appropriate distributional\nmodels, it is possible to robustly estimate the mean and covariance with\npolynomial time algorithms that can tolerate a constant fraction of\ncorruptions, independent of the dimension. However, the sample and time\ncomplexity of these algorithms is prohibitively large for high-dimensional\napplications. In this work, we address both of these issues by establishing\nsample complexity bounds that are optimal, up to logarithmic factors, as well\nas giving various refinements that allow the algorithms to tolerate a much\nlarger fraction of corruptions. Finally, we show on both synthetic and real\ndata that our algorithms have state-of-the-art performance and suddenly make\nhigh-dimensional robust estimation a realistic possibility.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 18:50:33 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 21:55:28 GMT"}, {"version": "v3", "created": "Thu, 14 Dec 2017 17:59:21 GMT"}, {"version": "v4", "created": "Tue, 13 Mar 2018 17:51:44 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kamath", "Gautam", ""], ["Kane", "Daniel M.", ""], ["Li", "Jerry", ""], ["Moitra", "Ankur", ""], ["Stewart", "Alistair", ""]]}, {"id": "1703.00955", "submitter": "Zhiting Hu", "authors": "Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, Eric P.\n  Xing", "title": "Toward Controlled Generation of Text", "comments": "Code adapted for text style transfer is released at:\n  https://github.com/asyml/texar/tree/master/examples/text_style_transfer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic generation and manipulation of text is challenging and has limited\nsuccess compared to recent deep generative modeling in visual domain. This\npaper aims at generating plausible natural language sentences, whose attributes\nare dynamically controlled by learning disentangled latent representations with\ndesignated semantics. We propose a new neural generative model which combines\nvariational auto-encoders and holistic attribute discriminators for effective\nimposition of semantic structures. With differentiable approximation to\ndiscrete text samples, explicit constraints on independent attribute controls,\nand efficient collaborative learning of generator and discriminators, our model\nlearns highly interpretable representations from even only word annotations,\nand produces realistic sentences with desired attributes. Quantitative\nevaluation validates the accuracy of sentence and attribute generation.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 21:23:47 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 21:15:43 GMT"}, {"version": "v3", "created": "Tue, 23 Jan 2018 08:01:18 GMT"}, {"version": "v4", "created": "Thu, 13 Sep 2018 02:16:40 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Hu", "Zhiting", ""], ["Yang", "Zichao", ""], ["Liang", "Xiaodan", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric P.", ""]]}, {"id": "1703.00956", "submitter": "Marlos C. Machado", "authors": "Marlos C. Machado and Marc G. Bellemare and Michael Bowling", "title": "A Laplacian Framework for Option Discovery in Reinforcement Learning", "comments": "Appearing in the Proceedings of the 34th International Conference on\n  Machine Learning (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning and option discovery are two of the biggest\nchallenges in reinforcement learning (RL). Proto-value functions (PVFs) are a\nwell-known approach for representation learning in MDPs. In this paper we\naddress the option discovery problem by showing how PVFs implicitly define\noptions. We do it by introducing eigenpurposes, intrinsic reward functions\nderived from the learned representations. The options discovered from\neigenpurposes traverse the principal directions of the state space. They are\nuseful for multiple tasks because they are discovered without taking the\nenvironment's rewards into consideration. Moreover, different options act at\ndifferent time scales, making them helpful for exploration. We demonstrate\nfeatures of eigenpurposes in traditional tabular domains as well as in Atari\n2600 games.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 21:31:29 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 02:52:21 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Machado", "Marlos C.", ""], ["Bellemare", "Marc G.", ""], ["Bowling", "Michael", ""]]}, {"id": "1703.00977", "submitter": "Keerthiram Murugesan", "authors": "Keerthiram Murugesan, Jaime Carbonell", "title": "Self-Paced Multitask Learning with Shared Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces self-paced task selection to multitask learning, where\ninstances from more closely related tasks are selected in a progression of\neasier-to-harder tasks, to emulate an effective human education strategy, but\napplied to multitask machine learning. We develop the mathematical foundation\nfor the approach based on iterative selection of the most appropriate task,\nlearning the task parameters, and updating the shared knowledge, optimizing a\nnew bi-convex loss function. This proposed method applies quite generally,\nincluding to multitask feature learning, multitask learning with alternating\nstructure optimization, etc. Results show that in each of the above\nformulations self-paced (easier-to-harder) task selection outperforms the\nbaseline version of these methods in all the experiments.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 22:49:14 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 17:40:13 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Murugesan", "Keerthiram", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1703.00978", "submitter": "Tommaso Dreossi", "authors": "Tommaso Dreossi, Alexandre Donz\\'e, Sanjit A. Seshia", "title": "Compositional Falsification of Cyber-Physical Systems with Machine\n  Learning Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPS), such as automotive systems, are starting to\ninclude sophisticated machine learning (ML) components. Their correctness,\ntherefore, depends on properties of the inner ML modules. While learning\nalgorithms aim to generalize from examples, they are only as good as the\nexamples provided, and recent efforts have shown that they can produce\ninconsistent output under small adversarial perturbations. This raises the\nquestion: can the output from learning components can lead to a failure of the\nentire CPS? In this work, we address this question by formulating it as a\nproblem of falsifying signal temporal logic (STL) specifications for CPS with\nML components. We propose a compositional falsification framework where a\ntemporal logic falsifier and a machine learning analyzer cooperate with the aim\nof finding falsifying executions of the considered model. The efficacy of the\nproposed technique is shown on an automatic emergency braking system model with\na perception component based on deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 22:58:10 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 23:10:04 GMT"}, {"version": "v3", "created": "Sun, 16 Dec 2018 23:05:06 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Dreossi", "Tommaso", ""], ["Donz\u00e9", "Alexandre", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1703.00986", "submitter": "Wei Ping", "authors": "Wei Ping, Alexander Ihler", "title": "Belief Propagation in Conditional RBMs for Structured Prediction", "comments": "Artificial Intelligence and Statistics (AISTATS) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann machines~(RBMs) and conditional RBMs~(CRBMs) are popular\nmodels for a wide range of applications. In previous work, learning on such\nmodels has been dominated by contrastive divergence~(CD) and its variants.\nBelief propagation~(BP) algorithms are believed to be slow for structured\nprediction on conditional RBMs~(e.g., Mnih et al. [2011]), and not as good as\nCD when applied in learning~(e.g., Larochelle et al. [2012]). In this work, we\npresent a matrix-based implementation of belief propagation algorithms on\nCRBMs, which is easily scalable to tens of thousands of visible and hidden\nunits. We demonstrate that, in both maximum likelihood and max-margin learning,\ntraining conditional RBMs with BP as the inference routine can provide\nsignificantly better results than current state-of-the-art CD methods on\nstructured prediction problems. We also include practical guidelines on\ntraining CRBMs with BP, and some insights on the interaction of learning and\ninference algorithms for CRBMs.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 23:28:53 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Ping", "Wei", ""], ["Ihler", "Alexander", ""]]}, {"id": "1703.00989", "submitter": "Reza Bonyadi Reza Bonyadi", "authors": "Mohammad Reza Bonyadi, Quang M. Tieng, David C. Reutens", "title": "Optimization of distributions differences for classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new classification algorithm called Optimization\nof Distributions Differences (ODD). The algorithm aims to find a transformation\nfrom the feature space to a new space where the instances in the same class are\nas close as possible to one another while the gravity centers of these classes\nare as far as possible from one another. This aim is formulated as a\nmultiobjective optimization problem that is solved by a hybrid of an\nevolutionary strategy and the Quasi-Newton method. The choice of the\ntransformation function is flexible and could be any continuous space function.\nWe experiment with a linear and a non-linear transformation in this paper. We\nshow that the algorithm can outperform 6 other state-of-the-art classification\nmethods, namely naive Bayes, support vector machines, linear discriminant\nanalysis, multi-layer perceptrons, decision trees, and k-nearest neighbors, in\n12 standard classification datasets. Our results show that the method is less\nsensitive to the imbalanced number of instances comparing to these methods. We\nalso show that ODD maintains its performance better than other classification\nmethods in these datasets, hence, offers a better generalization ability.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 23:42:33 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Bonyadi", "Mohammad Reza", ""], ["Tieng", "Quang M.", ""], ["Reutens", "David C.", ""]]}, {"id": "1703.00994", "submitter": "Keerthiram Murugesan", "authors": "Keerthiram Murugesan, Jaime Carbonell, Yiming Yang", "title": "Co-Clustering for Multitask Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new multitask learning framework that learns a shared\nrepresentation among the tasks, incorporating both task and feature clusters.\nThe jointly-induced clusters yield a shared latent subspace where task\nrelationships are learned more effectively and more generally than in\nstate-of-the-art multitask learning methods. The proposed general framework\nenables the derivation of more specific or restricted state-of-the-art\nmultitask methods. The paper also proposes a highly-scalable multitask learning\nalgorithm, based on the new framework, using conjugate gradient descent and\ngeneralized \\textit{Sylvester equations}. Experimental results on synthetic and\nbenchmark datasets show that the proposed method systematically outperforms\nseveral state-of-the-art multitask learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 00:03:14 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Murugesan", "Keerthiram", ""], ["Carbonell", "Jaime", ""], ["Yang", "Yiming", ""]]}, {"id": "1703.01006", "submitter": "Amir Ghaderi", "authors": "Mohammadhani Fouladgar, Mostafa Parchami, Ramez Elmasri, Amir Ghaderi", "title": "Scalable Deep Traffic Flow Neural Networks for Urban Traffic Congestion\n  Prediction", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN.2017.7966128", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking congestion throughout the network road is a critical component of\nIntelligent transportation network management systems. Understanding how the\ntraffic flows and short-term prediction of congestion occurrence due to\nrush-hour or incidents can be beneficial to such systems to effectively manage\nand direct the traffic to the most appropriate detours. Many of the current\ntraffic flow prediction systems are designed by utilizing a central processing\ncomponent where the prediction is carried out through aggregation of the\ninformation gathered from all measuring stations. However, centralized systems\nare not scalable and fail provide real-time feedback to the system whereas in a\ndecentralized scheme, each node is responsible to predict its own short-term\ncongestion based on the local current measurements in neighboring nodes.\n  We propose a decentralized deep learning-based method where each node\naccurately predicts its own congestion state in real-time based on the\ncongestion state of the neighboring stations. Moreover, historical data from\nthe deployment site is not required, which makes the proposed method more\nsuitable for newly installed stations. In order to achieve higher performance,\nwe introduce a regularized Euclidean loss function that favors high congestion\nsamples over low congestion samples to avoid the impact of the unbalanced\ntraining dataset. A novel dataset for this purpose is designed based on the\ntraffic data obtained from traffic control stations in northern California.\nExtensive experiments conducted on the designed benchmark reflect a successful\ncongestion prediction.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 01:12:38 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Fouladgar", "Mohammadhani", ""], ["Parchami", "Mostafa", ""], ["Elmasri", "Ramez", ""], ["Ghaderi", "Amir", ""]]}, {"id": "1703.01014", "submitter": "Akshay Krishnamurthy", "authors": "Akshay Krishnamurthy, Alekh Agarwal, Tzu-Kuo Huang, Hal Daume III,\n  John Langford", "title": "Active Learning for Cost-Sensitive Classification", "comments": null, "journal-ref": "Journal of Machine Learning Research, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design an active learning algorithm for cost-sensitive multiclass\nclassification: problems where different errors have different costs. Our\nalgorithm, COAL, makes predictions by regressing to each label's cost and\npredicting the smallest. On a new example, it uses a set of regressors that\nperform well on past data to estimate possible costs for each label. It queries\nonly the labels that could be the best, ignoring the sure losers. We prove COAL\ncan be efficiently implemented for any regression family that admits squared\nloss optimization; it also enjoys strong guarantees with respect to predictive\nperformance and labeling effort. We empirically compare COAL to passive\nlearning and several active learning baselines, showing significant\nimprovements in labeling effort and test cost on real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 02:17:13 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 21:52:19 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 14:11:53 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Krishnamurthy", "Akshay", ""], ["Agarwal", "Alekh", ""], ["Huang", "Tzu-Kuo", ""], ["Daume", "Hal", "III"], ["Langford", "John", ""]]}, {"id": "1703.01026", "submitter": "Edward Barker", "authors": "Edward W. Barker and Charl J. Ras", "title": "Unsupervised Basis Function Adaptation for Reinforcement Learning", "comments": "Extended abstract submitted (3 March 2017) for 3rd Multidisciplinary\n  Conference on Reinforcement Learning and Decision Making (RLDM) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using reinforcement learning (RL) algorithms to evaluate a policy it is\ncommon, given a large state space, to introduce some form of approximation\narchitecture for the value function (VF). The exact form of this architecture\ncan have a significant effect on the accuracy of the VF estimate, however, and\ndetermining a suitable approximation architecture can often be a highly complex\ntask. Consequently there is a large amount of interest in the potential for\nallowing RL algorithms to adaptively generate approximation architectures.\n  We investigate a method of adapting approximation architectures which uses\nfeedback regarding the frequency with which an agent has visited certain states\nto guide which areas of the state space to approximate with greater detail.\nThis method is \"unsupervised\" in the sense that it makes no direct reference to\nreward or the VF estimate. We introduce an algorithm based upon this idea which\nadapts a state aggregation approximation architecture on-line.\n  A common method of scoring a VF estimate is to weight the squared Bellman\nerror of each state-action by the probability of that state-action occurring.\nAdopting this scoring method, and assuming $S$ states, we demonstrate\ntheoretically that - provided (1) the number of cells $X$ in the state\naggregation architecture is of order $\\sqrt{S}\\log_2{S}\\ln{S}$ or greater, (2)\nthe policy and transition function are close to deterministic, and (3) the\nprior for the transition function is uniformly distributed - our algorithm,\nused in conjunction with a suitable RL algorithm, can guarantee a score which\nis arbitrarily close to zero as $S$ becomes large. It is able to do this\ndespite having only $O(X \\log_2S)$ space complexity and negligible time\ncomplexity. The results take advantage of certain properties of the stationary\ndistributions of Markov chains.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 03:24:03 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Barker", "Edward W.", ""], ["Ras", "Charl J.", ""]]}, {"id": "1703.01030", "submitter": "Wen Sun", "authors": "Wen Sun, Arun Venkatraman, Geoffrey J. Gordon, Byron Boots, J. Andrew\n  Bagnell", "title": "Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential\n  Prediction", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have demonstrated state-of-the-art performance in sequential\ndecision making problems (e.g., robotics control, sequential prediction) with\ndeep neural network models. One often has access to near-optimal oracles that\nachieve good performance on the task during training. We demonstrate that\nAggreVaTeD --- a policy gradient extension of the Imitation Learning (IL)\napproach of (Ross & Bagnell, 2014) --- can leverage such an oracle to achieve\nfaster and better solutions with less training data than a less-informed\nReinforcement Learning (RL) technique. Using both feedforward and recurrent\nneural network predictors, we present stochastic gradient procedures on a\nsequential prediction task, dependency-parsing from raw image data, as well as\non various high dimensional robotics control problems. We also provide a\ncomprehensive theoretical study of IL that demonstrates we can expect up to\nexponentially lower sample complexity for learning with AggreVaTeD than with RL\nalgorithms, which backs our empirical findings. Our results and theory indicate\nthat the proposed approach can achieve superior performance with respect to the\noracle when the demonstrator is sub-optimal.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 04:12:03 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Sun", "Wen", ""], ["Venkatraman", "Arun", ""], ["Gordon", "Geoffrey J.", ""], ["Boots", "Byron", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1703.01040", "submitter": "Jangwon Lee", "authors": "Jangwon Lee and Michael S. Ryoo", "title": "Learning Robot Activities from First-Person Human Videos Using\n  Convolutional Future Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new approach that allows robot learning of new activities from\nunlabeled human example videos. Given videos of humans executing the same\nactivity from a human's viewpoint (i.e., first-person videos), our objective is\nto make the robot learn the temporal structure of the activity as its future\nregression network, and learn to transfer such model for its own motor\nexecution. We present a new deep learning model: We extend the state-of-the-art\nconvolutional object detection network for the representation/estimation of\nhuman hands in training videos, and newly introduce the concept of using a\nfully convolutional network to regress (i.e., predict) the intermediate scene\nrepresentation corresponding to the future frame (e.g., 1-2 seconds later).\nCombining these allows direct prediction of future locations of human hands and\nobjects, which enables the robot to infer the motor control plan using our\nmanipulation network. We experimentally confirm that our approach makes\nlearning of robot activities from unlabeled human interaction videos possible,\nand demonstrate that our robot is able to execute the learned collaborative\nactivities in real-time directly based on its camera input.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 05:27:50 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 08:02:11 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Lee", "Jangwon", ""], ["Ryoo", "Michael S.", ""]]}, {"id": "1703.01101", "submitter": "Volker Fischer", "authors": "Volker Fischer, Mummadi Chaithanya Kumar, Jan Hendrik Metzen, Thomas\n  Brox", "title": "Adversarial Examples for Semantic Image Segmentation", "comments": "ICLR 2017 workshop submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods in general and Deep Neural Networks in particular\nhave shown to be vulnerable to adversarial perturbations. So far this\nphenomenon has mainly been studied in the context of whole-image\nclassification. In this contribution, we analyse how adversarial perturbations\ncan affect the task of semantic segmentation. We show how existing adversarial\nattackers can be transferred to this task and that it is possible to create\nimperceptible adversarial perturbations that lead a deep network to misclassify\nalmost all pixels of a chosen class while leaving network prediction nearly\nunchanged outside this class.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 10:27:16 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Fischer", "Volker", ""], ["Kumar", "Mummadi Chaithanya", ""], ["Metzen", "Jan Hendrik", ""], ["Brox", "Thomas", ""]]}, {"id": "1703.01106", "submitter": "Mikko Heikkil\\\"a", "authors": "Mikko Heikkil\\\"a and Eemil Lagerspetz and Samuel Kaski and Kana\n  Shimizu and Sasu Tarkoma and Antti Honkela", "title": "Differentially Private Bayesian Learning on Distributed Data", "comments": "13 pages, 7 figures. Modified text, changed algorithm used, included\n  tests on additional dataset, fixed several errors, added proof of asymptotic\n  efficiency to supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of machine learning, for example in health care, would\nbenefit from methods that can guarantee privacy of data subjects. Differential\nprivacy (DP) has become established as a standard for protecting learning\nresults. The standard DP algorithms require a single trusted party to have\naccess to the entire data, which is a clear weakness. We consider DP Bayesian\nlearning in a distributed setting, where each party only holds a single sample\nor a few samples of the data. We propose a learning strategy based on a secure\nmulti-party sum function for aggregating summaries from data holders and the\nGaussian mechanism for DP. Our method builds on an asymptotically optimal and\npractically efficient DP Bayesian inference with rapidly diminishing extra\ncost.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 10:44:47 GMT"}, {"version": "v2", "created": "Mon, 29 May 2017 15:11:26 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Heikkil\u00e4", "Mikko", ""], ["Lagerspetz", "Eemil", ""], ["Kaski", "Samuel", ""], ["Shimizu", "Kana", ""], ["Tarkoma", "Sasu", ""], ["Honkela", "Antti", ""]]}, {"id": "1703.01127", "submitter": "Dario Garcia-Gasulla PhD", "authors": "Dario Garcia-Gasulla, Ferran Par\\'es, Armand Vilalta, Jonatan Moreno,\n  Eduard Ayguad\\'e, Jes\\'us Labarta, Ulises Cort\\'es, Toyotaro Suzumura", "title": "On the Behavior of Convolutional Nets for Feature Extraction", "comments": "Published in the Journal of Artificial Intelligence Research (JAIR),\n  Special Track on Deep Learning, Knowledge Representation, and Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are representation learning techniques. During training,\na deep net is capable of generating a descriptive language of unprecedented\nsize and detail in machine learning. Extracting the descriptive language coded\nwithin a trained CNN model (in the case of image data), and reusing it for\nother purposes is a field of interest, as it provides access to the visual\ndescriptors previously learnt by the CNN after processing millions of images,\nwithout requiring an expensive training phase. Contributions to this field\n(commonly known as feature representation transfer or transfer learning) have\nbeen purely empirical so far, extracting all CNN features from a single layer\nclose to the output and testing their performance by feeding them to a\nclassifier. This approach has provided consistent results, although its\nrelevance is limited to classification tasks. In a completely different\napproach, in this paper we statistically measure the discriminative power of\nevery single feature found within a deep CNN, when used for characterizing\nevery class of 11 datasets. We seek to provide new insights into the behavior\nof CNN features, particularly the ones from convolutional layers, as this can\nbe relevant for their application to knowledge representation and reasoning.\nOur results confirm that low and middle level features may behave differently\nto high level features, but only under certain conditions. We find that all CNN\nfeatures can be used for knowledge representation purposes both by their\npresence or by their absence, doubling the information a single CNN feature may\nprovide. We also study how much noise these features may include, and propose a\nthresholding approach to discard most of it. All these insights have a direct\napplication to the generation of CNN embedding spaces.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 12:23:13 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 14:22:30 GMT"}, {"version": "v3", "created": "Mon, 13 Nov 2017 16:44:14 GMT"}, {"version": "v4", "created": "Mon, 29 Jan 2018 11:56:36 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Garcia-Gasulla", "Dario", ""], ["Par\u00e9s", "Ferran", ""], ["Vilalta", "Armand", ""], ["Moreno", "Jonatan", ""], ["Ayguad\u00e9", "Eduard", ""], ["Labarta", "Jes\u00fas", ""], ["Cort\u00e9s", "Ulises", ""], ["Suzumura", "Toyotaro", ""]]}, {"id": "1703.01141", "submitter": "Zhichen Gong", "authors": "Zhichen Gong, Huanhuan Chen", "title": "Dynamic State Warping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The ubiquity of sequences in many domains enhances significant recent\ninterest in sequence learning, for which a basic problem is how to measure the\ndistance between sequences. Dynamic time warping (DTW) aligns two sequences by\nnonlinear local warping and returns a distance value. DTW shows superior\nability in many applications, e.g. video, image, etc. However, in DTW, two\npoints are paired essentially based on point-to-point Euclidean distance (ED)\nwithout considering the autocorrelation of sequences. Thus, points with\ndifferent semantic meanings, e.g. peaks and valleys, may be matched providing\ntheir coordinate values are similar. As a result, DTW is sensitive to noise and\npoorly interpretable. This paper proposes an efficient and flexible sequence\nalignment algorithm, dynamic state warping (DSW). DSW converts each time point\ninto a latent state, which endows point-wise autocorrelation information.\nAlignment is performed by using the state sequences. Thus DSW is able to yield\nalignment that is semantically more interpretable than that of DTW. Using one\nnearest neighbor classifier, DSW shows significant improvement on\nclassification accuracy in comparison to ED (70/85 wins) and DTW (74/85 wins).\nWe also empirically demonstrate that DSW is more robust and scales better to\nlong sequences than ED and DTW.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 13:01:38 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Gong", "Zhichen", ""], ["Chen", "Huanhuan", ""]]}, {"id": "1703.01196", "submitter": "Asish Ghoshal", "authors": "Asish Ghoshal and Jean Honorio", "title": "Learning Identifiable Gaussian Bayesian Networks in Polynomial Time and\n  Sample Complexity", "comments": null, "journal-ref": "Neural Information Processing Systems (NIPS) 2017", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the directed acyclic graph (DAG) structure of a Bayesian network\nfrom observational data is a notoriously difficult problem for which many\nhardness results are known. In this paper we propose a provably polynomial-time\nalgorithm for learning sparse Gaussian Bayesian networks with equal noise\nvariance --- a class of Bayesian networks for which the DAG structure can be\nuniquely identified from observational data --- under high-dimensional\nsettings. We show that $O(k^4 \\log p)$ number of samples suffices for our\nmethod to recover the true DAG structure with high probability, where $p$ is\nthe number of variables and $k$ is the maximum Markov blanket size. We obtain\nour theoretical guarantees under a condition called Restricted Strong Adjacency\nFaithfulness, which is strictly weaker than strong faithfulness --- a condition\nthat other methods based on conditional independence testing need for their\nsuccess. The sample complexity of our method matches the information-theoretic\nlimits in terms of the dependence on $p$. We show that our method out-performs\nexisting state-of-the-art methods for learning Gaussian Bayesian networks in\nterms of recovering the true DAG structure while being comparable in speed to\nheuristic methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 15:05:44 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ghoshal", "Asish", ""], ["Honorio", "Jean", ""]]}, {"id": "1703.01203", "submitter": "Alexander Gorban", "authors": "A.N. Gorban, I.Y. Tyukin", "title": "Stochastic Separation Theorems", "comments": "6 pages, accepted for publication in Neural Networks (Letter section)", "journal-ref": "Neural Networks 94 (2017), 255-259", "doi": "10.1016/j.neunet.2017.07.014", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of non-iterative one-shot and non-destructive correction of\nunavoidable mistakes arises in all Artificial Intelligence applications in the\nreal world. Its solution requires robust separation of samples with errors from\nsamples where the system works properly. We demonstrate that in (moderately)\nhigh dimension this separation could be achieved with probability close to one\nby linear discriminants. Surprisingly, separation of a new image from a very\nlarge set of known images is almost always possible even in moderately high\ndimensions by linear functionals, and coefficients of these functionals can be\nfound explicitly. Based on fundamental properties of measure concentration, we\nshow that for $M<a\\exp(b{n})$ random $M$-element sets in $\\mathbb{R}^n$ are\nlinearly separable with probability $p$, $p>1-\\vartheta$, where $1>\\vartheta>0$\nis a given small constant. Exact values of $a,b>0$ depend on the probability\ndistribution that determines how the random $M$-element sets are drawn, and on\nthe constant $\\vartheta$. These {\\em stochastic separation theorems} provide a\nnew instrument for the development, analysis, and assessment of machine\nlearning methods and algorithms in high dimension. Theoretical statements are\nillustrated with numerical examples.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 15:27:38 GMT"}, {"version": "v2", "created": "Sat, 1 Apr 2017 16:47:51 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 17:37:06 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Gorban", "A. N.", ""], ["Tyukin", "I. Y.", ""]]}, {"id": "1703.01218", "submitter": "Asish Ghoshal", "authors": "Asish Ghoshal and Jean Honorio", "title": "Learning Graphical Games from Behavioral Data: Sufficient and Necessary\n  Conditions", "comments": "Accepted to AISTATS 2017, Florida. arXiv admin note: substantial text\n  overlap with arXiv:1607.02959", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we obtain sufficient and necessary conditions on the number of\nsamples required for exact recovery of the pure-strategy Nash equilibria (PSNE)\nset of a graphical game from noisy observations of joint actions. We consider\nsparse linear influence games --- a parametric class of graphical games with\nlinear payoffs, and represented by directed graphs of n nodes (players) and\nin-degree of at most k. We show that one can efficiently recover the PSNE set\nof a linear influence game with $O(k^2 \\log n)$ samples, under very general\nobservation models. On the other hand, we show that $\\Omega(k \\log n)$ samples\nare necessary for any procedure to recover the PSNE set from observations of\njoint actions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 15:55:16 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Ghoshal", "Asish", ""], ["Honorio", "Jean", ""]]}, {"id": "1703.01220", "submitter": "Antonia Creswell", "authors": "Antonia Creswell, Anil Anthony Bharath", "title": "Denoising Adversarial Autoencoders", "comments": "submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning is of growing interest because it unlocks the potential\nheld in vast amounts of unlabelled data to learn useful representations for\ninference. Autoencoders, a form of generative model, may be trained by learning\nto reconstruct unlabelled input data from a latent representation space. More\nrobust representations may be produced by an autoencoder if it learns to\nrecover clean input samples from corrupted ones. Representations may be further\nimproved by introducing regularisation during training to shape the\ndistribution of the encoded data in latent space. We suggest denoising\nadversarial autoencoders, which combine denoising and regularisation, shaping\nthe distribution of latent space using adversarial training. We introduce a\nnovel analysis that shows how denoising may be incorporated into the training\nand sampling of adversarial autoencoders. Experiments are performed to assess\nthe contributions that denoising makes to the learning of representations for\nclassification and sample synthesis. Our results suggest that autoencoders\ntrained using a denoising criterion achieve higher classification performance,\nand can synthesise samples that are more consistent with the input data than\nthose trained without a corruption process.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 15:59:16 GMT"}, {"version": "v2", "created": "Thu, 11 May 2017 20:21:44 GMT"}, {"version": "v3", "created": "Fri, 16 Jun 2017 16:07:58 GMT"}, {"version": "v4", "created": "Thu, 4 Jan 2018 17:18:16 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Creswell", "Antonia", ""], ["Bharath", "Anil Anthony", ""]]}, {"id": "1703.01250", "submitter": "Alonso Marco", "authors": "Alonso Marco, Felix Berkenkamp, Philipp Hennig, Angela P. Schoellig,\n  Andreas Krause, Stefan Schaal, Sebastian Trimpe", "title": "Virtual vs. Real: Trading Off Simulations and Physical Experiments in\n  Reinforcement Learning with Bayesian Optimization", "comments": "7 pages, 6 figures, to appear in IEEE 2017 International Conference\n  on Robotics and Automation (ICRA)", "journal-ref": null, "doi": "10.1109/ICRA.2017.7989186", "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, the parameters of control policies are often tuned manually.\nThis is time-consuming and frustrating. Reinforcement learning is a promising\nalternative that aims to automate this process, yet often requires too many\nexperiments to be practical. In this paper, we propose a solution to this\nproblem by exploiting prior knowledge from simulations, which are readily\navailable for most robotic platforms. Specifically, we extend Entropy Search, a\nBayesian optimization algorithm that maximizes information gain from each\nexperiment, to the case of multiple information sources. The result is a\nprincipled way to automatically combine cheap, but inaccurate information from\nsimulations with expensive and accurate physical experiments in a\ncost-effective manner. We apply the resulting method to a cart-pole system,\nwhich confirms that the algorithm can find good control policies with fewer\nexperiments than standard Bayesian optimization on the physical system only.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 17:20:09 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Marco", "Alonso", ""], ["Berkenkamp", "Felix", ""], ["Hennig", "Philipp", ""], ["Schoellig", "Angela P.", ""], ["Krause", "Andreas", ""], ["Schaal", "Stefan", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1703.01253", "submitter": "Jared Ostmeyer", "authors": "Jared Ostmeyer and Lindsay Cowell", "title": "Machine Learning on Sequential Data Using a Recurrent Weighted Average", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2018.11.066", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent Neural Networks (RNN) are a type of statistical model designed to\nhandle sequential data. The model reads a sequence one symbol at a time. Each\nsymbol is processed based on information collected from the previous symbols.\nWith existing RNN architectures, each symbol is processed using only\ninformation from the previous processing step. To overcome this limitation, we\npropose a new kind of RNN model that computes a recurrent weighted average\n(RWA) over every past processing step. Because the RWA can be computed as a\nrunning average, the computational overhead scales like that of any other RNN\narchitecture. The approach essentially reformulates the attention mechanism\ninto a stand-alone model. The performance of the RWA model is assessed on the\nvariable copy problem, the adding problem, classification of artificial\ngrammar, classification of sequences by length, and classification of the MNIST\nimages (where the pixels are read sequentially one at a time). On almost every\ntask, the RWA model is found to outperform a standard LSTM model.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 17:24:49 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 18:47:54 GMT"}, {"version": "v3", "created": "Thu, 16 Mar 2017 18:02:23 GMT"}, {"version": "v4", "created": "Sun, 26 Mar 2017 23:23:59 GMT"}, {"version": "v5", "created": "Thu, 4 May 2017 17:57:09 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Ostmeyer", "Jared", ""], ["Cowell", "Lindsay", ""]]}, {"id": "1703.01260", "submitter": "Justin Fu", "authors": "Justin Fu and John D. Co-Reyes, and Sergey Levine", "title": "EX2: Exploration with Exemplar Models for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms have been shown to learn complex tasks\nusing highly general policy classes. However, sparse reward problems remain a\nsignificant challenge. Exploration methods based on novelty detection have been\nparticularly successful in such settings but typically require generative or\npredictive models of the observations, which can be difficult to train when the\nobservations are very high-dimensional and complex, as in the case of raw\nimages. We propose a novelty detection algorithm for exploration that is based\nentirely on discriminatively trained exemplar models, where classifiers are\ntrained to discriminate each visited state against all others. Intuitively,\nnovel states are easier to distinguish against other states seen during\ntraining. We show that this kind of discriminative modeling corresponds to\nimplicit density estimation, and that it can be combined with count-based\nexploration to produce competitive results on a range of popular benchmark\ntasks, including state-of-the-art results on challenging egocentric\nobservations in the vizDoom benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 17:38:59 GMT"}, {"version": "v2", "created": "Sat, 27 May 2017 05:09:09 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Fu", "Justin", ""], ["Co-Reyes", "John D.", ""], ["Levine", "Sergey", ""]]}, {"id": "1703.01327", "submitter": "G. Zacharias Holland", "authors": "Kristopher De Asis, J. Fernando Hernandez-Garcia, G. Zacharias\n  Holland, Richard S. Sutton", "title": "Multi-step Reinforcement Learning: A Unifying Algorithm", "comments": "Appeared at the Thirty-Second AAAI Conference on Artificial\n  Intelligence (AAAI-18)", "journal-ref": "(2018). In AAAI Conference on Artificial Intelligence.\n  https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16294", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unifying seemingly disparate algorithmic ideas to produce better performing\nalgorithms has been a longstanding goal in reinforcement learning. As a primary\nexample, TD($\\lambda$) elegantly unifies one-step TD prediction with Monte\nCarlo methods through the use of eligibility traces and the trace-decay\nparameter $\\lambda$. Currently, there are a multitude of algorithms that can be\nused to perform TD control, including Sarsa, $Q$-learning, and Expected Sarsa.\nThese methods are often studied in the one-step case, but they can be extended\nacross multiple time steps to achieve better performance. Each of these\nalgorithms is seemingly distinct, and no one dominates the others for all\nproblems. In this paper, we study a new multi-step action-value algorithm\ncalled $Q(\\sigma)$ which unifies and generalizes these existing algorithms,\nwhile subsuming them as special cases. A new parameter, $\\sigma$, is introduced\nto allow the degree of sampling performed by the algorithm at each step during\nits backup to be continuously varied, with Sarsa existing at one extreme (full\nsampling), and Expected Sarsa existing at the other (pure expectation).\n$Q(\\sigma)$ is generally applicable to both on- and off-policy learning, but in\nthis work we focus on experiments in the on-policy case. Our results show that\nan intermediate value of $\\sigma$, which results in a mixture of the existing\nalgorithms, performs better than either extreme. The mixture can also be varied\ndynamically which can result in even greater performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 20:19:08 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 22:01:57 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["De Asis", "Kristopher", ""], ["Hernandez-Garcia", "J. Fernando", ""], ["Holland", "G. Zacharias", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1703.01340", "submitter": "Chaofei Yang", "authors": "Chaofei Yang, Qing Wu, Hai Li, Yiran Chen", "title": "Generative Poisoning Attack Method Against Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisoning attack is identified as a severe security threat to machine\nlearning algorithms. In many applications, for example, deep neural network\n(DNN) models collect public data as the inputs to perform re-training, where\nthe input data can be poisoned. Although poisoning attack against support\nvector machines (SVM) has been extensively studied before, there is still very\nlimited knowledge about how such attack can be implemented on neural networks\n(NN), especially DNNs. In this work, we first examine the possibility of\napplying traditional gradient-based method (named as the direct gradient\nmethod) to generate poisoned data against NNs by leveraging the gradient of the\ntarget model w.r.t. the normal data. We then propose a generative method to\naccelerate the generation rate of the poisoned data: an auto-encoder\n(generator) used to generate poisoned data is updated by a reward function of\nthe loss, and the target NN model (discriminator) receives the poisoned data to\ncalculate the loss w.r.t. the normal data. Our experiment results show that the\ngenerative method can speed up the poisoned data generation rate by up to\n239.38x compared with the direct gradient method, with slightly lower model\naccuracy degradation. A countermeasure is also designed to detect such\npoisoning attack methods by checking the loss of the target model.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 21:13:48 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Yang", "Chaofei", ""], ["Wu", "Qing", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "1703.01347", "submitter": "Seyoung Yun", "authors": "Se-Young Yun and Jun Hyun Nam and Sangwoo Mo and Jinwoo Shin", "title": "Contextual Multi-armed Bandits under Feature Uncertainty", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study contextual multi-armed bandit problems under linear realizability on\nrewards and uncertainty (or noise) on features. For the case of identical noise\non features across actions, we propose an algorithm, coined {\\em NLinRel},\nhaving $O\\left(T^{\\frac{7}{8}} \\left(\\log{(dT)}+K\\sqrt{d}\\right)\\right)$ regret\nbound for $T$ rounds, $K$ actions, and $d$-dimensional feature vectors. Next,\nfor the case of non-identical noise, we observe that popular linear hypotheses\nincluding {\\em NLinRel} are impossible to achieve such sub-linear regret.\nInstead, under assumption of Gaussian feature vectors, we prove that a greedy\nalgorithm has $O\\left(T^{\\frac23}\\sqrt{\\log d}\\right)$ regret bound with\nrespect to the optimal linear hypothesis. Utilizing our theoretical\nunderstanding on the Gaussian case, we also design a practical variant of {\\em\nNLinRel}, coined {\\em Universal-NLinRel}, for arbitrary feature distributions.\nIt first runs {\\em NLinRel} for finding the `true' coefficient vector using\nfeature uncertainties and then adjust it to minimize its regret using the\nstatistical feature information. We justify the performance of {\\em\nUniversal-NLinRel} on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 21:39:56 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Yun", "Se-Young", ""], ["Nam", "Jun Hyun", ""], ["Mo", "Sangwoo", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1703.01363", "submitter": "Yuan Gao", "authors": "James V. Burke, Yuan Gao, Tim Hoheisel", "title": "Convex Geometry of the Generalized Matrix-Fractional Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized matrix-fractional (GMF) functions are a class of matrix support\nfunctions introduced by Burke and Hoheisel as a tool for unifying a range of\nseemingly divergent matrix optimization problems associated with inverse\nproblems, regularization and learning. In this paper we dramatically simplify\nthe support function representation for GMF functions as well as the\nrepresentation of their subdifferentials. These new representations allow the\nready computation of a range of important related geometric objects whose\nformulations were previously unavailable.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 00:00:16 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Burke", "James V.", ""], ["Gao", "Yuan", ""], ["Hoheisel", "Tim", ""]]}, {"id": "1703.01365", "submitter": "Ankur Taly", "authors": "Mukund Sundararajan, Ankur Taly, Qiqi Yan", "title": "Axiomatic Attribution for Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of attributing the prediction of a deep network to its\ninput features, a problem previously studied by several other works. We\nidentify two fundamental axioms---Sensitivity and Implementation Invariance\nthat attribution methods ought to satisfy. We show that they are not satisfied\nby most known attribution methods, which we consider to be a fundamental\nweakness of those methods. We use the axioms to guide the design of a new\nattribution method called Integrated Gradients. Our method requires no\nmodification to the original network and is extremely simple to implement; it\njust needs a few calls to the standard gradient operator. We apply this method\nto a couple of image models, a couple of text models and a chemistry model,\ndemonstrating its ability to debug networks, to extract rules from a network,\nand to enable users to engage with models better.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 00:18:49 GMT"}, {"version": "v2", "created": "Tue, 13 Jun 2017 01:52:38 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Sundararajan", "Mukund", ""], ["Taly", "Ankur", ""], ["Yan", "Qiqi", ""]]}, {"id": "1703.01442", "submitter": "Abbas Hosseini", "authors": "Seyed Abbas Hosseini, Keivan Alizadeh, Ali Khodadadi, Ali Arabzadeh,\n  Mehrdad Farajtabar, Hongyuan Zha, Hamid R. Rabiee", "title": "Recurrent Poisson Factorization for Temporal Recommendation", "comments": "Submitted to KDD 2017 | Halifax, Nova Scotia - Canada - sigkdd, Codes\n  are available at https://github.com/AHosseini/RPF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisson factorization is a probabilistic model of users and items for\nrecommendation systems, where the so-called implicit consumer data is modeled\nby a factorized Poisson distribution. There are many variants of Poisson\nfactorization methods who show state-of-the-art performance on real-world\nrecommendation tasks. However, most of them do not explicitly take into account\nthe temporal behavior and the recurrent activities of users which is essential\nto recommend the right item to the right user at the right time. In this paper,\nwe introduce Recurrent Poisson Factorization (RPF) framework that generalizes\nthe classical PF methods by utilizing a Poisson process for modeling the\nimplicit feedback. RPF treats time as a natural constituent of the model and\nbrings to the table a rich family of time-sensitive factorization models. To\nelaborate, we instantiate several variants of RPF who are capable of handling\ndynamic user preferences and item specification (DRPF), modeling the\nsocial-aspect of product adoption (SRPF), and capturing the consumption\nheterogeneity among users and items (HRPF). We also develop a variational\nalgorithm for approximate posterior inference that scales up to massive data\nsets. Furthermore, we demonstrate RPF's superior performance over many\nstate-of-the-art methods on synthetic dataset, and large scale real-world\ndatasets on music streaming logs, and user-item interactions in M-Commerce\nplatforms.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 11:20:51 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Hosseini", "Seyed Abbas", ""], ["Alizadeh", "Keivan", ""], ["Khodadadi", "Ali", ""], ["Arabzadeh", "Ali", ""], ["Farajtabar", "Mehrdad", ""], ["Zha", "Hongyuan", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1703.01454", "submitter": "Truyen Tran", "authors": "Kien Do, Truyen Tran, Svetha Venkatesh", "title": "Learning Deep Matrix Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new distributed representation in deep neural nets wherein the\ninformation is represented in native form as a matrix. This differs from\ncurrent neural architectures that rely on vector representations. We consider\nmatrices as central to the architecture and they compose the input, hidden and\noutput layers. The model representation is more compact and elegant -- the\nnumber of parameters grows only with the largest dimension of the incoming\nlayer rather than the number of hidden units. We derive several new deep\nnetworks: (i) feed-forward nets that map an input matrix into an output matrix,\n(ii) recurrent nets which map a sequence of input matrices into a sequence of\noutput matrices. We also reinterpret existing models for (iii) memory-augmented\nnetworks and (iv) graphs using matrix notations. For graphs we demonstrate how\nthe new notations lead to simple but effective extensions with multiple\nattentions. Extensive experiments on handwritten digits recognition, face\nreconstruction, sequence to sequence learning, EEG classification, and\ngraph-based node classification demonstrate the efficacy and compactness of the\nmatrix architectures.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 13:35:49 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 02:08:41 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Do", "Kien", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1703.01457", "submitter": "Dajiang Zhou", "authors": "Shihao Wang, Dajiang Zhou, Xushen Han, Takeshi Yoshimura", "title": "Chain-NN: An Energy-Efficient 1D Chain Architecture for Accelerating\n  Deep Convolutional Neural Networks", "comments": "DATE 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNN) have shown their good performances\nin many computer vision tasks. However, the high computational complexity of\nCNN involves a huge amount of data movements between the computational\nprocessor core and memory hierarchy which occupies the major of the power\nconsumption. This paper presents Chain-NN, a novel energy-efficient 1D chain\narchitecture for accelerating deep CNNs. Chain-NN consists of the dedicated\ndual-channel process engines (PE). In Chain-NN, convolutions are done by the 1D\nsystolic primitives composed of a group of adjacent PEs. These systolic\nprimitives, together with the proposed column-wise scan input pattern, can\nfully reuse input operand to reduce the memory bandwidth requirement for energy\nsaving. Moreover, the 1D chain architecture allows the systolic primitives to\nbe easily reconfigured according to specific CNN parameters with fewer design\ncomplexity. The synthesis and layout of Chain-NN is under TSMC 28nm process. It\ncosts 3751k logic gates and 352KB on-chip memory. The results show a 576-PE\nChain-NN can be scaled up to 700MHz. This achieves a peak throughput of\n806.4GOPS with 567.5mW and is able to accelerate the five convolutional layers\nin AlexNet at a frame rate of 326.2fps. 1421.0GOPS/W power efficiency is at\nleast 2.5 to 4.1x times better than the state-of-the-art works.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 14:14:14 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Wang", "Shihao", ""], ["Zhou", "Dajiang", ""], ["Han", "Xushen", ""], ["Yoshimura", "Takeshi", ""]]}, {"id": "1703.01460", "submitter": "Xingjun Ma", "authors": "Xingjun Ma, Sudanthi Wijewickrema, Shuo Zhou, Yun Zhou, Zakaria\n  Mhammedi, Stephen O'Leary, James Bailey", "title": "Adversarial Generation of Real-time Feedback with Neural Networks for\n  Simulation-based Training", "comments": "Appeared in the Proceedings of the 26th International Joint\n  Conference on Artificial Intelligence (IJCAI), Melbourne, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation-based training (SBT) is gaining popularity as a low-cost and\nconvenient training technique in a vast range of applications. However, for a\nSBT platform to be fully utilized as an effective training tool, it is\nessential that feedback on performance is provided automatically in real-time\nduring training. It is the aim of this paper to develop an efficient and\neffective feedback generation method for the provision of real-time feedback in\nSBT. Existing methods either have low effectiveness in improving novice skills\nor suffer from low efficiency, resulting in their inability to be used in\nreal-time. In this paper, we propose a neural network based method to generate\nfeedback using the adversarial technique. The proposed method utilizes a\nbounded adversarial update to minimize a L1 regularized loss via\nback-propagation. We empirically show that the proposed method can be used to\ngenerate simple, yet effective feedback. Also, it was observed to have high\neffectiveness and efficiency when compared to existing methods, thus making it\na promising option for real-time feedback generation in SBT.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 14:24:27 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 07:54:58 GMT"}, {"version": "v3", "created": "Tue, 23 May 2017 14:16:20 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Ma", "Xingjun", ""], ["Wijewickrema", "Sudanthi", ""], ["Zhou", "Shuo", ""], ["Zhou", "Yun", ""], ["Mhammedi", "Zakaria", ""], ["O'Leary", "Stephen", ""], ["Bailey", "James", ""]]}, {"id": "1703.01461", "submitter": "Markus Wulfmeier", "authors": "Markus Wulfmeier, Alex Bewley and Ingmar Posner", "title": "Addressing Appearance Change in Outdoor Robotics with Adversarial Domain\n  Adaptation", "comments": "In Proceedings of the 2017 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Appearance changes due to weather and seasonal conditions represent a strong\nimpediment to the robust implementation of machine learning systems in outdoor\nrobotics. While supervised learning optimises a model for the training domain,\nit will deliver degraded performance in application domains that underlie\ndistributional shifts caused by these changes. Traditionally, this problem has\nbeen addressed via the collection of labelled data in multiple domains or by\nimposing priors on the type of shift between both domains. We frame the problem\nin the context of unsupervised domain adaptation and develop a framework for\napplying adversarial techniques to adapt popular, state-of-the-art network\narchitectures with the additional objective to align features across domains.\nMoreover, as adversarial training is notoriously unstable, we first perform an\nextensive ablation study, adapting many techniques known to stabilise\ngenerative adversarial networks, and evaluate on a surrogate classification\ntask with the same appearance change. The distilled insights are applied to the\nproblem of free-space segmentation for motion planning in autonomous driving.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 14:28:51 GMT"}, {"version": "v2", "created": "Sun, 17 Sep 2017 13:44:28 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Wulfmeier", "Markus", ""], ["Bewley", "Alex", ""], ["Posner", "Ingmar", ""]]}, {"id": "1703.01474", "submitter": "Anindya De", "authors": "Anindya De and Ryan O'Donnell and Rocco Servedio", "title": "Sharp bounds for population recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The population recovery problem is a basic problem in noisy unsupervised\nlearning that has attracted significant research attention in recent years\n[WY12,DRWY12, MS13, BIMP13, LZ15,DST16]. A number of different variants of this\nproblem have been studied, often under assumptions on the unknown distribution\n(such as that it has restricted support size). In this work we study the sample\ncomplexity and algorithmic complexity of the most general version of the\nproblem, under both bit-flip noise and erasure noise model. We give essentially\nmatching upper and lower sample complexity bounds for both noise models, and\nefficient algorithms matching these sample complexity bounds up to polynomial\nfactors.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 15:13:41 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["De", "Anindya", ""], ["O'Donnell", "Ryan", ""], ["Servedio", "Rocco", ""]]}, {"id": "1703.01507", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "Machine Learning Friendly Set Version of Johnson-Lindenstrauss Lemma", "comments": "38 pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we make a novel use of the Johnson-Lindenstrauss Lemma. The\nLemma has an existential form saying that there exists a JL transformation $f$\nof the data points into lower dimensional space such that all of them fall into\npredefined error range $\\delta$.\n  We formulate in this paper a theorem stating that we can choose the target\ndimensionality in a random projection type JL linear transformation in such a\nway that with probability $1-\\epsilon$ all of them fall into predefined error\nrange $\\delta$ for any user-predefined failure probability $\\epsilon$.\n  This result is important for applications such a data clustering where we\nwant to have a priori dimensionality reducing transformation instead of trying\nout a (large) number of them, as with traditional Johnson-Lindenstrauss Lemma.\nIn particular, we take a closer look at the $k$-means algorithm and prove that\na good solution in the projected space is also a good solution in the original\nspace. Furthermore, under proper assumptions local optima in the original space\nare also ones in the projected space. We define also conditions for which\nclusterability property of the original space is transmitted to the projected\nspace, so that special case algorithms for the original space are also\napplicable in the projected space.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 19:08:22 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 17:56:29 GMT"}, {"version": "v3", "created": "Thu, 7 Sep 2017 08:06:18 GMT"}, {"version": "v4", "created": "Mon, 18 Sep 2017 08:35:17 GMT"}, {"version": "v5", "created": "Thu, 9 Nov 2017 17:33:48 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "1703.01557", "submitter": "Lidong Bing", "authors": "Lidong Bing and William W. Cohen and Bhuwan Dhingra", "title": "Using Graphs of Classifiers to Impose Declarative Constraints on\n  Semi-supervised Learning", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general approach to modeling semi-supervised learning (SSL)\nalgorithms. Specifically, we present a declarative language for modeling both\ntraditional supervised classification tasks and many SSL heuristics, including\nboth well-known heuristics such as co-training and novel domain-specific\nheuristics. In addition to representing individual SSL heuristics, we show that\nmultiple heuristics can be automatically combined using Bayesian optimization\nmethods. We experiment with two classes of tasks, link-based text\nclassification and relation extraction. We show modest improvements on\nwell-studied link-based classification benchmarks, and state-of-the-art results\non relation-extraction tasks for two realistic domains.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 04:43:41 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 07:46:21 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Bing", "Lidong", ""], ["Cohen", "William W.", ""], ["Dhingra", "Bhuwan", ""]]}, {"id": "1703.01560", "submitter": "Jianwei Yang", "authors": "Jianwei Yang, Anitha Kannan, Dhruv Batra, Devi Parikh", "title": "LR-GAN: Layered Recursive Generative Adversarial Networks for Image\n  Generation", "comments": "21 pages, 22 figures, published as a conference paper at ICLR 2017,\n  code available on GitHub", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LR-GAN: an adversarial image generation model which takes scene\nstructure and context into account. Unlike previous generative adversarial\nnetworks (GANs), the proposed GAN learns to generate image background and\nforegrounds separately and recursively, and stitch the foregrounds on the\nbackground in a contextually relevant manner to produce a complete natural\nimage. For each foreground, the model learns to generate its appearance, shape\nand pose. The whole model is unsupervised, and is trained in an end-to-end\nmanner with gradient descent methods. The experiments demonstrate that LR-GAN\ncan generate more natural images with objects that are more human recognizable\nthan DCGAN.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 05:17:56 GMT"}, {"version": "v2", "created": "Sat, 1 Jul 2017 10:30:54 GMT"}, {"version": "v3", "created": "Wed, 2 Aug 2017 03:51:57 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Yang", "Jianwei", ""], ["Kannan", "Anitha", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1703.01594", "submitter": "Nicolas Tremblay", "authors": "Nicolas Tremblay, Pierre-Olivier Amblard, Simon Barthelm\\'e", "title": "Graph sampling with determinantal processes", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new random sampling strategy for k-bandlimited signals defined\non graphs, based on determinantal point processes (DPP). For small graphs, ie,\nin cases where the spectrum of the graph is accessible, we exhibit a DPP\nsampling scheme that enables perfect recovery of bandlimited signals. For large\ngraphs, ie, in cases where the graph's spectrum is not accessible, we\ninvestigate, both theoretically and empirically, a sub-optimal but much faster\nDPP based on loop-erased random walks on the graph. Preliminary experiments\nshow promising results especially in cases where the number of measurements\nshould stay as small as possible and for graphs that have a strong community\nstructure. Our sampling scheme is efficient and can be applied to graphs with\nup to $10^6$ nodes.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 13:18:19 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Tremblay", "Nicolas", ""], ["Amblard", "Pierre-Olivier", ""], ["Barthelm\u00e9", "Simon", ""]]}, {"id": "1703.01606", "submitter": "Lior Wolf", "authors": "Tomer Galanti, Lior Wolf", "title": "A Theory of Output-Side Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning a mapping from an input space to an output space, the\nassumption that the sample distribution of the training data is the same as\nthat of the test data is often violated. Unsupervised domain shift methods\nadapt the learned function in order to correct for this shift. Previous work\nhas focused on utilizing unlabeled samples from the target distribution. We\nconsider the complementary problem in which the unlabeled samples are given\npost mapping, i.e., we are given the outputs of the mapping of unknown samples\nfrom the shifted domain. Two other variants are also studied: the two sided\nversion, in which unlabeled samples are give from both the input and the output\nspaces, and the Domain Transfer problem, which was recently formalized. In all\ncases, we derive generalization bounds that employ discrepancy terms.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 15:12:09 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Galanti", "Tomer", ""], ["Wolf", "Lior", ""]]}, {"id": "1703.01610", "submitter": "Wei Chen", "authors": "Qinshi Wang and Wei Chen", "title": "Improving Regret Bounds for Combinatorial Semi-Bandits with\n  Probabilistically Triggered Arms and Its Applications", "comments": "This is the full version of the paper accepted at NIPS'2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study combinatorial multi-armed bandit with probabilistically triggered\narms (CMAB-T) and semi-bandit feedback. We resolve a serious issue in the prior\nCMAB-T studies where the regret bounds contain a possibly exponentially large\nfactor of $1/p^*$, where $p^*$ is the minimum positive probability that an arm\nis triggered by any action. We address this issue by introducing a triggering\nprobability modulated (TPM) bounded smoothness condition into the general\nCMAB-T framework, and show that many applications such as influence\nmaximization bandit and combinatorial cascading bandit satisfy this TPM\ncondition. As a result, we completely remove the factor of $1/p^*$ from the\nregret bounds, achieving significantly better regret bounds for influence\nmaximization and cascading bandits than before. Finally, we provide lower bound\nresults showing that the factor $1/p^*$ is unavoidable for general CMAB-T\nproblems, suggesting that the TPM condition is crucial in removing this factor.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 15:31:35 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 08:25:41 GMT"}, {"version": "v3", "created": "Sun, 5 Nov 2017 05:50:04 GMT"}, {"version": "v4", "created": "Wed, 21 Feb 2018 19:21:09 GMT"}, {"version": "v5", "created": "Tue, 8 Jun 2021 07:55:43 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Wang", "Qinshi", ""], ["Chen", "Wei", ""]]}, {"id": "1703.01619", "submitter": "Graham Neubig", "authors": "Graham Neubig", "title": "Neural Machine Translation and Sequence-to-sequence Models: A Tutorial", "comments": "65 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial introduces a new and powerful set of techniques variously\ncalled \"neural machine translation\" or \"neural sequence-to-sequence models\".\nThese techniques have been used in a number of tasks regarding the handling of\nhuman language, and can be a powerful tool in the toolbox of anyone who wants\nto model sequential data of some sort. The tutorial assumes that the reader\nknows the basics of math and programming, but does not assume any particular\nexperience with neural networks or natural language processing. It attempts to\nexplain the intuition behind the various methods covered, then delves into them\nwith enough mathematical detail to understand them concretely, and culiminates\nwith a suggestion for an implementation exercise, where readers can test that\nthey understood the content in practice.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 16:10:11 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Neubig", "Graham", ""]]}, {"id": "1703.01678", "submitter": "Ilja Kuzborskij", "authors": "Ilja Kuzborskij, Christoph H. Lampert", "title": "Data-Dependent Stability of Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a data-dependent notion of algorithmic stability for Stochastic\nGradient Descent (SGD), and employ it to develop novel generalization bounds.\nThis is in contrast to previous distribution-free algorithmic stability results\nfor SGD which depend on the worst-case constants. By virtue of the\ndata-dependent argument, our bounds provide new insights into learning with SGD\non convex and non-convex problems. In the convex case, we show that the bound\non the generalization error depends on the risk at the initialization point. In\nthe non-convex case, we prove that the expected curvature of the objective\nfunction around the initialization point has crucial influence on the\ngeneralization error. In both cases, our results suggest a simple data-driven\nstrategy to stabilize SGD by pre-screening its initialization. As a corollary,\nour results allow us to show optimistic generalization bounds that exhibit fast\nconvergence rates for SGD subject to a vanishing empirical risk and low noise\nof stochastic gradient.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 22:22:34 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 17:16:17 GMT"}, {"version": "v3", "created": "Fri, 26 May 2017 17:33:50 GMT"}, {"version": "v4", "created": "Thu, 15 Feb 2018 19:23:31 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Kuzborskij", "Ilja", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "1703.01680", "submitter": "Guy Uziel", "authors": "Guy Uziel and Ran El-Yaniv", "title": "Multi-Objective Non-parametric Sequential Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online-learning research has mainly been focusing on minimizing one objective\nfunction. In many real-world applications, however, several objective functions\nhave to be considered simultaneously. Recently, an algorithm for dealing with\nseveral objective functions in the i.i.d. case has been presented. In this\npaper, we extend the multi-objective framework to the case of stationary and\nergodic processes, thus allowing dependencies among observations. We first\nidentify an asymptomatic lower bound for any prediction strategy and then\npresent an algorithm whose predictions achieve the optimal solution while\nfulfilling any continuous and convex constraining criterion.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 22:41:00 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 19:46:50 GMT"}, {"version": "v3", "created": "Sun, 19 Mar 2017 15:50:42 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Uziel", "Guy", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1703.01703", "submitter": "Bradly Stadie", "authors": "Bradly C. Stadie, Pieter Abbeel, Ilya Sutskever", "title": "Third-Person Imitation Learning", "comments": "Only changed the abstract to remove unneeded hyphens", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) makes it possible to train agents capable of\nachieving sophisticated goals in complex and uncertain environments. A key\ndifficulty in reinforcement learning is specifying a reward function for the\nagent to optimize. Traditionally, imitation learning in RL has been used to\novercome this problem. Unfortunately, hitherto imitation learning methods tend\nto require that demonstrations are supplied in the first-person: the agent is\nprovided with a sequence of states and a specification of the actions that it\nshould have taken. While powerful, this kind of imitation learning is limited\nby the relatively hard problem of collecting first-person demonstrations.\nHumans address this problem by learning from third-person demonstrations: they\nobserve other humans perform tasks, infer the task, and accomplish the same\ntask themselves.\n  In this paper, we present a method for unsupervised third-person imitation\nlearning. Here third-person refers to training an agent to correctly achieve a\nsimple goal in a simple environment when it is provided a demonstration of a\nteacher achieving the same goal but from a different viewpoint; and\nunsupervised refers to the fact that the agent receives only these third-person\ndemonstrations, and is not provided a correspondence between teacher states and\nstudent states. Our methods primary insight is that recent advances from domain\nconfusion can be utilized to yield domain agnostic features which are crucial\nduring the training process. To validate our approach, we report successful\nexperiments on learning from third-person demonstrations in a pointmass domain,\na reacher domain, and inverted pendulum.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 02:02:34 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 18:31:15 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Stadie", "Bradly C.", ""], ["Abbeel", "Pieter", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1703.01717", "submitter": "Jack Gorham", "authors": "Jackson Gorham and Lester Mackey", "title": "Measuring Sample Quality with Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Markov chain Monte Carlo (MCMC) offers the promise of more rapid\nsampling at the cost of more biased inference. Since standard MCMC diagnostics\nfail to detect these biases, researchers have developed computable Stein\ndiscrepancy measures that provably determine the convergence of a sample to its\ntarget distribution. This approach was recently combined with the theory of\nreproducing kernels to define a closed-form kernel Stein discrepancy (KSD)\ncomputable by summing kernel evaluations across pairs of sample points. We\ndevelop a theory of weak convergence for KSDs based on Stein's method,\ndemonstrate that commonly used KSDs fail to detect non-convergence even for\nGaussian targets, and show that kernels with slowly decaying tails provably\ndetermine convergence for a large class of target distributions. The resulting\nconvergence-determining KSDs are suitable for comparing biased, exact, and\ndeterministic sample sequences and simpler to compute and parallelize than\nalternative Stein discrepancies. We use our tools to compare biased samplers,\nselect sampler hyperparameters, and improve upon existing KSD approaches to\none-sample hypothesis testing and sample quality improvement.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 03:22:39 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 06:04:43 GMT"}, {"version": "v3", "created": "Fri, 7 Jul 2017 20:41:24 GMT"}, {"version": "v4", "created": "Tue, 11 Jul 2017 23:30:56 GMT"}, {"version": "v5", "created": "Fri, 21 Jul 2017 04:38:46 GMT"}, {"version": "v6", "created": "Thu, 3 Aug 2017 21:23:32 GMT"}, {"version": "v7", "created": "Sat, 19 Aug 2017 01:35:40 GMT"}, {"version": "v8", "created": "Wed, 13 Sep 2017 20:51:38 GMT"}, {"version": "v9", "created": "Thu, 15 Oct 2020 02:08:48 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Gorham", "Jackson", ""], ["Mackey", "Lester", ""]]}, {"id": "1703.01732", "submitter": "Joshua Achiam", "authors": "Joshua Achiam, Shankar Sastry", "title": "Surprise-Based Intrinsic Motivation for Deep Reinforcement Learning", "comments": "Appeared in Deep RL Workshop at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in complex domains is a key challenge in reinforcement learning,\nespecially for tasks with very sparse rewards. Recent successes in deep\nreinforcement learning have been achieved mostly using simple heuristic\nexploration strategies such as $\\epsilon$-greedy action selection or Gaussian\ncontrol noise, but there are many tasks where these methods are insufficient to\nmake any learning progress. Here, we consider more complex heuristics:\nefficient and scalable exploration strategies that maximize a notion of an\nagent's surprise about its experiences via intrinsic motivation. We propose to\nlearn a model of the MDP transition probabilities concurrently with the policy,\nand to form intrinsic rewards that approximate the KL-divergence of the true\ntransition probabilities from the learned model. One of our approximations\nresults in using surprisal as intrinsic motivation, while the other gives the\n$k$-step learning progress. We show that our incentives enable agents to\nsucceed in a wide range of environments with high-dimensional state spaces and\nvery sparse rewards, including continuous control tasks and games in the Atari\nRAM domain, outperforming several other heuristic exploration techniques.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 05:51:42 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Achiam", "Joshua", ""], ["Sastry", "Shankar", ""]]}, {"id": "1703.01760", "submitter": "Yiteng Pan", "authors": "Yiteng Pan, Fazhi He, Haiping Yu", "title": "A Correlative Denoising Autoencoder to Model Social Influence for Top-N\n  Recommender System", "comments": "Accepted by Frontiers of Computer Science", "journal-ref": null, "doi": "10.1007/s11704-019-8123-3", "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there are numerous works been proposed to leverage the\ntechniques of deep learning to improve social-aware recommendation performance.\nIn most cases, it requires a larger number of data to train a robust deep\nlearning model, which contains a lot of parameters to fit training data.\nHowever, both data of user ratings and social networks are facing critical\nsparse problem, which makes it not easy to train a robust deep neural network\nmodel. Towards this problem, we propose a novel Correlative Denoising\nAutoencoder (CoDAE) method by taking correlations between users with multiple\nroles into account to learn robust representations from sparse inputs of\nratings and social networks for recommendation. We develop the CoDAE model by\nutilizing three separated autoencoders to learn user features with roles of\nrater, truster and trustee, respectively. Especially, on account of that each\ninput unit of user vectors with roles of truster and trustee is corresponding\nto a particular user, we propose to utilize shared parameters to learn common\ninformation of the units that corresponding to same users. Moreover, we propose\na related regularization term to learn correlations between user features that\nlearnt by the three subnetworks of CoDAE model. We further conduct a series of\nexperiments to evaluate the proposed method on two public datasets for Top-N\nrecommendation task. The experimental results demonstrate that the proposed\nmodel outperforms state-of-the-art algorithms on rank-sensitive metrics of MAP\nand NDCG.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 08:35:58 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 02:10:39 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 06:26:13 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Pan", "Yiteng", ""], ["He", "Fazhi", ""], ["Yu", "Haiping", ""]]}, {"id": "1703.01775", "submitter": "Edouard Oyallon", "authors": "Edouard Oyallon", "title": "Building a Regular Decision Boundary with Deep Networks", "comments": "CVPR 2017, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we build a generic architecture of Convolutional Neural\nNetworks to discover empirical properties of neural networks. Our first\ncontribution is to introduce a state-of-the-art framework that depends upon few\nhyper parameters and to study the network when we vary them. It has no max\npooling, no biases, only 13 layers, is purely convolutional and yields up to\n95.4% and 79.6% accuracy respectively on CIFAR10 and CIFAR100. We show that the\nnonlinearity of a deep network does not need to be continuous, non expansive or\npoint-wise, to achieve good performance. We show that increasing the width of\nour network permits being competitive with very deep networks. Our second\ncontribution is an analysis of the contraction and separation properties of\nthis network. Indeed, a 1-nearest neighbor classifier applied on deep features\nprogressively improves with depth, which indicates that the representation is\nprogressively more regular. Besides, we defined and analyzed local support\nvectors that separate classes locally. All our experiments are reproducible and\ncode is available online, based on TensorFlow.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 09:21:35 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Oyallon", "Edouard", ""]]}, {"id": "1703.01780", "submitter": "Antti Tarvainen", "authors": "Antti Tarvainen and Harri Valpola", "title": "Mean teachers are better role models: Weight-averaged consistency\n  targets improve semi-supervised deep learning results", "comments": "In this version: Corrected hyperparameters of the 4000-label CIFAR-10\n  ResNet experiment. Changed Antti's contact info, Advances in Neural\n  Information Processing Systems 30 (NIPS 2017) pre-proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed Temporal Ensembling has achieved state-of-the-art\nresults in several semi-supervised learning benchmarks. It maintains an\nexponential moving average of label predictions on each training example, and\npenalizes predictions that are inconsistent with this target. However, because\nthe targets change only once per epoch, Temporal Ensembling becomes unwieldy\nwhen learning large datasets. To overcome this problem, we propose Mean\nTeacher, a method that averages model weights instead of label predictions. As\nan additional benefit, Mean Teacher improves test accuracy and enables training\nwith fewer labels than Temporal Ensembling. Without changing the network\narchitecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250\nlabels, outperforming Temporal Ensembling trained with 1000 labels. We also\nshow that a good network architecture is crucial to performance. Combining Mean\nTeacher and Residual Networks, we improve the state of the art on CIFAR-10 with\n4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labels\nfrom 35.24% to 9.11%.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 09:34:56 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 07:41:30 GMT"}, {"version": "v3", "created": "Thu, 30 Nov 2017 11:14:43 GMT"}, {"version": "v4", "created": "Mon, 18 Dec 2017 09:13:01 GMT"}, {"version": "v5", "created": "Mon, 8 Jan 2018 08:10:09 GMT"}, {"version": "v6", "created": "Mon, 16 Apr 2018 10:39:11 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Tarvainen", "Antti", ""], ["Valpola", "Harri", ""]]}, {"id": "1703.01789", "submitter": "Jongpil Lee", "authors": "Jongpil Lee, Jiyoung Park, Keunhyoung Luke Kim, Juhan Nam", "title": "Sample-level Deep Convolutional Neural Networks for Music Auto-tagging\n  Using Raw Waveforms", "comments": "7 pages, Sound and Music Computing Conference (SMC), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the end-to-end approach that learns hierarchical representations\nfrom raw data using deep convolutional neural networks has been successfully\nexplored in the image, text and speech domains. This approach was applied to\nmusical signals as well but has been not fully explored yet. To this end, we\npropose sample-level deep convolutional neural networks which learn\nrepresentations from very small grains of waveforms (e.g. 2 or 3 samples)\nbeyond typical frame-level input representations. Our experiments show how deep\narchitectures with sample-level filters improve the accuracy in music\nauto-tagging and they provide results comparable to previous state-of-the-art\nperformances for the Magnatagatune dataset and Million Song Dataset. In\naddition, we visualize filters learned in a sample-level DCNN in each layer to\nidentify hierarchically learned features and show that they are sensitive to\nlog-scaled frequency along layer, such as mel-frequency spectrogram that is\nwidely used in music classification systems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 09:49:48 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 04:46:36 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Lee", "Jongpil", ""], ["Park", "Jiyoung", ""], ["Kim", "Keunhyoung Luke", ""], ["Nam", "Juhan", ""]]}, {"id": "1703.01793", "submitter": "Jongpil Lee", "authors": "Jongpil Lee, Juhan Nam", "title": "Multi-Level and Multi-Scale Feature Aggregation Using Pre-trained\n  Convolutional Neural Networks for Music Auto-tagging", "comments": "5 pages, 5 figures, 2 tables", "journal-ref": null, "doi": "10.1109/LSP.2017.2713830", "report-no": null, "categories": "cs.NE cs.LG cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music auto-tagging is often handled in a similar manner to image\nclassification by regarding the 2D audio spectrogram as image data. However,\nmusic auto-tagging is distinguished from image classification in that the tags\nare highly diverse and have different levels of abstractions. Considering this\nissue, we propose a convolutional neural networks (CNN)-based architecture that\nembraces multi-level and multi-scaled features. The architecture is trained in\nthree steps. First, we conduct supervised feature learning to capture local\naudio features using a set of CNNs with different input sizes. Second, we\nextract audio features from each layer of the pre-trained convolutional\nnetworks separately and aggregate them altogether given a long audio clip.\nFinally, we put them into fully-connected networks and make final predictions\nof the tags. Our experiments show that using the combination of multi-level and\nmulti-scale features is highly effective in music auto-tagging and the proposed\nmethod outperforms previous state-of-the-arts on the MagnaTagATune dataset and\nthe Million Song Dataset. We further show that the proposed architecture is\nuseful in transfer learning.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 09:57:25 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 17:21:04 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Lee", "Jongpil", ""], ["Nam", "Juhan", ""]]}, {"id": "1703.01804", "submitter": "Vatsal Sharan", "authors": "Vatsal Sharan, Gregory Valiant", "title": "Orthogonalized ALS: A Theoretically Principled Tensor Decomposition\n  Algorithm for Practical Use", "comments": "Minor updates to presentation. Appears in ICML'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popular Alternating Least Squares (ALS) algorithm for tensor\ndecomposition is efficient and easy to implement, but often converges to poor\nlocal optima---particularly when the weights of the factors are non-uniform. We\npropose a modification of the ALS approach that is as efficient as standard\nALS, but provably recovers the true factors with random initialization under\nstandard incoherence assumptions on the factors of the tensor. We demonstrate\nthe significant practical superiority of our approach over traditional ALS for\na variety of tasks on synthetic data---including tensor factorization on exact,\nnoisy and over-complete tensors, as well as tensor completion---and for\ncomputing word embeddings from a third-order word tri-occurrence tensor.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 10:31:00 GMT"}, {"version": "v2", "created": "Sat, 23 Sep 2017 21:15:50 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Sharan", "Vatsal", ""], ["Valiant", "Gregory", ""]]}, {"id": "1703.01827", "submitter": "Di Xie", "authors": "Di Xie and Jiang Xiong and Shiliang Pu", "title": "All You Need is Beyond a Good Init: Exploring Better Solution for\n  Training Extremely Deep Convolutional Neural Networks with Orthonormality and\n  Modulation", "comments": "Updating experiments; CVPR2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network is difficult to train and this predicament becomes worse\nas the depth increases. The essence of this problem exists in the magnitude of\nbackpropagated errors that will result in gradient vanishing or exploding\nphenomenon. We show that a variant of regularizer which utilizes orthonormality\namong different filter banks can alleviate this problem. Moreover, we design a\nbackward error modulation mechanism based on the quasi-isometry assumption\nbetween two consecutive parametric layers. Equipped with these two ingredients,\nwe propose several novel optimization solutions that can be utilized for\ntraining a specific-structured (repetitively triple modules of Conv-BNReLU)\nextremely deep convolutional neural network (CNN) WITHOUT any shortcuts/\nidentity mappings from scratch. Experiments show that our proposed solutions\ncan achieve distinct improvements for a 44-layer and a 110-layer plain networks\non both the CIFAR-10 and ImageNet datasets. Moreover, we can successfully train\nplain CNNs to match the performance of the residual counterparts.\n  Besides, we propose new principles for designing network structure from the\ninsights evoked by orthonormality. Combined with residual structure, we achieve\ncomparative performance on the ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 11:54:43 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2017 08:22:09 GMT"}, {"version": "v3", "created": "Mon, 10 Apr 2017 02:12:29 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Xie", "Di", ""], ["Xiong", "Jiang", ""], ["Pu", "Shiliang", ""]]}, {"id": "1703.01830", "submitter": "L\\'aszl\\'o V\\'egh", "authors": "Alina Ene and Huy L. Nguyen and L\\'aszl\\'o A. V\\'egh", "title": "Decomposable Submodular Function Minimization: Discrete and Continuous", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates connections between discrete and continuous\napproaches for decomposable submodular function minimization. We provide\nimproved running time estimates for the state-of-the-art continuous algorithms\nfor the problem using combinatorial arguments. We also provide a systematic\nexperimental comparison of the two types of methods, based on a clear\ndistinction between level-0 and level-1 algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 12:06:58 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Ene", "Alina", ""], ["Nguyen", "Huy L.", ""], ["V\u00e9gh", "L\u00e1szl\u00f3 A.", ""]]}, {"id": "1703.01898", "submitter": "Dani Yogatama", "authors": "Dani Yogatama, Chris Dyer, Wang Ling, Phil Blunsom", "title": "Generative and Discriminative Text Classification with Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically characterize the performance of discriminative and generative\nLSTM models for text classification. We find that although RNN-based generative\nmodels are more powerful than their bag-of-words ancestors (e.g., they account\nfor conditional dependencies across words in a document), they have higher\nasymptotic error rates than discriminatively trained RNN models. However we\nalso find that generative models approach their asymptotic error rate more\nrapidly than their discriminative counterparts---the same pattern that Ng &\nJordan (2001) proved holds for linear classification models that make more\nnaive conditional independence assumptions. Building on this finding, we\nhypothesize that RNN-based generative classification models will be more robust\nto shifts in the data distribution. This hypothesis is confirmed in a series of\nexperiments in zero-shot and continual learning settings that show that\ngenerative models substantially outperform discriminative models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 14:40:09 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 01:27:23 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Yogatama", "Dani", ""], ["Dyer", "Chris", ""], ["Ling", "Wang", ""], ["Blunsom", "Phil", ""]]}, {"id": "1703.01913", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Daniel M. Kane, Vladimir Nikishkin", "title": "Near-Optimal Closeness Testing of Discrete Histogram Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of testing the equivalence between two discrete\nhistograms. A {\\em $k$-histogram} over $[n]$ is a probability distribution that\nis piecewise constant over some set of $k$ intervals over $[n]$. Histograms\nhave been extensively studied in computer science and statistics. Given a set\nof samples from two $k$-histogram distributions $p, q$ over $[n]$, we want to\ndistinguish (with high probability) between the cases that $p = q$ and\n$\\|p-q\\|_1 \\geq \\epsilon$. The main contribution of this paper is a new\nalgorithm for this testing problem and a nearly matching information-theoretic\nlower bound. Specifically, the sample complexity of our algorithm matches our\nlower bound up to a logarithmic factor, improving on previous work by\npolynomial factors in the relevant parameters. Our algorithmic approach applies\nin a more general setting and yields improved sample upper bounds for testing\ncloseness of other structured distributions as well.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 15:03:55 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Nikishkin", "Vladimir", ""]]}, {"id": "1703.01946", "submitter": "Oier Mees", "authors": "Oier Mees, Nichola Abdo, Mladen Mazuran, Wolfram Burgard", "title": "Metric Learning for Generalizing Spatial Relations to New Objects", "comments": "Accepted at the 2017 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems. The new Freiburg Spatial Relations Dataset and a demo\n  video of our approach running on the PR-2 robot are available at our project\n  website: http://spatialrelations.cs.uni-freiburg.de", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-centered environments are rich with a wide variety of spatial relations\nbetween everyday objects. For autonomous robots to operate effectively in such\nenvironments, they should be able to reason about these relations and\ngeneralize them to objects with different shapes and sizes. For example, having\nlearned to place a toy inside a basket, a robot should be able to generalize\nthis concept using a spoon and a cup. This requires a robot to have the\nflexibility to learn arbitrary relations in a lifelong manner, making it\nchallenging for an expert to pre-program it with sufficient knowledge to do so\nbeforehand. In this paper, we address the problem of learning spatial relations\nby introducing a novel method from the perspective of distance metric learning.\nOur approach enables a robot to reason about the similarity between pairwise\nspatial relations, thereby enabling it to use its previous knowledge when\npresented with a new relation to imitate. We show how this makes it possible to\nlearn arbitrary spatial relations from non-expert users using a small number of\nexamples and in an interactive manner. Our extensive evaluation with real-world\ndata demonstrates the effectiveness of our method in reasoning about a\ncontinuous spectrum of spatial relations and generalizing them to new objects.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 16:13:17 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 12:47:56 GMT"}, {"version": "v3", "created": "Mon, 24 Jul 2017 12:24:31 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Mees", "Oier", ""], ["Abdo", "Nichola", ""], ["Mazuran", "Mladen", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1703.01958", "submitter": "David Hallac", "authors": "David Hallac, Youngsuk Park, Stephen Boyd, Jure Leskovec", "title": "Network Inference via the Time-Varying Graphical Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important problems can be modeled as a system of interconnected\nentities, where each entity is recording time-dependent observations or\nmeasurements. In order to spot trends, detect anomalies, and interpret the\ntemporal dynamics of such data, it is essential to understand the relationships\nbetween the different entities and how these relationships evolve over time. In\nthis paper, we introduce the time-varying graphical lasso (TVGL), a method of\ninferring time-varying networks from raw time series data. We cast the problem\nin terms of estimating a sparse time-varying inverse covariance matrix, which\nreveals a dynamic network of interdependencies between the entities. Since\ndynamic network inference is a computationally expensive task, we derive a\nscalable message-passing algorithm based on the Alternating Direction Method of\nMultipliers (ADMM) to solve this problem in an efficient way. We also discuss\nseveral extensions, including a streaming algorithm to update the model and\nincorporate new observations in real time. Finally, we evaluate our TVGL\nalgorithm on both real and synthetic datasets, obtaining interpretable results\nand outperforming state-of-the-art baselines in terms of both accuracy and\nscalability.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 16:35:48 GMT"}, {"version": "v2", "created": "Sat, 10 Jun 2017 01:07:39 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Hallac", "David", ""], ["Park", "Youngsuk", ""], ["Boyd", "Stephen", ""], ["Leskovec", "Jure", ""]]}, {"id": "1703.01961", "submitter": "Christos Louizos", "authors": "Christos Louizos and Max Welling", "title": "Multiplicative Normalizing Flows for Variational Bayesian Neural\n  Networks", "comments": "Appearing at the International Conference on Machine Learning (ICML)\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reinterpret multiplicative noise in neural networks as auxiliary random\nvariables that augment the approximate posterior in a variational setting for\nBayesian neural networks. We show that through this interpretation it is both\nefficient and straightforward to improve the approximation by employing\nnormalizing flows while still allowing for local reparametrizations and a\ntractable lower bound. In experiments we show that with this new approximation\nwe can significantly improve upon classical mean field for Bayesian neural\nnetworks on both predictive accuracy as well as predictive uncertainty.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 16:39:16 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 21:05:58 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Louizos", "Christos", ""], ["Welling", "Max", ""]]}, {"id": "1703.01968", "submitter": "Zi Wang", "authors": "Zi Wang and Stefanie Jegelka", "title": "Max-value Entropy Search for Efficient Bayesian Optimization", "comments": "Proceedings of the 34th International Conference on Machine Learning,\n  Sydney, Australia, PMLR 70, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy Search (ES) and Predictive Entropy Search (PES) are popular and\nempirically successful Bayesian Optimization techniques. Both rely on a\ncompelling information-theoretic motivation, and maximize the information\ngained about the $\\arg\\max$ of the unknown function; yet, both are plagued by\nthe expensive computation for estimating entropies. We propose a new criterion,\nMax-value Entropy Search (MES), that instead uses the information about the\nmaximum function value. We show relations of MES to other Bayesian optimization\nmethods, and establish a regret bound. We observe that MES maintains or\nimproves the good empirical performance of ES/PES, while tremendously\nlightening the computational burden. In particular, MES is much more robust to\nthe number of samples used for computing the entropy, and hence more efficient\nfor higher dimensional problems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 16:52:54 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 17:32:01 GMT"}, {"version": "v3", "created": "Tue, 2 Jan 2018 18:05:14 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Wang", "Zi", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1703.01970", "submitter": "Uri Stemmer", "authors": "Kobbi Nissim, Uri Stemmer", "title": "Concentration Bounds for High Sensitivity Functions Through Differential\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new line of work [Dwork et al. STOC 2015], [Hardt and Ullman FOCS 2014],\n[Steinke and Ullman COLT 2015], [Bassily et al. STOC 2016] demonstrates how\ndifferential privacy [Dwork et al. TCC 2006] can be used as a mathematical tool\nfor guaranteeing generalization in adaptive data analysis. Specifically, if a\ndifferentially private analysis is applied on a sample S of i.i.d. examples to\nselect a low-sensitivity function f, then w.h.p. f(S) is close to its\nexpectation, although f is being chosen based on the data.\n  Very recently, Steinke and Ullman observed that these generalization\nguarantees can be used for proving concentration bounds in the non-adaptive\nsetting, where the low-sensitivity function is fixed beforehand. In particular,\nthey obtain alternative proofs for classical concentration bounds for\nlow-sensitivity functions, such as the Chernoff bound and McDiarmid's\nInequality.\n  In this work, we set out to examine the situation for functions with\nhigh-sensitivity, for which differential privacy does not imply generalization\nguarantees under adaptive analysis. We show that differential privacy can be\nused to prove concentration bounds for such functions in the non-adaptive\nsetting.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 16:53:32 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Nissim", "Kobbi", ""], ["Stemmer", "Uri", ""]]}, {"id": "1703.01973", "submitter": "Zi Wang", "authors": "Zi Wang and Chengtao Li and Stefanie Jegelka and Pushmeet Kohli", "title": "Batched High-dimensional Bayesian Optimization via Structural Kernel\n  Learning", "comments": "Proceedings of the 34th International Conference on Machine Learning,\n  Sydney, Australia, PMLR 70, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of high-dimensional black-box functions is an extremely\nchallenging problem. While Bayesian optimization has emerged as a popular\napproach for optimizing black-box functions, its applicability has been limited\nto low-dimensional problems due to its computational and statistical challenges\narising from high-dimensional settings. In this paper, we propose to tackle\nthese challenges by (1) assuming a latent additive structure in the function\nand inferring it properly for more efficient and effective BO, and (2)\nperforming multiple evaluations in parallel to reduce the number of iterations\nrequired by the method. Our novel approach learns the latent structure with\nGibbs sampling and constructs batched queries using determinantal point\nprocesses. Experimental validations on both synthetic and real-world functions\ndemonstrate that the proposed method outperforms the existing state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 17:01:19 GMT"}, {"version": "v2", "created": "Sat, 6 Jan 2018 16:04:06 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Wang", "Zi", ""], ["Li", "Chengtao", ""], ["Jegelka", "Stefanie", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1703.01977", "submitter": "Bohdan Pavlyshenko", "authors": "B.M. Pavlyshenko", "title": "Linear, Machine Learning and Probabilistic Approaches for Time Series\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study different approaches for time series modeling. The\nforecasting approaches using linear models, ARIMA alpgorithm, XGBoost machine\nlearning algorithm are described. Results of different model combinations are\nshown. For probabilistic modeling the approaches using copulas and Bayesian\ninference are considered.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 10:41:26 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Pavlyshenko", "B. M.", ""]]}, {"id": "1703.01988", "submitter": "Alexander Pritzel", "authors": "Alexander Pritzel, Benigno Uria, Sriram Srinivasan, Adri\\`a\n  Puigdom\\`enech, Oriol Vinyals, Demis Hassabis, Daan Wierstra, Charles\n  Blundell", "title": "Neural Episodic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning methods attain super-human performance in a wide\nrange of environments. Such methods are grossly inefficient, often taking\norders of magnitudes more data than humans to achieve reasonable performance.\nWe propose Neural Episodic Control: a deep reinforcement learning agent that is\nable to rapidly assimilate new experiences and act upon them. Our agent uses a\nsemi-tabular representation of the value function: a buffer of past experience\ncontaining slowly changing state representations and rapidly updated estimates\nof the value function. We show across a wide range of environments that our\nagent learns significantly faster than other state-of-the-art, general purpose\ndeep reinforcement learning agents.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 17:23:27 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Pritzel", "Alexander", ""], ["Uria", "Benigno", ""], ["Srinivasan", "Sriram", ""], ["Puigdom\u00e8nech", "Adri\u00e0", ""], ["Vinyals", "Oriol", ""], ["Hassabis", "Demis", ""], ["Wierstra", "Daan", ""], ["Blundell", "Charles", ""]]}, {"id": "1703.02000", "submitter": "Zhiming Zhou", "authors": "Zhiming Zhou, Han Cai, Shu Rong, Yuxuan Song, Kan Ren, Weinan Zhang,\n  Yong Yu, Jun Wang", "title": "Activation Maximization Generative Adversarial Nets", "comments": "Accepted as a conference paper on ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class labels have been empirically shown useful in improving the sample\nquality of generative adversarial nets (GANs). In this paper, we mathematically\nstudy the properties of the current variants of GANs that make use of class\nlabel information. With class aware gradient and cross-entropy decomposition,\nwe reveal how class labels and associated losses influence GAN's training.\nBased on that, we propose Activation Maximization Generative Adversarial\nNetworks (AM-GAN) as an advanced solution. Comprehensive experiments have been\nconducted to validate our analysis and evaluate the effectiveness of our\nsolution, where AM-GAN outperforms other strong baselines and achieves\nstate-of-the-art Inception Score (8.91) on CIFAR-10. In addition, we\ndemonstrate that, with the Inception ImageNet classifier, Inception Score\nmainly tracks the diversity of the generator, and there is, however, no\nreliable evidence that it can reflect the true sample quality. We thus propose\na new metric, called AM Score, to provide a more accurate estimation of the\nsample quality. Our proposed model also outperforms the baseline methods in the\nnew metric.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 17:42:55 GMT"}, {"version": "v2", "created": "Sun, 21 May 2017 16:33:55 GMT"}, {"version": "v3", "created": "Tue, 1 Aug 2017 15:32:29 GMT"}, {"version": "v4", "created": "Wed, 2 Aug 2017 16:56:07 GMT"}, {"version": "v5", "created": "Sat, 5 Aug 2017 08:17:04 GMT"}, {"version": "v6", "created": "Wed, 8 Nov 2017 13:49:19 GMT"}, {"version": "v7", "created": "Tue, 30 Jan 2018 18:28:35 GMT"}, {"version": "v8", "created": "Wed, 11 Jul 2018 05:43:27 GMT"}, {"version": "v9", "created": "Fri, 16 Nov 2018 07:18:19 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Zhou", "Zhiming", ""], ["Cai", "Han", ""], ["Rong", "Shu", ""], ["Song", "Yuxuan", ""], ["Ren", "Kan", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Wang", "Jun", ""]]}, {"id": "1703.02018", "submitter": "Ashvin Nair", "authors": "Ashvin Nair, Dian Chen, Pulkit Agrawal, Phillip Isola, Pieter Abbeel,\n  Jitendra Malik, Sergey Levine", "title": "Combining Self-Supervised Learning and Imitation for Vision-Based Rope\n  Manipulation", "comments": "8 pages, accepted to International Conference on Robotics and\n  Automation (ICRA) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulation of deformable objects, such as ropes and cloth, is an important\nbut challenging problem in robotics. We present a learning-based system where a\nrobot takes as input a sequence of images of a human manipulating a rope from\nan initial to goal configuration, and outputs a sequence of actions that can\nreproduce the human demonstration, using only monocular images as input. To\nperform this task, the robot learns a pixel-level inverse dynamics model of\nrope manipulation directly from images in a self-supervised manner, using about\n60K interactions with the rope collected autonomously by the robot. The human\ndemonstration provides a high-level plan of what to do and the low-level\ninverse model is used to execute the plan. We show that by combining the high\nand low-level plans, the robot can successfully manipulate a rope into a\nvariety of target shapes using only a sequence of human-provided images for\ndirection.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 18:40:29 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Nair", "Ashvin", ""], ["Chen", "Dian", ""], ["Agrawal", "Pulkit", ""], ["Isola", "Phillip", ""], ["Abbeel", "Pieter", ""], ["Malik", "Jitendra", ""], ["Levine", "Sergey", ""]]}, {"id": "1703.02059", "submitter": "Manuel Gomez Rodriguez", "authors": "Ali Zarezade and Abir De and Hamid Rabiee and Manuel Gomez Rodriguez", "title": "Cheshire: An Online Algorithm for Activity Maximization in Social\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User engagement in social networks depends critically on the number of online\nactions their users take in the network. Can we design an algorithm that finds\nwhen to incentivize users to take actions to maximize the overall activity in a\nsocial network? In this paper, we model the number of online actions over time\nusing multidimensional Hawkes processes, derive an alternate representation of\nthese processes based on stochastic differential equations (SDEs) with jumps\nand, exploiting this alternate representation, address the above question from\nthe perspective of stochastic optimal control of SDEs with jumps. We find that\nthe optimal level of incentivized actions depends linearly on the current level\nof overall actions. Moreover, the coefficients of this linear relationship can\nbe found by solving a matrix Riccati differential equation, which can be solved\nefficiently, and a first order differential equation, which has a closed form\nsolution. As a result, we are able to design an efficient online algorithm,\nCheshire, to sample the optimal times of the users' incentivized actions.\nExperiments on both synthetic and real data gathered from Twitter show that our\nalgorithm is able to consistently maximize the number of online actions more\neffectively than the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 19:01:03 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Zarezade", "Ali", ""], ["De", "Abir", ""], ["Rabiee", "Hamid", ""], ["Rodriguez", "Manuel Gomez", ""]]}, {"id": "1703.02065", "submitter": "Or Sharir", "authors": "Or Sharir and Amnon Shashua", "title": "On the Expressive Power of Overlapping Architectures of Deep Learning", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expressive efficiency refers to the relation between two architectures A and\nB, whereby any function realized by B could be replicated by A, but there\nexists functions realized by A, which cannot be replicated by B unless its size\ngrows significantly larger. For example, it is known that deep networks are\nexponentially efficient with respect to shallow networks, in the sense that a\nshallow network must grow exponentially large in order to approximate the\nfunctions represented by a deep network of polynomial size. In this work, we\nextend the study of expressive efficiency to the attribute of network\nconnectivity and in particular to the effect of \"overlaps\" in the convolutional\nprocess, i.e., when the stride of the convolution is smaller than its filter\nsize (receptive field). To theoretically analyze this aspect of network's\ndesign, we focus on a well-established surrogate for ConvNets called\nConvolutional Arithmetic Circuits (ConvACs), and then demonstrate empirically\nthat our results hold for standard ConvNets as well. Specifically, our analysis\nshows that having overlapping local receptive fields, and more broadly denser\nconnectivity, results in an exponential increase in the expressive capacity of\nneural networks. Moreover, while denser connectivity can increase the\nexpressive capacity, we show that the most common types of modern architectures\nalready exhibit exponential increase in expressivity, without relying on\nfully-connected layers.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 19:07:12 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 09:05:54 GMT"}, {"version": "v3", "created": "Fri, 27 Oct 2017 14:02:11 GMT"}, {"version": "v4", "created": "Sat, 24 Feb 2018 14:47:00 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Sharir", "Or", ""], ["Shashua", "Amnon", ""]]}, {"id": "1703.02100", "submitter": "Yatao A. Bian", "authors": "Andrew An Bian, Joachim M. Buhmann, Andreas Krause, Sebastian\n  Tschiatschek", "title": "Guarantees for Greedy Maximization of Non-submodular Functions with\n  Applications", "comments": "published at ICML 2017. First author is now known as Yatao Bian\n  <ybian@inf.ethz.ch>. ORCID: https://orcid.org/0000-0002-2368-4084", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance of the standard Greedy algorithm for\ncardinality constrained maximization of non-submodular nondecreasing set\nfunctions. While there are strong theoretical guarantees on the performance of\nGreedy for maximizing submodular functions, there are few guarantees for\nnon-submodular ones. However, Greedy enjoys strong empirical performance for\nmany important non-submodular functions, e.g., the Bayesian A-optimality\nobjective in experimental design. We prove theoretical guarantees supporting\nthe empirical performance. Our guarantees are characterized by a combination of\nthe (generalized) curvature $\\alpha$ and the submodularity ratio $\\gamma$. In\nparticular, we prove that Greedy enjoys a tight approximation guarantee of\n$\\frac{1}{\\alpha}(1- e^{-\\gamma\\alpha})$ for cardinality constrained\nmaximization. In addition, we bound the submodularity ratio and curvature for\nseveral important real-world objectives, including the Bayesian A-optimality\nobjective, the determinantal function of a square submatrix and certain linear\nprograms with combinatorial constraints. We experimentally validate our\ntheoretical findings for both synthetic and real-world applications.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 20:28:23 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 07:51:03 GMT"}, {"version": "v3", "created": "Tue, 13 Jun 2017 08:22:12 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 12:37:18 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Bian", "Andrew An", ""], ["Buhmann", "Joachim M.", ""], ["Krause", "Andreas", ""], ["Tschiatschek", "Sebastian", ""]]}, {"id": "1703.02102", "submitter": "Yemi Okesanjo", "authors": "Yemi Okesanjo, Victor Kofia", "title": "Revisiting stochastic off-policy action-value gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy stochastic actor-critic methods rely on approximating the\nstochastic policy gradient in order to derive an optimal policy. One may also\nderive the optimal policy by approximating the action-value gradient. The use\nof action-value gradients is desirable as policy improvement occurs along the\ndirection of steepest ascent. This has been studied extensively within the\ncontext of natural gradient actor-critic algorithms and more recently within\nthe context of deterministic policy gradients. In this paper we briefly discuss\nthe off-policy stochastic counterpart to deterministic action-value gradients,\nas well as an incremental approach for following the policy gradient in lieu of\nthe natural gradient.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 20:33:24 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 02:25:10 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Okesanjo", "Yemi", ""], ["Kofia", "Victor", ""]]}, {"id": "1703.02111", "submitter": "Duncan Barrack S", "authors": "Duncan Barrack and Simon Preston", "title": "Classification and clustering for observations of event time data using\n  non-homogeneous Poisson process models", "comments": "cleaned up figures and text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data of the form of event times arise in various applications. A simple model\nfor such data is a non-homogeneous Poisson process (NHPP) which is specified by\na rate function that depends on time. We consider the problem of having access\nto multiple independent observations of event time data, observed on a common\ninterval, from which we wish to classify or cluster the observations according\nto their rate functions. Each rate function is unknown but assumed to belong to\na finite number of rate functions each defining a distinct class. We model the\nrate functions using a spline basis expansion, the coefficients of which need\nto be estimated from data. The classification approach consists of using\ntraining data for which the class membership is known, to calculate maximum\nlikelihood estimates of the coefficients for each group, then assigning test\nobservations to a group by a maximum likelihood criterion. For clustering, by\nanalogy to the Gaussian mixture model approach for Euclidean data, we consider\nmixtures of NHPP and use the expectation-maximisation algorithm to estimate the\ncoefficients of the rate functions for the component models and group\nmembership probabilities for each observation. The classification and\nclustering approaches perform well on both synthetic and real-world data sets.\nCode associated with this paper is available at\nhttps://github.com/duncan-barrack/NHPP .\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 21:15:01 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 19:11:50 GMT"}, {"version": "v3", "created": "Sun, 7 Jan 2018 20:59:44 GMT"}, {"version": "v4", "created": "Wed, 20 Jun 2018 19:06:03 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Barrack", "Duncan", ""], ["Preston", "Simon", ""]]}, {"id": "1703.02116", "submitter": "Spiros Denaxas", "authors": "Henrietta Forssen, Riyaz S. Patel, Natalie Fitzpatrick, Aroon\n  Hingorani, Adam Timmis, Harry Hemingway, Spiros C. Denaxas", "title": "Evaluation of Machine Learning Methods to Predict Coronary Artery\n  Disease Using Metabolomic Data", "comments": "Medical Informatics Europe (MIE2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metabolomic data can potentially enable accurate, non-invasive and low-cost\nprediction of coronary artery disease. Regression-based analytical approaches\nhowever might fail to fully account for interactions between metabolites, rely\non a priori selected input features and thus might suffer from poorer accuracy.\nSupervised machine learning methods can potentially be used in order to fully\nexploit the dimensionality and richness of the data. In this paper, we\nsystematically implement and evaluate a set of supervised learning methods (L1\nregression, random forest classifier) and compare them to traditional\nregression-based approaches for disease prediction using metabolomic data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 11:53:49 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Forssen", "Henrietta", ""], ["Patel", "Riyaz S.", ""], ["Fitzpatrick", "Natalie", ""], ["Hingorani", "Aroon", ""], ["Timmis", "Adam", ""], ["Hemingway", "Harry", ""], ["Denaxas", "Spiros C.", ""]]}, {"id": "1703.02144", "submitter": "Ian Fox", "authors": "Ian Fox, Lynn Ang, Mamta Jaiswal, Rodica Pop-Busui, Jenna Wiens", "title": "Contextual Motifs: Increasing the Utility of Motifs using Contextual\n  Data", "comments": "10 pages, 7 figures, accepted for oral presentation at KDD '17", "journal-ref": "Proceedings of the 23rd ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining, 2017", "doi": "10.1145/3097983.3098068", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motifs are a powerful tool for analyzing physiological waveform data.\nStandard motif methods, however, ignore important contextual information (e.g.,\nwhat the patient was doing at the time the data were collected). We hypothesize\nthat these additional contextual data could increase the utility of motifs.\nThus, we propose an extension to motifs, contextual motifs, that incorporates\ncontext. Recognizing that, oftentimes, context may be unobserved or\nunavailable, we focus on methods to jointly infer motifs and context. Applied\nto both simulated and real physiological data, our proposed approach improves\nupon existing motif methods in terms of the discriminative utility of the\ndiscovered motifs. In particular, we discovered contextual motifs in continuous\nglucose monitor (CGM) data collected from patients with type 1 diabetes.\nCompared to their contextless counterparts, these contextual motifs led to\nbetter predictions of hypo- and hyperglycemic events. Our results suggest that\neven when inferred, context is useful in both a long- and short-term prediction\nhorizon when processing and interpreting physiological waveform data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 23:02:09 GMT"}, {"version": "v2", "created": "Mon, 31 Jul 2017 16:37:27 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Fox", "Ian", ""], ["Ang", "Lynn", ""], ["Jaiswal", "Mamta", ""], ["Pop-Busui", "Rodica", ""], ["Wiens", "Jenna", ""]]}, {"id": "1703.02155", "submitter": "Quang N. Tran", "authors": "Ba-Ngu Vo, Dinh Phung, Quang N. Tran, and Ba-Tuong Vo", "title": "Model-Based Multiple Instance Learning", "comments": "16 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Multiple Instance (MI) data are point patterns -- sets or multi-sets of\nunordered points -- appropriate statistical point pattern models have not been\nused in MI learning. This article proposes a framework for model-based MI\nlearning using point process theory. Likelihood functions for point pattern\ndata derived from point process theory enable principled yet conceptually\ntransparent extensions of learning tasks, such as classification, novelty\ndetection and clustering, to point pattern data. Furthermore, tractable point\npattern models as well as solutions for learning and decision making from point\npattern data are developed.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 00:03:32 GMT"}, {"version": "v2", "created": "Sun, 13 Aug 2017 16:11:50 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Vo", "Ba-Ngu", ""], ["Phung", "Dinh", ""], ["Tran", "Quang N.", ""], ["Vo", "Ba-Tuong", ""]]}, {"id": "1703.02156", "submitter": "Jiaming Song", "authors": "Jiaming Song, Russell Stewart, Shengjia Zhao and Stefano Ermon", "title": "On the Limits of Learning Representations with Label-Based Supervision", "comments": "Submitted to ICLR 2017 Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in neural network based classifiers have transformed automatic\nfeature learning from a pipe dream of stronger AI to a routine and expected\nproperty of practical systems. Since the emergence of AlexNet every winning\nsubmission of the ImageNet challenge has employed end-to-end representation\nlearning, and due to the utility of good representations for transfer learning,\nrepresentation learning has become as an important and distinct task from\nsupervised learning. At present, this distinction is inconsequential, as\nsupervised methods are state-of-the-art in learning transferable\nrepresentations. But recent work has shown that generative models can also be\npowerful agents of representation learning. Will the representations learned\nfrom these generative methods ever rival the quality of those from their\nsupervised competitors? In this work, we argue in the affirmative, that from an\ninformation theoretic perspective, generative models have greater potential for\nrepresentation learning. Based on several experimentally validated assumptions,\nwe show that supervised learning is upper bounded in its capacity for\nrepresentation learning in ways that certain generative models, such as\nGenerative Adversarial Networks (GANs) are not. We hope that our analysis will\nprovide a rigorous motivation for further exploration of generative\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 00:09:31 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Song", "Jiaming", ""], ["Stewart", "Russell", ""], ["Zhao", "Shengjia", ""], ["Ermon", "Stefano", ""]]}, {"id": "1703.02161", "submitter": "Sofia Ira Ktena", "authors": "Sofia Ira Ktena, Sarah Parisot, Enzo Ferrante, Martin Rajchl, Matthew\n  Lee, Ben Glocker, Daniel Rueckert", "title": "Distance Metric Learning using Graph Convolutional Networks: Application\n  to Functional Brain Networks", "comments": "International Conference on Medical Image Computing and\n  Computer-Assisted Interventions (MICCAI) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating similarity between graphs is of major importance in several\ncomputer vision and pattern recognition problems, where graph representations\nare often used to model objects or interactions between elements. The choice of\na distance or similarity metric is, however, not trivial and can be highly\ndependent on the application at hand. In this work, we propose a novel metric\nlearning method to evaluate distance between graphs that leverages the power of\nconvolutional neural networks, while exploiting concepts from spectral graph\ntheory to allow these operations on irregular graphs. We demonstrate the\npotential of our method in the field of connectomics, where neuronal pathways\nor functional connections between brain regions are commonly modelled as\ngraphs. In this problem, the definition of an appropriate graph similarity\nfunction is critical to unveil patterns of disruptions associated with certain\nbrain disorders. Experimental results on the ABIDE dataset show that our method\ncan learn a graph similarity metric tailored for a clinical application,\nimproving the performance of a simple k-nn classifier by 11.9% compared to a\ntraditional distance metric.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 00:49:27 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 11:05:52 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Ktena", "Sofia Ira", ""], ["Parisot", "Sarah", ""], ["Ferrante", "Enzo", ""], ["Rajchl", "Martin", ""], ["Lee", "Matthew", ""], ["Glocker", "Ben", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1703.02205", "submitter": "Szu-Wei Fu", "authors": "Szu-Wei Fu, Yu Tsao, Xugang Lu, Hisashi Kawai", "title": "Raw Waveform-based Speech Enhancement by Fully Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a fully convolutional network (FCN) model for raw\nwaveform-based speech enhancement. The proposed system performs speech\nenhancement in an end-to-end (i.e., waveform-in and waveform-out) manner, which\ndif-fers from most existing denoising methods that process the magnitude\nspectrum (e.g., log power spectrum (LPS)) only. Because the fully connected\nlayers, which are involved in deep neural networks (DNN) and convolutional\nneural networks (CNN), may not accurately characterize the local information of\nspeech signals, particularly with high frequency components, we employed fully\nconvolutional layers to model the waveform. More specifically, FCN consists of\nonly convolutional layers and thus the local temporal structures of speech\nsignals can be efficiently and effectively preserved with relatively few\nweights. Experimental results show that DNN- and CNN-based models have limited\ncapability to restore high frequency components of waveforms, thus leading to\ndecreased intelligibility of enhanced speech. By contrast, the proposed FCN\nmodel can not only effectively recover the waveforms but also outperform the\nLPS-based DNN baseline in terms of short-time objective intelligibility (STOI)\nand perceptual evaluation of speech quality (PESQ). In addition, the number of\nmodel parameters in FCN is approximately only 0.2% compared with that in both\nDNN and CNN.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 04:03:27 GMT"}, {"version": "v2", "created": "Sun, 19 Mar 2017 09:51:36 GMT"}, {"version": "v3", "created": "Thu, 15 Jun 2017 11:10:07 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Fu", "Szu-Wei", ""], ["Tsao", "Yu", ""], ["Lu", "Xugang", ""], ["Kawai", "Hisashi", ""]]}, {"id": "1703.02291", "submitter": "Chongxuan Li", "authors": "Chongxuan Li and Kun Xu and Jun Zhu and Bo Zhang", "title": "Triple Generative Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Nets (GANs) have shown promise in image generation and\nsemi-supervised learning (SSL). However, existing GANs in SSL have two\nproblems: (1) the generator and the discriminator (i.e. the classifier) may not\nbe optimal at the same time; and (2) the generator cannot control the semantics\nof the generated samples. The problems essentially arise from the two-player\nformulation, where a single discriminator shares incompatible roles of\nidentifying fake samples and predicting labels and it only estimates the data\nwithout considering the labels. To address the problems, we present triple\ngenerative adversarial net (Triple-GAN), which consists of three players---a\ngenerator, a discriminator and a classifier. The generator and the classifier\ncharacterize the conditional distributions between images and labels, and the\ndiscriminator solely focuses on identifying fake image-label pairs. We design\ncompatible utilities to ensure that the distributions characterized by the\nclassifier and the generator both converge to the data distribution. Our\nresults on various datasets demonstrate that Triple-GAN as a unified model can\nsimultaneously (1) achieve the state-of-the-art classification results among\ndeep generative models, and (2) disentangle the classes and styles of the input\nand transfer smoothly in the data space via interpolation in the latent space\nclass-conditionally.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 09:26:56 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 09:12:51 GMT"}, {"version": "v3", "created": "Fri, 2 Jun 2017 08:21:45 GMT"}, {"version": "v4", "created": "Sun, 5 Nov 2017 17:25:11 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Li", "Chongxuan", ""], ["Xu", "Kun", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1703.02310", "submitter": "Shirli Di-Castro Shashua", "authors": "Shirli Di-Castro Shashua, Shie Mannor", "title": "Deep Robust Kalman Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Robust Markov Decision Process (RMDP) is a sequential decision making model\nthat accounts for uncertainty in the parameters of dynamic systems. This\nuncertainty introduces difficulties in learning an optimal policy, especially\nfor environments with large state spaces. We propose two algorithms, RTD-DQN\nand Deep-RoK, for solving large-scale RMDPs using nonlinear approximation\nschemes such as deep neural networks. The RTD-DQN algorithm incorporates the\nrobust Bellman temporal difference error into a robust loss function, yielding\nrobust policies for the agent. The Deep-RoK algorithm is a robust Bayesian\nmethod, based on the Extended Kalman Filter (EKF), that accounts for both the\nuncertainty in the weights of the approximated value function and the\nuncertainty in the transition probabilities, improving the robustness of the\nagent. We provide theoretical results for our approach and test the proposed\nalgorithms on a continuous state domain.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 10:16:45 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Shashua", "Shirli Di-Castro", ""], ["Mannor", "Shie", ""]]}, {"id": "1703.02317", "submitter": "Emre Cakir", "authors": "Emre\\c{C}ak{\\i}r, Sharath Adavanne, Giambattista Parascandolo,\n  Konstantinos Drossos, Tuomas Virtanen", "title": "Convolutional Recurrent Neural Networks for Bird Audio Detection", "comments": "Submitted to EUSIPCO 2017 Special Session on Bird Audio Signal\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bird sounds possess distinctive spectral structure which may exhibit small\nshifts in spectrum depending on the bird species and environmental conditions.\nIn this paper, we propose using convolutional recurrent neural networks on the\ntask of automated bird audio detection in real-life environments. In the\nproposed method, convolutional layers extract high dimensional, local frequency\nshift invariant features, while recurrent layers capture longer term\ndependencies between the features extracted from short time frames. This method\nachieves 88.5% Area Under ROC Curve (AUC) score on the unseen evaluation data\nand obtains the second place in the Bird Audio Detection challenge.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 10:36:30 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Emre\u00c7ak\u0131r", "", ""], ["Adavanne", "Sharath", ""], ["Parascandolo", "Giambattista", ""], ["Drossos", "Konstantinos", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1703.02363", "submitter": "Andre Ebert", "authors": "Andre Ebert, Michael Till Beck, Andy Mattausch, Lenz Belzner, Claudia\n  Linnhoff Popien", "title": "Qualitative Assessment of Recurrent Human Motion", "comments": "Published within the proceedings of the 25th European Signal\n  Processing Conference (EUSIPCO) 2017, Kos Island, Greece, IEEE 6 Pages, 5\n  Figures", "journal-ref": null, "doi": "10.23919/EUSIPCO.2017.8081218", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphone applications designed to track human motion in combination with\nwearable sensors, e.g., during physical exercising, raised huge attention\nrecently. Commonly, they provide quantitative services, such as personalized\ntraining instructions or the counting of distances. But qualitative monitoring\nand assessment is still missing, e.g., to detect malpositions, to prevent\ninjuries, or to optimize training success. We address this issue by presenting\na concept for qualitative as well as generic assessment of recurrent human\nmotion by processing multi-dimensional, continuous time series tracked with\nmotion sensors. Therefore, our segmentation procedure extracts individual\nevents of specific length and we propose expressive features to accomplish a\nqualitative motion assessment by supervised classification. We verified our\napproach within a comprehensive study encompassing 27 athletes undertaking\ndifferent body weight exercises. We are able to recognize six different\nexercise types with a success rate of 100% and to assess them qualitatively\nwith an average success rate of 99.3%.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 12:57:01 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 14:17:14 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Ebert", "Andre", ""], ["Beck", "Michael Till", ""], ["Mattausch", "Andy", ""], ["Belzner", "Lenz", ""], ["Popien", "Claudia Linnhoff", ""]]}, {"id": "1703.02375", "submitter": "Anne Morvan", "authors": "Anne Morvan, Krzysztof Choromanski, C\\'edric Gouy-Pailler, Jamal Atif", "title": "Graph sketching-based Space-efficient Data Clustering", "comments": "Proceedings of the 2018 SIAM International Conference on Data Mining", "journal-ref": null, "doi": "10.1137/1.9781611975321.2", "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of recovering arbitrary-shaped data\nclusters from datasets while facing \\emph{high space constraints}, as this is\nfor instance the case in many real-world applications when analysis algorithms\nare directly deployed on resources-limited mobile devices collecting the data.\nWe present DBMSTClu a new space-efficient density-based \\emph{non-parametric}\nmethod working on a Minimum Spanning Tree (MST) recovered from a limited number\nof linear measurements i.e. a \\emph{sketched} version of the dissimilarity\ngraph $\\mathcal{G}$ between the $N$ objects to cluster. Unlike $k$-means,\n$k$-medians or $k$-medoids algorithms, it does not fail at distinguishing\nclusters with particular forms thanks to the property of the MST for expressing\nthe underlying structure of a graph. No input parameter is needed contrarily to\nDBSCAN or the Spectral Clustering method. An approximate MST is retrieved by\nfollowing the dynamic \\emph{semi-streaming} model in handling the dissimilarity\ngraph $\\mathcal{G}$ as a stream of edge weight updates which is sketched in one\npass over the data into a compact structure requiring $O(N\n\\operatorname{polylog}(N))$ space, far better than the theoretical memory cost\n$O(N^2)$ of $\\mathcal{G}$. The recovered approximate MST $\\mathcal{T}$ as\ninput, DBMSTClu then successfully detects the right number of nonconvex\nclusters by performing relevant cuts on $\\mathcal{T}$ in a time linear in $N$.\nWe provide theoretical guarantees on the quality of the clustering partition\nand also demonstrate its advantage over the existing state-of-the-art on\nseveral datasets.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 13:43:45 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 13:11:52 GMT"}, {"version": "v3", "created": "Mon, 4 Sep 2017 07:58:04 GMT"}, {"version": "v4", "created": "Wed, 20 Dec 2017 20:37:29 GMT"}, {"version": "v5", "created": "Sun, 27 May 2018 17:17:46 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Morvan", "Anne", ""], ["Choromanski", "Krzysztof", ""], ["Gouy-Pailler", "C\u00e9dric", ""], ["Atif", "Jamal", ""]]}, {"id": "1703.02379", "submitter": "Christopher Morris", "authors": "Christopher Morris, Kristian Kersting, Petra Mutzel", "title": "Global Weisfeiler-Lehman Graph Kernels", "comments": "10 pages, accepted at IEEE ICDM 2017 (\"Glocalized Weisfeiler-Lehman\n  Graph Kernels: Global-Local Feature Maps of Graphs\")", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art graph kernels only take local graph properties into\naccount, i.e., the kernel is computed with regard to properties of the\nneighborhood of vertices or other small substructures. On the other hand,\nkernels that do take global graph propertiesinto account may not scale well to\nlarge graph databases. Here we propose to start exploring the space between\nlocal and global graph kernels, striking the balance between both worlds.\nSpecifically, we introduce a novel graph kernel based on the $k$-dimensional\nWeisfeiler-Lehman algorithm. Unfortunately, the $k$-dimensional\nWeisfeiler-Lehman algorithm scales exponentially in $k$. Consequently, we\ndevise a stochastic version of the kernel with provable approximation\nguarantees using conditional Rademacher averages. On bounded-degree graphs, it\ncan even be computed in constant time. We support our theoretical results with\nexperiments on several graph classification benchmarks, showing that our\nkernels often outperform the state-of-the-art in terms of classification\naccuracies.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 13:57:55 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 16:46:20 GMT"}, {"version": "v3", "created": "Fri, 22 Sep 2017 13:12:36 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Morris", "Christopher", ""], ["Kersting", "Kristian", ""], ["Mutzel", "Petra", ""]]}, {"id": "1703.02391", "submitter": "Yuncheng Li", "authors": "Yuncheng Li, Jianchao Yang, Yale Song, Liangliang Cao, Jiebo Luo,\n  Li-Jia Li", "title": "Learning from Noisy Labels with Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of learning from noisy labels is very useful in many visual\nrecognition tasks, as a vast amount of data with noisy labels are relatively\neasy to obtain. Traditionally, the label noises have been treated as\nstatistical outliers, and approaches such as importance re-weighting and\nbootstrap have been proposed to alleviate the problem. According to our\nobservation, the real-world noisy labels exhibit multi-mode characteristics as\nthe true labels, rather than behaving like independent random outliers. In this\nwork, we propose a unified distillation framework to use side information,\nincluding a small clean dataset and label relations in knowledge graph, to\n\"hedge the risk\" of learning from noisy labels. Furthermore, unlike the\ntraditional approaches evaluated based on simulated label noises, we propose a\nsuite of new benchmark datasets, in Sports, Species and Artifacts domains, to\nevaluate the task of learning from noisy labels in the practical setting. The\nempirical study demonstrates the effectiveness of our proposed method in all\nthe domains.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 14:15:14 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 07:21:56 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Li", "Yuncheng", ""], ["Yang", "Jianchao", ""], ["Song", "Yale", ""], ["Cao", "Liangliang", ""], ["Luo", "Jiebo", ""], ["Li", "Li-Jia", ""]]}, {"id": "1703.02403", "submitter": "Anton Osokin", "authors": "Anton Osokin, Francis Bach, Simon Lacoste-Julien", "title": "On Structured Prediction Theory with Calibrated Convex Surrogate Losses", "comments": "Appears in: Advances in Neural Information Processing Systems 30\n  (NIPS 2017). 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide novel theoretical insights on structured prediction in the context\nof efficient convex surrogate loss minimization with consistency guarantees.\nFor any task loss, we construct a convex surrogate that can be optimized via\nstochastic gradient descent and we prove tight bounds on the so-called\n\"calibration function\" relating the excess surrogate risk to the actual risk.\nIn contrast to prior related work, we carefully monitor the effect of the\nexponential number of classes in the learning guarantees as well as on the\noptimization complexity. As an interesting consequence, we formalize the\nintuition that some task losses make learning harder than others, and that the\nclassical 0-1 loss is ill-suited for general structured prediction.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 14:39:15 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 11:16:05 GMT"}, {"version": "v3", "created": "Thu, 16 Nov 2017 13:38:49 GMT"}, {"version": "v4", "created": "Mon, 29 Jan 2018 08:25:28 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Osokin", "Anton", ""], ["Bach", "Francis", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1703.02419", "submitter": "Andreas Svensson", "authors": "Thomas B. Sch\\\"on, Andreas Svensson, Lawrence Murray, Fredrik Lindsten", "title": "Probabilistic learning of nonlinear dynamical systems using sequential\n  Monte Carlo", "comments": "Thomas B. Sch\\\"on, Andreas Svensson, Lawrence Murray and Fredrik\n  Lindsten, 2018. Probabilistic learning of nonlinear dynamical systems using\n  sequential Monte Carlo. In Mechanical Systems and Signal Processing, Volume\n  104, pp. 866-883", "journal-ref": null, "doi": "10.1016/j.ymssp.2017.10.033", "report-no": null, "categories": "stat.CO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic modeling provides the capability to represent and manipulate\nuncertainty in data, models, predictions and decisions. We are concerned with\nthe problem of learning probabilistic models of dynamical systems from measured\ndata. Specifically, we consider learning of probabilistic nonlinear state-space\nmodels. There is no closed-form solution available for this problem, implying\nthat we are forced to use approximations. In this tutorial we will provide a\nself-contained introduction to one of the state-of-the-art methods---the\nparticle Metropolis--Hastings algorithm---which has proven to offer a practical\napproximation. This is a Monte Carlo based method, where the particle filter is\nused to guide a Markov chain Monte Carlo method through the parameter space.\nOne of the key merits of the particle Metropolis--Hastings algorithm is that it\nis guaranteed to converge to the \"true solution\" under mild assumptions,\ndespite being based on a particle filter with only a finite number of\nparticles. We will also provide a motivating numerical example illustrating the\nmethod using a modeling language tailored for sequential Monte Carlo methods.\nThe intention of modeling languages of this kind is to open up the power of\nsophisticated Monte Carlo methods---including particle\nMetropolis--Hastings---to a large group of users without requiring them to know\nall the underlying mathematical details.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 15:01:51 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 08:52:57 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Sch\u00f6n", "Thomas B.", ""], ["Svensson", "Andreas", ""], ["Murray", "Lawrence", ""], ["Lindsten", "Fredrik", ""]]}, {"id": "1703.02433", "submitter": "Bilal Farooq", "authors": "Isma\\\"il Saadi, Melvin Wong, Bilal Farooq, Jacques Teller, Mario Cools", "title": "An investigation into machine learning approaches for forecasting\n  spatio-temporal demand in ride-hailing service", "comments": "Currently under review for journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present machine learning approaches for characterizing and\nforecasting the short-term demand for on-demand ride-hailing services. We\npropose the spatio-temporal estimation of the demand that is a function of\nvariable effects related to traffic, pricing and weather conditions. With\nrespect to the methodology, a single decision tree, bootstrap-aggregated\n(bagged) decision trees, random forest, boosted decision trees, and artificial\nneural network for regression have been adapted and systematically compared\nusing various statistics, e.g. R-square, Root Mean Square Error (RMSE), and\nslope. To better assess the quality of the models, they have been tested on a\nreal case study using the data of DiDi Chuxing, the main on-demand ride hailing\nservice provider in China. In the current study, 199,584 time-slots describing\nthe spatio-temporal ride-hailing demand has been extracted with an\naggregated-time interval of 10 mins. All the methods are trained and validated\non the basis of two independent samples from this dataset. The results revealed\nthat boosted decision trees provide the best prediction accuracy (RMSE=16.41),\nwhile avoiding the risk of over-fitting, followed by artificial neural network\n(20.09), random forest (23.50), bagged decision trees (24.29) and single\ndecision tree (33.55).\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 15:26:38 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Saadi", "Isma\u00efl", ""], ["Wong", "Melvin", ""], ["Farooq", "Bilal", ""], ["Teller", "Jacques", ""], ["Cools", "Mario", ""]]}, {"id": "1703.02435", "submitter": "Sebastian Johann Wetzel", "authors": "Sebastian Johann Wetzel", "title": "Unsupervised learning of phase transitions: from principal component\n  analysis to variational autoencoders", "comments": "corrected typos", "journal-ref": "Phys. Rev. E 96, 022140 (2017)", "doi": "10.1103/PhysRevE.96.022140", "report-no": null, "categories": "cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ unsupervised machine learning techniques to learn latent parameters\nwhich best describe states of the two-dimensional Ising model and the\nthree-dimensional XY model. These methods range from principal component\nanalysis to artificial neural network based variational autoencoders. The\nstates are sampled using a Monte-Carlo simulation above and below the critical\ntemperature. We find that the predicted latent parameters correspond to the\nknown order parameters. The latent representation of the states of the models\nin question are clustered, which makes it possible to identify phases without\nprior knowledge of their existence or the underlying Hamiltonian. Furthermore,\nwe find that the reconstruction loss function can be used as a universal\nidentifier for phase transitions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 15:34:12 GMT"}, {"version": "v2", "created": "Sun, 12 Mar 2017 23:44:34 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Wetzel", "Sebastian Johann", ""]]}, {"id": "1703.02437", "submitter": "Santiago Manen", "authors": "Santiago Manen, Michael Gygli, Dengxin Dai, Luc Van Gool", "title": "PathTrack: Fast Trajectory Annotation with Path Supervision", "comments": "10 pages, ICCV submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in Multiple Object Tracking (MOT) has been historically limited by\nthe size of the available datasets. We present an efficient framework to\nannotate trajectories and use it to produce a MOT dataset of unprecedented\nsize. In our novel path supervision the annotator loosely follows the object\nwith the cursor while watching the video, providing a path annotation for each\nobject in the sequence. Our approach is able to turn such weak annotations into\ndense box trajectories. Our experiments on existing datasets prove that our\nframework produces more accurate annotations than the state of the art, in a\nfraction of the time. We further validate our approach by crowdsourcing the\nPathTrack dataset, with more than 15,000 person trajectories in 720 sequences.\nTracking approaches can benefit training on such large-scale datasets, as did\nobject recognition. We prove this by re-training an off-the-shelf person\nmatching network, originally trained on the MOT15 dataset, almost halving the\nmisclassification rate. Additionally, training on our data consistently\nimproves tracking results, both on our dataset and on MOT15. On the latter, we\nimprove the top-performing tracker (NOMT) dropping the number of IDSwitches by\n18% and fragments by 5%.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 15:36:39 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 07:08:34 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Manen", "Santiago", ""], ["Gygli", "Michael", ""], ["Dai", "Dengxin", ""], ["Van Gool", "Luc", ""]]}, {"id": "1703.02492", "submitter": "Thiernithi Variddhisa\\\"i", "authors": "Thiernithi Variddhisai and Danilo Mandic", "title": "Online Multilinear Dictionary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A method for online tensor dictionary learning is proposed. With the\nassumption of separable dictionaries, tensor contraction is used to diminish a\n$N$-way model of $\\mathcal{O}\\left(L^N\\right)$ into a simple matrix equation of\n$\\mathcal{O}\\left(NL^2\\right)$ with a real-time capability. To avoid numerical\ninstability due to inversion of sparse matrix, a class of stochastic gradient\nwith memory is formulated via a least-square solution to guarantee convergence\nand robustness. Both gradient descent with exact line search and Newton's\nmethod are discussed and realized. Extensions onto how to deal with bad\ninitialization and outliers are also explained in detail. Experiments on two\nsynthetic signals confirms an impressive performance of our proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 17:52:13 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 22:48:17 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 14:27:40 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 14:38:11 GMT"}, {"version": "v5", "created": "Tue, 10 Mar 2020 12:45:36 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Variddhisai", "Thiernithi", ""], ["Mandic", "Danilo", ""]]}, {"id": "1703.02504", "submitter": "Martin Jaggi", "authors": "Jan Deriu, Aurelien Lucchi, Valeria De Luca, Aliaksei Severyn, Simon\n  M\\\"uller, Mark Cieliebak, Thomas Hofmann, Martin Jaggi", "title": "Leveraging Large Amounts of Weakly Supervised Data for Multi-Language\n  Sentiment Classification", "comments": "appearing at WWW 2017 - 26th International World Wide Web Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel approach for multi-lingual sentiment\nclassification in short texts. This is a challenging task as the amount of\ntraining data in languages other than English is very limited. Previously\nproposed multi-lingual approaches typically require to establish a\ncorrespondence to English for which powerful classifiers are already available.\nIn contrast, our method does not require such supervision. We leverage large\namounts of weakly-supervised data in various languages to train a multi-layer\nconvolutional network and demonstrate the importance of using pre-training of\nsuch networks. We thoroughly evaluate our approach on various multi-lingual\ndatasets, including the recent SemEval-2016 sentiment prediction benchmark\n(Task 4), where we achieved state-of-the-art performance. We also compare the\nperformance of our model trained individually for each language to a variant\ntrained for all languages at once. We show that the latter model reaches\nslightly worse - but still acceptable - performance when compared to the single\nlanguage model, while benefiting from better generalization properties across\nlanguages.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 18:15:57 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Deriu", "Jan", ""], ["Lucchi", "Aurelien", ""], ["De Luca", "Valeria", ""], ["Severyn", "Aliaksei", ""], ["M\u00fcller", "Simon", ""], ["Cieliebak", "Mark", ""], ["Hofmann", "Thomas", ""], ["Jaggi", "Martin", ""]]}, {"id": "1703.02518", "submitter": "Martin Jaggi", "authors": "Dmytro Perekrestenko, Volkan Cevher, Martin Jaggi", "title": "Faster Coordinate Descent via Adaptive Importance Sampling", "comments": "appearing at AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Coordinate descent methods employ random partial updates of decision\nvariables in order to solve huge-scale convex optimization problems. In this\nwork, we introduce new adaptive rules for the random selection of their\nupdates. By adaptive, we mean that our selection rules are based on the dual\nresidual or the primal-dual gap estimates and can change at each iteration. We\ntheoretically characterize the performance of our selection rules and\ndemonstrate improvements over the state-of-the-art, and extend our theory and\nalgorithms to general convex objectives. Numerical evidence with hinge-loss\nsupport vector machines and Lasso confirm that the practice follows the theory.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 18:36:55 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Perekrestenko", "Dmytro", ""], ["Cevher", "Volkan", ""], ["Jaggi", "Martin", ""]]}, {"id": "1703.02527", "submitter": "Branislav Kveton", "authors": "Masrour Zoghi, Tomas Tunys, Mohammad Ghavamzadeh, Branislav Kveton,\n  Csaba Szepesvari, and Zheng Wen", "title": "Online Learning to Rank in Stochastic Click Models", "comments": "Proceedings of the 34th International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning to rank is a core problem in information retrieval and\nmachine learning. Many provably efficient algorithms have been recently\nproposed for this problem in specific click models. The click model is a model\nof how the user interacts with a list of documents. Though these results are\nsignificant, their impact on practice is limited, because all proposed\nalgorithms are designed for specific click models and lack convergence\nguarantees in other models. In this work, we propose BatchRank, the first\nonline learning to rank algorithm for a broad class of click models. The class\nencompasses two most fundamental click models, the cascade and position-based\nmodels. We derive a gap-dependent upper bound on the $T$-step regret of\nBatchRank and evaluate it on a range of web search queries. We observe that\nBatchRank outperforms ranked bandits and is more robust than CascadeKL-UCB, an\nexisting algorithm for the cascade model.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 18:53:58 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 07:13:15 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Zoghi", "Masrour", ""], ["Tunys", "Tomas", ""], ["Ghavamzadeh", "Mohammad", ""], ["Kveton", "Branislav", ""], ["Szepesvari", "Csaba", ""], ["Wen", "Zheng", ""]]}, {"id": "1703.02528", "submitter": "Samuel Albanie", "authors": "Samuel Albanie, S\\'ebastien Ehrhardt, Jo\\~ao F. Henriques", "title": "Stopping GAN Violence: Generative Unadversarial Networks", "comments": "Under review as a conference paper at SIGBOVIK 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the costs of human violence have attracted a great deal of attention\nfrom the research community, the effects of the network-on-network (NoN)\nviolence popularised by Generative Adversarial Networks have yet to be\naddressed. In this work, we quantify the financial, social, spiritual,\ncultural, grammatical and dermatological impact of this aggression and address\nthe issue by proposing a more peaceful approach which we term Generative\nUnadversarial Networks (GUNs). Under this framework, we simultaneously train\ntwo models: a generator G that does its best to capture whichever data\ndistribution it feels it can manage, and a motivator M that helps G to achieve\nits dream. Fighting is strictly verboten and both models evolve by learning to\nrespect their differences. The framework is both theoretically and electrically\ngrounded in game theory, and can be viewed as a winner-shares-all two-player\ngame in which both players work as a team to achieve the best score.\nExperiments show that by working in harmony, the proposed model is able to\nclaim both the moral and log-likelihood high ground. Our work builds on a rich\nhistory of carefully argued position-papers, published as anonymous YouTube\ncomments, which prove that the optimal solution to NoN violence is more GUNs.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 18:54:04 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Albanie", "Samuel", ""], ["Ehrhardt", "S\u00e9bastien", ""], ["Henriques", "Jo\u00e3o F.", ""]]}, {"id": "1703.02567", "submitter": "M. Sevi Baltaoglu", "authors": "Sevi Baltaoglu, Lang Tong, Qing Zhao", "title": "Online Learning of Optimal Bidding Strategy in Repeated Multi-Commodity\n  Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the online learning problem of a bidder who participates in repeated\nauctions. With the goal of maximizing his T-period payoff, the bidder\ndetermines the optimal allocation of his budget among his bids for $K$ goods at\neach period. As a bidding strategy, we propose a polynomial-time algorithm,\ninspired by the dynamic programming approach to the knapsack problem. The\nproposed algorithm, referred to as dynamic programming on discrete set (DPDS),\nachieves a regret order of $O(\\sqrt{T\\log{T}})$. By showing that the regret is\nlower bounded by $\\Omega(\\sqrt{T})$ for any strategy, we conclude that DPDS is\norder optimal up to a $\\sqrt{\\log{T}}$ term. We evaluate the performance of\nDPDS empirically in the context of virtual trading in wholesale electricity\nmarkets by using historical data from the New York market. Empirical results\nshow that DPDS consistently outperforms benchmark heuristic methods that are\nderived from machine learning and online learning approaches.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 19:33:50 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 17:01:18 GMT"}, {"version": "v3", "created": "Wed, 12 Apr 2017 12:55:06 GMT"}, {"version": "v4", "created": "Fri, 28 Apr 2017 22:00:22 GMT"}, {"version": "v5", "created": "Fri, 17 Nov 2017 18:45:00 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Baltaoglu", "Sevi", ""], ["Tong", "Lang", ""], ["Zhao", "Qing", ""]]}, {"id": "1703.02570", "submitter": "Amina Mollaysa", "authors": "Amina Mollaysa, Pablo Strasser, Alexandros Kalousis", "title": "Regularising Non-linear Models Using Feature Side-information", "comments": "11 page with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Very often features come with their own vectorial descriptions which provide\ndetailed information about their properties. We refer to these vectorial\ndescriptions as feature side-information. In the standard learning scenario,\ninput is represented as a vector of features and the feature side-information\nis most often ignored or used only for feature selection prior to model\nfitting. We believe that feature side-information which carries information\nabout features intrinsic property will help improve model prediction if used in\na proper way during learning process. In this paper, we propose a framework\nthat allows for the incorporation of the feature side-information during the\nlearning of very general model families to improve the prediction performance.\nWe control the structures of the learned models so that they reflect features\nsimilarities as these are defined on the basis of the side-information. We\nperform experiments on a number of benchmark datasets which show significant\npredictive performance gains, over a number of baselines, as a result of the\nexploitation of the side-information.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 19:47:22 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Mollaysa", "Amina", ""], ["Strasser", "Pablo", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1703.02573", "submitter": "Ziang Xie", "authors": "Ziang Xie, Sida I. Wang, Jiwei Li, Daniel L\\'evy, Aiming Nie, Dan\n  Jurafsky, Andrew Y. Ng", "title": "Data Noising as Smoothing in Neural Network Language Models", "comments": "ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data noising is an effective technique for regularizing neural network\nmodels. While noising is widely adopted in application domains such as vision\nand speech, commonly used noising primitives have not been developed for\ndiscrete sequence-level settings such as language modeling. In this paper, we\nderive a connection between input noising in neural network language models and\nsmoothing in $n$-gram models. Using this connection, we draw upon ideas from\nsmoothing to develop effective noising schemes. We demonstrate performance\ngains when applying the proposed schemes to language modeling and machine\ntranslation. Finally, we provide empirical analysis validating the relationship\nbetween noising and smoothing.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 19:56:26 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Xie", "Ziang", ""], ["Wang", "Sida I.", ""], ["Li", "Jiwei", ""], ["L\u00e9vy", "Daniel", ""], ["Nie", "Aiming", ""], ["Jurafsky", "Dan", ""], ["Ng", "Andrew Y.", ""]]}, {"id": "1703.02596", "submitter": "Benjamin Chamberlain", "authors": "Benjamin Paul Chamberlain, Angelo Cardoso, C.H. Bryan Liu, Roberto\n  Pagliari, Marc Peter Deisenroth", "title": "Customer Lifetime Value Prediction Using Embeddings", "comments": "10 pages, 11 figures", "journal-ref": "Proceedings of the 23rd ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining Pages 1753-1762, 2017", "doi": "10.1145/3097983.3098123", "report-no": null, "categories": "cs.LG cs.CY cs.IR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the Customer LifeTime Value (CLTV) prediction system deployed at\nASOS.com, a global online fashion retailer. CLTV prediction is an important\nproblem in e-commerce where an accurate estimate of future value allows\nretailers to effectively allocate marketing spend, identify and nurture high\nvalue customers and mitigate exposure to losses. The system at ASOS provides\ndaily estimates of the future value of every customer and is one of the\ncornerstones of the personalised shopping experience. The state of the art in\nthis domain uses large numbers of handcrafted features and ensemble regressors\nto forecast value, predict churn and evaluate customer loyalty. Recently,\ndomains including language, vision and speech have shown dramatic advances by\nreplacing handcrafted features with features that are learned automatically\nfrom data. We detail the system deployed at ASOS and show that learning feature\nrepresentations is a promising extension to the state of the art in CLTV\nmodelling. We propose a novel way to generate embeddings of customers, which\naddresses the issue of the ever changing product catalogue and obtain a\nsignificant improvement over an exhaustive set of handcrafted features.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 21:18:11 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 12:20:06 GMT"}, {"version": "v3", "created": "Thu, 6 Jul 2017 16:40:44 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Chamberlain", "Benjamin Paul", ""], ["Cardoso", "Angelo", ""], ["Liu", "C. H. Bryan", ""], ["Pagliari", "Roberto", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1703.02618", "submitter": "Edith Cohen", "authors": "Eliav Buchnik and Edith Cohen", "title": "Bootstrapped Graph Diffusions: Exposing the Power of Nonlinearity", "comments": "11 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based semi-supervised learning (SSL) algorithms predict labels for all\nnodes based on provided labels of a small set of seed nodes. Classic methods\ncapture the graph structure through some underlying diffusion process that\npropagates through the graph edges. Spectral diffusion, which includes\npersonalized page rank and label propagation, propagates through random walks.\nSocial diffusion propagates through shortest paths. A common ground to these\ndiffusions is their {\\em linearity}, which does not distinguish between\ncontributions of few \"strong\" relations and many \"weak\" relations.\n  Recently, non-linear methods such as node embeddings and graph convolutional\nnetworks (GCN) demonstrated a large gain in quality for SSL tasks. These\nmethods introduce multiple components and greatly vary on how the graph\nstructure, seed label information, and other features are used.\n  We aim here to study the contribution of non-linearity, as an isolated\ningredient, to the performance gain. To do so, we place classic linear graph\ndiffusions in a self-training framework. Surprisingly, we observe that SSL\nusing the resulting {\\em bootstrapped diffusions} not only significantly\nimproves over the respective non-bootstrapped baselines but also outperform\nstate-of-the-art non-linear SSL methods. Moreover, since the self-training\nwrapper retains the scalability of the base method, we obtain both higher\nquality and better scalability.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 22:10:34 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 11:54:41 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Buchnik", "Eliav", ""], ["Cohen", "Edith", ""]]}, {"id": "1703.02622", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky and Kwabena Boahen", "title": "Online Convex Optimization with Unconstrained Domains and Losses", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 29 (2016)\n  748-756", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online convex optimization algorithm (RescaledExp) that\nachieves optimal regret in the unconstrained setting without prior knowledge of\nany bounds on the loss functions. We prove a lower bound showing an exponential\nseparation between the regret of existing algorithms that require a known bound\non the loss functions and any algorithm that does not require such knowledge.\nRescaledExp matches this lower bound asymptotically in the number of\niterations. RescaledExp is naturally hyperparameter-free and we demonstrate\nempirically that it matches prior optimization algorithms that require\nhyperparameter optimization.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 22:14:53 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Cutkosky", "Ashok", ""], ["Boahen", "Kwabena", ""]]}, {"id": "1703.02626", "submitter": "Sharan Vaswani", "authors": "Sharan Vaswani, Mark Schmidt, Laks V.S. Lakshmanan", "title": "Horde of Bandits using Gaussian Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gang of bandits (GOB) model \\cite{cesa2013gang} is a recent contextual\nbandits framework that shares information between a set of bandit problems,\nrelated by a known (possibly noisy) graph. This model is useful in problems\nlike recommender systems where the large number of users makes it vital to\ntransfer information between users. Despite its effectiveness, the existing GOB\nmodel can only be applied to small problems due to its quadratic\ntime-dependence on the number of nodes. Existing solutions to combat the\nscalability issue require an often-unrealistic clustering assumption. By\nexploiting a connection to Gaussian Markov random fields (GMRFs), we show that\nthe GOB model can be made to scale to much larger graphs without additional\nassumptions. In addition, we propose a Thompson sampling algorithm which uses\nthe recent GMRF sampling-by-perturbation technique, allowing it to scale to\neven larger problems (leading to a \"horde\" of bandits). We give regret bounds\nand experimental results for GOB with Thompson sampling and epoch-greedy\nalgorithms, indicating that these methods are as good as or significantly\nbetter than ignoring the graph or adopting a clustering-based approach.\nFinally, when an existing graph is not available, we propose a heuristic for\nlearning it on the fly and show promising results.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 22:21:50 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Vaswani", "Sharan", ""], ["Schmidt", "Mark", ""], ["Lakshmanan", "Laks V. S.", ""]]}, {"id": "1703.02629", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky and Kwabena Boahen", "title": "Online Learning Without Prior Information", "comments": "12 pages main text; 35 pages total; COLT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of optimization and online learning algorithms today\nrequire some prior information about the data (often in the form of bounds on\ngradients or on the optimal parameter value). When this information is not\navailable, these algorithms require laborious manual tuning of various\nhyperparameters, motivating the search for algorithms that can adapt to the\ndata with no prior information. We describe a frontier of new lower bounds on\nthe performance of such algorithms, reflecting a tradeoff between a term that\ndepends on the optimal parameter value and a term that depends on the\ngradients' rate of growth. Further, we construct a family of algorithms whose\nperformance matches any desired point on this frontier, which no previous\nalgorithm reaches.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 22:32:06 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 01:29:10 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Cutkosky", "Ashok", ""], ["Boahen", "Kwabena", ""]]}, {"id": "1703.02641", "submitter": "Frederic Sala", "authors": "Frederic Sala, Shahroze Kabir, Guy Van den Broeck, and Lara Dolecek", "title": "Don't Fear the Bit Flips: Optimized Coding Strategies for Binary\n  Classification", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After being trained, classifiers must often operate on data that has been\ncorrupted by noise. In this paper, we consider the impact of such noise on the\nfeatures of binary classifiers. Inspired by tools for classifier robustness, we\nintroduce the same classification probability (SCP) to measure the resulting\ndistortion on the classifier outputs. We introduce a low-complexity estimate of\nthe SCP based on quantization and polynomial multiplication. We also study\nchannel coding techniques based on replication error-correcting codes. In\ncontrast to the traditional channel coding approach, where error-correction is\nmeant to preserve the data and is agnostic to the application, our schemes\nspecifically aim to maximize the SCP (equivalently minimizing the distortion of\nthe classifier output) for the same redundancy overhead.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 00:04:01 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Sala", "Frederic", ""], ["Kabir", "Shahroze", ""], ["Broeck", "Guy Van den", ""], ["Dolecek", "Lara", ""]]}, {"id": "1703.02647", "submitter": "Ethan R. Elenberg", "authors": "Ethan R. Elenberg, Alexandros G. Dimakis, Moran Feldman, Amin Karbasi", "title": "Streaming Weak Submodularity: Interpreting Neural Networks on the Fly", "comments": "To appear in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning applications, it is important to explain the\npredictions of a black-box classifier. For example, why does a deep neural\nnetwork assign an image to a particular class? We cast interpretability of\nblack-box classifiers as a combinatorial maximization problem and propose an\nefficient streaming algorithm to solve it subject to cardinality constraints.\nBy extending ideas from Badanidiyuru et al. [2014], we provide a constant\nfactor approximation guarantee for our algorithm in the case of random stream\norder and a weakly submodular objective function. This is the first such\ntheoretical guarantee for this general class of functions, and we also show\nthat no such algorithm exists for a worst case stream order. Our algorithm\nobtains similar explanations of Inception V3 predictions $10$ times faster than\nthe state-of-the-art LIME framework of Ribeiro et al. [2016].\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 00:31:30 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 20:17:54 GMT"}, {"version": "v3", "created": "Wed, 22 Nov 2017 19:18:22 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Elenberg", "Ethan R.", ""], ["Dimakis", "Alexandros G.", ""], ["Feldman", "Moran", ""], ["Karbasi", "Amin", ""]]}, {"id": "1703.02660", "submitter": "Aravind Rajeswaran", "authors": "Aravind Rajeswaran, Kendall Lowrey, Emanuel Todorov, Sham Kakade", "title": "Towards Generalization and Simplicity in Continuous Control", "comments": "NIPS 2017, Project page: https://sites.google.com/view/simple-pol", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work shows that policies with simple linear and RBF parameterizations\ncan be trained to solve a variety of continuous control tasks, including the\nOpenAI gym benchmarks. The performance of these trained policies are\ncompetitive with state of the art results, obtained with more elaborate\nparameterizations such as fully connected neural networks. Furthermore,\nexisting training and testing scenarios are shown to be very limited and prone\nto over-fitting, thus giving rise to only trajectory-centric policies. Training\nwith a diverse initial state distribution is shown to produce more global\npolicies with better generalization. This allows for interactive control\nscenarios where the system recovers from large on-line perturbations; as shown\nin the supplementary video.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 01:33:51 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 05:17:11 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Rajeswaran", "Aravind", ""], ["Lowrey", "Kendall", ""], ["Todorov", "Emanuel", ""], ["Kakade", "Sham", ""]]}, {"id": "1703.02662", "submitter": "Tomo Miyazaki", "authors": "Tomo Miyazaki, Shinichiro Omachi", "title": "Structural Data Recognition with Graph Model Boosting", "comments": "8 pages", "journal-ref": "IEEE Access, 2018", "doi": "10.1109/ACCESS.2018.2876860", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel method for structural data recognition using a\nlarge number of graph models. In general, prevalent methods for structural data\nrecognition have two shortcomings: 1) Only a single model is used to capture\nstructural variation. 2) Naive recognition methods are used, such as the\nnearest neighbor method. In this paper, we propose strengthening the\nrecognition performance of these models as well as their ability to capture\nstructural variation. The proposed method constructs a large number of graph\nmodels and trains decision trees using the models. This paper makes two main\ncontributions. The first is a novel graph model that can quickly perform\ncalculations, which allows us to construct several models in a feasible amount\nof time. The second contribution is a novel approach to structural data\nrecognition: graph model boosting. Comprehensive structural variations can be\ncaptured with a large number of graph models constructed in a boosting\nframework, and a sophisticated classifier can be formed by aggregating the\ndecision trees. Consequently, we can carry out structural data recognition with\npowerful recognition capability in the face of comprehensive structural\nvariation. The experiments shows that the proposed method achieves impressive\nresults and outperforms existing methods on datasets of IAM graph database\nrepository.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 01:45:54 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Miyazaki", "Tomo", ""], ["Omachi", "Shinichiro", ""]]}, {"id": "1703.02682", "submitter": "Murat Kocaoglu", "authors": "Karthikeyan Shanmugam, Murat Kocaoglu, Alexandros G. Dimakis and Sujay\n  Sanghavi", "title": "Sparse Quadratic Logistic Regression in Sub-quadratic Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider support recovery in the quadratic logistic regression setting -\nwhere the target depends on both p linear terms $x_i$ and up to $p^2$ quadratic\nterms $x_i x_j$. Quadratic terms enable prediction/modeling of higher-order\neffects between features and the target, but when incorporated naively may\ninvolve solving a very large regression problem. We consider the sparse case,\nwhere at most $s$ terms (linear or quadratic) are non-zero, and provide a new\nfaster algorithm. It involves (a) identifying the weak support (i.e. all\nrelevant variables) and (b) standard logistic regression optimization only on\nthese chosen variables. The first step relies on a novel insight about\ncorrelation tests in the presence of non-linearity, and takes $O(pn)$ time for\n$n$ samples - giving potentially huge computational gains over the naive\napproach. Motivated by insights from the boolean case, we propose a non-linear\ncorrelation test for non-binary finite support case that involves hashing a\nvariable and then correlating with the output variable. We also provide\nexperimental results to demonstrate the effectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 03:21:08 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Shanmugam", "Karthikeyan", ""], ["Kocaoglu", "Murat", ""], ["Dimakis", "Alexandros G.", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1703.02689", "submitter": "Erik Lindgren", "authors": "Erik M. Lindgren, Alexandros G. Dimakis, Adam Klivans", "title": "Exact MAP Inference by Avoiding Fractional Vertices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graphical model, one essential problem is MAP inference, that is,\nfinding the most likely configuration of states according to the model.\nAlthough this problem is NP-hard, large instances can be solved in practice. A\nmajor open question is to explain why this is true. We give a natural condition\nunder which we can provably perform MAP inference in polynomial time. We\nrequire that the number of fractional vertices in the LP relaxation exceeding\nthe optimal solution is bounded by a polynomial in the problem size. This\nresolves an open question by Dimakis, Gohari, and Wainwright. In contrast, for\ngeneral LP relaxations of integer programs, known techniques can only handle a\nconstant number of fractional vertices whose value exceeds the optimal\nsolution. We experimentally verify this condition and demonstrate how efficient\nvarious integer programming methods are at removing fractional solutions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 03:55:27 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Lindgren", "Erik M.", ""], ["Dimakis", "Alexandros G.", ""], ["Klivans", "Adam", ""]]}, {"id": "1703.02690", "submitter": "Erik Lindgren", "authors": "Erik M. Lindgren, Shanshan Wu, Alexandros G. Dimakis", "title": "Leveraging Sparsity for Efficient Submodular Data Summarization", "comments": "In NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The facility location problem is widely used for summarizing large datasets\nand has additional applications in sensor placement, image retrieval, and\nclustering. One difficulty of this problem is that submodular optimization\nalgorithms require the calculation of pairwise benefits for all items in the\ndataset. This is infeasible for large problems, so recent work proposed to only\ncalculate nearest neighbor benefits. One limitation is that several strong\nassumptions were invoked to obtain provable approximation guarantees. In this\npaper we establish that these extra assumptions are not necessary---solving the\nsparsified problem will be almost optimal under the standard assumptions of the\nproblem. We then analyze a different method of sparsification that is a better\nmodel for methods such as Locality Sensitive Hashing to accelerate the nearest\nneighbor computations and extend the use of the problem to a broader family of\nsimilarities. We validate our approach by demonstrating that it rapidly\ngenerates interpretable summaries.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 03:56:27 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Lindgren", "Erik M.", ""], ["Wu", "Shanshan", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1703.02702", "submitter": "Lerrel Pinto Mr", "authors": "Lerrel Pinto, James Davidson, Rahul Sukthankar and Abhinav Gupta", "title": "Robust Adversarial Reinforcement Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks coupled with fast simulation and improved computation\nhave led to recent successes in the field of reinforcement learning (RL).\nHowever, most current RL-based approaches fail to generalize since: (a) the gap\nbetween simulation and real world is so large that policy-learning approaches\nfail to transfer; (b) even if policy learning is done in real world, the data\nscarcity leads to failed generalization from training to test scenarios (e.g.,\ndue to different friction or object masses). Inspired from H-infinity control\nmethods, we note that both modeling errors and differences in training and test\nscenarios can be viewed as extra forces/disturbances in the system. This paper\nproposes the idea of robust adversarial reinforcement learning (RARL), where we\ntrain an agent to operate in the presence of a destabilizing adversary that\napplies disturbance forces to the system. The jointly trained adversary is\nreinforced -- that is, it learns an optimal destabilization policy. We\nformulate the policy learning as a zero-sum, minimax objective function.\nExtensive experiments in multiple environments (InvertedPendulum, HalfCheetah,\nSwimmer, Hopper and Walker2d) conclusively demonstrate that our method (a)\nimproves training stability; (b) is robust to differences in training/test\nconditions; and c) outperform the baseline even in the absence of the\nadversary.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 04:58:51 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Pinto", "Lerrel", ""], ["Davidson", "James", ""], ["Sukthankar", "Rahul", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1703.02721", "submitter": "Rajiv Khanna", "authors": "Rajiv Khanna, Ethan Elenberg, Alexandros G. Dimakis, Sahand Negahban", "title": "On Approximation Guarantees for Greedy Low Rank Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide new approximation guarantees for greedy low rank matrix estimation\nunder standard assumptions of restricted strong convexity and smoothness. Our\nnovel analysis also uncovers previously unknown connections between the low\nrank estimation and combinatorial optimization, so much so that our bounds are\nreminiscent of corresponding approximation bounds in submodular maximization.\nAdditionally, we also provide statistical recovery guarantees. Finally, we\npresent empirical comparison of greedy estimation with established baselines on\ntwo important real-world problems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 06:20:10 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Khanna", "Rajiv", ""], ["Elenberg", "Ethan", ""], ["Dimakis", "Alexandros G.", ""], ["Negahban", "Sahand", ""]]}, {"id": "1703.02723", "submitter": "Rajiv Khanna", "authors": "Rajiv Khanna, Ethan Elenberg, Alexandros G. Dimakis, Sahand Negahban,\n  Joydeep Ghosh", "title": "Scalable Greedy Feature Selection via Weak Submodularity", "comments": "To appear in AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greedy algorithms are widely used for problems in machine learning such as\nfeature selection and set function optimization. Unfortunately, for large\ndatasets, the running time of even greedy algorithms can be quite high. This is\nbecause for each greedy step we need to refit a model or calculate a function\nusing the previously selected choices and the new candidate.\n  Two algorithms that are faster approximations to the greedy forward selection\nwere introduced recently ([Mirzasoleiman et al. 2013, 2015]). They achieve\nbetter performance by exploiting distributed computation and stochastic\nevaluation respectively. Both algorithms have provable performance guarantees\nfor submodular functions.\n  In this paper we show that divergent from previously held opinion,\nsubmodularity is not required to obtain approximation guarantees for these two\nalgorithms. Specifically, we show that a generalized concept of weak\nsubmodularity suffices to give multiplicative approximation guarantees. Our\nresult extends the applicability of these algorithms to a larger class of\nfunctions. Furthermore, we show that a bounded submodularity ratio can be used\nto provide data dependent bounds that can sometimes be tighter also for\nsubmodular functions. We empirically validate our work by showing superior\nperformance of fast greedy approximations versus several established baselines\non artificial and real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 06:21:46 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Khanna", "Rajiv", ""], ["Elenberg", "Ethan", ""], ["Dimakis", "Alexandros G.", ""], ["Negahban", "Sahand", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1703.02724", "submitter": "Anru Zhang", "authors": "Anru Zhang and Dong Xia", "title": "Tensor SVD: Statistical and Computational Limits", "comments": "Typos fixed", "journal-ref": null, "doi": null, "report-no": "IEEE Transactions on Information Theory 64 (11), 7311-7338", "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a general framework for tensor singular value\ndecomposition (tensor SVD), which focuses on the methodology and theory for\nextracting the hidden low-rank structure from high-dimensional tensor data.\nComprehensive results are developed on both the statistical and computational\nlimits for tensor SVD. This problem exhibits three different phases according\nto the signal-to-noise ratio (SNR). In particular, with strong SNR, we show\nthat the classical higher-order orthogonal iteration achieves the minimax\noptimal rate of convergence in estimation; with weak SNR, the\ninformation-theoretical lower bound implies that it is impossible to have\nconsistent estimation in general; with moderate SNR, we show that the\nnon-convex maximum likelihood estimation provides optimal solution, but with\nNP-hard computational cost; moreover, under the hardness hypothesis of\nhypergraphic planted clique detection, there are no polynomial-time algorithms\nperforming consistently in general.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 06:22:56 GMT"}, {"version": "v2", "created": "Sat, 17 Jun 2017 18:54:51 GMT"}, {"version": "v3", "created": "Sat, 14 Apr 2018 17:29:56 GMT"}, {"version": "v4", "created": "Wed, 8 Jan 2020 12:35:34 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Zhang", "Anru", ""], ["Xia", "Dong", ""]]}, {"id": "1703.02728", "submitter": "Dylan Foster", "authors": "Dylan J. Foster, Daniel Reichman, Karthik Sridharan", "title": "Inference in Sparse Graphs with Pairwise Measurements and Side\n  Information", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the statistical problem of recovering a hidden \"ground truth\"\nbinary labeling for the vertices of a graph up to low Hamming error from noisy\nedge and vertex measurements. We present new algorithms and a sharp\nfinite-sample analysis for this problem on trees and sparse graphs with poor\nexpansion properties such as hypergrids and ring lattices. Our method\ngeneralizes and improves over that of Globerson et al. (2015), who introduced\nthe problem for two-dimensional grid lattices.\n  For trees we provide a simple, efficient, algorithm that infers the ground\ntruth with optimal Hamming error has optimal sample complexity and implies\nrecovery results for all connected graphs. Here, the presence of side\ninformation is critical to obtain a non-trivial recovery rate. We then show how\nto adapt this algorithm to tree decompositions of edge-subgraphs of certain\ngraph families such as lattices, resulting in optimal recovery error rates that\ncan be obtained efficiently\n  The thrust of our analysis is to 1) use the tree decomposition along with\nedge measurements to produce a small class of viable vertex labelings and 2)\napply an analysis influenced by statistical learning theory to show that we can\ninfer the ground truth from this class using vertex measurements. We show the\npower of our method in several examples including hypergrids, ring lattices,\nand the Newman-Watts model for small world graphs. For two-dimensional grids,\nour results improve over Globerson et al. (2015) by obtaining optimal recovery\nin the constant-height regime.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 06:51:41 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 09:46:53 GMT"}, {"version": "v3", "created": "Tue, 27 Feb 2018 01:33:39 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Foster", "Dylan J.", ""], ["Reichman", "Daniel", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1703.02757", "submitter": "El Mahdi El Mhamdi", "authors": "Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, Julien Stainer", "title": "Byzantine-Tolerant Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of data, the need for scalability and the complexity of models\nused in modern machine learning calls for distributed implementations. Yet, as\nof today, distributed machine learning frameworks have largely ignored the\npossibility of arbitrary (i.e., Byzantine) failures. In this paper, we study\nthe robustness to Byzantine failures at the fundamental level of stochastic\ngradient descent (SGD), the heart of most machine learning algorithms. Assuming\na set of $n$ workers, up to $f$ of them being Byzantine, we ask how robust can\nSGD be, without limiting the dimension, nor the size of the parameter space.\n  We first show that no gradient descent update rule based on a linear\ncombination of the vectors proposed by the workers (i.e, current approaches)\ntolerates a single Byzantine failure. We then formulate a resilience property\nof the update rule capturing the basic requirements to guarantee convergence\ndespite $f$ Byzantine workers. We finally propose Krum, an update rule that\nsatisfies the resilience property aforementioned. For a $d$-dimensional\nlearning problem, the time complexity of Krum is $O(n^2 \\cdot (d + \\log n))$.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 09:26:36 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Blanchard", "Peva", ""], ["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Stainer", "Julien", ""]]}, {"id": "1703.02810", "submitter": "Evangelos Michelioudakis", "authors": "Alain Kibangou and Alexander Artikis and Evangelos Michelioudakis and\n  Georgios Paliouras and Marius Schmitt and John Lygeros and Chris Baber and\n  Natan Morar and Fabiana Fournier and Inna Skarbovsky", "title": "An Integrated and Scalable Platform for Proactive Event-Driven Traffic\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic on freeways can be managed by means of ramp meters from Road Traffic\nControl rooms. Human operators cannot efficiently manage a network of ramp\nmeters. To support them, we present an intelligent platform for traffic\nmanagement which includes a new ramp metering coordination scheme in the\ndecision making module, an efficient dashboard for interacting with human\noperators, machine learning tools for learning event definitions and Complex\nEvent Processing tools able to deal with uncertainties inherent to the traffic\nuse case. Unlike the usual approach, the devised event-driven platform is able\nto predict a congestion up to 4 minutes before it really happens. Proactive\ndecision making can then be established leading to significant improvement of\ntraffic conditions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 12:35:52 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Kibangou", "Alain", ""], ["Artikis", "Alexander", ""], ["Michelioudakis", "Evangelos", ""], ["Paliouras", "Georgios", ""], ["Schmitt", "Marius", ""], ["Lygeros", "John", ""], ["Baber", "Chris", ""], ["Morar", "Natan", ""], ["Fournier", "Fabiana", ""], ["Skarbovsky", "Inna", ""]]}, {"id": "1703.02850", "submitter": "Shixiang Wan", "authors": "Quan Zou, Shixiang Wan, Ying Ju, Jijun Tang and Xiangxiang Zeng", "title": "Pretata: predicting TATA binding proteins with novel features and\n  dimensionality reduction strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: It is necessary and essential to discovery protein function from\nthe novel primary sequences. Wet lab experimental procedures are not only\ntime-consuming, but also costly, so predicting protein structure and function\nreliably based only on amino acid sequence has significant value. TATA-binding\nprotein (TBP) is a kind of DNA binding protein, which plays a key role in the\ntranscription regulation. Our study proposed an automatic approach for\nidentifying TATA-binding proteins efficiently, accurately, and conveniently.\nThis method would guide for the special protein identification with\ncomputational intelligence strategies. Results: Firstly, we proposed novel\nfingerprint features for TBP based on pseudo amino acid composition,\nphysicochemical properties, and secondary structure. Secondly, hierarchical\nfeatures dimensionality reduction strategies were employed to improve the\nperformance furthermore. Currently, Pretata achieves 92.92% TATA- binding\nprotein prediction accuracy, which is better than all other existing methods.\nConclusions: The experiments demonstrate that our method could greatly improve\nthe prediction accuracy and speed, thus allowing large-scale NGS data\nprediction to be practical. A web server is developed to facilitate the other\nresearchers, which can be accessed at http://server.malab.cn/preTata/.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 13:48:46 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Zou", "Quan", ""], ["Wan", "Shixiang", ""], ["Ju", "Ying", ""], ["Tang", "Jijun", ""], ["Zeng", "Xiangxiang", ""]]}, {"id": "1703.02868", "submitter": "Tomas Pevny", "authors": "Tomas Pevny and Petr Somol", "title": "Discriminative models for multi-instance problems with tree-structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling network traffic is gaining importance in order to counter modern\nthreats of ever increasing sophistication. It is though surprisingly difficult\nand costly to construct reliable classifiers on top of telemetry data due to\nthe variety and complexity of signals that no human can manage to interpret in\nfull. Obtaining training data with sufficiently large and variable body of\nlabels can thus be seen as prohibitive problem. The goal of this work is to\ndetect infected computers by observing their HTTP(S) traffic collected from\nnetwork sensors, which are typically proxy servers or network firewalls, while\nrelying on only minimal human input in model training phase. We propose a\ndiscriminative model that makes decisions based on all computer's traffic\nobserved during predefined time window (5 minutes in our case). The model is\ntrained on collected traffic samples over equally sized time window per large\nnumber of computers, where the only labels needed are human verdicts about the\ncomputer as a whole (presumed infected vs. presumed clean). As part of training\nthe model itself recognizes discriminative patterns in traffic targeted to\nindividual servers and constructs the final high-level classifier on top of\nthem. We show the classifier to perform with very high precision, while the\nlearned traffic patterns can be interpreted as Indicators of Compromise. In the\nfollowing we implement the discriminative model as a neural network with\nspecial structure reflecting two stacked multi-instance problems. The main\nadvantages of the proposed configuration include not only improved accuracy and\nability to learn from gross labels, but also automatic learning of server types\n(together with their detectors) which are typically visited by infected\ncomputers.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 06:53:34 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Pevny", "Tomas", ""], ["Somol", "Petr", ""]]}, {"id": "1703.02883", "submitter": "Hadi Zare", "authors": "Kayvan Bijari, Hadi Zare, Hadi Veisi, Hossein Bobarshad", "title": "Memory Enriched Big Bang Big Crunch Optimization Algorithm for Data\n  Clustering", "comments": "17 pages, 3 figures, 8 tables", "journal-ref": "Neural Comput & Applic (2016)", "doi": "10.1007/s00521-016-2528-9", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster analysis plays an important role in decision making process for many\nknowledge-based systems. There exist a wide variety of different approaches for\nclustering applications including the heuristic techniques, probabilistic\nmodels, and traditional hierarchical algorithms. In this paper, a novel\nheuristic approach based on big bang-big crunch algorithm is proposed for\nclustering problems. The proposed method not only takes advantage of heuristic\nnature to alleviate typical clustering algorithms such as k-means, but it also\nbenefits from the memory based scheme as compared to its similar heuristic\ntechniques. Furthermore, the performance of the proposed algorithm is\ninvestigated based on several benchmark test functions as well as on the\nwell-known datasets. The experimental results show the significant superiority\nof the proposed method over the similar algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 15:50:35 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Bijari", "Kayvan", ""], ["Zare", "Hadi", ""], ["Veisi", "Hadi", ""], ["Bobarshad", "Hossein", ""]]}, {"id": "1703.02899", "submitter": "Andreas Doerr", "authors": "Andreas Doerr, Duy Nguyen-Tuong, Alonso Marco, Stefan Schaal,\n  Sebastian Trimpe", "title": "Model-Based Policy Search for Automatic Tuning of Multivariate PID\n  Controllers", "comments": "Accepted final version to appear in 2017 IEEE International\n  Conference on Robotics and Automation (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PID control architectures are widely used in industrial applications. Despite\ntheir low number of open parameters, tuning multiple, coupled PID controllers\ncan become tedious in practice. In this paper, we extend PILCO, a model-based\npolicy search framework, to automatically tune multivariate PID controllers\npurely based on data observed on an otherwise unknown system. The system's\nstate is extended appropriately to frame the PID policy as a static state\nfeedback policy. This renders PID tuning possible as the solution of a finite\nhorizon optimal control problem without further a priori knowledge. The\nframework is applied to the task of balancing an inverted pendulum on a seven\ndegree-of-freedom robotic arm, thereby demonstrating its capabilities of fast\nand data-efficient policy learning, even on complex real world problems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 16:28:17 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Doerr", "Andreas", ""], ["Nguyen-Tuong", "Duy", ""], ["Marco", "Alonso", ""], ["Schaal", "Stefan", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1703.02905", "submitter": "Visak Chadalavada Vijay Kumar", "authors": "Visak CV Kumar, Sehoon Ha and C Karen Liu", "title": "Learning a Unified Control Policy for Safe Falling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to fall safely is a necessary motor skill for humanoids performing\nhighly dynamic tasks, such as running and jumping. We propose a new method to\nlearn a policy that minimizes the maximal impulse during the fall. The\noptimization solves for both a discrete contact planning problem and a\ncontinuous optimal control problem. Once trained, the policy can compute the\noptimal next contacting body part (e.g. left foot, right foot, or hands),\ncontact location and timing, and the required joint actuation. We represent the\npolicy as a mixture of actor-critic neural network, which consists of n control\npolicies and the corresponding value functions. Each pair of actor-critic is\nassociated with one of the n possible contacting body parts. During execution,\nthe policy corresponding to the highest value function will be executed while\nthe associated body part will be the next contact with the ground. With this\nmixture of actor-critic architecture, the discrete contact sequence planning is\nsolved through the selection of the best critics while the continuous control\nproblem is solved by the optimization of actors. We show that our policy can\nachieve comparable, sometimes even higher, rewards than a recursive search of\nthe action space using dynamic programming, while enjoying 50 to 400 times of\nspeed gain during online execution.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 16:38:21 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 15:17:35 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Kumar", "Visak CV", ""], ["Ha", "Sehoon", ""], ["Liu", "C Karen", ""]]}, {"id": "1703.02910", "submitter": "Yarin Gal", "authors": "Yarin Gal and Riashat Islam and Zoubin Ghahramani", "title": "Deep Bayesian Active Learning with Image Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though active learning forms an important pillar of machine learning,\ndeep learning tools are not prevalent within it. Deep learning poses several\ndifficulties when used in an active learning setting. First, active learning\n(AL) methods generally rely on being able to learn and update models from small\namounts of data. Recent advances in deep learning, on the other hand, are\nnotorious for their dependence on large amounts of data. Second, many AL\nacquisition functions rely on model uncertainty, yet deep learning methods\nrarely represent such model uncertainty. In this paper we combine recent\nadvances in Bayesian deep learning into the active learning framework in a\npractical way. We develop an active learning framework for high dimensional\ndata, a task which has been extremely challenging so far, with very sparse\nexisting literature. Taking advantage of specialised models such as Bayesian\nconvolutional neural networks, we demonstrate our active learning techniques\nwith image data, obtaining a significant improvement on existing active\nlearning approaches. We demonstrate this on both the MNIST dataset, as well as\nfor skin cancer diagnosis from lesion images (ISIC2016 task).\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 16:53:57 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Gal", "Yarin", ""], ["Islam", "Riashat", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1703.02914", "submitter": "Yarin Gal", "authors": "Yingzhen Li and Yarin Gal", "title": "Dropout Inference in Bayesian Neural Networks with Alpha-divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To obtain uncertainty estimates with real-world Bayesian deep learning\nmodels, practical inference approximations are needed. Dropout variational\ninference (VI) for example has been used for machine vision and medical\napplications, but VI can severely underestimates model uncertainty.\nAlpha-divergences are alternative divergences to VI's KL objective, which are\nable to avoid VI's uncertainty underestimation. But these are hard to use in\npractice: existing techniques can only use Gaussian approximating\ndistributions, and require existing models to be changed radically, thus are of\nlimited use for practitioners. We propose a re-parametrisation of the\nalpha-divergence objectives, deriving a simple inference technique which,\ntogether with dropout, can be easily implemented with existing models by simply\nchanging the loss of the model. We demonstrate improved uncertainty estimates\nand accuracy compared to VI in dropout networks. We study our model's epistemic\nuncertainty far away from the data using adversarial images, showing that these\ncan be distinguished from non-adversarial images by examining our model's\nuncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 17:00:21 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Li", "Yingzhen", ""], ["Gal", "Yarin", ""]]}, {"id": "1703.02930", "submitter": "Abbas Mehrabian", "authors": "Peter L. Bartlett and Nick Harvey and Chris Liaw and Abbas Mehrabian", "title": "Nearly-tight VC-dimension and pseudodimension bounds for piecewise\n  linear neural networks", "comments": "Extended abstract appeared in COLT 2017; the upper bound was\n  presented at the 2016 ACM Conference on Data Science. This version includes\n  all the proofs and a refinement of the upper bound, Theorem 6. 16 pages, 2\n  figures", "journal-ref": "Journal of Machine Learning Research 20 (2019) 1-17", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove new upper and lower bounds on the VC-dimension of deep neural\nnetworks with the ReLU activation function. These bounds are tight for almost\nthe entire range of parameters. Letting $W$ be the number of weights and $L$ be\nthe number of layers, we prove that the VC-dimension is $O(W L \\log(W))$, and\nprovide examples with VC-dimension $\\Omega( W L \\log(W/L) )$. This improves\nboth the previously known upper bounds and lower bounds. In terms of the number\n$U$ of non-linear units, we prove a tight bound $\\Theta(W U)$ on the\nVC-dimension. All of these bounds generalize to arbitrary piecewise linear\nactivation functions, and also hold for the pseudodimensions of these function\nclasses.\n  Combined with previous results, this gives an intriguing range of\ndependencies of the VC-dimension on depth for networks with different\nnon-linearities: there is no dependence for piecewise-constant, linear\ndependence for piecewise-linear, and no more than quadratic dependence for\ngeneral piecewise-polynomial.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 17:35:17 GMT"}, {"version": "v2", "created": "Sun, 4 Jun 2017 19:13:36 GMT"}, {"version": "v3", "created": "Mon, 16 Oct 2017 01:29:59 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Harvey", "Nick", ""], ["Liaw", "Chris", ""], ["Mehrabian", "Abbas", ""]]}, {"id": "1703.02952", "submitter": "Sina Sajadmanesh", "authors": "Seyed Ali Osia, Ali Shahin Shamsabadi, Sina Sajadmanesh, Ali Taheri,\n  Kleomenis Katevas, Hamid R. Rabiee, Nicholas D. Lane, Hamed Haddadi", "title": "A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile\n  Analytics", "comments": "To appear in IEEE Internet of Things Journal", "journal-ref": "IEEE Internet of Things Journal, May 2020", "doi": "10.1109/JIOT.2020.2967734", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) devices and applications are being deployed in our\nhomes and workplaces. These devices often rely on continuous data collection to\nfeed machine learning models. However, this approach introduces several privacy\nand efficiency challenges, as the service operator can perform unwanted\ninferences on the available data. Recently, advances in edge processing have\npaved the way for more efficient, and private, data processing at the source\nfor simple tasks and lighter models, though they remain a challenge for larger,\nand more complicated models. In this paper, we present a hybrid approach for\nbreaking down large, complex deep neural networks for cooperative,\nprivacy-preserving analytics. To this end, instead of performing the whole\noperation on the cloud, we let an IoT device to run the initial layers of the\nneural network, and then send the output to the cloud to feed the remaining\nlayers and produce the final result. In order to ensure that the user's device\ncontains no extra information except what is necessary for the main task and\npreventing any secondary inference on the data, we introduce Siamese\nfine-tuning. We evaluate the privacy benefits of this approach based on the\ninformation exposed to the cloud service. We also assess the local inference\ncost of different layers on a modern handset. Our evaluations show that by\nusing Siamese fine-tuning and at a small processing cost, we can greatly reduce\nthe level of unnecessary, potentially sensitive information in the personal\ndata, and thus achieving the desired trade-off between utility, privacy, and\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 18:21:03 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 11:14:55 GMT"}, {"version": "v3", "created": "Mon, 3 Apr 2017 11:43:10 GMT"}, {"version": "v4", "created": "Tue, 4 Apr 2017 05:28:20 GMT"}, {"version": "v5", "created": "Wed, 18 Apr 2018 05:44:35 GMT"}, {"version": "v6", "created": "Wed, 8 May 2019 11:29:32 GMT"}, {"version": "v7", "created": "Fri, 27 Dec 2019 00:15:48 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Osia", "Seyed Ali", ""], ["Shamsabadi", "Ali Shahin", ""], ["Sajadmanesh", "Sina", ""], ["Taheri", "Ali", ""], ["Katevas", "Kleomenis", ""], ["Rabiee", "Hamid R.", ""], ["Lane", "Nicholas D.", ""], ["Haddadi", "Hamed", ""]]}, {"id": "1703.02965", "submitter": "Omer Dror", "authors": "Omer Dror, Boaz Nadler, Erhan Bilal and Yuval Kluger", "title": "Unsupervised Ensemble Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a regression problem where there is no labeled data and the only\nobservations are the predictions $f_i(x_j)$ of $m$ experts $f_{i}$ over many\nsamples $x_j$. With no knowledge on the accuracy of the experts, is it still\npossible to accurately estimate the unknown responses $y_{j}$? Can one still\ndetect the least or most accurate experts? In this work we propose a framework\nto study these questions, based on the assumption that the $m$ experts have\nuncorrelated deviations from the optimal predictor. Assuming the first two\nmoments of the response are known, we develop methods to detect the best and\nworst regressors, and derive U-PCR, a novel principal components approach for\nunsupervised ensemble regression. We provide theoretical support for U-PCR and\nillustrate its improved accuracy over the ensemble mean and median on a variety\nof regression problems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 18:58:20 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Dror", "Omer", ""], ["Nadler", "Boaz", ""], ["Bilal", "Erhan", ""], ["Kluger", "Yuval", ""]]}, {"id": "1703.02992", "submitter": "Stephen Giguere", "authors": "Stephen Giguere, Francisco Garcia, Sridhar Mahadevan", "title": "A Manifold Approach to Learning Mutually Orthogonal Subspaces", "comments": "9 pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although many machine learning algorithms involve learning subspaces with\nparticular characteristics, optimizing a parameter matrix that is constrained\nto represent a subspace can be challenging. One solution is to use Riemannian\noptimization methods that enforce such constraints implicitly, leveraging the\nfact that the feasible parameter values form a manifold. While Riemannian\nmethods exist for some specific problems, such as learning a single subspace,\nthere are more general subspace constraints that offer additional flexibility\nwhen setting up an optimization problem, but have not been formulated as a\nmanifold.\n  We propose the partitioned subspace (PS) manifold for optimizing matrices\nthat are constrained to represent one or more subspaces. Each point on the\nmanifold defines a partitioning of the input space into mutually orthogonal\nsubspaces, where the number of partitions and their sizes are defined by the\nuser. As a result, distinct groups of features can be learned by defining\ndifferent objective functions for each partition. We illustrate the properties\nof the manifold through experiments on multiple dataset analysis and domain\nadaptation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 19:08:28 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Giguere", "Stephen", ""], ["Garcia", "Francisco", ""], ["Mahadevan", "Sridhar", ""]]}, {"id": "1703.03020", "submitter": "Sarah Parisot", "authors": "Sarah Parisot, Sofia Ira Ktena, Enzo Ferrante, Matthew Lee, Ricardo\n  Guerrerro Moreno, Ben Glocker, Daniel Rueckert", "title": "Spectral Graph Convolutions for Population-based Disease Prediction", "comments": "International Conference on Medical Image Computing and\n  Computer-Assisted Interventions (MICCAI) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting the wealth of imaging and non-imaging information for disease\nprediction tasks requires models capable of representing, at the same time,\nindividual features as well as data associations between subjects from\npotentially large populations. Graphs provide a natural framework for such\ntasks, yet previous graph-based approaches focus on pairwise similarities\nwithout modelling the subjects' individual characteristics and features. On the\nother hand, relying solely on subject-specific imaging feature vectors fails to\nmodel the interaction and similarity between subjects, which can reduce\nperformance. In this paper, we introduce the novel concept of Graph\nConvolutional Networks (GCN) for brain analysis in populations, combining\nimaging and non-imaging data. We represent populations as a sparse graph where\nits vertices are associated with image-based feature vectors and the edges\nencode phenotypic information. This structure was used to train a GCN model on\npartially labelled graphs, aiming to infer the classes of unlabelled nodes from\nthe node features and pairwise associations between subjects. We demonstrate\nthe potential of the method on the challenging ADNI and ABIDE databases, as a\nproof of concept of the benefit from integrating contextual information in\nclassification tasks. This has a clear impact on the quality of the\npredictions, leading to 69.5% accuracy for ABIDE (outperforming the current\nstate of the art of 66.8%) and 77% for ADNI for prediction of MCI conversion,\nsignificantly outperforming standard linear classifiers where only individual\nfeatures are considered.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 20:07:28 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 11:09:10 GMT"}, {"version": "v3", "created": "Wed, 21 Jun 2017 17:24:40 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Parisot", "Sarah", ""], ["Ktena", "Sofia Ira", ""], ["Ferrante", "Enzo", ""], ["Lee", "Matthew", ""], ["Moreno", "Ricardo Guerrerro", ""], ["Glocker", "Ben", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1703.03038", "submitter": "Daniele Ramazzotti", "authors": "Daniele Ramazzotti and Marco S. Nobile and Paolo Cazzaniga and\n  Giancarlo Mauri and Marco Antoniotti", "title": "Parallel Implementation of Efficient Search Schemes for the Inference of\n  Cancer Progression Models", "comments": null, "journal-ref": null, "doi": "10.1109/CIBCB.2016.7758109", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence and development of cancer is a consequence of the accumulation\nover time of genomic mutations involving a specific set of genes, which\nprovides the cancer clones with a functional selective advantage. In this work,\nwe model the order of accumulation of such mutations during the progression,\nwhich eventually leads to the disease, by means of probabilistic graphic\nmodels, i.e., Bayesian Networks (BNs). We investigate how to perform the task\nof learning the structure of such BNs, according to experimental evidence,\nadopting a global optimization meta-heuristics. In particular, in this work we\nrely on Genetic Algorithms, and to strongly reduce the execution time of the\ninference -- which can also involve multiple repetitions to collect\nstatistically significant assessments of the data -- we distribute the\ncalculations using both multi-threading and a multi-node architecture. The\nresults show that our approach is characterized by good accuracy and\nspecificity; we also demonstrate its feasibility, thanks to a 84x reduction of\nthe overall execution time with respect to a traditional sequential\nimplementation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 21:29:52 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Ramazzotti", "Daniele", ""], ["Nobile", "Marco S.", ""], ["Cazzaniga", "Paolo", ""], ["Mauri", "Giancarlo", ""], ["Antoniotti", "Marco", ""]]}, {"id": "1703.03041", "submitter": "Daniele Ramazzotti", "authors": "Stefano Beretta and Mauro Castelli and Ivo Goncalves and Ivan Merelli\n  and Daniele Ramazzotti", "title": "Combining Bayesian Approaches and Evolutionary Techniques for the\n  Inference of Breast Cancer Networks", "comments": null, "journal-ref": null, "doi": "10.5220/0006064102170224", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene and protein networks are very important to model complex large-scale\nsystems in molecular biology. Inferring or reverseengineering such networks can\nbe defined as the process of identifying gene/protein interactions from\nexperimental data through computational analysis. However, this task is\ntypically complicated by the enormously large scale of the unknowns in a rather\nsmall sample size. Furthermore, when the goal is to study causal relationships\nwithin the network, tools capable of overcoming the limitations of correlation\nnetworks are required. In this work, we make use of Bayesian Graphical Models\nto attach this problem and, specifically, we perform a comparative study of\ndifferent state-of-the-art heuristics, analyzing their performance in inferring\nthe structure of the Bayesian Network from breast cancer data.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 21:36:01 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Beretta", "Stefano", ""], ["Castelli", "Mauro", ""], ["Goncalves", "Ivo", ""], ["Merelli", "Ivan", ""], ["Ramazzotti", "Daniele", ""]]}, {"id": "1703.03044", "submitter": "Maher Al-Shoukairi", "authors": "Maher Al-Shoukairi, Philip Schniter, Bhaskar D. Rao", "title": "A GAMP Based Low Complexity Sparse Bayesian Learning Algorithm", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2017.2764855", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an algorithm for the sparse signal recovery problem\nthat incorporates damped Gaussian generalized approximate message passing\n(GGAMP) into Expectation-Maximization (EM)-based sparse Bayesian learning\n(SBL). In particular, GGAMP is used to implement the E-step in SBL in place of\nmatrix inversion, leveraging the fact that GGAMP is guaranteed to converge with\nappropriate damping. The resulting GGAMP-SBL algorithm is much more robust to\narbitrary measurement matrix $\\boldsymbol{A}$ than the standard damped GAMP\nalgorithm while being much lower complexity than the standard SBL algorithm. We\nthen extend the approach from the single measurement vector (SMV) case to the\ntemporally correlated multiple measurement vector (MMV) case, leading to the\nGGAMP-TSBL algorithm. We verify the robustness and computational advantages of\nthe proposed algorithms through numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 21:44:12 GMT"}, {"version": "v2", "created": "Sun, 8 Oct 2017 00:14:27 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Al-Shoukairi", "Maher", ""], ["Schniter", "Philip", ""], ["Rao", "Bhaskar D.", ""]]}, {"id": "1703.03054", "submitter": "Xiaodan Liang", "authors": "Xiaodan Liang and Lisa Lee and Eric P. Xing", "title": "Deep Variation-structured Reinforcement Learning for Visual Relationship\n  and Attribute Detection", "comments": "This manuscript is accepted by CVPR 2017 as a spotlight paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite progress in visual perception tasks such as image classification and\ndetection, computers still struggle to understand the interdependency of\nobjects in the scene as a whole, e.g., relations between objects or their\nattributes. Existing methods often ignore global context cues capturing the\ninteractions among different object instances, and can only recognize a handful\nof types by exhaustively training individual detectors for all possible\nrelationships. To capture such global interdependency, we propose a deep\nVariation-structured Reinforcement Learning (VRL) framework to sequentially\ndiscover object relationships and attributes in the whole image. First, a\ndirected semantic action graph is built using language priors to provide a rich\nand compact representation of semantic correlations between object categories,\npredicates, and attributes. Next, we use a variation-structured traversal over\nthe action graph to construct a small, adaptive action set for each step based\non the current state and historical actions. In particular, an ambiguity-aware\nobject mining scheme is used to resolve semantic ambiguity among object\ncategories that the object detector fails to distinguish. We then make\nsequential predictions using a deep RL framework, incorporating global context\ncues and semantic embeddings of previously extracted phrases in the state\nvector. Our experiments on the Visual Relationship Detection (VRD) dataset and\nthe large-scale Visual Genome dataset validate the superiority of VRL, which\ncan achieve significantly better detection results on datasets involving\nthousands of relationship and attribute types. We also demonstrate that VRL is\nable to predict unseen types embedded in our action graph by learning\ncorrelations on shared graph nodes.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 22:09:10 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Liang", "Xiaodan", ""], ["Lee", "Lisa", ""], ["Xing", "Eric P.", ""]]}, {"id": "1703.03055", "submitter": "Xiaodan Liang", "authors": "Xiaodan Liang and Liang Lin and Xiaohui Shen and Jiashi Feng and\n  Shuicheng Yan and Eric P. Xing", "title": "Interpretable Structure-Evolving LSTM", "comments": "To appear in CVPR 2017 as a spotlight paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a general framework for learning interpretable data\nrepresentation via Long Short-Term Memory (LSTM) recurrent neural networks over\nhierarchal graph structures. Instead of learning LSTM models over the pre-fixed\nstructures, we propose to further learn the intermediate interpretable\nmulti-level graph structures in a progressive and stochastic way from data\nduring the LSTM network optimization. We thus call this model the\nstructure-evolving LSTM. In particular, starting with an initial element-level\ngraph representation where each node is a small data element, the\nstructure-evolving LSTM gradually evolves the multi-level graph representations\nby stochastically merging the graph nodes with high compatibilities along the\nstacked LSTM layers. In each LSTM layer, we estimate the compatibility of two\nconnected nodes from their corresponding LSTM gate outputs, which is used to\ngenerate a merging probability. The candidate graph structures are accordingly\ngenerated where the nodes are grouped into cliques with their merging\nprobabilities. We then produce the new graph structure with a\nMetropolis-Hasting algorithm, which alleviates the risk of getting stuck in\nlocal optimums by stochastic sampling with an acceptance probability. Once a\ngraph structure is accepted, a higher-level graph is then constructed by taking\nthe partitioned cliques as its nodes. During the evolving process,\nrepresentation becomes more abstracted in higher-levels where redundant\ninformation is filtered out, allowing more efficient propagation of long-range\ndata dependencies. We evaluate the effectiveness of structure-evolving LSTM in\nthe application of semantic object parsing and demonstrate its advantage over\nstate-of-the-art LSTM models on standard benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 22:09:38 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Liang", "Xiaodan", ""], ["Lin", "Liang", ""], ["Shen", "Xiaohui", ""], ["Feng", "Jiashi", ""], ["Yan", "Shuicheng", ""], ["Xing", "Eric P.", ""]]}, {"id": "1703.03073", "submitter": "Liangzhen Lai", "authors": "Liangzhen Lai, Naveen Suda, Vikas Chandra", "title": "Deep Convolutional Neural Network Inference with Floating-point Weights\n  and Fixed-point Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural network (CNN) inference requires significant amount\nof memory and computation, which limits its deployment on embedded devices. To\nalleviate these problems to some extent, prior research utilize low precision\nfixed-point numbers to represent the CNN weights and activations. However, the\nminimum required data precision of fixed-point weights varies across different\nnetworks and also across different layers of the same network. In this work, we\npropose using floating-point numbers for representing the weights and\nfixed-point numbers for representing the activations. We show that using\nfloating-point representation for weights is more efficient than fixed-point\nrepresentation for the same bit-width and demonstrate it on popular large-scale\nCNNs such as AlexNet, SqueezeNet, GoogLeNet and VGG-16. We also show that such\na representation scheme enables compact hardware multiply-and-accumulate (MAC)\nunit design. Experimental results show that the proposed scheme reduces the\nweight storage by up to 36% and power consumption of the hardware multiplier by\nup to 50%.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 23:49:20 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Lai", "Liangzhen", ""], ["Suda", "Naveen", ""], ["Chandra", "Vikas", ""]]}, {"id": "1703.03074", "submitter": "Daniele Ramazzotti", "authors": "Daniele Ramazzotti and Marco S. Nobile and Marco Antoniotti and Alex\n  Graudenzi", "title": "Efficient computational strategies to learn the structure of\n  probabilistic graphical models of cumulative phenomena", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural learning of Bayesian Networks (BNs) is a NP-hard problem, which is\nfurther complicated by many theoretical issues, such as the I-equivalence among\ndifferent structures. In this work, we focus on a specific subclass of BNs,\nnamed Suppes-Bayes Causal Networks (SBCNs), which include specific structural\nconstraints based on Suppes' probabilistic causation to efficiently model\ncumulative phenomena. Here we compare the performance, via extensive\nsimulations, of various state-of-the-art search strategies, such as local\nsearch techniques and Genetic Algorithms, as well as of distinct regularization\nmethods. The assessment is performed on a large number of simulated datasets\nfrom topologies with distinct levels of complexity, various sample size and\ndifferent rates of errors in the data. Among the main results, we show that the\nintroduction of Suppes' constraints dramatically improve the inference\naccuracy, by reducing the solution space and providing a temporal ordering on\nthe variables. We also report on trade-offs among different search techniques\nthat can be efficiently employed in distinct experimental settings. This\nmanuscript is an extended version of the paper \"Structural Learning of\nProbabilistic Graphical Models of Cumulative Phenomena\" presented at the 2018\nInternational Conference on Computational Science.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 23:50:19 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 16:08:37 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 02:41:30 GMT"}, {"version": "v4", "created": "Tue, 23 Oct 2018 17:43:54 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Ramazzotti", "Daniele", ""], ["Nobile", "Marco S.", ""], ["Antoniotti", "Marco", ""], ["Graudenzi", "Alex", ""]]}, {"id": "1703.03076", "submitter": "Daniele Ramazzotti", "authors": "Gelin Gao and Bud Mishra and Daniele Ramazzotti", "title": "Causal Data Science for Financial Stress Testing", "comments": null, "journal-ref": null, "doi": "10.1016/j.jocs.2018.04.003", "report-no": null, "categories": "cs.LG cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most recent financial upheavals have cast doubt on the adequacy of some\nof the conventional quantitative risk management strategies, such as VaR (Value\nat Risk), in many common situations. Consequently, there has been an increasing\nneed for verisimilar financial stress testings, namely simulating and analyzing\nfinancial portfolios in extreme, albeit rare scenarios. Unlike conventional\nrisk management which exploits statistical correlations among financial\ninstruments, here we focus our analysis on the notion of probabilistic\ncausation, which is embodied by Suppes-Bayes Causal Networks (SBCNs); SBCNs are\nprobabilistic graphical models that have many attractive features in terms of\nmore accurate causal analysis for generating financial stress scenarios. In\nthis paper, we present a novel approach for conducting stress testing of\nfinancial portfolios based on SBCNs in combination with classical machine\nlearning classification tools. The resulting method is shown to be capable of\ncorrectly discovering the causal relationships among financial factors that\naffect the portfolios and thus, simulating stress testing scenarios with a\nhigher accuracy and lower computational complexity than conventional Monte\nCarlo Simulations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 23:54:09 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 14:08:44 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Gao", "Gelin", ""], ["Mishra", "Bud", ""], ["Ramazzotti", "Daniele", ""]]}, {"id": "1703.03111", "submitter": "Eric Balkanski", "authors": "Eric Balkanski, Umar Syed, Sergei Vassilvitskii", "title": "Statistical Cost Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the cost sharing problem for cooperative games in situations where\nthe cost function $C$ is not available via oracle queries, but must instead be\nderived from data, represented as tuples $(S, C(S))$, for different subsets $S$\nof players. We formalize this approach, which we call statistical cost sharing,\nand consider the computation of the core and the Shapley value, when the tuples\nare drawn from some distribution $\\mathcal{D}$.\n  Previous work by Balcan et al. in this setting showed how to compute cost\nshares that satisfy the core property with high probability for limited classes\nof functions. We expand on their work and give an algorithm that computes such\ncost shares for any function with a non-empty core. We complement these results\nby proving an inapproximability lower bound for a weaker relaxation.\n  We then turn our attention to the Shapley value. We first show that when cost\nfunctions come from the family of submodular functions with bounded curvature,\n$\\kappa$, the Shapley value can be approximated from samples up to a $\\sqrt{1 -\n\\kappa}$ factor, and that the bound is tight. We then define statistical\nanalogues of the Shapley axioms, and derive a notion of statistical Shapley\nvalue. We show that these can always be approximated arbitrarily well for\ngeneral functions over any distribution $\\mathcal{D}$.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 02:50:49 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Balkanski", "Eric", ""], ["Syed", "Umar", ""], ["Vassilvitskii", "Sergei", ""]]}, {"id": "1703.03121", "submitter": "Hoang M. Le", "authors": "Hoang M. Le, Yisong Yue, Peter Carr, Patrick Lucey", "title": "Coordinated Multi-Agent Imitation Learning", "comments": "International Conference on Machine Learning 2017", "journal-ref": "Hoang M. Le, Yisong Yue, Peter Carr, Patrick Lucey ; Proceedings\n  of the 34th International Conference on Machine Learning, PMLR 70:1995-2003,\n  2017", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of imitation learning from demonstrations of multiple\ncoordinating agents. One key challenge in this setting is that learning a good\nmodel of coordination can be difficult, since coordination is often implicit in\nthe demonstrations and must be inferred as a latent variable. We propose a\njoint approach that simultaneously learns a latent coordination model along\nwith the individual policies. In particular, our method integrates unsupervised\nstructure learning with conventional imitation learning. We illustrate the\npower of our approach on a difficult problem of learning multiple policies for\nfine-grained behavior modeling in team sports, where different players occupy\ndifferent roles in the coordinated team strategy. We show that having a\ncoordination model to infer the roles of players yields substantially improved\nimitation loss compared to conventional baselines.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 03:45:42 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 05:07:40 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Le", "Hoang M.", ""], ["Yue", "Yisong", ""], ["Carr", "Peter", ""], ["Lucey", "Patrick", ""]]}, {"id": "1703.03129", "submitter": "{\\L}ukasz Kaiser", "authors": "{\\L}ukasz Kaiser and Ofir Nachum and Aurko Roy and Samy Bengio", "title": "Learning to Remember Rare Events", "comments": "Conference paper accepted for ICLR'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances, memory-augmented deep neural networks are still\nlimited when it comes to life-long and one-shot learning, especially in\nremembering rare events. We present a large-scale life-long memory module for\nuse in deep learning. The module exploits fast nearest-neighbor algorithms for\nefficiency and thus scales to large memory sizes. Except for the\nnearest-neighbor query, the module is fully differentiable and trained\nend-to-end with no extra supervision. It operates in a life-long manner, i.e.,\nwithout the need to reset it during training.\n  Our memory module can be easily added to any part of a supervised neural\nnetwork. To show its versatility we add it to a number of networks, from simple\nconvolutional ones tested on image classification to deep sequence-to-sequence\nand recurrent-convolutional models. In all cases, the enhanced network gains\nthe ability to remember and do life-long one-shot learning. Our module\nremembers training examples shown many thousands of steps in the past and it\ncan successfully generalize from them. We set new state-of-the-art for one-shot\nlearning on the Omniglot dataset and demonstrate, for the first time, life-long\none-shot learning in recurrent neural networks on a large-scale machine\ntranslation task.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 04:36:15 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Kaiser", "\u0141ukasz", ""], ["Nachum", "Ofir", ""], ["Roy", "Aurko", ""], ["Bengio", "Samy", ""]]}, {"id": "1703.03130", "submitter": "Zhouhan Lin", "authors": "Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing\n  Xiang, Bowen Zhou, Yoshua Bengio", "title": "A Structured Self-attentive Sentence Embedding", "comments": "15 pages with appendix, 7 figures, 4 tables. Conference paper in 5th\n  International Conference on Learning Representations (ICLR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new model for extracting an interpretable sentence\nembedding by introducing self-attention. Instead of using a vector, we use a\n2-D matrix to represent the embedding, with each row of the matrix attending on\na different part of the sentence. We also propose a self-attention mechanism\nand a special regularization term for the model. As a side effect, the\nembedding comes with an easy way of visualizing what specific parts of the\nsentence are encoded into the embedding. We evaluate our model on 3 different\ntasks: author profiling, sentiment classification, and textual entailment.\nResults show that our model yields a significant performance gain compared to\nother sentence embedding methods in all of the 3 tasks.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 04:42:30 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Lin", "Zhouhan", ""], ["Feng", "Minwei", ""], ["Santos", "Cicero Nogueira dos", ""], ["Yu", "Mo", ""], ["Xiang", "Bing", ""], ["Zhou", "Bowen", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.03208", "submitter": "Ashish Bora", "authors": "Ashish Bora, Ajil Jalal, Eric Price, Alexandros G. Dimakis", "title": "Compressed Sensing using Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of compressed sensing is to estimate a vector from an\nunderdetermined system of noisy linear measurements, by making use of prior\nknowledge on the structure of vectors in the relevant domain. For almost all\nresults in this literature, the structure is represented by sparsity in a\nwell-chosen basis. We show how to achieve guarantees similar to standard\ncompressed sensing but without employing sparsity at all. Instead, we suppose\nthat vectors lie near the range of a generative model $G: \\mathbb{R}^k \\to\n\\mathbb{R}^n$. Our main theorem is that, if $G$ is $L$-Lipschitz, then roughly\n$O(k \\log L)$ random Gaussian measurements suffice for an $\\ell_2/\\ell_2$\nrecovery guarantee. We demonstrate our results using generative models from\npublished variational autoencoder and generative adversarial networks. Our\nmethod can use $5$-$10$x fewer measurements than Lasso for the same accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 10:11:03 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Bora", "Ashish", ""], ["Jalal", "Ajil", ""], ["Price", "Eric", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1703.03365", "submitter": "Ksenia Konyushkova", "authors": "Ksenia Konyushkova, Raphael Sznitman and Pascal Fua", "title": "Learning Active Learning from Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we suggest a novel data-driven approach to active learning\n(AL). The key idea is to train a regressor that predicts the expected error\nreduction for a candidate sample in a particular learning state. By formulating\nthe query selection procedure as a regression problem we are not restricted to\nworking with existing AL heuristics; instead, we learn strategies based on\nexperience from previous AL outcomes. We show that a strategy can be learnt\neither from simple synthetic 2D datasets or from a subset of domain-specific\ndata. Our method yields strategies that work well on real data from a wide\nrange of domains.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 17:36:52 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 07:33:28 GMT"}, {"version": "v3", "created": "Fri, 14 Jul 2017 12:59:12 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Konyushkova", "Ksenia", ""], ["Sznitman", "Raphael", ""], ["Fua", "Pascal", ""]]}, {"id": "1703.03385", "submitter": "Matthias Zeppelzauer", "authors": "J\\\"urgen Bernard and Christian Ritter and David Sessler and Matthias\n  Zeppelzauer and J\\\"orn Kohlhammer and Dieter Fellner", "title": "Visual-Interactive Similarity Search for Complex Objects by Example of\n  Soccer Player Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The definition of similarity is a key prerequisite when analyzing complex\ndata types in data mining, information retrieval, or machine learning. However,\nthe meaningful definition is often hampered by the complexity of data objects\nand particularly by different notions of subjective similarity latent in\ntargeted user groups. Taking the example of soccer players, we present a\nvisual-interactive system that learns users' mental models of similarity. In a\nvisual-interactive interface, users are able to label pairs of soccer players\nwith respect to their subjective notion of similarity. Our proposed similarity\nmodel automatically learns the respective concept of similarity using an active\nlearning strategy. A visual-interactive retrieval technique is provided to\nvalidate the model and to execute downstream retrieval tasks for soccer player\nanalysis. The applicability of the approach is demonstrated in different\nevaluation strategies, including usage scenarions and cross-validation tests.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 18:37:00 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Bernard", "J\u00fcrgen", ""], ["Ritter", "Christian", ""], ["Sessler", "David", ""], ["Zeppelzauer", "Matthias", ""], ["Kohlhammer", "J\u00f6rn", ""], ["Fellner", "Dieter", ""]]}, {"id": "1703.03389", "submitter": "Insu Han", "authors": "Insu Han, Prabhanjan Kambadur, Kyoungsoo Park, Jinwoo Shin", "title": "Faster Greedy MAP Inference for Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) are popular probabilistic models that\narise in many machine learning tasks, where distributions of diverse sets are\ncharacterized by matrix determinants. In this paper, we develop fast algorithms\nto find the most likely configuration (MAP) of large-scale DPPs, which is\nNP-hard in general. Due to the submodular nature of the MAP objective, greedy\nalgorithms have been used with empirical success. Greedy implementations\nrequire computation of log-determinants, matrix inverses or solving linear\nsystems at each iteration. We present faster implementations of the greedy\nalgorithms by utilizing the complementary benefits of two log-determinant\napproximation schemes: (a) first-order expansions to the matrix log-determinant\nfunction and (b) high-order expansions to the scalar log function with\nstochastic trace estimators. In our experiments, our algorithms are orders of\nmagnitude faster than their competitors, while sacrificing marginal accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 18:43:11 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 02:48:18 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Han", "Insu", ""], ["Kambadur", "Prabhanjan", ""], ["Park", "Kyoungsoo", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1703.03400", "submitter": "Chelsea Finn", "authors": "Chelsea Finn, Pieter Abbeel, Sergey Levine", "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks", "comments": "ICML 2017. Code at https://github.com/cbfinn/maml, Videos of RL\n  results at https://sites.google.com/view/maml, Blog post at\n  http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for meta-learning that is model-agnostic, in the\nsense that it is compatible with any model trained with gradient descent and\napplicable to a variety of different learning problems, including\nclassification, regression, and reinforcement learning. The goal of\nmeta-learning is to train a model on a variety of learning tasks, such that it\ncan solve new learning tasks using only a small number of training samples. In\nour approach, the parameters of the model are explicitly trained such that a\nsmall number of gradient steps with a small amount of training data from a new\ntask will produce good generalization performance on that task. In effect, our\nmethod trains the model to be easy to fine-tune. We demonstrate that this\napproach leads to state-of-the-art performance on two few-shot image\nclassification benchmarks, produces good results on few-shot regression, and\naccelerates fine-tuning for policy gradient reinforcement learning with neural\nnetwork policies.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 18:58:03 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 17:14:08 GMT"}, {"version": "v3", "created": "Tue, 18 Jul 2017 16:45:29 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Finn", "Chelsea", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1703.03454", "submitter": "Zhaohan Guo", "authors": "Zhaohan Daniel Guo, Emma Brunskill", "title": "Sample Efficient Feature Selection for Factored MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, the state of the real world is often represented\nby feature vectors. However, not all of the features may be pertinent for\nsolving the current task. We propose Feature Selection Explore and Exploit\n(FS-EE), an algorithm that automatically selects the necessary features while\nlearning a Factored Markov Decision Process, and prove that under mild\nassumptions, its sample complexity scales with the in-degree of the dynamics of\njust the necessary features, rather than the in-degree of all features. This\ncan result in a much better sample complexity when the in-degree of the\nnecessary features is smaller than the in-degree of all features.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 20:22:27 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Guo", "Zhaohan Daniel", ""], ["Brunskill", "Emma", ""]]}, {"id": "1703.03470", "submitter": "Brendan McCane", "authors": "Brendan McCane and Lech Szymanski", "title": "Deep Radial Kernel Networks: Approximating Radially Symmetric Functions\n  with Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that a particular deep network architecture is more efficient at\napproximating radially symmetric functions than the best known 2 or 3 layer\nnetworks. We use this architecture to approximate Gaussian kernel SVMs, and\nsubsequently improve upon them with further training. The architecture and\ninitial weights of the Deep Radial Kernel Network are completely specified by\nthe SVM and therefore sidesteps the problem of empirically choosing an\nappropriate deep network architecture.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 21:26:51 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["McCane", "Brendan", ""], ["Szymanski", "Lech", ""]]}, {"id": "1703.03478", "submitter": "Giulia DeSalvo", "authors": "Corinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri, Scott\n  Yang", "title": "Online Learning with Abstention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extensive study of the key problem of online learning where\nalgorithms are allowed to abstain from making predictions. In the adversarial\nsetting, we show how existing online algorithms and guarantees can be adapted\nto this problem. In the stochastic setting, we first point out a bias problem\nthat limits the straightforward extension of algorithms such as UCB-N to\ntime-varying feedback graphs, as needed in this context. Next, we give a new\nalgorithm, UCB-GT, that exploits historical data and is adapted to time-varying\nfeedback graphs. We show that this algorithm benefits from more favorable\nregret guarantees than a possible, but limited, extension of UCB-N. We further\nreport the results of a series of experiments demonstrating that UCB-GT largely\noutperforms that extension of UCB-N, as well as more standard baselines.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 22:17:40 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 23:45:39 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 17:07:35 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Cortes", "Corinna", ""], ["DeSalvo", "Giulia", ""], ["Gentile", "Claudio", ""], ["Mohri", "Mehryar", ""], ["Yang", "Scott", ""]]}, {"id": "1703.03633", "submitter": "Kaifeng Lv", "authors": "Kaifeng Lv, Shunhua Jiang, Jian Li", "title": "Learning Gradient Descent: Better Generalization and Longer Horizons", "comments": "Accepted to ICML 2017, 9 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks is a highly nontrivial task, involving\ncarefully selecting appropriate training algorithms, scheduling step sizes and\ntuning other hyperparameters. Trying different combinations can be quite\nlabor-intensive and time consuming. Recently, researchers have tried to use\ndeep learning algorithms to exploit the landscape of the loss function of the\ntraining problem of interest, and learn how to optimize over it in an automatic\nway. In this paper, we propose a new learning-to-learn model and some useful\nand practical tricks. Our optimizer outperforms generic, hand-crafted\noptimization algorithms and state-of-the-art learning-to-learn optimizers by\nDeepMind in many tasks. We demonstrate the effectiveness of our algorithms on a\nnumber of tasks, including deep MLPs, CNNs, and simple LSTMs.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 11:30:03 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 02:45:49 GMT"}, {"version": "v3", "created": "Sat, 10 Jun 2017 16:25:37 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Lv", "Kaifeng", ""], ["Jiang", "Shunhua", ""], ["Li", "Jian", ""]]}, {"id": "1703.03717", "submitter": "Andrew Ross", "authors": "Andrew Slavin Ross, Michael C. Hughes, Finale Doshi-Velez", "title": "Right for the Right Reasons: Training Differentiable Models by\n  Constraining their Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are among the most accurate supervised learning methods in\nuse today, but their opacity makes them difficult to trust in critical\napplications, especially when conditions in training differ from those in test.\nRecent work on explanations for black-box models has produced tools (e.g. LIME)\nto show the implicit rules behind predictions, which can help us identify when\nmodels are right for the wrong reasons. However, these methods do not scale to\nexplaining entire datasets and cannot correct the problems they reveal. We\nintroduce a method for efficiently explaining and regularizing differentiable\nmodels by examining and selectively penalizing their input gradients, which\nprovide a normal to the decision boundary. We apply these penalties both based\non expert annotation and in an unsupervised fashion that encourages diverse\nmodels with qualitatively different decision boundaries for the same\nclassification problem. On multiple datasets, we show our approach generates\nfaithful explanations and models that generalize much better when conditions\ndiffer between training and test.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 15:35:32 GMT"}, {"version": "v2", "created": "Thu, 25 May 2017 05:38:45 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Ross", "Andrew Slavin", ""], ["Hughes", "Michael C.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1703.03859", "submitter": "Guilherme Fran\\c{c}a", "authors": "Guilherme Fran\\c{c}a, Jos\\'e Bento", "title": "Markov Chain Lifting and Distributed ADMM", "comments": "This work was also selected for a talk at NIPS 2016, Optimization for\n  Machine Learning Workshop (OPT 2016)", "journal-ref": "IEEE Signal Processing Letters (Volume: 24, Issue: 3, March 2017)", "doi": "10.1109/LSP.2017.2654860", "report-no": null, "categories": "stat.ML cs.DS cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The time to converge to the steady state of a finite Markov chain can be\ngreatly reduced by a lifting operation, which creates a new Markov chain on an\nexpanded state space. For a class of quadratic objectives, we show an analogous\nbehavior where a distributed ADMM algorithm can be seen as a lifting of\nGradient Descent algorithm. This provides a deep insight for its faster\nconvergence rate under optimal parameter tuning. We conjecture that this gain\nis always present, as opposed to the lifting of a Markov chain which sometimes\nonly provides a marginal speedup.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 22:25:56 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Fran\u00e7a", "Guilherme", ""], ["Bento", "Jos\u00e9", ""]]}, {"id": "1703.03862", "submitter": "Jesus Daniel Arroyo Reli\\'on", "authors": "Shangsi Wang, Jes\\'us Arroyo, Joshua T. Vogelstein, Carey E. Priebe", "title": "Joint Embedding of Graphs", "comments": null, "journal-ref": null, "doi": "10.1109/TPAMI.2019.2948619", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction and dimension reduction for networks is critical in a wide\nvariety of domains. Efficiently and accurately learning features for multiple\ngraphs has important applications in statistical inference on graphs. We\npropose a method to jointly embed multiple undirected graphs. Given a set of\ngraphs, the joint embedding method identifies a linear subspace spanned by rank\none symmetric matrices and projects adjacency matrices of graphs into this\nsubspace. The projection coefficients can be treated as features of the graphs,\nwhile the embedding components can represent vertex features. We also propose a\nrandom graph model for multiple graphs that generalizes other classical models\nfor graphs. We show through theory and numerical experiments that under the\nmodel, the joint embedding method produces estimates of parameters with small\nerrors. Via simulation experiments, we demonstrate that the joint embedding\nmethod produces features which lead to state of the art performance in\nclassifying graphs. Applying the joint embedding method to human brain graphs,\nwe find it extracts interpretable features with good prediction accuracy in\ndifferent tasks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 22:46:09 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 01:19:23 GMT"}, {"version": "v3", "created": "Fri, 7 Dec 2018 03:58:47 GMT"}, {"version": "v4", "created": "Thu, 17 Oct 2019 16:15:53 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Wang", "Shangsi", ""], ["Arroyo", "Jes\u00fas", ""], ["Vogelstein", "Joshua T.", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1703.03864", "submitter": "Tim Salimans", "authors": "Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, Ilya Sutskever", "title": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of Evolution Strategies (ES), a class of black box\noptimization algorithms, as an alternative to popular MDP-based RL techniques\nsuch as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show\nthat ES is a viable solution strategy that scales extremely well with the\nnumber of CPUs available: By using a novel communication strategy based on\ncommon random numbers, our ES implementation only needs to communicate scalars,\nmaking it possible to scale to over a thousand parallel workers. This allows us\nto solve 3D humanoid walking in 10 minutes and obtain competitive results on\nmost Atari games after one hour of training. In addition, we highlight several\nadvantages of ES as a black box optimization technique: it is invariant to\naction frequency and delayed rewards, tolerant of extremely long horizons, and\ndoes not need temporal discounting or value function approximation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 23:02:19 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 23:28:48 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Salimans", "Tim", ""], ["Ho", "Jonathan", ""], ["Chen", "Xi", ""], ["Sidor", "Szymon", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1703.03869", "submitter": "Thomson Nguyen", "authors": "Philip Spanoudes, Thomson Nguyen", "title": "Deep Learning in Customer Churn Prediction: Unsupervised Feature\n  Learning on Abstract Company Independent Feature Vectors", "comments": "23 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As companies increase their efforts in retaining customers, being able to\npredict accurately ahead of time, whether a customer will churn in the\nforeseeable future is an extremely powerful tool for any marketing team. The\npaper describes in depth the application of Deep Learning in the problem of\nchurn prediction. Using abstract feature vectors, that can generated on any\nsubscription based company's user event logs, the paper proves that through the\nuse of the intrinsic property of Deep Neural Networks (learning secondary\nfeatures in an unsupervised manner), the complete pipeline can be applied to\nany subscription based company with extremely good churn predictive\nperformance. Furthermore the research documented in the paper was performed for\nFramed Data (a company that sells churn prediction as a service for other\ncompanies) in conjunction with the Data Science Institute at Lancaster\nUniversity, UK. This paper is the intellectual property of Framed Data.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 23:26:33 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Spanoudes", "Philip", ""], ["Nguyen", "Thomson", ""]]}, {"id": "1703.03924", "submitter": "Robert Nishihara", "authors": "Robert Nishihara, Philipp Moritz, Stephanie Wang, Alexey Tumanov,\n  William Paul, Johann Schleier-Smith, Richard Liaw, Mehrdad Niknami, Michael\n  I. Jordan, Ion Stoica", "title": "Real-Time Machine Learning: The Missing Pieces", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applications are increasingly deployed not only to serve\npredictions using static models, but also as tightly-integrated components of\nfeedback loops involving dynamic, real-time decision making. These applications\npose a new set of requirements, none of which are difficult to achieve in\nisolation, but the combination of which creates a challenge for existing\ndistributed execution frameworks: computation with millisecond latency at high\nthroughput, adaptive construction of arbitrary task graphs, and execution of\nheterogeneous kernels over diverse sets of resources. We assert that a new\ndistributed execution framework is needed for such ML applications and propose\na candidate approach with a proof-of-concept architecture that achieves a 63x\nperformance improvement over a state-of-the-art execution framework for a\nrepresentative application.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 07:46:51 GMT"}, {"version": "v2", "created": "Fri, 19 May 2017 22:52:32 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Nishihara", "Robert", ""], ["Moritz", "Philipp", ""], ["Wang", "Stephanie", ""], ["Tumanov", "Alexey", ""], ["Paul", "William", ""], ["Schleier-Smith", "Johann", ""], ["Liaw", "Richard", ""], ["Niknami", "Mehrdad", ""], ["Jordan", "Michael I.", ""], ["Stoica", "Ion", ""]]}, {"id": "1703.03928", "submitter": "Paolo Missier", "authors": "Paolo Missier and Callum McClean and Jonathan Carlton and Diego Cedrim\n  and Leonardo Silva and Alessandro Garcia and Alexandre Plastino and Alexander\n  Romanovsky", "title": "Recruiting from the network: discovering Twitter users who can help\n  combat Zika epidemics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tropical diseases like \\textit{Chikungunya} and \\textit{Zika} have come to\nprominence in recent years as the cause of serious, long-lasting,\npopulation-wide health problems. In large countries like Brasil, traditional\ndisease prevention programs led by health authorities have not been\nparticularly effective. We explore the hypothesis that monitoring and analysis\nof social media content streams may effectively complement such efforts.\nSpecifically, we aim to identify selected members of the public who are likely\nto be sensitive to virus combat initiatives that are organised in local\ncommunities. Focusing on Twitter and on the topic of Zika, our approach\ninvolves (i) training a classifier to select topic-relevant tweets from the\nTwitter feed, and (ii) discovering the top users who are actively posting\nrelevant content about the topic. We may then recommend these users as the\nprime candidates for direct engagement within their community. In this short\npaper we describe our analytical approach and prototype architecture, discuss\nthe challenges of dealing with noisy and sparse signal, and present encouraging\npreliminary results.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 07:55:45 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Missier", "Paolo", ""], ["McClean", "Callum", ""], ["Carlton", "Jonathan", ""], ["Cedrim", "Diego", ""], ["Silva", "Leonardo", ""], ["Garcia", "Alessandro", ""], ["Plastino", "Alexandre", ""], ["Romanovsky", "Alexander", ""]]}, {"id": "1703.03939", "submitter": "Govardana Sachithanandam Ramachandran", "authors": "Govardana Sachithanandam Ramachandran, Ajay Sohmshetty", "title": "Ask Me Even More: Dynamic Memory Tensor Networks (Extended Model)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine Memory Networks for the task of question answering (QA), under\ncommon real world scenario where training examples are scarce and under weakly\nsupervised scenario, that is only extrinsic labels are available for training.\nWe propose extensions for the Dynamic Memory Network (DMN), specifically within\nthe attention mechanism, we call the resulting Neural Architecture as Dynamic\nMemory Tensor Network (DMTN). Ultimately, we see that our proposed extensions\nresults in over 80% improvement in the number of task passed against the\nbaselined standard DMN and 20% more task passed compared to state-of-the-art\nEnd-to-End Memory Network for Facebook's single task weakly trained 1K bAbi\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 10:05:19 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Ramachandran", "Govardana Sachithanandam", ""], ["Sohmshetty", "Ajay", ""]]}, {"id": "1703.04025", "submitter": "Bryon Aragam", "authors": "Bryon Aragam, Jiaying Gu, Qing Zhou", "title": "Learning Large-Scale Bayesian Networks with the sparsebn Package", "comments": "To appear in the Journal of Statistical Software, 39 pages, 7 figures", "journal-ref": "Journal of Statistical Software, 91(11), 1-38, 2019", "doi": "10.18637/jss.v091.i11", "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning graphical models from data is an important problem with wide\napplications, ranging from genomics to the social sciences. Nowadays datasets\noften have upwards of thousands---sometimes tens or hundreds of thousands---of\nvariables and far fewer samples. To meet this challenge, we have developed a\nnew R package called sparsebn for learning the structure of large, sparse\ngraphical models with a focus on Bayesian networks. While there are many\nexisting software packages for this task, this package focuses on the unique\nsetting of learning large networks from high-dimensional data, possibly with\ninterventions. As such, the methods provided place a premium on scalability and\nconsistency in a high-dimensional setting. Furthermore, in the presence of\ninterventions, the methods implemented here achieve the goal of learning a\ncausal network from data. Additionally, the sparsebn package is fully\ncompatible with existing software packages for network analysis.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 20:07:06 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 23:22:10 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Aragam", "Bryon", ""], ["Gu", "Jiaying", ""], ["Zhou", "Qing", ""]]}, {"id": "1703.04070", "submitter": "Nikhil Mishra", "authors": "Nikhil Mishra, Pieter Abbeel, Igor Mordatch", "title": "Prediction and Control with Temporal Segment Models", "comments": "camera-ready version, ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for learning the dynamics of complex nonlinear systems\nbased on deep generative models over temporal segments of states and actions.\nUnlike dynamics models that operate over individual discrete timesteps, we\nlearn the distribution over future state trajectories conditioned on past\nstate, past action, and planned future action trajectories, as well as a latent\nprior over action trajectories. Our approach is based on convolutional\nautoregressive models and variational autoencoders. It makes stable and\naccurate predictions over long horizons for complex, stochastic systems,\neffectively expressing uncertainty and modeling the effects of collisions,\nsensory noise, and action delays. The learned dynamics model and action prior\ncan be used for end-to-end, fully differentiable trajectory optimization and\nmodel-based policy optimization, which we use to evaluate the performance and\nsample-efficiency of our method.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 04:59:15 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 04:54:00 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Mishra", "Nikhil", ""], ["Abbeel", "Pieter", ""], ["Mordatch", "Igor", ""]]}, {"id": "1703.04082", "submitter": "Sejun Park", "authors": "Sejun Park, Eunho Yang, Jinwoo Shin", "title": "Sequential Local Learning for Latent Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning parameters of latent graphical models (GM) is inherently much harder\nthan that of no-latent ones since the latent variables make the corresponding\nlog-likelihood non-concave. Nevertheless, expectation-maximization schemes are\npopularly used in practice, but they are typically stuck in local optima. In\nthe recent years, the method of moments have provided a refreshing angle for\nresolving the non-convex issue, but it is applicable to a quite limited class\nof latent GMs. In this paper, we aim for enhancing its power via enlarging such\na class of latent GMs. To this end, we introduce two novel concepts, coined\nmarginalization and conditioning, which can reduce the problem of learning a\nlarger GM to that of a smaller one. More importantly, they lead to a sequential\nlearning framework that repeatedly increases the learning portion of given\nlatent GM, and thus covers a significantly broader and more complicated class\nof loopy latent GMs which include convolutional and random regular models.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 08:18:11 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 02:38:19 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Park", "Sejun", ""], ["Yang", "Eunho", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1703.04122", "submitter": "Miko{\\l}aj Bi\\'nkowski", "authors": "Miko{\\l}aj Bi\\'nkowski, Gautier Marti, Philippe Donnat", "title": "Autoregressive Convolutional Neural Networks for Asynchronous Time\n  Series", "comments": "Proceedings of The 35th International Conference on Machine Learning\n  (ICML), Stockholm, Sweden, 2018, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Significance-Offset Convolutional Neural Network, a deep\nconvolutional network architecture for regression of multivariate asynchronous\ntime series. The model is inspired by standard autoregressive (AR) models and\ngating mechanisms used in recurrent neural networks. It involves an AR-like\nweighting system, where the final predictor is obtained as a weighted sum of\nadjusted regressors, while the weights are datadependent functions learnt\nthrough a convolutional network. The architecture was designed for applications\non asynchronous time series and is evaluated on such datasets: a hedge fund\nproprietary dataset of over 2 million quotes for a credit derivative index, an\nartificially generated noisy autoregressive series and UCI household\nelectricity consumption dataset. The proposed architecture achieves promising\nresults as compared to convolutional and recurrent neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 14:03:19 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 13:09:21 GMT"}, {"version": "v3", "created": "Sat, 24 Feb 2018 16:29:19 GMT"}, {"version": "v4", "created": "Tue, 12 Jun 2018 12:46:19 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Bi\u0144kowski", "Miko\u0142aj", ""], ["Marti", "Gautier", ""], ["Donnat", "Philippe", ""]]}, {"id": "1703.04140", "submitter": "J\\\"orn-Henrik Jacobsen", "authors": "J\\\"orn-Henrik Jacobsen, Edouard Oyallon, St\\'ephane Mallat, Arnold\n  W.M. Smeulders", "title": "Multiscale Hierarchical Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network algorithms are difficult to analyze because they lack\nstructure allowing to understand the properties of underlying transforms and\ninvariants. Multiscale hierarchical convolutional networks are structured deep\nconvolutional networks where layers are indexed by progressively higher\ndimensional attributes, which are learned from training data. Each new layer is\ncomputed with multidimensional convolutions along spatial and attribute\nvariables. We introduce an efficient implementation of such networks where the\ndimensionality is progressively reduced by averaging intermediate layers along\nattribute indices. Hierarchical networks are tested on CIFAR image data bases\nwhere they obtain comparable precisions to state of the art networks, with much\nfewer parameters. We study some properties of the attributes learned from these\ndatabases.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 16:29:44 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Jacobsen", "J\u00f6rn-Henrik", ""], ["Oyallon", "Edouard", ""], ["Mallat", "St\u00e9phane", ""], ["Smeulders", "Arnold W. M.", ""]]}, {"id": "1703.04170", "submitter": "Wentao Zhu", "authors": "Qing Han, Wentao Zhu and Yang Shi", "title": "Leak Event Identification in Water Systems Using High Order CRF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, detection of anomalous events in civil infrastructures (e.g. water\npipe breaks and leaks) is time consuming and often takes hours or days. Pipe\nbreakage as one of the most frequent types of failure of water networks often\ncauses community disruptions ranging from temporary interruptions in services\nto extended loss of business and relocation of residents. In this project, we\ndesign and implement a two-phase approach for leak event identification, which\nleverages dynamic data from multiple information sources including IoT sensing\ndata (pressure values and/or flow rates), geophysical data (water systems), and\nhuman inputs (tweets posted on Twitter). In the approach, a high order\nConditional Random Field (CRF) is constructed that enforces predictions based\non IoT observations consistent with human inputs to improve the performance of\nevent identifications.\n  Considering the physical water network as a graph, a CRF model is built and\nlearned by the Structured Support Vector Machine (SSVM) using node features\nsuch as water pressure and flow rate. After that, we built the high order CRF\nsystem by enforcing twitter leakage detection information. An optimal inference\nalgorithm is proposed for the adapted high order CRF model. Experimental\nresults show the effectiveness of our system.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 20:30:56 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Han", "Qing", ""], ["Zhu", "Wentao", ""], ["Shi", "Yang", ""]]}, {"id": "1703.04200", "submitter": "Ben Poole", "authors": "Friedemann Zenke, Ben Poole, Surya Ganguli", "title": "Continual Learning Through Synaptic Intelligence", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has led to remarkable advances across diverse\napplications, it struggles in domains where the data distribution changes over\nthe course of learning. In stark contrast, biological neural networks\ncontinually adapt to changing domains, possibly by leveraging complex molecular\nmachinery to solve many tasks simultaneously. In this study, we introduce\nintelligent synapses that bring some of this biological complexity into\nartificial neural networks. Each synapse accumulates task relevant information\nover time, and exploits this information to rapidly store new memories without\nforgetting old ones. We evaluate our approach on continual learning of\nclassification tasks, and show that it dramatically reduces forgetting while\nmaintaining computational efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 00:02:48 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 17:54:57 GMT"}, {"version": "v3", "created": "Mon, 12 Jun 2017 19:57:42 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Zenke", "Friedemann", ""], ["Poole", "Ben", ""], ["Ganguli", "Surya", ""]]}, {"id": "1703.04219", "submitter": "Ioakeim Perros", "authors": "Ioakeim Perros and Evangelos E. Papalexakis and Fei Wang and Richard\n  Vuduc and Elizabeth Searles and Michael Thompson and Jimeng Sun", "title": "SPARTan: Scalable PARAFAC2 for Large & Sparse Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In exploratory tensor mining, a common problem is how to analyze a set of\nvariables across a set of subjects whose observations do not align naturally.\nFor example, when modeling medical features across a set of patients, the\nnumber and duration of treatments may vary widely in time, meaning there is no\nmeaningful way to align their clinical records across time points for analysis\npurposes. To handle such data, the state-of-the-art tensor model is the\nso-called PARAFAC2, which yields interpretable and robust output and can\nnaturally handle sparse data. However, its main limitation up to now has been\nthe lack of efficient algorithms that can handle large-scale datasets.\n  In this work, we fill this gap by developing a scalable method to compute the\nPARAFAC2 decomposition of large and sparse datasets, called SPARTan. Our method\nexploits special structure within PARAFAC2, leading to a novel algorithmic\nreformulation that is both fast (in absolute time) and more memory-efficient\nthan prior work. We evaluate SPARTan on both synthetic and real datasets,\nshowing 22X performance gains over the best previous implementation and also\nhandling larger problem instances for which the baseline fails. Furthermore, we\nare able to apply SPARTan to the mining of temporally-evolving phenotypes on\ndata taken from real and medically complex pediatric patients. The clinical\nmeaningfulness of the phenotypes identified in this process, as well as their\ntemporal evolution over time for several patients, have been endorsed by\nclinical experts.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 01:38:56 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Perros", "Ioakeim", ""], ["Papalexakis", "Evangelos E.", ""], ["Wang", "Fei", ""], ["Vuduc", "Richard", ""], ["Searles", "Elizabeth", ""], ["Thompson", "Michael", ""], ["Sun", "Jimeng", ""]]}, {"id": "1703.04265", "submitter": "Mohammad Emtiyaz Khan", "authors": "Mohammad Emtiyaz Khan and Wu Lin", "title": "Conjugate-Computation Variational Inference : Converting Variational\n  Inference in Non-Conjugate Models to Inferences in Conjugate Models", "comments": "Published in AI-Stats 2017. Fixed some typos. This version contains a\n  short paragraph in the conclusions section which we could not add in the\n  conference version due to space constraints", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference is computationally challenging in models that contain\nboth conjugate and non-conjugate terms. Methods specifically designed for\nconjugate models, even though computationally efficient, find it difficult to\ndeal with non-conjugate terms. On the other hand, stochastic-gradient methods\ncan handle the non-conjugate terms but they usually ignore the conjugate\nstructure of the model which might result in slow convergence. In this paper,\nwe propose a new algorithm called Conjugate-computation Variational Inference\n(CVI) which brings the best of the two worlds together -- it uses conjugate\ncomputations for the conjugate terms and employs stochastic gradients for the\nrest. We derive this algorithm by using a stochastic mirror-descent method in\nthe mean-parameter space, and then expressing each gradient step as a\nvariational inference in a conjugate model. We demonstrate our algorithm's\napplicability to a large class of models and establish its convergence. Our\nexperimental results show that our method converges much faster than the\nmethods that ignore the conjugate structure of the model.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 06:23:53 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 07:32:19 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Lin", "Wu", ""]]}, {"id": "1703.04274", "submitter": "Liran Szlak", "authors": "Ohad Shamir, Liran Szlak", "title": "Online Learning with Local Permutations and Delayed Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an Online Learning with Local Permutations (OLLP) setting, in\nwhich the learner is allowed to slightly permute the \\emph{order} of the loss\nfunctions generated by an adversary. On one hand, this models natural\nsituations where the exact order of the learner's responses is not crucial, and\non the other hand, might allow better learning and regret performance, by\nmitigating highly adversarial loss sequences. Also, with random permutations,\nthis can be seen as a setting interpolating between adversarial and stochastic\nlosses. In this paper, we consider the applicability of this setting to convex\nonline learning with delayed feedback, in which the feedback on the prediction\nmade in round $t$ arrives with some delay $\\tau$. With such delayed feedback,\nthe best possible regret bound is well-known to be $O(\\sqrt{\\tau T})$. We prove\nthat by being able to permute losses by a distance of at most $M$ (for $M\\geq\n\\tau$), the regret can be improved to $O(\\sqrt{T}(1+\\sqrt{\\tau^2/M}))$, using a\nMirror-Descent based algorithm which can be applied for both Euclidean and\nnon-Euclidean geometries. We also prove a lower bound, showing that for\n$M<\\tau/3$, it is impossible to improve the standard $O(\\sqrt{\\tau T})$ regret\nbound by more than constant factors. Finally, we provide some experiments\nvalidating the performance of our algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 07:31:46 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Shamir", "Ohad", ""], ["Szlak", "Liran", ""]]}, {"id": "1703.04318", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini, Yize Chen, Sreeram Kannan, Baosen Zhang and Radha\n  Poovendran", "title": "Blocking Transferability of Adversarial Examples in Black-Box Learning\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in Machine Learning (ML) have led to its adoption as an integral\ncomponent in many applications, including banking, medical diagnosis, and\ndriverless cars. To further broaden the use of ML models, cloud-based services\noffered by Microsoft, Amazon, Google, and others have developed ML-as-a-service\ntools as black-box systems. However, ML classifiers are vulnerable to\nadversarial examples: inputs that are maliciously modified can cause the\nclassifier to provide adversary-desired outputs. Moreover, it is known that\nadversarial examples generated on one classifier are likely to cause another\nclassifier to make the same mistake, even if the classifiers have different\narchitectures or are trained on disjoint datasets. This property, which is\nknown as transferability, opens up the possibility of attacking black-box\nsystems by generating adversarial examples on a substitute classifier and\ntransferring the examples to the target classifier. Therefore, the key to\nprotect black-box learning systems against the adversarial examples is to block\ntheir transferability. To this end, we propose a training method that, as the\ninput is more perturbed, the classifier smoothly outputs lower confidence on\nthe original label and instead predicts that the input is \"invalid\". In\nessence, we augment the output class set with a NULL label and train the\nclassifier to reject the adversarial examples by classifying them as NULL. In\nexperiments, we apply a wide range of attacks based on adversarial examples on\nthe black-box systems. We show that a classifier trained with the proposed\nmethod effectively resists against the adversarial examples, while maintaining\nthe accuracy on clean data.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 10:28:24 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Hosseini", "Hossein", ""], ["Chen", "Yize", ""], ["Kannan", "Sreeram", ""], ["Zhang", "Baosen", ""], ["Poovendran", "Radha", ""]]}, {"id": "1703.04363", "submitter": "Michael Gygli", "authors": "Michael Gygli, Mohammad Norouzi, Anelia Angelova", "title": "Deep Value Networks Learn to Evaluate and Iteratively Refine Structured\n  Outputs", "comments": "Published at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach structured output prediction by optimizing a deep value network\n(DVN) to precisely estimate the task loss on different output configurations\nfor a given input. Once the model is trained, we perform inference by gradient\ndescent on the continuous relaxations of the output variables to find outputs\nwith promising scores from the value network. When applied to image\nsegmentation, the value network takes an image and a segmentation mask as\ninputs and predicts a scalar estimating the intersection over union between the\ninput and ground truth masks. For multi-label classification, the DVN's\nobjective is to correctly predict the F1 score for any potential label\nconfiguration. The DVN framework achieves the state-of-the-art results on\nmulti-label prediction and image segmentation benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 12:49:20 GMT"}, {"version": "v2", "created": "Tue, 8 Aug 2017 08:10:34 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Gygli", "Michael", ""], ["Norouzi", "Mohammad", ""], ["Angelova", "Anelia", ""]]}, {"id": "1703.04379", "submitter": "Nanyang Ye", "authors": "Nanyang Ye, Zhanxing Zhu, Rafal K. Mantiuk", "title": "Langevin Dynamics with Continuous Tempering for Training Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing non-convex and high-dimensional objective functions is\nchallenging, especially when training modern deep neural networks. In this\npaper, a novel approach is proposed which divides the training process into two\nconsecutive phases to obtain better generalization performance: Bayesian\nsampling and stochastic optimization. The first phase is to explore the energy\nlandscape and to capture the \"fat\" modes; and the second one is to fine-tune\nthe parameter learned from the first phase. In the Bayesian learning phase, we\napply continuous tempering and stochastic approximation into the Langevin\ndynamics to create an efficient and effective sampler, in which the temperature\nis adjusted automatically according to the designed \"temperature dynamics\".\nThese strategies can overcome the challenge of early trapping into bad local\nminima and have achieved remarkable improvements in various types of neural\nnetworks as shown in our theoretical analysis and empirical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 13:27:56 GMT"}, {"version": "v2", "created": "Mon, 31 Jul 2017 16:52:32 GMT"}, {"version": "v3", "created": "Wed, 2 Aug 2017 17:15:28 GMT"}, {"version": "v4", "created": "Tue, 10 Oct 2017 12:27:09 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Ye", "Nanyang", ""], ["Zhu", "Zhanxing", ""], ["Mantiuk", "Rafal K.", ""]]}, {"id": "1703.04389", "submitter": "Jian Wu", "authors": "Jian Wu, Matthias Poloczek, Andrew Gordon Wilson, and Peter I. Frazier", "title": "Bayesian Optimization with Gradients", "comments": "Advances in Neural Information Processing Systems 30 (NIPS), 2017", "journal-ref": "Advances in Neural Information Processing Systems 30 (NIPS), 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has been successful at global optimization of\nexpensive-to-evaluate multimodal objective functions. However, unlike most\noptimization methods, Bayesian optimization typically does not use derivative\ninformation. In this paper we show how Bayesian optimization can exploit\nderivative information to decrease the number of objective function evaluations\nrequired for good performance. In particular, we develop a novel Bayesian\noptimization algorithm, the derivative-enabled knowledge-gradient (dKG), for\nwhich we show one-step Bayes-optimality, asymptotic consistency, and greater\none-step value of information than is possible in the derivative-free setting.\nOur procedure accommodates noisy and incomplete derivative information, comes\nin both sequential and batch forms, and can optionally reduce the computational\ncost of inference through automatically selected retention of a single\ndirectional derivative. We also compute the d-KG acquisition function and its\ngradient using a novel fast discretization-free technique. We show d-KG\nprovides state-of-the-art performance compared to a wide range of optimization\nprocedures with and without gradients, on benchmarks including logistic\nregression, deep learning, kernel learning, and k-nearest neighbors.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 13:45:13 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 13:27:45 GMT"}, {"version": "v3", "created": "Wed, 7 Feb 2018 04:05:29 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Wu", "Jian", ""], ["Poloczek", "Matthias", ""], ["Wilson", "Andrew Gordon", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1703.04482", "submitter": "Stefano Cresci", "authors": "Stefano Cresci, Roberto Di Pietro, Marinella Petrocchi, Angelo\n  Spognardi, Maurizio Tesconi", "title": "Social Fingerprinting: detection of spambot groups through DNA-inspired\n  behavioral modeling", "comments": null, "journal-ref": "IEEE Transactions on Dependable and Secure Computing\n  15(4):561-576, 2018", "doi": "10.1109/TDSC.2017.2681672", "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spambot detection in online social networks is a long-lasting challenge\ninvolving the study and design of detection techniques capable of efficiently\nidentifying ever-evolving spammers. Recently, a new wave of social spambots has\nemerged, with advanced human-like characteristics that allow them to go\nundetected even by current state-of-the-art algorithms. In this paper, we show\nthat efficient spambots detection can be achieved via an in-depth analysis of\ntheir collective behaviors exploiting the digital DNA technique for modeling\nthe behaviors of social network users. Inspired by its biological counterpart,\nin the digital DNA representation the behavioral lifetime of a digital account\nis encoded in a sequence of characters. Then, we define a similarity measure\nfor such digital DNA sequences. We build upon digital DNA and the similarity\nbetween groups of users to characterize both genuine accounts and spambots.\nLeveraging such characterization, we design the Social Fingerprinting\ntechnique, which is able to discriminate among spambots and genuine accounts in\nboth a supervised and an unsupervised fashion. We finally evaluate the\neffectiveness of Social Fingerprinting and we compare it with three\nstate-of-the-art detection algorithms. Among the peculiarities of our approach\nis the possibility to apply off-the-shelf DNA analysis techniques to study\nonline users behaviors and to efficiently rely on a limited number of\nlightweight account characteristics.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 16:51:11 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Cresci", "Stefano", ""], ["Di Pietro", "Roberto", ""], ["Petrocchi", "Marinella", ""], ["Spognardi", "Angelo", ""], ["Tesconi", "Maurizio", ""]]}, {"id": "1703.04529", "submitter": "Priya Donti", "authors": "Priya L. Donti and Brandon Amos and J. Zico Kolter", "title": "Task-based End-to-end Model Learning in Stochastic Optimization", "comments": "In NIPS 2017. Code available at\n  https://github.com/locuslab/e2e-model-learning", "journal-ref": "Advances in Neural Information Processing Systems (pp. 5484-5494)\n  (2017)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of machine learning techniques, it has become\ncommon to see prediction algorithms operating within some larger process.\nHowever, the criteria by which we train these algorithms often differ from the\nultimate criteria on which we evaluate them. This paper proposes an end-to-end\napproach for learning probabilistic machine learning models in a manner that\ndirectly captures the ultimate task-based objective for which they will be\nused, within the context of stochastic programming. We present three\nexperimental evaluations of the proposed approach: a classical inventory stock\nproblem, a real-world electrical grid scheduling task, and a real-world energy\nstorage arbitrage task. We show that the proposed approach can outperform both\ntraditional modeling and purely black-box policy optimization approaches in\nthese applications.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 17:58:36 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 22:40:01 GMT"}, {"version": "v3", "created": "Tue, 3 Apr 2018 20:06:07 GMT"}, {"version": "v4", "created": "Thu, 25 Apr 2019 15:39:04 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Donti", "Priya L.", ""], ["Amos", "Brandon", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1703.04550", "submitter": "Steven Bohez", "authors": "Steven Bohez, Tim Verbelen, Elias De Coninck, Bert Vankeirsbilck,\n  Pieter Simoens, Bart Dhoedt", "title": "Sensor Fusion for Robot Control through Deep Reinforcement Learning", "comments": "6 pages, 6 figures, submitted to IROS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is becoming increasingly popular for robot\ncontrol algorithms, with the aim for a robot to self-learn useful feature\nrepresentations from unstructured sensory input leading to the optimal\nactuation policy. In addition to sensors mounted on the robot, sensors might\nalso be deployed in the environment, although these might need to be accessed\nvia an unreliable wireless connection. In this paper, we demonstrate deep\nneural network architectures that are able to fuse information coming from\nmultiple sensors and are robust to sensor failures at runtime. We evaluate our\nmethod on a search and pick task for a robot both in simulation and the real\nworld.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 20:08:39 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Bohez", "Steven", ""], ["Verbelen", "Tim", ""], ["De Coninck", "Elias", ""], ["Vankeirsbilck", "Bert", ""], ["Simoens", "Pieter", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1703.04664", "submitter": "Anshumali Shrivastava", "authors": "Anshumali Shrivastava", "title": "Optimal Densification for Fast and Accurate Minwise Hashing", "comments": "Fast Minwise Hashing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minwise hashing is a fundamental and one of the most successful hashing\nalgorithm in the literature. Recent advances based on the idea of\ndensification~\\cite{Proc:OneHashLSH_ICML14,Proc:Shrivastava_UAI14} have shown\nthat it is possible to compute $k$ minwise hashes, of a vector with $d$\nnonzeros, in mere $(d + k)$ computations, a significant improvement over the\nclassical $O(dk)$. These advances have led to an algorithmic improvement in the\nquery complexity of traditional indexing algorithms based on minwise hashing.\nUnfortunately, the variance of the current densification techniques is\nunnecessarily high, which leads to significantly poor accuracy compared to\nvanilla minwise hashing, especially when the data is sparse. In this paper, we\nprovide a novel densification scheme which relies on carefully tailored\n2-universal hashes. We show that the proposed scheme is variance-optimal, and\nwithout losing the runtime efficiency, it is significantly more accurate than\nexisting densification techniques. As a result, we obtain a significantly\nefficient hashing scheme which has the same variance and collision probability\nas minwise hashing. Experimental evaluations on real sparse and\nhigh-dimensional datasets validate our claims. We believe that given the\nsignificant advantages, our method will replace minwise hashing implementations\nin practice.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 18:49:57 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Shrivastava", "Anshumali", ""]]}, {"id": "1703.04697", "submitter": "Evgenii Chzhen", "authors": "Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Joseph Salmon", "title": "On the benefits of output sparsity for multi-label classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-label classification framework, where each observation can be\nassociated with a set of labels, has generated a tremendous amount of attention\nover recent years. The modern multi-label problems are typically large-scale in\nterms of number of observations, features and labels, and the amount of labels\ncan even be comparable with the amount of observations. In this context,\ndifferent remedies have been proposed to overcome the curse of dimensionality.\nIn this work, we aim at exploiting the output sparsity by introducing a new\nloss, called the sparse weighted Hamming loss. This proposed loss can be seen\nas a weighted version of classical ones, where active and inactive labels are\nweighted separately. Leveraging the influence of sparsity in the loss function,\nwe provide improved generalization bounds for the empirical risk minimizer, a\nsuitable property for large-scale problems. For this new loss, we derive rates\nof convergence linear in the underlying output-sparsity rather than linear in\nthe number of labels. In practice, minimizing the associated risk can be\nperformed efficiently by using convex surrogates and modern convex optimization\nalgorithms. We provide experiments on various real-world datasets demonstrating\nthe pertinence of our approach when compared to non-weighted techniques.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 20:19:08 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Chzhen", "Evgenii", ""], ["Denis", "Christophe", ""], ["Hebiri", "Mohamed", ""], ["Salmon", "Joseph", ""]]}, {"id": "1703.04706", "submitter": "Tharindu Fernando", "authors": "Tharindu Fernando, Simon Denman, Aaron McFadyen, Sridha Sridharan and\n  Clinton Fookes", "title": "Tree Memory Networks for Modelling Long-term Temporal Dependencies", "comments": null, "journal-ref": "Neurocomputing, Volume 304, 23 August 2018, Pages 64-81", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of sequence modelling, Recurrent Neural Networks (RNN) have\nbeen capable of achieving impressive results in a variety of application areas\nincluding visual question answering, part-of-speech tagging and machine\ntranslation. However this success in modelling short term dependencies has not\nsuccessfully transitioned to application areas such as trajectory prediction,\nwhich require capturing both short term and long term relationships. In this\npaper, we propose a Tree Memory Network (TMN) for modelling long term and short\nterm relationships in sequence-to-sequence mapping problems. The proposed\nnetwork architecture is composed of an input module, controller and a memory\nmodule. In contrast to related literature, which models the memory as a\nsequence of historical states, we model the memory as a recursive tree\nstructure. This structure more effectively captures temporal dependencies\nacross both short term and long term sequences using its hierarchical\nstructure. We demonstrate the effectiveness and flexibility of the proposed TMN\nin two practical problems, aircraft trajectory modelling and pedestrian\ntrajectory modelling in a surveillance setting, and in both cases we outperform\nthe current state-of-the-art. Furthermore, we perform an in depth analysis on\nthe evolution of the memory module content over time and provide visual\nevidence on how the proposed TMN is able to map both long term and short term\nrelationships efficiently via a hierarchical structure.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 21:13:28 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 05:18:59 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Fernando", "Tharindu", ""], ["Denman", "Simon", ""], ["McFadyen", "Aaron", ""], ["Sridharan", "Sridha", ""], ["Fookes", "Clinton", ""]]}, {"id": "1703.04730", "submitter": "Pang Wei Koh", "authors": "Pang Wei Koh and Percy Liang", "title": "Understanding Black-box Predictions via Influence Functions", "comments": "International Conference on Machine Learning, 2017. (This version\n  adds more historical references and fixes typos.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we explain the predictions of a black-box model? In this paper, we\nuse influence functions -- a classic technique from robust statistics -- to\ntrace a model's prediction through the learning algorithm and back to its\ntraining data, thereby identifying training points most responsible for a given\nprediction. To scale up influence functions to modern machine learning\nsettings, we develop a simple, efficient implementation that requires only\noracle access to gradients and Hessian-vector products. We show that even on\nnon-convex and non-differentiable models where the theory breaks down,\napproximations to influence functions can still provide valuable information.\nOn linear models and convolutional neural networks, we demonstrate that\ninfluence functions are useful for multiple purposes: understanding model\nbehavior, debugging models, detecting dataset errors, and even creating\nvisually-indistinguishable training-set attacks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 21:07:01 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 02:31:54 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 22:40:43 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Koh", "Pang Wei", ""], ["Liang", "Percy", ""]]}, {"id": "1703.04756", "submitter": "Nika Haghtalab", "authors": "Nika Haghtalab, Ritesh Noothigattu, Ariel D. Procaccia", "title": "Weighted Voting Via No-Regret Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voting systems typically treat all voters equally. We argue that perhaps they\nshould not: Voters who have supported good choices in the past should be given\nhigher weight than voters who have supported bad ones. To develop a formal\nframework for desirable weighting schemes, we draw on no-regret learning.\nSpecifically, given a voting rule, we wish to design a weighting scheme such\nthat applying the voting rule, with voters weighted by the scheme, leads to\nchoices that are almost as good as those endorsed by the best voter in\nhindsight. We derive possibility and impossibility results for the existence of\nsuch weighting schemes, depending on whether the voting rule and the weighting\nscheme are deterministic or randomized, as well as on the social choice axioms\nsatisfied by the voting rule.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:13:20 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Haghtalab", "Nika", ""], ["Noothigattu", "Ritesh", ""], ["Procaccia", "Ariel D.", ""]]}, {"id": "1703.04757", "submitter": "Nima Dehmamy", "authors": "Nima Dehmamy, Neda Rohani and Aggelos Katsaggelos", "title": "Separation of time scales and direct computation of weights in deep\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence is revolutionizing our lives at an ever increasing\npace. At the heart of this revolution is the recent advancements in deep neural\nnetworks (DNN), learning to perform sophisticated, high-level tasks. However,\ntraining DNNs requires massive amounts of data and is very computationally\nintensive. Gaining analytical understanding of the solutions found by DNNs can\nhelp us devise more efficient training algorithms, replacing the commonly used\nmthod of stochastic gradient descent (SGD). We analyze the dynamics of SGD and\nshow that, indeed, direct computation of the solutions is possible in many\ncases. We show that a high performing setup used in DNNs introduces a\nseparation of time-scales in the training dynamics, allowing SGD to train\nlayers from the lowest (closest to input) to the highest. We then show that for\neach layer, the distribution of solutions found by SGD can be estimated using a\nclass-based principal component analysis (PCA) of the layer's input. This\nfinding allows us to forgo SGD entirely and directly derive the DNN parameters\nusing this class-based PCA, which can be well estimated using significantly\nless data than SGD. We implement these results on image datasets MNIST, CIFAR10\nand CIFAR100 and find that, in fact, layers derived using our class-based PCA\nperform comparable or superior to neural networks of the same size and\narchitecture trained using SGD. We also confirm that the class-based PCA often\nconverges using a fraction of the data required for SGD. Thus, using our method\ntraining time can be reduced both by requiring less training data than SGD, and\nby eliminating layers in the costly backpropagation step of the training.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:13:41 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 07:53:52 GMT"}, {"version": "v3", "created": "Sun, 11 Mar 2018 20:30:28 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Dehmamy", "Nima", ""], ["Rohani", "Neda", ""], ["Katsaggelos", "Aggelos", ""]]}, {"id": "1703.04770", "submitter": "Huy Phan", "authors": "Huy Phan, Philipp Koch, Fabrice Katzberg, Marco Maass, Radoslaw Mazur,\n  Alfred Mertins", "title": "Audio Scene Classification with Deep Recurrent Neural Networks", "comments": "Accepted for Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce in this work an efficient approach for audio scene\nclassification using deep recurrent neural networks. An audio scene is firstly\ntransformed into a sequence of high-level label tree embedding feature vectors.\nThe vector sequence is then divided into multiple subsequences on which a deep\nGRU-based recurrent neural network is trained for sequence-to-label\nclassification. The global predicted label for the entire sequence is finally\nobtained via aggregation of subsequence classification outputs. We will show\nthat our approach obtains an F1-score of 97.7% on the LITIS Rouen dataset,\nwhich is the largest dataset publicly available for the task. Compared to the\nbest previously reported result on the dataset, our approach is able to reduce\nthe relative classification error by 35.3%.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:17:49 GMT"}, {"version": "v2", "created": "Mon, 5 Jun 2017 12:41:28 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Phan", "Huy", ""], ["Koch", "Philipp", ""], ["Katzberg", "Fabrice", ""], ["Maass", "Marco", ""], ["Mazur", "Radoslaw", ""], ["Mertins", "Alfred", ""]]}, {"id": "1703.04775", "submitter": "Andrea Tacchetti", "authors": "Andrea Tacchetti, Stephen Voinea, Georgios Evangelopoulos", "title": "Discriminate-and-Rectify Encoders: Learning from Image Transformation\n  Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of a learning task is increased by transformations in the\ninput space that preserve class identity. Visual object recognition for example\nis affected by changes in viewpoint, scale, illumination or planar\ntransformations. While drastically altering the visual appearance, these\nchanges are orthogonal to recognition and should not be reflected in the\nrepresentation or feature encoding used for learning. We introduce a framework\nfor weakly supervised learning of image embeddings that are robust to\ntransformations and selective to the class distribution, using sets of\ntransforming examples (orbit sets), deep parametrizations and a novel\norbit-based loss. The proposed loss combines a discriminative, contrastive part\nfor orbits with a reconstruction error that learns to rectify orbit\ntransformations. The learned embeddings are evaluated in distance metric-based\ntasks, such as one-shot classification under geometric transformations, as well\nas face verification and retrieval under more realistic visual variability. Our\nresults suggest that orbit sets, suitably computed or observed, can be used for\nefficient, weakly-supervised learning of semantically relevant image\nembeddings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:21:48 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Tacchetti", "Andrea", ""], ["Voinea", "Stephen", ""], ["Evangelopoulos", "Georgios", ""]]}, {"id": "1703.04782", "submitter": "Atilim Gunes Baydin", "authors": "Atilim Gunes Baydin, Robert Cornish, David Martinez Rubio, Mark\n  Schmidt, Frank Wood", "title": "Online Learning Rate Adaptation with Hypergradient Descent", "comments": "11 pages, 4 figures", "journal-ref": "In Sixth International Conference on Learning Representations\n  (ICLR), Vancouver, Canada, April 30 -- May 3, 2018.\n  https://openreview.net/forum?id=BkrsAzWAb", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general method for improving the convergence rate of\ngradient-based optimizers that is easy to implement and works well in practice.\nWe demonstrate the effectiveness of the method in a range of optimization\nproblems by applying it to stochastic gradient descent, stochastic gradient\ndescent with Nesterov momentum, and Adam, showing that it significantly reduces\nthe need for the manual tuning of the initial learning rate for these commonly\nused algorithms. Our method works by dynamically updating the learning rate\nduring optimization using the gradient with respect to the learning rate of the\nupdate rule itself. Computing this \"hypergradient\" needs little additional\ncomputation, requires only one extra copy of the original gradient to be stored\nin memory, and relies upon nothing more than what is provided by reverse-mode\nautomatic differentiation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:28:27 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 23:38:42 GMT"}, {"version": "v3", "created": "Mon, 26 Feb 2018 01:36:49 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Baydin", "Atilim Gunes", ""], ["Cornish", "Robert", ""], ["Rubio", "David Martinez", ""], ["Schmidt", "Mark", ""], ["Wood", "Frank", ""]]}, {"id": "1703.04785", "submitter": "Myung Cho", "authors": "Myung Cho, Lifeng Lai, Weiyu Xu", "title": "Distributed Dual Coordinate Ascent in General Tree Networks and\n  Communication Network Effect on Synchronous Machine Learning", "comments": "34 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the big size of data and limited data storage volume of a single\ncomputer or a single server, data are often stored in a distributed manner.\nThus, performing large-scale machine learning operations with the distributed\ndatasets through communication networks is often required. In this paper, we\nstudy the convergence rate of the distributed dual coordinate ascent for\ndistributed machine learning problems in a general tree-structured network.\nSince a tree network model can be understood as the generalization of a star\nnetwork model, our algorithm can be thought of as the generalization of the\ndistributed dual coordinate ascent in a star network model. We provide the\nconvergence rate of the distributed dual coordinate ascent over a general tree\nnetwork in a recursive manner and analyze the network effect on the convergence\nrate. Secondly, by considering network communication delays, we optimize the\ndistributed dual coordinate ascent algorithm to maximize its convergence speed.\nFrom our analytical result, we can choose the optimal number of local\niterations depending on the communication delay severity to achieve the fastest\nconvergence speed. In numerical experiments, we consider machine learning\nscenarios over communication networks, where local workers cannot directly\nreach to a central node due to constraints in communication, and demonstrate\nthat the usability of our distributed dual coordinate ascent algorithm in tree\nnetworks. Additionally, we show that adapting number of local and global\niterations to network communication delays in the distributed dual coordinated\nascent algorithm can improve its convergence speed.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:30:57 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 04:16:33 GMT"}, {"version": "v3", "created": "Tue, 20 Nov 2018 13:53:07 GMT"}, {"version": "v4", "created": "Fri, 8 Mar 2019 21:53:45 GMT"}, {"version": "v5", "created": "Sun, 15 Mar 2020 06:42:31 GMT"}, {"version": "v6", "created": "Tue, 21 Jul 2020 11:53:36 GMT"}, {"version": "v7", "created": "Thu, 18 Feb 2021 16:20:37 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Cho", "Myung", ""], ["Lai", "Lifeng", ""], ["Xu", "Weiyu", ""]]}, {"id": "1703.04813", "submitter": "Olga Wichrowska", "authors": "Olga Wichrowska, Niru Maheswaranathan, Matthew W. Hoffman, Sergio\n  Gomez Colmenarejo, Misha Denil, Nando de Freitas, Jascha Sohl-Dickstein", "title": "Learned Optimizers that Scale and Generalize", "comments": "Final ICML paper after reviewer suggestions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to learn has emerged as an important direction for achieving\nartificial intelligence. Two of the primary barriers to its adoption are an\ninability to scale to larger problems and a limited ability to generalize to\nnew tasks. We introduce a learned gradient descent optimizer that generalizes\nwell to new tasks, and which has significantly reduced memory and computation\noverhead. We achieve this by introducing a novel hierarchical RNN architecture,\nwith minimal per-parameter overhead, augmented with additional architectural\nfeatures that mirror the known structure of optimization tasks. We also develop\na meta-training ensemble of small, diverse optimization tasks capturing common\nproperties of loss landscapes. The optimizer learns to outperform RMSProp/ADAM\non problems in this corpus. More importantly, it performs comparably or better\nwhen applied to small convolutional neural networks, despite seeing no neural\nnetworks in its meta-training set. Finally, it generalizes to train Inception\nV3 and ResNet V2 architectures on the ImageNet dataset for thousands of steps,\noptimization problems that are of a vastly different scale than those it was\ntrained on. We release an open source implementation of the meta-training\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 23:05:54 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 21:55:33 GMT"}, {"version": "v3", "created": "Fri, 23 Jun 2017 22:22:38 GMT"}, {"version": "v4", "created": "Thu, 7 Sep 2017 23:38:09 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Wichrowska", "Olga", ""], ["Maheswaranathan", "Niru", ""], ["Hoffman", "Matthew W.", ""], ["Colmenarejo", "Sergio Gomez", ""], ["Denil", "Misha", ""], ["de Freitas", "Nando", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1703.04818", "submitter": "Sujith Ravi", "authors": "Thang D. Bui, Sujith Ravi, Vivek Ramavajjala", "title": "Neural Graph Machines: Learning Neural Networks Using Graphs", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label propagation is a powerful and flexible semi-supervised learning\ntechnique on graphs. Neural networks, on the other hand, have proven track\nrecords in many supervised learning tasks. In this work, we propose a training\nframework with a graph-regularised objective, namely \"Neural Graph Machines\",\nthat can combine the power of neural networks and label propagation. This work\ngeneralises previous literature on graph-augmented training of neural networks,\nenabling it to be applied to multiple neural architectures (Feed-forward NNs,\nCNNs and LSTM RNNs) and a wide range of graphs. The new objective allows the\nneural networks to harness both labeled and unlabeled data by: (a) allowing the\nnetwork to train using labeled data as in the supervised setting, (b) biasing\nthe network to learn similar hidden representations for neighboring nodes on a\ngraph, in the same vein as label propagation. Such architectures with the\nproposed objective can be trained efficiently using stochastic gradient descent\nand scaled to large graphs, with a runtime that is linear in the number of\nedges. The proposed joint training approach convincingly outperforms many\nexisting methods on a wide range of tasks (multi-label classification on social\ngraphs, news categorization, document classification and semantic intent\nclassification), with multiple forms of graph inputs (including graphs with and\nwithout node-level features) and using different types of neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 23:10:57 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Bui", "Thang D.", ""], ["Ravi", "Sujith", ""], ["Ramavajjala", "Vivek", ""]]}, {"id": "1703.04823", "submitter": "Jose Lugo-Martinez", "authors": "Jose Lugo-Martinez and Predrag Radivojac", "title": "Classification in biological networks with hypergraphlet kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological and cellular systems are often modeled as graphs in which vertices\nrepresent objects of interest (genes, proteins, drugs) and edges represent\nrelational ties among these objects (binds-to, interacts-with, regulates). This\napproach has been highly successful owing to the theory, methodology and\nsoftware that support analysis and learning on graphs. Graphs, however, often\nsuffer from information loss when modeling physical systems due to their\ninability to accurately represent multiobject relationships. Hypergraphs, a\ngeneralization of graphs, provide a framework to mitigate information loss and\nunify disparate graph-based methodologies. In this paper, we present a\nhypergraph-based approach for modeling physical systems and formulate vertex\nclassification, edge classification and link prediction problems on\n(hyper)graphs as instances of vertex classification on (extended, dual)\nhypergraphs in a semi-supervised setting. We introduce a novel kernel method on\nvertex- and edge-labeled (colored) hypergraphs for analysis and learning. The\nmethod is based on exact and inexact (via hypergraph edit distances)\nenumeration of small simple hypergraphs, referred to as hypergraphlets, rooted\nat a vertex of interest. We extensively evaluate this method and show its\npotential use in a positive-unlabeled setting to estimate the number of missing\nand false positive links in protein-protein interaction networks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 23:20:17 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Lugo-Martinez", "Jose", ""], ["Radivojac", "Predrag", ""]]}, {"id": "1703.04826", "submitter": "Diego Marcheggiani", "authors": "Diego Marcheggiani and Ivan Titov", "title": "Encoding Sentences with Graph Convolutional Networks for Semantic Role\n  Labeling", "comments": "To appear in EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) is the task of identifying the\npredicate-argument structure of a sentence. It is typically regarded as an\nimportant step in the standard NLP pipeline. As the semantic representations\nare closely related to syntactic ones, we exploit syntactic information in our\nmodel. We propose a version of graph convolutional networks (GCNs), a recent\nclass of neural networks operating on graphs, suited to model syntactic\ndependency graphs. GCNs over syntactic dependency trees are used as sentence\nencoders, producing latent feature representations of words in a sentence. We\nobserve that GCN layers are complementary to LSTM ones: when we stack both GCN\nand LSTM layers, we obtain a substantial improvement over an already\nstate-of-the-art LSTM SRL model, resulting in the best reported scores on the\nstandard benchmark (CoNLL-2009) both for Chinese and English.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 23:25:34 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 09:47:59 GMT"}, {"version": "v3", "created": "Wed, 24 May 2017 09:48:05 GMT"}, {"version": "v4", "created": "Sun, 30 Jul 2017 17:24:38 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Marcheggiani", "Diego", ""], ["Titov", "Ivan", ""]]}, {"id": "1703.04842", "submitter": "Vu Nguyen", "authors": "Vu Nguyen and Santu Rana and Sunil Gupta and Cheng Li and Svetha\n  Venkatesh", "title": "Budgeted Batch Bayesian Optimization With Unknown Batch Sizes", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter settings profoundly impact the performance of machine learning\nalgorithms and laboratory experiments. The classical grid search or trial-error\nmethods are exponentially expensive in large parameter spaces, and Bayesian\noptimization (BO) offers an elegant alternative for global optimization of\nblack box functions. In situations where the black box function can be\nevaluated at multiple points simultaneously, batch Bayesian optimization is\nused. Current batch BO approaches are restrictive in that they fix the number\nof evaluations per batch, and this can be wasteful when the number of specified\nevaluations is larger than the number of real maxima in the underlying\nacquisition function. We present the Budgeted Batch Bayesian Optimization (B3O)\nfor hyper-parameter tuning and experimental design - we identify the\nappropriate batch size for each iteration in an elegant way. To set the batch\nsize flexible, we use the infinite Gaussian mixture model (IGMM) for\nautomatically identifying the number of peaks in the underlying acquisition\nfunctions. We solve the intractability of estimating the IGMM directly from the\nacquisition function by formulating the batch generalized slice sampling to\nefficiently draw samples from the acquisition function. We perform extensive\nexperiments for both synthetic functions and two real world applications -\nmachine learning hyper-parameter tuning and experimental design for alloy\nhardening. We show empirically that the proposed B3O outperforms the existing\nfixed batch BO approaches in finding the optimum whilst requiring a fewer\nnumber of evaluations, thus saving cost and time.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 00:05:41 GMT"}, {"version": "v2", "created": "Sat, 15 Apr 2017 04:54:47 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Nguyen", "Vu", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Li", "Cheng", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1703.04886", "submitter": "Marc Vuffray", "authors": "Sidhant Misra, Marc Vuffray, Andrey Y. Lokhov", "title": "Information Theoretic Optimal Learning of Gaussian Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the optimal number of independent observations from which a sparse\nGaussian Graphical Model can be correctly recovered? Information-theoretic\narguments provide a lower bound on the minimum number of samples necessary to\nperfectly identify the support of any multivariate normal distribution as a\nfunction of model parameters. For a model defined on a sparse graph with $p$\nnodes, a maximum degree $d$ and minimum normalized edge strength $\\kappa$, this\nnecessary number of samples scales at least as $d \\log p/\\kappa^2$. The sample\ncomplexity requirements of existing methods for perfect graph reconstruction\nexhibit dependency on additional parameters that do not enter in the lower\nbound. The question of whether the lower bound is tight and achievable by a\npolynomial time algorithm remains open. In this paper, we constructively answer\nthis question and propose an algorithm, termed DICE, whose sample complexity\nmatches the information-theoretic lower bound up to a universal constant\nfactor. We also propose a related algorithm SLICE that has a slightly higher\nsample complexity, but can be implemented as a mixed integer quadratic program\nwhich makes it attractive in practice. Importantly, SLICE retains a critical\nadvantage of DICE in that its sample complexity only depends on quantities\npresent in the information theoretic lower bound. We anticipate that this\nresult will stimulate future search of computationally efficient sample-optimal\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 02:25:31 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 05:46:43 GMT"}, {"version": "v3", "created": "Sun, 18 Nov 2018 04:32:34 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Misra", "Sidhant", ""], ["Vuffray", "Marc", ""], ["Lokhov", "Andrey Y.", ""]]}, {"id": "1703.04890", "submitter": "Hiroyuki Kasai", "authors": "Hiroyuki Kasai and Hiroyuki Sato and Bamdev Mishra", "title": "Riemannian stochastic quasi-Newton algorithm with variance reduction and\n  its convergence analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variance reduction algorithms have recently become popular for\nminimizing the average of a large, but finite number of loss functions. The\npresent paper proposes a Riemannian stochastic quasi-Newton algorithm with\nvariance reduction (R-SQN-VR). The key challenges of averaging, adding, and\nsubtracting multiple gradients are addressed with notions of retraction and\nvector transport. We present convergence analyses of R-SQN-VR on both\nnon-convex and retraction-convex functions under retraction and vector\ntransport operators. The proposed algorithm is evaluated on the Karcher mean\ncomputation on the symmetric positive-definite manifold and the low-rank matrix\ncompletion on the Grassmann manifold. In all cases, the proposed algorithm\noutperforms the state-of-the-art Riemannian batch and stochastic gradient\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 02:34:39 GMT"}, {"version": "v2", "created": "Wed, 12 Apr 2017 15:52:38 GMT"}, {"version": "v3", "created": "Sat, 16 Sep 2017 09:47:22 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Kasai", "Hiroyuki", ""], ["Sato", "Hiroyuki", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1703.04933", "submitter": "Laurent Dinh", "authors": "Laurent Dinh, Razvan Pascanu, Samy Bengio, Yoshua Bengio", "title": "Sharp Minima Can Generalize For Deep Nets", "comments": "8.5 pages of main content, 2.5 of bibliography and 1 page of appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their overwhelming capacity to overfit, deep learning architectures\ntend to generalize relatively well to unseen data, allowing them to be deployed\nin practice. However, explaining why this is the case is still an open area of\nresearch. One standing hypothesis that is gaining popularity, e.g. Hochreiter &\nSchmidhuber (1997); Keskar et al. (2017), is that the flatness of minima of the\nloss function found by stochastic gradient based methods results in good\ngeneralization. This paper argues that most notions of flatness are problematic\nfor deep models and can not be directly applied to explain generalization.\nSpecifically, when focusing on deep networks with rectifier units, we can\nexploit the particular geometry of parameter space induced by the inherent\nsymmetries that these architectures exhibit to build equivalent models\ncorresponding to arbitrarily sharper minima. Furthermore, if we allow to\nreparametrize a function, the geometry of its parameters can change drastically\nwithout affecting its generalization properties.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 05:12:25 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 23:33:19 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Dinh", "Laurent", ""], ["Pascanu", "Razvan", ""], ["Bengio", "Samy", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.04940", "submitter": "Jacob Steinhardt", "authors": "Jacob Steinhardt and Moses Charikar and Gregory Valiant", "title": "Resilience: A Criterion for Learning in the Presence of Arbitrary\n  Outliers", "comments": "32 pages, full version of ITCS2018 paper (minor citation edit from\n  v2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a criterion, resilience, which allows properties of a dataset\n(such as its mean or best low rank approximation) to be robustly computed, even\nin the presence of a large fraction of arbitrary additional data. Resilience is\na weaker condition than most other properties considered so far in the\nliterature, and yet enables robust estimation in a broader variety of settings.\nWe provide new information-theoretic results on robust distribution learning,\nrobust estimation of stochastic block models, and robust mean estimation under\nbounded $k$th moments. We also provide new algorithmic results on robust\ndistribution learning, as well as robust mean estimation in $\\ell_p$-norms.\nAmong our proof techniques is a method for pruning a high-dimensional\ndistribution with bounded $1$st moments to a stable \"core\" with bounded $2$nd\nmoments, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 05:43:48 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 07:22:21 GMT"}, {"version": "v3", "created": "Mon, 27 Nov 2017 03:16:54 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Steinhardt", "Jacob", ""], ["Charikar", "Moses", ""], ["Valiant", "Gregory", ""]]}, {"id": "1703.04943", "submitter": "Zahra Razaee", "authors": "Zahra S. Razaee, Arash A. Amini, Jingyi Jessica Li", "title": "Matched bipartite block model with covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection or clustering is a fundamental task in the analysis of\nnetwork data. Many real networks have a bipartite structure which makes\ncommunity detection challenging. In this paper, we consider a model which\nallows for matched communities in the bipartite setting, in addition to node\ncovariates with information about the matching. We derive a simple fast\nalgorithm for fitting the model based on variational inference ideas and show\nits effectiveness on both simulated and real data. A variation of the model to\nallow for degree-correction is also considered, in addition to a novel approach\nto fitting such degree-corrected models.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 05:47:37 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Razaee", "Zahra S.", ""], ["Amini", "Arash A.", ""], ["Li", "Jingyi Jessica", ""]]}, {"id": "1703.05051", "submitter": "Robin Tibor Schirrmeister", "authors": "Robin Tibor Schirrmeister, Jost Tobias Springenberg, Lukas Dominique\n  Josef Fiederer, Martin Glasstetter, Katharina Eggensperger, Michael\n  Tangermann, Frank Hutter, Wolfram Burgard, Tonio Ball", "title": "Deep learning with convolutional neural networks for EEG decoding and\n  visualization", "comments": "A revised manuscript (with the new title) has been accepted at Human\n  Brain Mapping, see http://onlinelibrary.wiley.com/doi/10.1002/hbm.23730/full", "journal-ref": null, "doi": "10.1002/hbm.23730", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PLEASE READ AND CITE THE REVISED VERSION at Human Brain Mapping:\nhttp://onlinelibrary.wiley.com/doi/10.1002/hbm.23730/full\n  Code available here: https://github.com/robintibor/braindecode\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 09:52:58 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 11:06:38 GMT"}, {"version": "v3", "created": "Mon, 7 Aug 2017 16:16:08 GMT"}, {"version": "v4", "created": "Tue, 8 Aug 2017 08:48:58 GMT"}, {"version": "v5", "created": "Fri, 8 Jun 2018 16:13:56 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Schirrmeister", "Robin Tibor", ""], ["Springenberg", "Jost Tobias", ""], ["Fiederer", "Lukas Dominique Josef", ""], ["Glasstetter", "Martin", ""], ["Eggensperger", "Katharina", ""], ["Tangermann", "Michael", ""], ["Hutter", "Frank", ""], ["Burgard", "Wolfram", ""], ["Ball", "Tonio", ""]]}, {"id": "1703.05060", "submitter": "Dave Zachariah", "authors": "Dave Zachariah and Petre Stoica and Thomas B. Sch\\\"on", "title": "Online Learning for Distribution-Free Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an online learning method for prediction, which is important in\nproblems with large and/or streaming data sets. We formulate the learning\napproach using a covariance-fitting methodology, and show that the resulting\npredictor has desirable computational and distribution-free properties: It is\nimplemented online with a runtime that scales linearly in the number of\nsamples; has a constant memory requirement; avoids local minima problems; and\nprunes away redundant feature dimensions without relying on restrictive\nassumptions on the data distribution. In conjunction with the split conformal\napproach, it also produces distribution-free prediction confidence intervals in\na computationally efficient manner. The method is demonstrated on both real and\nsynthetic datasets.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 10:20:32 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Zachariah", "Dave", ""], ["Stoica", "Petre", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1703.05082", "submitter": "Fabricio Murai", "authors": "Fabricio Murai, Diogo Renn\\'o, Bruno Ribeiro, Gisele L. Pappa, Don\n  Towsley, Krista Gile", "title": "Selective Harvesting over Networks", "comments": "28 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active search (AS) on graphs focuses on collecting certain labeled nodes\n(targets) given global knowledge of the network topology and its edge weights\nunder a query budget. However, in most networks, nodes, topology and edge\nweights are all initially unknown. We introduce selective harvesting, a variant\nof AS where the next node to be queried must be chosen among the neighbors of\nthe current queried node set; the available training data for deciding which\nnode to query is restricted to the subgraph induced by the queried set (and\ntheir node attributes) and their neighbors (without any node or edge\nattributes). Therefore, selective harvesting is a sequential decision problem,\nwhere we must decide which node to query at each step. A classifier trained in\nthis scenario suffers from a tunnel vision effect: without recourse to\nindependent sampling, the urge to query promising nodes forces classifiers to\ngather increasingly biased training data, which we show significantly hurts the\nperformance of AS methods and standard classifiers. We find that it is possible\nto collect a much larger set of targets by using multiple classifiers, not by\ncombining their predictions as an ensemble, but switching between classifiers\nused at each step, as a way to ease the tunnel vision effect. We discover that\nswitching classifiers collects more targets by (a) diversifying the training\ndata and (b) broadening the choices of nodes that can be queried next. This\nhighlights an exploration, exploitation, and diversification trade-off in our\nproblem that goes beyond the exploration and exploitation duality found in\nclassic sequential decision problems. From these observations we propose D3TS,\na method based on multi-armed bandits for non-stationary stochastic processes\nthat enforces classifier diversity, matching or exceeding the performance of\ncompeting methods on seven real network datasets in our evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 11:17:02 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Murai", "Fabricio", ""], ["Renn\u00f3", "Diogo", ""], ["Ribeiro", "Bruno", ""], ["Pappa", "Gisele L.", ""], ["Towsley", "Don", ""], ["Gile", "Krista", ""]]}, {"id": "1703.05160", "submitter": "Ryan Spring", "authors": "Ryan Spring, Anshumali Shrivastava", "title": "A New Unbiased and Efficient Class of LSH-Based Samplers and Estimators\n  for Partition Function Computation in Log-Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log-linear models are arguably the most successful class of graphical models\nfor large-scale applications because of their simplicity and tractability.\nLearning and inference with these models require calculating the partition\nfunction, which is a major bottleneck and intractable for large state spaces.\nImportance Sampling (IS) and MCMC-based approaches are lucrative. However, the\ncondition of having a \"good\" proposal distribution is often not satisfied in\npractice.\n  In this paper, we add a new dimension to efficient estimation via sampling.\nWe propose a new sampling scheme and an unbiased estimator that estimates the\npartition function accurately in sub-linear time. Our samples are generated in\nnear-constant time using locality sensitive hashing (LSH), and so are\ncorrelated and unnormalized. We demonstrate the effectiveness of our proposed\napproach by comparing the accuracy and speed of estimating the partition\nfunction against other state-of-the-art estimation techniques including IS and\nthe efficient variant of Gumbel-Max sampling. With our efficient sampling\nscheme, we accurately train real-world language models using only 1-2% of\ncomputations.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 14:01:21 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Spring", "Ryan", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1703.05175", "submitter": "Jake Snell", "authors": "Jake Snell, Kevin Swersky, Richard S. Zemel", "title": "Prototypical Networks for Few-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose prototypical networks for the problem of few-shot classification,\nwhere a classifier must generalize to new classes not seen in the training set,\ngiven only a small number of examples of each new class. Prototypical networks\nlearn a metric space in which classification can be performed by computing\ndistances to prototype representations of each class. Compared to recent\napproaches for few-shot learning, they reflect a simpler inductive bias that is\nbeneficial in this limited-data regime, and achieve excellent results. We\nprovide an analysis showing that some simple design decisions can yield\nsubstantial improvements over recent approaches involving complicated\narchitectural choices and meta-learning. We further extend prototypical\nnetworks to zero-shot learning and achieve state-of-the-art results on the\nCU-Birds dataset.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 14:31:55 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 22:48:54 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Snell", "Jake", ""], ["Swersky", "Kevin", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1703.05291", "submitter": "Ying Shan", "authors": "Jie Zhu, Ying Shan, JC Mao, Dong Yu, Holakou Rahmanian, Yi Zhang", "title": "Deep Embedding Forest: Forest-based Serving with Deep Embedding Features", "comments": "14 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) have demonstrated superior ability to extract high\nlevel embedding vectors from low level features. Despite the success, the\nserving time is still the bottleneck due to expensive run-time computation of\nmultiple layers of dense matrices. GPGPU, FPGA, or ASIC-based serving systems\nrequire additional hardware that are not in the mainstream design of most\ncommercial applications. In contrast, tree or forest-based models are widely\nadopted because of low serving cost, but heavily depend on carefully engineered\nfeatures. This work proposes a Deep Embedding Forest model that benefits from\nthe best of both worlds. The model consists of a number of embedding layers and\na forest/tree layer. The former maps high dimensional (hundreds of thousands to\nmillions) and heterogeneous low-level features to the lower dimensional\n(thousands) vectors, and the latter ensures fast serving.\n  Built on top of a representative DNN model called Deep Crossing, and two\nforest/tree-based models including XGBoost and LightGBM, a two-step Deep\nEmbedding Forest algorithm is demonstrated to achieve on-par or slightly better\nperformance as compared with the DNN counterpart, with only a fraction of\nserving time on conventional hardware. After comparing with a joint\noptimization algorithm called partial fuzzification, also proposed in this\npaper, it is concluded that the two-step Deep Embedding Forest has achieved\nnear optimal performance. Experiments based on large scale data sets (up to 1\nbillion samples) from a major sponsored search engine proves the efficacy of\nthe proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 17:48:09 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Zhu", "Jie", ""], ["Shan", "Ying", ""], ["Mao", "JC", ""], ["Yu", "Dong", ""], ["Rahmanian", "Holakou", ""], ["Zhang", "Yi", ""]]}, {"id": "1703.05298", "submitter": "Dario Zanca", "authors": "Francesco Giannini, Vincenzo Laveglia, Alessandro Rossi, Dario Zanca,\n  Andrea Zugarini", "title": "Neural Networks for Beginners. A fast implementation in Matlab, Torch,\n  TensorFlow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report provides an introduction to some Machine Learning tools within\nthe most common development environments. It mainly focuses on practical\nproblems, skipping any theoretical introduction. It is oriented to both\nstudents trying to approach Machine Learning and experts looking for new\nframeworks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 18:01:20 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 08:32:19 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Giannini", "Francesco", ""], ["Laveglia", "Vincenzo", ""], ["Rossi", "Alessandro", ""], ["Zanca", "Dario", ""], ["Zugarini", "Andrea", ""]]}, {"id": "1703.05364", "submitter": "Steven Young", "authors": "Thomas E. Potok, Catherine Schuman, Steven R. Young, Robert M. Patton,\n  Federico Spedalieri, Jeremy Liu, Ke-Thia Yao, Garrett Rose, Gangotree Chakma", "title": "A Study of Complex Deep Learning Networks on High Performance,\n  Neuromorphic, and Quantum Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current Deep Learning approaches have been very successful using\nconvolutional neural networks (CNN) trained on large graphical processing units\n(GPU)-based computers. Three limitations of this approach are: 1) they are\nbased on a simple layered network topology, i.e., highly connected layers,\nwithout intra-layer connections; 2) the networks are manually configured to\nachieve optimal results, and 3) the implementation of neuron model is expensive\nin both cost and power. In this paper, we evaluate deep learning models using\nthree different computing architectures to address these problems: quantum\ncomputing to train complex topologies, high performance computing (HPC) to\nautomatically determine network topology, and neuromorphic computing for a\nlow-power hardware implementation. We use the MNIST dataset for our experiment,\ndue to input size limitations of current quantum computers. Our results show\nthe feasibility of using the three architectures in tandem to address the above\ndeep learning limitations. We show a quantum computer can find high quality\nvalues of intra-layer connections weights, in a tractable time as the\ncomplexity of the network increases; a high performance computer can find\noptimal layer-based topologies; and a neuromorphic computer can represent the\ncomplex topology and weights derived from the other architectures in low power\nmemristive hardware.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 19:37:08 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 18:47:59 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Potok", "Thomas E.", ""], ["Schuman", "Catherine", ""], ["Young", "Steven R.", ""], ["Patton", "Robert M.", ""], ["Spedalieri", "Federico", ""], ["Liu", "Jeremy", ""], ["Yao", "Ke-Thia", ""], ["Rose", "Garrett", ""], ["Chakma", "Gangotree", ""]]}, {"id": "1703.05390", "submitter": "Sercan Arik", "authors": "Sercan O. Arik, Markus Kliegl, Rewon Child, Joel Hestness, Andrew\n  Gibiansky, Chris Fougner, Ryan Prenger, Adam Coates", "title": "Convolutional Recurrent Neural Networks for Small-Footprint Keyword\n  Spotting", "comments": "Accepted to Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting (KWS) constitutes a major component of human-technology\ninterfaces. Maximizing the detection accuracy at a low false alarm (FA) rate,\nwhile minimizing the footprint size, latency and complexity are the goals for\nKWS. Towards achieving them, we study Convolutional Recurrent Neural Networks\n(CRNNs). Inspired by large-scale state-of-the-art speech recognition systems,\nwe combine the strengths of convolutional layers and recurrent layers to\nexploit local structure and long-range context. We analyze the effect of\narchitecture parameters, and propose training strategies to improve\nperformance. With only ~230k parameters, our CRNN model yields acceptably low\nlatency, and achieves 97.71% accuracy at 0.5 FA/hour for 5 dB signal-to-noise\nratio.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 21:20:44 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 00:37:05 GMT"}, {"version": "v3", "created": "Tue, 4 Jul 2017 22:49:18 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Arik", "Sercan O.", ""], ["Kliegl", "Markus", ""], ["Child", "Rewon", ""], ["Hestness", "Joel", ""], ["Gibiansky", "Andrew", ""], ["Fougner", "Chris", ""], ["Prenger", "Ryan", ""], ["Coates", "Adam", ""]]}, {"id": "1703.05407", "submitter": "Sainbayar Sukhbaatar", "authors": "Sainbayar Sukhbaatar, Zeming Lin, Ilya Kostrikov, Gabriel Synnaeve,\n  Arthur Szlam and Rob Fergus", "title": "Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play", "comments": "Published in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a simple scheme that allows an agent to learn about its\nenvironment in an unsupervised manner. Our scheme pits two versions of the same\nagent, Alice and Bob, against one another. Alice proposes a task for Bob to\ncomplete; and then Bob attempts to complete the task. In this work we will\nfocus on two kinds of environments: (nearly) reversible environments and\nenvironments that can be reset. Alice will \"propose\" the task by doing a\nsequence of actions and then Bob must undo or repeat them, respectively. Via an\nappropriate reward structure, Alice and Bob automatically generate a curriculum\nof exploration, enabling unsupervised training of the agent. When Bob is\ndeployed on an RL task within the environment, this unsupervised training\nreduces the number of supervised episodes needed to learn, and in some cases\nconverges to a higher reward.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 22:27:43 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 23:32:25 GMT"}, {"version": "v3", "created": "Sun, 4 Jun 2017 12:44:45 GMT"}, {"version": "v4", "created": "Sun, 29 Oct 2017 16:02:21 GMT"}, {"version": "v5", "created": "Fri, 27 Apr 2018 20:58:12 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Sukhbaatar", "Sainbayar", ""], ["Lin", "Zeming", ""], ["Kostrikov", "Ilya", ""], ["Synnaeve", "Gabriel", ""], ["Szlam", "Arthur", ""], ["Fergus", "Rob", ""]]}, {"id": "1703.05411", "submitter": "Tien Thanh Nguyen", "authors": "Tien Thanh Nguyen, Xuan Cuong Pham, Alan Wee-Chung Liew, Witold\n  Pedrycz", "title": "Aggregation of Classifiers: A Justifiable Information Granularity\n  Approach", "comments": "33 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we introduce a new approach to combine multi-classifiers in an\nensemble system. Instead of using numeric membership values encountered in\nfixed combining rules, we construct interval membership values associated with\neach class prediction at the level of meta-data of observation by using\nconcepts of information granules. In the proposed method, uncertainty\n(diversity) of findings produced by the base classifiers is quantified by\ninterval-based information granules. The discriminative decision model is\ngenerated by considering both the bounds and the length of the obtained\nintervals. We select ten and then fifteen learning algorithms to build a\nheterogeneous ensemble system and then conducted the experiment on a number of\nUCI datasets. The experimental results demonstrate that the proposed approach\nperforms better than the benchmark algorithms including six fixed combining\nmethods, one trainable combining method, AdaBoost, Bagging, and Random\nSubspace.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 22:48:05 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Nguyen", "Tien Thanh", ""], ["Pham", "Xuan Cuong", ""], ["Liew", "Alan Wee-Chung", ""], ["Pedrycz", "Witold", ""]]}, {"id": "1703.05430", "submitter": "Bangalore Ravi Kiran", "authors": "Kiran Bangalore Ravi, Jean Serra", "title": "Cost-complexity pruning of random forests", "comments": "Previous version in proceedings of ISMM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests perform bootstrap-aggregation by sampling the training samples\nwith replacement. This enables the evaluation of out-of-bag error which serves\nas a internal cross-validation mechanism. Our motivation lies in using the\nunsampled training samples to improve each decision tree in the ensemble. We\nstudy the effect of using the out-of-bag samples to improve the generalization\nerror first of the decision trees and second the random forest by post-pruning.\nA preliminary empirical study on four UCI repository datasets show consistent\ndecrease in the size of the forests without considerable loss in accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 23:58:19 GMT"}, {"version": "v2", "created": "Wed, 19 Jul 2017 16:28:28 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Ravi", "Kiran Bangalore", ""], ["Serra", "Jean", ""]]}, {"id": "1703.05446", "submitter": "Ke Gong", "authors": "Ke Gong, Xiaodan Liang, Dongyu Zhang, Xiaohui Shen, Liang Lin", "title": "Look into Person: Self-supervised Structure-sensitive Learning and A New\n  Benchmark for Human Parsing", "comments": "Accepted to appear in CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human parsing has recently attracted a lot of research interests due to its\nhuge application potentials. However existing datasets have limited number of\nimages and annotations, and lack the variety of human appearances and the\ncoverage of challenging cases in unconstrained environment. In this paper, we\nintroduce a new benchmark \"Look into Person (LIP)\" that makes a significant\nadvance in terms of scalability, diversity and difficulty, a contribution that\nwe feel is crucial for future developments in human-centric analysis. This\ncomprehensive dataset contains over 50,000 elaborately annotated images with 19\nsemantic part labels, which are captured from a wider range of viewpoints,\nocclusions and background complexity. Given these rich annotations we perform\ndetailed analyses of the leading human parsing approaches, gaining insights\ninto the success and failures of these methods. Furthermore, in contrast to the\nexisting efforts on improving the feature discriminative capability, we solve\nhuman parsing by exploring a novel self-supervised structure-sensitive learning\napproach, which imposes human pose structures into parsing results without\nresorting to extra supervision (i.e., no need for specifically labeling human\njoints in model training). Our self-supervised learning framework can be\ninjected into any advanced neural networks to help incorporate rich high-level\nknowledge regarding human joints from a global perspective and improve the\nparsing results. Extensive evaluations on our LIP and the public\nPASCAL-Person-Part dataset demonstrate the superiority of our method.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 01:14:36 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 01:41:39 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Gong", "Ke", ""], ["Liang", "Xiaodan", ""], ["Zhang", "Dongyu", ""], ["Shen", "Xiaohui", ""], ["Lin", "Liang", ""]]}, {"id": "1703.05449", "submitter": "Mohammad Gheshlaghi Azar", "authors": "Mohammad Gheshlaghi Azar and Ian Osband and R\\'emi Munos", "title": "Minimax Regret Bounds for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of provably optimal exploration in reinforcement\nlearning for finite horizon MDPs. We show that an optimistic modification to\nvalue iteration achieves a regret bound of $\\tilde{O}( \\sqrt{HSAT} +\nH^2S^2A+H\\sqrt{T})$ where $H$ is the time horizon, $S$ the number of states,\n$A$ the number of actions and $T$ the number of time-steps. This result\nimproves over the best previous known bound $\\tilde{O}(HS \\sqrt{AT})$ achieved\nby the UCRL2 algorithm of Jaksch et al., 2010. The key significance of our new\nresults is that when $T\\geq H^3S^3A$ and $SA\\geq H$, it leads to a regret of\n$\\tilde{O}(\\sqrt{HSAT})$ that matches the established lower bound of\n$\\Omega(\\sqrt{HSAT})$ up to a logarithmic factor. Our analysis contains two key\ninsights. We use careful application of concentration inequalities to the\noptimal value function as a whole, rather than to the transitions probabilities\n(to improve scaling in $S$), and we define Bernstein-based \"exploration\nbonuses\" that use the empirical variance of the estimated values at the next\nstates (to improve scaling in $H$).\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 01:31:33 GMT"}, {"version": "v2", "created": "Sat, 1 Jul 2017 13:00:06 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Azar", "Mohammad Gheshlaghi", ""], ["Osband", "Ian", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "1703.05452", "submitter": "Yuxin Chen", "authors": "Yuxin Chen, Jean-Michel Renders, Morteza Haghir Chehreghani, Andreas\n  Krause", "title": "Efficient Online Learning for Optimizing Value of Information: Theory\n  and Application to Interactive Troubleshooting", "comments": "18 pages, 6 figures, to appear in the Conference on Uncertainty in\n  Artificial Intelligence (UAI) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimal value of information (VoI) problem, where the goal is\nto sequentially select a set of tests with a minimal cost, so that one can\nefficiently make the best decision based on the observed outcomes. Existing\nalgorithms are either heuristics with no guarantees, or scale poorly (with\nexponential run time in terms of the number of available tests). Moreover,\nthese methods assume a known distribution over the test outcomes, which is\noften not the case in practice. We propose an efficient sampling-based online\nlearning framework to address the above issues. First, assuming the\ndistribution over hypotheses is known, we propose a dynamic hypothesis\nenumeration strategy, which allows efficient information gathering with strong\ntheoretical guarantees. We show that with sufficient amount of samples, one can\nidentify a near-optimal decision with high probability. Second, when the\nparameters of the hypotheses distribution are unknown, we propose an algorithm\nwhich learns the parameters progressively via posterior sampling in an online\nfashion. We further establish a rigorous bound on the expected regret. We\ndemonstrate the effectiveness of our approach on a real-world interactive\ntroubleshooting application and show that one can efficiently make high-quality\ndecisions with low cost.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 01:37:25 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 16:53:10 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Chen", "Yuxin", ""], ["Renders", "Jean-Michel", ""], ["Chehreghani", "Morteza Haghir", ""], ["Krause", "Andreas", ""]]}, {"id": "1703.05486", "submitter": "Oscar De Somer", "authors": "Oscar De Somer, Ana Soares, Tristan Kuijpers, Koen Vossen, Koen\n  Vanthournout and Fred Spiessens", "title": "Using Reinforcement Learning for Demand Response of Domestic Hot Water\n  Buffers: a Real-Life Demonstration", "comments": "Submitted to IEEE ISGT Europe 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates a data-driven control approach for demand response in\nreal-life residential buildings. The objective is to optimally schedule the\nheating cycles of the Domestic Hot Water (DHW) buffer to maximize the\nself-consumption of the local photovoltaic (PV) production. A model-based\nreinforcement learning technique is used to tackle the underlying sequential\ndecision-making problem. The proposed algorithm learns the stochastic occupant\nbehavior, predicts the PV production and takes into account the dynamics of the\nsystem. A real-life experiment with six residential buildings is performed\nusing this algorithm. The results show that the self-consumption of the PV\nproduction is significantly increased, compared to the default thermostat\ncontrol.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 06:42:07 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["De Somer", "Oscar", ""], ["Soares", "Ana", ""], ["Kuijpers", "Tristan", ""], ["Vossen", "Koen", ""], ["Vanthournout", "Koen", ""], ["Spiessens", "Fred", ""]]}, {"id": "1703.05537", "submitter": "Francesco Orsini", "authors": "Francesco Orsini, Daniele Baracchi and Paolo Frasconi", "title": "Shift Aggregate Extract Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an architecture based on deep hierarchical decompositions to\nlearn effective representations of large graphs. Our framework extends classic\nR-decompositions used in kernel methods, enabling nested \"part-of-part\"\nrelations. Unlike recursive neural networks, which unroll a template on input\ngraphs directly, we unroll a neural network template over the decomposition\nhierarchy, allowing us to deal with the high degree variability that typically\ncharacterize social network graphs. Deep hierarchical decompositions are also\namenable to domain compression, a technique that reduces both space and time\ncomplexity by exploiting symmetries. We show empirically that our approach is\ncompetitive with current state-of-the-art graph classification methods,\nparticularly when dealing with social network datasets.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 09:52:48 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Orsini", "Francesco", ""], ["Baracchi", "Daniele", ""], ["Frasconi", "Paolo", ""]]}, {"id": "1703.05561", "submitter": "Erwin Quiring", "authors": "Erwin Quiring, Daniel Arp, Konrad Rieck", "title": "Fraternal Twins: Unifying Attacks on Machine Learning and Digital\n  Watermarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is increasingly used in security-critical applications, such\nas autonomous driving, face recognition and malware detection. Most learning\nmethods, however, have not been designed with security in mind and thus are\nvulnerable to different types of attacks. This problem has motivated the\nresearch field of adversarial machine learning that is concerned with attacking\nand defending learning methods. Concurrently, a different line of research has\ntackled a very similar problem: In digital watermarking information are\nembedded in a signal in the presence of an adversary. As a consequence, this\nresearch field has also extensively studied techniques for attacking and\ndefending watermarking methods.\n  The two research communities have worked in parallel so far, unnoticeably\ndeveloping similar attack and defense strategies. This paper is a first effort\nto bring these communities together. To this end, we present a unified notation\nof black-box attacks against machine learning and watermarking that reveals the\nsimilarity of both settings. To demonstrate the efficacy of this unified view,\nwe apply concepts from watermarking to machine learning and vice versa. We show\nthat countermeasures from watermarking can mitigate recent model-extraction\nattacks and, similarly, that techniques for hardening machine learning can fend\noff oracle attacks against watermarks. Our work provides a conceptual link\nbetween two research fields and thereby opens novel directions for improving\nthe security of both, machine learning and digital watermarking.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 11:15:28 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Quiring", "Erwin", ""], ["Arp", "Daniel", ""], ["Rieck", "Konrad", ""]]}, {"id": "1703.05593", "submitter": "Ignacio Rocco", "authors": "Ignacio Rocco, Relja Arandjelovi\\'c, Josef Sivic", "title": "Convolutional neural network architecture for geometric matching", "comments": "In 2017 IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of determining correspondences between two images in\nagreement with a geometric model such as an affine or thin-plate spline\ntransformation, and estimating its parameters. The contributions of this work\nare three-fold. First, we propose a convolutional neural network architecture\nfor geometric matching. The architecture is based on three main components that\nmimic the standard steps of feature extraction, matching and simultaneous\ninlier detection and model parameter estimation, while being trainable\nend-to-end. Second, we demonstrate that the network parameters can be trained\nfrom synthetically generated imagery without the need for manual annotation and\nthat our matching layer significantly increases generalization capabilities to\nnever seen before images. Finally, we show that the same model can perform both\ninstance-level and category-level matching giving state-of-the-art results on\nthe challenging Proposal Flow dataset.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 13:03:54 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 22:32:43 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Rocco", "Ignacio", ""], ["Arandjelovi\u0107", "Relja", ""], ["Sivic", "Josef", ""]]}, {"id": "1703.05667", "submitter": "David Belanger", "authors": "David Belanger, Bishan Yang, Andrew McCallum", "title": "End-to-End Learning for Structured Prediction Energy Networks", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured Prediction Energy Networks (SPENs) are a simple, yet expressive\nfamily of structured prediction models (Belanger and McCallum, 2016). An energy\nfunction over candidate structured outputs is given by a deep network, and\npredictions are formed by gradient-based optimization. This paper presents\nend-to-end learning for SPENs, where the energy function is discriminatively\ntrained by back-propagating through gradient-based prediction. In our\nexperience, the approach is substantially more accurate than the structured SVM\nmethod of Belanger and McCallum (2016), as it allows us to use more\nsophisticated non-convex energies. We provide a collection of techniques for\nimproving the speed, accuracy, and memory requirements of end-to-end SPENs, and\ndemonstrate the power of our method on 7-Scenes image denoising and CoNLL-2005\nsemantic role labeling tasks. In both, inexact minimization of non-convex SPEN\nenergies is superior to baseline methods that use simplistic energy functions\nthat can be minimized exactly.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 15:14:48 GMT"}, {"version": "v2", "created": "Sat, 15 Jul 2017 04:50:13 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Belanger", "David", ""], ["Yang", "Bishan", ""], ["McCallum", "Andrew", ""]]}, {"id": "1703.05698", "submitter": "Vijayaraghavan Murali", "authors": "Vijayaraghavan Murali, Letao Qi, Swarat Chaudhuri, Chris Jermaine", "title": "Neural Sketch Learning for Conditional Program Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of generating source code in a strongly typed, Java-like\nprogramming language, given a label (for example a set of API calls or types)\ncarrying a small amount of information about the code that is desired. The\ngenerated programs are expected to respect a \"realistic\" relationship between\nprograms and labels, as exemplified by a corpus of labeled programs available\nduring training.\n  Two challenges in such conditional program generation are that the generated\nprograms must satisfy a rich set of syntactic and semantic constraints, and\nthat source code contains many low-level features that impede learning. We\naddress these problems by training a neural generator not on code but on\nprogram sketches, or models of program syntax that abstract out names and\noperations that do not generalize across programs. During generation, we infer\na posterior distribution over sketches, then concretize samples from this\ndistribution into type-safe programs using combinatorial techniques. We\nimplement our ideas in a system for generating API-heavy Java code, and show\nthat it can often predict the entire body of a method given just a few API\ncalls or data types that appear in the method.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 16:23:30 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 18:29:10 GMT"}, {"version": "v3", "created": "Mon, 17 Jul 2017 02:29:37 GMT"}, {"version": "v4", "created": "Mon, 15 Jan 2018 18:31:54 GMT"}, {"version": "v5", "created": "Thu, 12 Apr 2018 19:09:05 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Murali", "Vijayaraghavan", ""], ["Qi", "Letao", ""], ["Chaudhuri", "Swarat", ""], ["Jermaine", "Chris", ""]]}, {"id": "1703.05820", "submitter": "Chris J. Maddison", "authors": "Chris J. Maddison, Dieterich Lawson, George Tucker, Nicolas Heess,\n  Arnaud Doucet, Andriy Mnih, Yee Whye Teh", "title": "Particle Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The policy gradients of the expected return objective can react slowly to\nrare rewards. Yet, in some cases agents may wish to emphasize the low or high\nreturns regardless of their probability. Borrowing from the economics and\ncontrol literature, we review the risk-sensitive value function that arises\nfrom an exponential utility and illustrate its effects on an example. This\nrisk-sensitive value function is not always applicable to reinforcement\nlearning problems, so we introduce the particle value function defined by a\nparticle filter over the distributions of an agent's experience, which bounds\nthe risk-sensitive one. We illustrate the benefit of the policy gradients of\nthis objective in Cliffworld.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 21:08:31 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Maddison", "Chris J.", ""], ["Lawson", "Dieterich", ""], ["Tucker", "George", ""], ["Heess", "Nicolas", ""], ["Doucet", "Arnaud", ""], ["Mnih", "Andriy", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1703.05830", "submitter": "Mohammad Sadegh Norouzzadeh", "authors": "Mohammed Sadegh Norouzzadeh, Anh Nguyen, Margaret Kosmala, Ali\n  Swanson, Meredith Palmer, Craig Packer, Jeff Clune", "title": "Automatically identifying, counting, and describing wild animals in\n  camera-trap images with deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having accurate, detailed, and up-to-date information about the location and\nbehavior of animals in the wild would revolutionize our ability to study and\nconserve ecosystems. We investigate the ability to automatically, accurately,\nand inexpensively collect such data, which could transform many fields of\nbiology, ecology, and zoology into \"big data\" sciences. Motion sensor \"camera\ntraps\" enable collecting wildlife pictures inexpensively, unobtrusively, and\nfrequently. However, extracting information from these pictures remains an\nexpensive, time-consuming, manual task. We demonstrate that such information\ncan be automatically extracted by deep learning, a cutting-edge type of\nartificial intelligence. We train deep convolutional neural networks to\nidentify, count, and describe the behaviors of 48 species in the\n3.2-million-image Snapshot Serengeti dataset. Our deep neural networks\nautomatically identify animals with over 93.8% accuracy, and we expect that\nnumber to improve rapidly in years to come. More importantly, if our system\nclassifies only images it is confident about, our system can automate animal\nidentification for 99.3% of the data while still performing at the same 96.6%\naccuracy as that of crowdsourced teams of human volunteers, saving more than\n8.4 years (at 40 hours per week) of human labeling effort (i.e. over 17,000\nhours) on this 3.2-million-image dataset. Those efficiency gains immediately\nhighlight the importance of using deep neural networks to automate data\nextraction from camera-trap images. Our results suggest that this technology\ncould enable the inexpensive, unobtrusive, high-volume, and even real-time\ncollection of a wealth of information about vast numbers of animals in the\nwild.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 21:35:15 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 00:45:55 GMT"}, {"version": "v3", "created": "Thu, 30 Mar 2017 22:24:19 GMT"}, {"version": "v4", "created": "Wed, 5 Apr 2017 04:26:20 GMT"}, {"version": "v5", "created": "Wed, 15 Nov 2017 19:29:24 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Norouzzadeh", "Mohammed Sadegh", ""], ["Nguyen", "Anh", ""], ["Kosmala", "Margaret", ""], ["Swanson", "Ali", ""], ["Palmer", "Meredith", ""], ["Packer", "Craig", ""], ["Clune", "Jeff", ""]]}, {"id": "1703.05840", "submitter": "Yi Zhou", "authors": "Guanghui Lan, Sebastian Pokutta, Yi Zhou and Daniel Zink", "title": "Conditional Accelerated Lazy Stochastic Gradient Descent", "comments": "37 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a conditional accelerated lazy stochastic gradient\ndescent algorithm with optimal number of calls to a stochastic first-order\noracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^2}\\right)$ improving\nover the projection-free, Online Frank-Wolfe based stochastic gradient descent\nof Hazan and Kale [2012] with convergence rate\n$O\\left(\\frac{1}{\\varepsilon^4}\\right)$.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 22:15:17 GMT"}, {"version": "v2", "created": "Fri, 24 Mar 2017 20:28:16 GMT"}, {"version": "v3", "created": "Wed, 5 Apr 2017 13:24:06 GMT"}, {"version": "v4", "created": "Mon, 10 Apr 2017 16:43:11 GMT"}, {"version": "v5", "created": "Thu, 15 Feb 2018 23:36:11 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Lan", "Guanghui", ""], ["Pokutta", "Sebastian", ""], ["Zhou", "Yi", ""], ["Zink", "Daniel", ""]]}, {"id": "1703.05880", "submitter": "Lei Xie", "authors": "Wenpeng Li, BinBin Zhang, Lei Xie, Dong Yu", "title": "Empirical Evaluation of Parallel Training Algorithms on Acoustic\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models (DLMs) are state-of-the-art techniques in speech\nrecognition. However, training good DLMs can be time consuming especially for\nproduction-size models and corpora. Although several parallel training\nalgorithms have been proposed to improve training efficiency, there is no clear\nguidance on which one to choose for the task in hand due to lack of systematic\nand fair comparison among them. In this paper we aim at filling this gap by\ncomparing four popular parallel training algorithms in speech recognition,\nnamely asynchronous stochastic gradient descent (ASGD), blockwise model-update\nfiltering (BMUF), bulk synchronous parallel (BSP) and elastic averaging\nstochastic gradient descent (EASGD), on 1000-hour LibriSpeech corpora using\nfeed-forward deep neural networks (DNNs) and convolutional, long short-term\nmemory, DNNs (CLDNNs). Based on our experiments, we recommend using BMUF as the\ntop choice to train acoustic models since it is most stable, scales well with\nnumber of GPUs, can achieve reproducible results, and in many cases even\noutperforms single-GPU SGD. ASGD can be used as a substitute in some cases.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 03:38:48 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 06:29:54 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Li", "Wenpeng", ""], ["Zhang", "BinBin", ""], ["Xie", "Lei", ""], ["Yu", "Dong", ""]]}, {"id": "1703.05908", "submitter": "Yao-Hung Tsai", "authors": "Yao-Hung Hubert Tsai and Liang-Kang Huang and Ruslan Salakhutdinov", "title": "Learning Robust Visual-Semantic Embeddings", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the existing methods for learning joint embedding of images and text\nuse only supervised information from paired images and its textual attributes.\nTaking advantage of the recent success of unsupervised learning in deep neural\nnetworks, we propose an end-to-end learning framework that is able to extract\nmore robust multi-modal representations across domains. The proposed method\ncombines representation learning models (i.e., auto-encoders) together with\ncross-domain learning criteria (i.e., Maximum Mean Discrepancy loss) to learn\njoint embeddings for semantic and visual features. A novel technique of\nunsupervised-data adaptation inference is introduced to construct more\ncomprehensive embeddings for both labeled and unlabeled data. We evaluate our\nmethod on Animals with Attributes and Caltech-UCSD Birds 200-2011 dataset with\na wide range of applications, including zero and few-shot image recognition and\nretrieval, from inductive to transductive settings. Empirically, we show that\nour framework improves over the current state of the art on many of the\nconsidered tasks.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 06:59:51 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 00:28:07 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Huang", "Liang-Kang", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1703.05921", "submitter": "Thomas Schlegl", "authors": "Thomas Schlegl, Philipp Seeb\\\"ock, Sebastian M. Waldstein, Ursula\n  Schmidt-Erfurth, Georg Langs", "title": "Unsupervised Anomaly Detection with Generative Adversarial Networks to\n  Guide Marker Discovery", "comments": "To be published in the proceedings of the international conference on\n  Information Processing in Medical Imaging (IPMI), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining models that capture imaging markers relevant for disease\nprogression and treatment monitoring is challenging. Models are typically based\non large amounts of data with annotated examples of known markers aiming at\nautomating detection. High annotation effort and the limitation to a vocabulary\nof known markers limit the power of such approaches. Here, we perform\nunsupervised learning to identify anomalies in imaging data as candidates for\nmarkers. We propose AnoGAN, a deep convolutional generative adversarial network\nto learn a manifold of normal anatomical variability, accompanying a novel\nanomaly scoring scheme based on the mapping from image space to a latent space.\nApplied to new data, the model labels anomalies, and scores image patches\nindicating their fit into the learned distribution. Results on optical\ncoherence tomography images of the retina demonstrate that the approach\ncorrectly identifies anomalous images, such as images containing retinal fluid\nor hyperreflective foci.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 08:27:05 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Schlegl", "Thomas", ""], ["Seeb\u00f6ck", "Philipp", ""], ["Waldstein", "Sebastian M.", ""], ["Schmidt-Erfurth", "Ursula", ""], ["Langs", "Georg", ""]]}, {"id": "1703.05990", "submitter": "P\\'eter B\\'andi", "authors": "P\\'eter B\\'andi, Rob van de Loo, Milad Intezar, Daan Geijs, Francesco\n  Ciompi, Bram van Ginneken, Jeroen van der Laak, Geert Litjens", "title": "Comparison of Different Methods for Tissue Segmentation in\n  Histopathological Whole-Slide Images", "comments": "Accepted for poster presentation at the IEEE International Symposium\n  on Biomedical Imaging (ISBI) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tissue segmentation is an important pre-requisite for efficient and accurate\ndiagnostics in digital pathology. However, it is well known that whole-slide\nscanners can fail in detecting all tissue regions, for example due to the\ntissue type, or due to weak staining because their tissue detection algorithms\nare not robust enough. In this paper, we introduce two different convolutional\nneural network architectures for whole slide image segmentation to accurately\nidentify the tissue sections. We also compare the algorithms to a published\ntraditional method. We collected 54 whole slide images with differing stains\nand tissue types from three laboratories to validate our algorithms. We show\nthat while the two methods do not differ significantly they outperform their\ntraditional counterpart (Jaccard index of 0.937 and 0.929 vs. 0.870, p < 0.01).\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 12:32:25 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 17:46:32 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["B\u00e1ndi", "P\u00e9ter", ""], ["van de Loo", "Rob", ""], ["Intezar", "Milad", ""], ["Geijs", "Daan", ""], ["Ciompi", "Francesco", ""], ["van Ginneken", "Bram", ""], ["van der Laak", "Jeroen", ""], ["Litjens", "Geert", ""]]}, {"id": "1703.06060", "submitter": "Jie Xu", "authors": "Jie Xu, Lixing Chen, Shaolei Ren", "title": "Online Learning for Offloading and Autoscaling in Energy Harvesting\n  Mobile Edge Computing", "comments": "arXiv admin note: text overlap with arXiv:1701.01090 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing (a.k.a. fog computing) has recently emerged to enable\nin-situ processing of delay-sensitive applications at the edge of mobile\nnetworks. Providing grid power supply in support of mobile edge computing,\nhowever, is costly and even infeasible (in certain rugged or under-developed\nareas), thus mandating on-site renewable energy as a major or even sole power\nsupply in increasingly many scenarios. Nonetheless, the high intermittency and\nunpredictability of renewable energy make it very challenging to deliver a high\nquality of service to users in energy harvesting mobile edge computing systems.\nIn this paper, we address the challenge of incorporating renewables into mobile\nedge computing and propose an efficient reinforcement learning-based resource\nmanagement algorithm, which learns on-the-fly the optimal policy of dynamic\nworkload offloading (to the centralized cloud) and edge server provisioning to\nminimize the long-term system cost (including both service delay and\noperational cost). Our online learning algorithm uses a decomposition of the\n(offline) value iteration and (online) reinforcement learning, thus achieving a\nsignificant improvement of learning rate and run-time performance when compared\nto standard reinforcement learning algorithms such as Q-learning. We prove the\nconvergence of the proposed algorithm and analytically show that the learned\npolicy has a simple monotone structure amenable to practical implementation.\nOur simulation results validate the efficacy of our algorithm, which\nsignificantly improves the edge computing performance compared to fixed or\nmyopic optimization schemes and conventional reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 15:54:36 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Xu", "Jie", ""], ["Chen", "Lixing", ""], ["Ren", "Shaolei", ""]]}, {"id": "1703.06065", "submitter": "Urvashi Oswal", "authors": "Urvashi Oswal, Swayambhoo Jain, Kevin S. Xu, and Brian Eriksson", "title": "Block CUR: Decomposing Matrices using Groups of Columns", "comments": "shorter version to appear in ECML-PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem in large-scale data analysis is to approximate a matrix\nusing a combination of specifically sampled rows and columns, known as CUR\ndecomposition. Unfortunately, in many real-world environments, the ability to\nsample specific individual rows or columns of the matrix is limited by either\nsystem constraints or cost. In this paper, we consider matrix approximation by\nsampling predefined \\emph{blocks} of columns (or rows) from the matrix. We\npresent an algorithm for sampling useful column blocks and provide novel\nguarantees for the quality of the approximation. This algorithm has application\nin problems as diverse as biometric data analysis to distributed computing. We\ndemonstrate the effectiveness of the proposed algorithms for computing the\nBlock CUR decomposition of large matrices in a distributed setting with\nmultiple nodes in a compute cluster, where such blocks correspond to columns\n(or rows) of the matrix stored on the same node, which can be retrieved with\nmuch less overhead than retrieving individual columns stored across different\nnodes. In the biometric setting, the rows correspond to different users and\ncolumns correspond to users' biometric reaction to external stimuli, {\\em\ne.g.,}~watching video content, at a particular time instant. There is\nsignificant cost in acquiring each user's reaction to lengthy content so we\nsample a few important scenes to approximate the biometric response. An\nindividual time sample in this use case cannot be queried in isolation due to\nthe lack of context that caused that biometric reaction. Instead, collections\nof time segments ({\\em i.e.,} blocks) must be presented to the user. The\npractical application of these algorithms is shown via experimental results\nusing real-world user biometric data from a content testing environment.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 16:08:23 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 14:27:52 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Oswal", "Urvashi", ""], ["Jain", "Swayambhoo", ""], ["Xu", "Kevin S.", ""], ["Eriksson", "Brian", ""]]}, {"id": "1703.06076", "submitter": "Halim Abbas", "authors": "Halim Abbas, Ford Garberson, Eric Glover, Dennis P Wall", "title": "Machine learning approach for early detection of autism by combining\n  questionnaire and home video screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing screening tools for early detection of autism are expensive,\ncumbersome, time-intensive, and sometimes fall short in predictive value. In\nthis work, we apply Machine Learning (ML) to gold standard clinical data\nobtained across thousands of children at risk for autism spectrum disorders to\ncreate a low-cost, quick, and easy to apply autism screening tool that performs\nas well or better than most widely used standardized instruments. This new tool\ncombines two screening methods into a single assessment, one based on short,\nstructured parent-report questionnaires and the other on tagging key behaviors\nfrom short, semi-structured home videos of children. To overcome the scarcity,\nsparsity, and imbalance of training data, we apply creative feature selection,\nfeature engineering, and novel feature encoding techniques. We allow for\ninconclusive determination where appropriate in order to boost screening\naccuracy when conclusive. We demonstrate a significant accuracy improvement\nover standard screening tools in a clinical study sample of 162 children.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 22:37:41 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Abbas", "Halim", ""], ["Garberson", "Ford", ""], ["Glover", "Eric", ""], ["Wall", "Dennis P", ""]]}, {"id": "1703.06103", "submitter": "Thomas Kipf", "authors": "Michael Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den\n  Berg, Ivan Titov, Max Welling", "title": "Modeling Relational Data with Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs enable a wide variety of applications, including question\nanswering and information retrieval. Despite the great effort invested in their\ncreation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata)\nremain incomplete. We introduce Relational Graph Convolutional Networks\n(R-GCNs) and apply them to two standard knowledge base completion tasks: Link\nprediction (recovery of missing facts, i.e. subject-predicate-object triples)\nand entity classification (recovery of missing entity attributes). R-GCNs are\nrelated to a recent class of neural networks operating on graphs, and are\ndeveloped specifically to deal with the highly multi-relational data\ncharacteristic of realistic knowledge bases. We demonstrate the effectiveness\nof R-GCNs as a stand-alone model for entity classification. We further show\nthat factorization models for link prediction such as DistMult can be\nsignificantly improved by enriching them with an encoder model to accumulate\nevidence over multiple inference steps in the relational graph, demonstrating a\nlarge improvement of 29.8% on FB15k-237 over a decoder-only baseline.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 17:09:14 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 13:43:41 GMT"}, {"version": "v3", "created": "Tue, 6 Jun 2017 15:49:12 GMT"}, {"version": "v4", "created": "Thu, 26 Oct 2017 19:53:49 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Schlichtkrull", "Michael", ""], ["Kipf", "Thomas N.", ""], ["Bloem", "Peter", ""], ["Berg", "Rianne van den", ""], ["Titov", "Ivan", ""], ["Welling", "Max", ""]]}, {"id": "1703.06104", "submitter": "Shuang Qiu", "authors": "Shuang Qiu and Tingjin Luo and Jieping Ye and Ming Lin", "title": "Nonconvex One-bit Single-label Multi-label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an extreme scenario in multi-label learning where each training\ninstance is endowed with a single one-bit label out of multiple labels. We\nformulate this problem as a non-trivial special case of one-bit rank-one matrix\nsensing and develop an efficient non-convex algorithm based on alternating\npower iteration. The proposed algorithm is able to recover the underlying\nlow-rank matrix model with linear convergence. For a rank-$k$ model with $d_1$\nfeatures and $d_2$ classes, the proposed algorithm achieves $O(\\epsilon)$\nrecovery error after retrieving $O(k^{1.5}d_1 d_2/\\epsilon)$ one-bit labels\nwithin $O(kd)$ memory. Our bound is nearly optimal in the order of\n$O(1/\\epsilon)$. This significantly improves the state-of-the-art sampling\ncomplexity of one-bit multi-label learning. We perform experiments to verify\nour theory and evaluate the performance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 17:09:15 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Qiu", "Shuang", ""], ["Luo", "Tingjin", ""], ["Ye", "Jieping", ""], ["Lin", "Ming", ""]]}, {"id": "1703.06114", "submitter": "Manzil Zaheer", "authors": "Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos,\n  Ruslan Salakhutdinov, Alexander Smola", "title": "Deep Sets", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of designing models for machine learning tasks defined\non \\emph{sets}. In contrast to traditional approach of operating on fixed\ndimensional vectors, we consider objective functions defined on sets that are\ninvariant to permutations. Such problems are widespread, ranging from\nestimation of population statistics \\cite{poczos13aistats}, to anomaly\ndetection in piezometer data of embankment dams \\cite{Jung15Exploration}, to\ncosmology \\cite{Ntampaka16Dynamical,Ravanbakhsh16ICML1}. Our main theorem\ncharacterizes the permutation invariant functions and provides a family of\nfunctions to which any permutation invariant objective function must belong.\nThis family of functions has a special structure which enables us to design a\ndeep network architecture that can operate on sets and which can be deployed on\na variety of scenarios including both unsupervised and supervised learning\ntasks. We also derive the necessary and sufficient conditions for permutation\nequivariance in deep models. We demonstrate the applicability of our method on\npopulation statistic estimation, point cloud classification, set expansion, and\noutlier detection.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 21:02:53 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 16:04:56 GMT"}, {"version": "v3", "created": "Sat, 14 Apr 2018 18:54:19 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Zaheer", "Manzil", ""], ["Kottur", "Satwik", ""], ["Ravanbakhsh", "Siamak", ""], ["Poczos", "Barnabas", ""], ["Salakhutdinov", "Ruslan", ""], ["Smola", "Alexander", ""]]}, {"id": "1703.06180", "submitter": "Tobias Schnabel", "authors": "Aman Agarwal, Soumya Basu, Tobias Schnabel, Thorsten Joachims", "title": "Effective Evaluation using Logged Bandit Feedback from Multiple Loggers", "comments": "KDD 2018", "journal-ref": null, "doi": "10.1145/3097983.3098155", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately evaluating new policies (e.g. ad-placement models, ranking\nfunctions, recommendation functions) is one of the key prerequisites for\nimproving interactive systems. While the conventional approach to evaluation\nrelies on online A/B tests, recent work has shown that counterfactual\nestimators can provide an inexpensive and fast alternative, since they can be\napplied offline using log data that was collected from a different policy\nfielded in the past. In this paper, we address the question of how to estimate\nthe performance of a new target policy when we have log data from multiple\nhistoric policies. This question is of great relevance in practice, since\npolicies get updated frequently in most online systems. We show that naively\ncombining data from multiple logging policies can be highly suboptimal. In\nparticular, we find that the standard Inverse Propensity Score (IPS) estimator\nsuffers especially when logging and target policies diverge -- to a point where\nthrowing away data improves the variance of the estimator. We therefore propose\ntwo alternative estimators which we characterize theoretically and compare\nexperimentally. We find that the new estimators can provide substantially\nimproved estimation accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 19:29:36 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 11:52:23 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Agarwal", "Aman", ""], ["Basu", "Soumya", ""], ["Schnabel", "Tobias", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1703.06182", "submitter": "Shayegan Omidshafiei", "authors": "Shayegan Omidshafiei, Jason Pazis, Christopher Amato, Jonathan P. How,\n  John Vian", "title": "Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under\n  Partial Observability", "comments": "Accepted to ICML 2017", "journal-ref": "Proceedings of the 34th International Conference on Machine\n  Learning (ICML 2017), Sydney, Australia, PMLR 70:2681-2690, 2017", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world tasks involve multiple agents with partial observability and\nlimited communication. Learning is challenging in these settings due to local\nviewpoints of agents, which perceive the world as non-stationary due to\nconcurrently-exploring teammates. Approaches that learn specialized policies\nfor individual tasks face problems when applied to the real world: not only do\nagents have to learn and store distinct policies for each task, but in practice\nidentities of tasks are often non-observable, making these approaches\ninapplicable. This paper formalizes and addresses the problem of multi-task\nmulti-agent reinforcement learning under partial observability. We introduce a\ndecentralized single-task learning approach that is robust to concurrent\ninteractions of teammates, and present an approach for distilling single-task\npolicies into a unified policy that performs well across multiple related\ntasks, without explicit provision of task identity.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 19:32:38 GMT"}, {"version": "v2", "created": "Sat, 25 Mar 2017 15:54:36 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 16:09:39 GMT"}, {"version": "v4", "created": "Thu, 13 Jul 2017 17:34:34 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Omidshafiei", "Shayegan", ""], ["Pazis", "Jason", ""], ["Amato", "Christopher", ""], ["How", "Jonathan P.", ""], ["Vian", "John", ""]]}, {"id": "1703.06217", "submitter": "Mason McGill", "authors": "Mason McGill and Pietro Perona", "title": "Deciding How to Decide: Dynamic Routing in Artificial Neural Networks", "comments": "ICML 2017. Code at https://github.com/MasonMcGill/multipath-nn Video\n  abstract at https://youtu.be/NHQsDaycwyQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and systematically evaluate three strategies for training\ndynamically-routed artificial neural networks: graphs of learned\ntransformations through which different input signals may take different paths.\nThough some approaches have advantages over others, the resulting networks are\noften qualitatively similar. We find that, in dynamically-routed networks\ntrained to classify images, layers and branches become specialized to process\ndistinct categories of images. Additionally, given a fixed computational\nbudget, dynamically-routed networks tend to perform better than comparable\nstatically-routed networks.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 23:52:14 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 22:14:36 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["McGill", "Mason", ""], ["Perona", "Pietro", ""]]}, {"id": "1703.06229", "submitter": "Jacopo Cavazza", "authors": "Pietro Morerio, Jacopo Cavazza, Riccardo Volpi, Rene Vidal, Vittorio\n  Murino", "title": "Curriculum Dropout", "comments": "Accepted at ICCV (International Conference on Computer Vision) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a very effective way of regularizing neural networks.\nStochastically \"dropping out\" units with a certain probability discourages\nover-specific co-adaptations of feature detectors, preventing overfitting and\nimproving network generalization. Besides, Dropout can be interpreted as an\napproximate model aggregation technique, where an exponential number of smaller\nnetworks are averaged in order to get a more powerful ensemble. In this paper,\nwe show that using a fixed dropout probability during training is a suboptimal\nchoice. We thus propose a time scheduling for the probability of retaining\nneurons in the network. This induces an adaptive regularization scheme that\nsmoothly increases the difficulty of the optimization problem. This idea of\n\"starting easy\" and adaptively increasing the difficulty of the learning\nproblem has its roots in curriculum learning and allows one to train better\nmodels. Indeed, we prove that our optimization strategy implements a very\ngeneral curriculum scheme, by gradually adding noise to both the input and\nintermediate feature representations within the network architecture.\nExperiments on seven image classification datasets and different network\narchitectures show that our method, named Curriculum Dropout, frequently yields\nto better generalization and, at worst, performs just as well as the standard\nDropout method.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 00:59:40 GMT"}, {"version": "v2", "created": "Thu, 3 Aug 2017 06:27:09 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Morerio", "Pietro", ""], ["Cavazza", "Jacopo", ""], ["Volpi", "Riccardo", ""], ["Vidal", "Rene", ""], ["Murino", "Vittorio", ""]]}, {"id": "1703.06272", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Guodong Wang and Radu Grosu", "title": "An Automated Auto-encoder Correlation-based Health-Monitoring and\n  Prognostic Method for Machine Bearings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies an intelligent ultimate technique for health-monitoring\nand prognostic of common rotary machine components, particularly bearings.\nDuring a run-to-failure experiment, rich unsupervised features from vibration\nsensory data are extracted by a trained sparse auto-encoder. Then, the\ncorrelation of the extracted attributes of the initial samples (presumably\nhealthy at the beginning of the test) with the succeeding samples is calculated\nand passed through a moving-average filter. The normalized output is named\nauto-encoder correlation-based (AEC) rate which stands for an informative\nattribute of the system depicting its health status and precisely identifying\nthe degradation starting point. We show that AEC technique well-generalizes in\nseveral run-to-failure tests. AEC collects rich unsupervised features form the\nvibration data fully autonomous. We demonstrate the superiority of the AEC over\nmany other state-of-the-art approaches for the health monitoring and prognostic\nof machine bearings.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 08:38:51 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Wang", "Guodong", ""], ["Grosu", "Radu", ""]]}, {"id": "1703.06284", "submitter": "Morten Kolb{\\ae}k", "authors": "Morten Kolb{\\ae}k, Dong Yu, Zheng-Hua Tan, Jesper Jensen", "title": "Multi-talker Speech Separation with Utterance-level Permutation\n  Invariant Training of Deep Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the utterance-level Permutation Invariant Training\n(uPIT) technique. uPIT is a practically applicable, end-to-end, deep learning\nbased solution for speaker independent multi-talker speech separation.\nSpecifically, uPIT extends the recently proposed Permutation Invariant Training\n(PIT) technique with an utterance-level cost function, hence eliminating the\nneed for solving an additional permutation problem during inference, which is\notherwise required by frame-level PIT. We achieve this using Recurrent Neural\nNetworks (RNNs) that, during training, minimize the utterance-level separation\nerror, hence forcing separated frames belonging to the same speaker to be\naligned to the same output stream. In practice, this allows RNNs, trained with\nuPIT, to separate multi-talker mixed speech without any prior knowledge of\nsignal duration, number of speakers, speaker identity or gender. We evaluated\nuPIT on the WSJ0 and Danish two- and three-talker mixed-speech separation tasks\nand found that uPIT outperforms techniques based on Non-negative Matrix\nFactorization (NMF) and Computational Auditory Scene Analysis (CASA), and\ncompares favorably with Deep Clustering (DPCL) and the Deep Attractor Network\n(DANet). Furthermore, we found that models trained with uPIT generalize well to\nunseen speakers and languages. Finally, we found that a single model, trained\nwith uPIT, can handle both two-speaker, and three-speaker speech mixtures.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 10:59:03 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 12:02:01 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Kolb\u00e6k", "Morten", ""], ["Yu", "Dong", ""], ["Tan", "Zheng-Hua", ""], ["Jensen", "Jesper", ""]]}, {"id": "1703.06324", "submitter": "Biswa Sengupta", "authors": "B Sengupta and E Vasquez and Y Qian", "title": "Deep Tensor Encoding", "comments": "KDD Workshop on ML meets Fashion 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning an encoding of feature vectors in terms of an over-complete\ndictionary or a information geometric (Fisher vectors) construct is wide-spread\nin statistical signal processing and computer vision. In content based\ninformation retrieval using deep-learning classifiers, such encodings are\nlearnt on the flattened last layer, without adherence to the multi-linear\nstructure of the underlying feature tensor. We illustrate a variety of feature\nencodings incl. sparse dictionary coding and Fisher vectors along with\nproposing that a structured tensor factorization scheme enables us to perform\nretrieval that can be at par, in terms of average precision, with Fisher vector\nencoded image signatures. In short, we illustrate how structural constraints\nincrease retrieval fidelity.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 17:49:42 GMT"}, {"version": "v2", "created": "Sun, 12 Nov 2017 09:08:48 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Sengupta", "B", ""], ["Vasquez", "E", ""], ["Qian", "Y", ""]]}, {"id": "1703.06327", "submitter": "Sewoong Oh", "authors": "Ashish Khetan, Sewoong Oh", "title": "Spectrum Estimation from a Few Entries", "comments": "52 pages; 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular values of a data in a matrix form provide insights on the structure\nof the data, the effective dimensionality, and the choice of hyper-parameters\non higher-level data analysis tools. However, in many practical applications\nsuch as collaborative filtering and network analysis, we only get a partial\nobservation. Under such scenarios, we consider the fundamental problem of\nrecovering spectral properties of the underlying matrix from a sampling of its\nentries. We are particularly interested in directly recovering the spectrum,\nwhich is the set of singular values, and also in sample-efficient approaches\nfor recovering a spectral sum function, which is an aggregate sum of the same\nfunction applied to each of the singular values. We propose first estimating\nthe Schatten $k$-norms of a matrix, and then applying Chebyshev approximation\nto the spectral sum function or applying moment matching in Wasserstein\ndistance to recover the singular values. The main technical challenge is in\naccurately estimating the Schatten norms from a sampling of a matrix. We\nintroduce a novel unbiased estimator based on counting small structures in a\ngraph and provide guarantees that match its empirical performance. Our\ntheoretical analysis shows that Schatten norms can be recovered accurately from\nstrictly smaller number of samples compared to what is needed to recover the\nunderlying low-rank matrix. Numerical experiments suggest that we significantly\nimprove upon a competing approach of using matrix completion methods.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 18:12:17 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Khetan", "Ashish", ""], ["Oh", "Sewoong", ""]]}, {"id": "1703.06345", "submitter": "Zhilin Yang", "authors": "Zhilin Yang, Ruslan Salakhutdinov, William W. Cohen", "title": "Transfer Learning for Sequence Tagging with Hierarchical Recurrent\n  Networks", "comments": "Accepted as a conference paper at ICLR 2017. This is an extended\n  version of the original paper (https://arxiv.org/abs/1603.06270). The\n  original paper proposes a new architecture, while this version focuses on\n  transfer learning for a general model class", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent papers have shown that neural networks obtain state-of-the-art\nperformance on several different sequence tagging tasks. One appealing property\nof such systems is their generality, as excellent performance can be achieved\nwith a unified architecture and without task-specific feature engineering.\nHowever, it is unclear if such systems can be used for tasks without large\namounts of training data. In this paper we explore the problem of transfer\nlearning for neural sequence taggers, where a source task with plentiful\nannotations (e.g., POS tagging on Penn Treebank) is used to improve performance\non a target task with fewer available annotations (e.g., POS tagging for\nmicroblogs). We examine the effects of transfer learning for deep hierarchical\nrecurrent networks across domains, applications, and languages, and show that\nsignificant improvement can often be obtained. These improvements lead to\nimprovements over the current state-of-the-art on several well-studied tasks.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 20:21:44 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Yang", "Zhilin", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "1703.06367", "submitter": "Annie Liang", "authors": "Annie Liang, Xiaosheng Mu, Vasilis Syrgkanis", "title": "Optimal and Myopic Information Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimal dynamic information acquisition from many\ncorrelated information sources. Each period, the decision-maker jointly takes\nan action and allocates a fixed number of observations across the available\nsources. His payoff depends on the actions taken and on an unknown state. In\nthe canonical setting of jointly normal information sources, we show that the\noptimal dynamic information acquisition rule proceeds myopically after finitely\nmany periods. If signals are acquired in large blocks each period, then the\noptimal rule turns out to be myopic from period 1. These results demonstrate\nthe possibility of robust and \"simple\" optimal information acquisition, and\nsimplify the analysis of dynamic information acquisition in a widely used\ninformational environment.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 23:22:23 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 18:47:43 GMT"}, {"version": "v3", "created": "Mon, 14 Aug 2017 21:45:31 GMT"}, {"version": "v4", "created": "Mon, 14 May 2018 13:01:06 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Liang", "Annie", ""], ["Mu", "Xiaosheng", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1703.06426", "submitter": "Nir Rosenfeld", "authors": "Nir Rosenfeld and Amir Globerson", "title": "Semi-Supervised Learning with Competitive Infection Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal in semi-supervised learning is to effectively combine labeled and\nunlabeled data. One way to do this is by encouraging smoothness across edges in\na graph whose nodes correspond to input examples. In many graph-based methods,\nlabels can be thought of as propagating over the graph, where the underlying\npropagation mechanism is based on random walks or on averaging dynamics. While\ntheoretically elegant, these dynamics suffer from several drawbacks which can\nhurt predictive performance.\n  Our goal in this work is to explore alternative mechanisms for propagating\nlabels. In particular, we propose a method based on dynamic infection\nprocesses, where unlabeled nodes can be \"infected\" with the label of their\nalready infected neighbors. Our algorithm is efficient and scalable, and an\nanalysis of the underlying optimization objective reveals a surprising relation\nto other Laplacian approaches. We conclude with a thorough set of experiments\nacross multiple benchmarks and various learning settings.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 12:49:51 GMT"}, {"version": "v2", "created": "Sun, 21 May 2017 07:17:41 GMT"}, {"version": "v3", "created": "Mon, 16 Oct 2017 21:26:17 GMT"}, {"version": "v4", "created": "Tue, 27 Feb 2018 15:17:28 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Rosenfeld", "Nir", ""], ["Globerson", "Amir", ""]]}, {"id": "1703.06485", "submitter": "Peeyush Kumar", "authors": "Peeyush Kumar, Wolf Kohn, Zelda B. Zabinsky", "title": "Near Optimal Hamiltonian-Control and Learning via Chattering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications require solving non-linear control problems that are\nclassically not well behaved. This paper develops a simple and efficient\nchattering algorithm that learns near optimal decision policies through an\nopen-loop feedback strategy. The optimal control problem reduces to a series of\nlinear optimization programs that can be easily solved to recover a relaxed\noptimal trajectory. This algorithm is implemented on a real-time enterprise\nscheduling and control process.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 18:25:52 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Kumar", "Peeyush", ""], ["Kohn", "Wolf", ""], ["Zabinsky", "Zelda B.", ""]]}, {"id": "1703.06490", "submitter": "Edward Choi", "authors": "Edward Choi, Siddharth Biswal, Bradley Malin, Jon Duke, Walter F.\n  Stewart, Jimeng Sun", "title": "Generating Multi-label Discrete Patient Records using Generative\n  Adversarial Networks", "comments": "Accepted at Machine Learning in Health Care (MLHC) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to electronic health record (EHR) data has motivated computational\nadvances in medical research. However, various concerns, particularly over\nprivacy, can limit access to and collaborative use of EHR data. Sharing\nsynthetic EHR data could mitigate risk. In this paper, we propose a new\napproach, medical Generative Adversarial Network (medGAN), to generate\nrealistic synthetic patient records. Based on input real patient records,\nmedGAN can generate high-dimensional discrete variables (e.g., binary and count\nfeatures) via a combination of an autoencoder and generative adversarial\nnetworks. We also propose minibatch averaging to efficiently avoid mode\ncollapse, and increase the learning efficiency with batch normalization and\nshortcut connections. To demonstrate feasibility, we showed that medGAN\ngenerates synthetic patient records that achieve comparable performance to real\ndata on many experiments including distribution statistics, predictive modeling\ntasks and a medical expert review. We also empirically observe a limited\nprivacy risk in both identity and attribute disclosure using medGAN.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 18:56:37 GMT"}, {"version": "v2", "created": "Sat, 17 Jun 2017 08:51:01 GMT"}, {"version": "v3", "created": "Thu, 11 Jan 2018 20:41:54 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Choi", "Edward", ""], ["Biswal", "Siddharth", ""], ["Malin", "Bradley", ""], ["Duke", "Jon", ""], ["Stewart", "Walter F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1703.06513", "submitter": "Sumeet Katariya", "authors": "Sumeet Katariya, Branislav Kveton, Csaba Szepesv\\'ari, Claire Vernade,\n  Zheng Wen", "title": "Bernoulli Rank-$1$ Bandits for Click Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probability that a user will click a search result depends both on its\nrelevance and its position on the results page. The position based model\nexplains this behavior by ascribing to every item an attraction probability,\nand to every position an examination probability. To be clicked, a result must\nbe both attractive and examined. The probabilities of an item-position pair\nbeing clicked thus form the entries of a rank-$1$ matrix. We propose the\nlearning problem of a Bernoulli rank-$1$ bandit where at each step, the\nlearning agent chooses a pair of row and column arms, and receives the product\nof their Bernoulli-distributed values as a reward. This is a special case of\nthe stochastic rank-$1$ bandit problem considered in recent work that proposed\nan elimination based algorithm Rank1Elim, and showed that Rank1Elim's regret\nscales linearly with the number of rows and columns on \"benign\" instances.\nThese are the instances where the minimum of the average row and column rewards\n$\\mu$ is bounded away from zero. The issue with Rank1Elim is that it fails to\nbe competitive with straightforward bandit strategies as $\\mu \\rightarrow 0$.\nIn this paper we propose Rank1ElimKL which simply replaces the (crude)\nconfidence intervals of Rank1Elim with confidence intervals based on\nKullback-Leibler (KL) divergences, and with the help of a novel result\nconcerning the scaling of KL divergences we prove that with this change, our\nalgorithm will be competitive no matter the value of $\\mu$. Experiments with\nsynthetic data confirm that on benign instances the performance of Rank1ElimKL\nis significantly better than that of even Rank1Elim, while experiments with\nmodels derived from real data confirm that the improvements are significant\nacross the board, regardless of whether the data is benign or not.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 21:06:51 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Katariya", "Sumeet", ""], ["Kveton", "Branislav", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Vernade", "Claire", ""], ["Wen", "Zheng", ""]]}, {"id": "1703.06514", "submitter": "Shuangfei Fan", "authors": "Shuangfei Fan, Bert Huang", "title": "Recurrent Collective Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for training iterative collective classifiers for\nlabeling nodes in network data. The iterative classification algorithm (ICA) is\na canonical method for incorporating relational information into\nclassification. Yet, existing methods for training ICA models rely on the\nassumption that relational features reflect the true labels of the nodes. This\nunrealistic assumption introduces a bias that is inconsistent with the actual\nprediction algorithm. In this paper, we introduce recurrent collective\nclassification (RCC), a variant of ICA analogous to recurrent neural network\nprediction. RCC accommodates any differentiable local classifier and relational\nfeature functions. We provide gradient-based strategies for optimizing over\nmodel parameters to more directly minimize the loss function. In our\nexperiments, this direct loss minimization translates to improved accuracy and\nrobustness on real network data. We demonstrate the robustness of RCC in\nsettings where local classification is very noisy, settings that are\nparticularly challenging for ICA.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 21:19:04 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Fan", "Shuangfei", ""], ["Huang", "Bert", ""]]}, {"id": "1703.06536", "submitter": "Roei Gelbhart", "authors": "Roei Gelbhart, Ran El-Yaniv", "title": "The Relationship Between Agnostic Selective Classification Active\n  Learning and the Disagreement Coefficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A selective classifier (f,g) comprises a classification function f and a\nbinary selection function g, which determines if the classifier abstains from\nprediction, or uses f to predict. The classifier is called\npointwise-competitive if it classifies each point identically to the best\nclassifier in hindsight (from the same class), whenever it does not abstain.\nThe quality of such a classifier is quantified by its rejection mass, defined\nto be the probability mass of the points it rejects. A \"fast\" rejection rate is\nachieved if the rejection mass is bounded from above by O(1/m) where m is the\nnumber of labeled examples used to train the classifier (and O hides\nlogarithmic factors). Pointwise-competitive selective (PCS) classifiers are\nintimately related to disagreement-based active learning and it is known that\nin the realizable case, a fast rejection rate of a known PCS algorithm (called\nConsistent Selective Strategy) is equivalent to an exponential speedup of the\nwell-known CAL active algorithm.\n  We focus on the agnostic setting, for which there is a known algorithm called\nLESS that learns a PCS classifier and achieves a fast rejection rate (depending\non Hanneke's disagreement coefficient) under strong assumptions. We present an\nimproved PCS learning algorithm called ILESS for which we show a fast rate\n(depending on Hanneke's disagreement coefficient) without any assumptions. Our\nrejection bound smoothly interpolates the realizable and agnostic settings. The\nmain result of this paper is an equivalence between the following three\nentities: (i) the existence of a fast rejection rate for any PCS learning\nalgorithm (such as ILESS); (ii) a poly-logarithmic bound for Hanneke's\ndisagreement coefficient; and (iii) an exponential speedup for a new\ndisagreement-based active learner called ActiveiLESS.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 23:22:31 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 11:08:28 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Gelbhart", "Roei", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1703.06585", "submitter": "Abhishek Das", "authors": "Abhishek Das, Satwik Kottur, Jos\\'e M. F. Moura, Stefan Lee, Dhruv\n  Batra", "title": "Learning Cooperative Visual Dialog Agents with Deep Reinforcement\n  Learning", "comments": "11 pages, 4 figures, 2 tables, webpage: http://visualdialog.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first goal-driven training for visual question answering and\ndialog agents. Specifically, we pose a cooperative 'image guessing' game\nbetween two agents -- Qbot and Abot -- who communicate in natural language\ndialog so that Qbot can select an unseen image from a lineup of images. We use\ndeep reinforcement learning (RL) to learn the policies of these agents\nend-to-end -- from pixels to multi-agent multi-round dialog to game reward.\n  We demonstrate two experimental results.\n  First, as a 'sanity check' demonstration of pure RL (from scratch), we show\nresults on a synthetic world, where the agents communicate in ungrounded\nvocabulary, i.e., symbols with no pre-specified meanings (X, Y, Z). We find\nthat two bots invent their own communication protocol and start using certain\nsymbols to ask/answer about certain visual attributes (shape/color/style).\nThus, we demonstrate the emergence of grounded language and communication among\n'visual' dialog agents with no human supervision.\n  Second, we conduct large-scale real-image experiments on the VisDial dataset,\nwhere we pretrain with supervised dialog data and show that the RL 'fine-tuned'\nagents significantly outperform SL agents. Interestingly, the RL Qbot learns to\nask questions that Abot is good at, ultimately resulting in more informative\ndialog and a better team.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 03:50:57 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 17:41:23 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Das", "Abhishek", ""], ["Kottur", "Satwik", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""]]}, {"id": "1703.06683", "submitter": "Shuo Wang", "authors": "Shuo Wang, Leandro L. Minku, Xin Yao", "title": "A Systematic Study of Online Class Imbalance Learning with Concept Drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an emerging research topic, online class imbalance learning often combines\nthe challenges of both class imbalance and concept drift. It deals with data\nstreams having very skewed class distributions, where concept drift may occur.\nIt has recently received increased research attention; however, very little\nwork addresses the combined problem where both class imbalance and concept\ndrift coexist. As the first systematic study of handling concept drift in\nclass-imbalanced data streams, this paper first provides a comprehensive review\nof current research progress in this field, including current research focuses\nand open challenges. Then, an in-depth experimental study is performed, with\nthe goal of understanding how to best overcome concept drift in online learning\nwith class imbalance. Based on the analysis, a general guideline is proposed\nfor the development of an effective algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 11:22:10 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Wang", "Shuo", ""], ["Minku", "Leandro L.", ""], ["Yao", "Xin", ""]]}, {"id": "1703.06692", "submitter": "Peter Karkus", "authors": "Peter Karkus, David Hsu, Wee Sun Lee", "title": "QMDP-Net: Deep Learning for Planning under Partial Observability", "comments": "NIPS 2017 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the QMDP-net, a neural network architecture for\nplanning under partial observability. The QMDP-net combines the strengths of\nmodel-free learning and model-based planning. It is a recurrent policy network,\nbut it represents a policy for a parameterized set of tasks by connecting a\nmodel with a planning algorithm that solves the model, thus embedding the\nsolution structure of planning in a network learning architecture. The QMDP-net\nis fully differentiable and allows for end-to-end training. We train a QMDP-net\non different tasks so that it can generalize to new ones in the parameterized\ntask set and \"transfer\" to other similar tasks beyond the set. In preliminary\nexperiments, QMDP-net showed strong performance on several robotic tasks in\nsimulation. Interestingly, while QMDP-net encodes the QMDP algorithm, it\nsometimes outperforms the QMDP algorithm in the experiments, as a result of\nend-to-end learning.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 11:44:00 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 12:59:39 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 03:31:43 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Karkus", "Peter", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1703.06700", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko", "title": "Independence clustering (without a matrix)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The independence clustering problem is considered in the following\nformulation: given a set $S$ of random variables, it is required to find the\nfinest partitioning $\\{U_1,\\dots,U_k\\}$ of $S$ into clusters such that the\nclusters $U_1,\\dots,U_k$ are mutually independent. Since mutual independence is\nthe target, pairwise similarity measurements are of no use, and thus\ntraditional clustering algorithms are inapplicable. The distribution of the\nrandom variables in $S$ is, in general, unknown, but a sample is available.\nThus, the problem is cast in terms of time series. Two forms of sampling are\nconsidered: i.i.d.\\ and stationary time series, with the main emphasis being on\nthe latter, more general, case. A consistent, computationally tractable\nalgorithm for each of the settings is proposed, and a number of open directions\nfor further research are outlined.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 12:09:53 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Ryabko", "Daniil", ""]]}, {"id": "1703.06726", "submitter": "Gary B\\'ecigneul", "authors": "Gary B\\'ecigneul", "title": "On the effect of pooling on the geometry of representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning and neuroscience, certain computational structures and\nalgorithms are known to yield disentangled representations without us\nunderstanding why, the most striking examples being perhaps convolutional\nneural networks and the ventral stream of the visual cortex in humans and\nprimates. As for the latter, it was conjectured that representations may be\ndisentangled by being flattened progressively and at a local scale. An attempt\nat a formalization of the role of invariance in learning representations was\nmade recently, being referred to as I-theory. In this framework and using the\nlanguage of differential geometry, we show that pooling over a group of\ntransformations of the input contracts the metric and reduces its curvature,\nand provide quantitative bounds, in the aim of moving towards a theoretical\nunderstanding on how to disentangle representations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 13:18:56 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["B\u00e9cigneul", "Gary", ""]]}, {"id": "1703.06748", "submitter": "Yen-Chen Lin", "authors": "Yen-Chen Lin, Zhang-Wei Hong, Yuan-Hong Liao, Meng-Li Shih, Ming-Yu\n  Liu, Min Sun", "title": "Tactics of Adversarial Attack on Deep Reinforcement Learning Agents", "comments": "To Appear at IJCAI 2017. Project website:\n  http://yenchenlin.me/adversarial_attack_RL/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two tactics to attack agents trained by deep reinforcement\nlearning algorithms using adversarial examples, namely the strategically-timed\nattack and the enchanting attack. In the strategically-timed attack, the\nadversary aims at minimizing the agent's reward by only attacking the agent at\na small subset of time steps in an episode. Limiting the attack activity to\nthis subset helps prevent detection of the attack by the agent. We propose a\nnovel method to determine when an adversarial example should be crafted and\napplied. In the enchanting attack, the adversary aims at luring the agent to a\ndesignated target state. This is achieved by combining a generative model and a\nplanning algorithm: while the generative model predicts the future states, the\nplanning algorithm generates a preferred sequence of actions for luring the\nagent. A sequence of adversarial examples is then crafted to lure the agent to\ntake the preferred sequence of actions. We apply the two tactics to the agents\ntrained by the state-of-the-art deep reinforcement learning algorithm including\nDQN and A3C. In 5 Atari games, our strategically timed attack reduces as much\nreward as the uniform attack (i.e., attacking at every time step) does by\nattacking the agent 4 times less often. Our enchanting attack lures the agent\ntoward designated target states with a more than 70% success rate. Videos are\navailable at http://yenchenlin.me/adversarial_attack_RL/\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 04:39:34 GMT"}, {"version": "v2", "created": "Mon, 1 May 2017 08:12:44 GMT"}, {"version": "v3", "created": "Tue, 23 May 2017 01:26:42 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2019 01:24:00 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lin", "Yen-Chen", ""], ["Hong", "Zhang-Wei", ""], ["Liao", "Yuan-Hong", ""], ["Shih", "Meng-Li", ""], ["Liu", "Ming-Yu", ""], ["Sun", "Min", ""]]}, {"id": "1703.06749", "submitter": "Nick Pawlowski", "authors": "Nick Pawlowski, Miguel Jaques, Ben Glocker", "title": "Efficient variational Bayesian neural network ensembles for outlier\n  detection", "comments": "Presented at Workshop track - ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we perform outlier detection using ensembles of neural networks\nobtained by variational approximation of the posterior in a Bayesian neural\nnetwork setting. The variational parameters are obtained by sampling from the\ntrue posterior by gradient descent. We show our outlier detection results are\ncomparable to those obtained using other efficient ensembling methods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 14:02:11 GMT"}, {"version": "v2", "created": "Sat, 22 Apr 2017 13:03:20 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Pawlowski", "Nick", ""], ["Jaques", "Miguel", ""], ["Glocker", "Ben", ""]]}, {"id": "1703.06777", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall and Gavin C. Cawley", "title": "On the Use of Default Parameter Settings in the Empirical Evaluation of\n  Classification Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that, for a range of state-of-the-art machine learning\nalgorithms, the differences in generalisation performance obtained using\ndefault parameter settings and using parameters tuned via cross-validation can\nbe similar in magnitude to the differences in performance observed between\nstate-of-the-art and uncompetitive learning systems. This means that fair and\nrigorous evaluation of new learning algorithms requires performance comparison\nagainst benchmark methods with best-practice model selection procedures, rather\nthan using default parameter settings. We investigate the sensitivity of three\nkey machine learning algorithms (support vector machine, random forest and\nrotation forest) to their default parameter settings, and provide guidance on\ndetermining sensible default parameter values for implementations of these\nalgorithms. We also conduct an experimental comparison of these three\nalgorithms on 121 classification problems and find that, perhaps surprisingly,\nrotation forest is significantly more accurate on average than both random\nforest and a support vector machine.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 14:42:27 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Bagnall", "Anthony", ""], ["Cawley", "Gavin C.", ""]]}, {"id": "1703.06807", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, Yuanyuan Liu, James Cheng, Kelvin Kai Wing Ng, Yuichi\n  Yoshida", "title": "Guaranteed Sufficient Decrease for Variance Reduced Stochastic Gradient\n  Descent", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel sufficient decrease technique for variance\nreduced stochastic gradient descent methods such as SAG, SVRG and SAGA. In\norder to make sufficient decrease for stochastic optimization, we design a new\nsufficient decrease criterion, which yields sufficient decrease versions of\nvariance reduction algorithms such as SVRG-SD and SAGA-SD as a byproduct. We\nintroduce a coefficient to scale current iterate and satisfy the sufficient\ndecrease property, which takes the decisions to shrink, expand or move in the\nopposite direction, and then give two specific update rules of the coefficient\nfor Lasso and ridge regression. Moreover, we analyze the convergence properties\nof our algorithms for strongly convex problems, which show that both of our\nalgorithms attain linear convergence rates. We also provide the convergence\nguarantees of our algorithms for non-strongly convex problems. Our experimental\nresults further verify that our algorithms achieve significantly better\nperformance than their counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 15:43:10 GMT"}, {"version": "v2", "created": "Sun, 4 Jun 2017 15:20:30 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Shang", "Fanhua", ""], ["Liu", "Yuanyuan", ""], ["Cheng", "James", ""], ["Ng", "Kelvin Kai Wing", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "1703.06846", "submitter": "Nadav Cohen", "authors": "Nadav Cohen, Ronen Tamari, Amnon Shashua", "title": "Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The driving force behind deep networks is their ability to compactly\nrepresent rich classes of functions. The primary notion for formally reasoning\nabout this phenomenon is expressive efficiency, which refers to a situation\nwhere one network must grow unfeasibly large in order to realize (or\napproximate) functions of another. To date, expressive efficiency analyses\nfocused on the architectural feature of depth, showing that deep networks are\nrepresentationally superior to shallow ones. In this paper we study the\nexpressive efficiency brought forth by connectivity, motivated by the\nobservation that modern networks interconnect their layers in elaborate ways.\nWe focus on dilated convolutional networks, a family of deep models delivering\nstate of the art performance in sequence processing tasks. By introducing and\nanalyzing the concept of mixed tensor decompositions, we prove that\ninterconnecting dilated convolutional networks can lead to expressive\nefficiency. In particular, we show that even a single connection between\nintermediate layers can already lead to an almost quadratic gap, which in\nlarge-scale settings typically makes the difference between a model that is\npractical and one that is not. Empirical evaluation demonstrates how the\nexpressive efficiency of connectivity, similarly to that of depth, translates\ninto gains in accuracy. This leads us to believe that expressive efficiency may\nserve a key role in the development of new tools for deep network design.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 17:05:38 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 18:22:33 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 17:20:29 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Cohen", "Nadav", ""], ["Tamari", "Ronen", ""], ["Shashua", "Amnon", ""]]}, {"id": "1703.06856", "submitter": "Matthew Kusner", "authors": "Matt J. Kusner, Joshua R. Loftus, Chris Russell, Ricardo Silva", "title": "Counterfactual Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning can impact people with legal or ethical consequences when it\nis used to automate decisions in areas such as insurance, lending, hiring, and\npredictive policing. In many of these scenarios, previous decisions have been\nmade that are unfairly biased against certain subpopulations, for example those\nof a particular race, gender, or sexual orientation. Since this past data may\nbe biased, machine learning predictors must account for this to avoid\nperpetuating or creating discriminatory practices. In this paper, we develop a\nframework for modeling fairness using tools from causal inference. Our\ndefinition of counterfactual fairness captures the intuition that a decision is\nfair towards an individual if it is the same in (a) the actual world and (b) a\ncounterfactual world where the individual belonged to a different demographic\ngroup. We demonstrate our framework on a real-world problem of fair prediction\nof success in law school.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 17:18:57 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 20:06:54 GMT"}, {"version": "v3", "created": "Thu, 8 Mar 2018 11:23:13 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Kusner", "Matt J.", ""], ["Loftus", "Joshua R.", ""], ["Russell", "Chris", ""], ["Silva", "Ricardo", ""]]}, {"id": "1703.06857", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini, Baicen Xiao, Mayoore Jaiswal and Radha Poovendran", "title": "On the Limitation of Convolutional Neural Networks in Recognizing\n  Negative Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have achieved state-of-the-art\nperformance on a variety of computer vision tasks, particularly visual\nclassification problems, where new algorithms reported to achieve or even\nsurpass the human performance. In this paper, we examine whether CNNs are\ncapable of learning the semantics of training data. To this end, we evaluate\nCNNs on negative images, since they share the same structure and semantics as\nregular images and humans can classify them correctly. Our experimental results\nindicate that when training on regular images and testing on negative images,\nthe model accuracy is significantly lower than when it is tested on regular\nimages. This leads us to the conjecture that current training methods do not\neffectively train models to generalize the concepts. We then introduce the\nnotion of semantic adversarial examples - transformed inputs that semantically\nrepresent the same objects, but the model does not classify them correctly -\nand present negative images as one class of such inputs.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 17:21:19 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 20:53:28 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Hosseini", "Hossein", ""], ["Xiao", "Baicen", ""], ["Jaiswal", "Mayoore", ""], ["Poovendran", "Radha", ""]]}, {"id": "1703.06891", "submitter": "Chris Donahue", "authors": "Chris Donahue, Zachary C. Lipton, Julian McAuley", "title": "Dance Dance Convolution", "comments": "Published as a conference paper at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players\nperform steps on a dance platform in synchronization with music as directed by\non-screen step charts. While many step charts are available in standardized\npacks, players may grow tired of existing charts, or wish to dance to a song\nfor which no chart exists. We introduce the task of learning to choreograph.\nGiven a raw audio track, the goal is to produce a new step chart. This task\ndecomposes naturally into two subtasks: deciding when to place steps and\ndeciding which steps to select. For the step placement task, we combine\nrecurrent and convolutional neural networks to ingest spectrograms of low-level\naudio features to predict steps, conditioned on chart difficulty. For step\nselection, we present a conditional LSTM generative model that substantially\noutperforms n-gram and fixed-window approaches.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 18:00:13 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 07:44:55 GMT"}, {"version": "v3", "created": "Wed, 21 Jun 2017 00:45:51 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Donahue", "Chris", ""], ["Lipton", "Zachary C.", ""], ["McAuley", "Julian", ""]]}, {"id": "1703.06902", "submitter": "Juncheng Li", "authors": "Juncheng Li, Wei Dai, Florian Metze, Shuhui Qu, Samarjit Das", "title": "A Comparison of deep learning methods for environmental sound", "comments": "5 pages including reference", "journal-ref": "published at ICASSP 2017", "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environmental sound detection is a challenging application of machine\nlearning because of the noisy nature of the signal, and the small amount of\n(labeled) data that is typically available. This work thus presents a\ncomparison of several state-of-the-art Deep Learning models on the IEEE\nchallenge on Detection and Classification of Acoustic Scenes and Events (DCASE)\n2016 challenge task and data, classifying sounds into one of fifteen common\nindoor and outdoor acoustic scenes, such as bus, cafe, car, city center, forest\npath, library, train, etc. In total, 13 hours of stereo audio recordings are\navailable, making this one of the largest datasets available. We perform\nexperiments on six sets of features, including standard Mel-frequency cepstral\ncoefficients (MFCC), Binaural MFCC, log Mel-spectrum and two different large-\nscale temporal pooling features extracted using OpenSMILE. On these features,\nwe apply five models: Gaussian Mixture Model (GMM), Deep Neural Network (DNN),\nRecurrent Neural Network (RNN), Convolutional Deep Neural Net- work (CNN) and\ni-vector. Using the late-fusion approach, we improve the performance of the\nbaseline 72.5% by 15.6% in 4-fold Cross Validation (CV) avg. accuracy and 11%\nin test accuracy, which matches the best result of the DCASE 2016 challenge.\nWith large feature sets, deep neural network models out- perform traditional\nmethods and achieve the best performance among all the studied methods.\nConsistent with other work, the best performing single model is the\nnon-temporal DNN model, which we take as evidence that sounds in the DCASE\nchallenge do not exhibit strong temporal dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 18:11:47 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Li", "Juncheng", ""], ["Dai", "Wei", ""], ["Metze", "Florian", ""], ["Qu", "Shuhui", ""], ["Das", "Samarjit", ""]]}, {"id": "1703.06907", "submitter": "Joshua Tobin", "authors": "Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba,\n  Pieter Abbeel", "title": "Domain Randomization for Transferring Deep Neural Networks from\n  Simulation to the Real World", "comments": "8 pages, 7 figures. Submitted to 2017 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bridging the 'reality gap' that separates simulated robotics from experiments\non hardware could accelerate robotic research through improved data\navailability. This paper explores domain randomization, a simple technique for\ntraining models on simulated images that transfer to real images by randomizing\nrendering in the simulator. With enough variability in the simulator, the real\nworld may appear to the model as just another variation. We focus on the task\nof object localization, which is a stepping stone to general robotic\nmanipulation skills. We find that it is possible to train a real-world object\ndetector that is accurate to $1.5$cm and robust to distractors and partial\nocclusions using only data from a simulator with non-realistic random textures.\nTo demonstrate the capabilities of our detectors, we show they can be used to\nperform grasping in a cluttered environment. To our knowledge, this is the\nfirst successful transfer of a deep neural network trained only on simulated\nRGB images (without pre-training on real images) to the real world for the\npurpose of robotic control.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 18:17:25 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Tobin", "Josh", ""], ["Fong", "Rachel", ""], ["Ray", "Alex", ""], ["Schneider", "Jonas", ""], ["Zaremba", "Wojciech", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1703.06912", "submitter": "Caifa Zhou", "authors": "Caifa Zhou and Andreas Wieser", "title": "Application of backpropagation neural networks to both stages of\n  fingerprinting based WIPS", "comments": "11 pages, 11 figures, published in proceedings UPINLBS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scheme to employ backpropagation neural networks (BPNNs) for\nboth stages of fingerprinting-based indoor positioning using WLAN/WiFi signal\nstrengths (FWIPS): radio map construction during the offline stage, and\nlocalization during the online stage. Given a training radio map (TRM), i.e., a\nset of coordinate vectors and associated WLAN/WiFi signal strengths of the\navailable access points, a BPNN can be trained to output the expected signal\nstrengths for any input position within the region of interest (BPNN-RM). This\ncan be used to provide a continuous representation of the radio map and to\nfilter, densify or decimate a discrete radio map. Correspondingly, the TRM can\nalso be used to train another BPNN to output the expected position within the\nregion of interest for any input vector of recorded signal strengths and thus\ncarry out localization (BPNN-LA).Key aspects of the design of such artificial\nneural networks for a specific application are the selection of design\nparameters like the number of hidden layers and nodes within the network, and\nthe training procedure. Summarizing extensive numerical simulations, based on\nreal measurements in a testbed, we analyze the impact of these design choices\non the performance of the BPNN and compare the results in particular to those\nobtained using the $k$ nearest neighbors ($k$NN) and weighted $k$ nearest\nneighbors approaches to FWIPS.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 20:30:50 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Zhou", "Caifa", ""], ["Wieser", "Andreas", ""]]}, {"id": "1703.06914", "submitter": "Iaroslav Omelianenko", "authors": "Iaroslav Omelianenko", "title": "Applying Deep Machine Learning for psycho-demographic profiling of\n  Internet users using O.C.E.A.N. model of personality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the modern era, each Internet user leaves enormous amounts of auxiliary\ndigital residuals (footprints) by using a variety of on-line services. All this\ndata is already collected and stored for many years. In recent works, it was\ndemonstrated that it's possible to apply simple machine learning methods to\nanalyze collected digital footprints and to create psycho-demographic profiles\nof individuals. However, while these works clearly demonstrated the\napplicability of machine learning methods for such an analysis, created simple\nprediction models still lacks accuracy necessary to be successfully applied for\npractical needs. We have assumed that using advanced deep machine learning\nmethods may considerably increase the accuracy of predictions. We started with\nsimple machine learning methods to estimate basic prediction performance and\nmoved further by applying advanced methods based on shallow and deep neural\nnetworks. Then we compared prediction power of studied models and made\nconclusions about its performance. Finally, we made hypotheses how prediction\naccuracy can be further improved. As result of this work, we provide full\nsource code used in the experiments for all interested researchers and\npractitioners in corresponding GitHub repository. We believe that applying deep\nmachine learning for psycho-demographic profiling may have an enormous impact\non the society (for good or worse) and provides means for Artificial\nIntelligence (AI) systems to better understand humans by creating their\npsychological profiles. Thus AI agents may achieve the human-like ability to\nparticipate in conversation (communication) flow by anticipating human\nopponents' reactions, expectations, and behavior.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 09:27:21 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 12:16:24 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Omelianenko", "Iaroslav", ""]]}, {"id": "1703.06925", "submitter": "Hiva Ghanbari", "authors": "Hiva Ghanbari, Katya Scheinberg", "title": "Black-Box Optimization in Machine Learning with Trust Region Based\n  Derivative Free Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we utilize a Trust Region based Derivative Free Optimization\n(DFO-TR) method to directly maximize the Area Under Receiver Operating\nCharacteristic Curve (AUC), which is a nonsmooth, noisy function. We show that\nAUC is a smooth function, in expectation, if the distributions of the positive\nand negative data points obey a jointly normal distribution. The practical\nperformance of this algorithm is compared to three prominent Bayesian\noptimization methods and random search. The presented numerical results show\nthat DFO-TR surpasses Bayesian optimization and random search on various\nblack-box optimization problem, such as maximizing AUC and hyperparameter\ntuning.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 19:00:18 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Ghanbari", "Hiva", ""], ["Scheinberg", "Katya", ""]]}, {"id": "1703.06934", "submitter": "William La Cava", "authors": "William La Cava and Jason H. Moore", "title": "Ensemble representation learning: an analysis of fitness and survival\n  for wrapper-based genetic programming methods", "comments": "Genetic and Evolutionary Computation Conference (GECCO) 2017, Berlin,\n  Germany", "journal-ref": null, "doi": "10.1145/3071178/3071215", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we proposed a general, ensemble-based feature engineering wrapper\n(FEW) that was paired with a number of machine learning methods to solve\nregression problems. Here, we adapt FEW for supervised classification and\nperform a thorough analysis of fitness and survival methods within this\nframework. Our tests demonstrate that two fitness metrics, one introduced as an\nadaptation of the silhouette score, outperform the more commonly used Fisher\ncriterion. We analyze survival methods and demonstrate that $\\epsilon$-lexicase\nsurvival works best across our test problems, followed by random survival which\noutperforms both tournament and deterministic crowding. We conduct a benchmark\ncomparison to several classification methods using a large set of problems and\nshow that FEW can improve the best classifier performance in several cases. We\nshow that FEW generates consistent, meaningful features for a biomedical\nproblem with different ML pairings.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 19:26:00 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 12:46:40 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 19:01:17 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["La Cava", "William", ""], ["Moore", "Jason H.", ""]]}, {"id": "1703.06959", "submitter": "Natali Ruchansky", "authors": "Natali Ruchansky, Sungyong Seo, Yan Liu", "title": "CSI: A Hybrid Deep Model for Fake News Detection", "comments": "In Proceedings of the 26th ACM International Conference on\n  Information and Knowledge Management (CIKM) 2017", "journal-ref": null, "doi": "10.1145/3132847.3132877", "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic of fake news has drawn attention both from the public and the\nacademic communities. Such misinformation has the potential of affecting public\nopinion, providing an opportunity for malicious parties to manipulate the\noutcomes of public events such as elections. Because such high stakes are at\nplay, automatically detecting fake news is an important, yet challenging\nproblem that is not yet well understood. Nevertheless, there are three\ngenerally agreed upon characteristics of fake news: the text of an article, the\nuser response it receives, and the source users promoting it. Existing work has\nlargely focused on tailoring solutions to one particular characteristic which\nhas limited their success and generality. In this work, we propose a model that\ncombines all three characteristics for a more accurate and automated\nprediction. Specifically, we incorporate the behavior of both parties, users\nand articles, and the group behavior of users who propagate fake news.\nMotivated by the three characteristics, we propose a model called CSI which is\ncomposed of three modules: Capture, Score, and Integrate. The first module is\nbased on the response and text; it uses a Recurrent Neural Network to capture\nthe temporal pattern of user activity on a given article. The second module\nlearns the source characteristic based on the behavior of users, and the two\nare integrated with the third module to classify an article as fake or not.\nExperimental analysis on real-world data demonstrates that CSI achieves higher\naccuracy than existing models, and extracts meaningful latent representations\nof both users and articles.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 20:33:32 GMT"}, {"version": "v2", "created": "Sun, 26 Mar 2017 17:29:45 GMT"}, {"version": "v3", "created": "Thu, 1 Jun 2017 06:00:56 GMT"}, {"version": "v4", "created": "Sun, 3 Sep 2017 22:05:42 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Ruchansky", "Natali", ""], ["Seo", "Sungyong", ""], ["Liu", "Yan", ""]]}, {"id": "1703.06971", "submitter": "Jan van Gemert", "authors": "Miriam W. Huijser and Jan C. van Gemert", "title": "Active Decision Boundary Annotation with Deep Generative Models", "comments": "ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is on active learning where the goal is to reduce the data\nannotation burden by interacting with a (human) oracle during training.\nStandard active learning methods ask the oracle to annotate data samples.\nInstead, we take a profoundly different approach: we ask for annotations of the\ndecision boundary. We achieve this using a deep generative model to create\nnovel instances along a 1d line. A point on the decision boundary is revealed\nwhere the instances change class. Experimentally we show on three data sets\nthat our method can be plugged-in to other active learning schemes, that human\noracles can effectively annotate points on the decision boundary, that our\nmethod is robust to annotation noise, and that decision boundary annotations\nimprove over annotating data samples.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 21:20:21 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 09:36:55 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Huijser", "Miriam W.", ""], ["van Gemert", "Jan C.", ""]]}, {"id": "1703.06975", "submitter": "Florian Bordes", "authors": "Florian Bordes, Sina Honari, Pascal Vincent", "title": "Learning to Generate Samples from Noise through Infusion Training", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate a novel training procedure to learn a generative\nmodel as the transition operator of a Markov chain, such that, when applied\nrepeatedly on an unstructured random noise sample, it will denoise it into a\nsample that matches the target distribution from the training set. The novel\ntraining procedure to learn this progressive denoising operation involves\nsampling from a slightly different chain than the model chain used for\ngeneration in the absence of a denoising target. In the training chain we\ninfuse information from the training target example that we would like the\nchains to reach with a high probability. The thus learned transition operator\nis able to produce quality and varied samples in a small number of steps.\nExperiments show competitive results compared to the samples generated with a\nbasic Generative Adversarial Net\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 21:29:18 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Bordes", "Florian", ""], ["Honari", "Sina", ""], ["Vincent", "Pascal", ""]]}, {"id": "1703.06990", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel and Nil Geisweiller and Chris Poulin", "title": "Metalearning for Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general formulation of optimization problems in which various candidate\nsolutions may use different feature-sets is presented, encompassing supervised\nclassification, automated program learning and other cases. A novel\ncharacterization of the concept of a \"good quality feature\" for such an\noptimization problem is provided; and a proposal regarding the integration of\nquality based feature selection into metalearning is suggested, wherein the\nquality of a feature for a problem is estimated using knowledge about related\nfeatures in the context of related problems. Results are presented regarding\nextensive testing of this \"feature metalearning\" approach on supervised text\nclassification problems; it is demonstrated that, in this context, feature\nmetalearning can provide significant and sometimes dramatic speedup over\nstandard feature selection heuristics.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 22:32:36 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Goertzel", "Ben", ""], ["Geisweiller", "Nil", ""], ["Poulin", "Chris", ""]]}, {"id": "1703.07004", "submitter": "Marzyeh Ghassemi", "authors": "Harini Suresh, Peter Szolovits, Marzyeh Ghassemi", "title": "The Use of Autoencoders for Discovering Patient Phenotypes", "comments": null, "journal-ref": "NIPS Workshop on Machine Learning for Healthcare (NIPS ML4HC) 2016", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use autoencoders to create low-dimensional embeddings of underlying\npatient phenotypes that we hypothesize are a governing factor in determining\nhow different patients will react to different interventions. We compare the\nperformance of autoencoders that take fixed length sequences of concatenated\ntimesteps as input with a recurrent sequence-to-sequence autoencoder. We\nevaluate our methods on around 35,500 patients from the latest MIMIC III\ndataset from Beth Israel Deaconess Hospital.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 23:30:40 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Suresh", "Harini", ""], ["Szolovits", "Peter", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "1703.07015", "submitter": "Guokun Lai", "authors": "Guokun Lai, Wei-Cheng Chang, Yiming Yang, Hanxiao Liu", "title": "Modeling Long- and Short-Term Temporal Patterns with Deep Neural\n  Networks", "comments": "Accepted by SIGIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series forecasting is an important machine learning problem\nacross many domains, including predictions of solar plant energy output,\nelectricity consumption, and traffic jam situation. Temporal data arise in\nthese real-world applications often involves a mixture of long-term and\nshort-term patterns, for which traditional approaches such as Autoregressive\nmodels and Gaussian Process may fail. In this paper, we proposed a novel deep\nlearning framework, namely Long- and Short-term Time-series network (LSTNet),\nto address this open challenge. LSTNet uses the Convolution Neural Network\n(CNN) and the Recurrent Neural Network (RNN) to extract short-term local\ndependency patterns among variables and to discover long-term patterns for time\nseries trends. Furthermore, we leverage traditional autoregressive model to\ntackle the scale insensitive problem of the neural network model. In our\nevaluation on real-world data with complex mixtures of repetitive patterns,\nLSTNet achieved significant performance improvements over that of several\nstate-of-the-art baseline methods. All the data and experiment codes are\navailable online.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 00:33:36 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 01:24:10 GMT"}, {"version": "v3", "created": "Wed, 18 Apr 2018 21:54:36 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Lai", "Guokun", ""], ["Chang", "Wei-Cheng", ""], ["Yang", "Yiming", ""], ["Liu", "Hanxiao", ""]]}, {"id": "1703.07022", "submitter": "Xiaodan Liang", "authors": "Xiaodan Liang, Zhiting Hu, Hao Zhang, Chuang Gan, Eric P. Xing", "title": "Recurrent Topic-Transition GAN for Visual Paragraph Generation", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural image usually conveys rich semantic content and can be viewed from\ndifferent angles. Existing image description methods are largely restricted by\nsmall sets of biased visual paragraph annotations, and fail to cover rich\nunderlying semantics. In this paper, we investigate a semi-supervised paragraph\ngenerative framework that is able to synthesize diverse and semantically\ncoherent paragraph descriptions by reasoning over local semantic regions and\nexploiting linguistic knowledge. The proposed Recurrent Topic-Transition\nGenerative Adversarial Network (RTT-GAN) builds an adversarial framework\nbetween a structured paragraph generator and multi-level paragraph\ndiscriminators. The paragraph generator generates sentences recurrently by\nincorporating region-based visual and language attention mechanisms at each\nstep. The quality of generated paragraph sentences is assessed by multi-level\nadversarial discriminators from two aspects, namely, plausibility at sentence\nlevel and topic-transition coherence at paragraph level. The joint adversarial\ntraining of RTT-GAN drives the model to generate realistic paragraphs with\nsmooth logical transition between sentence topics. Extensive quantitative\nexperiments on image and video paragraph datasets demonstrate the effectiveness\nof our RTT-GAN in both supervised and semi-supervised settings. Qualitative\nresults on telling diverse stories for an image also verify the\ninterpretability of RTT-GAN.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 01:43:12 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 20:06:15 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Liang", "Xiaodan", ""], ["Hu", "Zhiting", ""], ["Zhang", "Hao", ""], ["Gan", "Chuang", ""], ["Xing", "Eric P.", ""]]}, {"id": "1703.07026", "submitter": "Xin Huang", "authors": "Xin Huang and Yuxin Peng", "title": "Cross-modal Deep Metric Learning with Multi-task Regularization", "comments": "Revision: Added reference [7] 6 pages, 1 figure, to appear in the\n  proceedings of the IEEE International Conference on Multimedia and Expo\n  (ICME), Jul 10, 2017 - Jul 14, 2017, Hong Kong, Hong Kong", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNN-based cross-modal retrieval has become a research hotspot, by which users\ncan search results across various modalities like image and text. However,\nexisting methods mainly focus on the pairwise correlation and reconstruction\nerror of labeled data. They ignore the semantically similar and dissimilar\nconstraints between different modalities, and cannot take advantage of\nunlabeled data. This paper proposes Cross-modal Deep Metric Learning with\nMulti-task Regularization (CDMLMR), which integrates quadruplet ranking loss\nand semi-supervised contrastive loss for modeling cross-modal semantic\nsimilarity in a unified multi-task learning architecture. The quadruplet\nranking loss can model the semantically similar and dissimilar constraints to\npreserve cross-modal relative similarity ranking information. The\nsemi-supervised contrastive loss is able to maximize the semantic similarity on\nboth labeled and unlabeled data. Compared to the existing methods, CDMLMR\nexploits not only the similarity ranking information but also unlabeled\ncross-modal data, and thus boosts cross-modal retrieval accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 02:04:30 GMT"}, {"version": "v2", "created": "Wed, 5 Apr 2017 05:02:20 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Huang", "Xin", ""], ["Peng", "Yuxin", ""]]}, {"id": "1703.07027", "submitter": "Zhiting Hu", "authors": "Prasoon Goyal, Zhiting Hu, Xiaodan Liang, Chenyu Wang, Eric Xing", "title": "Nonparametric Variational Auto-encoders for Hierarchical Representation\n  Learning", "comments": "Accepted in ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently developed variational autoencoders (VAEs) have proved to be an\neffective confluence of the rich representational power of neural networks with\nBayesian methods. However, most work on VAEs use a rather simple prior over the\nlatent variables such as standard normal distribution, thereby restricting its\napplications to relatively simple phenomena. In this work, we propose\nhierarchical nonparametric variational autoencoders, which combines\ntree-structured Bayesian nonparametric priors with VAEs, to enable infinite\nflexibility of the latent representation space. Both the neural parameters and\nBayesian priors are learned jointly using tailored variational inference. The\nresulting model induces a hierarchical structure of latent semantic concepts\nunderlying the data corpus, and infers accurate representations of data\ninstances. We apply our model in video representation learning. Our method is\nable to discover highly interpretable activity hierarchies, and obtain improved\nclustering accuracy and generalization capacity based on the learned rich\nrepresentations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 02:08:05 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 18:52:57 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Goyal", "Prasoon", ""], ["Hu", "Zhiting", ""], ["Liang", "Xiaodan", ""], ["Wang", "Chenyu", ""], ["Xing", "Eric", ""]]}, {"id": "1703.07047", "submitter": "Krzysztof J. Geras", "authors": "Krzysztof J. Geras and Stacey Wolfson and Yiqiu Shen and Nan Wu and S.\n  Gene Kim and Eric Kim and Laura Heacock and Ujas Parikh and Linda Moy and\n  Kyunghyun Cho", "title": "High-Resolution Breast Cancer Screening with Multi-View Deep\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep learning for natural images have prompted a surge of\ninterest in applying similar techniques to medical images. The majority of the\ninitial attempts focused on replacing the input of a deep convolutional neural\nnetwork with a medical image, which does not take into consideration the\nfundamental differences between these two types of images. Specifically, fine\ndetails are necessary for detection in medical images, unlike in natural images\nwhere coarse structures matter most. This difference makes it inadequate to use\nthe existing network architectures developed for natural images, because they\nwork on heavily downscaled images to reduce the memory requirements. This hides\ndetails necessary to make accurate predictions. Additionally, a single exam in\nmedical imaging often comes with a set of views which must be fused in order to\nreach a correct conclusion. In our work, we propose to use a multi-view deep\nconvolutional neural network that handles a set of high-resolution medical\nimages. We evaluate it on large-scale mammography-based breast cancer screening\n(BI-RADS prediction) using 886,000 images. We focus on investigating the impact\nof the training set size and image size on the prediction accuracy. Our results\nhighlight that performance increases with the size of training set, and that\nthe best performance can only be achieved using the original resolution. In the\nreader study, performed on a random subset of the test set, we confirmed the\nefficacy of our model, which achieved performance comparable to a committee of\nradiologists when presented with the same data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 04:11:13 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 06:39:33 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 01:21:51 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Geras", "Krzysztof J.", ""], ["Wolfson", "Stacey", ""], ["Shen", "Yiqiu", ""], ["Wu", "Nan", ""], ["Kim", "S. Gene", ""], ["Kim", "Eric", ""], ["Heacock", "Laura", ""], ["Parikh", "Ujas", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1703.07055", "submitter": "Xiujun Li", "authors": "Xiujun Li and Yun-Nung Chen and Lihong Li and Jianfeng Gao and Asli\n  Celikyilmaz", "title": "Investigation of Language Understanding Impact for Reinforcement\n  Learning Based Dialogue Systems", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language understanding is a key component in a spoken dialogue system. In\nthis paper, we investigate how the language understanding module influences the\ndialogue system performance by conducting a series of systematic experiments on\na task-oriented neural dialogue system in a reinforcement learning based\nsetting. The empirical study shows that among different types of language\nunderstanding errors, slot-level errors can have more impact on the overall\nperformance of a dialogue system compared to intent-level errors. In addition,\nour experiments demonstrate that the reinforcement learning based dialogue\nsystem is able to learn when and what to confirm in order to achieve better\nperformance and greater robustness.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 04:56:14 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Li", "Xiujun", ""], ["Chen", "Yun-Nung", ""], ["Li", "Lihong", ""], ["Gao", "Jianfeng", ""], ["Celikyilmaz", "Asli", ""]]}, {"id": "1703.07056", "submitter": "Atsushi Shibagaki", "authors": "Atsushi Shibagaki, Ichiro Takeuchi", "title": "Stochastic Primal Dual Coordinate Method with Non-Uniform Sampling Based\n  on Optimality Violations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study primal-dual type stochastic optimization algorithms with non-uniform\nsampling. Our main theoretical contribution in this paper is to present a\nconvergence analysis of Stochastic Primal Dual Coordinate (SPDC) Method with\narbitrary sampling. Based on this theoretical framework, we propose Optimality\nViolation-based Sampling SPDC (ovsSPDC), a non-uniform sampling method based on\nOptimality Violation. We also propose two efficient heuristic variants of\novsSPDC called ovsSDPC+ and ovsSDPC++. Through intensive numerical experiments,\nwe demonstrate that the proposed method and its variants are faster than other\nstate-of-the-art primal-dual type stochastic optimization methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 05:08:33 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Shibagaki", "Atsushi", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1703.07076", "submitter": "Esben Jannik Bjerrum", "authors": "Esben Jannik Bjerrum", "title": "SMILES Enumeration as Data Augmentation for Neural Network Modeling of\n  Molecules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simplified Molecular Input Line Entry System (SMILES) is a single line text\nrepresentation of a unique molecule. One molecule can however have multiple\nSMILES strings, which is a reason that canonical SMILES have been defined,\nwhich ensures a one to one correspondence between SMILES string and molecule.\nHere the fact that multiple SMILES represent the same molecule is explored as a\ntechnique for data augmentation of a molecular QSAR dataset modeled by a long\nshort term memory (LSTM) cell based neural network. The augmented dataset was\n130 times bigger than the original. The network trained with the augmented\ndataset shows better performance on a test set when compared to a model built\nwith only one canonical SMILES string per molecule. The correlation coefficient\nR2 on the test set was improved from 0.56 to 0.66 when using SMILES\nenumeration, and the root mean square error (RMS) likewise fell from 0.62 to\n0.55. The technique also works in the prediction phase. By taking the average\nper molecule of the predictions for the enumerated SMILES a further improvement\nto a correlation coefficient of 0.68 and a RMS of 0.52 was found.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 07:13:13 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 11:24:43 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Bjerrum", "Esben Jannik", ""]]}, {"id": "1703.07115", "submitter": "Mandar Kulkarni Mr.", "authors": "Mandar Kulkarni, Shirish Karande", "title": "Layer-wise training of deep networks using kernel similarity", "comments": null, "journal-ref": "Deep Learning for Pattern Recognition (DLPR) workshop at ICPR 2016", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown promising results in many machine learning\napplications. The hierarchical feature representation built by deep networks\nenable compact and precise encoding of the data. A kernel analysis of the\ntrained deep networks demonstrated that with deeper layers, more simple and\nmore accurate data representations are obtained. In this paper, we propose an\napproach for layer-wise training of a deep network for the supervised\nclassification task. A transformation matrix of each layer is obtained by\nsolving an optimization aimed at a better representation where a subsequent\nlayer builds its representation on the top of the features produced by a\nprevious layer. We compared the performance of our approach with a DNN trained\nusing back-propagation which has same architecture as ours. Experimental\nresults on the real image datasets demonstrate efficacy of our approach. We\nalso performed kernel analysis of layer representations to validate the claim\nof better feature encoding.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 09:53:51 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Kulkarni", "Mandar", ""], ["Karande", "Shirish", ""]]}, {"id": "1703.07131", "submitter": "Mandar Kulkarni Mr.", "authors": "Mandar Kulkarni, Kalpesh Patil, Shirish Karande", "title": "Knowledge distillation using unlabeled mismatched images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches for Knowledge Distillation (KD) either directly use\ntraining data or sample from the training data distribution. In this paper, we\ndemonstrate effectiveness of 'mismatched' unlabeled stimulus to perform KD for\nimage classification networks. For illustration, we consider scenarios where\nthis is a complete absence of training data, or mismatched stimulus has to be\nused for augmenting a small amount of training data. We demonstrate that\nstimulus complexity is a key factor for distillation's good performance. Our\nexamples include use of various datasets for stimulating MNIST and CIFAR\nteachers.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 10:34:59 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Kulkarni", "Mandar", ""], ["Patil", "Kalpesh", ""], ["Karande", "Shirish", ""]]}, {"id": "1703.07255", "submitter": "Hao Wang", "authors": "Hao Wang, Xiaodan Liang, Hao Zhang, Dit-Yan Yeung, Eric P. Xing", "title": "ZM-Net: Real-time Zero-shot Image Manipulation Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in image processing and computer vision (e.g. colorization,\nstyle transfer) can be posed as 'manipulating' an input image into a\ncorresponding output image given a user-specified guiding signal. A holy-grail\nsolution towards generic image manipulation should be able to efficiently alter\nan input image with any personalized signals (even signals unseen during\ntraining), such as diverse paintings and arbitrary descriptive attributes.\nHowever, existing methods are either inefficient to simultaneously process\nmultiple signals (let alone generalize to unseen signals), or unable to handle\nsignals from other modalities. In this paper, we make the first attempt to\naddress the zero-shot image manipulation task. We cast this problem as\nmanipulating an input image according to a parametric model whose key\nparameters can be conditionally generated from any guiding signal (even unseen\nones). To this end, we propose the Zero-shot Manipulation Net (ZM-Net), a\nfully-differentiable architecture that jointly optimizes an\nimage-transformation network (TNet) and a parameter network (PNet). The PNet\nlearns to generate key transformation parameters for the TNet given any guiding\nsignal while the TNet performs fast zero-shot image manipulation according to\nboth signal-dependent parameters from the PNet and signal-invariant parameters\nfrom the TNet itself. Extensive experiments show that our ZM-Net can perform\nhigh-quality image manipulation conditioned on different forms of guiding\nsignals (e.g. style images and attributes) in real-time (tens of milliseconds\nper image) even for unseen signals. Moreover, a large-scale style dataset with\nover 20,000 style images is also constructed to promote further research.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 15:01:59 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 17:08:40 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Wang", "Hao", ""], ["Liang", "Xiaodan", ""], ["Zhang", "Hao", ""], ["Yeung", "Dit-Yan", ""], ["Xing", "Eric P.", ""]]}, {"id": "1703.07261", "submitter": "Konstantinos Chatzilygeroudis", "authors": "Konstantinos Chatzilygeroudis, Roberto Rama, Rituraj Kaushik, Dorian\n  Goepp, Vassilis Vassiliades and Jean-Baptiste Mouret", "title": "Black-Box Data-efficient Policy Search for Robotics", "comments": "Accepted at the IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS) 2017; Code at\n  http://github.com/resibots/blackdrops; Video at http://youtu.be/kTEyYiIFGPM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most data-efficient algorithms for reinforcement learning (RL) in\nrobotics are based on uncertain dynamical models: after each episode, they\nfirst learn a dynamical model of the robot, then they use an optimization\nalgorithm to find a policy that maximizes the expected return given the model\nand its uncertainties. It is often believed that this optimization can be\ntractable only if analytical, gradient-based algorithms are used; however,\nthese algorithms require using specific families of reward functions and\npolicies, which greatly limits the flexibility of the overall approach. In this\npaper, we introduce a novel model-based RL algorithm, called Black-DROPS\n(Black-box Data-efficient RObot Policy Search) that: (1) does not impose any\nconstraint on the reward function or the policy (they are treated as\nblack-boxes), (2) is as data-efficient as the state-of-the-art algorithm for\ndata-efficient RL in robotics, and (3) is as fast (or faster) than analytical\napproaches when several cores are available. The key idea is to replace the\ngradient-based optimization algorithm with a parallel, black-box algorithm that\ntakes into account the model uncertainties. We demonstrate the performance of\nour new algorithm on two standard control benchmark problems (in simulation)\nand a low-cost robotic manipulator (with a real robot).\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 15:13:04 GMT"}, {"version": "v2", "created": "Sat, 22 Jul 2017 10:39:11 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Chatzilygeroudis", "Konstantinos", ""], ["Rama", "Roberto", ""], ["Kaushik", "Rituraj", ""], ["Goepp", "Dorian", ""], ["Vassiliades", "Vassilis", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1703.07285", "submitter": "Mathurin Massias", "authors": "Mathurin Massias and Alexandre Gramfort and Joseph Salmon", "title": "From safe screening rules to working sets for faster Lasso-type solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex sparsity-promoting regularizations are ubiquitous in modern\nstatistical learning. By construction, they yield solutions with few non-zero\ncoefficients, which correspond to saturated constraints in the dual\noptimization formulation. Working set (WS) strategies are generic optimization\ntechniques that consist in solving simpler problems that only consider a subset\nof constraints, whose indices form the WS. Working set methods therefore\ninvolve two nested iterations: the outer loop corresponds to the definition of\nthe WS and the inner loop calls a solver for the subproblems. For the Lasso\nestimator a WS is a set of features, while for a Group Lasso it refers to a set\nof groups. In practice, WS are generally small in this context so the\nassociated feature Gram matrix can fit in memory. Here we show that the\nGauss-Southwell rule (a greedy strategy for block coordinate descent\ntechniques) leads to fast solvers in this case. Combined with a working set\nstrategy based on an aggressive use of so-called Gap Safe screening rules, we\npropose a solver achieving state-of-the-art performance on sparse learning\nproblems. Results are presented on Lasso and multi-task Lasso estimators.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 15:42:38 GMT"}, {"version": "v2", "created": "Mon, 1 May 2017 10:30:25 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Massias", "Mathurin", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""]]}, {"id": "1703.07326", "submitter": "Yan Duan", "authors": "Yan Duan, Marcin Andrychowicz, Bradly C. Stadie, Jonathan Ho, Jonas\n  Schneider, Ilya Sutskever, Pieter Abbeel, Wojciech Zaremba", "title": "One-Shot Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning has been commonly applied to solve different tasks in\nisolation. This usually requires either careful feature engineering, or a\nsignificant number of samples. This is far from what we desire: ideally, robots\nshould be able to learn from very few demonstrations of any given task, and\ninstantly generalize to new situations of the same task, without requiring\ntask-specific engineering. In this paper, we propose a meta-learning framework\nfor achieving such capability, which we call one-shot imitation learning.\n  Specifically, we consider the setting where there is a very large set of\ntasks, and each task has many instantiations. For example, a task could be to\nstack all blocks on a table into a single tower, another task could be to place\nall blocks on a table into two-block towers, etc. In each case, different\ninstances of the task would consist of different sets of blocks with different\ninitial states. At training time, our algorithm is presented with pairs of\ndemonstrations for a subset of all tasks. A neural net is trained that takes as\ninput one demonstration and the current state (which initially is the initial\nstate of the other demonstration of the pair), and outputs an action with the\ngoal that the resulting sequence of states and actions matches as closely as\npossible with the second demonstration. At test time, a demonstration of a\nsingle instance of a new task is presented, and the neural net is expected to\nperform well on new instances of this new task. The use of soft attention\nallows the model to generalize to conditions and tasks unseen in the training\ndata. We anticipate that by training this model on a much greater variety of\ntasks and settings, we will obtain a general system that can turn any\ndemonstrations into robust policies that can accomplish an overwhelming variety\nof tasks.\n  Videos available at https://bit.ly/nips2017-oneshot .\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 17:22:29 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 00:24:03 GMT"}, {"version": "v3", "created": "Mon, 4 Dec 2017 21:53:23 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Duan", "Yan", ""], ["Andrychowicz", "Marcin", ""], ["Stadie", "Bradly C.", ""], ["Ho", "Jonathan", ""], ["Schneider", "Jonas", ""], ["Sutskever", "Ilya", ""], ["Abbeel", "Pieter", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "1703.07332", "submitter": "Adrian Bulat", "authors": "Adrian Bulat and Georgios Tzimiropoulos", "title": "How far are we from solving the 2D & 3D Face Alignment problem? (and a\n  dataset of 230,000 3D facial landmarks)", "comments": "accepted to ICCV 2017", "journal-ref": null, "doi": "10.1109/ICCV.2017.116", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how far a very deep neural network is from attaining\nclose to saturating performance on existing 2D and 3D face alignment datasets.\nTo this end, we make the following 5 contributions: (a) we construct, for the\nfirst time, a very strong baseline by combining a state-of-the-art architecture\nfor landmark localization with a state-of-the-art residual block, train it on a\nvery large yet synthetically expanded 2D facial landmark dataset and finally\nevaluate it on all other 2D facial landmark datasets. (b) We create a guided by\n2D landmarks network which converts 2D landmark annotations to 3D and unifies\nall existing datasets, leading to the creation of LS3D-W, the largest and most\nchallenging 3D facial landmark dataset to date ~230,000 images. (c) Following\nthat, we train a neural network for 3D face alignment and evaluate it on the\nnewly introduced LS3D-W. (d) We further look into the effect of all\n\"traditional\" factors affecting face alignment performance like large pose,\ninitialization and resolution, and introduce a \"new\" one, namely the size of\nthe network. (e) We show that both 2D and 3D face alignment networks achieve\nperformance of remarkable accuracy which is probably close to saturating the\ndatasets used. Training and testing code as well as the dataset can be\ndownloaded from https://www.adrianbulat.com/face-alignment/\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 17:37:36 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 15:03:19 GMT"}, {"version": "v3", "created": "Thu, 7 Sep 2017 16:21:37 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Bulat", "Adrian", ""], ["Tzimiropoulos", "Georgios", ""]]}, {"id": "1703.07345", "submitter": "Haichuan Yang", "authors": "Haichuan Yang, Shupeng Gui, Chuyang Ke, Daniel Stefankovic, Ryohei\n  Fujimaki, and Ji Liu", "title": "On The Projection Operator to A Three-view Cardinality Constrained Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cardinality constraint is an intrinsic way to restrict the solution\nstructure in many domains, for example, sparse learning, feature selection, and\ncompressed sensing. To solve a cardinality constrained problem, the key\nchallenge is to solve the projection onto the cardinality constraint set, which\nis NP-hard in general when there exist multiple overlapped cardinality\nconstraints. In this paper, we consider the scenario where the overlapped\ncardinality constraints satisfy a Three-view Cardinality Structure (TVCS),\nwhich reflects the natural restriction in many applications, such as\nidentification of gene regulatory networks and task-worker assignment problem.\nWe cast the projection into a linear programming, and show that for TVCS, the\nvertex solution of this linear programming is the solution for the original\nprojection problem. We further prove that such solution can be found with the\ncomplexity proportional to the number of variables and constraints. We finally\nuse synthetic experiments and two interesting applications in bioinformatics\nand crowdsourcing to validate the proposed TVCS model and method.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 17:58:03 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 17:05:57 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Yang", "Haichuan", ""], ["Gui", "Shupeng", ""], ["Ke", "Chuyang", ""], ["Stefankovic", "Daniel", ""], ["Fujimaki", "Ryohei", ""], ["Liu", "Ji", ""]]}, {"id": "1703.07348", "submitter": "Dajiang Zhou", "authors": "Xushen Han, Dajiang Zhou, Shihao Wang, and Shinji Kimura", "title": "CNN-MERP: An FPGA-Based Memory-Efficient Reconfigurable Processor for\n  Forward and Backward Propagation of Convolutional Neural Networks", "comments": null, "journal-ref": "ICCD 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale deep convolutional neural networks (CNNs) are widely used in\nmachine learning applications. While CNNs involve huge complexity, VLSI (ASIC\nand FPGA) chips that deliver high-density integration of computational\nresources are regarded as a promising platform for CNN's implementation. At\nmassive parallelism of computational units, however, the external memory\nbandwidth, which is constrained by the pin count of the VLSI chip, becomes the\nsystem bottleneck. Moreover, VLSI solutions are usually regarded as a lack of\nthe flexibility to be reconfigured for the various parameters of CNNs. This\npaper presents CNN-MERP to address these issues. CNN-MERP incorporates an\nefficient memory hierarchy that significantly reduces the bandwidth\nrequirements from multiple optimizations including on/off-chip data allocation,\ndata flow optimization and data reuse. The proposed 2-level reconfigurability\nis utilized to enable fast and efficient reconfiguration, which is based on the\ncontrol logic and the multiboot feature of FPGA. As a result, an external\nmemory bandwidth requirement of 1.94MB/GFlop is achieved, which is 55% lower\nthan prior arts. Under limited DRAM bandwidth, a system throughput of\n1244GFlop/s is achieved at the Vertex UltraScale platform, which is 5.48 times\nhigher than the state-of-the-art FPGA implementations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 01:31:23 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Han", "Xushen", ""], ["Zhou", "Dajiang", ""], ["Wang", "Shihao", ""], ["Kimura", "Shinji", ""]]}, {"id": "1703.07370", "submitter": "George Tucker", "authors": "George Tucker, Andriy Mnih, Chris J. Maddison, Dieterich Lawson,\n  Jascha Sohl-Dickstein", "title": "REBAR: Low-variance, unbiased gradient estimates for discrete latent\n  variable models", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in models with discrete latent variables is challenging due to high\nvariance gradient estimators. Generally, approaches have relied on control\nvariates to reduce the variance of the REINFORCE estimator. Recent work (Jang\net al. 2016, Maddison et al. 2016) has taken a different approach, introducing\na continuous relaxation of discrete variables to produce low-variance, but\nbiased, gradient estimates. In this work, we combine the two approaches through\na novel control variate that produces low-variance, \\emph{unbiased} gradient\nestimates. Then, we introduce a modification to the continuous relaxation and\nshow that the tightness of the relaxation can be adapted online, removing it as\na hyperparameter. We show state-of-the-art variance reduction on several\nbenchmark generative modeling tasks, generally leading to faster convergence to\na better final log-likelihood.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 18:05:31 GMT"}, {"version": "v2", "created": "Sat, 22 Apr 2017 11:04:12 GMT"}, {"version": "v3", "created": "Thu, 8 Jun 2017 20:54:49 GMT"}, {"version": "v4", "created": "Mon, 6 Nov 2017 17:50:34 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Tucker", "George", ""], ["Mnih", "Andriy", ""], ["Maddison", "Chris J.", ""], ["Lawson", "Dieterich", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1703.07394", "submitter": "Shumeet Baluja", "authors": "Shumeet Baluja", "title": "Deep Learning for Explicitly Modeling Optimization Landscapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In all but the most trivial optimization problems, the structure of the\nsolutions exhibit complex interdependencies between the input parameters.\nDecades of research with stochastic search techniques has shown the benefit of\nexplicitly modeling the interactions between sets of parameters and the overall\nquality of the solutions discovered. We demonstrate a novel method, based on\nlearning deep networks, to model the global landscapes of optimization\nproblems. To represent the search space concisely and accurately, the deep\nnetworks must encode information about the underlying parameter interactions\nand their contributions to the quality of the solution. Once the networks are\ntrained, the networks are probed to reveal parameter combinations with high\nexpected performance with respect to the optimization task. These estimates are\nused to initialize fast, randomized, local search algorithms, which in turn\nexpose more information about the search space that is subsequently used to\nrefine the models. We demonstrate the technique on multiple optimization\nproblems that have arisen in a variety of real-world domains, including:\npacking, graphics, job scheduling, layout and compression. The problems include\ncombinatoric search spaces, discontinuous and highly non-linear spaces, and\nspan binary, higher-cardinality discrete, as well as continuous parameters.\nStrengths, limitations, and extensions of the approach are extensively\ndiscussed and demonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 19:12:35 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Baluja", "Shumeet", ""]]}, {"id": "1703.07432", "submitter": "Nika Haghtalab", "authors": "Pranjal Awasthi, Avrim Blum, Nika Haghtalab, Yishay Mansour", "title": "Efficient PAC Learning from the Crowd", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years crowdsourcing has become the method of choice for gathering\nlabeled training data for learning algorithms. Standard approaches to\ncrowdsourcing view the process of acquiring labeled data separately from the\nprocess of learning a classifier from the gathered data. This can give rise to\ncomputational and statistical challenges. For example, in most cases there are\nno known computationally efficient learning algorithms that are robust to the\nhigh level of noise that exists in crowdsourced data, and efforts to eliminate\nnoise through voting often require a large number of queries per example.\n  In this paper, we show how by interleaving the process of labeling and\nlearning, we can attain computational efficiency with much less overhead in the\nlabeling cost. In particular, we consider the realizable setting where there\nexists a true target function in $\\mathcal{F}$ and consider a pool of labelers.\nWhen a noticeable fraction of the labelers are perfect, and the rest behave\narbitrarily, we show that any $\\mathcal{F}$ that can be efficiently learned in\nthe traditional realizable PAC model can be learned in a computationally\nefficient manner by querying the crowd, despite high amounts of noise in the\nresponses. Moreover, we show that this can be done while each labeler only\nlabels a constant number of examples and the number of labels requested per\nexample, on average, is a constant. When no perfect labelers exist, a related\ntask is to find a set of the labelers which are good but not perfect. We show\nthat we can identify all good labelers, when at least the majority of labelers\nare good.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 21:05:27 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 21:21:41 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Blum", "Avrim", ""], ["Haghtalab", "Nika", ""], ["Mansour", "Yishay", ""]]}, {"id": "1703.07473", "submitter": "Niko S\\\"underhauf", "authors": "Feras Dayoub, Niko S\\\"underhauf, Peter Corke", "title": "Episode-Based Active Learning with Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate different strategies for active learning with Bayesian deep\nneural networks. We focus our analysis on scenarios where new, unlabeled data\nis obtained episodically, such as commonly encountered in mobile robotics\napplications. An evaluation of different strategies for acquisition, updating,\nand final training on the CIFAR-10 dataset shows that incremental network\nupdates with final training on the accumulated acquisition set are essential\nfor best performance, while limiting the amount of required human labeling\nlabor.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 23:56:51 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Dayoub", "Feras", ""], ["S\u00fcnderhauf", "Niko", ""], ["Corke", "Peter", ""]]}, {"id": "1703.07506", "submitter": "Marc Goessling", "authors": "Marc Goessling", "title": "LogitBoost autoregressive networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.csda.2017.03.010", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate binary distributions can be decomposed into products of\nunivariate conditional distributions. Recently popular approaches have modeled\nthese conditionals through neural networks with sophisticated weight-sharing\nstructures. It is shown that state-of-the-art performance on several standard\nbenchmark datasets can actually be achieved by training separate probability\nestimators for each dimension. In that case, model training can be trivially\nparallelized over data dimensions. On the other hand, complexity control has to\nbe performed for each learned conditional distribution. Three possible methods\nare considered and experimentally compared. The estimator that is employed for\neach conditional is LogitBoost. Similarities and differences between the\nproposed approach and autoregressive models based on neural networks are\ndiscussed in detail.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 03:26:32 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Goessling", "Marc", ""]]}, {"id": "1703.07588", "submitter": "Yu-Hsuan Wang", "authors": "Yu-Hsuan Wang, Cheng-Tao Chung, Hung-yi Lee", "title": "Gate Activation Signal Analysis for Gated Recurrent Neural Networks and\n  Its Correlation with Phoneme Boundaries", "comments": "5 pages, The code is available at\n  https://github.com/allyoushawn/timit_gas.git", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the gate activation signals inside the gated\nrecurrent neural networks, and find the temporal structure of such signals is\nhighly correlated with the phoneme boundaries. This correlation is further\nverified by a set of experiments for phoneme segmentation, in which better\nresults compared to standard approaches were obtained.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 10:08:51 GMT"}, {"version": "v2", "created": "Thu, 31 Aug 2017 12:01:36 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Wang", "Yu-Hsuan", ""], ["Chung", "Cheng-Tao", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1703.07608", "submitter": "Ian Osband", "authors": "Ian Osband, Benjamin Van Roy, Daniel Russo, Zheng Wen", "title": "Deep Exploration via Randomized Value Functions", "comments": "Accepted for publication in Journal of Machine Learning Research 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of randomized value functions to guide deep exploration in\nreinforcement learning. This offers an elegant means for synthesizing\nstatistically and computationally efficient exploration with common practical\napproaches to value function learning. We present several reinforcement\nlearning algorithms that leverage randomized value functions and demonstrate\ntheir efficacy through computational studies. We also prove a regret bound that\nestablishes statistical efficiency with a tabular representation.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 11:53:53 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 17:13:06 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 09:17:37 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2019 23:48:32 GMT"}, {"version": "v5", "created": "Mon, 23 Sep 2019 18:29:02 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Osband", "Ian", ""], ["Van Roy", "Benjamin", ""], ["Russo", "Daniel", ""], ["Wen", "Zheng", ""]]}, {"id": "1703.07625", "submitter": "Joris Gu\\'erin", "authors": "Joris Gu\\'erin, Olivier Gibaru, St\\'ephane Thiery and Eric Nyiri", "title": "Clustering for Different Scales of Measurement - the Gap-Ratio Weighted\n  K-means Algorithm", "comments": "13 pages, 6 figures, 2 tables. This paper is under the review process\n  for AIAP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a method for clustering data that are spread out over\nlarge regions and which dimensions are on different scales of measurement. Such\nan algorithm was developed to implement a robotics application consisting in\nsorting and storing objects in an unsupervised way. The toy dataset used to\nvalidate such application consists of Lego bricks of different shapes and\ncolors. The uncontrolled lighting conditions together with the use of RGB color\nfeatures, respectively involve data with a large spread and different levels of\nmeasurement between data dimensions. To overcome the combination of these two\ncharacteristics in the data, we have developed a new weighted K-means\nalgorithm, called gap-ratio K-means, which consists in weighting each dimension\nof the feature space before running the K-means algorithm. The weight\nassociated with a feature is proportional to the ratio of the biggest gap\nbetween two consecutive data points, and the average of all the other gaps.\nThis method is compared with two other variants of K-means on the Lego bricks\nclustering problem as well as two other common classification datasets.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 12:50:15 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Gu\u00e9rin", "Joris", ""], ["Gibaru", "Olivier", ""], ["Thiery", "St\u00e9phane", ""], ["Nyiri", "Eric", ""]]}, {"id": "1703.07638", "submitter": "Shaul Zevin", "authors": "Shaul Zevin, Catherine Holzem", "title": "Machine Learning Based Source Code Classification Using Syntax Oriented\n  Features", "comments": "13 pages, 4 tables, 4 examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As of today the programming language of the vast majority of the published\nsource code is manually specified or programmatically assigned based on the\nsole file extension. In this paper we show that the source code programming\nlanguage identification task can be fully automated using machine learning\ntechniques. We first define the criteria that a production-level automatic\nprogramming language identification solution should meet. Our criteria include\naccuracy, programming language coverage, extensibility and performance. We then\ndescribe our approach: How training files are preprocessed for extracting\nfeatures that mimic grammar productions, and then how these extracted grammar\nproductions are used for the training and testing of our classifier. We achieve\na 99 percent accuracy rate while classifying 29 of the most popular programming\nlanguages with a Maximum Entropy classifier.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 10:44:40 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Zevin", "Shaul", ""], ["Holzem", "Catherine", ""]]}, {"id": "1703.07684", "submitter": "Camille Couprie", "authors": "Pauline Luc, Natalia Neverova, Camille Couprie, Jakob Verbeek, Yann\n  LeCun", "title": "Predicting Deeper into the Future of Semantic Segmentation", "comments": "Accepted to ICCV 2017. Supplementary material available on the\n  authors' webpages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to predict and therefore to anticipate the future is an important\nattribute of intelligence. It is also of utmost importance in real-time\nsystems, e.g. in robotics or autonomous driving, which depend on visual scene\nunderstanding for decision making. While prediction of the raw RGB pixel values\nin future video frames has been studied in previous work, here we introduce the\nnovel task of predicting semantic segmentations of future frames. Given a\nsequence of video frames, our goal is to predict segmentation maps of not yet\nobserved video frames that lie up to a second or further in the future. We\ndevelop an autoregressive convolutional neural network that learns to\niteratively generate multiple frames. Our results on the Cityscapes dataset\nshow that directly predicting future segmentations is substantially better than\npredicting and then segmenting future RGB frames. Prediction results up to half\na second in the future are visually convincing and are much more accurate than\nthose of a baseline based on warping semantic segmentations using optical flow.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 14:45:15 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 13:54:24 GMT"}, {"version": "v3", "created": "Tue, 8 Aug 2017 10:02:36 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Luc", "Pauline", ""], ["Neverova", "Natalia", ""], ["Couprie", "Camille", ""], ["Verbeek", "Jakob", ""], ["LeCun", "Yann", ""]]}, {"id": "1703.07698", "submitter": "Morteza Ashraphijuo", "authors": "Morteza Ashraphijuo, Xiaodong Wang", "title": "Characterization of Deterministic and Probabilistic Sampling Patterns\n  for Finite Completability of Low Tensor-Train Rank Tensor", "comments": "arXiv admin note: text overlap with arXiv:1612.01597", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.AG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the fundamental conditions for low-rank tensor\ncompletion given the separation or tensor-train (TT) rank, i.e., ranks of\nunfoldings. We exploit the algebraic structure of the TT decomposition to\nobtain the deterministic necessary and sufficient conditions on the locations\nof the samples to ensure finite completability. Specifically, we propose an\nalgebraic geometric analysis on the TT manifold that can incorporate the whole\nrank vector simultaneously in contrast to the existing approach based on the\nGrassmannian manifold that can only incorporate one rank component. Our\nproposed technique characterizes the algebraic independence of a set of\npolynomials defined based on the sampling pattern and the TT decomposition,\nwhich is instrumental to obtaining the deterministic condition on the sampling\npattern for finite completability. In addition, based on the proposed analysis,\nassuming that the entries of the tensor are sampled independently with\nprobability $p$, we derive a lower bound on the sampling probability $p$, or\nequivalently, the number of sampled entries that ensures finite completability\nwith high probability. Moreover, we also provide the deterministic and\nprobabilistic conditions for unique completability.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 15:11:55 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Ashraphijuo", "Morteza", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1703.07710", "submitter": "Christoph Dann", "authors": "Christoph Dann, Tor Lattimore, Emma Brunskill", "title": "Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement\n  Learning", "comments": "appears in Neural Information Processing Systems 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical performance bounds for reinforcement learning (RL) algorithms can\nbe critical for high-stakes applications like healthcare. This paper introduces\na new framework for theoretically measuring the performance of such algorithms\ncalled Uniform-PAC, which is a strengthening of the classical Probably\nApproximately Correct (PAC) framework. In contrast to the PAC framework, the\nuniform version may be used to derive high probability regret guarantees and so\nforms a bridge between the two setups that has been missing in the literature.\nWe demonstrate the benefits of the new framework for finite-state episodic MDPs\nwith a new algorithm that is Uniform-PAC and simultaneously achieves optimal\nregret and PAC guarantees except for a factor of the horizon.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 15:34:23 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 21:04:38 GMT"}, {"version": "v3", "created": "Tue, 2 Jan 2018 13:25:46 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Dann", "Christoph", ""], ["Lattimore", "Tor", ""], ["Brunskill", "Emma", ""]]}, {"id": "1703.07718", "submitter": "Emmanuel Bengio", "authors": "Emmanuel Bengio, Valentin Thomas, Joelle Pineau, Doina Precup, Yoshua\n  Bengio", "title": "Independently Controllable Features", "comments": "RLDM submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding features that disentangle the different causes of variation in real\ndata is a difficult task, that has nonetheless received considerable attention\nin static domains like natural images. Interactive environments, in which an\nagent can deliberately take actions, offer an opportunity to tackle this task\nbetter, because the agent can experiment with different actions and observe\ntheir effects. We introduce the idea that in interactive environments, latent\nfactors that control the variation in observed data can be identified by\nfiguring out what the agent can control. We propose a naive method to find\nfactors that explain or measure the effect of the actions of a learner, and\ntest it in illustrative experiments.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 15:54:18 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Bengio", "Emmanuel", ""], ["Thomas", "Valentin", ""], ["Pineau", "Joelle", ""], ["Precup", "Doina", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.07758", "submitter": "Hongyang Zhang", "authors": "Maria-Florina Balcan and Hongyang Zhang", "title": "Sample and Computationally Efficient Learning Algorithms under S-Concave\n  Distributions", "comments": "Appear in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide new results for noise-tolerant and sample-efficient learning\nalgorithms under $s$-concave distributions. The new class of $s$-concave\ndistributions is a broad and natural generalization of log-concavity, and\nincludes many important additional distributions, e.g., the Pareto distribution\nand $t$-distribution. This class has been studied in the context of efficient\nsampling, integration, and optimization, but much remains unknown about the\ngeometry of this class of distributions and their applications in the context\nof learning. The challenge is that unlike the commonly used distributions in\nlearning (uniform or more generally log-concave distributions), this broader\nclass is not closed under the marginalization operator and many such\ndistributions are fat-tailed. In this work, we introduce new convex geometry\ntools to study the properties of $s$-concave distributions and use these\nproperties to provide bounds on quantities of interest to learning including\nthe probability of disagreement between two halfspaces, disagreement outside a\nband, and the disagreement coefficient. We use these results to significantly\ngeneralize prior results for margin-based active learning, disagreement-based\nactive learning, and passive learning of intersections of halfspaces. Our\nanalysis of geometric properties of $s$-concave distributions might be of\nindependent interest to optimization more broadly.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 17:27:57 GMT"}, {"version": "v2", "created": "Sat, 27 Jan 2018 21:10:19 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Zhang", "Hongyang", ""]]}, {"id": "1703.07771", "submitter": "Hrayr Harutyunyan", "authors": "Hrayr Harutyunyan, Hrant Khachatrian, David C. Kale, Greg Ver Steeg,\n  and Aram Galstyan", "title": "Multitask learning and benchmarking with clinical time series data", "comments": "This version of the paper adds details about the generation of the\n  benchmark tasks and describes improved neural baselines", "journal-ref": "Scientific Data 6 (2019) 96", "doi": "10.1038/s41597-019-0103-9", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health care is one of the most exciting frontiers in data mining and machine\nlearning. Successful adoption of electronic health records (EHRs) created an\nexplosion in digital clinical data available for analysis, but progress in\nmachine learning for healthcare research has been difficult to measure because\nof the absence of publicly available benchmark data sets. To address this\nproblem, we propose four clinical prediction benchmarks using data derived from\nthe publicly available Medical Information Mart for Intensive Care (MIMIC-III)\ndatabase. These tasks cover a range of clinical problems including modeling\nrisk of mortality, forecasting length of stay, detecting physiologic decline,\nand phenotype classification. We propose strong linear and neural baselines for\nall four tasks and evaluate the effect of deep supervision, multitask training\nand data-specific architectural modifications on the performance of neural\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 17:53:27 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 21:56:38 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 19:21:40 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Harutyunyan", "Hrayr", ""], ["Khachatrian", "Hrant", ""], ["Kale", "David C.", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1703.07807", "submitter": "Theja Tulabandhula", "authors": "Arun Rajkumar and Koyel Mukherjee and Theja Tulabandhula", "title": "Learning to Partition using Score Based Compatibilities", "comments": "Appears in the Proceedings of the 16th International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning to partition users into groups, where one\nmust learn the compatibilities between the users to achieve optimal groupings.\nWe define four natural objectives that optimize for average and worst case\ncompatibilities and propose new algorithms for adaptively learning optimal\ngroupings. When we do not impose any structure on the compatibilities, we show\nthat the group formation objectives considered are $NP$ hard to solve and we\neither give approximation guarantees or prove inapproximability results. We\nthen introduce an elegant structure, namely that of \\textit{intrinsic scores},\nthat makes many of these problems polynomial time solvable. We explicitly\ncharacterize the optimal groupings under this structure and show that the\noptimal solutions are related to \\emph{homophilous} and \\emph{heterophilous}\npartitions, well-studied in the psychology literature. For one of the four\nobjectives, we show $NP$ hardness under the score structure and give a\n$\\frac{1}{2}$ approximation algorithm for which no constant approximation was\nknown thus far. Finally, under the score structure, we propose an online low\nsample complexity PAC algorithm for learning the optimal partition. We\ndemonstrate the efficacy of the proposed algorithm on synthetic and real world\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 18:30:10 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Rajkumar", "Arun", ""], ["Mukherjee", "Koyel", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1703.07822", "submitter": "Shaojun Zhu", "authors": "Shaojun Zhu, Andrew Kimmel, Abdeslam Boularias", "title": "Information-theoretic Model Identification and Policy Search using\n  Physics Engines with Application to Robotic Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of a robot learning the mechanical properties of\nobjects through physical interaction with the object, and introduce a\npractical, data-efficient approach for identifying the motion models of these\nobjects. The proposed method utilizes a physics engine, where the robot seeks\nto identify the inertial and friction parameters of the object by simulating\nits motion under different values of the parameters and identifying those that\nresult in a simulation which matches the observed real motions. The problem is\nsolved in a Bayesian optimization framework. The same framework is used for\nboth identifying the model of an object online and searching for a policy that\nwould minimize a given cost function according to the identified model.\nExperimental results both in simulation and using a real robot indicate that\nthe proposed method outperforms state-of-the-art model-free reinforcement\nlearning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 19:08:48 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Zhu", "Shaojun", ""], ["Kimmel", "Andrew", ""], ["Boularias", "Abdeslam", ""]]}, {"id": "1703.07823", "submitter": "Mehrdad Farajtabar", "authors": "Mehrdad Farajtabar, Jiachen Yang, Xiaojing Ye, Huan Xu, Rakshit\n  Trivedi, Elias Khalil, Shuang Li, Le Song, Hongyuan Zha", "title": "Fake News Mitigation via Point Process Based Intervention", "comments": "Point Process, Hawkes Process, Social Networks, Intervention and\n  Control, Reinforcement Learning, ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first multistage intervention framework that tackles fake news\nin social networks by combining reinforcement learning with a point process\nnetwork activity model. The spread of fake news and mitigation events within\nthe network is modeled by a multivariate Hawkes process with additional\nexogenous control terms. By choosing a feature representation of states,\ndefining mitigation actions and constructing reward functions to measure the\neffectiveness of mitigation activities, we map the problem of fake news\nmitigation into the reinforcement learning framework. We develop a policy\niteration method unique to the multivariate networked point process, with the\ngoal of optimizing the actions for maximal total reward under budget\nconstraints. Our method shows promising performance in real-time intervention\nexperiments on a Twitter network to mitigate a surrogate fake news campaign,\nand outperforms alternatives on synthetic datasets.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 19:09:12 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 20:59:29 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Farajtabar", "Mehrdad", ""], ["Yang", "Jiachen", ""], ["Ye", "Xiaojing", ""], ["Xu", "Huan", ""], ["Trivedi", "Rakshit", ""], ["Khalil", "Elias", ""], ["Li", "Shuang", ""], ["Song", "Le", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1703.07830", "submitter": "Mircea Andrecut Dr", "authors": "M. Andrecut", "title": "Randomized Kernel Methods for Least-Squares Support Vector Machines", "comments": "16 pages, 6 figures", "journal-ref": "Int. J. Mod. Phys. C, 28, 1750015 (2017)", "doi": "10.1142/S0129183117500152", "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The least-squares support vector machine is a frequently used kernel method\nfor non-linear regression and classification tasks. Here we discuss several\napproximation algorithms for the least-squares support vector machine\nclassifier. The proposed methods are based on randomized block kernel matrices,\nand we show that they provide good accuracy and reliable scaling for\nmulti-class classification problems with relatively large data sets. Also, we\npresent several numerical experiments that illustrate the practical\napplicability of the proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 19:33:54 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Andrecut", "M.", ""]]}, {"id": "1703.07841", "submitter": "Maysum Panju", "authors": "Ri Wang, Maysum Panju, Mahmood Gohari", "title": "Classification-based RNN machine translation using GRUs", "comments": "7 pages, 1 figure; graduate course research project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report the results of our classification-based machine translation model,\nbuilt upon the framework of a recurrent neural network using gated recurrent\nunits. Unlike other RNN models that attempt to maximize the overall conditional\nlog probability of sentences against sentences, our model focuses a\nclassification approach of estimating the conditional probability of the next\nword given the input sequence. This simpler approach using GRUs was hoped to be\ncomparable with more complicated RNN models, but achievements in this\nimplementation were modest and there remains a lot of room for improving this\nclassification approach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 20:31:47 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Wang", "Ri", ""], ["Panju", "Maysum", ""], ["Gohari", "Mahmood", ""]]}, {"id": "1703.07844", "submitter": "Daniele Ramazzotti", "authors": "Bo Wang and Daniele Ramazzotti and Luca De Sano and Junjie Zhu and\n  Emma Pierson and Serafim Batzoglou", "title": "SIMLR: A Tool for Large-Scale Genomic Analyses by Multi-Kernel Learning", "comments": null, "journal-ref": null, "doi": "10.1002/pmic.201700232", "report-no": null, "categories": "q-bio.GN cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We here present SIMLR (Single-cell Interpretation via Multi-kernel LeaRning),\nan open-source tool that implements a novel framework to learn a\nsample-to-sample similarity measure from expression data observed for\nheterogenous samples. SIMLR can be effectively used to perform tasks such as\ndimension reduction, clustering, and visualization of heterogeneous populations\nof samples. SIMLR was benchmarked against state-of-the-art methods for these\nthree tasks on several public datasets, showing it to be scalable and capable\nof greatly improving clustering performance, as well as providing valuable\ninsights by making the data more interpretable via better a visualization.\nAvailability and Implementation\n  SIMLR is available on GitHub in both R and MATLAB implementations.\nFurthermore, it is also available as an R package on http://bioconductor.org.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 06:48:59 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 20:12:44 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Wang", "Bo", ""], ["Ramazzotti", "Daniele", ""], ["De Sano", "Luca", ""], ["Zhu", "Junjie", ""], ["Pierson", "Emma", ""], ["Batzoglou", "Serafim", ""]]}, {"id": "1703.07853", "submitter": "Vikas Jain", "authors": "Vikas Jain and Theja Tulabandhula", "title": "Faster Reinforcement Learning Using Active Simulators", "comments": "12 pages and 4 figures More experiments added to the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose several online methods to build a \\emph{learning\ncurriculum} from a given set of target-task-specific training tasks in order to\nspeed up reinforcement learning (RL). These methods can decrease the total\ntraining time needed by an RL agent compared to training on the target task\nfrom scratch. Unlike traditional transfer learning, we consider creating a\nsequence from several training tasks in order to provide the most benefit in\nterms of reducing the total time to train.\n  Our methods utilize the learning trajectory of the agent on the curriculum\ntasks seen so far to decide which tasks to train on next. An attractive feature\nof our methods is that they are weakly coupled to the choice of the RL\nalgorithm as well as the transfer learning method. Further, when there is\ndomain information available, our methods can incorporate such knowledge to\nfurther speed up the learning. We experimentally show that these methods can be\nused to obtain suitable learning curricula that speed up the overall training\ntime on two different domains.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 21:07:35 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 11:48:31 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Jain", "Vikas", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1703.07872", "submitter": "Amit Daniely", "authors": "Amit Daniely, Roy Frostig, Vineet Gupta, Yoram Singer", "title": "Random Features for Compositional Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe and analyze a simple random feature scheme (RFS) from prescribed\ncompositional kernels. The compositional kernels we use are inspired by the\nstructure of convolutional neural networks and kernels. The resulting scheme\nyields sparse and efficiently computable features. Each random feature can be\nrepresented as an algebraic expression over a small number of (random) paths in\na composition tree. Thus, compositional random features can be stored\ncompactly. The discrete nature of the generation process enables de-duplication\nof repeated features, further compacting the representation and increasing the\ndiversity of the embeddings. Our approach complements and can be combined with\nprevious random feature schemes.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 22:05:04 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Daniely", "Amit", ""], ["Frostig", "Roy", ""], ["Gupta", "Vineet", ""], ["Singer", "Yoram", ""]]}, {"id": "1703.07909", "submitter": "Tegjyot Singh Sethi", "authors": "Tegjyot Singh Sethi, Mehmed Kantardzic", "title": "Data Driven Exploratory Attacks on Black Box Classifiers in Adversarial\n  Domains", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2018.02.007", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While modern day web applications aim to create impact at the civilization\nlevel, they have become vulnerable to adversarial activity, where the next\ncyber-attack can take any shape and can originate from anywhere. The increasing\nscale and sophistication of attacks, has prompted the need for a data driven\nsolution, with machine learning forming the core of many cybersecurity systems.\nMachine learning was not designed with security in mind, and the essential\nassumption of stationarity, requiring that the training and testing data follow\nsimilar distributions, is violated in an adversarial domain. In this paper, an\nadversary's view point of a classification based system, is presented. Based on\na formal adversarial model, the Seed-Explore-Exploit framework is presented,\nfor simulating the generation of data driven and reverse engineering attacks on\nclassifiers. Experimental evaluation, on 10 real world datasets and using the\nGoogle Cloud Prediction Platform, demonstrates the innate vulnerability of\nclassifiers and the ease with which evasion can be carried out, without any\nexplicit information about the classifier type, the training data or the\napplication domain. The proposed framework, algorithms and empirical\nevaluation, serve as a white hat analysis of the vulnerabilities, and aim to\nfoster the development of secure machine learning frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 02:40:36 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sethi", "Tegjyot Singh", ""], ["Kantardzic", "Mehmed", ""]]}, {"id": "1703.07915", "submitter": "Dhagash Mehta", "authors": "Andrew J. Ballard, Ritankar Das, Stefano Martiniani, Dhagash Mehta,\n  Levent Sagun, Jacob D. Stevenson, David J. Wales", "title": "Perspective: Energy Landscapes for Machine Learning", "comments": "41 pages, 25 figures. Accepted for publication in Physical Chemistry\n  Chemical Physics, 2017", "journal-ref": null, "doi": "10.1039/C7CP01108C", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.CV cs.LG hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques are being increasingly used as flexible\nnon-linear fitting and prediction tools in the physical sciences. Fitting\nfunctions that exhibit multiple solutions as local minima can be analysed in\nterms of the corresponding machine learning landscape. Methods to explore and\nvisualise molecular potential energy landscapes can be applied to these machine\nlearning landscapes to gain new insight into the solution space involved in\ntraining and the nature of the corresponding predictions. In particular, we can\ndefine quantities analogous to molecular structure, thermodynamics, and\nkinetics, and relate these emergent properties to the structure of the\nunderlying landscape. This Perspective aims to describe these analogies with\nexamples from recent applications, and suggest avenues for new\ninterdisciplinary research.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 03:17:14 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Ballard", "Andrew J.", ""], ["Das", "Ritankar", ""], ["Martiniani", "Stefano", ""], ["Mehta", "Dhagash", ""], ["Sagun", "Levent", ""], ["Stevenson", "Jacob D.", ""], ["Wales", "David J.", ""]]}, {"id": "1703.07940", "submitter": "Edward Barker", "authors": "Edward Barker and Charl Ras", "title": "Unsupervised Basis Function Adaptation for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using reinforcement learning (RL) algorithms it is common, given a large\nstate space, to introduce some form of approximation architecture for the value\nfunction (VF). The exact form of this architecture can have a significant\neffect on an agent's performance, however, and determining a suitable\napproximation architecture can often be a highly complex task. Consequently\nthere is currently interest among researchers in the potential for allowing RL\nalgorithms to adaptively generate (i.e. to learn) approximation architectures.\nOne relatively unexplored method of adapting approximation architectures\ninvolves using feedback regarding the frequency with which an agent has visited\ncertain states to guide which areas of the state space to approximate with\ngreater detail. In this article we will: (a) informally discuss the potential\nadvantages offered by such methods; (b) introduce a new algorithm based on such\nmethods which adapts a state aggregation approximation architecture on-line and\nis designed for use in conjunction with SARSA; (c) provide theoretical results,\nin a policy evaluation setting, regarding this particular algorithm's\ncomplexity, convergence properties and potential to reduce VF error; and\nfinally (d) test experimentally the extent to which this algorithm can improve\nperformance given a number of different test problems. Taken together our\nresults suggest that our algorithm (and potentially such methods more\ngenerally) can provide a versatile and computationally lightweight means of\nsignificantly boosting RL performance given suitable conditions which are\ncommonly encountered in practice.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 05:23:34 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 21:26:30 GMT"}, {"version": "v3", "created": "Sat, 16 Feb 2019 23:14:40 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Barker", "Edward", ""], ["Ras", "Charl", ""]]}, {"id": "1703.07943", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "Role of zero synapses in unsupervised feature learning", "comments": "6 pages, 4 figures, to appear in J. Phys A as a LETTER", "journal-ref": null, "doi": "10.1088/1751-8121/aaa631", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.stat-mech cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synapses in real neural circuits can take discrete values, including zero\n(silent or potential) synapses. The computational role of zero synapses in\nunsupervised feature learning of unlabeled noisy data is still unclear, thus it\nis important to understand how the sparseness of synaptic activity is shaped\nduring learning and its relationship with receptive field formation. Here, we\nformulate this kind of sparse feature learning by a statistical mechanics\napproach. We find that learning decreases the fraction of zero synapses, and\nwhen the fraction decreases rapidly around a critical data size, an\nintrinsically structured receptive field starts to develop. Further increasing\nthe data size refines the receptive field, while a very small fraction of zero\nsynapses remain to act as contour detectors. This phenomenon is discovered not\nonly in learning a handwritten digits dataset, but also in learning retinal\nneural activity measured in a natural-movie-stimuli experiment.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 06:19:47 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 08:07:52 GMT"}, {"version": "v3", "created": "Wed, 12 Jul 2017 05:13:42 GMT"}, {"version": "v4", "created": "Wed, 10 Jan 2018 06:57:00 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Huang", "Haiping", ""]]}, {"id": "1703.07948", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, Yuanyuan Liu, James Cheng, and Jiacheng Zhuo", "title": "Fast Stochastic Variance Reduced Gradient Method with Momentum\n  Acceleration for Machine Learning", "comments": "Corrected a few typos in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, research on accelerated stochastic gradient descent methods (e.g.,\nSVRG) has made exciting progress (e.g., linear convergence for strongly convex\nproblems). However, the best-known methods (e.g., Katyusha) requires at least\ntwo auxiliary variables and two momentum parameters. In this paper, we propose\na fast stochastic variance reduction gradient (FSVRG) method, in which we\ndesign a novel update rule with the Nesterov's momentum and incorporate the\ntechnique of growing epoch size. FSVRG has only one auxiliary variable and one\nmomentum weight, and thus it is much simpler and has much lower per-iteration\ncomplexity. We prove that FSVRG achieves linear convergence for strongly convex\nproblems and the optimal $\\mathcal{O}(1/T^2)$ convergence rate for non-strongly\nconvex problems, where $T$ is the number of outer-iterations. We also extend\nFSVRG to directly solve the problems with non-smooth component functions, such\nas SVM. Finally, we empirically study the performance of FSVRG for solving\nvarious machine learning problems such as logistic regression, ridge\nregression, Lasso and SVM. Our results show that FSVRG outperforms the\nstate-of-the-art stochastic methods, including Katyusha.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 07:13:28 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 17:16:49 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Shang", "Fanhua", ""], ["Liu", "Yuanyuan", ""], ["Cheng", "James", ""], ["Zhuo", "Jiacheng", ""]]}, {"id": "1703.07950", "submitter": "Shaked Shammah", "authors": "Shai Shalev-Shwartz and Ohad Shamir and Shaked Shammah", "title": "Failures of Gradient-Based Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Learning has become the go-to solution for a broad\nrange of applications, often outperforming state-of-the-art. However, it is\nimportant, for both theoreticians and practitioners, to gain a deeper\nunderstanding of the difficulties and limitations associated with common\napproaches and algorithms. We describe four types of simple problems, for which\nthe gradient-based algorithms commonly used in deep learning either fail or\nsuffer from significant difficulties. We illustrate the failures through\npractical experiments, and provide theoretical insights explaining their\nsource, and how they might be remedied.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 07:16:37 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 05:23:26 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Shalev-Shwartz", "Shai", ""], ["Shamir", "Ohad", ""], ["Shammah", "Shaked", ""]]}, {"id": "1703.07980", "submitter": "Fengfu Li", "authors": "Fengfu Li, Hong Qiao, Bo Zhang, Xuanyang Xi", "title": "Discriminatively Boosted Image Clustering with Fully Convolutional\n  Auto-Encoders", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional image clustering methods take a two-step approach, feature\nlearning and clustering, sequentially. However, recent research results\ndemonstrated that combining the separated phases in a unified framework and\ntraining them jointly can achieve a better performance. In this paper, we first\nintroduce fully convolutional auto-encoders for image feature learning and then\npropose a unified clustering framework to learn image representations and\ncluster centers jointly based on a fully convolutional auto-encoder and soft\n$k$-means scores. At initial stages of the learning procedure, the\nrepresentations extracted from the auto-encoder may not be very discriminative\nfor latter clustering. We address this issue by adopting a boosted\ndiscriminative distribution, where high score assignments are highlighted and\nlow score ones are de-emphasized. With the gradually boosted discrimination,\nclustering assignment scores are discriminated and cluster purities are\nenlarged. Experiments on several vision benchmark datasets show that our\nmethods can achieve a state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 09:49:37 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Li", "Fengfu", ""], ["Qiao", "Hong", ""], ["Zhang", "Bo", ""], ["Xi", "Xuanyang", ""]]}, {"id": "1703.08002", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Philemon Brakel, Maurizio Omologo, Yoshua Bengio", "title": "A network of deep neural networks for distant speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the remarkable progress recently made in distant speech recognition,\nstate-of-the-art technology still suffers from a lack of robustness, especially\nwhen adverse acoustic conditions characterized by non-stationary noises and\nreverberation are met. A prominent limitation of current systems lies in the\nlack of matching and communication between the various technologies involved in\nthe distant speech recognition process. The speech enhancement and speech\nrecognition modules are, for instance, often trained independently. Moreover,\nthe speech enhancement normally helps the speech recognizer, but the output of\nthe latter is not commonly used, in turn, to improve the speech enhancement. To\naddress both concerns, we propose a novel architecture based on a network of\ndeep neural networks, where all the components are jointly trained and better\ncooperate with each other thanks to a full communication scheme between them.\nExperiments, conducted using different datasets, tasks and acoustic conditions,\nrevealed that the proposed framework can overtake other competitive solutions,\nincluding recent joint training approaches.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 11:02:47 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Brakel", "Philemon", ""], ["Omologo", "Maurizio", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.08013", "submitter": "Mao Tan", "authors": "Mao Tan, Si-Ping Yuan, Yong-Xin Su", "title": "Content-based similar document image retrieval using fusion of CNN\n  features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid increase of digitized document give birth to high demand of document\nimage retrieval. While conventional document image retrieval approaches depend\non complex OCR-based text recognition and text similarity detection, this paper\nproposes a new content-based approach, in which more attention is paid to\nfeatures extraction and fusion. In the proposed approach, multiple features of\ndocument images are extracted by different CNN models. After that, the\nextracted CNN features are reduced and fused into weighted average feature.\nFinally, the document images are ranked based on feature similarity to a\nprovided query image. Experimental procedure is performed on a group of\ndocument images that transformed from academic papers, which contain both\nEnglish and Chinese document, the results show that the proposed approach has\ngood ability to retrieve document images with similar text content, and the\nfusion of CNN features can effectively improve the retrieval accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 11:35:27 GMT"}, {"version": "v2", "created": "Fri, 24 Mar 2017 09:30:41 GMT"}, {"version": "v3", "created": "Fri, 1 Sep 2017 00:34:52 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Tan", "Mao", ""], ["Yuan", "Si-Ping", ""], ["Su", "Yong-Xin", ""]]}, {"id": "1703.08131", "submitter": "Pantelis Bouboulis", "authors": "Pantelis Bouboulis, Symeon Chouvardas, Sergios Theodoridis", "title": "Online Distributed Learning Over Networks in RKH Spaces Using Random\n  Fourier Features", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2017.2781640", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel diffusion scheme for online kernel-based learning over\nnetworks. So far, a major drawback of any online learning algorithm, operating\nin a reproducing kernel Hilbert space (RKHS), is the need for updating a\ngrowing number of parameters as time iterations evolve. Besides complexity,\nthis leads to an increased need of communication resources, in a distributed\nsetting. In contrast, the proposed method approximates the solution as a\nfixed-size vector (of larger dimension than the input space) using Random\nFourier Features. This paves the way to use standard linear combine-then-adapt\ntechniques. To the best of our knowledge, this is the first time that a\ncomplete protocol for distributed online learning in RKHS is presented.\nConditions for asymptotic convergence and boundness of the networkwise regret\nare also provided. The simulated tests illustrate the performance of the\nproposed scheme.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 16:27:40 GMT"}, {"version": "v2", "created": "Fri, 24 Mar 2017 09:35:30 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Bouboulis", "Pantelis", ""], ["Chouvardas", "Symeon", ""], ["Theodoridis", "Sergios", ""]]}, {"id": "1703.08135", "submitter": "Herman Kamper", "authors": "Herman Kamper, Karen Livescu, Sharon Goldwater", "title": "An embedded segmental K-means model for unsupervised segmentation and\n  clustering of speech", "comments": "8 pages, 3 figures, 3 tables; accepted to ASRU 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised segmentation and clustering of unlabelled speech are core\nproblems in zero-resource speech processing. Most approaches lie at\nmethodological extremes: some use probabilistic Bayesian models with\nconvergence guarantees, while others opt for more efficient heuristic\ntechniques. Despite competitive performance in previous work, the full Bayesian\napproach is difficult to scale to large speech corpora. We introduce an\napproximation to a recent Bayesian model that still has a clear objective\nfunction but improves efficiency by using hard clustering and segmentation\nrather than full Bayesian inference. Like its Bayesian counterpart, this\nembedded segmental K-means model (ES-KMeans) represents arbitrary-length word\nsegments as fixed-dimensional acoustic word embeddings. We first compare\nES-KMeans to previous approaches on common English and Xitsonga data sets (5\nand 2.5 hours of speech): ES-KMeans outperforms a leading heuristic method in\nword segmentation, giving similar scores to the Bayesian model while being 5\ntimes faster with fewer hyperparameters. However, its clusters are less pure\nthan those of the other models. We then show that ES-KMeans scales to larger\ncorpora by applying it to the 5 languages of the Zero Resource Speech Challenge\n2017 (up to 45 hours), where it performs competitively compared to the\nchallenge baseline.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 16:45:22 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 14:14:11 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Kamper", "Herman", ""], ["Livescu", "Karen", ""], ["Goldwater", "Sharon", ""]]}, {"id": "1703.08245", "submitter": "Martin Schrimpf", "authors": "Nicholas Cheney, Martin Schrimpf, Gabriel Kreiman", "title": "On the Robustness of Convolutional Neural Networks to Internal\n  Architecture and Weight Perturbations", "comments": "under review at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks are generally regarded as robust function\napproximators. So far, this intuition is based on perturbations to external\nstimuli such as the images to be classified. Here we explore the robustness of\nconvolutional neural networks to perturbations to the internal weights and\narchitecture of the network itself. We show that convolutional networks are\nsurprisingly robust to a number of internal perturbations in the higher\nconvolutional layers but the bottom convolutional layers are much more fragile.\nFor instance, Alexnet shows less than a 30% decrease in classification\nperformance when randomly removing over 70% of weight connections in the top\nconvolutional or dense layers but performance is almost at chance with the same\nperturbation in the first convolutional layer. Finally, we suggest further\ninvestigations which could continue to inform the robustness of convolutional\nnetworks to internal perturbations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 22:25:05 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Cheney", "Nicholas", ""], ["Schrimpf", "Martin", ""], ["Kreiman", "Gabriel", ""]]}, {"id": "1703.08283", "submitter": "Cuiju Luan", "authors": "Cuiju Luan and Guozhu Dong", "title": "Experimental Identification of Hard Data Sets for Classification and\n  Feature Selection Methods with Insights on Method Selection", "comments": "18 pages, 3 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper reports an experimentally identified list of benchmark data sets\nthat are hard for representative classification and feature selection methods.\nThis was done after systematically evaluating a total of 48 combinations of\nmethods, involving eight state-of-the-art classification algorithms and six\ncommonly used feature selection methods, on 129 data sets from the UCI\nrepository (some data sets with known high classification accuracy were\nexcluded). In this paper, a data set for classification is called hard if none\nof the 48 combinations can achieve an AUC over 0.8 and none of them can achieve\nan F-Measure value over 0.8; it is called easy otherwise. A total of 15 out of\nthe 129 data sets were found to be hard in that sense. This paper also compares\nthe performance of different methods, and it produces rankings of\nclassification methods, separately on the hard data sets and on the easy data\nsets. This paper is the first to rank methods separately for hard data sets and\nfor easy data sets. It turns out that the classifier rankings resulting from\nour experiments are somehow different from those in the literature and hence\nthey offer new insights on method selection. It should be noted that the Random\nForest method remains to be the best in all groups of experiments.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 04:26:22 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 02:25:36 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Luan", "Cuiju", ""], ["Dong", "Guozhu", ""]]}, {"id": "1703.08294", "submitter": "Roy Fox", "authors": "Roy Fox, Sanjay Krishnan, Ion Stoica, Ken Goldberg", "title": "Multi-Level Discovery of Deep Options", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Augmenting an agent's control with useful higher-level behaviors called\noptions can greatly reduce the sample complexity of reinforcement learning, but\nmanually designing options is infeasible in high-dimensional and abstract state\nspaces. While recent work has proposed several techniques for automated option\ndiscovery, they do not scale to multi-level hierarchies and to expressive\nrepresentations such as deep networks. We present Discovery of Deep Options\n(DDO), a policy-gradient algorithm that discovers parametrized options from a\nset of demonstration trajectories, and can be used recursively to discover\nadditional levels of the hierarchy. The scalability of our approach to\nmulti-level hierarchies stems from the decoupling of low-level option discovery\nfrom high-level meta-control policy learning, facilitated by\nunder-parametrization of the high level. We demonstrate that using the\ndiscovered options to augment the action space of Deep Q-Network agents can\naccelerate learning by guiding exploration in tasks where random actions are\nunlikely to reach valuable states. We show that DDO is effective in adding\noptions that accelerate learning in 4 out of 5 Atari RAM environments chosen in\nour experiments. We also show that DDO can discover structure in robot-assisted\nsurgical videos and kinematics that match expert annotation with 72% accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 06:35:46 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 07:33:58 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Fox", "Roy", ""], ["Krishnan", "Sanjay", ""], ["Stoica", "Ion", ""], ["Goldberg", "Ken", ""]]}, {"id": "1703.08378", "submitter": "Shenglan Liu", "authors": "Shenglan Liu, Muxin Sun, Wei Wang, Feilong Wang", "title": "Feature Fusion using Extended Jaccard Graph and Stochastic Gradient\n  Descent for Robot", "comments": "Assembly Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot vision is a fundamental device for human-robot interaction and robot\ncomplex tasks. In this paper, we use Kinect and propose a feature graph fusion\n(FGF) for robot recognition. Our feature fusion utilizes RGB and depth\ninformation to construct fused feature from Kinect. FGF involves multi-Jaccard\nsimilarity to compute a robust graph and utilize word embedding method to\nenhance the recognition results. We also collect DUT RGB-D face dataset and a\nbenchmark datset to evaluate the effectiveness and efficiency of our method.\nThe experimental results illustrate FGF is robust and effective to face and\nobject datasets in robot applications.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 11:58:14 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Liu", "Shenglan", ""], ["Sun", "Muxin", ""], ["Wang", "Wei", ""], ["Wang", "Feilong", ""]]}, {"id": "1703.08383", "submitter": "Joseph Lemley", "authors": "Joseph Lemley, Shabab Bazrafkan, Peter Corcoran", "title": "Smart Augmentation - Learning an Optimal Data Augmentation Strategy", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2017.2696121", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recurring problem faced when training neural networks is that there is\ntypically not enough data to maximize the generalization capability of deep\nneural networks(DNN). There are many techniques to address this, including data\naugmentation, dropout, and transfer learning. In this paper, we introduce an\nadditional method which we call Smart Augmentation and we show how to use it to\nincrease the accuracy and reduce overfitting on a target network. Smart\nAugmentation works by creating a network that learns how to generate augmented\ndata during the training process of a target network in a way that reduces that\nnetworks loss. This allows us to learn augmentations that minimize the error of\nthat network.\n  Smart Augmentation has shown the potential to increase accuracy by\ndemonstrably significant measures on all datasets tested. In addition, it has\nshown potential to achieve similar or improved performance levels with\nsignificantly smaller network sizes in a number of tested cases.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 12:07:34 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Lemley", "Joseph", ""], ["Bazrafkan", "Shabab", ""], ["Corcoran", "Peter", ""]]}, {"id": "1703.08403", "submitter": "Brijnesh Jain", "authors": "Brijnesh Jain and David Schultz", "title": "Asymmetric Learning Vector Quantization for Efficient Nearest Neighbor\n  Classification in Dynamic Time Warping Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nearest neighbor method together with the dynamic time warping (DTW)\ndistance is one of the most popular approaches in time series classification.\nThis method suffers from high storage and computation requirements for large\ntraining sets. As a solution to both drawbacks, this article extends learning\nvector quantization (LVQ) from Euclidean spaces to DTW spaces. The proposed LVQ\nscheme uses asymmetric weighted averaging as update rule. Empirical results\nexhibited superior performance of asymmetric generalized LVQ (GLVQ) over other\nstate-of-the-art prototype generation methods for nearest neighbor\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 13:29:52 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Jain", "Brijnesh", ""], ["Schultz", "David", ""]]}, {"id": "1703.08434", "submitter": "Kojo Sarfo Gyamfi", "authors": "Kojo Sarfo Gyamfi, James Brusey, Andrew Hunt and Elena Gaura", "title": "Linear classifier design under heteroscedasticity in Linear Discriminant\n  Analysis", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2017.02.039", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under normality and homoscedasticity assumptions, Linear Discriminant\nAnalysis (LDA) is known to be optimal in terms of minimising the Bayes error\nfor binary classification. In the heteroscedastic case, LDA is not guaranteed\nto minimise this error. Assuming heteroscedasticity, we derive a linear\nclassifier, the Gaussian Linear Discriminant (GLD), that directly minimises the\nBayes error for binary classification. In addition, we also propose a local\nneighbourhood search (LNS) algorithm to obtain a more robust classifier if the\ndata is known to have a non-normal distribution. We evaluate the proposed\nclassifiers on two artificial and ten real-world datasets that cut across a\nwide range of application areas including handwriting recognition, medical\ndiagnosis and remote sensing, and then compare our algorithm against existing\nLDA approaches and other linear classifiers. The GLD is shown to outperform the\noriginal LDA procedure in terms of the classification accuracy under\nheteroscedasticity. While it compares favourably with other existing\nheteroscedastic LDA approaches, the GLD requires as much as 60 times lower\ntraining time on some datasets. Our comparison with the support vector machine\n(SVM) also shows that, the GLD, together with the LNS, requires as much as 150\ntimes lower training time to achieve an equivalent classification accuracy on\nsome of the datasets. Thus, our algorithms can provide a cheap and reliable\noption for classification in a lot of expert systems.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 14:45:12 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Gyamfi", "Kojo Sarfo", ""], ["Brusey", "James", ""], ["Hunt", "Andrew", ""], ["Gaura", "Elena", ""]]}, {"id": "1703.08440", "submitter": "Kojo Sarfo Gyamfi", "authors": "Kojo Sarfo Gyamfi, James Brusey and Andrew Hunt", "title": "K-Means Clustering using Tabu Search with Quantized Means", "comments": "World Conference on Engineering and Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tabu Search (TS) metaheuristic has been proposed for K-Means clustering\nas an alternative to Lloyd's algorithm, which for all its ease of\nimplementation and fast runtime, has the major drawback of being trapped at\nlocal optima. While the TS approach can yield superior performance, it involves\na high computational complexity. Moreover, the difficulty in parameter\nselection in the existing TS approach does not make it any more attractive.\nThis paper presents an alternative, low-complexity formulation of the TS\noptimization procedure for K-Means clustering. This approach does not require\nmany parameter settings. We initially constrain the centers to points in the\ndataset. We then aim at evolving these centers using a unique neighborhood\nstructure that makes use of gradient information of the objective function.\nThis results in an efficient exploration of the search space, after which the\nmeans are refined. The proposed scheme is implemented in MATLAB and tested on\nfour real-world datasets, and it achieves a significant improvement over the\nexisting TS approach in terms of the intra cluster sum of squares and\ncomputational time.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 14:59:06 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Gyamfi", "Kojo Sarfo", ""], ["Brusey", "James", ""], ["Hunt", "Andrew", ""]]}, {"id": "1703.08471", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Philemon Brakel, Maurizio Omologo, Yoshua Bengio", "title": "Batch-normalized joint training for DNN-based distant speech recognition", "comments": "arXiv admin note: text overlap with arXiv:1703.08002", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving distant speech recognition is a crucial step towards flexible\nhuman-machine interfaces. Current technology, however, still exhibits a lack of\nrobustness, especially when adverse acoustic conditions are met. Despite the\nsignificant progress made in the last years on both speech enhancement and\nspeech recognition, one potential limitation of state-of-the-art technology\nlies in composing modules that are not well matched because they are not\ntrained jointly. To address this concern, a promising approach consists in\nconcatenating a speech enhancement and a speech recognition deep neural network\nand to jointly update their parameters as if they were within a single bigger\nnetwork. Unfortunately, joint training can be difficult because the output\ndistribution of the speech enhancement system may change substantially during\nthe optimization procedure. The speech recognition module would have to deal\nwith an input distribution that is non-stationary and unnormalized. To mitigate\nthis issue, we propose a joint training approach based on a fully\nbatch-normalized architecture. Experiments, conducted using different datasets,\ntasks and acoustic conditions, revealed that the proposed framework\nsignificantly overtakes other competitive solutions, especially in challenging\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 15:40:19 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Brakel", "Philemon", ""], ["Omologo", "Maurizio", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.08475", "submitter": "Sang-Woo Lee", "authors": "Sang-Woo Lee, Jin-Hwa Kim, Jaehyun Jun, Jung-Woo Ha, Byoung-Tak Zhang", "title": "Overcoming Catastrophic Forgetting by Incremental Moment Matching", "comments": "Accepted for NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting is a problem of neural networks that loses the\ninformation of the first task after training the second task. Here, we propose\na method, i.e. incremental moment matching (IMM), to resolve this problem. IMM\nincrementally matches the moment of the posterior distribution of the neural\nnetwork which is trained on the first and the second task, respectively. To\nmake the search space of posterior parameter smooth, the IMM procedure is\ncomplemented by various transfer learning techniques including weight transfer,\nL2-norm of the old and the new parameter, and a variant of dropout with the old\nparameter. We analyze our approach on a variety of datasets including the\nMNIST, CIFAR-10, Caltech-UCSD-Birds, and Lifelog datasets. The experimental\nresults show that IMM achieves state-of-the-art performance by balancing the\ninformation between an old and a new network.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 15:43:39 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 13:01:46 GMT"}, {"version": "v3", "created": "Tue, 30 Jan 2018 05:01:28 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Lee", "Sang-Woo", ""], ["Kim", "Jin-Hwa", ""], ["Jun", "Jaehyun", ""], ["Ha", "Jung-Woo", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1703.08524", "submitter": "Shuai Xiao", "authors": "Shuai Xiao, Junchi Yan, Mehrdad Farajtabar, Le Song, Xiaokang Yang,\n  Hongyuan Zha", "title": "Joint Modeling of Event Sequence and Time Series with Attentional Twin\n  Recurrent Neural Networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of real-world processes (over networks) produce sequences of data\nwhose complex temporal dynamics need to be studied. More especially, the event\ntimestamps can carry important information about the underlying network\ndynamics, which otherwise are not available from the time-series evenly sampled\nfrom continuous signals. Moreover, in most complex processes, event sequences\nand evenly-sampled times series data can interact with each other, which\nrenders joint modeling of those two sources of data necessary. To tackle the\nabove problems, in this paper, we utilize the rich framework of (temporal)\npoint processes to model event data and timely update its intensity function by\nthe synergic twin Recurrent Neural Networks (RNNs). In the proposed\narchitecture, the intensity function is synergistically modulated by one RNN\nwith asynchronous events as input and another RNN with time series as input.\nFurthermore, to enhance the interpretability of the model, the attention\nmechanism for the neural point process is introduced. The whole model with\nevent type and timestamp prediction output layers can be trained end-to-end and\nallows a black-box treatment for modeling the intensity. We substantiate the\nsuperiority of our model in synthetic data and three real-world benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 17:29:14 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Xiao", "Shuai", ""], ["Yan", "Junchi", ""], ["Farajtabar", "Mehrdad", ""], ["Song", "Le", ""], ["Yang", "Xiaokang", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1703.08581", "submitter": "Ron J Weiss", "authors": "Ron J. Weiss, Jan Chorowski, Navdeep Jaitly, Yonghui Wu, Zhifeng Chen", "title": "Sequence-to-Sequence Models Can Directly Translate Foreign Speech", "comments": "5 pages, 1 figure. Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a recurrent encoder-decoder deep neural network architecture that\ndirectly translates speech in one language into text in another. The model does\nnot explicitly transcribe the speech into text in the source language, nor does\nit require supervision from the ground truth source language transcription\nduring training. We apply a slightly modified sequence-to-sequence with\nattention architecture that has previously been used for speech recognition and\nshow that it can be repurposed for this more complex task, illustrating the\npower of attention-based models. A single model trained end-to-end obtains\nstate-of-the-art performance on the Fisher Callhome Spanish-English speech\ntranslation task, outperforming a cascade of independently trained\nsequence-to-sequence speech recognition and machine translation models by 1.8\nBLEU points on the Fisher test set. In addition, we find that making use of the\ntraining data in both languages by multi-task training sequence-to-sequence\nspeech translation and recognition models with a shared encoder network can\nimprove performance by a further 1.4 BLEU points.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 19:45:24 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 13:54:12 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Weiss", "Ron J.", ""], ["Chorowski", "Jan", ""], ["Jaitly", "Navdeep", ""], ["Wu", "Yonghui", ""], ["Chen", "Zhifeng", ""]]}, {"id": "1703.08595", "submitter": "Aswin Raghavan", "authors": "Sek Chai, Aswin Raghavan, David Zhang, Mohamed Amer, Tim Shields", "title": "Low Precision Neural Networks using Subband Decomposition", "comments": "Presented at CogArch Workshop, Atlanta, GA, April 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale deep neural networks (DNN) have been successfully used in a\nnumber of tasks from image recognition to natural language processing. They are\ntrained using large training sets on large models, making them computationally\nand memory intensive. As such, there is much interest in research development\nfor faster training and test time. In this paper, we present a unique approach\nusing lower precision weights for more efficient and faster training phase. We\nseparate imagery into different frequency bands (e.g. with different\ninformation content) such that the neural net can better learn using less bits.\nWe present this approach as a complement existing methods such as pruning\nnetwork connections and encoding learning weights. We show results where this\napproach supports more stable learning with 2-4X reduction in precision with\n17X reduction in DNN parameters.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 20:59:50 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Chai", "Sek", ""], ["Raghavan", "Aswin", ""], ["Zhang", "David", ""], ["Amer", "Mohamed", ""], ["Shields", "Tim", ""]]}, {"id": "1703.08612", "submitter": "Charles Schaff", "authors": "Charles Schaff, David Yunis, Ayan Chakrabarti, Matthew R. Walter", "title": "Jointly Optimizing Placement and Inference for Beacon-based Localization", "comments": "Appeared at 2017 International Conference on Intelligent Robots and\n  Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of robots to estimate their location is crucial for a wide\nvariety of autonomous operations. In settings where GPS is unavailable,\nmeasurements of transmissions from fixed beacons provide an effective means of\nestimating a robot's location as it navigates. The accuracy of such a\nbeacon-based localization system depends both on how beacons are distributed in\nthe environment, and how the robot's location is inferred based on noisy and\npotentially ambiguous measurements. We propose an approach for making these\ndesign decisions automatically and without expert supervision, by explicitly\nsearching for the placement and inference strategies that, together, are\noptimal for a given environment. Since this search is computationally\nexpensive, our approach encodes beacon placement as a differential neural layer\nthat interfaces with a neural network for inference. This formulation allows us\nto employ standard techniques for training neural networks to carry out the\njoint optimization. We evaluate this approach on a variety of environments and\nsettings, and find that it is able to discover designs that enable high\nlocalization accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 21:57:37 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 16:56:43 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Schaff", "Charles", ""], ["Yunis", "David", ""], ["Chakrabarti", "Ayan", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1703.08667", "submitter": "Ronan Fruit", "authors": "Ronan Fruit, Alessandro Lazaric", "title": "Exploration--Exploitation in MDPs with Options", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While a large body of empirical results show that temporally-extended actions\nand options may significantly affect the learning performance of an agent, the\ntheoretical understanding of how and when options can be beneficial in online\nreinforcement learning is relatively limited. In this paper, we derive an upper\nand lower bound on the regret of a variant of UCRL using options. While we\nfirst analyze the algorithm in the general case of semi-Markov decision\nprocesses (SMDPs), we show how these results can be translated to the specific\ncase of MDPs with options and we illustrate simple scenarios in which the\nregret of learning with options can be \\textit{provably} much smaller than the\nregret suffered when learning with primitive actions.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 09:30:31 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 09:55:01 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Fruit", "Ronan", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "1703.08710", "submitter": "Joseph Paul Cohen", "authors": "Joseph Paul Cohen and Genevieve Boucher and Craig A. Glastonbury and\n  Henry Z. Lo and Yoshua Bengio", "title": "Count-ception: Counting by Fully Convolutional Redundant Counting", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting objects in digital images is a process that should be replaced by\nmachines. This tedious task is time consuming and prone to errors due to\nfatigue of human annotators. The goal is to have a system that takes as input\nan image and returns a count of the objects inside and justification for the\nprediction in the form of object localization. We repose a problem, originally\nposed by Lempitsky and Zisserman, to instead predict a count map which contains\nredundant counts based on the receptive field of a smaller regression network.\nThe regression network predicts a count of the objects that exist inside this\nframe. By processing the image in a fully convolutional way each pixel is going\nto be accounted for some number of times, the number of windows which include\nit, which is the size of each window, (i.e., 32x32 = 1024). To recover the true\ncount we take the average over the redundant predictions. Our contribution is\nredundant counting instead of predicting a density map in order to average over\nerrors. We also propose a novel deep neural network architecture adapted from\nthe Inception family of networks called the Count-ception network. Together our\napproach results in a 20% relative improvement (2.9 to 2.3 MAE) over the state\nof the art method by Xie, Noble, and Zisserman in 2016.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 16:49:03 GMT"}, {"version": "v2", "created": "Sun, 23 Jul 2017 17:36:30 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Cohen", "Joseph Paul", ""], ["Boucher", "Genevieve", ""], ["Glastonbury", "Craig A.", ""], ["Lo", "Henry Z.", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.08774", "submitter": "Melody Guan", "authors": "Melody Y. Guan, Varun Gulshan, Andrew M. Dai, Geoffrey E. Hinton", "title": "Who Said What: Modeling Individual Labelers Improves Classification", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data are often labeled by many different experts with each expert only\nlabeling a small fraction of the data and each data point being labeled by\nseveral experts. This reduces the workload on individual experts and also gives\na better estimate of the unobserved ground truth. When experts disagree, the\nstandard approaches are to treat the majority opinion as the correct label or\nto model the correct label as a distribution. These approaches, however, do not\nmake any use of potentially valuable information about which expert produced\nwhich label. To make use of this extra information, we propose modeling the\nexperts individually and then learning averaging weights for combining them,\npossibly in sample-specific ways. This allows us to give more weight to more\nreliable experts and take advantage of the unique strengths of individual\nexperts at classifying certain types of data. Here we show that our approach\nleads to improvements in computer-aided diagnosis of diabetic retinopathy. We\nalso show that our method performs better than competing algorithms by Welinder\nand Perona (2010), and by Mnih and Hinton (2012). Our work offers an innovative\napproach for dealing with the myriad real-world settings that use expert\nopinions to define labels for training.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 06:34:45 GMT"}, {"version": "v2", "created": "Thu, 4 Jan 2018 21:46:22 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Guan", "Melody Y.", ""], ["Gulshan", "Varun", ""], ["Dai", "Andrew M.", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "1703.08816", "submitter": "Konstantinos Zygalakis", "authors": "Andrea L. Bertozzi and Xiyang Luo and Andrew M. Stuart and\n  Konstantinos C. Zygalakis", "title": "Uncertainty quantification in graph-based classification of high\n  dimensional data", "comments": "33 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of high dimensional data finds wide-ranging applications. In\nmany of these applications equipping the resulting classification with a\nmeasure of uncertainty may be as important as the classification itself. In\nthis paper we introduce, develop algorithms for, and investigate the properties\nof, a variety of Bayesian models for the task of binary classification; via the\nposterior distribution on the classification labels, these methods\nautomatically give measures of uncertainty. The methods are all based around\nthe graph formulation of semi-supervised learning.\n  We provide a unified framework which brings together a variety of methods\nwhich have been introduced in different communities within the mathematical\nsciences. We study probit classification in the graph-based setting, generalize\nthe level-set method for Bayesian inverse problems to the classification\nsetting, and generalize the Ginzburg-Landau optimization-based classifier to a\nBayesian setting; we also show that the probit and level set approaches are\nnatural relaxations of the harmonic function approach introduced in [Zhu et al\n2003].\n  We introduce efficient numerical methods, suited to large data-sets, for both\nMCMC-based sampling as well as gradient-based MAP estimation. Through numerical\nexperiments we study classification accuracy and uncertainty quantification for\nour models; these experiments showcase a suite of datasets commonly used to\nevaluate graph-based semi-supervised learning algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 13:29:25 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 19:16:13 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Bertozzi", "Andrea L.", ""], ["Luo", "Xiyang", ""], ["Stuart", "Andrew M.", ""], ["Zygalakis", "Konstantinos C.", ""]]}, {"id": "1703.08836", "submitter": "Silvano Galliani", "authors": "Wilfried Hartmann, Silvano Galliani, Michal Havlena, Luc Van Gool,\n  Konrad Schindler", "title": "Learned Multi-Patch Similarity", "comments": "10 pages, 7 figures, Accepted at ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating a depth map from multiple views of a scene is a fundamental task\nin computer vision. As soon as more than two viewpoints are available, one\nfaces the very basic question how to measure similarity across >2 image\npatches. Surprisingly, no direct solution exists, instead it is common to fall\nback to more or less robust averaging of two-view similarities. Encouraged by\nthe success of machine learning, and in particular convolutional neural\nnetworks, we propose to learn a matching function which directly maps multiple\nimage patches to a scalar similarity score. Experiments on several multi-view\ndatasets demonstrate that this approach has advantages over methods based on\npairwise patch similarity.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 16:17:55 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 13:10:39 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Hartmann", "Wilfried", ""], ["Galliani", "Silvano", ""], ["Havlena", "Michal", ""], ["Van Gool", "Luc", ""], ["Schindler", "Konrad", ""]]}, {"id": "1703.08838", "submitter": "Saber Salehkaleybar", "authors": "Saber Salehkaleybar, Arsalan Sharif-Nassab, S. Jamaloddin Golestani", "title": "Distributed Voting/Ranking with Optimal Number of States per Node", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering a network with $n$ nodes, where each node initially votes for one\n(or more) choices out of $K$ possible choices, we present a Distributed\nMulti-choice Voting/Ranking (DMVR) algorithm to determine either the choice\nwith maximum vote (the voting problem) or to rank all the choices in terms of\ntheir acquired votes (the ranking problem). The algorithm consolidates node\nvotes across the network by updating the states of interacting nodes using two\nkey operations, the union and the intersection. The proposed algorithm is\nsimple, independent from network size, and easily scalable in terms of the\nnumber of choices $K$, using only $K\\times 2^{K-1}$ nodal states for voting,\nand $K\\times K!$ nodal states for ranking. We prove the number of states to be\noptimal in the ranking case, this optimality is conjectured to also apply to\nthe voting case. The time complexity of the algorithm is analyzed in complete\ngraphs. We show that the time complexity for both ranking and voting is\n$O(\\log(n))$ for given vote percentages, and is inversely proportional to the\nminimum of the vote percentage differences among various choices.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 16:19:31 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Salehkaleybar", "Saber", ""], ["Sharif-Nassab", "Arsalan", ""], ["Golestani", "S. Jamaloddin", ""]]}, {"id": "1703.08840", "submitter": "Yunzhu Li", "authors": "Yunzhu Li, Jiaming Song, Stefano Ermon", "title": "InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations", "comments": "14 pages, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of imitation learning is to mimic expert behavior without access to\nan explicit reward signal. Expert demonstrations provided by humans, however,\noften show significant variability due to latent factors that are typically not\nexplicitly modeled. In this paper, we propose a new algorithm that can infer\nthe latent structure of expert demonstrations in an unsupervised way. Our\nmethod, built on top of Generative Adversarial Imitation Learning, can not only\nimitate complex behaviors, but also learn interpretable and meaningful\nrepresentations of complex behavioral data, including visual demonstrations. In\nthe driving domain, we show that a model learned from human demonstrations is\nable to both accurately reproduce a variety of behaviors and accurately\nanticipate human actions using raw visual inputs. Compared with various\nbaselines, our method can better capture the latent structure underlying expert\ndemonstrations, often recovering semantically meaningful factors of variation\nin the data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 16:20:36 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 21:51:21 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Li", "Yunzhu", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "1703.08933", "submitter": "Quang N. Tran", "authors": "Quang N. Tran, Ba-Ngu Vo, Dinh Phung, Ba-Tuong Vo, and Thuong Nguyen", "title": "Multiple Instance Learning with the Optimal Sub-Pattern Assignment\n  Metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple instance data are sets or multi-sets of unordered elements. Using\nmetrics or distances for sets, we propose an approach to several multiple\ninstance learning tasks, such as clustering (unsupervised learning),\nclassification (supervised learning), and novelty detection (semi-supervised\nlearning). In particular, we introduce the Optimal Sub-Pattern Assignment\nmetric to multiple instance learning so as to provide versatile design choices.\nNumerical experiments on both simulated and real data are presented to\nillustrate the versatility of the proposed solution.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 05:23:32 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Tran", "Quang N.", ""], ["Vo", "Ba-Ngu", ""], ["Phung", "Dinh", ""], ["Vo", "Ba-Tuong", ""], ["Nguyen", "Thuong", ""]]}, {"id": "1703.08961", "submitter": "Eugene Belilovsky", "authors": "Edouard Oyallon (DI-ENS), Eugene Belilovsky (CVN, GALEN), Sergey\n  Zagoruyko (ENPC)", "title": "Scaling the Scattering Transform: Deep Hybrid Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the scattering network as a generic and fixed ini-tialization of the\nfirst layers of a supervised hybrid deep network. We show that early layers do\nnot necessarily need to be learned, providing the best results to-date with\npre-defined representations while being competitive with Deep CNNs. Using a\nshallow cascade of 1 x 1 convolutions, which encodes scattering coefficients\nthat correspond to spatial windows of very small sizes, permits to obtain\nAlexNet accuracy on the imagenet ILSVRC2012. We demonstrate that this local\nencoding explicitly learns invariance w.r.t. rotations. Combining scattering\nnetworks with a modern ResNet, we achieve a single-crop top 5 error of 11.4% on\nimagenet ILSVRC2012, comparable to the Resnet-18 architecture, while utilizing\nonly 10 layers. We also find that hybrid architectures can yield excellent\nperformance in the small sample regime, exceeding their end-to-end\ncounterparts, through their ability to incorporate geometrical priors. We\ndemonstrate this on subsets of the CIFAR-10 dataset and on the STL-10 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 07:49:43 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 06:13:22 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Oyallon", "Edouard", "", "DI-ENS"], ["Belilovsky", "Eugene", "", "CVN, GALEN"], ["Zagoruyko", "Sergey", "", "ENPC"]]}, {"id": "1703.08970", "submitter": "Ahmed Ben Said", "authors": "Ahmed Ben Said and Amr Mohamed and Tarek Elfouly and Khaled Harras and\n  Z. Jane Wang", "title": "Multimodal deep learning approach for joint EEG-EMG data compression and\n  classification", "comments": "IEEE Wireless Communications and Networking Conference (WCNC), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a joint compression and classification approach of\nEEG and EMG signals using a deep learning approach. Specifically, we build our\nsystem based on the deep autoencoder architecture which is designed not only to\nextract discriminant features in the multimodal data representation but also to\nreconstruct the data from the latent representation using encoder-decoder\nlayers. Since autoencoder can be seen as a compression approach, we extend it\nto handle multimodal data at the encoder layer, reconstructed and retrieved at\nthe decoder layer. We show through experimental results, that exploiting both\nmultimodal data intercorellation and intracorellation 1) Significantly reduces\nsignal distortion particularly for high compression levels 2) Achieves better\naccuracy in classifying EEG and EMG signals recorded and labeled according to\nthe sentiments of the volunteer.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 08:37:35 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Said", "Ahmed Ben", ""], ["Mohamed", "Amr", ""], ["Elfouly", "Tarek", ""], ["Harras", "Khaled", ""], ["Wang", "Z. Jane", ""]]}, {"id": "1703.09068", "submitter": "Rafael Lima Goncalves de", "authors": "Rafael Lima and Jaesik Choi", "title": "Make Hawkes Processes Explainable by Decomposing Self-Triggering Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hawkes Processes capture self-excitation and mutual-excitation between events\nwhen the arrival of an event makes future events more likely to happen.\nIdentification of such temporal covariance can reveal the underlying structure\nto better predict future events. In this paper, we present a new framework to\ndecompose discrete events with a composition of multiple self-triggering\nkernels. The composition scheme allows us to decompose empirical covariance\ndensities into the sum or the product of base kernels which are easily\ninterpretable. Here, we present the first multiplicative kernel composition\nmethods for Hawkes Processes. We demonstrate that the new automatic kernel\ndecomposition procedure outperforms the existing methods on the prediction of\ndiscrete events in real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 15:25:54 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 04:43:25 GMT"}, {"version": "v3", "created": "Tue, 18 Jul 2017 10:01:49 GMT"}, {"version": "v4", "created": "Wed, 14 Feb 2018 06:24:52 GMT"}, {"version": "v5", "created": "Thu, 13 Sep 2018 18:44:08 GMT"}, {"version": "v6", "created": "Tue, 2 Jun 2020 04:05:46 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Lima", "Rafael", ""], ["Choi", "Jaesik", ""]]}, {"id": "1703.09146", "submitter": "Aswin Raghavan", "authors": "Aswin Raghavan, Mohamed Amer, Timothy Shields, David Zhang, Sek Chai", "title": "GPU Activity Prediction using Representation Learning", "comments": "Proceedings of the 33 rd International Conference on Machine\n  Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by\n  the author(s)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPU activity prediction is an important and complex problem. This is due to\nthe high level of contention among thousands of parallel threads. This problem\nwas mostly addressed using heuristics. We propose a representation learning\napproach to address this problem. We model any performance metric as a temporal\nfunction of the executed instructions with the intuition that the flow of\ninstructions can be identified as distinct activities of the code. Our\nexperiments show high accuracy and non-trivial predictive power of\nrepresentation learning on a benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 15:31:02 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Raghavan", "Aswin", ""], ["Amer", "Mohamed", ""], ["Shields", "Timothy", ""], ["Zhang", "David", ""], ["Chai", "Sek", ""]]}, {"id": "1703.09185", "submitter": "Shripad Gade", "authors": "Shripad Gade and Nitin H. Vaidya", "title": "Private Learning on Networks: Part II", "comments": "Privacy-Convergence Trade-off added. New simulation results added\n  (Current Version: 5 November 2017. First Version: 27 March 2017. )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a distributed multi-agent optimization problem, with the\nglobal objective consisting of the sum of local objective functions of the\nagents. The agents solve the optimization problem using local computation and\ncommunication between adjacent agents in the network. We present two randomized\niterative algorithms for distributed optimization. To improve privacy, our\nalgorithms add \"structured\" randomization to the information exchanged between\nthe agents. We prove deterministic correctness (in every execution) of the\nproposed algorithms despite the information being perturbed by noise with\nnon-zero mean. We prove that a special case of a proposed algorithm (called\nfunction sharing) preserves privacy of individual polynomial objective\nfunctions under a suitable connectivity condition on the network topology.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 16:59:49 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 23:41:58 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Gade", "Shripad", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "1703.09194", "submitter": "Geoffrey Roeder", "authors": "Geoffrey Roeder, Yuhuai Wu, David Duvenaud", "title": "Sticking the Landing: Simple, Lower-Variance Gradient Estimators for\n  Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple and general variant of the standard reparameterized\ngradient estimator for the variational evidence lower bound. Specifically, we\nremove a part of the total derivative with respect to the variational\nparameters that corresponds to the score function. Removing this term produces\nan unbiased gradient estimator whose variance approaches zero as the\napproximate posterior approaches the exact posterior. We analyze the behavior\nof this gradient estimator theoretically and empirically, and generalize it to\nmore complex variational distributions such as mixtures and importance-weighted\nposteriors.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 17:25:02 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 21:22:19 GMT"}, {"version": "v3", "created": "Sun, 28 May 2017 17:47:33 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Roeder", "Geoffrey", ""], ["Wu", "Yuhuai", ""], ["Duvenaud", "David", ""]]}, {"id": "1703.09197", "submitter": "Nathan West", "authors": "Nathan E West and Timothy J. O'Shea", "title": "Deep Architectures for Modulation Recognition", "comments": "7 pages, 14 figures, to be published in proceedings of IEEE DySPAN\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We survey the latest advances in machine learning with deep neural networks\nby applying them to the task of radio modulation recognition. Results show that\nradio modulation recognition is not limited by network depth and further work\nshould focus on improving learned synchronization and equalization. Advances in\nthese areas will likely come from novel architectures designed for these tasks\nor through novel training methods.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 17:28:43 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["West", "Nathan E", ""], ["O'Shea", "Timothy J.", ""]]}, {"id": "1703.09202", "submitter": "Aran Nayebi", "authors": "Aran Nayebi, Surya Ganguli", "title": "Biologically inspired protection of deep networks from adversarial\n  attacks", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by biophysical principles underlying nonlinear dendritic computation\nin neural circuits, we develop a scheme to train deep neural networks to make\nthem robust to adversarial attacks. Our scheme generates highly nonlinear,\nsaturated neural networks that achieve state of the art performance on gradient\nbased adversarial examples on MNIST, despite never being exposed to\nadversarially chosen examples during training. Moreover, these networks exhibit\nunprecedented robustness to targeted, iterative schemes for generating\nadversarial examples, including second-order methods. We further identify\nprinciples governing how these networks achieve their robustness, drawing on\nmethods from information geometry. We find these networks progressively create\nhighly flat and compressed internal representations that are sensitive to very\nfew input dimensions, while still solving the task. Moreover, they employ\nhighly kurtotic weight distributions, also found in the brain, and we\ndemonstrate how such kurtosis can protect even linear classifiers from\nadversarial attack.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 17:45:07 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Nayebi", "Aran", ""], ["Ganguli", "Surya", ""]]}, {"id": "1703.09260", "submitter": "Somil Bansal", "authors": "Somil Bansal, Roberto Calandra, Ted Xiao, Sergey Levine, Claire J.\n  Tomlin", "title": "Goal-Driven Dynamics Learning via Bayesian Optimization", "comments": "This is the extended version of the CDC'17 paper titled \"Goal-Driven\n  Dynamics Learning via Bayesian Optimization.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world robots are becoming increasingly complex and commonly act in\npoorly understood environments where it is extremely challenging to model or\nlearn their true dynamics. Therefore, it might be desirable to take a\ntask-specific approach, wherein the focus is on explicitly learning the\ndynamics model which achieves the best control performance for the task at\nhand, rather than learning the true dynamics. In this work, we use Bayesian\noptimization in an active learning framework where a locally linear dynamics\nmodel is learned with the intent of maximizing the control performance, and\nused in conjunction with optimal control schemes to efficiently design a\ncontroller for a given task. This model is updated directly based on the\nperformance observed in experiments on the physical system in an iterative\nmanner until a desired performance is achieved. We demonstrate the efficacy of\nthe proposed approach through simulations and real experiments on a quadrotor\ntestbed.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 18:38:06 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 02:06:56 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Bansal", "Somil", ""], ["Calandra", "Roberto", ""], ["Xiao", "Ted", ""], ["Levine", "Sergey", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "1703.09310", "submitter": "Brett Israelsen", "authors": "Brett W. Israelsen, Nisar Ahmed, Kenneth Center, Roderick Green,\n  Winston Bennett Jr", "title": "Adaptive Simulation-based Training of AI Decision-makers using Bayesian\n  Optimization", "comments": "submitted to JAIS for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies how an AI-controlled dog-fighting agent with tunable\ndecision-making parameters can learn to optimize performance against an\nintelligent adversary, as measured by a stochastic objective function evaluated\non simulated combat engagements. Gaussian process Bayesian optimization (GPBO)\ntechniques are developed to automatically learn global Gaussian Process (GP)\nsurrogate models, which provide statistical performance predictions in both\nexplored and unexplored areas of the parameter space. This allows a learning\nengine to sample full-combat simulations at parameter values that are most\nlikely to optimize performance and also provide highly informative data points\nfor improving future predictions. However, standard GPBO methods do not provide\na reliable surrogate model for the highly volatile objective functions found in\naerial combat, and thus do not reliably identify global maxima. These issues\nare addressed by novel Repeat Sampling (RS) and Hybrid Repeat/Multi-point\nSampling (HRMS) techniques. Simulation studies show that HRMS improves the\naccuracy of GP surrogate models, allowing AI decision-makers to more accurately\npredict performance and efficiently tune parameters.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 21:05:15 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 22:54:26 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Israelsen", "Brett W.", ""], ["Ahmed", "Nisar", ""], ["Center", "Kenneth", ""], ["Green", "Roderick", ""], ["Bennett", "Winston", "Jr"]]}, {"id": "1703.09327", "submitter": "Michael Laskey", "authors": "Michael Laskey, Jonathan Lee, Roy Fox, Anca Dragan, Ken Goldberg", "title": "DART: Noise Injection for Robust Imitation Learning", "comments": null, "journal-ref": "1st Conference on Robot Learning (CoRL 2017)", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One approach to Imitation Learning is Behavior Cloning, in which a robot\nobserves a supervisor and infers a control policy. A known problem with this\n\"off-policy\" approach is that the robot's errors compound when drifting away\nfrom the supervisor's demonstrations. On-policy, techniques alleviate this by\niteratively collecting corrective actions for the current robot policy.\nHowever, these techniques can be tedious for human supervisors, add significant\ncomputation burden, and may visit dangerous states during training. We propose\nan off-policy approach that injects noise into the supervisor's policy while\ndemonstrating. This forces the supervisor to demonstrate how to recover from\nerrors. We propose a new algorithm, DART (Disturbances for Augmenting Robot\nTrajectories), that collects demonstrations with injected noise, and optimizes\nthe noise level to approximate the error of the robot's trained policy during\ndata collection. We compare DART with DAgger and Behavior Cloning in two\ndomains: in simulation with an algorithmic supervisor on the MuJoCo tasks\n(Walker, Humanoid, Hopper, Half-Cheetah) and in physical experiments with human\nsupervisors training a Toyota HSR robot to perform grasping in clutter. For\nhigh dimensional tasks like Humanoid, DART can be up to $3x$ faster in\ncomputation time and only decreases the supervisor's cumulative reward by $5\\%$\nduring training, whereas DAgger executes policies that have $80\\%$ less\ncumulative reward than the supervisor. On the grasping in clutter task, DART\nobtains on average a $62\\%$ performance increase over Behavior Cloning.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 22:26:16 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 03:52:18 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Laskey", "Michael", ""], ["Lee", "Jonathan", ""], ["Fox", "Roy", ""], ["Dragan", "Anca", ""], ["Goldberg", "Ken", ""]]}, {"id": "1703.09370", "submitter": "Thomas Ploetz", "authors": "Yu Guan and Thomas Ploetz", "title": "Ensembles of Deep LSTM Learners for Activity Recognition using Wearables", "comments": "accepted for publication in ACM IMWUT (Ubicomp) 2017", "journal-ref": null, "doi": "10.1145/3090076", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning (DL) methods have been introduced very successfully\ninto human activity recognition (HAR) scenarios in ubiquitous and wearable\ncomputing. Especially the prospect of overcoming the need for manual feature\ndesign combined with superior classification capabilities render deep neural\nnetworks very attractive for real-life HAR application. Even though DL-based\napproaches now outperform the state-of-the-art in a number of recognitions\ntasks of the field, yet substantial challenges remain. Most prominently, issues\nwith real-life datasets, typically including imbalanced datasets and\nproblematic data quality, still limit the effectiveness of activity recognition\nusing wearables. In this paper we tackle such challenges through Ensembles of\ndeep Long Short Term Memory (LSTM) networks. We have developed modified\ntraining procedures for LSTM networks and combine sets of diverse LSTM learners\ninto classifier collectives. We demonstrate, both formally and empirically,\nthat Ensembles of deep LSTM learners outperform the individual LSTM networks.\nThrough an extensive experimental evaluation on three standard benchmarks\n(Opportunity, PAMAP2, Skoda) we demonstrate the excellent recognition\ncapabilities of our approach and its potential for real-life applications of\nhuman activity recognition.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 02:00:47 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Guan", "Yu", ""], ["Ploetz", "Thomas", ""]]}, {"id": "1703.09390", "submitter": "Sean McGregor", "authors": "Sean McGregor, Rachel Houtman, Claire Montgomery, Ronald Metoyer,\n  Thomas G. Dietterich", "title": "Factoring Exogenous State for Model-Free Monte Carlo", "comments": "9 pages, 5 figures. Corrected equation 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy analysts wish to visualize a range of policies for large\nsimulator-defined Markov Decision Processes (MDPs). One visualization approach\nis to invoke the simulator to generate on-policy trajectories and then\nvisualize those trajectories. When the simulator is expensive, this is not\npractical, and some method is required for generating trajectories for new\npolicies without invoking the simulator. The method of Model-Free Monte Carlo\n(MFMC) can do this by stitching together state transitions for a new policy\nbased on previously-sampled trajectories from other policies. This \"off-policy\nMonte Carlo simulation\" method works well when the state space has low\ndimension but fails as the dimension grows. This paper describes a method for\nfactoring out some of the state and action variables so that MFMC can work in\nhigh-dimensional MDPs. The new method, MFMCi, is evaluated on a very\nchallenging wildfire management MDP.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 03:32:55 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 20:34:12 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["McGregor", "Sean", ""], ["Houtman", "Rachel", ""], ["Montgomery", "Claire", ""], ["Metoyer", "Ronald", ""], ["Dietterich", "Thomas G.", ""]]}, {"id": "1703.09391", "submitter": "Sean McGregor", "authors": "Sean McGregor, Rachel Houtman, Claire Montgomery, Ronald Metoyer,\n  Thomas G. Dietterich", "title": "Fast Optimization of Wildfire Suppression Policies with SMAC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Managers of US National Forests must decide what policy to apply for dealing\nwith lightning-caused wildfires. Conflicts among stakeholders (e.g., timber\ncompanies, home owners, and wildlife biologists) have often led to spirited\npolitical debates and even violent eco-terrorism. One way to transform these\nconflicts into multi-stakeholder negotiations is to provide a high-fidelity\nsimulation environment in which stakeholders can explore the space of\nalternative policies and understand the tradeoffs therein. Such an environment\nneeds to support fast optimization of MDP policies so that users can adjust\nreward functions and analyze the resulting optimal policies. This paper\nassesses the suitability of SMAC---a black-box empirical function optimization\nalgorithm---for rapid optimization of MDP policies. The paper describes five\nreward function components and four stakeholder constituencies. It then\nintroduces a parameterized class of policies that can be easily understood by\nthe stakeholders. SMAC is applied to find the optimal policy in this class for\nthe reward functions of each of the stakeholder constituencies. The results\nconfirm that SMAC is able to rapidly find good policies that make sense from\nthe domain perspective. Because the full-fidelity forest fire simulator is far\ntoo expensive to support interactive optimization, SMAC is applied to a\nsurrogate model constructed from a modest number of runs of the full-fidelity\nsimulator. To check the quality of the SMAC-optimized policies, the policies\nare evaluated on the full-fidelity simulator. The results confirm that the\nsurrogate values estimates are valid. This is the first successful optimization\nof wildfire management policies using a full-fidelity simulation. The same\nmethodology should be applicable to other contentious natural resource\nmanagement problems where high-fidelity simulation is extremely expensive.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 03:33:02 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["McGregor", "Sean", ""], ["Houtman", "Rachel", ""], ["Montgomery", "Claire", ""], ["Metoyer", "Ronald", ""], ["Dietterich", "Thomas G.", ""]]}, {"id": "1703.09397", "submitter": "Muneki Yasuda", "authors": "Muneki Yasuda and Shun Kataoka", "title": "Solving Non-parametric Inverse Problem in Continuous Markov Random Field\n  using Loopy Belief Propagation", "comments": null, "journal-ref": null, "doi": "10.7566/JPSJ.86.084806", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the inverse problem, or the statistical machine\nlearning problem, in Markov random fields with a non-parametric pair-wise\nenergy function with continuous variables. The inverse problem is formulated by\nmaximum likelihood estimation. The exact treatment of maximum likelihood\nestimation is intractable because of two problems: (1) it includes the\nevaluation of the partition function and (2) it is formulated in the form of\nfunctional optimization. We avoid Problem (1) by using Bethe approximation.\nBethe approximation is an approximation technique equivalent to the loopy\nbelief propagation. Problem (2) can be solved by using orthonormal function\nexpansion. Orthonormal function expansion can reduce a functional optimization\nproblem to a function optimization problem. Our method can provide an analytic\nform of the solution of the inverse problem within the framework of Bethe\napproximation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 04:42:11 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Yasuda", "Muneki", ""], ["Kataoka", "Shun", ""]]}, {"id": "1703.09452", "submitter": "Santiago Pascual De La Puente", "authors": "Santiago Pascual, Antonio Bonafonte, Joan Serr\\`a", "title": "SEGAN: Speech Enhancement Generative Adversarial Network", "comments": "5 pages, 4 figures, accepted in INTERSPEECH 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current speech enhancement techniques operate on the spectral domain and/or\nexploit some higher-level feature. The majority of them tackle a limited number\nof noise conditions and rely on first-order statistics. To circumvent these\nissues, deep networks are being increasingly used, thanks to their ability to\nlearn complex functions from large example sets. In this work, we propose the\nuse of generative adversarial networks for speech enhancement. In contrast to\ncurrent techniques, we operate at the waveform level, training the model\nend-to-end, and incorporate 28 speakers and 40 different noise conditions into\nthe same model, such that model parameters are shared across them. We evaluate\nthe proposed model using an independent, unseen test set with two speakers and\n20 alternative noise conditions. The enhanced samples confirm the viability of\nthe proposed model, and both objective and subjective evaluations confirm the\neffectiveness of it. With that, we open the exploration of generative\narchitectures for speech enhancement, which may progressively incorporate\nfurther speech-centric design choices to improve their performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 08:39:06 GMT"}, {"version": "v2", "created": "Fri, 21 Apr 2017 12:37:03 GMT"}, {"version": "v3", "created": "Fri, 9 Jun 2017 11:34:06 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Pascual", "Santiago", ""], ["Bonafonte", "Antonio", ""], ["Serr\u00e0", "Joan", ""]]}, {"id": "1703.09470", "submitter": "Silvano Galliani", "authors": "Silvano Galliani, Charis Lanaras, Dimitrios Marmanis, Emmanuel\n  Baltsavias, Konrad Schindler", "title": "Learned Spectral Super-Resolution", "comments": "Submitted to ICCV 2017 (10 pages, 8 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel method for blind, single-image spectral super-resolution.\nWhile conventional super-resolution aims to increase the spatial resolution of\nan input image, our goal is to spectrally enhance the input, i.e., generate an\nimage with the same spatial resolution, but a greatly increased number of\nnarrow (hyper-spectral) wave-length bands. Just like the spatial statistics of\nnatural images has rich structure, which one can exploit as prior to predict\nhigh-frequency content from a low resolution image, the same is also true in\nthe spectral domain: the materials and lighting conditions of the observed\nworld induce structure in the spectrum of wavelengths observed at a given\npixel. Surprisingly, very little work exists that attempts to use this\ndiagnosis and achieve blind spectral super-resolution from single images. We\nstart from the conjecture that, just like in the spatial domain, we can learn\nthe statistics of natural image spectra, and with its help generate finely\nresolved hyper-spectral images from RGB input. Technically, we follow the\ncurrent best practice and implement a convolutional neural network (CNN), which\nis trained to carry out the end-to-end mapping from an entire RGB image to the\ncorresponding hyperspectral image of equal size. We demonstrate spectral\nsuper-resolution both for conventional RGB images and for multi-spectral\nsatellite data, outperforming the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 09:17:38 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Galliani", "Silvano", ""], ["Lanaras", "Charis", ""], ["Marmanis", "Dimitrios", ""], ["Baltsavias", "Emmanuel", ""], ["Schindler", "Konrad", ""]]}, {"id": "1703.09480", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall, Aaron Bostrom, James Large and Jason Lines", "title": "Simulated Data Experiments for Time Series Classification Part 1:\n  Accuracy Comparison with Default Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are now a broad range of time series classification (TSC) algorithms\ndesigned to exploit different representations of the data. These have been\nevaluated on a range of problems hosted at the UCR-UEA TSC Archive\n(www.timeseriesclassification.com), and there have been extensive comparative\nstudies. However, our understanding of why one algorithm outperforms another is\nstill anecdotal at best. This series of experiments is meant to help provide\ninsights into what sort of discriminatory features in the data lead one set of\nalgorithms that exploit a particular representation to be better than other\nalgorithms. We categorise five different feature spaces exploited by TSC\nalgorithms then design data simulators to generate randomised data from each\nrepresentation. We describe what results we expected from each class of\nalgorithm and data representation, then observe whether these prior beliefs are\nsupported by the experimental evidence. We provide an open source\nimplementation of all the simulators to allow for the controlled testing of\nhypotheses relating to classifier performance on different data\nrepresentations. We identify many surprising results that confounded our\nexpectations, and use these results to highlight how an over simplified view of\nclassifier structure can often lead to erroneous prior beliefs. We believe\nensembling can often overcome prior bias, and our results support the belief by\nshowing that the ensemble approach adopted by the Hierarchical Collective of\nTransform based Ensembles (HIVE-COTE) is significantly better than the\nalternatives when the data representation is unknown, and is significantly\nbetter than, or not significantly significantly better than, or not\nsignificantly worse than, the best other approach on three out of five of the\nindividual simulators.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 09:48:52 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Bagnall", "Anthony", ""], ["Bostrom", "Aaron", ""], ["Large", "James", ""], ["Lines", "Jason", ""]]}, {"id": "1703.09580", "submitter": "Maren Mahsereci", "authors": "Maren Mahsereci, Lukas Balles, Christoph Lassner, Philipp Hennig", "title": "Early Stopping without a Validation Set", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early stopping is a widely used technique to prevent poor generalization\nperformance when training an over-expressive model by means of gradient-based\noptimization. To find a good point to halt the optimizer, a common practice is\nto split the dataset into a training and a smaller validation set to obtain an\nongoing estimate of the generalization performance. We propose a novel early\nstopping criterion based on fast-to-compute local statistics of the computed\ngradients and entirely removes the need for a held-out validation set. Our\nexperiments show that this is a viable approach in the setting of least-squares\nand logistic regression, as well as neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 14:01:57 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 15:39:09 GMT"}, {"version": "v3", "created": "Tue, 6 Jun 2017 12:41:22 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Mahsereci", "Maren", ""], ["Balles", "Lukas", ""], ["Lassner", "Christoph", ""], ["Hennig", "Philipp", ""]]}, {"id": "1703.09646", "submitter": "Rundong Du", "authors": "Rundong Du, Barry Drake, Haesun Park", "title": "Hybrid Clustering based on Content and Connection Structure using Joint\n  Nonnegative Matrix Factorization", "comments": "9 pages, Submitted to a conference, Feb. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a hybrid method for latent information discovery on the data sets\ncontaining both text content and connection structure based on constrained low\nrank approximation. The new method jointly optimizes the Nonnegative Matrix\nFactorization (NMF) objective function for text clustering and the Symmetric\nNMF (SymNMF) objective function for graph clustering. We propose an effective\nalgorithm for the joint NMF objective function, based on a block coordinate\ndescent (BCD) framework. The proposed hybrid method discovers content\nassociations via latent connections found using SymNMF. The method can also be\napplied with a natural conversion of the problem when a hypergraph formulation\nis used or the content is associated with hypergraph edges.\n  Experimental results show that by simultaneously utilizing both content and\nconnection structure, our hybrid method produces higher quality clustering\nresults compared to the other NMF clustering methods that uses content alone\n(standard NMF) or connection structure alone (SymNMF). We also present some\ninteresting applications to several types of real world data such as citation\nrecommendations of papers. The hybrid method proposed in this paper can also be\napplied to general data expressed with both feature space vectors and pairwise\nsimilarities and can be extended to the case with multiple feature spaces or\nmultiple similarity measures.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 15:56:53 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Du", "Rundong", ""], ["Drake", "Barry", ""], ["Park", "Haesun", ""]]}, {"id": "1703.09651", "submitter": "Divya Shyam Singh", "authors": "Divya Shyam Singha, G.B.L. Chowdarya, D Roy Mahapatraa", "title": "Structural Damage Identification Using Artificial Neural Network and\n  Synthetic data", "comments": "6 pages,6 figures, ISSS conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents real-time vibration based identification technique using\nmeasured frequency response functions(FRFs) under random vibration loading.\nArtificial Neural Networks (ANNs) are trained to map damage fingerprints to\ndamage characteristic parameters. Principal component statistical analysis(PCA)\ntechnique was used to tackle the problem of high dimensionality and high noise\nof data, which is common for industrial structures. The present study considers\nCrack, Rivet hole expansion and redundant uniform mass as damages on the\nstructure. Frequency response function data after being reduced in size using\nPCA is fed to individual neural networks to localize and predict the severity\nof damage on the structure. The system of ANNs trained with both numerical and\nexperimental model data to make the system reliable and robust. The methodology\nis applied to a numerical model of stiffened panel structure, where damages are\nconfined close to the stiffener. The results showed that, in all the cases\nconsidered, it is possible to localize and predict severity of the damage\noccurrence with very good accuracy and reliability.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 08:54:09 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Singha", "Divya Shyam", ""], ["Chowdarya", "G. B. L.", ""], ["Mahapatraa", "D Roy", ""]]}, {"id": "1703.09700", "submitter": "Antti Kangasr\\\"a\\\"asi\\\"o", "authors": "Antti Kangasr\\\"a\\\"asi\\\"o, Samuel Kaski", "title": "Inverse Reinforcement Learning from Summary Data", "comments": "To appear in ECMLPKDD'2018", "journal-ref": null, "doi": "10.1007/s10994-018-5730-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) aims to explain observed strategic\nbehavior by fitting reinforcement learning models to behavioral data. However,\ntraditional IRL methods are only applicable when the observations are in the\nform of state-action paths. This assumption may not hold in many real-world\nmodeling settings, where only partial or summarized observations are available.\nIn general, we may assume that there is a summarizing function $\\sigma$, which\nacts as a filter between us and the true state-action paths that constitute the\ndemonstration. Some initial approaches to extending IRL to such situations have\nbeen presented, but with very specific assumptions about the structure of\n$\\sigma$, such as that only certain state observations are missing. This paper\ninstead focuses on the most general case of the problem, where no assumptions\nare made about the summarizing function, except that it can be evaluated. We\ndemonstrate that inference is still possible. The paper presents exact and\napproximate inference algorithms that allow full posterior inference, which is\nparticularly important for assessing parameter uncertainty in this challenging\ninference situation. Empirical scalability is demonstrated to reasonably sized\nproblems, and practical applicability is demonstrated by estimating the\nposterior for a cognitive science RL model based on an observed user's task\ncompletion time only.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 16:13:23 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 14:55:11 GMT"}, {"version": "v3", "created": "Sun, 17 Jun 2018 06:46:22 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Kangasr\u00e4\u00e4si\u00f6", "Antti", ""], ["Kaski", "Samuel", ""]]}, {"id": "1703.09752", "submitter": "Nhien-An Le-Khac", "authors": "Loic Bontemps, Van Loi Cao, James McDermott, Nhien-An Le-Khac", "title": "Collective Anomaly Detection based on Long Short Term Memory Recurrent\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection for computer network systems becomes one of the most\ncritical tasks for network administrators today. It has an important role for\norganizations, governments and our society due to its valuable resources on\ncomputer networks. Traditional misuse detection strategies are unable to detect\nnew and unknown intrusion. Besides, anomaly detection in network security is\naim to distinguish between illegal or malicious events and normal behavior of\nnetwork systems. Anomaly detection can be considered as a classification\nproblem where it builds models of normal network behavior, which it uses to\ndetect new patterns that significantly deviate from the model. Most of the cur-\nrent research on anomaly detection is based on the learning of normally and\nanomaly behaviors. They do not take into account the previous, re- cent events\nto detect the new incoming one. In this paper, we propose a real time\ncollective anomaly detection model based on neural network learning and feature\noperating. Normally a Long Short Term Memory Recurrent Neural Network (LSTM\nRNN) is trained only on normal data and it is capable of predicting several\ntime steps ahead of an input. In our approach, a LSTM RNN is trained with\nnormal time series data before performing a live prediction for each time step.\nInstead of considering each time step separately, the observation of prediction\nerrors from a certain number of time steps is now proposed as a new idea for\ndetecting collective anomalies. The prediction errors from a number of the\nlatest time steps above a threshold will indicate a collective anomaly. The\nmodel is built on a time series version of the KDD 1999 dataset. The\nexperiments demonstrate that it is possible to offer reliable and efficient for\ncollective anomaly detection.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 19:04:11 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Bontemps", "Loic", ""], ["Cao", "Van Loi", ""], ["McDermott", "James", ""], ["Le-Khac", "Nhien-An", ""]]}, {"id": "1703.09766", "submitter": "Kai Fan", "authors": "Kai Fan", "title": "Unifying the Stochastic Spectral Descent for Restricted Boltzmann\n  Machines with Bernoulli or Gaussian Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent based algorithms are typically used as the\ngeneral optimization tools for most deep learning models. A Restricted\nBoltzmann Machine (RBM) is a probabilistic generative model that can be stacked\nto construct deep architectures. For RBM with Bernoulli inputs, non-Euclidean\nalgorithm such as stochastic spectral descent (SSD) has been specifically\ndesigned to speed up the convergence with improved use of the gradient\nestimation by sampling methods. However, the existing algorithm and\ncorresponding theoretical justification depend on the assumption that the\npossible configurations of inputs are finite, like binary variables. The\npurpose of this paper is to generalize SSD for Gaussian RBM being capable of\nmod- eling continuous data, regardless of the previous assumption. We propose\nthe gradient descent methods in non-Euclidean space of parameters, via de-\nriving the upper bounds of logarithmic partition function for RBMs based on\nSchatten-infinity norm. We empirically show that the advantage and improvement\nof SSD over stochastic gradient descent (SGD).\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 19:42:16 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Fan", "Kai", ""]]}, {"id": "1703.09772", "submitter": "Dorian Cazau", "authors": "D. Cazau, G. Revillon, W. Yuancheng, O. Adam", "title": "Particle Filtering for PLCA model with Application to Music\n  Transcription", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Music Transcription (AMT) consists in automatically estimating the\nnotes in an audio recording, through three attributes: onset time, duration and\npitch. Probabilistic Latent Component Analysis (PLCA) has become very popular\nfor this task. PLCA is a spectrogram factorization method, able to model a\nmagnitude spectrogram as a linear combination of spectral vectors from a\ndictionary. Such methods use the Expectation-Maximization (EM) algorithm to\nestimate the parameters of the acoustic model. This algorithm presents\nwell-known inherent defaults (local convergence, initialization dependency),\nmaking EM-based systems limited in their applications to AMT, particularly in\nregards to the mathematical form and number of priors. To overcome such limits,\nwe propose in this paper to employ a different estimation framework based on\nParticle Filtering (PF), which consists in sampling the posterior distribution\nover larger parameter ranges. This framework proves to be more robust in\nparameter estimation, more flexible and unifying in the integration of prior\nknowledge in the system. Note-level transcription accuracies of 61.8 $\\%$ and\n59.5 $\\%$ were achieved on evaluation sound datasets of two different\ninstrument repertoires, including the classical piano (from MAPS dataset) and\nthe marovany zither, and direct comparisons to previous PLCA-based approaches\nare provided. Steps for further development are also outlined.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 19:56:47 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Cazau", "D.", ""], ["Revillon", "G.", ""], ["Yuancheng", "W.", ""], ["Adam", "O.", ""]]}, {"id": "1703.09783", "submitter": "Rui Zhao", "authors": "Rui Zhao, Haider Ali, Patrick van der Smagt", "title": "Two-Stream RNN/CNN for Action Recognition in 3D Videos", "comments": "Published in 2017 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS)", "journal-ref": null, "doi": "10.1109/IROS.2017.8206288", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recognition of actions from video sequences has many applications in\nhealth monitoring, assisted living, surveillance, and smart homes. Despite\nadvances in sensing, in particular related to 3D video, the methodologies to\nprocess the data are still subject to research. We demonstrate superior results\nby a system which combines recurrent neural networks with convolutional neural\nnetworks in a voting approach. The gated-recurrent-unit-based neural networks\nare particularly well-suited to distinguish actions based on long-term\ninformation from optical tracking data; the 3D-CNNs focus more on detailed,\nrecent information from video data. The resulting features are merged in an SVM\nwhich then classifies the movement. In this architecture, our method improves\nrecognition rates of state-of-the-art methods by 14% on standard data sets.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 22:29:56 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 16:16:31 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Zhao", "Rui", ""], ["Ali", "Haider", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1703.09784", "submitter": "Yanhai Gan", "authors": "Yanhai Gan, Huifang Chi, Ying Gao, Jun Liu, Guoqiang Zhong, Junyu Dong", "title": "Perception Driven Texture Generation", "comments": "7 pages, 4 figures, icme2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a novel task of generating texture images from\nperceptual descriptions. Previous work on texture generation focused on either\nsynthesis from examples or generation from procedural models. Generating\ntextures from perceptual attributes have not been well studied yet. Meanwhile,\nperceptual attributes, such as directionality, regularity and roughness are\nimportant factors for human observers to describe a texture. In this paper, we\npropose a joint deep network model that combines adversarial training and\nperceptual feature regression for texture generation, while only random noise\nand user-defined perceptual attributes are required as input. In this model, a\npreliminary trained convolutional neural network is essentially integrated with\nthe adversarial framework, which can drive the generated textures to possess\ngiven perceptual attributes. An important aspect of the proposed model is that,\nif we change one of the input perceptual features, the corresponding appearance\nof the generated textures will also be changed. We design several experiments\nto validate the effectiveness of the proposed method. The results show that the\nproposed method can produce high quality texture images with desired perceptual\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 01:25:30 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Gan", "Yanhai", ""], ["Chi", "Huifang", ""], ["Gao", "Ying", ""], ["Liu", "Jun", ""], ["Zhong", "Guoqiang", ""], ["Dong", "Junyu", ""]]}, {"id": "1703.09793", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini, Baicen Xiao and Radha Poovendran", "title": "Deceiving Google's Cloud Video Intelligence API Built for Summarizing\n  Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the rapid progress of the techniques for image classification, video\nannotation has remained a challenging task. Automated video annotation would be\na breakthrough technology, enabling users to search within the videos.\nRecently, Google introduced the Cloud Video Intelligence API for video\nanalysis. As per the website, the system can be used to \"separate signal from\nnoise, by retrieving relevant information at the video, shot or per frame\"\nlevel. A demonstration website has been also launched, which allows anyone to\nselect a video for annotation. The API then detects the video labels (objects\nwithin the video) as well as shot labels (description of the video events over\ntime). In this paper, we examine the usability of the Google's Cloud Video\nIntelligence API in adversarial environments. In particular, we investigate\nwhether an adversary can subtly manipulate a video in such a way that the API\nwill return only the adversary-desired labels. For this, we select an image,\nwhich is different from the video content, and insert it, periodically and at a\nvery low rate, into the video. We found that if we insert one image every two\nseconds, the API is deceived into annotating the video as if it only contained\nthe inserted image. Note that the modification to the video is hardly\nnoticeable as, for instance, for a typical frame rate of 25, we insert only one\nimage per 50 video frames. We also found that, by inserting one image per\nsecond, all the shot labels returned by the API are related to the inserted\nimage. We perform the experiments on the sample videos provided by the API\ndemonstration website and show that our attack is successful with different\nvideos and images.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 20:52:43 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 05:25:36 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Hosseini", "Hossein", ""], ["Xiao", "Baicen", ""], ["Poovendran", "Radha", ""]]}, {"id": "1703.09800", "submitter": "Iman Niazazari", "authors": "Iman Niazazari and Hanif Livani", "title": "Disruptive Event Classification using PMU Data in Distribution Networks", "comments": "5 pages, 5 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Proliferation of advanced metering devices with high sampling rates in\ndistribution grids, e.g., micro-phasor measurement units ({\\mu}PMU), provides\nunprecedented potentials for wide-area monitoring and diagnostic applications,\ne.g., situational awareness, health monitoring of distribution assets.\nUnexpected disruptive events interrupting the normal operation of assets in\ndistribution grids can eventually lead to permanent failure with expensive\nreplacement cost over time. Therefore, disruptive event classification provides\nuseful information for preventive maintenance of the assets in distribution\nnetworks. Preventive maintenance provides wide range of benefits in terms of\ntime, avoiding unexpected outages, maintenance crew utilization, and equipment\nreplacement cost. In this paper, a PMU-data-driven framework is proposed for\nclassification of disruptive events in distribution networks. The two\ndisruptive events, i.e., malfunctioned capacitor bank switching and\nmalfunctioned regulator on-load tap changer (OLTC) switching are considered and\ndistinguished from the normal abrupt load change in distribution grids. The\nperformance of the proposed framework is verified using the simulation of the\nevents in the IEEE 13-bus distribution network. The event classification is\nformulated using two different algorithms as; i) principle component analysis\n(PCA) together with multi-class support vector machine (SVM), and ii)\nautoencoder along with softmax classifier. The results demonstrate the\neffectiveness of the proposed algorithms and satisfactory classification\naccuracies.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 01:31:43 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Niazazari", "Iman", ""], ["Livani", "Hanif", ""]]}, {"id": "1703.09831", "submitter": "Haonan Yu", "authors": "Haonan Yu, Haichao Zhang, and Wei Xu", "title": "A Deep Compositional Framework for Human-like Language Acquisition in\n  Virtual Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle a task where an agent learns to navigate in a 2D maze-like\nenvironment called XWORLD. In each session, the agent perceives a sequence of\nraw-pixel frames, a natural language command issued by a teacher, and a set of\nrewards. The agent learns the teacher's language from scratch in a grounded and\ncompositional manner, such that after training it is able to correctly execute\nzero-shot commands: 1) the combination of words in the command never appeared\nbefore, and/or 2) the command contains new object concepts that are learned\nfrom another task but never learned from navigation. Our deep framework for the\nagent is trained end to end: it learns simultaneously the visual\nrepresentations of the environment, the syntax and semantics of the language,\nand the action module that outputs actions. The zero-shot learning capability\nof our framework results from its compositionality and modularity with\nparameter tying. We visualize the intermediate outputs of the framework,\ndemonstrating that the agent truly understands how to solve the problem. We\nbelieve that our results provide some preliminary insights on how to train an\nagent with similar abilities in a 3D environment.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 22:29:53 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 20:28:59 GMT"}, {"version": "v3", "created": "Fri, 19 May 2017 23:33:28 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Yu", "Haonan", ""], ["Zhang", "Haichao", ""], ["Xu", "Wei", ""]]}, {"id": "1703.09833", "submitter": "Qianli Liao", "authors": "Qianli Liao and Tomaso Poggio", "title": "Theory II: Landscape of the Empirical Risk in Deep Learning", "comments": "Merged figures to make the main text more compact. Moved some similar\n  figures to the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous theoretical work on deep learning and neural network optimization\ntend to focus on avoiding saddle points and local minima. However, the\npractical observation is that, at least in the case of the most successful Deep\nConvolutional Neural Networks (DCNNs), practitioners can always increase the\nnetwork size to fit the training data (an extreme example would be [1]). The\nmost successful DCNNs such as VGG and ResNets are best used with a degree of\n\"overparametrization\". In this work, we characterize with a mix of theory and\nexperiments, the landscape of the empirical risk of overparametrized DCNNs. We\nfirst prove in the regression framework the existence of a large number of\ndegenerate global minimizers with zero empirical error (modulo inconsistent\nequations). The argument that relies on the use of Bezout theorem is rigorous\nwhen the RELUs are replaced by a polynomial nonlinearity (which empirically\nworks as well). As described in our Theory III [2] paper, the same minimizers\nare degenerate and thus very likely to be found by SGD that will furthermore\nselect with higher probability the most robust zero-minimizer. We further\nexperimentally explored and visualized the landscape of empirical risk of a\nDCNN on CIFAR-10 during the entire training process and especially the global\nminima. Finally, based on our theoretical and experimental results, we propose\nan intuitive model of the landscape of DCNN's empirical loss surface, which\nmight not be as complicated as people commonly believe.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 22:47:04 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 09:33:35 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Liao", "Qianli", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1703.09842", "submitter": "Lillian Ratliff", "authors": "Lillian J. Ratliff and Eric Mazumdar", "title": "Inverse Risk-Sensitive Reinforcement Learning", "comments": "v3 (comments regarding updates): We significantly extended the theory\n  (Theorem 2, 3, 5 and Proposition 3). We also correct some minor typos\n  throughout the document; v2 (comments regarding updates): We corrected some\n  notational typos and made clarifications in the proof. We also added\n  clarifying remarks regarding reference points and acceptance levels which\n  were previously conflated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of inverse reinforcement learning in Markov decision\nprocesses where the agent is risk-sensitive. In particular, we model\nrisk-sensitivity in a reinforcement learning framework by making use of models\nof human decision-making having their origins in behavioral psychology,\nbehavioral economics, and neuroscience. We propose a gradient-based inverse\nreinforcement learning algorithm that minimizes a loss function defined on the\nobserved behavior. We demonstrate the performance of the proposed technique on\ntwo examples, the first of which is the canonical Grid World example and the\nsecond of which is a Markov decision process modeling passengers' decisions\nregarding ride-sharing. In the latter, we use pricing and travel time data from\na ride-sharing company to construct the transition probabilities and rewards of\nthe Markov decision process.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 00:10:17 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 01:14:47 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 20:51:05 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Ratliff", "Lillian J.", ""], ["Mazumdar", "Eric", ""]]}, {"id": "1703.09844", "submitter": "Gao Huang", "authors": "Gao Huang, Danlu Chen, Tianhong Li, Felix Wu, Laurens van der Maaten\n  and Kilian Q. Weinberger", "title": "Multi-Scale Dense Networks for Resource Efficient Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate image classification with computational resource\nlimits at test time. Two such settings are: 1. anytime classification, where\nthe network's prediction for a test example is progressively updated,\nfacilitating the output of a prediction at any time; and 2. budgeted batch\nclassification, where a fixed amount of computation is available to classify a\nset of examples that can be spent unevenly across \"easier\" and \"harder\" inputs.\nIn contrast to most prior work, such as the popular Viola and Jones algorithm,\nour approach is based on convolutional neural networks. We train multiple\nclassifiers with varying resource demands, which we adaptively apply during\ntest time. To maximally re-use computation between the classifiers, we\nincorporate them as early-exits into a single deep convolutional neural network\nand inter-connect them with dense connectivity. To facilitate high quality\nclassification early on, we use a two-dimensional multi-scale network\narchitecture that maintains coarse and fine level features all-throughout the\nnetwork. Experiments on three image-classification tasks demonstrate that our\nframework substantially improves the existing state-of-the-art in both\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 00:19:20 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 14:17:22 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 01:05:26 GMT"}, {"version": "v4", "created": "Mon, 6 Nov 2017 14:35:44 GMT"}, {"version": "v5", "created": "Thu, 7 Jun 2018 14:39:29 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Huang", "Gao", ""], ["Chen", "Danlu", ""], ["Li", "Tianhong", ""], ["Wu", "Felix", ""], ["van der Maaten", "Laurens", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "1703.09851", "submitter": "Mohamed Abuella", "authors": "Mohamed Abuella and Badrul Chowdhury", "title": "Solar Power Forecasting Using Support Vector Regression", "comments": "This works has been presented in the American Society for Engineering\n  Management, International Annual Conference, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.AP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Generation and load balance is required in the economic scheduling of\ngenerating units in the smart grid. Variable energy generations, particularly\nfrom wind and solar energy resources, are witnessing a rapid boost, and, it is\nanticipated that with a certain level of their penetration, they can become\nnoteworthy sources of uncertainty. As in the case of load demand, energy\nforecasting can also be used to mitigate some of the challenges that arise from\nthe uncertainty in the resource. While wind energy forecasting research is\nconsidered mature, solar energy forecasting is witnessing a steadily growing\nattention from the research community. This paper presents a support vector\nregression model to produce solar power forecasts on a rolling basis for 24\nhours ahead over an entire year, to mimic the practical business of energy\nforecasting. Twelve weather variables are considered from a high-quality\nbenchmark dataset and new variables are extracted. The added value of the heat\nindex and wind speed as additional variables to the model is studied across\ndifferent seasons. The support vector regression model performance is compared\nwith artificial neural networks and multiple linear regression models for\nenergy forecasting.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 00:58:01 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Abuella", "Mohamed", ""], ["Chowdhury", "Badrul", ""]]}, {"id": "1703.09891", "submitter": "Hexiang Hu", "authors": "Hexiang Hu, Zhiwei Deng, Guang-Tong Zhou, Fei Sha, Greg Mori", "title": "LabelBank: Revisiting Global Perspectives for Semantic Segmentation", "comments": "Pre-prints", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation requires a detailed labeling of image pixels by object\ncategory. Information derived from local image patches is necessary to describe\nthe detailed shape of individual objects. However, this information is\nambiguous and can result in noisy labels. Global inference of image content can\ninstead capture the general semantic concepts present. We advocate that\nholistic inference of image concepts provides valuable information for detailed\npixel labeling. We propose a generic framework to leverage holistic information\nin the form of a LabelBank for pixel-level segmentation.\n  We show the ability of our framework to improve semantic segmentation\nperformance in a variety of settings. We learn models for extracting a holistic\nLabelBank from visual cues, attributes, and/or textual descriptions. We\ndemonstrate improvements in semantic segmentation accuracy on standard datasets\nacross a range of state-of-the-art segmentation architectures and holistic\ninference approaches.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 05:58:21 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Hu", "Hexiang", ""], ["Deng", "Zhiwei", ""], ["Zhou", "Guang-Tong", ""], ["Sha", "Fei", ""], ["Mori", "Greg", ""]]}, {"id": "1703.09938", "submitter": "Subin Yi", "authors": "Subin Yi, Janghoon Ju, Man-Ki Yoon, Jaesik Choi", "title": "Grouped Convolutional Neural Networks for Multivariate Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing multivariate time series data is important for many applications\nsuch as automated control, fault diagnosis and anomaly detection. One of the\nkey challenges is to learn latent features automatically from dynamically\nchanging multivariate input. In visual recognition tasks, convolutional neural\nnetworks (CNNs) have been successful to learn generalized feature extractors\nwith shared parameters over the spatial domain. However, when high-dimensional\nmultivariate time series is given, designing an appropriate CNN model structure\nbecomes challenging because the kernels may need to be extended through the\nfull dimension of the input volume. To address this issue, we present two\nstructure learning algorithms for deep CNN models. Our algorithms exploit the\ncovariance structure over multiple time series to partition input volume into\ngroups. The first algorithm learns the group CNN structures explicitly by\nclustering individual input sequences. The second algorithm learns the group\nCNN structures implicitly from the error backpropagation. In experiments with\ntwo real-world datasets, we demonstrate that our group CNNs outperform existing\nCNN based regression methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 09:05:40 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 05:18:33 GMT"}, {"version": "v3", "created": "Tue, 4 Apr 2017 06:05:50 GMT"}, {"version": "v4", "created": "Thu, 31 May 2018 00:39:45 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Yi", "Subin", ""], ["Ju", "Janghoon", ""], ["Yoon", "Man-Ki", ""], ["Choi", "Jaesik", ""]]}, {"id": "1703.09947", "submitter": "Kai Zheng", "authors": "Jiaqi Zhang, Kai Zheng, Wenlong Mou, Liwei Wang", "title": "Efficient Private ERM for Smooth Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider efficient differentially private empirical risk\nminimization from the viewpoint of optimization algorithms. For strongly convex\nand smooth objectives, we prove that gradient descent with output perturbation\nnot only achieves nearly optimal utility, but also significantly improves the\nrunning time of previous state-of-the-art private optimization algorithms, for\nboth $\\epsilon$-DP and $(\\epsilon, \\delta)$-DP. For non-convex but smooth\nobjectives, we propose an RRPSGD (Random Round Private Stochastic Gradient\nDescent) algorithm, which provably converges to a stationary point with privacy\nguarantee. Besides the expected utility bounds, we also provide guarantees in\nhigh probability form. Experiments demonstrate that our algorithm consistently\noutperforms existing method in both utility and running time.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 09:31:47 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 12:57:48 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Zhang", "Jiaqi", ""], ["Zheng", "Kai", ""], ["Mou", "Wenlong", ""], ["Wang", "Liwei", ""]]}, {"id": "1703.09956", "submitter": "Indranil Pan", "authors": "Indranil Pan and Dirk Bester", "title": "Marginal likelihood based model comparison in Fuzzy Bayesian Learning", "comments": "6 pages, 1 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper [1] we introduced the Fuzzy Bayesian Learning (FBL)\nparadigm where expert opinions can be encoded in the form of fuzzy rule bases\nand the hyper-parameters of the fuzzy sets can be learned from data using a\nBayesian approach. The present paper extends this work for selecting the most\nappropriate rule base among a set of competing alternatives, which best\nexplains the data, by calculating the model evidence or marginal likelihood. We\nexplain why this is an attractive alternative over simply minimizing a mean\nsquared error metric of prediction and show the validity of the proposition\nusing synthetic examples and a real world case study in the financial services\nsector.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 10:17:57 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Pan", "Indranil", ""], ["Bester", "Dirk", ""]]}, {"id": "1703.10034", "submitter": "Maren Mahsereci", "authors": "Maren Mahsereci, Philipp Hennig", "title": "Probabilistic Line Searches for Stochastic Optimization", "comments": "Extended version of the NIPS '15 conference paper, includes detailed\n  pseudo-code, 59 pages, 35 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deterministic optimization, line searches are a standard tool ensuring\nstability and efficiency. Where only stochastic gradients are available, no\ndirect equivalent has so far been formulated, because uncertain gradients do\nnot allow for a strict sequence of decisions collapsing the search space. We\nconstruct a probabilistic line search by combining the structure of existing\ndeterministic methods with notions from Bayesian optimization. Our method\nretains a Gaussian process surrogate of the univariate optimization objective,\nand uses a probabilistic belief over the Wolfe conditions to monitor the\ndescent. The algorithm has very low computational cost, and no user-controlled\nparameters. Experiments show that it effectively removes the need to define a\nlearning rate for stochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 13:43:52 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 16:18:08 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Mahsereci", "Maren", ""], ["Hennig", "Philipp", ""]]}, {"id": "1703.10039", "submitter": "Feiyun Zhu", "authors": "Feiyun Zhu, Peng Liao, Xinliang Zhu, Yaowen Yao and Junzhou Huang", "title": "Cohesion-based Online Actor-Critic Reinforcement Learning for mHealth\n  Intervention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the wake of the vast population of smart device users worldwide, mobile\nhealth (mHealth) technologies are hopeful to generate positive and wide\ninfluence on people's health. They are able to provide flexible, affordable and\nportable health guides to device users. Current online decision-making methods\nfor mHealth assume that the users are completely heterogeneous. They share no\ninformation among users and learn a separate policy for each user. However,\ndata for each user is very limited in size to support the separate online\nlearning, leading to unstable policies that contain lots of variances. Besides,\nwe find the truth that a user may be similar with some, but not all, users, and\nconnected users tend to have similar behaviors. In this paper, we propose a\nnetwork cohesion constrained (actor-critic) Reinforcement Learning (RL) method\nfor mHealth. The goal is to explore how to share information among similar\nusers to better convert the limited user information into sharper learned\npolicies. To the best of our knowledge, this is the first online actor-critic\nRL for mHealth and first network cohesion constrained (actor-critic) RL method\nin all applications. The network cohesion is important to derive effective\npolicies. We come up with a novel method to learn the network by using the warm\nstart trajectory, which directly reflects the users' property. The optimization\nof our model is difficult and very different from the general supervised\nlearning due to the indirect observation of values. As a contribution, we\npropose two algorithms for the proposed online RLs. Apart from mHealth, the\nproposed methods can be easily applied or adapted to other health-related\ntasks. Extensive experiment results on the HeartSteps dataset demonstrates that\nin a variety of parameter settings, the proposed two methods obtain obvious\nimprovements over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 23:01:20 GMT"}, {"version": "v2", "created": "Wed, 23 Aug 2017 22:40:49 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Zhu", "Feiyun", ""], ["Liao", "Peng", ""], ["Zhu", "Xinliang", ""], ["Yao", "Yaowen", ""], ["Huang", "Junzhou", ""]]}, {"id": "1703.10069", "submitter": "Ying Wen", "authors": "Peng Peng, Ying Wen, Yaodong Yang, Quan Yuan, Zhenkun Tang, Haitao\n  Long, Jun Wang", "title": "Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level\n  Coordination in Learning to Play StarCraft Combat Games", "comments": "10 pages, 10 figures. Previously as title: \"Multiagent\n  Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat\n  Games\", Mar 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many artificial intelligence (AI) applications often require multiple\nintelligent agents to work in a collaborative effort. Efficient learning for\nintra-agent communication and coordination is an indispensable step towards\ngeneral AI. In this paper, we take StarCraft combat game as a case study, where\nthe task is to coordinate multiple agents as a team to defeat their enemies. To\nmaintain a scalable yet effective communication protocol, we introduce a\nMultiagent Bidirectionally-Coordinated Network (BiCNet ['bIknet]) with a\nvectorised extension of actor-critic formulation. We show that BiCNet can\nhandle different types of combats with arbitrary numbers of AI agents for both\nsides. Our analysis demonstrates that without any supervisions such as human\ndemonstrations or labelled data, BiCNet could learn various types of advanced\ncoordination strategies that have been commonly used by experienced game\nplayers. In our experiments, we evaluate our approach against multiple\nbaselines under different scenarios; it shows state-of-the-art performance, and\npossesses potential values for large-scale real-world applications.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 14:37:25 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 07:01:31 GMT"}, {"version": "v3", "created": "Tue, 20 Jun 2017 10:08:42 GMT"}, {"version": "v4", "created": "Thu, 14 Sep 2017 12:45:46 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Peng", "Peng", ""], ["Wen", "Ying", ""], ["Yang", "Yaodong", ""], ["Yuan", "Quan", ""], ["Tang", "Zhenkun", ""], ["Long", "Haitao", ""], ["Wang", "Jun", ""]]}, {"id": "1703.10089", "submitter": "Yagmur Gizem Cinar", "authors": "Yagmur G. Cinar, Hamid Mirisaee, Parantapa Goswami, Eric Gaussier, Ali\n  Ait-Bachir, and Vadim Strijov", "title": "Position-based Content Attention for Time Series Forecasting with\n  Sequence-to-sequence RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose here an extended attention model for sequence-to-sequence\nrecurrent neural networks (RNNs) designed to capture (pseudo-)periods in time\nseries. This extended attention model can be deployed on top of any RNN and is\nshown to yield state-of-the-art performance for time series forecasting on\nseveral univariate and multivariate time series.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 15:11:16 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 12:36:58 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Cinar", "Yagmur G.", ""], ["Mirisaee", "Hamid", ""], ["Goswami", "Parantapa", ""], ["Gaussier", "Eric", ""], ["Ait-Bachir", "Ali", ""], ["Strijov", "Vadim", ""]]}, {"id": "1703.10094", "submitter": "Junyu Luo", "authors": "Junyu Luo, Yong Xu, Chenwei Tang, and Jiancheng Lv", "title": "Learning Inverse Mapping by Autoencoder based Generative Adversarial\n  Nets", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse mapping of GANs'(Generative Adversarial Nets) generator has a\ngreat potential value.Hence, some works have been developed to construct the\ninverse function of generator by directly learning or adversarial\nlearning.While the results are encouraging, the problem is highly challenging\nand the existing ways of training inverse models of GANs have many\ndisadvantages, such as hard to train or poor performance.Due to these reasons,\nwe propose a new approach based on using inverse generator ($IG$) model as\nencoder and pre-trained generator ($G$) as decoder of an AutoEncoder network to\ntrain the $IG$ model. In the proposed model, the difference between the input\nand output, which are both the generated image of pre-trained GAN's generator,\nof AutoEncoder is directly minimized. The optimizing method can overcome the\ndifficulty in training and inverse model of an non one-to-one function.We also\napplied the inverse model of GANs' generators to image searching and\ntranslation.The experimental results prove that the proposed approach works\nbetter than the traditional approaches in image searching.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 15:23:40 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 08:46:47 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Luo", "Junyu", ""], ["Xu", "Yong", ""], ["Tang", "Chenwei", ""], ["Lv", "Jiancheng", ""]]}, {"id": "1703.10121", "submitter": "Patrick O. Glauner", "authors": "Patrick Glauner, Manxing Du, Victor Paraschiv, Andrey Boytsov, Isabel\n  Lopez Andrade, Jorge Meira, Petko Valtchev, Radu State", "title": "The Top 10 Topics in Machine Learning Revisited: A Quantitative\n  Meta-Study", "comments": null, "journal-ref": "Proceedings of the 25th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN 2017)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Which topics of machine learning are most commonly addressed in research?\nThis question was initially answered in 2007 by doing a qualitative survey\namong distinguished researchers. In our study, we revisit this question from a\nquantitative perspective. Concretely, we collect 54K abstracts of papers\npublished between 2007 and 2016 in leading machine learning journals and\nconferences. We then use machine learning in order to determine the top 10\ntopics in machine learning. We not only include models, but provide a holistic\nview across optimization, data, features, etc. This quantitative approach\nallows reducing the bias of surveys. It reveals new and up-to-date insights\ninto what the 10 most prolific topics in machine learning research are. This\nallows researchers to identify popular topics as well as new and rising topics\nfor their research.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 16:29:04 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Glauner", "Patrick", ""], ["Du", "Manxing", ""], ["Paraschiv", "Victor", ""], ["Boytsov", "Andrey", ""], ["Andrade", "Isabel Lopez", ""], ["Meira", "Jorge", ""], ["Valtchev", "Petko", ""], ["State", "Radu", ""]]}, {"id": "1703.10127", "submitter": "Gautam Kamath", "authors": "Bryan Cai, Constantinos Daskalakis, Gautam Kamath", "title": "Priv'IT: Private and Sample Efficient Identity Testing", "comments": "To appear in ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop differentially private hypothesis testing methods for the small\nsample regime. Given a sample $\\cal D$ from a categorical distribution $p$ over\nsome domain $\\Sigma$, an explicitly described distribution $q$ over $\\Sigma$,\nsome privacy parameter $\\varepsilon$, accuracy parameter $\\alpha$, and\nrequirements $\\beta_{\\rm I}$ and $\\beta_{\\rm II}$ for the type I and type II\nerrors of our test, the goal is to distinguish between $p=q$ and\n$d_{\\rm{TV}}(p,q) \\geq \\alpha$.\n  We provide theoretical bounds for the sample size $|{\\cal D}|$ so that our\nmethod both satisfies $(\\varepsilon,0)$-differential privacy, and guarantees\n$\\beta_{\\rm I}$ and $\\beta_{\\rm II}$ type I and type II errors. We show that\ndifferential privacy may come for free in some regimes of parameters, and we\nalways beat the sample complexity resulting from running the $\\chi^2$-test with\nnoisy counts, or standard approaches such as repetition for endowing\nnon-private $\\chi^2$-style statistics with differential privacy guarantees. We\nexperimentally compare the sample complexity of our method to that of recently\nproposed methods for private hypothesis testing.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 16:42:21 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 14:53:34 GMT"}, {"version": "v3", "created": "Wed, 7 Jun 2017 02:46:11 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Cai", "Bryan", ""], ["Daskalakis", "Constantinos", ""], ["Kamath", "Gautam", ""]]}, {"id": "1703.10135", "submitter": "Yuxuan Wang", "authors": "Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J. Weiss,\n  Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, Quoc Le,\n  Yannis Agiomyrgiannakis, Rob Clark, Rif A. Saurous", "title": "Tacotron: Towards End-to-End Speech Synthesis", "comments": "Submitted to Interspeech 2017. v2 changed paper title to be\n  consistent with our conference submission (no content change other than typo\n  fixes)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A text-to-speech synthesis system typically consists of multiple stages, such\nas a text analysis frontend, an acoustic model and an audio synthesis module.\nBuilding these components often requires extensive domain expertise and may\ncontain brittle design choices. In this paper, we present Tacotron, an\nend-to-end generative text-to-speech model that synthesizes speech directly\nfrom characters. Given <text, audio> pairs, the model can be trained completely\nfrom scratch with random initialization. We present several key techniques to\nmake the sequence-to-sequence framework perform well for this challenging task.\nTacotron achieves a 3.82 subjective 5-scale mean opinion score on US English,\noutperforming a production parametric system in terms of naturalness. In\naddition, since Tacotron generates speech at the frame level, it's\nsubstantially faster than sample-level autoregressive methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 16:55:13 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2017 21:20:34 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Wang", "Yuxuan", ""], ["Skerry-Ryan", "RJ", ""], ["Stanton", "Daisy", ""], ["Wu", "Yonghui", ""], ["Weiss", "Ron J.", ""], ["Jaitly", "Navdeep", ""], ["Yang", "Zongheng", ""], ["Xiao", "Ying", ""], ["Chen", "Zhifeng", ""], ["Bengio", "Samy", ""], ["Le", "Quoc", ""], ["Agiomyrgiannakis", "Yannis", ""], ["Clark", "Rob", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1703.10284", "submitter": "Mark Riedl", "authors": "Mark O. Riedl, Brent Harrison", "title": "Enter the Matrix: Safely Interruptible Autonomous Systems via\n  Virtualization", "comments": "6 pages; 1 figure; title, abstract updated; new experimental results", "journal-ref": "Proceedings of the AAAI 2019 Workshop on SafeAI", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems that operate around humans will likely always rely on kill\nswitches that stop their execution and allow them to be remote-controlled for\nthe safety of humans or to prevent damage to the system. It is theoretically\npossible for an autonomous system with sufficient sensor and effector\ncapability that learn online using reinforcement learning to discover that the\nkill switch deprives it of long-term reward and thus learn to disable the\nswitch or otherwise prevent a human operator from using the switch. This is\nreferred to as the big red button problem. We present a technique that prevents\na reinforcement learning agent from learning to disable the kill switch. We\nintroduce an interruption process in which the agent's sensors and effectors\nare redirected to a virtual simulation where it continues to believe it is\nreceiving reward. We illustrate our technique in a simple grid world\nenvironment.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 01:35:01 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 01:39:36 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Riedl", "Mark O.", ""], ["Harrison", "Brent", ""]]}, {"id": "1703.10355", "submitter": "Senjian An Dr.", "authors": "Senjian An, Farid Boussaid, Mohammed Bennamoun, and Jiankun Hu", "title": "From Deep to Shallow: Transformations of Deep Rectifier Networks", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce transformations of deep rectifier networks,\nenabling the conversion of deep rectifier networks into shallow rectifier\nnetworks. We subsequently prove that any rectifier net of any depth can be\nrepresented by a maximum of a number of functions that can be realized by a\nshallow network with a single hidden layer. The transformations of both deep\nrectifier nets and deep residual nets are conducted to demonstrate the\nadvantages of the residual nets over the conventional neural nets and the\nadvantages of the deep neural nets over the shallow neural nets. In summary,\nfor two rectifier nets with different depths but with same total number of\nhidden units, the corresponding single hidden layer representation of the\ndeeper net is much more complex than the corresponding single hidden\nrepresentation of the shallower net. Similarly, for a residual net and a\nconventional rectifier net with the same structure except for the skip\nconnections in the residual net, the corresponding single hidden layer\nrepresentation of the residual net is much more complex than the corresponding\nsingle hidden layer representation of the conventional net.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 08:37:14 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["An", "Senjian", ""], ["Boussaid", "Farid", ""], ["Bennamoun", "Mohammed", ""], ["Hu", "Jiankun", ""]]}, {"id": "1703.10356", "submitter": "Lior Fritz", "authors": "Lior Fritz, David Burshtein", "title": "Simplified End-to-End MMI Training and Voting for ASR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simplified speech recognition system that uses the maximum mutual\ninformation (MMI) criterion is considered. End-to-end training using gradient\ndescent is suggested, similarly to the training of connectionist temporal\nclassification (CTC). We use an MMI criterion with a simple language model in\nthe training stage, and a standard HMM decoder. Our method compares favorably\nto CTC in terms of performance, robustness, decoding time, disk footprint and\nquality of alignments. The good alignments enable the use of a straightforward\nensemble method, obtained by simply averaging the predictions of several neural\nnetwork models, that were trained separately end-to-end. The ensemble method\nyields a considerable reduction in the word error rate.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 08:40:19 GMT"}, {"version": "v2", "created": "Sun, 16 Jul 2017 15:12:39 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Fritz", "Lior", ""], ["Burshtein", "David", ""]]}, {"id": "1703.10444", "submitter": "Jiashi Feng", "authors": "Jiashi Feng", "title": "On Fundamental Limits of Robust Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problems of robust PAC learning from distributed and\nstreaming data, which may contain malicious errors and outliers, and analyze\ntheir fundamental complexity questions. In particular, we establish lower\nbounds on the communication complexity for distributed robust learning\nperformed on multiple machines, and on the space complexity for robust learning\nfrom streaming data on a single machine. These results demonstrate that gaining\nrobustness of learning algorithms is usually at the expense of increased\ncomplexities. As far as we know, this work gives the first complexity results\nfor distributed and online robust PAC learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 12:46:46 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Feng", "Jiashi", ""]]}, {"id": "1703.10458", "submitter": "Abhinav Madahar", "authors": "Abhinav Madahar, Yuze Ma, and Kunal Patel", "title": "Application of a Shallow Neural Network to Short-Term Stock Trading", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning is increasingly prevalent in stock market trading. Though\nneural networks have seen success in computer vision and natural language\nprocessing, they have not been as useful in stock market trading. To\ndemonstrate the applicability of a neural network in stock trading, we made a\nsingle-layer neural network that recommends buying or selling shares of a stock\nby comparing the highest high of 10 consecutive days with that of the next 10\ndays, a process repeated for the stock's year-long historical data. A\nchi-squared analysis found that the neural network can accurately and\nappropriately decide whether to buy or sell shares for a given stock, showing\nthat a neural network can make simple decisions about the stock market.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 13:18:35 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Madahar", "Abhinav", ""], ["Ma", "Yuze", ""], ["Patel", "Kunal", ""]]}, {"id": "1703.10513", "submitter": "Zhenghan Zhu", "authors": "Zhenghan Zhu and Steven Kay", "title": "On Bayesian Exponentially Embedded Family for Model Order Selection", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2017.2781642", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive a Bayesian model order selection rule by using the\nexponentially embedded family method, termed Bayesian EEF. Unlike many other\nBayesian model selection methods, the Bayesian EEF can use vague proper priors\nand improper noninformative priors to be objective in the elicitation of\nparameter priors. Moreover, the penalty term of the rule is shown to be the sum\nof half of the parameter dimension and the estimated mutual information between\nparameter and observed data. This helps to reveal the EEF mechanism in\nselecting model orders and may provide new insights into the open problems of\nchoosing an optimal penalty term for model order selection and choosing a good\nprior from information theoretic viewpoints. The important example of linear\nmodel order selection is given to illustrate the algorithms and arguments.\nLastly, the Bayesian EEF that uses Jeffreys prior coincides with the EEF rule\nderived by frequentist strategies. This shows another interesting relationship\nbetween the frequentist and Bayesian philosophies for model selection.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 15:12:02 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 03:55:14 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Zhu", "Zhenghan", ""], ["Kay", "Steven", ""]]}, {"id": "1703.10534", "submitter": "Zhaoqiang Liu", "authors": "Zhaoqiang Liu, Vincent Y. F. Tan", "title": "The Informativeness of $k$-Means for Learning Mixture Models", "comments": "Accepted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning of mixture models can be viewed as a clustering problem. Indeed,\ngiven data samples independently generated from a mixture of distributions, we\noften would like to find the correct target clustering of the samples according\nto which component distribution they were generated from. For a clustering\nproblem, practitioners often choose to use the simple k-means algorithm.\nk-means attempts to find an optimal clustering which minimizes the\nsum-of-squared distance between each point and its cluster center. In this\npaper, we provide sufficient conditions for the closeness of any optimal\nclustering and the correct target clustering assuming that the data samples are\ngenerated from a mixture of log-concave distributions. Moreover, we show that\nunder similar or even weaker conditions on the mixture model, any optimal\nclustering for the samples with reduced dimensionality is also close to the\ncorrect target clustering. These results provide intuition for the\ninformativeness of k-means (with and without dimensionality reduction) as an\nalgorithm for learning mixture models. We verify the correctness of our\ntheorems using numerical experiments and demonstrate using datasets with\nreduced dimensionality significant speed ups for the time required to perform\nclustering.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 15:41:10 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 06:54:35 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 13:48:52 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Liu", "Zhaoqiang", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "1703.10571", "submitter": "Alex Ter-Sarkisov", "authors": "Aram Ter-Sarkisov and Robert Ross and John Kelleher", "title": "Bootstrapping Labelled Dataset Construction for Cow Tracking and\n  Behavior Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new approach to the long-term tracking of an object\nin a challenging environment. The object is a cow and the environment is an\nenclosure in a cowshed. Some of the key challenges in this domain are a\ncluttered background, low contrast and high similarity between moving objects\nwhich greatly reduces the efficiency of most existing approaches, including\nthose based on background subtraction. Our approach is split into object\nlocalization, instance segmentation, learning and tracking stages. Our solution\nis compared to a range of semi-supervised object tracking algorithms and we\nshow that the performance is strong and well suited to subsequent analysis. We\npresent our solution as a first step towards broader tracking and behavior\nmonitoring for cows in precision agriculture with the ultimate objective of\nearly detection of lameness.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 17:09:39 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Ter-Sarkisov", "Aram", ""], ["Ross", "Robert", ""], ["Kelleher", "John", ""]]}, {"id": "1703.10603", "submitter": "Joseph Gomes", "authors": "Joseph Gomes, Bharath Ramsundar, Evan N. Feinberg, Vijay S. Pande", "title": "Atomic Convolutional Networks for Predicting Protein-Ligand Binding\n  Affinity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical scoring functions based on either molecular force fields or\ncheminformatics descriptors are widely used, in conjunction with molecular\ndocking, during the early stages of drug discovery to predict potency and\nbinding affinity of a drug-like molecule to a given target. These models\nrequire expert-level knowledge of physical chemistry and biology to be encoded\nas hand-tuned parameters or features rather than allowing the underlying model\nto select features in a data-driven procedure. Here, we develop a general\n3-dimensional spatial convolution operation for learning atomic-level chemical\ninteractions directly from atomic coordinates and demonstrate its application\nto structure-based bioactivity prediction. The atomic convolutional neural\nnetwork is trained to predict the experimentally determined binding affinity of\na protein-ligand complex by direct calculation of the energy associated with\nthe complex, protein, and ligand given the crystal structure of the binding\npose. Non-covalent interactions present in the complex that are absent in the\nprotein-ligand sub-structures are identified and the model learns the\ninteraction strength associated with these features. We test our model by\npredicting the binding free energy of a subset of protein-ligand complexes\nfound in the PDBBind dataset and compare with state-of-the-art cheminformatics\nand machine learning-based approaches. We find that all methods achieve\nexperimental accuracy and that atomic convolutional networks either outperform\nor perform competitively with the cheminformatics based methods. Unlike all\nprevious protein-ligand prediction systems, atomic convolutional networks are\nend-to-end and fully-differentiable. They represent a new data-driven,\nphysics-based deep learning model paradigm that offers a strong foundation for\nfuture improvements in structure-based bioactivity prediction.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 17:58:31 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Gomes", "Joseph", ""], ["Ramsundar", "Bharath", ""], ["Feinberg", "Evan N.", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1703.10622", "submitter": "Siyuan Ma", "authors": "Siyuan Ma, Mikhail Belkin", "title": "Diving into the shallows: a computational perspective on large-scale\n  shallow learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we first identify a basic limitation in gradient descent-based\noptimization methods when used in conjunctions with smooth kernels. An analysis\nbased on the spectral properties of the kernel demonstrates that only a\nvanishingly small portion of the function space is reachable after a polynomial\nnumber of gradient descent iterations. This lack of approximating power\ndrastically limits gradient descent for a fixed computational budget leading to\nserious over-regularization/underfitting. The issue is purely algorithmic,\npersisting even in the limit of infinite data.\n  To address this shortcoming in practice, we introduce EigenPro iteration,\nbased on a preconditioning scheme using a small number of approximately\ncomputed eigenvectors. It can also be viewed as learning a new kernel optimized\nfor gradient descent. It turns out that injecting this small (computationally\ninexpensive and SGD-compatible) amount of approximate second-order information\nleads to major improvements in convergence. For large data, this translates\ninto significant performance boost over the standard kernel methods. In\nparticular, we are able to consistently match or improve the state-of-the-art\nresults recently reported in the literature with a small fraction of their\ncomputational budget.\n  Finally, we feel that these results show a need for a broader computational\nperspective on modern large-scale learning to complement more traditional\nstatistical and convergence analyses. In particular, many phenomena of\nlarge-scale high-dimensional inference are best understood in terms of\noptimization on infinite dimensional Hilbert spaces, where standard algorithms\ncan sometimes have properties at odds with finite-dimensional intuition. A\nsystematic analysis concentrating on the approximation power of such algorithms\nwithin a budget of computation may lead to progress both in theory and\npractice.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 18:09:43 GMT"}, {"version": "v2", "created": "Sat, 17 Jun 2017 23:45:25 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Ma", "Siyuan", ""], ["Belkin", "Mikhail", ""]]}, {"id": "1703.10631", "submitter": "Jinkyu Kim", "authors": "Jinkyu Kim and John Canny", "title": "Interpretable Learning for Self-Driving Cars by Visualizing Causal\n  Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural perception and control networks are likely to be a key component\nof self-driving vehicles. These models need to be explainable - they should\nprovide easy-to-interpret rationales for their behavior - so that passengers,\ninsurance companies, law enforcement, developers etc., can understand what\ntriggered a particular behavior. Here we explore the use of visual\nexplanations. These explanations take the form of real-time highlighted regions\nof an image that causally influence the network's output (steering control).\nOur approach is two-stage. In the first stage, we use a visual attention model\nto train a convolution network end-to-end from images to steering angle. The\nattention model highlights image regions that potentially influence the\nnetwork's output. Some of these are true influences, but some are spurious. We\nthen apply a causal filtering step to determine which input regions actually\ninfluence the output. This produces more succinct visual explanations and more\naccurately exposes the network's behavior. We demonstrate the effectiveness of\nour model on three datasets totaling 16 hours of driving. We first show that\ntraining with attention does not degrade the performance of the end-to-end\nnetwork. Then we show that the network causally cues on a variety of features\nthat are used by humans while driving.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 18:37:49 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Kim", "Jinkyu", ""], ["Canny", "John", ""]]}, {"id": "1703.10651", "submitter": "Peter Schulam", "authors": "Peter Schulam and Suchi Saria", "title": "Reliable Decision Support using Counterfactual Models", "comments": "Published in the proceedings of Neural Information Processing Systems\n  (NIPS) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-makers are faced with the challenge of estimating what is likely to\nhappen when they take an action. For instance, if I choose not to treat this\npatient, are they likely to die? Practitioners commonly use supervised learning\nalgorithms to fit predictive models that help decision-makers reason about\nlikely future outcomes, but we show that this approach is unreliable, and\nsometimes even dangerous. The key issue is that supervised learning algorithms\nare highly sensitive to the policy used to choose actions in the training data,\nwhich causes the model to capture relationships that do not generalize. We\npropose using a different learning objective that predicts counterfactuals\ninstead of predicting outcomes under an existing action policy as in supervised\nlearning. To support decision-making in temporal settings, we introduce the\nCounterfactual Gaussian Process (CGP) to predict the counterfactual future\nprogression of continuous-time trajectories under sequences of future actions.\nWe demonstrate the benefits of the CGP on two important decision-support tasks:\nrisk prediction and \"what if?\" reasoning for individualized treatment planning.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 19:51:03 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 18:05:23 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 14:28:13 GMT"}, {"version": "v4", "created": "Thu, 1 Feb 2018 13:40:16 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Schulam", "Peter", ""], ["Saria", "Suchi", ""]]}, {"id": "1703.10663", "submitter": "Vince Grolmusz", "authors": "Balazs Szalkai and Vince Grolmusz", "title": "Near Perfect Protein Multi-Label Classification with Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs) have gained a well-deserved popularity\namong machine learning tools upon their recent successful applications in\nimage- and sound processing and classification problems. ANNs have also been\napplied for predicting the family or function of a protein, knowing its residue\nsequence. Here we present two new ANNs with multi-label classification ability,\nshowing impressive accuracy when classifying protein sequences into 698 UniProt\nfamilies (AUC=99.99%) and 983 Gene Ontology classes (AUC=99.45%).\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 20:25:01 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Szalkai", "Balazs", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1703.10669", "submitter": "Lenz Belzner", "authors": "Lenz Belzner, Thomas Gabor", "title": "QoS-Aware Multi-Armed Bandits", "comments": "Accepted at IEEE Workshop on Quality Assurance for Self-adaptive\n  Self-organising Systems, FAS* 2016", "journal-ref": null, "doi": "10.1109/FAS-W.2016.36", "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by runtime verification of QoS requirements in self-adaptive and\nself-organizing systems that are able to reconfigure their structure and\nbehavior in response to runtime data, we propose a QoS-aware variant of\nThompson sampling for multi-armed bandits. It is applicable in settings where\nQoS satisfaction of an arm has to be ensured with high confidence efficiently,\nrather than finding the optimal arm while minimizing regret. Preliminary\nexperimental results encourage further research in the field of QoS-aware\ndecision making.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 15:01:51 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Belzner", "Lenz", ""], ["Gabor", "Thomas", ""]]}, {"id": "1703.10675", "submitter": "Yangyang Li", "authors": "Yangyang Li and Ruqian Lu", "title": "Applying Ricci Flow to High Dimensional Manifold Learning", "comments": "18 pages, 4 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional manifold learning algorithms often bear an assumption that the\nlocal neighborhood of any point on embedded manifold is roughly equal to the\ntangent space at that point without considering the curvature. The curvature\nindifferent way of manifold processing often makes traditional dimension\nreduction poorly neighborhood preserving. To overcome this drawback we propose\na new algorithm called RF-ML to perform an operation on the manifold with help\nof Ricci flow before reducing the dimension of manifold.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 07:27:04 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 08:01:52 GMT"}, {"version": "v3", "created": "Tue, 11 Apr 2017 00:46:25 GMT"}, {"version": "v4", "created": "Thu, 16 Nov 2017 02:34:20 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Li", "Yangyang", ""], ["Lu", "Ruqian", ""]]}, {"id": "1703.10717", "submitter": "David Berthelot", "authors": "David Berthelot, Thomas Schumm, Luke Metz", "title": "BEGAN: Boundary Equilibrium Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new equilibrium enforcing method paired with a loss derived from\nthe Wasserstein distance for training auto-encoder based Generative Adversarial\nNetworks. This method balances the generator and discriminator during training.\nAdditionally, it provides a new approximate convergence measure, fast and\nstable training and high visual quality. We also derive a way of controlling\nthe trade-off between image diversity and visual quality. We focus on the image\ngeneration task, setting a new milestone in visual quality, even at higher\nresolutions. This is achieved while using a relatively simple model\narchitecture and a standard training procedure.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 00:13:33 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2017 22:42:24 GMT"}, {"version": "v3", "created": "Thu, 18 May 2017 23:54:04 GMT"}, {"version": "v4", "created": "Wed, 31 May 2017 19:05:58 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Berthelot", "David", ""], ["Schumm", "Thomas", ""], ["Metz", "Luke", ""]]}, {"id": "1703.10740", "submitter": "Morteza Ashraphijuo", "authors": "Morteza Ashraphijuo, Xiaodong Wang", "title": "Fundamental Conditions for Low-CP-Rank Tensor Completion", "comments": "arXiv admin note: text overlap with arXiv:1703.07698", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of low canonical polyadic (CP) rank tensor\ncompletion. A completion is a tensor whose entries agree with the observed\nentries and its rank matches the given CP rank. We analyze the manifold\nstructure corresponding to the tensors with the given rank and define a set of\npolynomials based on the sampling pattern and CP decomposition. Then, we show\nthat finite completability of the sampled tensor is equivalent to having a\ncertain number of algebraically independent polynomials among the defined\npolynomials. Our proposed approach results in characterizing the maximum number\nof algebraically independent polynomials in terms of a simple geometric\nstructure of the sampling pattern, and therefore we obtain the deterministic\nnecessary and sufficient condition on the sampling pattern for finite\ncompletability of the sampled tensor. Moreover, assuming that the entries of\nthe tensor are sampled independently with probability $p$ and using the\nmentioned deterministic analysis, we propose a combinatorial method to derive a\nlower bound on the sampling probability $p$, or equivalently, the number of\nsampled entries that guarantees finite completability with high probability. We\nalso show that the existing result for the matrix completion problem can be\nused to obtain a loose lower bound on the sampling probability $p$. In\naddition, we obtain deterministic and probabilistic conditions for unique\ncompletability. It is seen that the number of samples required for finite or\nunique completability obtained by the proposed analysis on the CP manifold is\norders-of-magnitude lower than that is obtained by the existing analysis on the\nGrassmannian manifold.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 03:21:32 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Ashraphijuo", "Morteza", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1703.10757", "submitter": "Zhiguang Wang", "authors": "Zhiguang Wang, Jianbo Yang", "title": "Diabetic Retinopathy Detection via Deep Convolutional Networks for\n  Discriminative Localization and Visual Explanation", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed a deep learning method for interpretable diabetic retinopathy\n(DR) detection. The visual-interpretable feature of the proposed method is\nachieved by adding the regression activation map (RAM) after the global\naveraging pooling layer of the convolutional networks (CNN). With RAM, the\nproposed model can localize the discriminative regions of an retina image to\nshow the specific region of interest in terms of its severity level. We believe\nthis advantage of the proposed deep learning model is highly desired for DR\ndetection because in practice, users are not only interested with high\nprediction performance, but also keen to understand the insights of DR\ndetection and why the adopted learning model works. In the experiments\nconducted on a large scale of retina image dataset, we show that the proposed\nCNN model can achieve high performance on DR detection compared with the\nstate-of-the-art while achieving the merits of providing the RAM to highlight\nthe salient regions of the input image.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 05:10:56 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 16:44:23 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 22:05:07 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Wang", "Zhiguang", ""], ["Yang", "Jianbo", ""]]}, {"id": "1703.10887", "submitter": "Dorian Cazau", "authors": "Cazau Dorian, Riwal Lefort, Julien Bonnel, Jean-Luc Zarader and\n  Olivier Adam", "title": "Bi-class classification of humpback whale sound units against complex\n  background noise with Deep Convolution Neural Network", "comments": "arXiv admin note: text overlap with arXiv:1702.02741 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically detecting sound units of humpback whales in complex\ntime-varying background noises is a current challenge for scientists. In this\npaper, we explore the applicability of Convolution Neural Network (CNN) method\nfor this task. In the evaluation stage, we present 6 bi-class classification\nexperimentations of whale sound detection against different background noise\ntypes (e.g., rain, wind). In comparison to classical FFT-based representation\nlike spectrograms, we showed that the use of image-based pretrained CNN\nfeatures brought higher performance to classify whale sounds and background\nnoise.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 13:11:06 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Dorian", "Cazau", ""], ["Lefort", "Riwal", ""], ["Bonnel", "Julien", ""], ["Zarader", "Jean-Luc", ""], ["Adam", "Olivier", ""]]}, {"id": "1703.10927", "submitter": "Duc Nguyen", "authors": "Bao Wang, Zhixiong Zhao, Duc D. Nguyen, Guo-Wei Wei", "title": "Feature functional theory - binding predictor (FFT-BP) for the blind\n  prediction of binding free energies", "comments": "25 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a feature functional theory - binding predictor (FFT-BP) for the\nprotein-ligand binding affinity prediction. The underpinning assumptions of\nFFT-BP are as follows: i) representability: there exists a microscopic feature\nvector that can uniquely characterize and distinguish one protein-ligand\ncomplex from another; ii) feature-function relationship: the macroscopic\nfeatures, including binding free energy, of a complex is a functional of\nmicroscopic feature vectors; and iii) similarity: molecules with similar\nmicroscopic features have similar macroscopic features, such as binding\naffinity. Physical models, such as implicit solvent models and quantum theory,\nare utilized to extract microscopic features, while machine learning algorithms\nare employed to rank the similarity among protein-ligand complexes. A large\nvariety of numerical validations and tests confirms the accuracy and robustness\nof the proposed FFT-BP model. The root mean square errors (RMSEs) of FFT-BP\nblind predictions of a benchmark set of 100 complexes, the PDBBind v2007 core\nset of 195 complexes and the PDBBind v2015 core set of 195 complexes are 1.99,\n2.02 and 1.92 kcal/mol, respectively. Their corresponding Pearson correlation\ncoefficients are 0.75, 0.80, and 0.78, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 15:00:07 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Wang", "Bao", ""], ["Zhao", "Zhixiong", ""], ["Nguyen", "Duc D.", ""], ["Wei", "Guo-Wei", ""]]}, {"id": "1703.10931", "submitter": "Xingxing Zhang", "authors": "Xingxing Zhang, Mirella Lapata", "title": "Sentence Simplification with Deep Reinforcement Learning", "comments": "to appear in EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence simplification aims to make sentences easier to read and understand.\nMost recent approaches draw on insights from machine translation to learn\nsimplification rewrites from monolingual corpora of complex and simple\nsentences. We address the simplification problem with an encoder-decoder model\ncoupled with a deep reinforcement learning framework. Our model, which we call\n{\\sc Dress} (as shorthand for {\\bf D}eep {\\bf RE}inforcement {\\bf S}entence\n{\\bf S}implification), explores the space of possible simplifications while\nlearning to optimize a reward function that encourages outputs which are\nsimple, fluent, and preserve the meaning of the input. Experiments on three\ndatasets demonstrate that our model outperforms competitive simplification\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 15:05:45 GMT"}, {"version": "v2", "created": "Sun, 16 Jul 2017 02:28:14 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Zhang", "Xingxing", ""], ["Lapata", "Mirella", ""]]}, {"id": "1703.10951", "submitter": "Kedi Wu", "authors": "Kedi Wu, Guo-Wei Wei", "title": "Comparison of multi-task convolutional neural network (MT-CNN) and a few\n  other methods for toxicity prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toxicity analysis and prediction are of paramount importance to human health\nand environmental protection. Existing computational methods are built from a\nwide variety of descriptors and regressors, which makes their performance\nanalysis difficult. For example, deep neural network (DNN), a successful\napproach in many occasions, acts like a black box and offers little conceptual\nelegance or physical understanding. The present work constructs a common set of\nmicroscopic descriptors based on established physical models for charges,\nsurface areas and free energies to assess the performance of multi-task\nconvolutional neural network (MT-CNN) architectures and a few other approaches,\nincluding random forest (RF) and gradient boosting decision tree (GBDT), on an\nequal footing. Comparison is also given to convolutional neural network (CNN)\nand non-convolutional deep neural network (DNN) algorithms. Four benchmark\ntoxicity data sets (i.e., endpoints) are used to evaluate various approaches.\nExtensive numerical studies indicate that the present MT-CNN architecture is\nable to outperform the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 15:40:24 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Wu", "Kedi", ""], ["Wei", "Guo-Wei", ""]]}, {"id": "1703.11000", "submitter": "Alex Lee", "authors": "Alex X. Lee, Sergey Levine, Pieter Abbeel", "title": "Learning Visual Servoing with Deep Features and Fitted Q-Iteration", "comments": "ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual servoing involves choosing actions that move a robot in response to\nobservations from a camera, in order to reach a goal configuration in the\nworld. Standard visual servoing approaches typically rely on manually designed\nfeatures and analytical dynamics models, which limits their generalization\ncapability and often requires extensive application-specific feature and model\nengineering. In this work, we study how learned visual features, learned\npredictive dynamics models, and reinforcement learning can be combined to learn\nvisual servoing mechanisms. We focus on target following, with the goal of\ndesigning algorithms that can learn a visual servo using low amounts of data of\nthe target in question, to enable quick adaptation to new targets. Our approach\nis based on servoing the camera in the space of learned visual features, rather\nthan image pixels or manually-designed keypoints. We demonstrate that standard\ndeep features, in our case taken from a model trained for object\nclassification, can be used together with a bilinear predictive model to learn\nan effective visual servo that is robust to visual variation, changes in\nviewing angle and appearance, and occlusions. A key component of our approach\nis to use a sample-efficient fitted Q-iteration algorithm to learn which\nfeatures are best suited for the task at hand. We show that we can learn an\neffective visual servo on a complex synthetic car following benchmark using\njust 20 training trajectory samples for reinforcement learning. We demonstrate\nsubstantial improvement over a conventional approach based on image pixels or\nhand-designed keypoints, and we show an improvement in sample-efficiency of\nmore than two orders of magnitude over standard model-free deep reinforcement\nlearning algorithms. Videos are available at\nhttp://rll.berkeley.edu/visual_servoing .\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 17:45:53 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 00:26:55 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Lee", "Alex X.", ""], ["Levine", "Sergey", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1703.11008", "submitter": "Daniel Roy", "authors": "Gintare Karolina Dziugaite, Daniel M. Roy", "title": "Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural\n  Networks with Many More Parameters than Training Data", "comments": "14 pages, 1 table, 2 figures. Corresponds with UAI camera ready and\n  supplement. Includes additional references and related experiments", "journal-ref": "Proceedings of the Thirty-Third Conference on Uncertainty in\n  Artificial Intelligence, UAI 2016, August 11--15, 2017, Sydney, NSW,\n  Australia", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the defining properties of deep learning is that models are chosen to\nhave many more parameters than available training data. In light of this\ncapacity for overfitting, it is remarkable that simple algorithms like SGD\nreliably return solutions with low test error. One roadblock to explaining\nthese phenomena in terms of implicit regularization, structural properties of\nthe solution, and/or easiness of the data is that many learning bounds are\nquantitatively vacuous when applied to networks learned by SGD in this \"deep\nlearning\" regime. Logically, in order to explain generalization, we need\nnonvacuous bounds. We return to an idea by Langford and Caruana (2001), who\nused PAC-Bayes bounds to compute nonvacuous numerical bounds on generalization\nerror for stochastic two-layer two-hidden-unit neural networks via a\nsensitivity analysis. By optimizing the PAC-Bayes bound directly, we are able\nto extend their approach and obtain nonvacuous generalization bounds for deep\nstochastic neural network classifiers with millions of parameters trained on\nonly tens of thousands of examples. We connect our findings to recent and old\nwork on flat minima and MDL-based explanations of generalization.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 17:56:41 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 03:39:56 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Dziugaite", "Gintare Karolina", ""], ["Roy", "Daniel M.", ""]]}]