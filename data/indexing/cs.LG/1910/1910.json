[{"id": "1910.00004", "submitter": "Carl Yang", "authors": "Carl Yang, Yichen Feng, Pan Li, Yu Shi, Jiawei Han", "title": "Meta-Graph Based HIN Spectral Embedding: Methods, Analyses, and Insights", "comments": "10 pages, published at ICDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to study the utility of different meta-graphs, as\nwell as how to simultaneously leverage multiple meta-graphs for HIN embedding\nin an unsupervised manner. Motivated by prolific research on homogeneous\nnetworks, especially spectral graph theory, we firstly conduct a systematic\nempirical study on the spectrum and embedding quality of different meta-graphs\non multiple HINs, which leads to an efficient method of meta-graph assessment.\nIt also helps us to gain valuable insight into the higher-order organization of\nHINs and indicates a practical way of selecting useful embedding dimensions.\nFurther, we explore the challenges of combining multiple meta-graphs to capture\nthe multi-dimensional semantics in HIN through reasoning from mathematical\ngeometry and arrive at an embedding compression method of autoencoder with\n$\\ell_{2,1}$-loss, which finds the most informative meta-graphs and embeddings\nin an end-to-end unsupervised manner. Finally, empirical analysis suggests a\nunified workflow to close the gap between our meta-graph assessment and\ncombination methods. To the best of our knowledge, this is the first research\neffort to provide rich theoretical and empirical analyses on the utility of\nmeta-graphs and their combinations, especially regarding HIN embedding.\nExtensive experimental comparisons with various state-of-the-art neural network\nbased embedding methods on multiple real-world HINs demonstrate the\neffectiveness and efficiency of our framework in finding useful meta-graphs and\ngenerating high-quality HIN embeddings.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 01:28:58 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Yang", "Carl", ""], ["Feng", "Yichen", ""], ["Li", "Pan", ""], ["Shi", "Yu", ""], ["Han", "Jiawei", ""]]}, {"id": "1910.00005", "submitter": "Carl Yang", "authors": "Carl Yang, Jieyu Zhang, Jiawei Han", "title": "Neural Embedding Propagation on Heterogeneous Networks", "comments": "11 pages, published at ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is one of the most important problems in machine learning. To\naddress label scarcity, semi-supervised learning (SSL) has been intensively\nstudied over the past two decades, which mainly leverages data affinity modeled\nby networks. Label propagation (LP), however, as the most popular SSL\ntechnique, mostly only works on homogeneous networks with single-typed simple\ninteractions. In this work, we focus on the more general and powerful\nheterogeneous networks, which accommodate multi-typed objects and links, and\nthus endure multi-typed complex interactions. Specifically, we propose\n\\textit{neural embedding propagation} (NEP), which leverages distributed\nembeddings to represent objects and dynamically composed modular networks to\nmodel their complex interactions. While generalizing LP as a simple instance,\nNEP is far more powerful in its natural awareness of different types of objects\nand links, and the ability to automatically capture their important interaction\npatterns. Further, we develop a series of efficient training strategies for\nNEP, leading to its easy deployment on real-world heterogeneous networks with\nmillions of objects. With extensive experiments on three datasets, we\ncomprehensively demonstrate the effectiveness, efficiency, and robustness of\nNEP compared with state-of-the-art network embedding and SSL algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 01:36:41 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Yang", "Carl", ""], ["Zhang", "Jieyu", ""], ["Han", "Jiawei", ""]]}, {"id": "1910.00019", "submitter": "Sho Yaida", "authors": "Sho Yaida", "title": "Non-Gaussian processes and neural networks at finite widths", "comments": "33 pages, 3 figures; v2: final version accepted at MSML 2020, with\n  some clarification on the connection to renormalization-group flow", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are ubiquitous in nature and engineering. A case in point\nis a class of neural networks in the infinite-width limit, whose priors\ncorrespond to Gaussian processes. Here we perturbatively extend this\ncorrespondence to finite-width neural networks, yielding non-Gaussian processes\nas priors. The methodology developed herein allows us to track the flow of\npreactivation distributions by progressively integrating out random variables\nfrom lower to higher layers, reminiscent of renormalization-group flow. We\nfurther develop a perturbative procedure to perform Bayesian inference with\nweakly non-Gaussian priors.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 18:00:02 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 22:50:38 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Yaida", "Sho", ""]]}, {"id": "1910.00024", "submitter": "Shuohui Li", "authors": "Shuo-Hui Li, Chen-Xiao Dong, Linfeng Zhang, and Lei Wang", "title": "Neural Canonical Transformation with Symplectic Flows", "comments": "Main text: 9 pages, 8 figures. Supplement: 2 page, 1 figure. GitHub\n  link: https://github.com/li012589/neuralCT", "journal-ref": "Phys. Rev. X 10, 021020 (2020)", "doi": "10.1103/PhysRevX.10.021020", "report-no": null, "categories": "cond-mat.stat-mech cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical transformation plays a fundamental role in simplifying and solving\nclassical Hamiltonian systems. We construct flexible and powerful canonical\ntransformations as generative models using symplectic neural networks. The\nmodel transforms physical variables towards a latent representation with an\nindependent harmonic oscillator Hamiltonian. Correspondingly, the phase space\ndensity of the physical system flows towards a factorized Gaussian distribution\nin the latent space. Since the canonical transformation preserves the\nHamiltonian evolution, the model captures nonlinear collective modes in the\nlearned latent representation. We present an efficient implementation of\nsymplectic neural coordinate transformations and two ways to train the model.\nThe variational free energy calculation is based on the analytical form of\nphysical Hamiltonian. While the phase space density estimation only requires\nsamples in the coordinate space for separable Hamiltonians. We demonstrate\nappealing features of neural canonical transformation using toy problems\nincluding two-dimensional ring potential and harmonic chain. Finally, we apply\nthe approach to real-world problems such as identifying slow collective modes\nin alanine dipeptide and conceptual compression of the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 18:00:05 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 14:59:18 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 15:16:17 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Li", "Shuo-Hui", ""], ["Dong", "Chen-Xiao", ""], ["Zhang", "Linfeng", ""], ["Wang", "Lei", ""]]}, {"id": "1910.00054", "submitter": "Giannis Karamanolakis", "authors": "Giannis Karamanolakis, Daniel Hsu, Luis Gravano", "title": "Weakly Supervised Attention Networks for Fine-Grained Opinion Mining and\n  Public Health", "comments": "Accepted for the 5th Workshop on Noisy User-generated Text (W-NUT\n  2019), held in conjunction with EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many review classification applications, a fine-grained analysis of the\nreviews is desirable, because different segments (e.g., sentences) of a review\nmay focus on different aspects of the entity in question. However, training\nsupervised models for segment-level classification requires segment labels,\nwhich may be more difficult or expensive to obtain than review labels. In this\npaper, we employ Multiple Instance Learning (MIL) and use only weak supervision\nin the form of a single label per review. First, we show that when\ninappropriate MIL aggregation functions are used, then MIL-based networks are\noutperformed by simpler baselines. Second, we propose a new aggregation\nfunction based on the sigmoid attention mechanism and show that our proposed\nmodel outperforms the state-of-the-art models for segment-level sentiment\nclassification (by up to 9.8% in F1). Finally, we highlight the importance of\nfine-grained predictions in an important public-health application: finding\nactionable reports of foodborne illness. We show that our model achieves 48.6%\nhigher recall compared to previous models, thus increasing the chance of\nidentifying previously unknown foodborne outbreaks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 18:40:59 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Karamanolakis", "Giannis", ""], ["Hsu", "Daniel", ""], ["Gravano", "Luis", ""]]}, {"id": "1910.00062", "submitter": "Georgi Nalbantov", "authors": "Georgi Nalbantov, Svetoslav Ivanov", "title": "Tutorial on Implied Posterior Probability for SVMs", "comments": "20 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implied posterior probability of a given model (say, Support Vector Machines\n(SVM)) at a point $\\bf{x}$ is an estimate of the class posterior probability\npertaining to the class of functions of the model applied to a given dataset.\nIt can be regarded as a score (or estimate) for the true posterior probability,\nwhich can then be calibrated/mapped onto expected (non-implied by the model)\nposterior probability implied by the underlying functions, which have generated\nthe data. In this tutorial we discuss how to compute implied posterior\nprobabilities of SVMs for the binary classification case as well as how to\ncalibrate them via a standard method of isotonic regression.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 19:13:14 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Nalbantov", "Georgi", ""], ["Ivanov", "Svetoslav", ""]]}, {"id": "1910.00067", "submitter": "Cory Stephenson", "authors": "Cory Stephenson, Gokce Keskin, Anil Thomas, Oguz H. Elibol", "title": "Semi-supervised voice conversion with amortized variational inference", "comments": "Accepted for publication at Interspeech 2019", "journal-ref": "Proc. Interspeech 2019 (2019): 729-733", "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a semi-supervised approach to the voice conversion\nproblem, in which speech from a source speaker is converted into speech of a\ntarget speaker. The proposed method makes use of both parallel and non-parallel\nutterances from the source and target simultaneously during training. This\napproach can be used to extend existing parallel data voice conversion systems\nsuch that they can be trained with semi-supervision. We show that incorporating\nsemi-supervision improves the voice conversion performance compared to fully\nsupervised training when the number of parallel utterances is limited as in\nmany practical applications. Additionally, we find that increasing the number\nnon-parallel utterances used in training continues to improve performance when\nthe amount of parallel training data is held constant.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 19:39:57 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Stephenson", "Cory", ""], ["Keskin", "Gokce", ""], ["Thomas", "Anil", ""], ["Elibol", "Oguz H.", ""]]}, {"id": "1910.00069", "submitter": "Robert Bamler", "authors": "Robert Bamler, Cheng Zhang, Manfred Opper, Stephan Mandt", "title": "Tightening Bounds for Variational Inference by Revisiting Perturbation\n  Theory", "comments": "To appear in Journal of Statistical Mechanics: Theory and Experiment\n  (JSTAT), 2019", "journal-ref": null, "doi": "10.1088/1742-5468/ab43d3", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference has become one of the most widely used methods in\nlatent variable modeling. In its basic form, variational inference employs a\nfully factorized variational distribution and minimizes its KL divergence to\nthe posterior. As the minimization can only be carried out approximately, this\napproximation induces a bias. In this paper, we revisit perturbation theory as\na powerful way of improving the variational approximation. Perturbation theory\nrelies on a form of Taylor expansion of the log marginal likelihood, vaguely in\nterms of the log ratio of the true posterior and its variational approximation.\nWhile first order terms give the classical variational bound, higher-order\nterms yield corrections that tighten it. However, traditional perturbation\ntheory does not provide a lower bound, making it inapt for stochastic\noptimization. In this paper, we present a similar yet alternative way of\nderiving corrections to the ELBO that resemble perturbation theory, but that\nresult in a valid bound. We show in experiments on Gaussian Processes and\nVariational Autoencoders that the new bounds are more mass covering, and that\nthe resulting posterior covariances are closer to the true posterior and lead\nto higher likelihoods on held-out data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 19:44:18 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Bamler", "Robert", ""], ["Zhang", "Cheng", ""], ["Opper", "Manfred", ""], ["Mandt", "Stephan", ""]]}, {"id": "1910.00078", "submitter": "Jehandad Khan", "authors": "Jehandad Khan, Paul Fultz, Artem Tamazov, Daniel Lowell, Chao Liu,\n  Michael Melesse, Murali Nandhimandalam, Kamil Nasyrov, Ilya Perminov, Tejash\n  Shah, Vasilii Filippov, Jing Zhang, Jing Zhou, Bragadeesh Natarajan, Mayank\n  Daga", "title": "MIOpen: An Open Source Library For Deep Learning Primitives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has established itself to be a common occurrence in the\nbusiness lexicon. The unprecedented success of deep learning in recent years\ncan be attributed to: abundance of data, availability of gargantuan compute\ncapabilities offered by GPUs, and adoption of open-source philosophy by the\nresearchers and industry. Deep neural networks can be decomposed into a series\nof different operators. MIOpen, AMD's open-source deep learning primitives\nlibrary for GPUs, provides highly optimized implementations of such operators,\nshielding researchers from internal implementation details and hence,\naccelerating the time to discovery. This paper introduces MIOpen and provides\ndetails about the internal workings of the library and supported features.\nMIOpen innovates on several fronts, such as implementing fusion to optimize for\nmemory bandwidth and GPU launch overheads, providing an auto-tuning\ninfrastructure to overcome the large design space of problem configurations,\nand implementing different algorithms to optimize convolutions for different\nfilter and input sizes. MIOpen is one of the first libraries to publicly\nsupport the bfloat16 data-type for convolutions, allowing efficient training at\nlower precision without the loss of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 20:07:36 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Khan", "Jehandad", ""], ["Fultz", "Paul", ""], ["Tamazov", "Artem", ""], ["Lowell", "Daniel", ""], ["Liu", "Chao", ""], ["Melesse", "Michael", ""], ["Nandhimandalam", "Murali", ""], ["Nasyrov", "Kamil", ""], ["Perminov", "Ilya", ""], ["Shah", "Tejash", ""], ["Filippov", "Vasilii", ""], ["Zhang", "Jing", ""], ["Zhou", "Jing", ""], ["Natarajan", "Bragadeesh", ""], ["Daga", "Mayank", ""]]}, {"id": "1910.00084", "submitter": "Gengchen Mai", "authors": "Gengchen Mai, Krzysztof Janowicz, Bo Yan, Rui Zhu, Ling Cai, Ni Lao", "title": "Contextual Graph Attention for Answering Logical Queries over Incomplete\n  Knowledge Graphs", "comments": "8 pages, 3 figures, camera ready version of article accepted to K-CAP\n  2019, Marina del Rey, California, United States", "journal-ref": "K-CAP 2019, Nov. 19 - 21, 2019, Marina del Rey, CA, USA", "doi": "10.1145/3360901.3364432", "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several studies have explored methods for using KG embedding to\nanswer logical queries. These approaches either treat embedding learning and\nquery answering as two separated learning tasks, or fail to deal with the\nvariability of contributions from different query paths. We proposed to\nleverage a graph attention mechanism to handle the unequal contribution of\ndifferent query paths. However, commonly used graph attention assumes that the\ncenter node embedding is provided, which is unavailable in this task since the\ncenter node is to be predicted. To solve this problem we propose a multi-head\nattention-based end-to-end logical query answering model, called Contextual\nGraph Attention model(CGA), which uses an initial neighborhood aggregation\nlayer to generate the center embedding, and the whole model is trained jointly\non the original KG structure as well as the sampled query-answer pairs. We also\nintroduce two new datasets, DB18 and WikiGeo19, which are rather large in size\ncompared to the existing datasets and contain many more relation types, and use\nthem to evaluate the performance of the proposed model. Our result shows that\nthe proposed CGA with fewer learnable parameters consistently outperforms the\nbaseline models on both datasets as well as Bio dataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 20:20:48 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Yan", "Bo", ""], ["Zhu", "Rui", ""], ["Cai", "Ling", ""], ["Lao", "Ni", ""]]}, {"id": "1910.00091", "submitter": "Wendelin B\\\"ohmer", "authors": "Wendelin B\\\"ohmer, Vitaly Kurin, Shimon Whiteson", "title": "Deep Coordination Graphs", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the deep coordination graph (DCG) for collaborative\nmulti-agent reinforcement learning. DCG strikes a flexible trade-off between\nrepresentational capacity and generalization by factoring the joint value\nfunction of all agents according to a coordination graph into payoffs between\npairs of agents. The value can be maximized by local message passing along the\ngraph, which allows training of the value function end-to-end with Q-learning.\nPayoff functions are approximated with deep neural networks that employ\nparameter sharing and low-rank approximations to significantly improve sample\nefficiency. We show that DCG can solve predator-prey tasks that highlight the\nrelative overgeneralization pathology, as well as challenging StarCraft II\nmicromanagement tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 17:25:41 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 16:13:15 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 16:12:47 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 17:28:04 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["B\u00f6hmer", "Wendelin", ""], ["Kurin", "Vitaly", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1910.00099", "submitter": "Wenhao Ding", "authors": "Wenhao Ding, Mengdi Xu, Ding Zhao", "title": "CMTS: Conditional Multiple Trajectory Synthesizer for Generating\n  Safety-critical Driving Scenarios", "comments": "Submitted to ICRA 2020, 8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Naturalistic driving trajectories are crucial for the performance of\nautonomous driving algorithms. However, most of the data is collected in safe\nscenarios leading to the duplication of trajectories which are easy to be\nhandled by currently developed algorithms. When considering safety, testing\nalgorithms in near-miss scenarios that rarely show up in off-the-shelf datasets\nis a vital part of the evaluation. As a remedy, we propose a near-miss data\nsynthesizing framework based on Variational Bayesian methods and term it as\nConditional Multiple Trajectory Synthesizer (CMTS). We leverage a generative\nmodel conditioned on road maps to bridge safe and collision driving data by\nrepresenting their distribution in the latent space. By sampling from the\nnear-miss distribution, we can synthesize safety-critical data crucial for\nunderstanding traffic scenarios but not shown in neither the original dataset\nnor the collision dataset. Our experimental results demonstrate that the\naugmented dataset covers more kinds of driving scenarios, especially the\nnear-miss ones, which help improve the trajectory prediction accuracy and the\ncapability of dealing with risky driving scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 13:43:14 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 18:03:36 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Ding", "Wenhao", ""], ["Xu", "Mengdi", ""], ["Zhao", "Ding", ""]]}, {"id": "1910.00100", "submitter": "Jiatong Li", "authors": "Jiatong Li, Ricardo Guerrero, Vladimir Pavlovic", "title": "Deep Cooking: Predicting Relative Food Ingredient Amounts from Images", "comments": null, "journal-ref": null, "doi": "10.1145/3347448.3357164", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the novel problem of not only predicting ingredients\nfrom a food image, but also predicting the relative amounts of the detected\ningredients. We propose two prediction-based models using deep learning that\noutput sparse and dense predictions, coupled with important semi-automatic\nmulti-database integrative data pre-processing, to solve the problem.\nExperiments on a dataset of recipes collected from the Internet show the models\ngenerate encouraging experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 19:49:28 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Li", "Jiatong", ""], ["Guerrero", "Ricardo", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "1910.00101", "submitter": "Maymoonah Toubeh", "authors": "Maymoonah Toubeh and Pratap Tokekar", "title": "Risk-Aware Planning by Confidence Estimation using Deep Learning-Based\n  Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes the use of Bayesian approximations of uncertainty from\ndeep learning in a robot planner, showing that this produces more cautious\nactions in safety-critical scenarios. The case study investigated is motivated\nby a setup where an aerial robot acts as a \"scout\" for a ground robot. This is\nuseful when the below area is unknown or dangerous, with applications in space\nexploration, military, or search-and-rescue. Images taken from the aerial view\nare used to provide a less obstructed map to guide the navigation of the robot\non the ground. Experiments are conducted using a deep learning semantic image\nsegmentation, followed by a path planner based on the resulting cost map, to\nprovide an empirical analysis of the proposed method. A comparison with similar\napproaches is presented to portray the usefulness of certain techniques, or\nvariations within a technique, in similar experimental settings. The method is\nanalyzed to assess the impact of variations in the uncertainty extraction, as\nwell as the absence of an uncertainty metric, on the overall system with the\nuse of a defined metric which measures surprise to the planner. The analysis is\nperformed on multiple datasets, showing a similar trend of lower surprise when\nuncertainty information is incorporated in the planning, given threshold values\nof the hyperparameters in the uncertainty extraction have been met. We find\nthat taking uncertainty into account leads to paths that could be 18% less\nrisky on an average.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:20:41 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Toubeh", "Maymoonah", ""], ["Tokekar", "Pratap", ""]]}, {"id": "1910.00105", "submitter": "Kuno Kim", "authors": "Kuno Kim, Yihong Gu, Jiaming Song, Shengjia Zhao, Stefano Ermon", "title": "Domain Adaptive Imitation Learning", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the question of how to imitate tasks across domains with\ndiscrepancies such as embodiment, viewpoint, and dynamics mismatch. Many prior\nworks require paired, aligned demonstrations and an additional RL step that\nrequires environment interactions. However, paired, aligned demonstrations are\nseldom obtainable and RL procedures are expensive. We formalize the Domain\nAdaptive Imitation Learning (DAIL) problem, which is a unified framework for\nimitation learning in the presence of viewpoint, embodiment, and dynamics\nmismatch. Informally, DAIL is the process of learning how to perform a task\noptimally, given demonstrations of the task in a distinct domain. We propose a\ntwo step approach to DAIL: alignment followed by adaptation. In the alignment\nstep we execute a novel unsupervised MDP alignment algorithm, Generative\nAdversarial MDP Alignment (GAMA), to learn state and action correspondences\nfrom \\emph{unpaired, unaligned} demonstrations. In the adaptation step we\nleverage the correspondences to zero-shot imitate tasks across domains. To\ndescribe when DAIL is feasible via alignment and adaptation, we introduce a\ntheory of MDP alignability. We experimentally evaluate GAMA against baselines\nin embodiment, viewpoint, and dynamics mismatch scenarios where aligned\ndemonstrations don't exist and show the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 20:58:55 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 18:36:20 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Kim", "Kuno", ""], ["Gu", "Yihong", ""], ["Song", "Jiaming", ""], ["Zhao", "Shengjia", ""], ["Ermon", "Stefano", ""]]}, {"id": "1910.00110", "submitter": "Benjamin Peherstorfer", "authors": "Zlatko Drma\\v{c} and Benjamin Peherstorfer", "title": "Learning low-dimensional dynamical-system models from noisy\n  frequency-response data with Loewner rational interpolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loewner rational interpolation provides a versatile tool to learn\nlow-dimensional dynamical-system models from frequency-response measurements.\nThis work investigates the robustness of the Loewner approach to noise. The key\nfinding is that if the measurements are polluted with Gaussian noise, then the\nerror due to noise grows at most linearly with the standard deviation with high\nprobability under certain conditions. The analysis gives insights into making\nthe Loewner approach robust against noise via linear transformations and\njudicious selections of measurements. Numerical results demonstrate the linear\ngrowth of the error on benchmark examples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 21:10:43 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 23:20:48 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Drma\u010d", "Zlatko", ""], ["Peherstorfer", "Benjamin", ""]]}, {"id": "1910.00116", "submitter": "Tony Tung", "authors": "Yuanlu Xu, Song-Chun Zhu, Tony Tung", "title": "DenseRaC: Joint 3D Pose and Shape Estimation by Dense Render-and-Compare", "comments": "11 pages, 8 figures, International Conference on Computer Vision\n  (ICCV) 2019, Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DenseRaC, a novel end-to-end framework for jointly estimating 3D\nhuman pose and body shape from a monocular RGB image. Our two-step framework\ntakes the body pixel-to-surface correspondence map (i.e., IUV map) as proxy\nrepresentation and then performs estimation of parameterized human pose and\nshape. Specifically, given an estimated IUV map, we develop a deep neural\nnetwork optimizing 3D body reconstruction losses and further integrating a\nrender-and-compare scheme to minimize differences between the input and the\nrendered output, i.e., dense body landmarks, body part masks, and adversarial\npriors. To boost learning, we further construct a large-scale synthetic dataset\n(MOCA) utilizing web-crawled Mocap sequences, 3D scans and animations. The\ngenerated data covers diversified camera views, human actions and body shapes,\nand is paired with full ground truth. Our model jointly learns to represent the\n3D human body from hybrid datasets, mitigating the problem of unpaired training\ndata. Our experiments show that DenseRaC obtains superior performance against\nstate of the art on public benchmarks of various humanrelated tasks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 21:34:31 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 17:52:02 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Xu", "Yuanlu", ""], ["Zhu", "Song-Chun", ""], ["Tung", "Tony", ""]]}, {"id": "1910.00120", "submitter": "Dimitri Bertsekas", "authors": "Dimitri Bertsekas", "title": "Multiagent Rollout Algorithms and Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider finite and infinite horizon dynamic programming problems, where\nthe control at each stage consists of several distinct decisions, each one made\nby one of several agents. We introduce an approach, whereby at every stage,\neach agent's decision is made by executing a local rollout algorithm that uses\na base policy, together with some coordinating information from the other\nagents. The amount of local computation required at every stage by each agent\nis independent of the number of agents, while the amount of total computation\n(over all agents) grows linearly with the number of agents. By contrast, with\nthe standard rollout algorithm, the amount of total computation grows\nexponentially with the number of agents. Despite the drastic reduction in\nrequired computation, we show that our algorithm has the fundamental cost\nimprovement property of rollout: an improved performance relative to the base\npolicy. We also discuss possibilities to improve further the method's\ncomputational efficiency through limited agent coordination and parallelization\nof the agents' computations. Finally, we explore related approximate policy\niteration algorithms for infinite horizon problems, and we prove that the cost\nimprovement property steers the algorithm towards convergence to an\nagent-by-agent optimal policy.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 21:39:07 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 11:47:13 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 20:55:05 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Bertsekas", "Dimitri", ""]]}, {"id": "1910.00121", "submitter": "Benno Kuckuck", "authors": "Christan Beck, Arnulf Jentzen, Benno Kuckuck", "title": "Full error analysis for the training of deep neural networks", "comments": "53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms have been applied very successfully in recent years\nto a range of problems out of reach for classical solution paradigms.\nNevertheless, there is no completely rigorous mathematical error and\nconvergence analysis which explains the success of deep learning algorithms.\nThe error of a deep learning algorithm can in many situations be decomposed\ninto three parts, the approximation error, the generalization error, and the\noptimization error. In this work we estimate for a certain deep learning\nalgorithm each of these three errors and combine these three error estimates to\nobtain an overall error analysis for the deep learning algorithm under\nconsideration. In particular, we thereby establish convergence with a suitable\nconvergence speed for the overall error of the deep learning algorithm under\nconsideration. Our convergence speed analysis is far from optimal and the\nconvergence speed that we establish is rather slow, increases exponentially in\nthe dimensions, and, in particular, suffers from the curse of dimensionality.\nThe main contribution of this work is, instead, to provide a full error\nanalysis (i) which covers each of the three different sources of errors usually\nemerging in deep learning algorithms and (ii) which merges these three sources\nof errors into one overall error estimate for the considered deep learning\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 21:43:45 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 11:48:59 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Beck", "Christan", ""], ["Jentzen", "Arnulf", ""], ["Kuckuck", "Benno", ""]]}, {"id": "1910.00125", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor, Pratik Chaudhari, Stefano Soatto, Alexander J. Smola", "title": "Meta-Q-Learning", "comments": "ICLR 2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Meta-Q-Learning (MQL), a new off-policy algorithm for\nmeta-Reinforcement Learning (meta-RL). MQL builds upon three simple ideas.\nFirst, we show that Q-learning is competitive with state-of-the-art meta-RL\nalgorithms if given access to a context variable that is a representation of\nthe past trajectory. Second, a multi-task objective to maximize the average\nreward across the training tasks is an effective method to meta-train RL\npolicies. Third, past data from the meta-training replay buffer can be recycled\nto adapt the policy on a new task using off-policy updates. MQL draws upon\nideas in propensity estimation to do so and thereby amplifies the amount of\navailable data for adaptation. Experiments on standard continuous-control\nbenchmarks suggest that MQL compares favorably with the state of the art in\nmeta-RL.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 21:50:32 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 10:38:40 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Fakoor", "Rasool", ""], ["Chaudhari", "Pratik", ""], ["Soatto", "Stefano", ""], ["Smola", "Alexander J.", ""]]}, {"id": "1910.00152", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Nhat Ho, Marco Cuturi and Michael I. Jordan", "title": "On the Complexity of Approximating Multimarginal Optimal Transport", "comments": "Improve the paper significantly; 39 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of approximating the multimarginal optimal transport\n(MOT) distance, a generalization of the classical optimal transport distance,\nconsidered here between $m$ discrete probability distributions supported each\non $n$ support points. First, we show that the standard linear programming (LP)\nrepresentation of the MOT problem is not a minimum-cost flow problem when $m\n\\geq 3$. This negative result implies that some combinatorial algorithms, e.g.,\nnetwork simplex method, are not suitable for approximating the MOT problem,\nwhile the worst-case complexity bound for the deterministic interior-point\nalgorithm remains a quantity of $\\tilde{O}(n^{3m})$. We then propose two simple\nand \\textit{deterministic} algorithms for approximating the MOT problem. The\nfirst algorithm, which we refer to as \\textit{multimarginal Sinkhorn}\nalgorithm, is a provably efficient multimarginal generalization of the Sinkhorn\nalgorithm. We show that it achieves a complexity bound of\n$\\tilde{O}(m^3n^m\\varepsilon^{-2})$ for a tolerance $\\varepsilon \\in (0, 1)$.\nThis provides a first \\textit{near-linear time} complexity bound guarantee for\napproximating the MOT problem and matches the best known complexity bound for\nthe Sinkhorn algorithm in the classical OT setting when $m = 2$. The second\nalgorithm, which we refer to as \\textit{accelerated multimarginal Sinkhorn}\nalgorithm, achieves the acceleration by incorporating an estimate sequence and\nthe complexity bound is $\\tilde{O}(m^3n^{m+1/3}\\varepsilon^{-4/3})$. This bound\nis better than that of the first algorithm in terms of $1/\\varepsilon$, and\naccelerated alternating minimization\nalgorithm~\\citep{Tupitsa-2020-Multimarginal} in terms of $n$. Finally, we\ncompare our new algorithms with the commercial LP solver \\textsc{Gurobi}.\nPreliminary results on synthetic data and real images demonstrate the\neffectiveness and efficiency of our algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 23:43:43 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 23:00:46 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Lin", "Tianyi", ""], ["Ho", "Nhat", ""], ["Cuturi", "Marco", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1910.00163", "submitter": "Xiang Lisa Li", "authors": "Xiang Lisa Li and Jason Eisner", "title": "Specializing Word Embeddings (for Parsing) by Information Bottleneck", "comments": "Accepted for publication at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained word embeddings like ELMo and BERT contain rich syntactic and\nsemantic information, resulting in state-of-the-art performance on various\ntasks. We propose a very fast variational information bottleneck (VIB) method\nto nonlinearly compress these embeddings, keeping only the information that\nhelps a discriminative parser. We compress each word embedding to either a\ndiscrete tag or a continuous vector. In the discrete version, our automatically\ncompressed tags form an alternative tag set: we show experimentally that our\ntags capture most of the information in traditional POS tag annotations, but\nour tag sequences can be parsed more accurately at the same level of tag\ngranularity. In the continuous version, we show experimentally that moderately\ncompressing the word embeddings by our method yields a more accurate parser in\n8 of 9 languages, unlike simple dimensionality reduction.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 00:47:31 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Li", "Xiang Lisa", ""], ["Eisner", "Jason", ""]]}, {"id": "1910.00164", "submitter": "Devansh Arpit", "authors": "Devansh Arpit, Caiming Xiong, Richard Socher", "title": "Predicting with High Correlation Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that instead of learning actual object features, deep\nnetworks tend to exploit non-robust (spurious) discriminative features that are\nshared between training and test sets. Therefore, while they achieve state of\nthe art performance on such test sets, they achieve poor generalization on out\nof distribution (OOD) samples where the IID (independent, identical\ndistribution) assumption breaks and the distribution of non-robust features\nshifts. In this paper, we consider distribution shift as a shift in the\ndistribution of input features during test time that exhibit low correlation\nwith targets in the training set. Under this definition, we evaluate existing\nrobust feature learning methods and regularization methods and compare them\nagainst a baseline designed to specifically capture high correlation features\nin training set. As a controlled test-bed, we design a colored MNIST (C-MNIST)\ndataset and find that existing methods trained on this set fail to generalize\nwell on an OOD version this dataset, showing that they overfit the low\ncorrelation color features. This is avoided by the baseline method trained on\nthe same C-MNIST data, which is designed to learn high correlation features,\nand is able to generalize on the test sets of vanilla MNIST, MNIST-M and SVHN\ndatasets. Our code is available at\n\\url{https://github.com/salesforce/corr_based_prediction}.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 00:48:27 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 19:39:27 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Arpit", "Devansh", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1910.00174", "submitter": "Luke Merrick", "authors": "Luke Merrick", "title": "Randomized Ablation Feature Importance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a model $f$ that predicts a target $y$ from a vector of input features\n$\\pmb{x} = x_1, x_2, \\ldots, x_M$, we seek to measure the importance of each\nfeature with respect to the model's ability to make a good prediction. To this\nend, we consider how (on average) some measure of goodness or badness of\nprediction (which we term \"loss\" $\\ell$), changes when we hide or ablate each\nfeature from the model. To ablate a feature, we replace its value with another\npossible value randomly. By averaging over many points and many possible\nreplacements, we measure the importance of a feature on the model's ability to\nmake good predictions. Furthermore, we present statistical measures of\nuncertainty that quantify how confident we are that the feature importance we\nmeasure from our finite dataset and finite number of ablations is close to the\ntheoretical true importance value.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 01:56:46 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 02:09:43 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Merrick", "Luke", ""]]}, {"id": "1910.00177", "submitter": "Xue Bin Peng", "authors": "Xue Bin Peng, Aviral Kumar, Grace Zhang, Sergey Levine", "title": "Advantage-Weighted Regression: Simple and Scalable Off-Policy\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to develop a simple and scalable reinforcement learning\nalgorithm that uses standard supervised learning methods as subroutines. Our\ngoal is an algorithm that utilizes only simple and convergent maximum\nlikelihood loss functions, while also being able to leverage off-policy data.\nOur proposed approach, which we refer to as advantage-weighted regression\n(AWR), consists of two standard supervised learning steps: one to regress onto\ntarget values for a value function, and another to regress onto weighted target\nactions for the policy. The method is simple and general, can accommodate\ncontinuous and discrete actions, and can be implemented in just a few lines of\ncode on top of standard supervised learning methods. We provide a theoretical\nmotivation for AWR and analyze its properties when incorporating off-policy\ndata from experience replay. We evaluate AWR on a suite of standard OpenAI Gym\nbenchmark tasks, and show that it achieves competitive performance compared to\na number of well-established state-of-the-art RL algorithms. AWR is also able\nto acquire more effective policies than most off-policy algorithms when\nlearning from purely static datasets with no additional environmental\ninteractions. Furthermore, we demonstrate our algorithm on challenging\ncontinuous control tasks with highly complex simulated characters.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 02:23:38 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 03:56:32 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2019 20:23:21 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Peng", "Xue Bin", ""], ["Kumar", "Aviral", ""], ["Zhang", "Grace", ""], ["Levine", "Sergey", ""]]}, {"id": "1910.00178", "submitter": "Wenlei Bao", "authors": "Wenlei Bao, Li-Wen Chang, Yang Chen, Ke Deng, Amit Agarwal, Emad\n  Barsoum, Abe Taha", "title": "NGEMM: Optimizing GEMM for Deep Learning via Compiler-based Techniques", "comments": "Comments: performance figure updated, experiments added, formula\n  corrected, references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization has emerged to be an effective way to significantly boost the\nperformance of deep neural networks (DNNs) by utilizing low-bit computations.\nDespite having lower numerical precision, quantized DNNs are able to reduce\nboth memory bandwidth and computation cycles with little losses of accuracy.\nInteger GEMM (General Matrix Multiplication) is critical to running quantized\nDNN models efficiently, as GEMM operations often dominate the computations in\nthese models. Various approaches have been developed by leveraging techniques\nsuch as vectorization and memory layout to improve the performance of integer\nGEMM. However, these existing approaches are not fast enough in certain\nscenarios. We developed NGEMM, a compiler-based GEMM implementation for\naccelerating lower-precision training and inference. NGEMM has better use of\nthe vector units by avoiding unnecessary vector computation that is introduced\nduring tree reduction. We compared NGEMM's performance with the state-of-art\nBLAS libraries such as MKL. Our experimental results showed that NGEMM\noutperformed MKL non-pack and pack version by an average of 1.86x and 1.16x,\nrespectively. We have applied NGEMM to a number of production services in\nMicrosoft.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 02:27:17 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 23:12:33 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Bao", "Wenlei", ""], ["Chang", "Li-Wen", ""], ["Chen", "Yang", ""], ["Deng", "Ke", ""], ["Agarwal", "Amit", ""], ["Barsoum", "Emad", ""], ["Taha", "Abe", ""]]}, {"id": "1910.00185", "submitter": "Xiang Li", "authors": "Jiaming Guo, Wei Qiu, Xiang Li, Xuandong Zhao, Ning Guo, Quanzheng Li", "title": "Predicting Alzheimer's Disease by Hierarchical Graph Convolution from\n  Positron Emission Tomography Imaging", "comments": "Jiaming Guo, Wei Qiu and Xiang Li contribute equally to this work", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9005971", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging-based early diagnosis of Alzheimer Disease (AD) has become an\neffective approach, especially by using nuclear medicine imaging techniques\nsuch as Positron Emission Topography (PET). In various literature it has been\nfound that PET images can be better modeled as signals (e.g. uptake of\nflorbetapir) defined on a network (non-Euclidean) structure which is governed\nby its underlying graph patterns of pathological progression and metabolic\nconnectivity. In order to effectively apply deep learning framework for PET\nimage analysis to overcome its limitation on Euclidean grid, we develop a\nsolution for 3D PET image representation and analysis under a generalized,\ngraph-based CNN architecture (PETNet), which analyzes PET signals defined on a\ngroup-wise inferred graph structure. Computations in PETNet are defined in\nnon-Euclidean, graph (network) domain, as it performs feature extraction by\nconvolution operations on spectral-filtered signals on the graph and pooling\noperations based on hierarchical graph clustering. Effectiveness of the PETNet\nis evaluated on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset,\nwhich shows improved performance over both deep learning and other machine\nlearning-based methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 03:05:18 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Guo", "Jiaming", ""], ["Qiu", "Wei", ""], ["Li", "Xiang", ""], ["Zhao", "Xuandong", ""], ["Guo", "Ning", ""], ["Li", "Quanzheng", ""]]}, {"id": "1910.00189", "submitter": "Kevin Hsieh", "authors": "Kevin Hsieh, Amar Phanishayee, Onur Mutlu, Phillip B. Gibbons", "title": "The Non-IID Data Quagmire of Decentralized Machine Learning", "comments": null, "journal-ref": "International Conference on Machine Learning (ICML), 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many large-scale machine learning (ML) applications need to perform\ndecentralized learning over datasets generated at different devices and\nlocations. Such datasets pose a significant challenge to decentralized learning\nbecause their different contexts result in significant data distribution skew\nacross devices/locations. In this paper, we take a step toward better\nunderstanding this challenge by presenting a detailed experimental study of\ndecentralized DNN training on a common type of data skew: skewed distribution\nof data labels across devices/locations. Our study shows that: (i) skewed data\nlabels are a fundamental and pervasive problem for decentralized learning,\ncausing significant accuracy loss across many ML applications, DNN models,\ntraining datasets, and decentralized learning algorithms; (ii) the problem is\nparticularly challenging for DNN models with batch normalization; and (iii) the\ndegree of data skew is a key determinant of the difficulty of the problem.\nBased on these findings, we present SkewScout, a system-level approach that\nadapts the communication frequency of decentralized learning algorithms to the\n(skew-induced) accuracy loss between data partitions. We also show that group\nnormalization can recover much of the accuracy loss of batch normalization.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 03:52:47 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 00:58:47 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Hsieh", "Kevin", ""], ["Phanishayee", "Amar", ""], ["Mutlu", "Onur", ""], ["Gibbons", "Phillip B.", ""]]}, {"id": "1910.00195", "submitter": "Mingwei Wei", "authors": "Mingwei Wei, David J Schwab", "title": "How noise affects the Hessian spectrum in overparameterized neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) forms the core optimization method for deep\nneural networks. While some theoretical progress has been made, it still\nremains unclear why SGD leads the learning dynamics in overparameterized\nnetworks to solutions that generalize well. Here we show that for\noverparameterized networks with a degenerate valley in their loss landscape,\nSGD on average decreases the trace of the Hessian of the loss. We also\ngeneralize this result to other noise structures and show that isotropic noise\nin the non-degenerate subspace of the Hessian decreases its determinant. In\naddition to explaining SGDs role in sculpting the Hessian spectrum, this opens\nthe door to new optimization approaches that may confer better generalization\nperformance. We test our results with experiments on toy models and deep neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 04:13:27 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 16:41:33 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Wei", "Mingwei", ""], ["Schwab", "David J", ""]]}, {"id": "1910.00199", "submitter": "Joseph Viviano", "authors": "Joseph D. Viviano, Becks Simpson, Francis Dutil, Yoshua Bengio, and\n  Joseph Paul Cohen", "title": "Saliency is a Possible Red Herring When Diagnosing Poor Generalization", "comments": "25 pages, 27 figures, 5 tables, code in paper\n  (https://github.com/josephdviviano/saliency-red-herring). Published at\n  International Conference on Learning Representations (ICLR) 2021. Previously\n  titled \"Underwhelming Generalization Improvements from Controlling Feature\n  Attribution\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poor generalization is one symptom of models that learn to predict target\nvariables using spuriously-correlated image features present only in the\ntraining distribution instead of the true image features that denote a class.\nIt is often thought that this can be diagnosed visually using attribution (aka\nsaliency) maps. We study if this assumption is correct. In some prediction\ntasks, such as for medical images, one may have some images with masks drawn by\na human expert, indicating a region of the image containing relevant\ninformation to make the prediction. We study multiple methods that take\nadvantage of such auxiliary labels, by training networks to ignore distracting\nfeatures which may be found outside of the region of interest. This mask\ninformation is only used during training and has an impact on generalization\naccuracy depending on the severity of the shift between the training and test\ndistributions. Surprisingly, while these methods improve generalization\nperformance in the presence of a covariate shift, there is no strong\ncorrespondence between the correction of attribution towards the features a\nhuman expert has labelled as important and generalization performance. These\nresults suggest that the root cause of poor generalization may not always be\nspatially defined, and raise questions about the utility of masks as\n\"attribution priors\" as well as saliency maps for explainable predictions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 04:29:18 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 05:25:18 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 16:40:27 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Viviano", "Joseph D.", ""], ["Simpson", "Becks", ""], ["Dutil", "Francis", ""], ["Bengio", "Yoshua", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "1910.00201", "submitter": "Guangyuan Zhao", "authors": "Yunhao Ba, Guangyuan Zhao and Achuta Kadambi", "title": "Blending Diverse Physical Priors with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning in context of physical systems merits a re-examination of\nthe learning strategy. In addition to data, one can leverage a vast library of\nphysical prior models (e.g. kinematics, fluid flow, etc) to perform more robust\ninference. The nascent sub-field of \\emph{physics-based learning} (PBL) studies\nthe blending of neural networks with physical priors. While previous PBL\nalgorithms have been applied successfully to specific tasks, it is hard to\ngeneralize existing PBL methods to a wide range of physics-based problems. Such\ngeneralization would require an architecture that can adapt to variations in\nthe correctness of the physics, or in the quality of training data. No such\narchitecture exists. In this paper, we aim to generalize PBL, by making a first\nattempt to bring neural architecture search (NAS) to the realm of PBL. We\nintroduce a new method known as physics-based neural architecture search\n(PhysicsNAS) that is a top-performer across a diverse range of quality in the\nphysical model and the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 05:01:19 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Ba", "Yunhao", ""], ["Zhao", "Guangyuan", ""], ["Kadambi", "Achuta", ""]]}, {"id": "1910.00204", "submitter": "Ehsan Amid", "authors": "Ehsan Amid, Manfred K. Warmuth", "title": "TriMap: Large-scale Dimensionality Reduction Using Triplets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce ``TriMap''; a dimensionality reduction technique based on\ntriplet constraints that preserves the global accuracy of the data better than\nthe other commonly used methods such as t-SNE, LargeVis, and UMAP. To quantify\nthe global accuracy, we introduce a score which roughly reflects the relative\nplacement of the clusters rather than the individual points. We empirically\nshow the excellent performance of TriMap on a large variety of datasets in\nterms of the quality of the embedding as well as the runtime. On our\nperformance benchmarks, TriMap easily scales to millions of points without\ndepleting the memory and clearly outperforms t-SNE, LargeVis, and UMAP in terms\nof runtime.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 05:28:57 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Amid", "Ehsan", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1910.00211", "submitter": "Harshad Khadilkar", "authors": "Hardik Meisheri and Vinita Baniwal and Nazneen N Sultana and Balaraman\n  Ravindran and Harshad Khadilkar", "title": "Reinforcement Learning for Multi-Objective Optimization of Online\n  Decisions in High-Dimensional Systems", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a purely data-driven solution to a class of sequential\ndecision-making problems with a large number of concurrent online decisions,\nwith applications to computing systems and operations research. We assume that\nwhile the micro-level behaviour of the system can be broadly captured by\nanalytical expressions or simulation, the macro-level or emergent behaviour is\ncomplicated by non-linearity, constraints, and stochasticity. If we represent\nthe set of concurrent decisions to be computed as a vector, each element of the\nvector is assumed to be a continuous variable, and the number of such elements\nis arbitrarily large and variable from one problem instance to another. We\nfirst formulate the decision-making problem as a canonical reinforcement\nlearning (RL) problem, which can be solved using purely data-driven techniques.\nWe modify a standard approach known as advantage actor critic (A2C) to ensure\nits suitability to the problem at hand, and compare its performance to that of\nbaseline approaches on the specific instance of a multi-product inventory\nmanagement task. The key modifications include a parallelised formulation of\nthe decision-making task, and a training procedure that explicitly recognises\nthe quantitative relationship between different decisions. We also present\nexperimental results probing the learned policies, and their robustness to\nvariations in the data.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 06:16:48 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Meisheri", "Hardik", ""], ["Baniwal", "Vinita", ""], ["Sultana", "Nazneen N", ""], ["Ravindran", "Balaraman", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "1910.00216", "submitter": "Akihiro Nakamura", "authors": "Akihiro Nakamura, Tatsuya Harada", "title": "Revisiting Fine-tuning for Few-shot Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning is the process of learning novel classes using only a few\nexamples and it remains a challenging task in machine learning. Many\nsophisticated few-shot learning algorithms have been proposed based on the\nnotion that networks can easily overfit to novel examples if they are simply\nfine-tuned using only a few examples. In this study, we show that in the\ncommonly used low-resolution mini-ImageNet dataset, the fine-tuning method\nachieves higher accuracy than common few-shot learning algorithms in the 1-shot\ntask and nearly the same accuracy as that of the state-of-the-art algorithm in\nthe 5-shot task. We then evaluate our method with more practical tasks, namely\nthe high-resolution single-domain and cross-domain tasks. With both tasks, we\nshow that our method achieves higher accuracy than common few-shot learning\nalgorithms. We further analyze the experimental results and show that: 1) the\nretraining process can be stabilized by employing a low learning rate, 2) using\nadaptive gradient optimizers during fine-tuning can increase test accuracy, and\n3) test accuracy can be improved by updating the entire network when a large\ndomain-shift exists between base and novel classes.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 06:21:50 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 04:53:10 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Nakamura", "Akihiro", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1910.00237", "submitter": "Irene Unceta", "authors": "Irene Unceta, Diego Palacios, Jordi Nin, Oriol Pujol", "title": "Sampling Unknown Decision Functions to Build Classifier Copies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Copies have been proposed as a viable alternative to endow machine learning\nmodels with properties and features that adapt them to changing needs. A\nfundamental step of the copying process is generating an unlabelled set of\npoints to explore the decision behavior of the targeted classifier throughout\nthe input space. In this article we propose two sampling strategies to produce\nsuch sets. We validate them in six well-known problems and compare them with\ntwo standard methods. We evaluate our proposals in terms of both their accuracy\nperformance and their computational cost.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 07:54:26 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Unceta", "Irene", ""], ["Palacios", "Diego", ""], ["Nin", "Jordi", ""], ["Pujol", "Oriol", ""]]}, {"id": "1910.00270", "submitter": "Daniel Greenfeld", "authors": "Daniel Greenfeld, Uri Shalit", "title": "Robust Learning with the Hilbert-Schmidt Independence Criterion", "comments": "Proceedings of the 37th International Conference on Machine Learning\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of a non-parametric independence measure, the\nHilbert-Schmidt Independence Criterion (HSIC), as a loss-function for learning\nrobust regression and classification models. This loss-function encourages\nlearning models where the distribution of the residuals between the label and\nthe model prediction is statistically independent of the distribution of the\ninstances themselves. This loss-function was first proposed by Mooij et al.\n(2009) in the context of learning causal graphs. We adapt it to the task of\nlearning for unsupervised covariate shift: learning on a source domain without\naccess to any instances or labels from the unknown target domain, but with the\nassumption that $p(y|x)$ (the conditional probability of labels given\ninstances) remains the same in the target domain. We show that the proposed\nloss is expected to give rise to models that generalize well on a class of\ntarget domains characterised by the complexity of their description within a\nreproducing kernel Hilbert space. Experiments on unsupervised covariate shift\ntasks demonstrate that models learned with the proposed loss-function\noutperform models learned with standard loss functions, achieving\nstate-of-the-art results on a challenging cell-microscopy unsupervised\ncovariate shift task.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 09:27:33 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 15:41:43 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 12:55:51 GMT"}, {"version": "v4", "created": "Sat, 11 Jul 2020 14:46:57 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Greenfeld", "Daniel", ""], ["Shalit", "Uri", ""]]}, {"id": "1910.00275", "submitter": "Jeroen Van Hautte", "authors": "Jeroen Van Hautte, Guy Emerson, Marek Rei", "title": "Bad Form: Comparing Context-Based and Form-Based Few-Shot Learning in\n  Distributional Semantic Models", "comments": "Accepted to the Proceedings of the Second Workshop on Deep Learning\n  for Low-Resource NLP (DeepLo 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are an essential component in a wide range of natural\nlanguage processing applications. However, distributional semantic models are\nknown to struggle when only a small number of context sentences are available.\nSeveral methods have been proposed to obtain higher-quality vectors for these\nwords, leveraging both this context information and sometimes the word forms\nthemselves through a hybrid approach. We show that the current tasks do not\nsuffice to evaluate models that use word-form information, as such models can\neasily leverage word forms in the training data that are related to word forms\nin the test data. We introduce 3 new tasks, allowing for a more balanced\ncomparison between models. Furthermore, we show that hyperparameters that have\nlargely been ignored in previous work can consistently improve the performance\nof both baseline and advanced models, achieving a new state of the art on 4 out\nof 6 tasks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 09:39:07 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Van Hautte", "Jeroen", ""], ["Emerson", "Guy", ""], ["Rei", "Marek", ""]]}, {"id": "1910.00290", "submitter": "Marco Valentino", "authors": "Mokanarangan Thayaparan, Marco Valentino, Viktor Schlegel, Andre\n  Freitas", "title": "Identifying Supporting Facts for Multi-hop Question Answering with\n  Document Graph Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in reading comprehension have resulted in models that surpass\nhuman performance when the answer is contained in a single, continuous passage\nof text. However, complex Question Answering (QA) typically requires multi-hop\nreasoning - i.e. the integration of supporting facts from different sources, to\ninfer the correct answer. This paper proposes Document Graph Network (DGN), a\nmessage passing architecture for the identification of supporting facts over a\ngraph-structured representation of text. The evaluation on HotpotQA shows that\nDGN obtains competitive results when compared to a reading comprehension\nbaseline operating on raw text, confirming the relevance of structured\nrepresentations for supporting multi-hop reasoning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 10:26:08 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Thayaparan", "Mokanarangan", ""], ["Valentino", "Marco", ""], ["Schlegel", "Viktor", ""], ["Freitas", "Andre", ""]]}, {"id": "1910.00292", "submitter": "Florian Schmidt", "authors": "Florian Schmidt", "title": "Generalization in Generation: A closer look at Exposure Bias", "comments": "wngt2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exposure bias refers to the train-test discrepancy that seemingly arises when\nan autoregressive generative model uses only ground-truth contexts at training\ntime but generated ones at test time. We separate the contributions of the\nmodel and the learning framework to clarify the debate on consequences and\nreview proposed counter-measures. In this light, we argue that generalization\nis the underlying property to address and propose unconditional generation as\nits fundamental benchmark. Finally, we combine latent variable modeling with a\nrecent formulation of exploration in reinforcement learning to obtain a\nrigorous handling of true and generated contexts. Results on language modeling\nand variational sentence auto-encoding confirm the model's generalization\ncapability.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 10:28:32 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 06:55:36 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Schmidt", "Florian", ""]]}, {"id": "1910.00314", "submitter": "Yatin Chaudhary", "authors": "Yatin Chaudhary, Pankaj Gupta, Hinrich Sch\\\"utze", "title": "BioNLP-OST 2019 RDoC Tasks: Multi-grain Neural Relevance Ranking Using\n  Topics and Attention Based Query-Document-Sentence Interactions", "comments": "EMNLP2019, 10 pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our system details and results of participation in the\nRDoC Tasks of BioNLP-OST 2019. Research Domain Criteria (RDoC) construct is a\nmulti-dimensional and broad framework to describe mental health disorders by\ncombining knowledge from genomics to behaviour. Non-availability of RDoC\nlabelled dataset and tedious labelling process hinders the use of RDoC\nframework to reach its full potential in Biomedical research community and\nHealthcare industry. Therefore, Task-1 aims at retrieval and ranking of PubMed\nabstracts relevant to a given RDoC construct and Task-2 aims at extraction of\nthe most relevant sentence from a given PubMed abstract. We investigate (1)\nattention based supervised neural topic model and SVM for retrieval and ranking\nof PubMed abstracts and, further utilize BM25 and other relevance measures for\nre-ranking, (2) supervised and unsupervised sentence ranking models utilizing\nmulti-view representations comprising of query-aware attention-based sentence\nrepresentation (QAR), bag-of-words (BoW) and TF-IDF. Our best systems achieved\n1st rank and scored 0.86 mean average precision (mAP) and 0.58 macro average\naccuracy (MAA) in Task-1 and Task-2 respectively.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 11:47:36 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 08:06:02 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Chaudhary", "Yatin", ""], ["Gupta", "Pankaj", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1910.00324", "submitter": "Ahmet Iscen", "authors": "Ahmet Iscen, Giorgos Tolias, Yannis Avrithis, Ondrej Chum, Cordelia\n  Schmid", "title": "Graph convolutional networks for learning with few clean and many noisy\n  labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the problem of learning a classifier from noisy\nlabels when a few clean labeled examples are given. The structure of clean and\nnoisy data is modeled by a graph per class and Graph Convolutional Networks\n(GCN) are used to predict class relevance of noisy examples. For each class,\nthe GCN is treated as a binary classifier, which learns to discriminate clean\nfrom noisy examples using a weighted binary cross-entropy loss function. The\nGCN-inferred \"clean\" probability is then exploited as a relevance measure. Each\nnoisy example is weighted by its relevance when learning a classifier for the\nend task. We evaluate our method on an extended version of a few-shot learning\nproblem, where the few clean examples of novel classes are supplemented with\nadditional noisy data. Experimental results show that our GCN-based cleaning\nprocess significantly improves the classification accuracy over not cleaning\nthe noisy data, as well as standard few-shot classification where only few\nclean examples are used.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 11:56:09 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 22:01:35 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 21:33:51 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Iscen", "Ahmet", ""], ["Tolias", "Giorgos", ""], ["Avrithis", "Yannis", ""], ["Chum", "Ondrej", ""], ["Schmid", "Cordelia", ""]]}, {"id": "1910.00330", "submitter": "Sayed Soroush Haj Zargarbashi", "authors": "S. Soroush Haj Zargarbashi, Bagher Babaali", "title": "A Multi-Modal Feature Embedding Approach to Diagnose Alzheimer Disease\n  from Spoken Language", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction: Alzheimer's disease is a type of dementia in which early\ndiagnosis plays a major rule in the quality of treatment. Among new works in\nthe diagnosis of Alzheimer's disease, there are many of them analyzing the\nvoice stream acoustically, syntactically or both. The mostly used tools to\nperform these analysis usually include machine learning techniques. Objective:\nDesigning an automatic machine learning based diagnosis system will help in the\nprocedure of early detection. Also, systems, using noninvasive data are\npreferable. Methods: We used are classification system based on spoken\nlanguage. We use three (statistical and neural) approaches to classify audio\nsignals from spoken language into two classes of dementia and control. Result:\nThis work designs a multi-modal feature embedding on the spoken language audio\nsignal using three approaches; N-gram, i-vector, and x-vector. The evaluation\nof the system is done on the cookie picture description task from Pitt Corpus\ndementia bank with the accuracy of 83:6\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 12:03:24 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Zargarbashi", "S. Soroush Haj", ""], ["Babaali", "Bagher", ""]]}, {"id": "1910.00337", "submitter": "Piotr Niewinski", "authors": "Piotr Niewinski, Maria Pszona, Maria Janicka", "title": "TMLab: Generative Enhanced Model (GEM) for adversarial attacks", "comments": "7 pages + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our Generative Enhanced Model (GEM) that we used to create samples\nawarded the first prize on the FEVER 2.0 Breakers Task. GEM is the extended\nlanguage model developed upon GPT-2 architecture. The addition of novel target\nvocabulary input to the already existing context input enabled controlled text\ngeneration. The training procedure resulted in creating a model that inherited\nthe knowledge of pretrained GPT-2, and therefore was ready to generate\nnatural-like English sentences in the task domain with some additional control.\nAs a result, GEM generated malicious claims that mixed facts from various\narticles, so it became difficult to classify their truthfulness.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 12:25:44 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Niewinski", "Piotr", ""], ["Pszona", "Maria", ""], ["Janicka", "Maria", ""]]}, {"id": "1910.00341", "submitter": "Myunghun Jung", "authors": "Myunghun Jung, Hyungjun Lim, Jahyun Goo, Youngmoon Jung, and Hoirin\n  Kim", "title": "Additional Shared Decoder on Siamese Multi-view Encoders for Learning\n  Acoustic Word Embeddings", "comments": "Accepted at 2019 IEEE Automatic Speech Recognition and Understanding\n  Workshop (ASRU 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.IR cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic word embeddings --- fixed-dimensional vector representations of\narbitrary-length words --- have attracted increasing interest in\nquery-by-example spoken term detection. Recently, on the fact that the\northography of text labels partly reflects the phonetic similarity between the\nwords' pronunciation, a multi-view approach has been introduced that jointly\nlearns acoustic and text embeddings. It showed that it is possible to learn\ndiscriminative embeddings by designing the objective which takes text labels as\nwell as word segments. In this paper, we propose a network architecture that\nexpands the multi-view approach by combining the Siamese multi-view encoders\nwith a shared decoder network to maximize the effect of the relationship\nbetween acoustic and text embeddings in embedding space. Discriminatively\ntrained with multi-view triplet loss and decoding loss, our proposed approach\nachieves better performance on acoustic word discrimination task with the WSJ\ndataset, resulting in 11.1% relative improvement in average precision. We also\npresent experimental results on cross-view word discrimination and word level\nspeech recognition tasks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 12:36:18 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Jung", "Myunghun", ""], ["Lim", "Hyungjun", ""], ["Goo", "Jahyun", ""], ["Jung", "Youngmoon", ""], ["Kim", "Hoirin", ""]]}, {"id": "1910.00352", "submitter": "Moksh Jain", "authors": "Moksh Jain and Sowmya Kamath S", "title": "Proximal Policy Optimization for Improved Convergence in IRGAN", "comments": "5 pages. Smooth Games Optimization and Machine Learning Workshop\n  (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  IRGAN is an information retrieval (IR) modeling approach that uses a\ntheoretical minimax game between a generative and a discriminative model to\niteratively optimize both of them, hence unifying the generative and\ndiscriminative approaches. Despite significant performance improvements in\nseveral information retrieval tasks, IRGAN training is an unstable process, and\nthe solution varies largely with the random parameter initialization. In this\nwork, we present an improved training objective based on proximal policy\noptimization objective and Gumbel-Softmax based sampling for the generator. We\nalso propose a modified training algorithm which takes a single gradient update\non both the generator as well as discriminator for each iteration step. We\npresent empirical evidence of the improved convergence of the proposed model\nover the original IRGAN and a comparison on three different IR tasks on\nbenchmark datasets is also discussed, emphasizing the proposed model's superior\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 12:56:32 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Jain", "Moksh", ""], ["S", "Sowmya Kamath", ""]]}, {"id": "1910.00359", "submitter": "Jonas Geiping", "authors": "Micah Goldblum, Jonas Geiping, Avi Schwarzschild, Michael Moeller and\n  Tom Goldstein", "title": "Truth or Backpropaganda? An Empirical Investigation of Deep Learning\n  Theory", "comments": "18 pages, 6 figures. First two authors contributed equally. Published\n  as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically evaluate common assumptions about neural networks that are\nwidely held by practitioners and theorists alike. In this work, we: (1) prove\nthe widespread existence of suboptimal local minima in the loss landscape of\nneural networks, and we use our theory to find examples; (2) show that\nsmall-norm parameters are not optimal for generalization; (3) demonstrate that\nResNets do not conform to wide-network theories, such as the neural tangent\nkernel, and that the interaction between skip connections and batch\nnormalization plays a role; (4) find that rank does not correlate with\ngeneralization or robustness in a practical setting.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:09:46 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 13:26:16 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 16:29:45 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Goldblum", "Micah", ""], ["Geiping", "Jonas", ""], ["Schwarzschild", "Avi", ""], ["Moeller", "Michael", ""], ["Goldstein", "Tom", ""]]}, {"id": "1910.00370", "submitter": "Yijun Bian", "authors": "Yijun Bian, Qingquan Song, Mengnan Du, Jun Yao, Huanhuan Chen, Xia Hu", "title": "Sub-Architecture Ensemble Pruning in Neural Architecture Search", "comments": "Accepted by TNNLS. This work was done when the first author was a\n  visiting research scholar at Texas A&M University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) is gaining more and more attention in recent\nyears due to its flexibility and remarkable capability to reduce the burden of\nneural network design. To achieve better performance, however, the searching\nprocess usually costs massive computations that might not be affordable for\nresearchers and practitioners. While recent attempts have employed ensemble\nlearning methods to mitigate the enormous computational cost, however, they\nneglect a key property of ensemble methods, namely diversity, which leads to\ncollecting more similar sub-architectures with potential redundancy in the\nfinal design. To tackle this problem, we propose a pruning method for NAS\nensembles called \"Sub-Architecture Ensemble Pruning in Neural Architecture\nSearch (SAEP).\" It targets to leverage diversity and to achieve sub-ensemble\narchitectures at a smaller size with comparable performance to ensemble\narchitectures that are not pruned. Three possible solutions are proposed to\ndecide which sub-architectures to prune during the searching process.\nExperimental results exhibit the effectiveness of the proposed method by\nlargely reducing the number of sub-architectures without degrading the\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:26:54 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 03:37:48 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Bian", "Yijun", ""], ["Song", "Qingquan", ""], ["Du", "Mengnan", ""], ["Yao", "Jun", ""], ["Chen", "Huanhuan", ""], ["Hu", "Xia", ""]]}, {"id": "1910.00382", "submitter": "Xiaoan Ding", "authors": "Xiaoan Ding, Kevin Gimpel", "title": "Latent-Variable Generative Models for Data-Efficient Text Classification", "comments": "11 pages, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative classifiers offer potential advantages over their discriminative\ncounterparts, namely in the areas of data efficiency, robustness to data shift\nand adversarial examples, and zero-shot learning (Ng and Jordan,2002; Yogatama\net al., 2017; Lewis and Fan,2019). In this paper, we improve generative text\nclassifiers by introducing discrete latent variables into the generative story,\nand explore several graphical model configurations. We parameterize the\ndistributions using standard neural architectures used in conditional language\nmodeling and perform learning by directly maximizing the log marginal\nlikelihood via gradient-based optimization, which avoids the need to do\nexpectation-maximization. We empirically characterize the performance of our\nmodels on six text classification datasets. The choice of where to include the\nlatent variable has a significant impact on performance, with the strongest\nresults obtained when using the latent variable as an auxiliary conditioning\nvariable in the generation of the textual input. This model consistently\noutperforms both the generative and discriminative classifiers in small-data\nsettings. We analyze our model by using it for controlled generation, finding\nthat the latent variable captures interpretable properties of the data, even\nwith very small training sets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:45:56 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Ding", "Xiaoan", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1910.00387", "submitter": "Fei Wu", "authors": "Fei Wu, Thomas Michel and Alexandre Briot", "title": "Leveraging Model Interpretability and Stability to increase Model\n  Robustness", "comments": "2019 ICCV workshop on Interpreting and Explaining Visual AI models; 8\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art Deep Neural Networks (DNN) can now achieve above human level\naccuracy on image classification tasks. However their outstanding performances\ncome along with a complex inference mechanism making them arduously\ninterpretable models. In order to understand the underlying prediction rules of\nDNNs, Dhamdhere et al. propose an interpretability method to break down a DNN\nprediction score as sum of its hidden unit contributions, in the form of a\nmetric called conductance. Analyzing conductances of DNN hidden units, we find\nout there is a difference in how wrong and correct predictions are inferred. We\nidentify distinguishable patterns of hidden unit activations for wrong and\ncorrect predictions. We then use an error detector in the form of a binary\nclassifier on top of the DNN to automatically discriminate wrong and correct\npredictions of the DNN based on their hidden unit activations. Detected wrong\npredictions are discarded, increasing the model robustness. A different\napproach to distinguish wrong and correct predictions of DNNs is proposed by\nWang et al. whose method is based on the premise that input samples leading a\nDNN into making wrong predictions are less stable to the DNN weight changes\nthan correctly classified input samples. In our study, we compare both methods\nand find out by combining them that better detection of wrong predictions can\nbe achieved.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:51:56 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 23:23:04 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Wu", "Fei", ""], ["Michel", "Thomas", ""], ["Briot", "Alexandre", ""]]}, {"id": "1910.00391", "submitter": "Jacob S{\\o}gaard Larsen Mr.", "authors": "Jacob S{\\o}gaard Larsen, Line Clemmensen", "title": "Deep learning for Chemometric and non-translational data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method to train deep convolutional neural networks which\nlearn from multiple data sets of varying input sizes through weight sharing.\nThis is an advantage in chemometrics where individual measurements represent\nexact chemical compounds and thus signals cannot be translated or resized\nwithout disturbing their interpretation. Our approach show superior performance\ncompared to transfer learning when a medium sized and a small data set are\ntrained together. While we observe a small improvement compared to individual\ntraining when two medium sized data sets are trained together, in particular\nthrough a reduction in the variance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:55:44 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 12:37:08 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 11:30:12 GMT"}, {"version": "v4", "created": "Thu, 7 Nov 2019 13:54:14 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Larsen", "Jacob S\u00f8gaard", ""], ["Clemmensen", "Line", ""]]}, {"id": "1910.00393", "submitter": "Johannes Haupt", "authors": "Johannes Haupt, Daniel Jacob, Robin M. Gubela, Stefan Lessmann", "title": "Affordable Uplift: Supervised Randomization in Controlled Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customer scoring models are the core of scalable direct marketing. Uplift\nmodels provide an estimate of the incremental benefit from a treatment that is\nused for operational decision-making. Training and monitoring of uplift models\nrequire experimental data. However, the collection of data under randomized\ntreatment assignment is costly, since random targeting deviates from an\nestablished targeting policy. To increase the cost-efficiency of\nexperimentation and facilitate frequent data collection and model training, we\nintroduce supervised randomization. It is a novel approach that integrates\nexisting scoring models into randomized trials to target relevant customers,\nwhile ensuring consistent estimates of treatment effects through correction for\nactive sample selection. An empirical Monte Carlo study shows that data\ncollection under supervised randomization is cost-efficient, while downstream\nuplift models perform competitively.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 14:01:14 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Haupt", "Johannes", ""], ["Jacob", "Daniel", ""], ["Gubela", "Robin M.", ""], ["Lessmann", "Stefan", ""]]}, {"id": "1910.00399", "submitter": "David Isele", "authors": "David Isele, Alireza Nakhaei, and Kikuo Fujimura", "title": "Safe Reinforcement Learning on Autonomous Vehicles", "comments": null, "journal-ref": "IROS 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been numerous advances in reinforcement learning, but the\ntypically unconstrained exploration of the learning process prevents the\nadoption of these methods in many safety critical applications. Recent work in\nsafe reinforcement learning uses idealized models to achieve their guarantees,\nbut these models do not easily accommodate the stochasticity or\nhigh-dimensionality of real world systems. We investigate how prediction\nprovides a general and intuitive framework to constraint exploration, and show\nhow it can be used to safely learn intersection handling behaviors on an\nautonomous vehicle.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 20:36:28 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Isele", "David", ""], ["Nakhaei", "Alireza", ""], ["Fujimura", "Kikuo", ""]]}, {"id": "1910.00406", "submitter": "Juntang Zhuang", "authors": "Juntang Zhuang, Nicha C. Dvornek, Xiaoxiao Li, Junlin Yang, James S.\n  Duncan", "title": "Decision Explanation and Feature Importance for Invertible Networks", "comments": "Correct notations", "journal-ref": "ICCVW 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial attacks and hard to\ninterpret because of their black-box nature. The recently proposed invertible\nnetwork is able to accurately reconstruct the inputs to a layer from its\noutputs, thus has the potential to unravel the black-box model. An invertible\nnetwork classifier can be viewed as a two-stage model: (1) invertible\ntransformation from input space to the feature space; (2) a linear classifier\nin the feature space. We can determine the decision boundary of a linear\nclassifier in the feature space; since the transform is invertible, we can\ninvert the decision boundary from the feature space to the input space.\nFurthermore, we propose to determine the projection of a data point onto the\ndecision boundary, and define explanation as the difference between data and\nits projection. Finally, we propose to locally approximate a neural network\nwith its first-order Taylor expansion, and define feature importance using a\nlocal linear model. We provide the implementation of our method:\n\\url{https://github.com/juntang-zhuang/explain_invertible}.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 01:01:58 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 03:34:24 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Zhuang", "Juntang", ""], ["Dvornek", "Nicha C.", ""], ["Li", "Xiaoxiao", ""], ["Yang", "Junlin", ""], ["Duncan", "James S.", ""]]}, {"id": "1910.00411", "submitter": "Jiachun Liao", "authors": "Peter Kairouz and Jiachun Liao and Chong Huang and Maunil Vyas and\n  Monica Welfert and Lalitha Sankar", "title": "Generating Fair Universal Representations using Adversarial Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven framework for learning fair universal\nrepresentations (FUR) that guarantee statistical fairness for any learning task\nthat may not be known a priori. Our framework leverages recent advances in\nadversarial learning to allow a data holder to learn representations in which a\nset of sensitive attributes are decoupled from the rest of the dataset. We\nformulate this as a constrained minimax game between an encoder and an\nadversary where the constraint ensures a measure of usefulness (utility) of the\nrepresentation. The resulting problem is that of censoring, i.e., finding a\nrepresentation that is least informative about the sensitive attributes given a\nutility constraint. For appropriately chosen adversarial loss functions, our\ncensoring framework precisely clarifies the optimal adversarial strategy\nagainst strong information-theoretic adversaries; it also achieves the fairness\nmeasure of demographic parity for the resulting constrained representations. We\nevaluate the performance of our proposed framework on both synthetic and\npublicly available datasets. For these datasets, we use two tradeoff measures:\ncensoring vs. representation fidelity and fairness vs. utility for downstream\ntasks, to amply demonstrate that multiple sensitive features can be effectively\ncensored even as the resulting fair representations ensure accuracy for\nmultiple downstream tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 23:06:09 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 18:45:36 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 23:58:08 GMT"}, {"version": "v4", "created": "Fri, 20 Mar 2020 19:49:50 GMT"}, {"version": "v5", "created": "Tue, 24 Mar 2020 05:56:28 GMT"}, {"version": "v6", "created": "Fri, 30 Apr 2021 01:07:44 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Kairouz", "Peter", ""], ["Liao", "Jiachun", ""], ["Huang", "Chong", ""], ["Vyas", "Maunil", ""], ["Welfert", "Monica", ""], ["Sankar", "Lalitha", ""]]}, {"id": "1910.00412", "submitter": "Eric M\\\"uller-Budack", "authors": "Eric M\\\"uller-Budack, Jonas Theiner, Robert Rein, Ralph Ewerth", "title": "\"Does 4-4-2 exist?\" -- An Analytics Approach to Understand and Classify\n  Football Team Formations in Single Match Situations", "comments": "Accepted at MMSports 2019 (Workshop of ACM Multimedia 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The chances to win a football match can be significantly increased if the\nright tactic is chosen and the behavior of the opposite team is well\nanticipated. For this reason, every professional football club employs a team\nof game analysts. However, at present game performance analysis is done\nmanually and therefore highly time-consuming. Consequently, automated tools to\nsupport the analysis process are required. In this context, one of the main\ntasks is to summarize team formations by patterns such as 4-4-2. In this paper,\nwe introduce an analytics approach that automatically classifies and visualizes\nthe team formation based on the players' position data. We focus on single\nmatch situations instead of complete halftimes or matches to provide a more\ndetailed analysis. A detailed analysis of individual match situations depending\non ball possession and match segment length is provided. For this purpose, a\nvisual summary is utilized that summarizes the team formation in a match\nsegment. An expert annotation study is conducted that demonstrates 1) the\ncomplexity of the task and 2) the usefulness of the visualization of single\nsituations to understand team formations. The suggested classification approach\noutperforms existing methods for formation classification. In particular, our\napproach gives insights about the shortcomings of using patterns like 4-4-2 to\ndescribe team formations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 16:14:46 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["M\u00fcller-Budack", "Eric", ""], ["Theiner", "Jonas", ""], ["Rein", "Robert", ""], ["Ewerth", "Ralph", ""]]}, {"id": "1910.00413", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "A Note On $k$-Means Probabilistic Poverty", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is proven, by example, that the version of $k$-means with random\ninitialization does not have the property \\emph{probabilistic $k$-richness}.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 05:14:43 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "1910.00421", "submitter": "Khanh Nguyen", "authors": "Khanh Nguyen and Hal Daum\\'e III", "title": "Global Voices: Crossing Borders in Automatic News Summarization", "comments": "NewSum workshop at EMNLP 2019, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct Global Voices, a multilingual dataset for evaluating\ncross-lingual summarization methods. We extract social-network descriptions of\nGlobal Voices news articles to cheaply collect evaluation data for into-English\nand from-English summarization in 15 languages. Especially, for the\ninto-English summarization task, we crowd-source a high-quality evaluation\ndataset based on guidelines that emphasize accuracy, coverage, and\nunderstandability. To ensure the quality of this dataset, we collect human\nratings to filter out bad summaries, and conduct a survey on humans, which\nshows that the remaining summaries are preferred over the social-network\nsummaries. We study the effect of translation quality in cross-lingual\nsummarization, comparing a translate-then-summarize approach with several\nbaselines. Our results highlight the limitations of the ROUGE metric that are\noverlooked in monolingual summarization. Our dataset is available for download\nat https://forms.gle/gpkJDT6RJWHM1Ztz9 .\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 14:19:40 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 02:13:40 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 15:19:30 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 16:00:33 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Nguyen", "Khanh", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "1910.00423", "submitter": "Keith Levin", "authors": "Keith Levin, Fred Roosta, Minh Tang, Michael W. Mahoney, Carey E.\n  Priebe", "title": "Limit theorems for out-of-sample extensions of the adjacency and\n  Laplacian spectral embeddings", "comments": "Portions of this work originally appeared in ICML2018 as\n  \"Out-of-sample extension of graph adjacency spectral embedding\" (accompanying\n  technical report available at arXiv:1802.06307). This work extends the\n  results of that earlier paper to a second graph embedding technique called\n  the Laplacian spectral embedding and presents additional experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embeddings, a class of dimensionality reduction techniques designed for\nrelational data, have proven useful in exploring and modeling network\nstructure. Most dimensionality reduction methods allow out-of-sample\nextensions, by which an embedding can be applied to observations not present in\nthe training set. Applied to graphs, the out-of-sample extension problem\nconcerns how to compute the embedding of a vertex that is added to the graph\nafter an embedding has already been computed. In this paper, we consider the\nout-of-sample extension problem for two graph embedding procedures: the\nadjacency spectral embedding and the Laplacian spectral embedding. In both\ncases, we prove that when the underlying graph is generated according to a\nlatent space model called the random dot product graph, which includes the\npopular stochastic block model as a special case, an out-of-sample extension\nbased on a least-squares objective obeys a central limit theorem about the true\nlatent position of the out-of-sample vertex. In addition, we prove a\nconcentration inequality for the out-of-sample extension of the adjacency\nspectral embedding based on a maximum-likelihood objective. Our results also\nyield a convenient framework in which to analyze trade-offs between estimation\naccuracy and computational expense, which we explore briefly.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 04:02:10 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Levin", "Keith", ""], ["Roosta", "Fred", ""], ["Tang", "Minh", ""], ["Mahoney", "Michael W.", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1910.00424", "submitter": "Mandar Gogate", "authors": "Mandar Gogate, Ahsan Adeel, Kia Dashtipour, Peter Derleth, Amir\n  Hussain", "title": "AV Speech Enhancement Challenge using a Real Noisy Corpus", "comments": "arXiv admin note: substantial text overlap with arXiv:1909.10407", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents, a first of its kind, audio-visual (AV) speech enhacement\nchallenge in real-noisy settings. A detailed description of the AV challenge, a\nnovel real noisy AV corpus (ASPIRE), benchmark speech enhancement task, and\nbaseline performance results are outlined. The latter are based on training a\ndeep neural architecture on a synthetic mixture of Grid corpus and ChiME3\nnoises (consisting of bus, pedestrian, cafe, and street noises) and testing on\nthe ASPIRE corpus. Subjective evaluations of five different speech enhancement\nalgorithms (including SEAGN, spectrum subtraction (SS) , log-minimum\nmean-square error (LMMSE), audio-only CochleaNet, and AV CochleaNet) are\npresented as baseline results. The aim of the multi-modal challenge is to\nprovide a timely opportunity for comprehensive evaluation of novel AV speech\nenhancement algorithms, using our new benchmark, real-noisy AV corpus and\nspecified performance metrics. This will promote AV speech processing research\nglobally, stimulate new ground-breaking multi-modal approaches, and attract\ninterest from companies, academics and researchers working in AV speech\ntechnologies and applications. We encourage participants (through a challenge\nwebsite sign-up) from both the speech and hearing research communities, to\nbenefit from their complementary approaches to AV speech in noise processing.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:58:14 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Gogate", "Mandar", ""], ["Adeel", "Ahsan", ""], ["Dashtipour", "Kia", ""], ["Derleth", "Peter", ""], ["Hussain", "Amir", ""]]}, {"id": "1910.00445", "submitter": "Ivan Y. Tyukin", "authors": "Ivan Y. Tyukin, Alexander N. Gorban, Alistair A. McEwan, Sepehr\n  Meshkinfamfard, Lixin Tang", "title": "Blessing of dimensionality at the edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present theory and algorithms enabling classes of Artificial\nIntelligence (AI) systems to continuously and incrementally improve with\na-priori quantifiable guarantees - or more specifically remove classification\nerrors - over time. This is distinct from state-of-the-art machine learning,\nAI, and software approaches. Another feature of this approach is that, in the\nsupervised setting, the computational complexity of training is linear in the\nnumber of training samples. At the time of classification, the computational\ncomplexity is bounded by few inner product calculations. Moreover, the\nimplementation is shown to be very scalable. This makes it viable for\ndeployment in applications where computational power and memory are limited,\nsuch as embedded environments. It enables the possibility for fast on-line\noptimisation using improved training samples. The approach is based on the\nconcentration of measure effects and stochastic separation theorems and is\nillustrated with an example on the identification faulty processes in Computer\nNumerical Control (CNC) milling and with a case study on adaptive removal of\nfalse positives in an industrial video surveillance and analytics system.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 16:18:42 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 15:48:40 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Tyukin", "Ivan Y.", ""], ["Gorban", "Alexander N.", ""], ["McEwan", "Alistair A.", ""], ["Meshkinfamfard", "Sepehr", ""], ["Tang", "Lixin", ""]]}, {"id": "1910.00452", "submitter": "Balasubramaniam Srinivasan", "authors": "Balasubramaniam Srinivasan and Bruno Ribeiro", "title": "On the Equivalence between Positional Node Embeddings and Structural\n  Graph Representations", "comments": "This version corrects some typos in the definition of \\Sigma, it\n  should be \\Sigma_n. Code available at\n  https://github.com/PurdueMINDS/Equivalence", "journal-ref": "Published as a conference paper at the Eighth International\n  Conference on Learning Representations (ICLR 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides the first unifying theoretical framework for node\n(positional) embeddings and structural graph representations, bridging methods\nlike matrix factorization and graph neural networks. Using invariant theory, we\nshow that the relationship between structural representations and node\nembeddings is analogous to that of a distribution and its samples. We prove\nthat all tasks that can be performed by node embeddings can also be performed\nby structural representations and vice-versa. We also show that the concept of\ntransductive and inductive learning is unrelated to node embeddings and graph\nrepresentations, clearing another source of confusion in the literature.\nFinally, we introduce new practical guidelines to generating and using node\nembeddings, which fixes significant shortcomings of standard operating\nprocedures used today.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 14:37:22 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 18:26:37 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 01:08:22 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Srinivasan", "Balasubramaniam", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "1910.00458", "submitter": "Di Jin", "authors": "Di Jin, Shuyang Gao, Jiun-Yu Kao, Tagyoung Chung, Dilek Hakkani-tur", "title": "MMM: Multi-stage Multi-task Learning for Multi-choice Reading\n  Comprehension", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) for question answering (QA), which aims\nto answer a question given the relevant context passages, is an important way\nto test the ability of intelligence systems to understand human language.\nMultiple-Choice QA (MCQA) is one of the most difficult tasks in MRC because it\noften requires more advanced reading comprehension skills such as logical\nreasoning, summarization, and arithmetic operations, compared to the extractive\ncounterpart where answers are usually spans of text within given passages.\nMoreover, most existing MCQA datasets are small in size, making the learning\ntask even harder. We introduce MMM, a Multi-stage Multi-task learning framework\nfor Multi-choice reading comprehension. Our method involves two sequential\nstages: coarse-tuning stage using out-of-domain datasets and multi-task\nlearning stage using a larger in-domain dataset to help model generalize better\nwith limited data. Furthermore, we propose a novel multi-step attention network\n(MAN) as the top-level classifier for this task. We demonstrate MMM\nsignificantly advances the state-of-the-art on four representative MCQA\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 14:43:37 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 01:01:01 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Jin", "Di", ""], ["Gao", "Shuyang", ""], ["Kao", "Jiun-Yu", ""], ["Chung", "Tagyoung", ""], ["Hakkani-tur", "Dilek", ""]]}, {"id": "1910.00460", "submitter": "Ivan Stankevich", "authors": "Konstantin Korishchenko, Ivan Stankevich, Nikolay Pilnik, Daria\n  Petrova", "title": "Usage-Based Vehicle Insurance: Driving Style Factors of Accident\n  Probability and Severity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces an approach to telematics devices data application in\nautomotive insurance. We conduct a comparative analysis of different types of\ndevices that collect information on vehicle utilization and driving style of\nits driver, describe advantages and disadvantages of these devices and indicate\nthe most efficient from the insurer point of view. The possible formats of\ntelematics data are described and methods of their processing to a format\nconvenient for modelling are proposed. We also introduce an approach to\nclassify the accidents strength. Using all the available information, we\nestimate accident probability models for different types of accidents and\nidentify an optimal set of factors for each of the models. We assess the\nquality of resulting models using both in-sample and out-of-sample estimates.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 14:45:50 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 16:09:06 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Korishchenko", "Konstantin", ""], ["Stankevich", "Ivan", ""], ["Pilnik", "Nikolay", ""], ["Petrova", "Daria", ""]]}, {"id": "1910.00462", "submitter": "Ivan Donadello", "authors": "Ivan Donadello and Luciano Serafini", "title": "Compensating Supervision Incompleteness with Prior Knowledge in Semantic\n  Image Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Image Interpretation is the task of extracting a structured semantic\ndescription from images. This requires the detection of visual relationships:\ntriples (subject,relation,object) describing a semantic relation between a\nsubject and an object. A pure supervised approach to visual relationship\ndetection requires a complete and balanced training set for all the possible\ncombinations of (subject, relation, object). However, such training sets are\nnot available and would require a prohibitive human effort. This implies the\nability of predicting triples which do not appear in the training set. This\nproblem is called zero-shot learning. State-of-the-art approaches to zero-shot\nlearning exploit similarities among relationships in the training set or\nexternal linguistic knowledge. In this paper, we perform zero-shot learning by\nusing Logic Tensor Networks, a novel Statistical Relational Learning framework\nthat exploits both the similarities with other seen relationships and\nbackground knowledge, expressed with logical constraints between subjects,\nrelations and objects. The experiments on the Visual Relationship Dataset show\nthat the use of logical constraints outperforms the current methods. This\nimplies that background knowledge can be used to alleviate the incompleteness\nof training sets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 14:56:08 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Donadello", "Ivan", ""], ["Serafini", "Luciano", ""]]}, {"id": "1910.00470", "submitter": "Ambra Demontis Ph.D.", "authors": "Angelo Sotgiu, Ambra Demontis, Marco Melis, Battista Biggio, Giorgio\n  Fumera, Xiaoyi Feng and Fabio Roli", "title": "Deep Neural Rejection against Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the impressive performances reported by deep neural networks in\ndifferent application domains, they remain largely vulnerable to adversarial\nexamples, i.e., input samples that are carefully perturbed to cause\nmisclassification at test time. In this work, we propose a deep neural\nrejection mechanism to detect adversarial examples, based on the idea of\nrejecting samples that exhibit anomalous feature representations at different\nnetwork layers. With respect to competing approaches, our method does not\nrequire generating adversarial examples at training time, and it is less\ncomputationally demanding. To properly evaluate our method, we define an\nadaptive white-box attack that is aware of the defense mechanism and aims to\nbypass it. Under this worst-case setting, we empirically show that our approach\noutperforms previously-proposed methods that detect adversarial examples by\nonly analyzing the feature representation provided by the output network layer.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 15:08:34 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 17:51:25 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 13:42:24 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Sotgiu", "Angelo", ""], ["Demontis", "Ambra", ""], ["Melis", "Marco", ""], ["Biggio", "Battista", ""], ["Fumera", "Giorgio", ""], ["Feng", "Xiaoyi", ""], ["Roli", "Fabio", ""]]}, {"id": "1910.00482", "submitter": "Di Wang", "authors": "Di Wang and Lijie Hu and Huanyu Zhang and Marco Gaboardi and Jinhui Xu", "title": "Estimating Smooth GLM in Non-interactive Local Differential Privacy\n  Model with Public Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the problem of estimating smooth Generalized Linear\nModels (GLM) in the Non-interactive Local Differential Privacy (NLDP) model.\nDifferent from its classical setting, our model allows the server to access\nsome additional public but unlabeled data. By using Stein's lemma and its\nvariants, we first show that there is an $(\\epsilon, \\delta)$-NLDP algorithm\nfor GLM (under some mild assumptions), if each data record is i.i.d sampled\nfrom some sub-Gaussian distribution with bounded $\\ell_1$-norm. Then with high\nprobability, the sample complexity of the public and private data, for the\nalgorithm to achieve an $\\alpha$ estimation error (in $\\ell_\\infty$-norm), is\n$O(p^2\\alpha^{-2})$ and ${O}(p^2\\alpha^{-2}\\epsilon^{-2})$, respectively, if\n$\\alpha$ is not too small ({\\em i.e.,} $\\alpha\\geq\n\\Omega(\\frac{1}{\\sqrt{p}})$), where $p$ is the dimensionality of the data. This\nis a significant improvement over the previously known quasi-polynomial (in\n$\\alpha$) or exponential (in $p$) complexity of GLM with no public data. Also,\nour algorithm can answer multiple (at most $\\exp(O(p))$) GLM queries with the\nsame sample complexities as in the one GLM query case with at least constant\nprobability. We then extend our idea to the non-linear regression problem and\nshow a similar phenomenon for it. Finally, we demonstrate the effectiveness of\nour algorithms through experiments on both synthetic and real world datasets.\nTo our best knowledge, this is the first paper showing the existence of\nefficient and effective algorithms for GLM and non-linear regression in the\nNLDP model with public unlabeled data.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 15:31:15 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 16:15:36 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 14:08:52 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Wang", "Di", ""], ["Hu", "Lijie", ""], ["Zhang", "Huanyu", ""], ["Gaboardi", "Marco", ""], ["Xu", "Jinhui", ""]]}, {"id": "1910.00500", "submitter": "Alexey Gy\\\"ori", "authors": "Alexey Gy\\\"ori, Mathis Niederau, Violett Zeller, Volker Stich", "title": "Evaluation of Deep Learning-based prediction models in Microgrids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is crucial today that economies harness renewable energies and integrate\nthem into the existing grid. Conventionally, energy has been generated based on\nforecasts of peak and low demands. Renewable energy can neither be produced on\ndemand nor stored efficiently. Thus, the aim of this paper is to evaluate Deep\nLearning-based forecasts of energy consumption to align energy consumption with\nrenewable energy production. Using a dataset from a use-case related to\nlandfill leachate management, multiple prediction models were used to forecast\nenergy demand.The results were validated based on the same dataset from the\nrecycling industry. Shallow models showed the lowest Mean Absolute Percentage\nError (MAPE), significantly outperforming a persistence baseline for both,\nlong-term (30 days), mid-term (7 days) and short-term (1 day) forecasts. A\npotential decrease of up to 23% in peak energy demand was found that could lead\nto a reduction of 3,091 kg in CO2-emissions per year. Our approach requires low\nfinanacial investments for energy-management hardware, making it suitable for\nusage in Small and Medium sized Enterprises (SMEs).\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:55:30 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Gy\u00f6ri", "Alexey", ""], ["Niederau", "Mathis", ""], ["Zeller", "Violett", ""], ["Stich", "Volker", ""]]}, {"id": "1910.00511", "submitter": "Yang Zhang", "authors": "Yang Zhang, Shiyu Chang, Mo Yu, Kaizhi Qian", "title": "An Efficient and Margin-Approaching Zero-Confidence Adversarial Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two major paradigms of white-box adversarial attacks that attempt\nto impose input perturbations. The first paradigm, called the fix-perturbation\nattack, crafts adversarial samples within a given perturbation level. The\nsecond paradigm, called the zero-confidence attack, finds the smallest\nperturbation needed to cause mis-classification, also known as the margin of an\ninput feature. While the former paradigm is well-resolved, the latter is not.\nExisting zero-confidence attacks either introduce significant ap-proximation\nerrors, or are too time-consuming. We therefore propose MARGINATTACK, a\nzero-confidence attack framework that is able to compute the margin with\nimproved accuracy and efficiency. Our experiments show that MARGINATTACK is\nable to compute a smaller margin than the state-of-the-art zero-confidence\nattacks, and matches the state-of-the-art fix-perturbation at-tacks. In\naddition, it runs significantly faster than the Carlini-Wagner attack,\ncurrently the most ac-curate zero-confidence attack algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 15:59:52 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Zhang", "Yang", ""], ["Chang", "Shiyu", ""], ["Yu", "Mo", ""], ["Qian", "Kaizhi", ""]]}, {"id": "1910.00514", "submitter": "Alexis Duburcq", "authors": "Alexis Duburcq, Yann Chevaleyre, Nicolas Bredeche and Guilhem Bo\\'eris", "title": "Online Trajectory Planning Through Combined Trajectory Optimization and\n  Function Approximation: Application to the Exoskeleton Atalante", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous robots require online trajectory planning capability to operate in\nthe real world. Efficient offline trajectory planning methods already exist,\nbut are computationally demanding, preventing their use online. In this paper,\nwe present a novel algorithm called Guided Trajectory Learning that learns a\nfunction approximation of solutions computed through trajectory optimization\nwhile ensuring accurate and reliable predictions. This function approximation\nis then used online to generate trajectories. This algorithm is designed to be\neasy to implement, and practical since it does not require massive computing\npower. It is readily applicable to any robotics systems and effortless to set\nup on real hardware since robust control strategies are usually already\navailable. We demonstrate the computational performance of our algorithm on\nflat-foot walking with the self-balanced exoskeleton Atalante.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 16:06:21 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 12:10:53 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 11:35:42 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Duburcq", "Alexis", ""], ["Chevaleyre", "Yann", ""], ["Bredeche", "Nicolas", ""], ["Bo\u00e9ris", "Guilhem", ""]]}, {"id": "1910.00515", "submitter": "Bahman Mirheidari", "authors": "Bahman Mirheidari and Yilin Pan and Traci Walker and Markus Reuber and\n  Annalena Venneri and Daniel Blackburn and Heidi Christensen", "title": "Detecting Alzheimer's Disease by estimating attention and elicitation\n  path through the alignment of spoken picture descriptions with the picture\n  prompt", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive decline is a sign of Alzheimer's disease (AD), and there is\nevidence that tracking a person's eye movement, using eye tracking devices, can\nbe used for the automatic identification of early signs of cognitive decline.\nHowever, such devices are expensive and may not be easy-to-use for people with\ncognitive problems. In this paper, we present a new way of capturing similar\nvisual features, by using the speech of people describing the Cookie Theft\npicture - a common cognitive testing task - to identify regions in the picture\nprompt that will have caught the speaker's attention and elicited their speech.\nAfter aligning the automatically recognised words with different regions of the\npicture prompt, we extract information inspired by eye tracking metrics such as\ncoordinates of the area of interests (AOI)s, time spent in AOI, time to reach\nthe AOI, and the number of AOI visits. Using the DementiaBank dataset we train\na binary classifier (AD vs. healthy control) using 10-fold cross-validation and\nachieve an 80% F1-score using the timing information from the forced alignments\nof the automatic speech recogniser (ASR); this achieved around 72% using the\ntiming information from the ASR outputs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 16:06:44 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Mirheidari", "Bahman", ""], ["Pan", "Yilin", ""], ["Walker", "Traci", ""], ["Reuber", "Markus", ""], ["Venneri", "Annalena", ""], ["Blackburn", "Daniel", ""], ["Christensen", "Heidi", ""]]}, {"id": "1910.00517", "submitter": "Juho Lauri", "authors": "Marco Grassia, Juho Lauri, Sourav Dutta, Deepak Ajwani", "title": "Learning Multi-Stage Sparsification for Maximum Clique Enumeration", "comments": "Appeared at the Data Science Meets Optimization Workshop (DSO) at\n  IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-stage learning approach for pruning the search space of\nmaximum clique enumeration, a fundamental computationally difficult problem\narising in various network analysis tasks. In each stage, our approach learns\nthe characteristics of vertices in terms of various neighborhood features and\nleverage them to prune the set of vertices that are likely not contained in any\nmaximum clique. Furthermore, we demonstrate that our approach is domain\nindependent -- the same small set of features works well on graph instances\nfrom different domain. Compared to the state-of-the-art heuristics and\npreprocessing strategies, the advantages of our approach are that (i) it does\nnot require any estimate on the maximum clique size at runtime and (ii) we\ndemonstrate it to be effective also for dense graphs. In particular, for dense\ngraphs, we typically prune around 30 \\% of the vertices resulting in speedups\nof up to 53 times for state-of-the-art solvers while generally preserving the\nsize of the maximum clique (though some maximum cliques may be lost). For large\nreal-world sparse graphs, we routinely prune over 99 \\% of the vertices\nresulting in several tenfold speedups at best, typically with no impact on\nsolution quality.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:39:04 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Grassia", "Marco", ""], ["Lauri", "Juho", ""], ["Dutta", "Sourav", ""], ["Ajwani", "Deepak", ""]]}, {"id": "1910.00528", "submitter": "Shruti Mishra", "authors": "Shruti Mishra, Abbas Abdolmaleki, Arthur Guez, Piotr Trochim, Doina\n  Precup", "title": "Augmenting learning using symmetry in a biologically-inspired domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Invariances to translation, rotation and other spatial transformations are a\nhallmark of the laws of motion, and have widespread use in the natural sciences\nto reduce the dimensionality of systems of equations. In supervised learning,\nsuch as in image classification tasks, rotation, translation and scale\ninvariances are used to augment training datasets. In this work, we use data\naugmentation in a similar way, exploiting symmetry in the quadruped domain of\nthe DeepMind control suite (Tassa et al. 2018) to add to the trajectories\nexperienced by the actor in the actor-critic algorithm of Abdolmaleki et al.\n(2018). In a data-limited regime, the agent using a set of experiences\naugmented through symmetry is able to learn faster. Our approach can be used to\ninject knowledge of invariances in the domain and task to augment learning in\nrobots, and more generally, to speed up learning in realistic robotics\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 16:29:14 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Mishra", "Shruti", ""], ["Abdolmaleki", "Abbas", ""], ["Guez", "Arthur", ""], ["Trochim", "Piotr", ""], ["Precup", "Doina", ""]]}, {"id": "1910.00535", "submitter": "Vaios Laschos Dr", "authors": "Vaios Laschos, Jan Tinapp, Klaus Obermayer", "title": "Training Generative Networks with general Optimal Transport distances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm that uses an auxiliary neural network to express\nthe potential of the optimal transport map between two data distributions. In\nthe sequel, we use the aforementioned map to train generative networks. Unlike\nWGANs, where the Euclidean distance is ${\\it implicitly}$ used, this new method\nallows to ${\\it explicitly}$ use ${\\it any}$ transportation cost function that\ncan be chosen to match the problem at hand. For example, it allows to use the\nsquared distance as a transportation cost function, giving rise to the\nWasserstein-2 metric for probability distributions, which results in fast and\nstable gradient descends. It also allows to use image centered distances, like\nthe structure similarity index, with notable differences in the results.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 16:39:50 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 17:37:34 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 10:03:04 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Laschos", "Vaios", ""], ["Tinapp", "Jan", ""], ["Obermayer", "Klaus", ""]]}, {"id": "1910.00547", "submitter": "Bruno Ribeiro", "authors": "S Chandra Mouli, Leonardo Teixeira, Jennifer Neville, Bruno Ribeiro", "title": "Deep Lifetime Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of lifetime clustering is to develop an inductive model that maps\nsubjects into $K$ clusters according to their underlying (unobserved) lifetime\ndistribution. We introduce a neural-network based lifetime clustering model\nthat can find cluster assignments by directly maximizing the divergence between\nthe empirical lifetime distributions of the clusters. Accordingly, we define a\nnovel clustering loss function over the lifetime distributions (of entire\nclusters) based on a tight upper bound of the two-sample Kuiper test p-value.\nThe resultant model is robust to the modeling issues associated with the\nunobservability of termination signals, and does not assume proportional\nhazards. Our results in real and synthetic datasets show significantly better\nlifetime clusters (as evaluated by C-index, Brier Score, Logrank score and\nadjusted Rand index) as compared to competing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:10:16 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 02:57:43 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Mouli", "S Chandra", ""], ["Teixeira", "Leonardo", ""], ["Neville", "Jennifer", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "1910.00551", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Nicolas Flammarion, Martin J. Wainwright, Peter L.\n  Bartlett", "title": "An Efficient Sampling Algorithm for Non-smooth Composite Potentials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sampling from a density of the form $p(x) \\propto\n\\exp(-f(x)- g(x))$, where $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}$ is a smooth\nand strongly convex function and $g: \\mathbb{R}^d \\rightarrow \\mathbb{R}$ is a\nconvex and Lipschitz function. We propose a new algorithm based on the\nMetropolis-Hastings framework, and prove that it mixes to within TV distance\n$\\varepsilon$ of the target density in at most $O(d \\log (d/\\varepsilon))$\niterations. This guarantee extends previous results on sampling from\ndistributions with smooth log densities ($g = 0$) to the more general composite\nnon-smooth case, with the same mixing time up to a multiple of the condition\nnumber. Our method is based on a novel proximal-based proposal distribution\nthat can be efficiently computed for a large class of non-smooth functions $g$.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:25:55 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Mou", "Wenlong", ""], ["Flammarion", "Nicolas", ""], ["Wainwright", "Martin J.", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "1910.00553", "submitter": "Lei Yu", "authors": "Lei Yu, Laurent Sartran, Wojciech Stokowiec, Wang Ling, Lingpeng Kong,\n  Phil Blunsom, Chris Dyer", "title": "Better Document-Level Machine Translation with Bayes' Rule", "comments": "Accepted by TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that Bayes' rule provides an effective mechanism for creating\ndocument translation models that can be learned from only parallel sentences\nand monolingual documents---a compelling benefit as parallel documents are not\nalways available. In our formulation, the posterior probability of a candidate\ntranslation is the product of the unconditional (prior) probability of the\ncandidate output document and the \"reverse translation probability\" of\ntranslating the candidate output back into the source language. Our proposed\nmodel uses a powerful autoregressive language model as the prior on target\nlanguage documents, but it assumes that each sentence is translated\nindependently from the target to the source language. Crucially, at test time,\nwhen a source document is observed, the document language model prior induces\ndependencies between the translations of the source sentences in the posterior.\nThe model's independence assumption not only enables efficient use of available\ndata, but it additionally admits a practical left-to-right beam-search\nalgorithm for carrying out inference. Experiments show that our model benefits\nfrom using cross-sentence context in the language model, and it outperforms\nexisting document translation approaches.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:30:56 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 10:47:17 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Yu", "Lei", ""], ["Sartran", "Laurent", ""], ["Stokowiec", "Wojciech", ""], ["Ling", "Wang", ""], ["Kong", "Lingpeng", ""], ["Blunsom", "Phil", ""], ["Dyer", "Chris", ""]]}, {"id": "1910.00565", "submitter": "Shahram Ghorbani", "authors": "Shahram Ghorbani, Soheil Khorram, John H.L. Hansen", "title": "Domain Expansion in DNN-based Acoustic Models for Robust Speech\n  Recognition", "comments": "Accepted at ASRU, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training acoustic models with sequentially incoming data -- while both\nleveraging new data and avoiding the forgetting effect-- is an essential\nobstacle to achieving human intelligence level in speech recognition. An\nobvious approach to leverage data from a new domain (e.g., new accented speech)\nis to first generate a comprehensive dataset of all domains, by combining all\navailable data, and then use this dataset to retrain the acoustic models.\nHowever, as the amount of training data grows, storing and retraining on such a\nlarge-scale dataset becomes practically impossible. To deal with this problem,\nin this study, we study several domain expansion techniques which exploit only\nthe data of the new domain to build a stronger model for all domains. These\ntechniques are aimed at learning the new domain with a minimal forgetting\neffect (i.e., they maintain original model performance). These techniques\nmodify the adaptation procedure by imposing new constraints including (1)\nweight constraint adaptation (WCA): keeping the model parameters close to the\noriginal model parameters; (2) elastic weight consolidation (EWC): slowing down\ntraining for parameters that are important for previously established domains;\n(3) soft KL-divergence (SKLD): restricting the KL-divergence between the\noriginal and the adapted model output distributions; and (4) hybrid SKLD-EWC:\nincorporating both SKLD and EWC constraints. We evaluate these techniques in an\naccent adaptation task in which we adapt a deep neural network (DNN) acoustic\nmodel trained with native English to three different English accents:\nAustralian, Hispanic, and Indian. The experimental results show that SKLD\nsignificantly outperforms EWC, and EWC works better than WCA. The hybrid\nSKLD-EWC technique results in the best overall performance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:40:49 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Ghorbani", "Shahram", ""], ["Khorram", "Soheil", ""], ["Hansen", "John H. L.", ""]]}, {"id": "1910.00577", "submitter": "Uri Alon", "authors": "Uri Alon, Roy Sadaka, Omer Levy, Eran Yahav", "title": "Structural Language Models of Code", "comments": "Appeared in ICML'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of any-code completion - generating a missing piece of\nsource code in a given program without any restriction on the vocabulary or\nstructure. We introduce a new approach to any-code completion that leverages\nthe strict syntax of programming languages to model a code snippet as a tree -\nstructural language modeling (SLM). SLM estimates the probability of the\nprogram's abstract syntax tree (AST) by decomposing it into a product of\nconditional probabilities over its nodes. We present a neural model that\ncomputes these conditional probabilities by considering all AST paths leading\nto a target node. Unlike previous techniques that have severely restricted the\nkinds of expressions that can be generated in this task, our approach can\ngenerate arbitrary code in any programming language. Our model significantly\noutperforms both seq2seq and a variety of structured approaches in generating\nJava and C# code. Our code, data, and trained models are available at\nhttp://github.com/tech-srl/slm-code-generation/ . An online demo is available\nat http://AnyCodeGen.org .\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 18:54:07 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 09:07:27 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 09:04:07 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2020 12:15:33 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Alon", "Uri", ""], ["Sadaka", "Roy", ""], ["Levy", "Omer", ""], ["Yahav", "Eran", ""]]}, {"id": "1910.00579", "submitter": "Jesse Zhang", "authors": "Daiyaan Arfeen, Jesse Zhang", "title": "Unsupervised Projection Networks for Generative Adversarial Networks", "comments": "6 Pages, 8 Figures, ICCV 2019 Workshop: Sensing, Understanding and\n  Synthesizing Humans", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of unsupervised learning to train projection networks that\nproject onto the latent space of an already trained generator. We apply our\nmethod to a trained StyleGAN, and use our projection network to perform image\nsuper-resolution and clustering of images into semantically identifiable\ngroups.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 23:31:46 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 17:08:33 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Arfeen", "Daiyaan", ""], ["Zhang", "Jesse", ""]]}, {"id": "1910.00582", "submitter": "Xi Yang", "authors": "Xi Yang, Yan Gong, Nida Waheed, Keith March, Jiang Bian, William R.\n  Hogan, Yonghui Wu", "title": "Identifying Cancer Patients at Risk for Heart Failure Using Machine\n  Learning Methods", "comments": "6 pages, 1 figure, 3 tables, accepted by AMIA 2019", "journal-ref": "AMIA Annu Symp Proc (2019) 933-941", "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiotoxicity related to cancer therapies has become a serious issue,\ndiminishing cancer treatment outcomes and quality of life. Early detection of\ncancer patients at risk for cardiotoxicity before cardiotoxic treatments and\nproviding preventive measures are potential solutions to improve cancer\npatients's quality of life. This study focuses on predicting the development of\nheart failure in cancer patients after cancer diagnoses using historical\nelectronic health record (EHR) data. We examined four machine learning\nalgorithms using 143,199 cancer patients from the University of Florida Health\n(UF Health) Integrated Data Repository (IDR). We identified a total number of\n1,958 qualified cases and matched them to 15,488 controls by gender, age, race,\nand major cancer type. Two feature encoding strategies were compared to encode\nvariables as machine learning features. The gradient boosting (GB) based model\nachieved the best AUC score of 0.9077 (with a sensitivity of 0.8520 and a\nspecificity of 0.8138), outperforming other machine learning methods. We also\nlooked into the subgroup of cancer patients with exposure to chemotherapy drugs\nand observed a lower specificity score (0.7089). The experimental results show\nthat machine learning methods are able to capture clinical factors that are\nknown to be associated with heart failure and that it is feasible to use\nmachine learning methods to identify cancer patients at risk for cancer\ntherapy-related heart failure.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 12:13:04 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Yang", "Xi", ""], ["Gong", "Yan", ""], ["Waheed", "Nida", ""], ["March", "Keith", ""], ["Bian", "Jiang", ""], ["Hogan", "William R.", ""], ["Wu", "Yonghui", ""]]}, {"id": "1910.00584", "submitter": "Arpan Kusari", "authors": "Arpan Kusari", "title": "CWAE-IRL: Formulating a supervised approach to Inverse Reinforcement\n  Learning problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) is used to infer the reward function\nfrom the actions of an expert running a Markov Decision Process (MDP). A novel\napproach using variational inference for learning the reward function is\nproposed in this research. Using this technique, the intractable posterior\ndistribution of the continuous latent variable (the reward function in this\ncase) is analytically approximated to appear to be as close to the prior belief\nwhile trying to reconstruct the future state conditioned on the current state\nand action. The reward function is derived using a well-known deep generative\nmodel known as Conditional Variational Auto-encoder (CVAE) with Wasserstein\nloss function, thus referred to as Conditional Wasserstein Auto-encoder-IRL\n(CWAE-IRL), which can be analyzed as a combination of the backward and forward\ninference. This can then form an efficient alternative to the previous\napproaches to IRL while having no knowledge of the system dynamics of the\nagent. Experimental results on standard benchmarks such as objectworld and\npendulum show that the proposed algorithm can effectively learn the latent\nreward function in complex, high-dimensional environments.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:06:23 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Kusari", "Arpan", ""]]}, {"id": "1910.00617", "submitter": "Rhys Goodall", "authors": "Rhys E. A. Goodall and Alpha A. Lee", "title": "Predicting materials properties without crystal structure: Deep\n  representation learning from stoichiometry", "comments": "A working implementation of our model is available at\n  https://github.com/CompRhys/roost", "journal-ref": null, "doi": "10.1038/s41467-020-19964-7", "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has the potential to accelerate materials discovery by\naccurately predicting materials properties at a low computational cost.\nHowever, the model inputs remain a key stumbling block. Current methods\ntypically use descriptors constructed from knowledge of either the full crystal\nstructure -- therefore only applicable to materials with already characterised\nstructures -- or structure-agnostic fixed-length representations\nhand-engineered from the stoichiometry. We develop a machine learning approach\nthat takes only the stoichiometry as input and automatically learns appropriate\nand systematically improvable descriptors from data. Our key insight is to\ntreat the stoichiometric formula as a dense weighted graph between elements.\nCompared to the state of the art for structure-agnostic methods, our approach\nachieves lower errors with less data.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 18:52:54 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 05:43:55 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 11:26:39 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 17:16:56 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Goodall", "Rhys E. A.", ""], ["Lee", "Alpha A.", ""]]}, {"id": "1910.00618", "submitter": "Maria Bauza", "authors": "Maria Bauza, Ferran Alet, Yen-Chen Lin, Tomas Lozano-Perez, Leslie P.\n  Kaelbling, Phillip Isola, and Alberto Rodriguez", "title": "Omnipush: accurate, diverse, real-world dataset of pushing dynamics with\n  RGB-D video", "comments": "IROS 2019, 8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pushing is a fundamental robotic skill. Existing work has shown how to\nexploit models of pushing to achieve a variety of tasks, including grasping\nunder uncertainty, in-hand manipulation and clearing clutter. Such models,\nhowever, are approximate, which limits their applicability.\n  Learning-based methods can reason directly from raw sensory data with\naccuracy, and have the potential to generalize to a wider diversity of\nscenarios. However, developing and testing such methods requires rich-enough\ndatasets. In this paper we introduce Omnipush, a dataset with high variety of\nplanar pushing behavior.\n  In particular, we provide 250 pushes for each of 250 objects, all recorded\nwith RGB-D and a high precision tracking system. The objects are constructed so\nas to systematically explore key factors that affect pushing --the shape of the\nobject and its mass distribution-- which have not been broadly explored in\nprevious datasets, and allow to study generalization in model learning.\n  Omnipush includes a benchmark for meta-learning dynamic models, which\nrequires algorithms that make good predictions and estimate their own\nuncertainty. We also provide an RGB video prediction benchmark and propose\nother relevant tasks that can be suited with this dataset.\n  Data and code are available at\n\\url{https://web.mit.edu/mcube/omnipush-dataset/}.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 18:58:19 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Bauza", "Maria", ""], ["Alet", "Ferran", ""], ["Lin", "Yen-Chen", ""], ["Lozano-Perez", "Tomas", ""], ["Kaelbling", "Leslie P.", ""], ["Isola", "Phillip", ""], ["Rodriguez", "Alberto", ""]]}, {"id": "1910.00623", "submitter": "Gabriel Terejanu", "authors": "Asif J. Chowdhury, Wenqiang Yang, Kareem E. Abdelfatah, Mehdi Zare,\n  Andreas Heyden, Gabriel Terejanu", "title": "A Multiple Filter Based Neural Network Approach to the Extrapolation of\n  Adsorption Energies on Metal Surfaces for Catalysis Applications", "comments": null, "journal-ref": "J. Chem. Theory Comput 16 (2020) 1105-1114", "doi": "10.1021/acs.jctc.9b00986", "report-no": null, "categories": "physics.chem-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational catalyst discovery involves the development of microkinetic\nreactor models based on estimated parameters determined from density functional\ntheory (DFT). For complex surface chemistries, the cost of calculating the\nadsorption energies by DFT for a large number of reaction intermediates can\nbecome prohibitive. Here, we have identified appropriate descriptors and\nmachine learning models that can be used to predict part of these adsorption\nenergies given data on the rest of them. Our investigations also included the\ncase when the species data used to train the predictive model is of different\nsize relative to the species the model tries to predict - an extrapolation in\nthe data space which is typically difficult with regular machine learning\nmodels. We have developed a neural network based predictive model that combines\nan established model with the concepts of a convolutional neural network that,\nwhen extrapolating, achieves significant improvement over the previous models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 19:09:57 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Chowdhury", "Asif J.", ""], ["Yang", "Wenqiang", ""], ["Abdelfatah", "Kareem E.", ""], ["Zare", "Mehdi", ""], ["Heyden", "Andreas", ""], ["Terejanu", "Gabriel", ""]]}, {"id": "1910.00628", "submitter": "Athma Lakshmi Narayanan", "authors": "Athma Narayanan, Avinash Siravuru, Behzad Dariush", "title": "Sensor Fusion: Gated Recurrent Fusion to Learn Driving Behavior from\n  Temporal Multimodal Data", "comments": "Accepted to Robotics and Automation Letters 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Tactical Driver Behavior modeling problem requires understanding of\ndriver actions in complicated urban scenarios from a rich multi modal signals\nincluding video, LiDAR and CAN bus data streams. However, the majority of deep\nlearning research is focused either on learning the vehicle/environment state\n(sensor fusion) or the driver policy (from temporal data), but not both.\nLearning both tasks end-to-end offers the richest distillation of knowledge,\nbut presents challenges in formulation and successful training. In this work,\nwe propose promising first steps in this direction. Inspired by the gating\nmechanisms in LSTM, we propose gated recurrent fusion units (GRFU) that learn\nfusion weighting and temporal weighting simultaneously. We demonstrate it's\nsuperior performance over multimodal and temporal baselines in supervised\nregression and classification tasks, all in the realm of autonomous navigation.\nWe note a 10% improvement in the mAP score over state-of-the-art for tactical\ndriver behavior classification in HDD dataset and a 20% drop in overall Mean\nsquared error for steering action regression on TORCS dataset.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 19:34:09 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 17:31:55 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Narayanan", "Athma", ""], ["Siravuru", "Avinash", ""], ["Dariush", "Behzad", ""]]}, {"id": "1910.00643", "submitter": "Jianyu Wang", "authors": "Jianyu Wang, Vinayak Tantia, Nicolas Ballas, Michael Rabbat", "title": "SlowMo: Improving Communication-Efficient Distributed SGD with Slow\n  Momentum", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed optimization is essential for training large models on large\ndatasets. Multiple approaches have been proposed to reduce the communication\noverhead in distributed training, such as synchronizing only after performing\nmultiple local SGD steps, and decentralized methods (e.g., using gossip\nalgorithms) to decouple communications among workers. Although these methods\nrun faster than AllReduce-based methods, which use blocking communication\nbefore every update, the resulting models may be less accurate after the same\nnumber of updates. Inspired by the BMUF method of Chen & Huo (2016), we propose\na slow momentum (SlowMo) framework, where workers periodically synchronize and\nperform a momentum update, after multiple iterations of a base optimization\nalgorithm. Experiments on image classification and machine translation tasks\ndemonstrate that SlowMo consistently yields improvements in optimization and\ngeneralization performance relative to the base optimizer, even when the\nadditional overhead is amortized over many updates so that the SlowMo runtime\nis on par with that of the base optimizer. We provide theoretical convergence\nguarantees showing that SlowMo converges to a stationary point of smooth\nnon-convex losses. Since BMUF can be expressed through the SlowMo framework,\nour results also correspond to the first theoretical convergence guarantees for\nBMUF.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 20:06:48 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 20:00:02 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Jianyu", ""], ["Tantia", "Vinayak", ""], ["Ballas", "Nicolas", ""], ["Rabbat", "Michael", ""]]}, {"id": "1910.00650", "submitter": "Xiaobo Qu", "authors": "Tieyuan Lu, Xinlin Zhang, Yihui Huang, Yonggui Yang, Gang Guo, Lijun\n  Bao, Feng Huang, Di Guo, Xiaobo Qu", "title": "pISTA-SENSE-ResNet for Parallel MRI Reconstruction", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmr.2020.106790", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance imaging has been widely applied in clinical diagnosis,\nhowever, is limited by its long data acquisition time. Although imaging can be\naccelerated by sparse sampling and parallel imaging, achieving promising\nreconstruction images with a fast reconstruction speed remains a challenge.\nRecently, deep learning approaches have attracted a lot of attention for its\nencouraging reconstruction results but without a proper interpretability. In\nthis letter, to enable high-quality image reconstruction for the parallel\nmagnetic resonance imaging, we design the network structure from the\nperspective of sparse iterative reconstruction and enhance it with the residual\nstructure. The experimental results of a public knee dataset show that compared\nwith the optimization-based method and the latest deep learning parallel\nimaging methods, the proposed network has less error in reconstruction and is\nmore stable under different acceleration factors.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 15:18:05 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lu", "Tieyuan", ""], ["Zhang", "Xinlin", ""], ["Huang", "Yihui", ""], ["Yang", "Yonggui", ""], ["Guo", "Gang", ""], ["Bao", "Lijun", ""], ["Huang", "Feng", ""], ["Guo", "Di", ""], ["Qu", "Xiaobo", ""]]}, {"id": "1910.00659", "submitter": "Aaron Griffith", "authors": "Aaron Griffith, Andrew Pomerance, Daniel J. Gauthier", "title": "Forecasting Chaotic Systems with Very Low Connectivity Reservoir\n  Computers", "comments": null, "journal-ref": null, "doi": "10.1063/1.5120710", "report-no": null, "categories": "cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the hyperparameter space of reservoir computers used for\nforecasting of the chaotic Lorenz '63 attractor with Bayesian optimization. We\nuse a new measure of reservoir performance, designed to emphasize learning the\nglobal climate of the forecasted system rather than short-term prediction. We\nfind that optimizing over this measure more quickly excludes reservoirs that\nfail to reproduce the climate. The results of optimization are surprising: the\noptimized parameters often specify a reservoir network with very low\nconnectivity. Inspired by this observation, we explore reservoir designs with\neven simpler structure, and find well-performing reservoirs that have zero\nspectral radius and no recurrence. These simple reservoirs provide\ncounterexamples to widely used heuristics in the field, and may be useful for\nhardware implementations of reservoir computers.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 20:39:25 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 19:51:35 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Griffith", "Aaron", ""], ["Pomerance", "Andrew", ""], ["Gauthier", "Daniel J.", ""]]}, {"id": "1910.00662", "submitter": "Hao-Chih Lee", "authors": "Hao-Chih Lee, Sarah T Cherng, Riccardo Miotto, Joel T Dudley", "title": "Enhancing high-content imaging for studying microtubule networks at\n  large-scale", "comments": "accepted and presented in Machine Learning for Healthcare 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Given the crucial role of microtubules for cell survival, many researchers\nhave found success using microtubule-targeting agents in the search for\neffective cancer therapeutics. Understanding microtubule responses to targeted\ninterventions requires that the microtubule network within cells can be\nconsistently observed across a large sample of images. However, fluorescence\nnoise sources captured simultaneously with biological signals while using\nwide-field microscopes can obfuscate fine microtubule structures. Such\nrequirements are particularly challenging for high-throughput imaging, where\nresearchers must make decisions related to the trade-off between imaging\nquality and speed. Here, we propose a computational framework to enhance the\nquality of high-throughput imaging data to achieve fast speed and high quality\nsimultaneously. Using CycleGAN, we learn an image model from low-throughput,\nhigh-resolution images to enhance features, such as microtubule networks in\nhigh-throughput low-resolution images. We show that CycleGAN is effective in\nidentifying microtubules with 0.93+ AUC-ROC and that these results are robust\nto different kinds of image noise. We further apply CycleGAN to quantify the\nchanges in microtubule density as a result of the application of drug\ncompounds, and show that the quantified responses correspond well with known\ndrug effects\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 20:43:39 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Lee", "Hao-Chih", ""], ["Cherng", "Sarah T", ""], ["Miotto", "Riccardo", ""], ["Dudley", "Joel T", ""]]}, {"id": "1910.00668", "submitter": "Andrew Carr", "authors": "Andrew Carr and Jared Nielsen and David Wingate", "title": "Wasserstein Neural Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Processes (NPs) are a class of models that learn a mapping from a\ncontext set of input-output pairs to a distribution over functions. They are\ntraditionally trained using maximum likelihood with a KL divergence\nregularization term. We show that there are desirable classes of problems where\nNPs, with this loss, fail to learn any reasonable distribution. We also show\nthat this drawback is solved by using approximations of Wasserstein distance\nwhich calculates optimal transport distances even for distributions of disjoint\nsupport. We give experimental justification for our method and demonstrate\nperformance. These Wasserstein Neural Processes (WNPs) maintain all of the\nbenefits of traditional NPs while being able to approximate a new class of\nfunction mappings.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 21:13:10 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 00:28:06 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Carr", "Andrew", ""], ["Nielsen", "Jared", ""], ["Wingate", "David", ""]]}, {"id": "1910.00696", "submitter": "Eric Carver", "authors": "Eric Carver, Zhenzhen Dai, Evan Liang, James Snyder, Ning Wen", "title": "Improvement of Multiparametric MR Image Segmentation by Augmenting the\n  Data with Generative Adversarial Networks for Glioma Patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every year thousands of patients are diagnosed with a glioma, a type of\nmalignant brain tumor. Physicians use MR images as a key tool in the diagnosis\nand treatment of these patients. Neural networks show great potential to aid\nphysicians in the medical image analysis. This study investigates the use of\nvarying amounts of synthetic brain T1-weighted (T1), post-contrast T1-weighted\n(T1Gd), T2-weighted (T2), and T2 Fluid Attenuated Inversion Recovery (FLAIR) MR\nimages created by a generative adversarial network to overcome the lack of\nannotated medical image data in training separate 2D U-Nets to segment\nenhancing tumor, peritumoral edema, and necrosis (non-enhancing tumor core)\nregions on gliomas. These synthetic MR images were assessed quantitively\n(SSIM=0.79) and qualitatively by a physician who found that the synthetic\nimages seem stronger for delineation of structural boundaries but struggle more\nwhen gradient is significant, (e.g. edema signal in T2 modalities). Multiple 2D\nU-Nets were trained with original BraTS data and differing subsets of a\nquarter, half, three-quarters, and all synthetic MR images. There was not an\nobvious correlation between the improvement of values of the metrics in\nseparate validation dataset for each structure and amount of synthetic data\nadded, there is a strong correlation between the amount of synthetic data added\nand the number of best overall validation metrics. In summary, this study\nshowed ability to generate high quality synthetic Flair, T2, T1, and T1CE MR\nimages using the GAN. Using the synthetic MR images showed encouraging results\nto improve the U-Net segmentation performance which has the potential to\naddress the scarcity of readily available medical images.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 22:14:25 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Carver", "Eric", ""], ["Dai", "Zhenzhen", ""], ["Liang", "Evan", ""], ["Snyder", "James", ""], ["Wen", "Ning", ""]]}, {"id": "1910.00698", "submitter": "Chaochao Yan", "authors": "Chaochao Yan and Sheng Wang and Jinyu Yang and Tingyang Xu and Junzhou\n  Huang", "title": "Re-balancing Variational Autoencoder Loss for Molecule Sequence\n  Generation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecule generation is to design new molecules with specific chemical\nproperties and further to optimize the desired chemical properties. Following\nprevious work, we encode molecules into continuous vectors in the latent space\nand then decode the vectors into molecules under the variational autoencoder\n(VAE) framework. We investigate the posterior collapse problem of current\nRNN-based VAEs for molecule sequence generation. For the first time, we find\nthat underestimated reconstruction loss leads to posterior collapse, and\nprovide both theoretical and experimental evidence. We propose an effective and\nefficient solution to fix the problem and avoid posterior collapse. Without\nbells and whistles, our method achieves SOTA reconstruction accuracy and\ncompetitive validity on the ZINC 250K dataset. When generating 10,000 unique\nvalid SMILES from random prior sampling, it costs JT-VAE1450s while our method\nonly needs 9s. Our implementation is at\nhttps://github.com/chaoyan1037/Re-balanced-VAE.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 22:17:50 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 11:25:44 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Yan", "Chaochao", ""], ["Wang", "Sheng", ""], ["Yang", "Jinyu", ""], ["Xu", "Tingyang", ""], ["Huang", "Junzhou", ""]]}, {"id": "1910.00700", "submitter": "Ali Mirzaeian", "authors": "Ali Mirzaeian, Houman Homayoun, Avesta Sasan", "title": "NESTA: Hamming Weight Compression-Based Neural Proc. Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we present NESTA, a specialized Neural engine that\nsignificantly accelerates the computation of convolution layers in a deep\nconvolutional neural network, while reducing the computational energy. NESTA\nreformats Convolutions into $3 \\times 3$ batches and uses a hierarchy of\nHamming Weight Compressors to process each batch. Besides, when processing the\nconvolution across multiple channels, NESTA, rather than computing the precise\nresult of a convolution per channel, quickly computes an approximation of its\npartial sum, and a residual value such that if added to the approximate partial\nsum, generates the accurate output. Then, instead of immediately adding the\nresidual, it uses (consumes) the residual when processing the next batch in the\nhamming weight compressors with available capacity. This mechanism shortens the\ncritical path by avoiding the need to propagate carry signals during each round\nof computation and speeds up the convolution of each channel. In the last stage\nof computation, when the partial sum of the last channel is computed, NESTA\nterminates by adding the residual bits to the approximate output to generate a\ncorrect result.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 22:32:35 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Mirzaeian", "Ali", ""], ["Homayoun", "Houman", ""], ["Sasan", "Avesta", ""]]}, {"id": "1910.00701", "submitter": "Zizhao Zhang", "authors": "Zizhao Zhang, Han Zhang, Sercan O. Arik, Honglak Lee, Tomas Pfister", "title": "Distilling Effective Supervision from Severe Label Noise", "comments": "CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collecting large-scale data with clean labels for supervised training of\nneural networks is practically challenging. Although noisy labels are usually\ncheap to acquire, existing methods suffer a lot from label noise. This paper\ntargets at the challenge of robust training at high label noise regimes. The\nkey insight to achieve this goal is to wisely leverage a small trusted set to\nestimate exemplar weights and pseudo labels for noisy data in order to reuse\nthem for supervised training. We present a holistic framework to train deep\nneural networks in a way that is highly invulnerable to label noise. Our method\nsets the new state of the art on various types of label noise and achieves\nexcellent performance on large-scale datasets with real-world label noise. For\ninstance, on CIFAR100 with a $40\\%$ uniform noise ratio and only 10 trusted\nlabeled data per class, our method achieves $80.2{\\pm}0.3\\%$ classification\naccuracy, where the error rate is only $1.4\\%$ higher than a neural network\ntrained without label noise. Moreover, increasing the noise ratio to $80\\%$,\nour method still maintains a high accuracy of $75.5{\\pm}0.2\\%$, compared to the\nprevious best accuracy $48.2\\%$.\n  Source code available:\nhttps://github.com/google-research/google-research/tree/master/ieg\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 22:34:29 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 22:06:28 GMT"}, {"version": "v3", "created": "Mon, 30 Dec 2019 23:50:48 GMT"}, {"version": "v4", "created": "Mon, 30 Mar 2020 16:59:37 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 23:58:13 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zhang", "Zizhao", ""], ["Zhang", "Han", ""], ["Arik", "Sercan O.", ""], ["Lee", "Honglak", ""], ["Pfister", "Tomas", ""]]}, {"id": "1910.00702", "submitter": "Ling Cai", "authors": "Ling Cai, Bo Yan, Gengchen Mai, Krzysztof Janowicz, Rui Zhu", "title": "TransGCN:Coupling Transformation Assumptions with Graph Convolutional\n  Networks for Link Prediction", "comments": null, "journal-ref": null, "doi": "10.1145/3360901.3364441", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is an important and frequently studied task that contributes\nto an understanding of the structure of knowledge graphs (KGs) in statistical\nrelational learning. Inspired by the success of graph convolutional networks\n(GCN) in modeling graph data, we propose a unified GCN framework, named\nTransGCN, to address this task, in which relation and entity embeddings are\nlearned simultaneously. To handle heterogeneous relations in KGs, we introduce\na novel way of representing heterogeneous neighborhood by introducing\ntransformation assumptions on the relationship between the subject, the\nrelation, and the object of a triple. Specifically, a relation is treated as a\ntransformation operator transforming a head entity to a tail entity. Both\ntranslation assumption in TransE and rotation assumption in RotatE are explored\nin our framework. Additionally, instead of only learning entity embeddings in\nthe convolution-based encoder while learning relation embeddings in the decoder\nas done by the state-of-art models, e.g., R-GCN, the TransGCN framework trains\nrelation embeddings and entity embeddings simultaneously during the graph\nconvolution operation, thus having fewer parameters compared with R-GCN.\nExperiments show that our models outperform the-state-of-arts methods on both\nFB15K-237 and WN18RR.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 22:34:40 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Cai", "Ling", ""], ["Yan", "Bo", ""], ["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Zhu", "Rui", ""]]}, {"id": "1910.00713", "submitter": "Maani Ghaffari Jadidi", "authors": "Tzu-Yuan Lin, William Clark, Ryan M. Eustice, Jessy W. Grizzle,\n  Anthony Bloch, Maani Ghaffari", "title": "Adaptive Continuous Visual Odometry from RGB-D Images", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend the recently developed continuous visual odometry\nframework for RGB-D cameras to an adaptive framework via online hyperparameter\nlearning. We focus on the case of isotropic kernels with a scalar as the\nlength-scale. In practice and as expected, the length-scale has remarkable\nimpacts on the performance of the original framework. Previously it was handled\nusing a fixed set of conditions within the solver to reduce the length-scale as\nthe algorithm reaches a local minimum. We automate this process by a greedy\ngradient descent step at each iteration to find the next-best length-scale.\nFurthermore, to handle failure cases in the gradient descent step where the\ngradient is not well-behaved, such as the absence of structure or texture in\nthe scene, we use a search interval for the length-scale and guide it gradually\ntoward the smaller values. This latter strategy reverts the adaptive framework\nto the original setup. The experimental evaluations using publicly available\nRGB-D benchmarks show the proposed adaptive continuous visual odometry\noutperforms the original framework and the current state-of-the-art. We also\nmake the software for the developed algorithm publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 23:29:16 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Lin", "Tzu-Yuan", ""], ["Clark", "William", ""], ["Eustice", "Ryan M.", ""], ["Grizzle", "Jessy W.", ""], ["Bloch", "Anthony", ""], ["Ghaffari", "Maani", ""]]}, {"id": "1910.00722", "submitter": "Sudhir Sornapudi", "authors": "Sudhir Sornapudi, G. T. Brown, Zhiyun Xue, Rodney Long, Lisa Allen,\n  Sameer Antani", "title": "Comparing Deep Learning Models for Multi-cell Classification in\n  Liquid-based Cervical Cytology Images", "comments": "AMIA 2019 Annual Symposium, Washington DC", "journal-ref": "AMIA Annu Symp Proc. 2019 (2019) 820-827", "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Liquid-based cytology (LBC) is a reliable automated technique for the\nscreening of Papanicolaou (Pap) smear data. It is an effective technique for\ncollecting a majority of the cervical cells and aiding cytopathologists in\nlocating abnormal cells. Most methods published in the research literature rely\non accurate cell segmentation as a prior, which remains challenging due to a\nvariety of factors, e.g., stain consistency, presence of clustered cells, etc.\nWe propose a method for automatic classification of cervical slide images\nthrough generation of labeled cervical patch data and extracting deep\nhierarchical features by fine-tuning convolution neural networks, as well as a\nnovel graph-based cell detection approach for cellular level evaluation. The\nresults show that the proposed pipeline can classify images of both single cell\nand overlapping cells. The VGG-19 model is found to be the best at classifying\nthe cervical cytology patch data with 95 % accuracy under precision-recall\ncurve.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 00:20:23 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Sornapudi", "Sudhir", ""], ["Brown", "G. T.", ""], ["Xue", "Zhiyun", ""], ["Long", "Rodney", ""], ["Allen", "Lisa", ""], ["Antani", "Sameer", ""]]}, {"id": "1910.00726", "submitter": "Gaurav Mittal", "authors": "Gaurav Mittal and Baoyuan Wang", "title": "Animating Face using Disentangled Audio Representations", "comments": "Accepted at WACV 2020 (Winter conference on Applications of Computer\n  Vision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All previous methods for audio-driven talking head generation assume the\ninput audio to be clean with a neutral tone. As we show empirically, one can\neasily break these systems by simply adding certain background noise to the\nutterance or changing its emotional tone (to such as sad). To make talking head\ngeneration robust to such variations, we propose an explicit audio\nrepresentation learning framework that disentangles audio sequences into\nvarious factors such as phonetic content, emotional tone, background noise and\nothers. We conduct experiments to validate that conditioned on disentangled\ncontent representation, the generated mouth movement by our model is\nsignificantly more accurate than previous approaches (without disentangled\nlearning) in the presence of noise and emotional variations. We further\ndemonstrate that our framework is compatible with current state-of-the-art\napproaches by replacing their original audio learning component with ours. To\nour best knowledge, this is the first work which improves the performance of\ntalking head generation from disentangled audio representation perspective,\nwhich is important for many real-world applications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 00:47:19 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Mittal", "Gaurav", ""], ["Wang", "Baoyuan", ""]]}, {"id": "1910.00727", "submitter": "Varun Chandrasekaran", "authors": "Lakshya Jain, Varun Chandrasekaran, Uyeong Jang, Wilson Wu, Andrew\n  Lee, Andy Yan, Steven Chen, Somesh Jha, Sanjit A. Seshia", "title": "Analyzing and Improving Neural Networks by Generating Semantic\n  Counterexamples through Differentiable Rendering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even as deep neural networks (DNNs) have achieved remarkable success on\nvision-related tasks, their performance is brittle to transformations in the\ninput. Of particular interest are semantic transformations that model changes\nthat have a basis in the physical world, such as rotations, translations,\nchanges in lighting or camera pose. In this paper, we show how differentiable\nrendering can be utilized to generate images that are informative, yet\nrealistic, and which can be used to analyze DNN performance and improve its\nrobustness through data augmentation. Given a differentiable renderer and a\nDNN, we show how to use off-the-shelf attacks from adversarial machine learning\nto generate semantic counterexamples -- images where semantic features are\nchanged as to produce misclassifications or misdetections. We validate our\napproach on DNNs for image classification and object detection. For\nclassification, we show that semantic counterexamples, when used to augment the\ndataset, (i) improve generalization performance (ii) enhance robustness to\nsemantic transformations, and (iii) transfer between models. Additionally, in\ncomparison to sampling-based semantic augmentation, our technique generates\nmore informative data in a sample efficient manner.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 00:47:57 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 22:08:36 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Jain", "Lakshya", ""], ["Chandrasekaran", "Varun", ""], ["Jang", "Uyeong", ""], ["Wu", "Wilson", ""], ["Lee", "Andrew", ""], ["Yan", "Andy", ""], ["Chen", "Steven", ""], ["Jha", "Somesh", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1910.00731", "submitter": "Jaafar Elmirghani", "authors": "Sanaa Hamid Mohamed, Taisir E.H. El-Gorashi and Jaafar M.H. Elmirghani", "title": "A Survey of Big Data Machine Learning Applications Optimization in Cloud\n  Data Centers and Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey article reviews the challenges associated with deploying and\noptimizing big data applications and machine learning algorithms in cloud data\ncenters and networks. The MapReduce programming model and its widely-used\nopen-source platform; Hadoop, are enabling the development of a large number of\ncloud-based services and big data applications. MapReduce and Hadoop thus\nintroduce innovative, efficient, and accelerated intensive computations and\nanalytics. These services usually utilize commodity clusters within\ngeographically-distributed data centers and provide cost-effective and elastic\nsolutions. However, the increasing traffic between and within the data centers\nthat migrate, store, and process big data, is becoming a bottleneck that calls\nfor enhanced infrastructures capable of reducing the congestion and power\nconsumption. Moreover, enterprises with multiple tenants requesting various big\ndata services are challenged by the need to optimize leasing their resources at\nreduced running costs and power consumption while avoiding under or over\nutilization. In this survey, we present a summary of the characteristics of\nvarious big data programming models and applications and provide a review of\ncloud computing infrastructures, and related technologies such as\nvirtualization, and software-defined networking that increasingly support big\ndata systems. Moreover, we provide a brief review of data centers topologies,\nrouting protocols, and traffic characteristics, and emphasize the implications\nof big data on such cloud data centers and their supporting networks. Wide\nranging efforts were devoted to optimize systems that handle big data in terms\nof various applications performance metrics and/or infrastructure energy\nefficiency. Finally, some insights and future research directions are provided.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 08:05:34 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Mohamed", "Sanaa Hamid", ""], ["El-Gorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "1910.00741", "submitter": "Shresth Verma", "authors": "Shresth Verma, Joydip Dhar", "title": "Emergence of Writing Systems Through Multi-Agent Cooperation", "comments": "Under Review as Student Abstract at AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CL cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to communicate is considered an essential task to develop a general\nAI. While recent literature in language evolution has studied emergent language\nthrough discrete or continuous message symbols, there has been little work in\nthe emergence of writing systems in artificial agents. In this paper, we\npresent a referential game setup with two agents, where the mode of\ncommunication is a written language system that emerges during the play. We\nshow that the agents can learn to coordinate successfully using this mode of\ncommunication. Further, we study how the game rules affect the writing system\ntaxonomy by proposing a consistency metric.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 01:35:14 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Verma", "Shresth", ""], ["Dhar", "Joydip", ""]]}, {"id": "1910.00744", "submitter": "David Rolnick", "authors": "David Rolnick and Konrad P. Kording", "title": "Reverse-Engineering Deep ReLU Networks", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been widely assumed that a neural network cannot be recovered from its\noutputs, as the network depends on its parameters in a highly nonlinear way.\nHere, we prove that in fact it is often possible to identify the architecture,\nweights, and biases of an unknown deep ReLU network by observing only its\noutput. Every ReLU network defines a piecewise linear function, where the\nboundaries between linear regions correspond to inputs for which some neuron in\nthe network switches between inactive and active ReLU states. By dissecting the\nset of region boundaries into components associated with particular neurons, we\nshow both theoretically and empirically that it is possible to recover the\nweights of neurons and their arrangement within the network, up to isomorphism.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 01:53:15 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 16:40:31 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Rolnick", "David", ""], ["Kording", "Konrad P.", ""]]}, {"id": "1910.00748", "submitter": "Nikita Srivatsan", "authors": "Nikita Srivatsan, Jonathan T. Barron, Dan Klein, Taylor\n  Berg-Kirkpatrick", "title": "A Deep Factorization of Style and Structure in Fonts", "comments": "EMNLP 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep factorization model for typographic analysis that\ndisentangles content from style. Specifically, a variational inference\nprocedure factors each training glyph into the combination of a\ncharacter-specific content embedding and a latent font-specific style variable.\nThe underlying generative model combines these factors through an asymmetric\ntranspose convolutional process to generate the image of the glyph itself. When\ntrained on corpora of fonts, our model learns a manifold over font styles that\ncan be used to analyze or reconstruct new, unseen fonts. On the task of\nreconstructing missing glyphs from an unknown font given only a small number of\nobservations, our model outperforms both a strong nearest neighbors baseline\nand a state-of-the-art discriminative model from prior work.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 02:24:12 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 01:43:18 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Srivatsan", "Nikita", ""], ["Barron", "Jonathan T.", ""], ["Klein", "Dan", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1910.00752", "submitter": "Daniel Severo", "authors": "Daniel Severo, Fl\\'avio Amaro, Estevam R. Hruschka Jr, Andr\\'e Soares\n  de Moura Costa", "title": "Ward2ICU: A Vital Signs Dataset of Inpatients from the General Ward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a proxy dataset of vital signs with class labels indicating\npatient transitions from the ward to intensive care units called Ward2ICU.\nPatient privacy is protected using a Wasserstein Generative Adversarial Network\nto implicitly learn an approximation of the data distribution, allowing us to\nsample synthetic data. The quality of data generation is assessed directly on\nthe binary classification task by comparing specificity and sensitivity of an\nLSTM classifier on proxy and original datasets. We initialize a discussion of\nunintentionally disclosing commercial sensitive information and propose a\nsolution for a special case through class label balancing\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 02:38:33 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Severo", "Daniel", ""], ["Amaro", "Fl\u00e1vio", ""], ["Hruschka", "Estevam R.", "Jr"], ["Costa", "Andr\u00e9 Soares de Moura", ""]]}, {"id": "1910.00753", "submitter": "Jonas K\\\"ohler", "authors": "Jonas K\\\"ohler, Leon Klein, Frank No\\'e", "title": "Equivariant Flows: sampling configurations for multi-body systems with\n  symmetric energies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flows are exact-likelihood generative neural networks that transform samples\nfrom a simple prior distribution to the samples of the probability distribution\nof interest. Boltzmann Generators (BG) combine flows and statistical mechanics\nto sample equilibrium states of strongly interacting many-body systems such as\nproteins with 1000 atoms. In order to scale and generalize these results, it is\nessential that the natural symmetries of the probability density - in physics\ndefined by the invariances of the energy function - are built into the flow.\nHere we develop theoretical tools for constructing such equivariant flows and\ndemonstrate that a BG that is equivariant with respect to rotations and\nparticle permutations can generalize to sampling nontrivially new\nconfigurations where a nonequivariant BG cannot.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 02:42:34 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["K\u00f6hler", "Jonas", ""], ["Klein", "Leon", ""], ["No\u00e9", "Frank", ""]]}, {"id": "1910.00760", "submitter": "Renjie Liao", "authors": "Renjie Liao, Yujia Li, Yang Song, Shenlong Wang, Charlie Nash, William\n  L. Hamilton, David Duvenaud, Raquel Urtasun, Richard S. Zemel", "title": "Efficient Graph Generation with Graph Recurrent Attention Networks", "comments": "Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new family of efficient and expressive deep generative models of\ngraphs, called Graph Recurrent Attention Networks (GRANs). Our model generates\ngraphs one block of nodes and associated edges at a time. The block size and\nsampling stride allow us to trade off sample quality for efficiency. Compared\nto previous RNN-based graph generative models, our framework better captures\nthe auto-regressive conditioning between the already-generated and\nto-be-generated parts of the graph using Graph Neural Networks (GNNs) with\nattention. This not only reduces the dependency on node ordering but also\nbypasses the long-term bottleneck caused by the sequential nature of RNNs.\nMoreover, we parameterize the output distribution per block using a mixture of\nBernoulli, which captures the correlations among generated edges within the\nblock. Finally, we propose to handle node orderings in generation by\nmarginalizing over a family of canonical orderings. On standard benchmarks, we\nachieve state-of-the-art time efficiency and sample quality compared to\nprevious models. Additionally, we show our model is capable of generating large\ngraphs of up to 5K nodes with good quality. To the best of our knowledge, GRAN\nis the first deep graph generative model that can scale to this size. Our code\nis released at: https://github.com/lrjconan/GRAN.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 03:28:16 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 18:49:57 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 20:25:18 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Liao", "Renjie", ""], ["Li", "Yujia", ""], ["Song", "Yang", ""], ["Wang", "Shenlong", ""], ["Nash", "Charlie", ""], ["Hamilton", "William L.", ""], ["Duvenaud", "David", ""], ["Urtasun", "Raquel", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1910.00762", "submitter": "Angela Jiang", "authors": "Angela H. Jiang, Daniel L.-K. Wong, Giulio Zhou, David G. Andersen,\n  Jeffrey Dean, Gregory R. Ganger, Gauri Joshi, Michael Kaminksy, Michael\n  Kozuch, Zachary C. Lipton, Padmanabhan Pillai", "title": "Accelerating Deep Learning by Focusing on the Biggest Losers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Selective-Backprop, a technique that accelerates the\ntraining of deep neural networks (DNNs) by prioritizing examples with high loss\nat each iteration. Selective-Backprop uses the output of a training example's\nforward pass to decide whether to use that example to compute gradients and\nupdate parameters, or to skip immediately to the next example. By reducing the\nnumber of computationally-expensive backpropagation steps performed,\nSelective-Backprop accelerates training. Evaluation on CIFAR10, CIFAR100, and\nSVHN, across a variety of modern image models, shows that Selective-Backprop\nconverges to target error rates up to 3.5x faster than with standard SGD and\nbetween 1.02--1.8x faster than a state-of-the-art importance sampling approach.\nFurther acceleration of 26% can be achieved by using stale forward pass results\nfor selection, thus also skipping forward passes of low priority examples.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 03:34:29 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Jiang", "Angela H.", ""], ["Wong", "Daniel L. -K.", ""], ["Zhou", "Giulio", ""], ["Andersen", "David G.", ""], ["Dean", "Jeffrey", ""], ["Ganger", "Gregory R.", ""], ["Joshi", "Gauri", ""], ["Kaminksy", "Michael", ""], ["Kozuch", "Michael", ""], ["Lipton", "Zachary C.", ""], ["Pillai", "Padmanabhan", ""]]}, {"id": "1910.00768", "submitter": "Zijian Zhang", "authors": "Zijian Zhang, Fan Yang, Haofan Wang, Xia Hu", "title": "Contextual Local Explanation for Black Box Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new model-agnostic explanation technique which explains the\nprediction of any classifier called CLE. CLE gives an faithful and\ninterpretable explanation to the prediction, by approximating the model locally\nusing an interpretable model. We demonstrate the flexibility of CLE by\nexplaining different models for text, tabular and image classification, and the\nfidelity of it by doing simulated user experiments.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 03:58:12 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Zhang", "Zijian", ""], ["Yang", "Fan", ""], ["Wang", "Haofan", ""], ["Hu", "Xia", ""]]}, {"id": "1910.00775", "submitter": "Taesup Kim", "authors": "Taesup Kim, Sungjin Ahn, Yoshua Bengio", "title": "Variational Temporal Abstraction", "comments": "Accepted in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variational approach to learning and inference of temporally\nhierarchical structure and representation for sequential data. We propose the\nVariational Temporal Abstraction (VTA), a hierarchical recurrent state space\nmodel that can infer the latent temporal structure and thus perform the\nstochastic state transition hierarchically. We also propose to apply this model\nto implement the jumpy-imagination ability in imagination-augmented\nagent-learning in order to improve the efficiency of the imagination. In\nexperiments, we demonstrate that our proposed method can model 2D and 3D visual\nsequence datasets with interpretable temporal structure discovery and that its\napplication to jumpy imagination enables more efficient agent-learning in a 3D\nnavigation task.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 04:37:23 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Kim", "Taesup", ""], ["Ahn", "Sungjin", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1910.00780", "submitter": "Kartikeya Bhardwaj", "authors": "Kartikeya Bhardwaj, Guihong Li, Radu Marculescu", "title": "How does topology influence gradient propagation and model performance\n  of deep networks with DenseNet-type skip connections?", "comments": "Accepted at CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DenseNets introduce concatenation-type skip connections that achieve\nstate-of-the-art accuracy in several computer vision tasks. In this paper, we\nreveal that the topology of the concatenation-type skip connections is closely\nrelated to the gradient propagation which, in turn, enables a predictable\nbehavior of DNNs' test performance. To this end, we introduce a new metric\ncalled NN-Mass to quantify how effectively information flows through DNNs.\nMoreover, we empirically show that NN-Mass also works for other types of skip\nconnections, e.g., for ResNets, Wide-ResNets (WRNs), and MobileNets, which\ncontain addition-type skip connections (i.e., residuals or inverted residuals).\nAs such, for both DenseNet-like CNNs and ResNets/WRNs/MobileNets, our\ntheoretically grounded NN-Mass can identify models with similar accuracy,\ndespite having significantly different size/compute requirements. Detailed\nexperiments on both synthetic and real datasets (e.g., MNIST, CIFAR-10,\nCIFAR-100, ImageNet) provide extensive evidence for our insights. Finally, the\nclosed-form equation of our NN-Mass enables us to design significantly\ncompressed DenseNets (for CIFAR-10) and MobileNets (for ImageNet) directly at\ninitialization without time-consuming training and/or searching.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 05:25:47 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 02:51:57 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 00:04:30 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Bhardwaj", "Kartikeya", ""], ["Li", "Guihong", ""], ["Marculescu", "Radu", ""]]}, {"id": "1910.00783", "submitter": "Mihailo Jovanovic", "authors": "Dongsheng Ding and Mihailo R. Jovanovi\\'c", "title": "Global exponential stability of primal-dual gradient flow dynamics based\n  on the proximal augmented Lagrangian: A Lyapunov-based approach", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a class of nonsmooth composite optimization problems with linear equality\nconstraints, we utilize a Lyapunov-based approach to establish the global\nexponential stability of the primal-dual gradient flow dynamics based on the\nproximal augmented Lagrangian. The result holds when the differentiable part of\nthe objective function is strongly convex with a Lipschitz continuous gradient;\nthe non-differentiable part is proper, lower semi-continuous, and convex; and\nthe matrix in the linear constraint is full row rank. Our quadratic Lyapunov\nfunction generalizes recent result from strongly convex problems with either\naffine equality or inequality constraints to a broader class of composite\noptimization problems with nonsmooth regularizers and it provides a worst-case\nlower bound of the exponential decay rate. Finally, we use computational\nexperiments to demonstrate that our convergence rate estimate is less\nconservative than the existing alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 05:29:55 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Ding", "Dongsheng", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1910.00795", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Speech-to-speech Translation between Untranscribed Unknown Languages", "comments": "Accepted in IEEE ASRU 2019. Web-page for more samples & details:\n  https://sp2code-translation-v1.netlify.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore a method for training speech-to-speech translation\ntasks without any transcription or linguistic supervision. Our proposed method\nconsists of two steps: First, we train and generate discrete representation\nwith unsupervised term discovery with a discrete quantized autoencoder. Second,\nwe train a sequence-to-sequence model that directly maps the source language\nspeech to the target language's discrete representation. Our proposed method\ncan directly generate target speech without any auxiliary or pre-training steps\nwith a source or target transcription. To the best of our knowledge, this is\nthe first work that performed pure speech-to-speech translation between\nuntranscribed unknown languages.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 06:42:57 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 08:03:25 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1910.00821", "submitter": "Nicolas Gillis", "authors": "Pierre De Handschutter, Nicolas Gillis, Arnaud Vandaele, Xavier\n  Siebert", "title": "Near-Convex Archetypal Analysis", "comments": "10 pages, 3 figures", "journal-ref": "IEEE Signal Processing Letters 27 (1), pp. 81-85, 2020", "doi": "10.1109/LSP.2019.2957604", "report-no": null, "categories": "eess.SP cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is a widely used linear dimensionality\nreduction technique for nonnegative data. NMF requires that each data point is\napproximated by a convex combination of basis elements. Archetypal analysis\n(AA), also referred to as convex NMF, is a well-known NMF variant imposing that\nthe basis elements are themselves convex combinations of the data points. AA\nhas the advantage to be more interpretable than NMF because the basis elements\nare directly constructed from the data points. However, it usually suffers from\na high data fitting error because the basis elements are constrained to be\ncontained in the convex cone of the data points. In this letter, we introduce\nnear-convex archetypal analysis (NCAA) which combines the advantages of both AA\nand NMF. As for AA, the basis vectors are required to be linear combinations of\nthe data points and hence are easily interpretable. As for NMF, the additional\nflexibility in choosing the basis elements allows NCAA to have a low data\nfitting error. We show that NCAA compares favorably with a state-of-the-art\nminimum-volume NMF method on synthetic datasets and on a real-world\nhyperspectral image.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 08:16:14 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["De Handschutter", "Pierre", ""], ["Gillis", "Nicolas", ""], ["Vandaele", "Arnaud", ""], ["Siebert", "Xavier", ""]]}, {"id": "1910.00877", "submitter": "David Rohde", "authors": "Otmane Sakhi, Stephen Bonner, David Rohde, Flavian Vasile", "title": "Reconsidering Analytical Variational Bounds for Output Layers of Deep\n  Networks", "comments": "8 pages 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of the re-parameterization trick with the use of variational\nauto-encoders has caused a sensation in Bayesian deep learning, allowing the\ntraining of realistic generative models of images and has considerably\nincreased our ability to use scalable latent variable models. The\nre-parameterization trick is necessary for models in which no analytical\nvariational bound is available and allows noisy gradients to be computed for\narbitrary models. However, for certain standard output layers of a neural\nnetwork, analytical bounds are available and the variational auto-encoder may\nbe used both without the re-parameterization trick or the need for any Monte\nCarlo approximation. In this work, we show that using Jaakola and Jordan bound,\nwe can produce a binary classification layer that allows a Bayesian output\nlayer to be trained, using the standard stochastic gradient descent algorithm.\nWe further demonstrate that a latent variable model utilizing the Bouchard\nbound for multi-class classification allows for fast training of a fully\nprobabilistic latent factor model, even when the number of classes is very\nlarge.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 11:06:47 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 13:21:41 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Sakhi", "Otmane", ""], ["Bonner", "Stephen", ""], ["Rohde", "David", ""], ["Vasile", "Flavian", ""]]}, {"id": "1910.00879", "submitter": "Isaac Matthews", "authors": "Tom Ryder, Dennis Prangle, Andrew Golightly, Isaac Matthews", "title": "The Neural Moving Average Model for Scalable Variational Inference of\n  State Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference has had great success in scaling approximate Bayesian\ninference to big data by exploiting mini-batch training. To date, however, this\nstrategy has been most applicable to models of independent data. We propose an\nextension to state space models of time series data based on a novel generative\nmodel for latent temporal states: the neural moving average model. This permits\na subsequence to be sampled without drawing from the entire distribution,\nenabling training iterations to use mini-batches of the time series at low\ncomputational cost. We illustrate our method on autoregressive, Lotka-Volterra,\nFitzHugh-Nagumo and stochastic volatility models, achieving accurate parameter\nestimation in a short time.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 11:28:40 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 16:34:09 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Ryder", "Tom", ""], ["Prangle", "Dennis", ""], ["Golightly", "Andrew", ""], ["Matthews", "Isaac", ""]]}, {"id": "1910.00888", "submitter": "Thomas Pinetz", "authors": "Thomas Pinetz, Daniel Soukup and Thomas Pock", "title": "On the estimation of the Wasserstein distance in generative models", "comments": "Accepted and presented at GCPR 2019 (http://gcpr2019.tu-dortmund.de/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have been used to model the underlying\nprobability distribution of sample based datasets. GANs are notoriuos for\ntraining difficulties and their dependence on arbitrary hyperparameters. One\nrecent improvement in GAN literature is to use the Wasserstein distance as loss\nfunction leading to Wasserstein Generative Adversarial Networks (WGANs). Using\nthis as a basis, we show various ways in which the Wasserstein distance is\nestimated for the task of generative modelling. Additionally, the secrets in\ntraining such models are shown and summarized at the end of this work. Where\napplicable, we extend current works to different algorithms, different cost\nfunctions, and different regularization schemes to improve generative models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 11:49:00 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Pinetz", "Thomas", ""], ["Soukup", "Daniel", ""], ["Pock", "Thomas", ""]]}, {"id": "1910.00925", "submitter": "Ali Siahkoohi", "authors": "Ali Siahkoohi, Mathias Louboutin, Felix J. Herrmann", "title": "Neural network augmented wave-equation simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.geo-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate forward modeling is important for solving inverse problems. An\ninaccurate wave-equation simulation, as a forward operator, will offset the\nresults obtained via inversion. In this work, we consider the case where we\ndeal with incomplete physics. One proxy of incomplete physics is an inaccurate\ndiscretization of Laplacian in simulation of wave equation via\nfinite-difference method. We exploit intrinsic one-to-one similarities between\ntimestepping algorithm with Convolutional Neural Networks (CNNs), and propose\nto intersperse CNNs between low-fidelity timesteps. Augmenting neural networks\nwith low-fidelity timestepping algorithms may allow us to take large timesteps\nwhile limiting the numerical dispersion artifacts. While simulating the\nwave-equation with low-fidelity timestepping algorithm, by correcting the\nwavefield several time during propagation, we hope to limit the numerical\ndispersion artifact introduced by a poor discretization of the Laplacian. As a\nproof of concept, we demonstrate this principle by correcting for numerical\ndispersion by keeping the velocity model fixed, and varying the source\nlocations to generate training and testing pairs for our supervised learning\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 21:00:51 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 22:08:24 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Siahkoohi", "Ali", ""], ["Louboutin", "Mathias", ""], ["Herrmann", "Felix J.", ""]]}, {"id": "1910.00927", "submitter": "Stefano Albrecht", "authors": "Maciej Wiatrak, Stefano V. Albrecht, Andrew Nystrom", "title": "Stabilizing Generative Adversarial Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a type of generative model which\nhave received much attention due to their ability to model complex real-world\ndata. Despite their recent successes, the process of training GANs remains\nchallenging, suffering from instability problems such as non-convergence,\nvanishing or exploding gradients, and mode collapse. In recent years, a diverse\nset of approaches have been proposed which focus on stabilizing the GAN\ntraining procedure. The purpose of this survey is to provide a comprehensive\noverview of the GAN training stabilization methods which can be found in the\nliterature. We discuss the advantages and disadvantages of each approach, offer\na comparative summary, and conclude with a discussion of open problems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 00:27:08 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 20:16:02 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Wiatrak", "Maciej", ""], ["Albrecht", "Stefano V.", ""], ["Nystrom", "Andrew", ""]]}, {"id": "1910.00928", "submitter": "Mathis Bode", "authors": "Mathis Bode and Michael Gauding and Konstantin Kleinheinz and Heinz\n  Pitsch", "title": "Deep learning at scale for subgrid modeling in turbulent flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling of turbulent flows is still challenging. One way to deal with the\nlarge scale separation due to turbulence is to simulate only the large scales\nand model the unresolved contributions as done in large-eddy simulation (LES).\nThis paper focuses on two deep learning (DL) strategies, regression and\nreconstruction, which are data-driven and promising alternatives to classical\nmodeling concepts. Using three-dimensional (3-D) forced turbulence direct\nnumerical simulation (DNS) data, subgrid models are evaluated, which predict\nthe unresolved part of quantities based on the resolved solution. For\nregression, it is shown that feedforward artificial neural networks (ANNs) are\nable to predict the fully-resolved scalar dissipation rate using filtered input\ndata. It was found that a combination of a large-scale quantity, such as the\nfiltered passive scalar itself, and a small-scale quantity, such as the\nfiltered energy dissipation rate, gives the best agreement with the actual DNS\ndata. Furthermore, a DL network motivated by enhanced super-resolution\ngenerative adversarial networks (ESRGANs) was used to reconstruct\nfully-resolved 3-D velocity fields from filtered velocity fields. The energy\nspectrum shows very good agreement. As size of scientific data is often in the\norder of terabytes or more, DL needs to be combined with high performance\ncomputing (HPC). Necessary code improvements for HPC-DL are discussed with\nrespect to the supercomputer JURECA. After optimizing the training code, 396.2\nTFLOPS were achieved.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 15:50:10 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Bode", "Mathis", ""], ["Gauding", "Michael", ""], ["Kleinheinz", "Konstantin", ""], ["Pitsch", "Heinz", ""]]}, {"id": "1910.00932", "submitter": "Ji Lin", "authors": "Ji Lin, Chuang Gan, Song Han", "title": "Training Kinetics in 15 Minutes: Large-scale Distributed Training on\n  Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep video recognition is more computationally expensive than image\nrecognition, especially on large-scale datasets like Kinetics [1]. Therefore,\ntraining scalability is essential to handle a large amount of videos. In this\npaper, we study the factors that impact the training scalability of video\nnetworks. We recognize three bottlenecks, including data loading (data movement\nfrom disk to GPU), communication (data movement over networking), and\ncomputation FLOPs. We propose three design guidelines to improve the\nscalability: (1) fewer FLOPs and hardware-friendly operator to increase the\ncomputation efficiency; (2) fewer input frames to reduce the data movement and\nincrease the data loading efficiency; (3) smaller model size to reduce the\nnetworking traffic and increase the networking efficiency. With these\nguidelines, we designed a new operator Temporal Shift Module (TSM) that is\nefficient and scalable for distributed training. TSM model can achieve 1.8x\nhigher throughput compared to previous I3D models. We scale up the training of\nthe TSM model to 1,536 GPUs, with a mini-batch of 12,288 video clips/98,304\nimages, without losing the accuracy. With such hardware-aware model design, we\nare able to scale up the training on Summit supercomputer and reduce the\ntraining time on Kinetics dataset from 49 hours 55 minutes to 14 minutes 13\nseconds, achieving a top-1 accuracy of 74.0%, which is 1.6x and 2.9x faster\nthan previous 3D video models with higher accuracy. The code and more details\ncan be found here: http://tsm-hanlab.mit.edu.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:58:07 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 23:04:39 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Lin", "Ji", ""], ["Gan", "Chuang", ""], ["Han", "Song", ""]]}, {"id": "1910.00935", "submitter": "Yuanming Hu", "authors": "Yuanming Hu, Luke Anderson, Tzu-Mao Li, Qi Sun, Nathan Carr, Jonathan\n  Ragan-Kelley, Fr\\'edo Durand", "title": "DiffTaichi: Differentiable Programming for Physical Simulation", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DiffTaichi, a new differentiable programming language tailored for\nbuilding high-performance differentiable physical simulators. Based on an\nimperative programming language, DiffTaichi generates gradients of simulation\nsteps using source code transformations that preserve arithmetic intensity and\nparallelism. A light-weight tape is used to record the whole simulation program\nstructure and replay the gradient kernels in a reversed order, for end-to-end\nbackpropagation. We demonstrate the performance and productivity of our\nlanguage in gradient-based learning and optimization tasks on 10 different\nphysical simulators. For example, a differentiable elastic object simulator\nwritten in our language is 4.2x shorter than the hand-engineered CUDA version\nyet runs as fast, and is 188x faster than the TensorFlow implementation. Using\nour differentiable programs, neural network controllers are typically optimized\nwithin only tens of iterations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 05:00:26 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 13:13:28 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 06:21:07 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Hu", "Yuanming", ""], ["Anderson", "Luke", ""], ["Li", "Tzu-Mao", ""], ["Sun", "Qi", ""], ["Carr", "Nathan", ""], ["Ragan-Kelley", "Jonathan", ""], ["Durand", "Fr\u00e9do", ""]]}, {"id": "1910.00942", "submitter": "Guillaume Salha", "authors": "Guillaume Salha, Romain Hennequin, Michalis Vazirgiannis", "title": "Keep It Simple: Graph Autoencoders Without Graph Convolutional Networks", "comments": "NeurIPS 2019 Graph Representation Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph autoencoders (AE) and variational autoencoders (VAE) recently emerged\nas powerful node embedding methods, with promising performances on challenging\ntasks such as link prediction and node clustering. Graph AE, VAE and most of\ntheir extensions rely on graph convolutional networks (GCN) to learn vector\nspace representations of nodes. In this paper, we propose to replace the GCN\nencoder by a simple linear model w.r.t. the adjacency matrix of the graph. For\nthe two aforementioned tasks, we empirically show that this approach\nconsistently reaches competitive performances w.r.t. GCN-based models for\nnumerous real-world graphs, including the widely used Cora, Citeseer and Pubmed\ncitation networks that became the de facto benchmark datasets for evaluating\ngraph AE and VAE. This result questions the relevance of repeatedly using these\nthree datasets to compare complex graph AE and VAE models. It also emphasizes\nthe effectiveness of simple node encoding schemes for many real-world\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 13:30:08 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Salha", "Guillaume", ""], ["Hennequin", "Romain", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1910.00943", "submitter": "Jos\\'e Ant\\'onio Ferreira", "authors": "Jos\\'e A. Ferreira", "title": "Data-generating models under which the random forest algorithm performs\n  badly", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Examples are given of data-generating models under which some versions of the\nrandom forest algorithm may fail to be consistent or be extremely slow to\nconverge to the optimal predictor. The evidence provided for these properties\nis based on mostly intuitive arguments, similar to those used earlier with\nsimpler examples, and on numerical experiments. Although one can always choose\na model under which random forests perform very badly, it is shown that when\nsubstantial improvement is possible simple methods based on statistics of\n'variable use' and 'variable importance' may indicate a better predictor based\non a sort of mixture of random forests; thus, by acknowledging the difficulties\nposed by some models one may improve the performance of random forests in some\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 13:33:33 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 08:15:42 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 07:52:44 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 10:23:39 GMT"}, {"version": "v5", "created": "Tue, 14 Jan 2020 12:21:14 GMT"}, {"version": "v6", "created": "Fri, 7 May 2021 20:17:06 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Ferreira", "Jos\u00e9 A.", ""]]}, {"id": "1910.00945", "submitter": "Michael Lones", "authors": "Michael Lones", "title": "Optimising Optimisers with Push GP", "comments": null, "journal-ref": "In: Hu T., Louren\\c{c}o N., Medvet E., Divina F. (eds) Genetic\n  Programming. EuroGP 2020. Lecture Notes in Computer Science, vol 12101.\n  Springer, Cham", "doi": "10.1007/978-3-030-44094-7_7", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work uses Push GP to automatically design both local and\npopulation-based optimisers for continuous-valued problems. The optimisers are\ntrained on a single function optimisation landscape, using random\ntransformations to discourage overfitting. They are then tested for generality\non larger versions of the same problem, and on other continuous-valued\nproblems. In most cases, the optimisers generalise well to the larger problems.\nSurprisingly, some of them also generalise very well to previously unseen\nproblems, outperforming existing general purpose optimisers such as CMA-ES.\nAnalysis of the behaviour of the evolved optimisers indicates a range of\ninteresting optimisation strategies that are not found within conventional\noptimisers, suggesting that this approach could be useful for discovering novel\nand effective forms of optimisation in an automated manner.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 13:38:55 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Lones", "Michael", ""]]}, {"id": "1910.00964", "submitter": "Venet Osmani", "authors": "Seyedmostafa Sheikhalishahi, Vevake Balaraman, Venet Osmani", "title": "Benchmarking machine learning models on multi-centre eICU critical care\n  dataset", "comments": "Source code to replicate the results\n  https://github.com/mostafaalishahi/eICU_Benchmark", "journal-ref": null, "doi": "10.1371/journal.pone.0235424", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress of machine learning in critical care has been difficult to track, in\npart due to absence of public benchmarks. Other fields of research (such as\ncomputer vision and natural language processing) have established various\ncompetitions and public benchmarks. Recent availability of large clinical\ndatasets has enabled the possibility of establishing public benchmarks. Taking\nadvantage of this opportunity, we propose a public benchmark suite to address\nfour areas of critical care, namely mortality prediction, estimation of length\nof stay, patient phenotyping and risk of decompensation. We define each task\nand compare the performance of both clinical models as well as baseline and\ndeep learning models using eICU critical care dataset of around 73,000\npatients. This is the first public benchmark on a multi-centre critical care\ndataset, comparing the performance of clinical gold standard with our\npredictive model. We also investigate the impact of numerical variables as well\nas handling of categorical variables on each of the defined tasks. The source\ncode, detailing our methods and experiments is publicly available such that\nanyone can replicate our results and build upon our work.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:04:24 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:44:40 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Sheikhalishahi", "Seyedmostafa", ""], ["Balaraman", "Vevake", ""], ["Osmani", "Venet", ""]]}, {"id": "1910.00965", "submitter": "Ozgur Emre Sivrikaya", "authors": "Mert Yuksekgonul, Ozgur Emre Sivrikaya, Mustafa Gokce Baydogan", "title": "Learning Maximally Predictive Prototypes in Multiple Instance Learning", "comments": "Sets & Partitions Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a simple model that provides permutation invariant\nmaximally predictive prototype generator from a given dataset, which leads to\ninterpretability of the solution and concrete insights to the nature and the\nsolution of a problem. Our aim is to find out prototypes in the feature space\nto map the collection of instances (i.e. bags) to a distance feature space and\nsimultaneously learn a linear classifier for multiple instance learning (MIL).\nOur experiments on classical MIL benchmark datasets demonstrate that proposed\nframework is an accurate and efficient classifier compared to the existing\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:04:48 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 07:46:13 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 11:49:34 GMT"}, {"version": "v4", "created": "Fri, 22 Jan 2021 11:56:24 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Yuksekgonul", "Mert", ""], ["Sivrikaya", "Ozgur Emre", ""], ["Baydogan", "Mustafa Gokce", ""]]}, {"id": "1910.00969", "submitter": "Andreas Hinterreiter", "authors": "Andreas Hinterreiter, Peter Ruch, Holger Stitz, Martin Ennemoser,\n  J\\\"urgen Bernard, Hendrik Strobelt, Marc Streit", "title": "ConfusionFlow: A model-agnostic visualization for temporal analysis of\n  classifier confusion", "comments": "Changes compared to previous version: Reintroduced NN pruning use\n  case; restructured Evaluation section; several additional minor revisions.\n  Submitted as Minor Revision to IEEE TVCG on 2020-07-02", "journal-ref": null, "doi": "10.1109/TVCG.2020.3012063", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers are among the most widely used supervised machine learning\nalgorithms. Many classification models exist, and choosing the right one for a\ngiven task is difficult. During model selection and debugging, data scientists\nneed to assess classifiers' performances, evaluate their learning behavior over\ntime, and compare different models. Typically, this analysis is based on\nsingle-number performance measures such as accuracy. A more detailed evaluation\nof classifiers is possible by inspecting class errors. The confusion matrix is\nan established way for visualizing these class errors, but it was not designed\nwith temporal or comparative analysis in mind. More generally, established\nperformance analysis systems do not allow a combined temporal and comparative\nanalysis of class-level information. To address this issue, we propose\nConfusionFlow, an interactive, comparative visualization tool that combines the\nbenefits of class confusion matrices with the visualization of performance\ncharacteristics over time. ConfusionFlow is model-agnostic and can be used to\ncompare performances for different model types, model architectures, and/or\ntraining and test datasets. We demonstrate the usefulness of ConfusionFlow in a\ncase study on instance selection strategies in active learning. We further\nassess the scalability of ConfusionFlow and present a use case in the context\nof neural network pruning.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:18:09 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 11:35:57 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 17:01:55 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Hinterreiter", "Andreas", ""], ["Ruch", "Peter", ""], ["Stitz", "Holger", ""], ["Ennemoser", "Martin", ""], ["Bernard", "J\u00fcrgen", ""], ["Strobelt", "Hendrik", ""], ["Streit", "Marc", ""]]}, {"id": "1910.00982", "submitter": "Micah Goldblum", "authors": "Micah Goldblum, Liam Fowl, Tom Goldstein", "title": "Adversarially Robust Few-Shot Learning: A Meta-Learning Approach", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on adversarially robust neural networks for image\nclassification requires large training sets and computationally expensive\ntraining procedures. On the other hand, few-shot learning methods are highly\nvulnerable to adversarial examples. The goal of our work is to produce networks\nwhich both perform well at few-shot classification tasks and are simultaneously\nrobust to adversarial examples. We develop an algorithm, called Adversarial\nQuerying (AQ), for producing adversarially robust meta-learners, and we\nthoroughly investigate the causes for adversarial vulnerability. Moreover, our\nmethod achieves far superior robust performance on few-shot image\nclassification tasks, such as Mini-ImageNet and CIFAR-FS, than robust transfer\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:39:21 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 03:33:24 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 15:09:38 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Goldblum", "Micah", ""], ["Fowl", "Liam", ""], ["Goldstein", "Tom", ""]]}, {"id": "1910.00983", "submitter": "Mark Van der Merwe", "authors": "Mark Van der Merwe, Qingkai Lu, Balakumar Sundaralingam, Martin Matak,\n  Tucker Hermans", "title": "Learning Continuous 3D Reconstructions for Geometrically Aware Grasping", "comments": "IEEE Conference on Robotics and Automation 2020 (ICRA 2020)\n  Camera-Ready. Includes updated experiments from initial submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has enabled remarkable improvements in grasp synthesis for\npreviously unseen objects from partial object views. However, existing\napproaches lack the ability to explicitly reason about the full 3D geometry of\nthe object when selecting a grasp, relying on indirect geometric reasoning\nderived when learning grasp success networks. This abandons explicit geometric\nreasoning, such as avoiding undesired robot object collisions. We propose to\nutilize a novel, learned 3D reconstruction to enable geometric awareness in a\ngrasping system. We leverage the structure of the reconstruction network to\nlearn a grasp success classifier which serves as the objective function for a\ncontinuous grasp optimization. We additionally explicitly constrain the\noptimization to avoid undesired contact, directly using the reconstruction. We\nexamine the role of geometry in grasping both in the training of grasp metrics\nand through 96 robot grasping trials. Our results can be found on\nhttps://sites.google.com/view/reconstruction-grasp/.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:40:16 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 04:25:35 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Van der Merwe", "Mark", ""], ["Lu", "Qingkai", ""], ["Sundaralingam", "Balakumar", ""], ["Matak", "Martin", ""], ["Hermans", "Tucker", ""]]}, {"id": "1910.00998", "submitter": "Peter J Liu", "authors": "Peter J. Liu, Yu-An Chung, Jie Ren", "title": "SummAE: Zero-Shot Abstractive Text Summarization using Length-Agnostic\n  Auto-Encoders", "comments": "first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end neural model for zero-shot abstractive text\nsummarization of paragraphs, and introduce a benchmark task, ROCSumm, based on\nROCStories, a subset for which we collected human summaries. In this task,\nfive-sentence stories (paragraphs) are summarized with one sentence, using\nhuman summaries only for evaluation. We show results for extractive and human\nbaselines to demonstrate a large abstractive gap in performance. Our model,\nSummAE, consists of a denoising auto-encoder that embeds sentences and\nparagraphs in a common space, from which either can be decoded. Summaries for\nparagraphs are generated by decoding a sentence from the paragraph\nrepresentations. We find that traditional sequence-to-sequence auto-encoders\nfail to produce good summaries and describe how specific architectural choices\nand pre-training techniques can significantly improve performance,\noutperforming extractive baselines. The data, training, evaluation code, and\nbest model weights are open-sourced.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:57:55 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Liu", "Peter J.", ""], ["Chung", "Yu-An", ""], ["Ren", "Jie", ""]]}, {"id": "1910.01007", "submitter": "John Mellor", "authors": "John F. J. Mellor, Eunbyung Park, Yaroslav Ganin, Igor Babuschkin,\n  Tejas Kulkarni, Dan Rosenbaum, Andy Ballard, Theophane Weber, Oriol Vinyals,\n  S. M. Ali Eslami", "title": "Unsupervised Doodling and Painting with Improved SPIRAL", "comments": "See https://learning-to-paint.github.io for an interactive version of\n  this paper, with videos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate using reinforcement learning agents as generative models of\nimages (extending arXiv:1804.01118). A generative agent controls a simulated\npainting environment, and is trained with rewards provided by a discriminator\nnetwork simultaneously trained to assess the realism of the agent's samples,\neither unconditional or reconstructions. Compared to prior work, we make a\nnumber of improvements to the architectures of the agents and discriminators\nthat lead to intriguing and at times surprising results. We find that when\nsufficiently constrained, generative agents can learn to produce images with a\ndegree of visual abstraction, despite having only ever seen real photographs\n(no human brush strokes). And given enough time with the painting environment,\nthey can produce images with considerable realism. These results show that,\nunder the right circumstances, some aspects of human drawing can emerge from\nsimulated embodiment, without the need for external supervision, imitation or\nsocial cues. Finally, we note the framework's potential for use in creative\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 15:12:06 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Mellor", "John F. J.", ""], ["Park", "Eunbyung", ""], ["Ganin", "Yaroslav", ""], ["Babuschkin", "Igor", ""], ["Kulkarni", "Tejas", ""], ["Rosenbaum", "Dan", ""], ["Ballard", "Andy", ""], ["Weber", "Theophane", ""], ["Vinyals", "Oriol", ""], ["Eslami", "S. M. Ali", ""]]}, {"id": "1910.01055", "submitter": "Srivatsan Krishnan", "authors": "Maximilian Lam, Sharad Chitlangia, Srivatsan Krishnan, Zishen Wan,\n  Gabriel Barth-Maron, Aleksandra Faust, Vijay Janapa Reddi", "title": "Quantized Reinforcement Learning (QUARL)", "comments": "Equal contribution from first three authors Updating the manuscript\n  with ActorQ results with Deepmind's ACME", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved significant milestones, however, the\ncomputational demands of reinforcement learning training and inference remain\nsubstantial. Quantization is an effective method to reduce the computational\noverheads of neural networks, though in the context of reinforcement learning,\nit is unknown whether quantization's computational benefits outweigh the\naccuracy costs introduced by the corresponding quantization error. To quantify\nthis tradeoff we perform a broad study applying quantization to reinforcement\nlearning. We apply standard quantization techniques such as post-training\nquantization (PTQ) and quantization aware training (QAT) to a comprehensive set\nof reinforcement learning tasks (Atari, Gym), algorithms (A2C, DDPG, DQN, D4PG,\nPPO), and models (MLPs, CNNs) and show that policies may be quantized to 8-bits\nwithout degrading reward, enabling significant inference speedups on\nresource-constrained edge devices. Motivated by the effectiveness of standard\nquantization techniques on reinforcement learning policies, we introduce a\nnovel quantization algorithm, \\textit{ActorQ}, for quantized actor-learner\ndistributed reinforcement learning training. By leveraging full precision\noptimization on the learner and quantized execution on the actors,\n\\textit{ActorQ} enables 8-bit inference while maintaining convergence. We\ndevelop a system for quantized reinforcement learning training around\n\\textit{ActorQ} and demonstrate end to end speedups of $>$ 1.5 $\\times$ - 2.5\n$\\times$ over full precision training on a range of tasks (Deepmind Control\nSuite). Finally, we break down the various runtime costs of distributed\nreinforcement learning training (such as communication time, inference time,\nmodel load time, etc) and evaluate the effects of quantization on these system\nattributes.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:22:29 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 21:44:52 GMT"}, {"version": "v3", "created": "Sat, 7 Dec 2019 00:57:49 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2021 20:05:26 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Lam", "Maximilian", ""], ["Chitlangia", "Sharad", ""], ["Krishnan", "Srivatsan", ""], ["Wan", "Zishen", ""], ["Barth-Maron", "Gabriel", ""], ["Faust", "Aleksandra", ""], ["Reddi", "Vijay Janapa", ""]]}, {"id": "1910.01059", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang, Osvaldo Simeone, Brian Gardner, and Andr\\'e Gr\\\"uning", "title": "An Introduction to Probabilistic Spiking Neural Networks: Probabilistic\n  Models, Learning Rules, and Applications", "comments": "Published in IEEE Signal Processing Magazine, Vol. 36, No. 6, pp.\n  64-77 (subsumes arXiv:1812.03929), Author's Accepted Manuscript", "journal-ref": null, "doi": "10.1109/MSP.2019.2935234", "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are distributed trainable systems whose\ncomputing elements, or neurons, are characterized by internal analog dynamics\nand by digital and sparse synaptic communications. The sparsity of the synaptic\nspiking inputs and the corresponding event-driven nature of neural processing\ncan be leveraged by energy-efficient hardware implementations, which can offer\nsignificant energy reductions as compared to conventional artificial neural\nnetworks (ANNs). The design of training algorithms lags behind the hardware\nimplementations. Most existing training algorithms for SNNs have been designed\neither for biological plausibility or through conversion from pretrained ANNs\nvia rate encoding. This article provides an introduction to SNNs by focusing on\na probabilistic signal processing methodology that enables the direct\nderivation of learning rules by leveraging the unique time-encoding\ncapabilities of SNNs. We adopt discrete-time probabilistic models for networked\nspiking neurons and derive supervised and unsupervised learning rules from\nfirst principles via variational inference. Examples and open research problems\nare also provided.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:28:34 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 18:14:03 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""], ["Gardner", "Brian", ""], ["Gr\u00fcning", "Andr\u00e9", ""]]}, {"id": "1910.01062", "submitter": "Chen Tessler", "authors": "Chen Tessler, Nadav Merlis and Shie Mannor", "title": "Stabilizing Deep Reinforcement Learning with Conservative Updates", "comments": "Under review at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, advances in deep learning have enabled the application of\nreinforcement learning algorithms in complex domains. However, they lack the\ntheoretical guarantees which are present in the tabular setting and suffer from\nmany stability and reproducibility problems \\citep{henderson2018deep}. In this\nwork, we suggest a simple approach for improving stability and providing\nprobabilistic performance improvement in off-policy actor-critic deep\nreinforcement learning regimes. Experiments on continuous action spaces, in the\nMuJoCo control suite, show that our proposed method reduces the variance of the\nprocess and improves the overall performance.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:32:25 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 09:56:55 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Tessler", "Chen", ""], ["Merlis", "Nadav", ""], ["Mannor", "Shie", ""]]}, {"id": "1910.01064", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem", "title": "Concept Drift Detection and Adaptation with Weak Supervision on\n  Streaming Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept drift in learning and classification occurs when the statistical\nproperties of either the data features or target change over time; evidence of\ndrift has appeared in search data, medical research, malware, web data, and\nvideo. Drift adaptation has not yet been addressed in high dimensional, noisy,\nlow-context data such as streaming text, video, or images due to the unique\nchallenges these domains present. We present a two-fold approach to deal with\nconcept drift in these domains: a density-based clustering approach to deal\nwith virtual concept drift (change in statistical properties of features) and a\nweak-supervision step to deal with real concept drift (change in statistical\nproperties of target). Our density-based clustering avoids problems posed by\nthe curse of dimensionality to create an evolving 'map' of the live data space,\nthereby addressing virtual drift in features. Our weak-supervision step\nleverages high-confidence labels (oracle or heuristic labels) to generate\nweighted training sets to generalize and update existing deep learners to adapt\nto changing decision boundaries (real drift) and create new deep learners for\nunseen regions of the data space. Our results show that our two-fold approach\nperforms well with >90% precision in 2018, four years after initial deployment\nin 2014, without any human intervention.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:33:51 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Suprem", "Abhijit", ""]]}, {"id": "1910.01067", "submitter": "Mohammad-Ali Javidian", "authors": "Mohammad Ali Javidian, Marco Valtorta, Pooyan Jamshidi", "title": "Order-Independent Structure Learning of Multivariate Regression Chain\n  Graphs", "comments": "This paper is an extended version of the accepted paper for SUM 2019\n  that will appear in the proceedings published by Springer in the Lecture\n  Notes in Artificial Intelligence (LNAI) series", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with multivariate regression chain graphs (MVR CGs), which\nwere introduced by Cox and Wermuth [3,4] to represent linear causal models with\ncorrelated errors. We consider the PC-like algorithm for structure learning of\nMVR CGs, which is a constraint-based method proposed by Sonntag and Pe\\~{n}a in\n[18]. We show that the PC-like algorithm is order-dependent, in the sense that\nthe output can depend on the order in which the variables are given. This\norder-dependence is a minor issue in low-dimensional settings. However, it can\nbe very pronounced in high-dimensional settings, where it can lead to highly\nvariable results. We propose two modifications of the PC-like algorithm that\nremove part or all of this order-dependence. Simulations under a variety of\nsettings demonstrate the competitive performance of our algorithms in\ncomparison with the original PC-like algorithm in low-dimensional settings and\nimproved performance in high-dimensional settings.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 14:07:55 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Valtorta", "Marco", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "1910.01074", "submitter": "Eleanor Quint", "authors": "Eleanor Quint and Dong Xu and Samuel Flint and Stephen Scott and\n  Matthew Dwyer", "title": "Formal Language Constraints for Markov Decision Processes", "comments": "NeurIPS 2019 Workshop on Safety and Robustness in Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to satisfy safety conditions, an agent may be constrained from\nacting freely. A safe controller can be designed a priori if an environment is\nwell understood, but not when learning is employed. In particular,\nreinforcement learned (RL) controllers require exploration, which can be\nhazardous in safety critical situations. We study the benefits of giving\nstructure to the constraints of a constrained Markov decision process by\nspecifying them in formal languages as a step towards using safety methods from\nsoftware engineering and controller synthesis. We instantiate these constraints\nas finite automata to efficiently recognise constraint violations. Constraint\nstates are then used to augment the underlying MDP state and to learn a dense\ncost function, easing the problem of quickly learning joint MDP/constraint\ndynamics. We empirically evaluate the effect of these methods on training a\nvariety of RL algorithms over several constraints specified in Safety Gym,\nMuJoCo, and Atari environments.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:45:23 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 22:38:36 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 18:00:26 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Quint", "Eleanor", ""], ["Xu", "Dong", ""], ["Flint", "Samuel", ""], ["Scott", "Stephen", ""], ["Dwyer", "Matthew", ""]]}, {"id": "1910.01075", "submitter": "Nan Rosemary Ke", "authors": "Nan Rosemary Ke, Olexa Bilaniuk, Anirudh Goyal, Stefan Bauer, Hugo\n  Larochelle, Bernhard Sch\\\"olkopf, Michael C. Mozer, Chris Pal, Yoshua Bengio", "title": "Learning Neural Causal Models from Unknown Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Promising results have driven a recent surge of interest in continuous\noptimization methods for Bayesian network structure learning from observational\ndata. However, there are theoretical limitations on the identifiability of\nunderlying structures obtained from observational data alone. Interventional\ndata provides much richer information about the underlying data-generating\nprocess. However, the extension and application of methods designed for\nobservational data to include interventions is not straightforward and remains\nan open problem. In this paper we provide a general framework based on\ncontinuous optimization and neural networks to create models for the\ncombination of observational and interventional data. The proposed method is\neven applicable in the challenging and realistic case that the identity of the\nintervened upon variable is unknown. We examine the proposed method in the\nsetting of graph recovery both de novo and from a partially-known edge set. We\nestablish strong benchmark results on several structure learning tasks,\nincluding structure recovery of both synthetic graphs as well as standard\ngraphs from the Bayesian Network Repository.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:50:15 GMT"}, {"version": "v2", "created": "Sun, 23 Aug 2020 04:23:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ke", "Nan Rosemary", ""], ["Bilaniuk", "Olexa", ""], ["Goyal", "Anirudh", ""], ["Bauer", "Stefan", ""], ["Larochelle", "Hugo", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Mozer", "Michael C.", ""], ["Pal", "Chris", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1910.01077", "submitter": "Konrad Zolna", "authors": "Konrad Zolna, Scott Reed, Alexander Novikov, Sergio Gomez Colmenarejo,\n  David Budden, Serkan Cabi, Misha Denil, Nando de Freitas, Ziyu Wang", "title": "Task-Relevant Adversarial Imitation Learning", "comments": "Accepted to CoRL 2020 (see presentation here:\n  https://youtu.be/ZgQvFGuEgFU )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a critical vulnerability in adversarial imitation is the\ntendency of discriminator networks to learn spurious associations between\nvisual features and expert labels. When the discriminator focuses on\ntask-irrelevant features, it does not provide an informative reward signal,\nleading to poor task performance. We analyze this problem in detail and propose\na solution that outperforms standard Generative Adversarial Imitation Learning\n(GAIL). Our proposed method, Task-Relevant Adversarial Imitation Learning\n(TRAIL), uses constrained discriminator optimization to learn informative\nrewards. In comprehensive experiments, we show that TRAIL can solve challenging\nrobotic manipulation tasks from pixels by imitating human operators without\naccess to any task rewards, and clearly outperforms comparable baseline\nimitation agents, including those trained via behaviour cloning and\nconventional GAIL.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:53:37 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 18:30:23 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Zolna", "Konrad", ""], ["Reed", "Scott", ""], ["Novikov", "Alexander", ""], ["Colmenarejo", "Sergio Gomez", ""], ["Budden", "David", ""], ["Cabi", "Serkan", ""], ["Denil", "Misha", ""], ["de Freitas", "Nando", ""], ["Wang", "Ziyu", ""]]}, {"id": "1910.01092", "submitter": "Orestes Manzanilla-Salazar M.Sc.", "authors": "Orestes Manzanilla-Salazar, Filippo Malandra, Hakim Mellah, Constant\n  Wette and Brunilde Sanso", "title": "A Machine Learning framework for Sleeping Cell Detection in a Smart-city\n  IoT Telecommunications Infrastructure", "comments": "Submitted to the IEEE Access Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The smooth operation of largely deployed Internet of Things (IoT)\napplications will depend on, among other things, effective infrastructure\nfailure detection. Access failures in wireless network Base Stations (BSs)\nproduce a phenomenon called \"sleeping cells\", which can render a cell catatonic\nwithout triggering any alarms or provoking immediate effects on cell\nperformance, making them difficult to discover. To detect this kind of failure,\nwe propose a Machine Learning (ML) framework based on the use of Key\nPerformance Indicator (KPI) statistics from the BS under study, as well as\nthose of the neighboring BSs with propensity to have their performance affected\nby the failure. A simple way to define neighbors is to use adjacency in Voronoi\ndiagrams. In this paper, we propose a much more realistic approach based on the\nnature of radio-propagation and the way devices choose the BS to which they\nsend access requests. We gather data from large-scale simulators that use real\nlocation data for BSs and IoT devices and pose the detection problem as a\nsupervised binary classification problem. We measure the effects on the\ndetection performance by the size of time aggregations of the data, the level\nof traffic and the parameters of the neighborhood definition. The Extra Trees\nand Naive Bayes classifiers achieve Receiver Operating Characteristic (ROC)\nArea Under the Curve (AUC) scores of 0.996 and 0.993, respectively, with False\nPositive Rate (FPR) under 5 %. The proposed framework holds potential for other\npattern recognition tasks in smart-city wireless infrastructures, that would\nenable the monitoring, prediction and improvement of the Quality of Service\n(QoS) experienced by IoT applications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 17:17:22 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 18:47:28 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Manzanilla-Salazar", "Orestes", ""], ["Malandra", "Filippo", ""], ["Mellah", "Hakim", ""], ["Wette", "Constant", ""], ["Sanso", "Brunilde", ""]]}, {"id": "1910.01112", "submitter": "Utkarsh Ojha", "authors": "Utkarsh Ojha, Krishna Kumar Singh, Cho-Jui Hsieh, Yong Jae Lee", "title": "Elastic-InfoGAN: Unsupervised Disentangled Representation Learning in\n  Class-Imbalanced Data", "comments": "Camera ready version for NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel unsupervised generative model that learns to disentangle\nobject identity from other low-level aspects in class-imbalanced data. We first\ninvestigate the issues surrounding the assumptions about uniformity made by\nInfoGAN, and demonstrate its ineffectiveness to properly disentangle object\nidentity in imbalanced data. Our key idea is to make the discovery of the\ndiscrete latent factor of variation invariant to identity-preserving\ntransformations in real images, and use that as a signal to learn the\nappropriate latent distribution representing object identity. Experiments on\nboth artificial (MNIST, 3D cars, 3D chairs, ShapeNet) and real-world\n(YouTube-Faces) imbalanced datasets demonstrate the effectiveness of our method\nin disentangling object identity as a latent factor of variation.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:50:44 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 10:48:53 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Ojha", "Utkarsh", ""], ["Singh", "Krishna Kumar", ""], ["Hsieh", "Cho-Jui", ""], ["Lee", "Yong Jae", ""]]}, {"id": "1910.01113", "submitter": "Johannes Leuschner", "authors": "Johannes Leuschner, Maximilian Schmidt, Daniel Otero Baguer, Peter\n  Maa{\\ss}", "title": "The LoDoPaB-CT Dataset: A Benchmark Dataset for Low-Dose CT\n  Reconstruction Methods", "comments": null, "journal-ref": "Scientific Data Volume 8, Article number: 109 (2021)", "doi": "10.1038/s41597-021-00893-z", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Learning approaches for solving Inverse Problems in imaging have become\nvery effective and are demonstrated to be quite competitive in the field.\nComparing these approaches is a challenging task since they highly rely on the\ndata and the setup that is used for training. We provide a public dataset of\ncomputed tomography images and simulated low-dose measurements suitable for\ntraining this kind of methods. With the LoDoPaB-CT Dataset we aim to create a\nbenchmark that allows for a fair comparison. It contains over 40,000 scan\nslices from around 800 patients selected from the LIDC/IDRI Database. In this\npaper we describe how we processed the original slices and how we simulated the\nmeasurements. We also include first baseline results.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 18:59:45 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 15:00:35 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Leuschner", "Johannes", ""], ["Schmidt", "Maximilian", ""], ["Baguer", "Daniel Otero", ""], ["Maa\u00df", "Peter", ""]]}, {"id": "1910.01114", "submitter": "Vinayakumar R", "authors": "Shisrut Rawat, Aishwarya Srinivasan, and Vinayakumar R", "title": "Intrusion detection systems using classical machine learning techniques\n  versus integrated unsupervised feature learning and deep neural network", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security analysts and administrators face a lot of challenges to detect and\nprevent network intrusions in their organizations, and to prevent network\nbreaches, detecting the breach on time is crucial. Challenges arise while\ndetecting unforeseen attacks. This work includes a performance comparison of\nclassical machine learning approaches that require vast feature engineering,\nversus integrated unsupervised feature learning and deep neural networks on the\nNSL-KDD dataset. Various trials of experiments were run to identify suitable\nhyper-parameters and network configurations of machine learning models. The DNN\nusing 15 features extracted using Principal Component analysis was the most\neffective modeling method. The further analysis using the Software Defined\nNetworking features also presented a good accuracy using Deep Neural network.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 23:48:20 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Rawat", "Shisrut", ""], ["Srinivasan", "Aishwarya", ""], ["R", "Vinayakumar", ""]]}, {"id": "1910.01116", "submitter": "Irene Y. Chen", "authors": "Irene Y. Chen, Monica Agrawal, Steven Horng, David Sontag", "title": "Robustly Extracting Medical Knowledge from EHRs: A Case Study of\n  Learning a Health Knowledge Graph", "comments": "12 pages, presented at PSB 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly large electronic health records (EHRs) provide an opportunity to\nalgorithmically learn medical knowledge. In one prominent example, a causal\nhealth knowledge graph could learn relationships between diseases and symptoms\nand then serve as a diagnostic tool to be refined with additional clinical\ninput. Prior research has demonstrated the ability to construct such a graph\nfrom over 270,000 emergency department patient visits. In this work, we\ndescribe methods to evaluate a health knowledge graph for robustness. Moving\nbeyond precision and recall, we analyze for which diseases and for which\npatients the graph is most accurate. We identify sample size and unmeasured\nconfounders as major sources of error in the health knowledge graph. We\nintroduce a method to leverage non-linear functions in building the causal\ngraph to better understand existing model assumptions. Finally, to assess model\ngeneralizability, we extend to a larger set of complete patient visits within a\nhospital system. We conclude with a discussion on how to robustly extract\nmedical knowledge from EHRs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 03:42:03 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Chen", "Irene Y.", ""], ["Agrawal", "Monica", ""], ["Horng", "Steven", ""], ["Sontag", "David", ""]]}, {"id": "1910.01155", "submitter": "Paul K. Faehrmann", "authors": "Ryan Sweke, Frederik Wilde, Johannes Meyer, Maria Schuld, Paul K.\n  Faehrmann, Barth\\'el\\'emy Meynard-Piganeau and Jens Eisert", "title": "Stochastic gradient descent for hybrid quantum-classical optimization", "comments": "Significantly revised version - accepted in Quantum. Includes\n  reference and discussion of earlier related work by Harrow and Napp\n  (arXiv:1901.05374)", "journal-ref": "Quantum 4, 314 (2020)", "doi": "10.22331/q-2020-08-31-314", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Within the context of hybrid quantum-classical optimization, gradient descent\nbased optimizers typically require the evaluation of expectation values with\nrespect to the outcome of parameterized quantum circuits. In this work, we\nexplore the consequences of the prior observation that estimation of these\nquantities on quantum hardware results in a form of stochastic gradient descent\noptimization. We formalize this notion, which allows us to show that in many\nrelevant cases, including VQE, QAOA and certain quantum classifiers, estimating\nexpectation values with $k$ measurement outcomes results in optimization\nalgorithms whose convergence properties can be rigorously well understood, for\nany value of $k$. In fact, even using single measurement outcomes for the\nestimation of expectation values is sufficient. Moreover, in many settings the\nrequired gradients can be expressed as linear combinations of expectation\nvalues -- originating, e.g., from a sum over local terms of a Hamiltonian, a\nparameter shift rule, or a sum over data-set instances -- and we show that in\nthese cases $k$-shot expectation value estimation can be combined with sampling\nover terms of the linear combination, to obtain \"doubly stochastic\" gradient\ndescent optimizers. For all algorithms we prove convergence guarantees,\nproviding a framework for the derivation of rigorous optimization results in\nthe context of near-term quantum devices. Additionally, we explore numerically\nthese methods on benchmark VQE, QAOA and quantum-enhanced machine learning\ntasks and show that treating the stochastic settings as hyper-parameters allows\nfor state-of-the-art results with significantly fewer circuit executions and\nmeasurements.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 18:25:45 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 16:25:47 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 13:54:41 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Sweke", "Ryan", ""], ["Wilde", "Frederik", ""], ["Meyer", "Johannes", ""], ["Schuld", "Maria", ""], ["Faehrmann", "Paul K.", ""], ["Meynard-Piganeau", "Barth\u00e9l\u00e9my", ""], ["Eisert", "Jens", ""]]}, {"id": "1910.01161", "submitter": "Siddhant Garg", "authors": "Siddhant Garg, Aditya Kumar Akash", "title": "Stochastic Bandits with Delayed Composite Anonymous Feedback", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS)\n  Workshop on Machine Learning with Guarantees", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore a novel setting of the Multi-Armed Bandit (MAB) problem inspired\nfrom real world applications which we call bandits with \"stochastic delayed\ncomposite anonymous feedback (SDCAF)\". In SDCAF, the rewards on pulling arms\nare stochastic with respect to time but spread over a fixed number of time\nsteps in the future after pulling the arm. The complexity of this problem stems\nfrom the anonymous feedback to the player and the stochastic generation of the\nreward. Due to the aggregated nature of the rewards, the player is unable to\nassociate the reward to a particular time step from the past. We present two\nalgorithms for this more complicated setting of SDCAF using phase based\nextensions of the UCB algorithm. We perform regret analysis to show sub-linear\ntheoretical guarantees on both the algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 18:49:16 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 06:05:12 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Garg", "Siddhant", ""], ["Akash", "Aditya Kumar", ""]]}, {"id": "1910.01170", "submitter": "Jessica Whittlestone", "authors": "Jess Whittlestone, Aviv Ovadya", "title": "The tension between openness and prudence in AI research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores the tension between openness and prudence in AI research,\nevident in two core principles of the Montr\\'eal Declaration for Responsible\nAI. While the AI community has strong norms around open sharing of research,\nconcerns about the potential harms arising from misuse of research are growing,\nprompting some to consider whether the field of AI needs to reconsider\npublication norms. We discuss how different beliefs and values can lead to\ndiffering perspectives on how the AI community should manage this tension, and\nexplore implications for what responsible publication norms in AI research\nmight look like in practice.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 19:09:43 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 14:51:59 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Whittlestone", "Jess", ""], ["Ovadya", "Aviv", ""]]}, {"id": "1910.01177", "submitter": "Augustus Odena", "authors": "Zhengli Zhao, Nicolas Papernot, Sameer Singh, Neoklis Polyzotis,\n  Augustus Odena", "title": "Improving Differentially Private Models with Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Broad adoption of machine learning techniques has increased privacy concerns\nfor models trained on sensitive data such as medical records. Existing\ntechniques for training differentially private (DP) models give rigorous\nprivacy guarantees, but applying these techniques to neural networks can\nseverely degrade model performance. This performance reduction is an obstacle\nto deploying private models in the real world. In this work, we improve the\nperformance of DP models by fine-tuning them through active learning on public\ndata. We introduce two new techniques - DIVERSEPUBLIC and NEARPRIVATE - for\ndoing this fine-tuning in a privacy-aware way. For the MNIST and SVHN datasets,\nthese techniques improve state-of-the-art accuracy for DP models while\nretaining privacy guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 19:24:31 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Zhao", "Zhengli", ""], ["Papernot", "Nicolas", ""], ["Singh", "Sameer", ""], ["Polyzotis", "Neoklis", ""], ["Odena", "Augustus", ""]]}, {"id": "1910.01178", "submitter": "Arnaud Mignan", "authors": "Arnaud Mignan, Marco Broccardo", "title": "Neural Network Applications in Earthquake Prediction (1994-2019):\n  Meta-Analytic Insight on their Limitations", "comments": "25 pages, 7 figures", "journal-ref": "Seismological Research Letters, 2020", "doi": "10.1785/0220200021", "report-no": null, "categories": "cs.NE cs.LG physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, deep learning has solved seemingly intractable\nproblems, boosting the hope to find approximate solutions to problems that now\nare considered unsolvable. Earthquake prediction, the Grail of Seismology, is,\nin this context of continuous exciting discoveries, an obvious choice for deep\nlearning exploration. We review the entire literature of artificial neural\nnetwork (ANN) applications for earthquake prediction (77 articles, 1994-2019\nperiod) and find two emerging trends: an increasing interest in this domain,\nand a complexification of ANN models over time, towards deep learning. Despite\napparent positive results observed in this corpus, we demonstrate that simpler\nmodels seem to offer similar predictive powers, if not better ones. Due to the\nstructured, tabulated nature of earthquake catalogues, and the limited number\nof features so far considered, simpler and more transparent machine learning\nmodels seem preferable at the present stage of research. Those baseline models\nfollow first physical principles and are consistent with the known empirical\nlaws of Statistical Seismology, which have minimal abilities to predict large\nearthquakes.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 19:28:34 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Mignan", "Arnaud", ""], ["Broccardo", "Marco", ""]]}, {"id": "1910.01179", "submitter": "Eric Zhan", "authors": "Eric Zhan, Albert Tseng, Yisong Yue, Adith Swaminathan, Matthew\n  Hausknecht", "title": "Learning Calibratable Policies using Programmatic Style-Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of controllable generation of long-term sequential\nbehaviors, where the goal is to calibrate to multiple behavior styles\nsimultaneously. In contrast to the well-studied areas of controllable\ngeneration of images, text, and speech, there are two questions that pose\nsignificant challenges when generating long-term behaviors: how should we\nspecify the factors of variation to control, and how can we ensure that the\ngenerated behavior faithfully demonstrates combinatorially many styles? We\nleverage programmatic labeling functions to specify controllable styles, and\nderive a formal notion of style-consistency as a learning objective, which can\nthen be solved using conventional policy learning approaches. We evaluate our\nframework using demonstrations from professional basketball players and agents\nin the MuJoCo physics environment, and show that existing approaches that do\nnot explicitly enforce style-consistency fail to generate diverse behaviors\nwhereas our learned policies can be calibrated for up to 1024 distinct style\ncombinations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 19:34:51 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 00:26:26 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 04:42:13 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Zhan", "Eric", ""], ["Tseng", "Albert", ""], ["Yue", "Yisong", ""], ["Swaminathan", "Adith", ""], ["Hausknecht", "Matthew", ""]]}, {"id": "1910.01180", "submitter": "Thomas Magelinski", "authors": "Thomas Magelinski, David Beskow, Kathleen M. Carley", "title": "Graph-Hist: Graph Classification from Latent Feature Histograms With\n  Application to Bot Detection", "comments": null, "journal-ref": "AAAI 2020 (pp. 5134-5141)", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly used for graph classification in a variety\nof contexts. Social media is a critical application area in this space, however\nthe characteristics of social media graphs differ from those seen in most\npopular benchmark datasets. Social networks tend to be large and sparse, while\nbenchmarks are small and dense. Classically, large and sparse networks are\nanalyzed by studying the distribution of local properties. Inspired by this, we\nintroduce Graph-Hist: an end-to-end architecture that extracts a graph's latent\nlocal features, bins nodes together along 1-D cross sections of the feature\nspace, and classifies the graph based on this multi-channel histogram. We show\nthat Graph-Hist improves state of the art performance on true social media\nbenchmark datasets, while still performing well on other benchmarks. Finally,\nwe demonstrate Graph-Hist's performance by conducting bot detection in social\nmedia. While sophisticated bot and cyborg accounts increasingly evade\ntraditional detection methods, they leave artificial artifacts in their\nconversational graph that are detected through graph classification. We apply\nGraph-Hist to classify these conversational graphs. In the process, we confirm\nthat social media graphs are different than most baselines and that Graph-Hist\noutperforms existing bot-detection models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 19:35:13 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Magelinski", "Thomas", ""], ["Beskow", "David", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "1910.01182", "submitter": "Salimeh Yasaei Sekeh", "authors": "Salimeh Yasaei Sekeh, Madan Ravi Ganesh, Shurjo Banerjee, Jason J.\n  Corso, and Alfred O. Hero", "title": "A Geometric Approach to Online Streaming Feature Selection", "comments": "10 page, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Streaming Feature Selection (OSFS) is a sequential learning problem\nwhere individual features across all samples are made available to algorithms\nin a streaming fashion. In this work, firstly, we assert that OSFS's main\nassumption of having data from all the samples available at runtime is\nunrealistic and introduce a new setting where features and samples are streamed\nconcurrently called OSFS with Streaming Samples (OSFS-SS). Secondly, the\nprimary OSFS method, SAOLA utilizes an unbounded mutual information measure and\nrequires multiple comparison steps between the stored and incoming feature sets\nto evaluate a feature's importance. We introduce Geometric Online Adaption, an\nalgorithm that requires relatively less feature comparison steps and uses a\nbounded conditional geometric dependency measure. Our algorithm outperforms\nseveral OSFS baselines including SAOLA on a variety of datasets. We also extend\nSAOLA to work in the OSFS-SS setting and show that GOA continues to achieve the\nbest results. Thirdly, the current paradigm of the OSFS algorithm comparison is\nflawed. Algorithms are measured by comparing the number of features used and\nthe accuracy obtained by the learner, two properties that are fundamentally at\nodds with one another. Without fixing a limit on either of these properties,\nthe qualities of features obtained by different algorithms are incomparable. We\ntry to rectify this inconsistency by fixing the maximum number of features\navailable to the learner and comparing algorithms in terms of their accuracy.\nAdditionally, we characterize the behaviour of SAOLA and GOA on feature sets\nderived from popular deep convolutional featurizers.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 19:36:46 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 04:49:21 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Sekeh", "Salimeh Yasaei", ""], ["Ganesh", "Madan Ravi", ""], ["Banerjee", "Shurjo", ""], ["Corso", "Jason J.", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1910.01191", "submitter": "Yu Liang", "authors": "Dakila Ledesma, Yu Liang, and Dalei Wu", "title": "Adaptive Generation of Phantom Limbs Using Visible Hierarchical\n  Autoencoders", "comments": "arXiv admin note: text overlap with arXiv:1612.06336 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposed a hierarchical visible autoencoder in the adaptive\nphantom limbs generation according to the kinetic behavior of functional\nbody-parts, which are measured by heterogeneous kinetic sensors. The proposed\nvisible hierarchical autoencoder consists of interpretable and multi-correlated\nautoencoder pipelines, which is directly derived from the hierarchical network\ndescribed in forest data-structure. According to specified kinetic script\n(e.g., dancing, running, etc.) and users' physical conditions, hierarchical\nnetwork is extracted from human musculoskeletal network, which is fabricated by\nmultiple body components (e.g., muscle, bone, and joints, etc.) that are\nbio-mechanically, functionally, or nervously correlated with each other and\nexhibit mostly non-divergent kinetic behaviors. Multi-layer perceptron (MLP)\nregressor models, as well as several variations of autoencoder models, are\ninvestigated for the sequential generation of missing or dysfunctional limbs.\nThe resulting kinematic behavior of phantom limbs will be constructed using\nvirtual reality and augmented reality (VR/AR), actuators, and potentially\ncontroller for a prosthesis (an artificial device that replaces a missing body\npart). The addressed work aims to develop practical innovative exercise methods\nthat (1) engage individuals at all ages, including those with a chronic health\ncondition(s) and/or disability, in regular physical activities, (2) accelerate\nthe rehabilitation of patients, and (3) release users' phantom limb pain. The\nphysiological and psychological impact of the addressed work will critically be\nassessed in future work.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 19:54:19 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Ledesma", "Dakila", ""], ["Liang", "Yu", ""], ["Wu", "Dalei", ""]]}, {"id": "1910.01196", "submitter": "Chih-Chieh Yang", "authors": "Chih-Chieh Yang and Guojing Cong", "title": "Accelerating Data Loading in Deep Neural Network Training", "comments": "11 pages, 12 figures, accepted for publication in IEEE International\n  Conference on High Performance Computing, Data and Analytics (HiPC) 2019", "journal-ref": null, "doi": "10.1109/HiPC.2019.00037", "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data loading can dominate deep neural network training time on large-scale\nsystems. We present a comprehensive study on accelerating data loading\nperformance in large-scale distributed training. We first identify performance\nand scalability issues in current data loading implementations. We then propose\noptimizations that utilize CPU resources to the data loader design. We use an\nanalytical model to characterize the impact of data loading on the overall\ntraining time and establish the performance trend as we scale up distributed\ntraining. Our model suggests that I/O rate limits the scalability of\ndistributed training, which inspires us to design a locality-aware data loading\nmethod. By utilizing software caches, our method can drastically reduce the\ndata loading communication volume in comparison with the original data loading\nimplementation. Finally, we evaluate the proposed optimizations with various\nexperiments. We achieved more than 30x speedup in data loading using 256 nodes\nwith 1,024 learners.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 20:03:02 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Yang", "Chih-Chieh", ""], ["Cong", "Guojing", ""]]}, {"id": "1910.01210", "submitter": "Mihir Prabhudesai", "authors": "Mihir Prabhudesai, Hsiao-Yu Fish Tung, Syed Ashar Javed, Maximilian\n  Sieb, Adam W. Harley, Katerina Fragkiadaki", "title": "Embodied Language Grounding with 3D Visual Feature Representations", "comments": null, "journal-ref": "Conference on Computer Vision and Pattern Recognition. 2020, pp.\n  2220-2229", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose associating language utterances to 3D visual abstractions of the\nscene they describe. The 3D visual abstractions are encoded as 3-dimensional\nvisual feature maps. We infer these 3D visual scene feature maps from RGB\nimages of the scene via view prediction: when the generated 3D scene feature\nmap is neurally projected from a camera viewpoint, it should match the\ncorresponding RGB image. We present generative models that condition on the\ndependency tree of an utterance and generate a corresponding visual 3D feature\nmap as well as reason about its plausibility, and detector models that\ncondition on both the dependency tree of an utterance and a related image and\nlocalize the object referents in the 3D feature map inferred from the image.\nOur model outperforms models of language and vision that associate language\nwith 2D CNN activations or 2D images by a large margin in a variety of tasks,\nsuch as, classifying plausibility of utterances, detecting referential\nexpressions, and supplying rewards for trajectory optimization of object\nplacement policies from language instructions. We perform numerous ablations\nand show the improved performance of our detectors is due to its better\ngeneralization across camera viewpoints and lack of object interferences in the\ninferred 3D feature space, and the improved performance of our generators is\ndue to their ability to spatially reason about objects and their configurations\nin 3D when mapping from language to scenes.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 20:37:27 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 16:04:27 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 21:31:18 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Prabhudesai", "Mihir", ""], ["Tung", "Hsiao-Yu Fish", ""], ["Javed", "Syed Ashar", ""], ["Sieb", "Maximilian", ""], ["Harley", "Adam W.", ""], ["Fragkiadaki", "Katerina", ""]]}, {"id": "1910.01211", "submitter": "Gabriele Franch", "authors": "Gabriele Franch, Giuseppe Jurman, Luca Coviello, Marta Pendesini,\n  Cesare Furlanello", "title": "MASS-UMAP: Fast and accurate analog ensemble search in weather radar\n  archive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of analogs - similar weather patterns - for weather forecasting and\nanalysis is an established method in meteorology. The most challenging aspect\nof using this approach in the context of operational radar applications is to\nbe able to perform a fast and accurate search for similar spatiotemporal\nprecipitation patterns in a large archive of historical records. In this\ncontext, sequential pairwise search is too slow and computationally expensive.\nHere we propose an architecture to significantly speed-up spatiotemporal analog\nretrieval by combining nonlinear geometric dimensionality reduction (UMAP) with\nthe fastest known Euclidean search algorithm for time series (MASS) to find\nradar analogs in constant time, independently of the desired temporal length to\nmatch and the number of extracted analogs. We compare UMAP with Principal\ncomponent analysis (PCA) and show that UMAP outperforms PCA for spatial MSE\nanalog search with proper settings. Moreover, we show that MASS is 20 times\nfaster than brute force search on the UMAP embeddings space. We test the\narchitecture on a real dataset and show that it enables precise and fast\noperational analog ensemble search through more than 2 years of radar archive\nin less than 5 seconds on a single workstation.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:32:51 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Franch", "Gabriele", ""], ["Jurman", "Giuseppe", ""], ["Coviello", "Luca", ""], ["Pendesini", "Marta", ""], ["Furlanello", "Cesare", ""]]}, {"id": "1910.01212", "submitter": "Vahid Moraveji Hashemi", "authors": "Vahid Moraveji Hashemi", "title": "Social Influence and Radicalization: A Social Data Analytics Study", "comments": "Master Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The confluence of technological and societal advances is changing the nature\nof global terrorism. For example, engagement with Web, social media, and smart\ndevices has the potential to affect the mental behavior of the individuals and\ninfluence extremist and criminal behaviors such as Radicalization. In this\ncontext, social data analytics (i.e., the discovery, interpretation, and\ncommunication of meaningful patterns in social data) and influence maximization\n(i.e., the problem of finding a small subset of nodes in a social network which\ncan maximize the propagation of influence) has the potential to become a vital\nasset to explore the factors involved in influencing people to participate in\nextremist activities.\n  To address this challenge, we study and analyze the recent work done in\ninfluence maximization and social data analytics from effectiveness, efficiency\nand scalability viewpoints. We introduce a social data analytics pipeline,\nnamely iRadical, to enable analysts engage with social data to explore the\npotential for online radicalization. In iRadical, we present algorithms to\nanalyse the social data as well as the user activity patterns to learn how\ninfluence flows in social networks. We implement iRadical as an extensible\narchitecture that is publicly available on GitHub and present the evaluation\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 02:36:59 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Hashemi", "Vahid Moraveji", ""]]}, {"id": "1910.01213", "submitter": "Kyri Baker", "authors": "Ahmed Zamzam and Kyri Baker", "title": "Learning Optimal Solutions for Extremely Fast AC Optimal Power Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an online method that leverages machine learning to\nobtain feasible solutions to the AC optimal power flow (OPF) problem with\nnegligible optimality gaps on extremely fast timescales (e.g., milliseconds),\nbypassing solving an AC OPF altogether. This is motivated by the fact that as\nthe power grid experiences increasing amounts of renewable power generation,\ncontrollable loads, and other inverter-interfaced devices, faster system\ndynamics and quicker fluctuations in the power supply are likely to occur.\nCurrently, grid operators typically solve AC OPF every 15 minutes to determine\neconomic generator settings while ensuring grid constraints are satisfied. Due\nto the computational challenges with solving this nonconvex problem, many\nefforts have focused on linearizing or approximating the problem in order to\nsolve the AC OPF on faster timescales. However, many of these approximations\ncan be fairly poor representations of the actual system state and still require\nsolving an optimization problem, which can be time consuming for large\nnetworks. In this work, we leverage historical data to learn a mapping between\nthe system loading and optimal generation values, enabling us to find\nnear-optimal and feasible AC OPF solutions on extremely fast timescales without\nactually solving an optimization problem.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 17:47:10 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Zamzam", "Ahmed", ""], ["Baker", "Kyri", ""]]}, {"id": "1910.01215", "submitter": "Xingyou Song", "authors": "Xingyou Song, Wenbo Gao, Yuxiang Yang, Krzysztof Choromanski, Aldo\n  Pacchiano, Yunhao Tang", "title": "ES-MAML: Simple Hessian-Free Meta Learning", "comments": "Published as a conference paper in ICLR 2020. Code can be found in\n  http://github.com/google-research/google-research/tree/master/es_maml", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce ES-MAML, a new framework for solving the model agnostic meta\nlearning (MAML) problem based on Evolution Strategies (ES). Existing algorithms\nfor MAML are based on policy gradients, and incur significant difficulties when\nattempting to estimate second derivatives using backpropagation on stochastic\npolicies. We show how ES can be applied to MAML to obtain an algorithm which\navoids the problem of estimating second derivatives, and is also conceptually\nsimple and easy to implement. Moreover, ES-MAML can handle new types of\nnonsmooth adaptation operators, and other techniques for improving performance\nand estimation of ES methods become applicable. We show empirically that\nES-MAML is competitive with existing methods and often yields better adaptation\nwith fewer queries.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 19:28:33 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 20:39:22 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 15:30:11 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 15:49:16 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Song", "Xingyou", ""], ["Gao", "Wenbo", ""], ["Yang", "Yuxiang", ""], ["Choromanski", "Krzysztof", ""], ["Pacchiano", "Aldo", ""], ["Tang", "Yunhao", ""]]}, {"id": "1910.01226", "submitter": "Emily Wenger", "authors": "Huiying Li, Emily Wenger, Shawn Shan, Ben Y. Zhao, Haitao Zheng", "title": "Piracy Resistant Watermarks for Deep Neural Networks", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As companies continue to invest heavily in larger, more accurate and more\nrobust deep learning models, they are exploring approaches to monetize their\nmodels while protecting their intellectual property. Model licensing is\npromising, but requires a robust tool for owners to claim ownership of models,\ni.e. a watermark. Unfortunately, current designs have not been able to address\npiracy attacks, where third parties falsely claim model ownership by embedding\ntheir own \"pirate watermarks\" into an already-watermarked model. We observe\nthat resistance to piracy attacks is fundamentally at odds with the current use\nof incremental training to embed watermarks into models. In this work, we\npropose null embedding, a new way to build piracy-resistant watermarks into\nDNNs that can only take place at a model's initial training. A null embedding\ntakes a bit string (watermark value) as input, and builds strong dependencies\nbetween the model's normal classification accuracy and the watermark. As a\nresult, attackers cannot remove an embedded watermark via tuning or incremental\ntraining, and cannot add new pirate watermarks to already watermarked models.\nWe empirically show that our proposed watermarks achieve piracy resistance and\nother watermark properties, over a wide range of tasks and models. Finally, we\nexplore a number of adaptive counter-measures, and show our watermark remains\nrobust against a variety of model modifications, including model fine-tuning,\ncompression, and existing methods to detect/remove backdoors. Our watermarked\nmodels are also amenable to transfer learning without losing their watermark\nproperties.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 21:20:06 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 14:48:01 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 21:22:45 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Li", "Huiying", ""], ["Wenger", "Emily", ""], ["Shan", "Shawn", ""], ["Zhao", "Ben Y.", ""], ["Zheng", "Haitao", ""]]}, {"id": "1910.01240", "submitter": "Shresth Verma", "authors": "Shresth Verma, Haritha S. Nair, Gaurav Agarwal, Joydip Dhar, Anupam\n  Shukla", "title": "Deep Reinforcement Learning for Single-Shot Diagnosis and Adaptation in\n  Damaged Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotics has proved to be an indispensable tool in many industrial as well as\nsocial applications, such as warehouse automation, manufacturing, disaster\nrobotics, etc. In most of these scenarios, damage to the agent while\naccomplishing mission-critical tasks can result in failure. To enable robotic\nadaptation in such situations, the agent needs to adopt policies which are\nrobust to a diverse set of damages and must do so with minimum computational\ncomplexity. We thus propose a damage aware control architecture which diagnoses\nthe damage prior to gait selection while also incorporating domain\nrandomization in the damage space for learning a robust policy. To implement\ndamage awareness, we have used a Long Short Term Memory based supervised\nlearning network which diagnoses the damage and predicts the type of damage.\nThe main novelty of this approach is that only a single policy is trained to\nadapt against a wide variety of damages and the diagnosis is done in a single\ntrial at the time of damage.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 22:16:40 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Verma", "Shresth", ""], ["Nair", "Haritha S.", ""], ["Agarwal", "Gaurav", ""], ["Dhar", "Joydip", ""], ["Shukla", "Anupam", ""]]}, {"id": "1910.01249", "submitter": "James Preiss", "authors": "James A. Preiss, S\\'ebastien M. R. Arnold, Chen-Yu Wei, Marius Kloft", "title": "Analyzing the Variance of Policy Gradient Estimators for the\n  Linear-Quadratic Regulator", "comments": "Accepted at NeurIPS 2019 Workshop on Optimization Foundations for\n  Reinforcement Learning. 7 pages + 6 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the variance of the REINFORCE policy gradient estimator in\nenvironments with continuous state and action spaces, linear dynamics,\nquadratic cost, and Gaussian noise. These simple environments allow us to\nderive bounds on the estimator variance in terms of the environment and noise\nparameters. We compare the predictions of our bounds to the empirical variance\nin simulation experiments.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 23:18:59 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Preiss", "James A.", ""], ["Arnold", "S\u00e9bastien M. R.", ""], ["Wei", "Chen-Yu", ""], ["Kloft", "Marius", ""]]}, {"id": "1910.01254", "submitter": "Masih Aminbeidokhti", "authors": "Masih Aminbeidokhti, Marco Pedersoli, Patrick Cardinal, Eric Granger", "title": "Emotion Recognition with Spatial Attention and Temporal Softmax Pooling", "comments": "9 pages; 2 figures; 2 tables; Best paper award at ICIAR 2019", "journal-ref": null, "doi": "10.1007/978-3-030-27202-9_29", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video-based emotion recognition is a challenging task because it requires to\ndistinguish the small deformations of the human face that represent emotions,\nwhile being invariant to stronger visual differences due to different\nidentities. State-of-the-art methods normally use complex deep learning models\nsuch as recurrent neural networks (RNNs, LSTMs, GRUs), convolutional neural\nnetworks (CNNs, C3D, residual networks) and their combination. In this paper,\nwe propose a simpler approach that combines a CNN pre-trained on a public\ndataset of facial images with (1) a spatial attention mechanism, to localize\nthe most important regions of the face for a given emotion, and (2) temporal\nsoftmax pooling, to select the most important frames of the given video.\nResults on the challenging EmotiW dataset show that this approach can achieve\nhigher accuracy than more complex approaches.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 23:53:10 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 02:52:19 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Aminbeidokhti", "Masih", ""], ["Pedersoli", "Marco", ""], ["Cardinal", "Patrick", ""], ["Granger", "Eric", ""]]}, {"id": "1910.01255", "submitter": "Yiping Lu", "authors": "Bin Dong, Jikai Hou, Yiping Lu, Zhihua Zhang", "title": "Distillation $\\approx$ Early Stopping? Harvesting Dark Knowledge\n  Utilizing Anisotropic Information Retrieval For Overparameterized Neural\n  Network", "comments": "Accepted by NeurIPS 2019 Workshop on Machine Learning with\n  Guarantees. Submitted to other places", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distillation is a method to transfer knowledge from one model to another and\noften achieves higher accuracy with the same capacity. In this paper, we aim to\nprovide a theoretical understanding on what mainly helps with the distillation.\nOur answer is \"early stopping\". Assuming that the teacher network is\noverparameterized, we argue that the teacher network is essentially harvesting\ndark knowledge from the data via early stopping. This can be justified by a new\nconcept, {Anisotropic Information Retrieval (AIR)}, which means that the neural\nnetwork tends to fit the informative information first and the non-informative\ninformation (including noise) later. Motivated by the recent development on\ntheoretically analyzing overparameterized neural networks, we can characterize\nAIR by the eigenspace of the Neural Tangent Kernel(NTK). AIR facilities a new\nunderstanding of distillation. With that, we further utilize distillation to\nrefine noisy labels. We propose a self-distillation algorithm to sequentially\ndistill knowledge from the network in the previous training epoch to avoid\nmemorizing the wrong labels. We also demonstrate, both theoretically and\nempirically, that self-distillation can benefit from more than just early\nstopping. Theoretically, we prove convergence of the proposed algorithm to the\nground truth labels for randomly initialized overparameterized neural networks\nin terms of $\\ell_2$ distance, while the previous result was on convergence in\n$0$-$1$ loss. The theoretical result ensures the learned neural network enjoy a\nmargin on the training data which leads to better generalization. Empirically,\nwe achieve better testing accuracy and entirely avoid early stopping which\nmakes the algorithm more user-friendly.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 23:53:39 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Dong", "Bin", ""], ["Hou", "Jikai", ""], ["Lu", "Yiping", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1910.01262", "submitter": "Guofeng Zhang", "authors": "Xiaoqiang Wang, Lejia Gu, Joseph Heung-wing Joseph Lee, Guofeng Zhang", "title": "Quantum tensor singular value decomposition with applications to\n  recommendation systems", "comments": "29 pages, 5 figure. Comments are welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a quantum singular value decomposition algorithm\nfor third-order tensors inspired by the classical algorithm of tensor singular\nvalue decomposition (t-svd) and then extend it to order-$p$ tensors. It can be\nproved that the quantum version of the t-svd for a third-order tensor\n$\\mathcal{A} \\in \\mathbb{R}^{N\\times N \\times N}$ achieves the complexity of\n$\\mathcal{O}(N{\\rm polylog}(N))$, an exponential speedup compared with its\nclassical counterpart. As an application, we propose a quantum algorithm for\nrecommendation systems which incorporates the contextual situation of users to\nthe personalized recommendation. We provide recommendations varying with\ncontexts by measuring the output quantum state corresponding to an\napproximation of this user's preferences. This algorithm runs in expected time\n$\\mathcal{O}(N{\\rm polylog}(N){\\rm poly}(k)),$ if every frontal slice of the\npreference tensor has a good rank-$k$ approximation. At last, we provide a\nquantum algorithm for tensor completion based on a different truncation method\nwhich is tested to have a good performance in dynamic video completion.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 00:45:27 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 14:59:39 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Xiaoqiang", ""], ["Gu", "Lejia", ""], ["Lee", "Joseph Heung-wing Joseph", ""], ["Zhang", "Guofeng", ""]]}, {"id": "1910.01269", "submitter": "Gopal Sharma", "authors": "Gopal Sharma, Evangelos Kalogerakis and Subhransu Maji", "title": "Learning Point Embeddings from Shape Repositories for Few-Shot\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User generated 3D shapes in online repositories contain rich information\nabout surfaces, primitives, and their geometric relations, often arranged in a\nhierarchy. We present a framework for learning representations of 3D shapes\nthat reflect the information present in this meta data and show that it leads\nto improved generalization for semantic segmentation tasks. Our approach is a\npoint embedding network that generates a vectorial representation of the 3D\npoints such that it reflects the grouping hierarchy and tag data. The main\nchallenge is that the data is noisy and highly variable. To this end, we\npresent a tree-aware metric-learning approach and demonstrate that such learned\nembeddings offer excellent transfer to semantic segmentation tasks, especially\nwhen training data is limited. Our approach reduces the relative error by\n$10.2\\%$ with $8$ training examples, by $11.72\\%$ with $120$ training examples\non the ShapeNet semantic segmentation benchmark, in comparison to the network\ntrained from scratch. By utilizing tag data the relative error is reduced by\n$12.8\\%$ with $8$ training examples, in comparison to the network trained from\nscratch. These improvements come at no additional labeling cost as the meta\ndata is freely available.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 01:26:31 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Sharma", "Gopal", ""], ["Kalogerakis", "Evangelos", ""], ["Maji", "Subhransu", ""]]}, {"id": "1910.01277", "submitter": "Vaneet Aggarwal", "authors": "Qinbo Bai and Mridul Agarwal and Vaneet Aggarwal", "title": "Escaping Saddle Points for Zeroth-order Nonconvex Optimization using\n  Estimated Gradient Descent", "comments": "arXiv admin note: text overlap with arXiv:1703.00887 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent and its variants are widely used in machine learning.\nHowever, oracle access of gradient may not be available in many applications,\nlimiting the direct use of gradient descent. This paper proposes a method of\nestimating gradient to perform gradient descent, that converges to a stationary\npoint for general non-convex optimization problems. Beyond the first-order\nstationary properties, the second-order stationary properties are important in\nmachine learning applications to achieve better performance. We show that the\nproposed model-free non-convex optimization algorithm returns an\n$\\epsilon$-second-order stationary point with\n$\\widetilde{O}(\\frac{d^{2+\\frac{\\theta}{2}}}{\\epsilon^{8+\\theta}})$ queries of\nthe function for any arbitrary $\\theta>0$.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 02:02:32 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Bai", "Qinbo", ""], ["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1910.01288", "submitter": "Shuai Yang", "authors": "Shuai Yang and Hao Wang and Kui Yu and Fuyuan Cao and Xindong Wu", "title": "Towards Efficient Local Causal Structure Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local causal structure learning aims to discover and distinguish direct\ncauses (parents) and direct effects (children) of a variable of interest from\ndata. While emerging successes have been made, existing methods need to search\na large space to distinguish direct causes from direct effects of a target\nvariable \\emph{T}. To tackle this issue, we propose a novel Efficient Local\nCausal Structure learning algorithm, named ELCS. Specifically, we first propose\nthe concept of N-structures, then design an efficient Markov Blanket (MB)\ndiscovery subroutine to integrate MB learning with N-structures to learn the MB\nof \\emph{T} and simultaneously distinguish direct causes from direct effects of\n\\emph{T}. With the proposed MB subroutine, ELCS starts from the target\nvariable, sequentially finds MBs of variables connected to the target variable\nand simultaneously constructs local causal structures over MBs until the direct\ncauses and direct effects of the target variable have been distinguished. Using\neight Bayesian networks the extensive experiments have validated that ELCS\nachieves better accuracy and efficiency than the state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 03:15:51 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 03:49:48 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2021 02:23:05 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Yang", "Shuai", ""], ["Wang", "Hao", ""], ["Yu", "Kui", ""], ["Cao", "Fuyuan", ""], ["Wu", "Xindong", ""]]}, {"id": "1910.01299", "submitter": "Yuta Koreeda", "authors": "Yuta Koreeda, Gaku Morio, Terufumi Morishita, Hiroaki Ozaki, Kohsuke\n  Yanai", "title": "Hitachi at MRP 2019: Unified Encoder-to-Biaffine Network for\n  Cross-Framework Meaning Representation Parsing", "comments": "13 pages, 3 figures", "journal-ref": "in Proceedings of the Shared Task on Cross-Framework Meaning\n  Representation Parsing at the 2019 Conference on Natural Language Learning", "doi": "10.18653/v1/K19-2011", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the proposed system of the Hitachi team for the\nCross-Framework Meaning Representation Parsing (MRP 2019) shared task. In this\nshared task, the participating systems were asked to predict nodes, edges and\ntheir attributes for five frameworks, each with different order of\n\"abstraction\" from input tokens. We proposed a unified encoder-to-biaffine\nnetwork for all five frameworks, which effectively incorporates a shared\nencoder to extract rich input features, decoder networks to generate anchorless\nnodes in UCCA and AMR, and biaffine networks to predict edges. Our system was\nranked fifth with the macro-averaged MRP F1 score of 0.7604, and outperformed\nthe baseline unified transition-based MRP. Furthermore, post-evaluation\nexperiments showed that we can boost the performance of the proposed system by\nincorporating multi-task learning, whereas the baseline could not. These imply\nefficacy of incorporating the biaffine network to the shared architecture for\nMRP and that learning heterogeneous meaning representations at once can boost\nthe system performance.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 04:27:49 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 14:56:26 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 05:17:41 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Koreeda", "Yuta", ""], ["Morio", "Gaku", ""], ["Morishita", "Terufumi", ""], ["Ozaki", "Hiroaki", ""], ["Yanai", "Kohsuke", ""]]}, {"id": "1910.01312", "submitter": "Chengjing Wang", "authors": "Dunbiao Niu, Chengjing Wang, Peipei Tang, Qingsong Wang, and Enbin\n  Song", "title": "A sparse semismooth Newton based augmented Lagrangian method for\n  large-scale support vector machines", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machines (SVMs) are successful modeling and prediction tools\nwith a variety of applications. Previous work has demonstrated the superiority\nof the SVMs in dealing with the high dimensional, low sample size problems.\nHowever, the numerical difficulties of the SVMs will become severe with the\nincrease of the sample size. Although there exist many solvers for the SVMs,\nonly few of them are designed by exploiting the special structures of the SVMs.\nIn this paper, we propose a highly efficient sparse semismooth Newton based\naugmented Lagrangian method for solving a large-scale convex quadratic\nprogramming problem with a linear equality constraint and a simple box\nconstraint, which is generated from the dual problems of the SVMs. By\nleveraging the primal-dual error bound result, the fast local convergence rate\nof the augmented Lagrangian method can be guaranteed. Furthermore, by\nexploiting the second-order sparsity of the problem when using the semismooth\nNewton method,the algorithm can efficiently solve the aforementioned difficult\nproblems. Finally, numerical comparisons demonstrate that the proposed\nalgorithm outperforms the current state-of-the-art solvers for the large-scale\nSVMs.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 05:51:47 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 06:08:02 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Niu", "Dunbiao", ""], ["Wang", "Chengjing", ""], ["Tang", "Peipei", ""], ["Wang", "Qingsong", ""], ["Song", "Enbin", ""]]}, {"id": "1910.01319", "submitter": "Tiago Ramalho", "authors": "Tiago Ramalho, Thierry Sousbie, Stefano Peluchetti", "title": "An empirical study of pretrained representations for few-shot\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent algorithms with state-of-the-art few-shot classification results start\ntheir procedure by computing data features output by a large pretrained model.\nIn this paper we systematically investigate which models provide the best\nrepresentations for a few-shot image classification task when pretrained on the\nImagenet dataset. We test their representations when used as the starting point\nfor different few-shot classification algorithms. We observe that models\ntrained on a supervised classification task have higher performance than models\ntrained in an unsupervised manner even when transferred to out-of-distribution\ndatasets. Models trained with adversarial robustness transfer better, while\nhaving slightly lower accuracy than supervised models.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 06:31:58 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Ramalho", "Tiago", ""], ["Sousbie", "Thierry", ""], ["Peluchetti", "Stefano", ""]]}, {"id": "1910.01327", "submitter": "Wanrong Zhang", "authors": "Rachel Cummings, Sara Krehbiel, Yuliia Lut, Wanrong Zhang", "title": "Privately detecting changes in unknown distributions", "comments": null, "journal-ref": "Proceedings of the International Conference on Machine Learning\n  (2020) Pages 958-968", "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The change-point detection problem seeks to identify distributional changes\nin streams of data. Increasingly, tools for change-point detection are applied\nin settings where data may be highly sensitive and formal privacy guarantees\nare required, such as identifying disease outbreaks based on hospital records,\nor IoT devices detecting activity within a home. Differential privacy has\nemerged as a powerful technique for enabling data analysis while preventing\ninformation leakage about individuals. Much of the prior work on change-point\ndetection---including the only private algorithms for this problem---requires\ncomplete knowledge of the pre-change and post-change distributions. However,\nthis assumption is not realistic for many practical applications of interest.\nThis work develops differentially private algorithms for solving the\nchange-point problem when the data distributions are unknown. Additionally, the\ndata may be sampled from distributions that change smoothly over time, rather\nthan fixed pre-change and post-change distributions. We apply our algorithms to\ndetect changes in the linear trends of such data streams. Finally, we also\nprovide experimental results to empirically validate the performance of our\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 07:05:59 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 22:35:49 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Cummings", "Rachel", ""], ["Krehbiel", "Sara", ""], ["Lut", "Yuliia", ""], ["Zhang", "Wanrong", ""]]}, {"id": "1910.01329", "submitter": "He Zhao", "authors": "He Zhao, Trung Le, Paul Montague, Olivier De Vel, Tamas Abraham, Dinh\n  Phung", "title": "Perturbations are not Enough: Generating Adversarial Examples with\n  Spatial Distortions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural network image classifiers are reported to be susceptible to\nadversarial evasion attacks, which use carefully crafted images created to\nmislead a classifier. Recently, various kinds of adversarial attack methods\nhave been proposed, most of which focus on adding small perturbations to input\nimages. Despite the success of existing approaches, the way to generate\nrealistic adversarial images with small perturbations remains a challenging\nproblem. In this paper, we aim to address this problem by proposing a novel\nadversarial method, which generates adversarial examples by imposing not only\nperturbations but also spatial distortions on input images, including scaling,\nrotation, shear, and translation. As humans are less susceptible to small\nspatial distortions, the proposed approach can produce visually more realistic\nattacks with smaller perturbations, able to deceive classifiers without\naffecting human predictions. We learn our method by amortized techniques with\nneural networks and generate adversarial examples efficiently by a forward pass\nof the networks. Extensive experiments on attacking different types of\nnon-robustified classifiers and robust classifiers with defence show that our\nmethod has state-of-the-art performance in comparison with advanced attack\nparallels.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 07:15:40 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Zhao", "He", ""], ["Le", "Trung", ""], ["Montague", "Paul", ""], ["De Vel", "Olivier", ""], ["Abraham", "Tamas", ""], ["Phung", "Dinh", ""]]}, {"id": "1910.01340", "submitter": "Bilal Ghanem", "authors": "Bilal Ghanem, Davide Buscaldi, Paolo Rosso", "title": "TexTrolls: Identifying Russian Trolls on Twitter from a Textual\n  Perspective", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The online new emerging suspicious users, that usually are called trolls, are\none of the main sources of hate, fake, and deceptive online messages. Some\nagendas are utilizing these harmful users to spread incitement tweets, and as a\nconsequence, the audience get deceived. The challenge in detecting such\naccounts is that they conceal their identities which make them disguised in\nsocial media, adding more difficulty to identify them using just their social\nnetwork information. Therefore, in this paper, we propose a text-based approach\nto detect the online trolls such as those that were discovered during the US\n2016 presidential elections. Our approach is mainly based on textual features\nwhich utilize thematic information, and profiling features to identify the\naccounts from their way of writing tweets. We deduced the thematic information\nin a unsupervised way and we show that coupling them with the textual features\nenhanced the performance of the proposed model. In addition, we find that the\nproposed profiling features perform the best comparing to the textual features.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 07:56:52 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Ghanem", "Bilal", ""], ["Buscaldi", "Davide", ""], ["Rosso", "Paolo", ""]]}, {"id": "1910.01347", "submitter": "Samuel Paradis", "authors": "Samuel Paradis and Michael Whitmeyer", "title": "Pay Attention: Leveraging Sequence Models to Predict the Useful Life of\n  Batteries", "comments": "6 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use data on 124 batteries released by Stanford University to first try to\nsolve the binary classification problem of determining if a battery is \"good\"\nor \"bad\" given only the first 5 cycles of data (i.e., will it last longer than\na certain threshold of cycles), as well as the prediction problem of\ndetermining the exact number of cycles a battery will last given the first 100\ncycles of data. We approach the problem from a purely data-driven standpoint,\nhoping to use deep learning to learn the patterns in the sequences of data that\nthe Stanford team engineered by hand. For both problems, we used a similar deep\nnetwork design, that included an optional 1-D convolution, LSTMs, an optional\nAttention layer, followed by fully connected layers to produce our output. For\nthe classification task, we were able to achieve very competitive results, with\nvalidation accuracies above 90%, and a test accuracy of 95%, compared to the\n97.5% test accuracy of the current leading model. For the prediction task, we\nwere also able to achieve competitive results, with a test MAPE error of 12.5%\nas compared with a 9.1% MAPE error achieved by the current leading model\n(Severson et al. 2019).\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 08:14:02 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 20:32:49 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Paradis", "Samuel", ""], ["Whitmeyer", "Michael", ""]]}, {"id": "1910.01348", "submitter": "Jang Hyun Cho", "authors": "Jang Hyun Cho and Bharath Hariharan", "title": "On the Efficacy of Knowledge Distillation", "comments": "13 pages, including Appendix", "journal-ref": "ICCV 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a thorough evaluation of the efficacy of knowledge\ndistillation and its dependence on student and teacher architectures. Starting\nwith the observation that more accurate teachers often don't make good\nteachers, we attempt to tease apart the factors that affect knowledge\ndistillation performance. We find crucially that larger models do not often\nmake better teachers. We show that this is a consequence of mismatched\ncapacity, and that small students are unable to mimic large teachers. We find\ntypical ways of circumventing this (such as performing a sequence of knowledge\ndistillation steps) to be ineffective. Finally, we show that this effect can be\nmitigated by stopping the teacher's training early. Our results generalize\nacross datasets and models.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 08:14:13 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Cho", "Jang Hyun", ""], ["Hariharan", "Bharath", ""]]}, {"id": "1910.01355", "submitter": "Wentai Wu", "authors": "Wentai Wu, Ligang He, Weiwei Lin, Rui Mao, Carsten Maple, Stephen\n  Jarvis", "title": "SAFA: a Semi-Asynchronous Protocol for Fast Federated Learning with Low\n  Overhead", "comments": "16 pages, 8 figures", "journal-ref": "IEEE Transactions on Computers. vol. 70, pp. 655-668 (2020)", "doi": "10.1109/TC.2020.2994391", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated learning (FL) has attracted increasing attention as a promising\napproach to driving a vast number of end devices with artificial intelligence.\nHowever, it is very challenging to guarantee the efficiency of FL considering\nthe unreliable nature of end devices while the cost of device-server\ncommunication cannot be neglected. In this paper, we propose SAFA, a\nsemi-asynchronous FL protocol, to address the problems in federated learning\nsuch as low round efficiency and poor convergence rate in extreme conditions\n(e.g., clients dropping offline frequently). We introduce novel designs in the\nsteps of model distribution, client selection and global aggregation to\nmitigate the impacts of stragglers, crashes and model staleness in order to\nboost efficiency and improve the quality of the global model. We have conducted\nextensive experiments with typical machine learning tasks. The results\ndemonstrate that the proposed protocol is effective in terms of shortening\nfederated round duration, reducing local resource wastage, and improving the\naccuracy of the global model at an acceptable communication cost.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 08:43:09 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 08:58:39 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 09:00:09 GMT"}, {"version": "v4", "created": "Fri, 23 Apr 2021 10:22:34 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Wu", "Wentai", ""], ["He", "Ligang", ""], ["Lin", "Weiwei", ""], ["Mao", "Rui", ""], ["Maple", "Carsten", ""], ["Jarvis", "Stephen", ""]]}, {"id": "1910.01382", "submitter": "Zhe Hou", "authors": "Hadrien Bride, Zhe Hou, Jie Dong, Jin Song Dong and Ali Mirjalili", "title": "Silas: High Performance, Explainable and Verifiable Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new classification tool named Silas, which is built\nto provide a more transparent and dependable data analytics service. A focus of\nSilas is on providing a formal foundation of decision trees in order to support\nlogical analysis and verification of learned prediction models. This paper\ndescribes the distinct features of Silas: The Model Audit module formally\nverifies the prediction model against user specifications, the Enforcement\nLearning module trains prediction models that are guaranteed correct, the Model\nInsight and Prediction Insight modules reason about the prediction model and\nexplain the decision-making of predictions. We also discuss implementation\ndetails ranging from programming paradigm to memory management that help\nachieve high-performance computation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 10:17:50 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Bride", "Hadrien", ""], ["Hou", "Zhe", ""], ["Dong", "Jie", ""], ["Dong", "Jin Song", ""], ["Mirjalili", "Ali", ""]]}, {"id": "1910.01400", "submitter": "Kieran Woodward Mr", "authors": "Kieran Woodward, Eiman Kanjo and Andreas Oikonomou", "title": "LabelSens: Enabling Real-time Sensor Data Labelling at the point of\n  Collection on Edge Computing", "comments": "Pers Ubiquit Comput (2020)", "journal-ref": null, "doi": "10.1007/s00779-020-01427-x", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning has developed rapidly, enabling the\ndevelopment of applications with high levels of recognition accuracy relating\nto the use of speech and images. However, other types of data to which these\nmodels can be applied have not yet been explored as thoroughly. Labelling is an\nindispensable stage of data pre-processing that can be particularly\nchallenging, especially when applied to single or multi-model real-time sensor\ndata collection approaches. Currently, real-time sensor data labelling is an\nunwieldy process, with a limited range of tools available and poor performance\ncharacteristics, which can lead to the performance of the machine learning\nmodels being compromised. In this paper, we introduce new techniques for\nlabelling at the point of collection coupled with a pilot study and a\nsystematic performance comparison of two popular types of deep neural networks\nrunning on five custom built devices and a comparative mobile app (68.5-89%\naccuracy within-device GRU model, 92.8% highest LSTM model accuracy). These\ndevices are designed to enable real-time labelling with various buttons, slide\npotentiometer and force sensors. This exploratory work illustrates several key\nfeatures that inform the design of data collection tools that can help\nresearchers select and apply appropriate labelling techniques to their work. We\nalso identify common bottlenecks in each architecture and provide field tested\nguidelines to assist in building adaptive, high-performance edge solutions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 10:54:15 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 08:55:23 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 13:39:46 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Woodward", "Kieran", ""], ["Kanjo", "Eiman", ""], ["Oikonomou", "Andreas", ""]]}, {"id": "1910.01409", "submitter": "Dexuan Zhang", "authors": "Dexuan Zhang, Tatsuya Harada", "title": "A General Upper Bound for Unsupervised Domain Adaptation", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a novel upper bound of target error to address the\nproblem for unsupervised domain adaptation. Recent studies reveal that a deep\nneural network can learn transferable features which generalize well to novel\ntasks. Furthermore, a theory proposed by Ben-David et al. (2010) provides a\nupper bound for target error when transferring the knowledge, which can be\nsummarized as minimizing the source error and distance between marginal\ndistributions simultaneously. However, common methods based on the theory\nusually ignore the joint error such that samples from different classes might\nbe mixed together when matching marginal distribution. And in such case, no\nmatter how we minimize the marginal discrepancy, the target error is not\nbounded due to an increasing joint error. To address this problem, we propose a\ngeneral upper bound taking joint error into account, such that the undesirable\ncase can be properly penalized. In addition, we utilize constrained hypothesis\nspace to further formalize a tighter bound as well as a novel cross margin\ndiscrepancy to measure the dissimilarity between hypotheses which alleviates\ninstability during adversarial learning. Extensive empirical evidence shows\nthat our proposal outperforms related approaches in image classification error\nrates on standard domain adaptation benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 11:31:14 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 07:40:18 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zhang", "Dexuan", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1910.01417", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias and Stefanos Zafeiriou", "title": "Exploiting multi-CNN features in CNN-RNN based Dimensional Emotion\n  Recognition on the OMG in-the-wild Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel CNN-RNN based approach, which exploits multiple\nCNN features for dimensional emotion recognition in-the-wild, utilizing the\nOne-Minute Gradual-Emotion (OMG-Emotion) dataset. Our approach includes first\npre-training with the relevant and large in size, Aff-Wild and Aff-Wild2\nemotion databases. Low-, mid- and high-level features are extracted from the\ntrained CNN component and are exploited by RNN subnets in a multi-task\nframework. Their outputs constitute an intermediate level prediction; final\nestimates are obtained as the mean or median values of these predictions.\nFusion of the networks is also examined for boosting the obtained performance,\nat Decision-, or at Model-level; in the latter case a RNN was used for the\nfusion. Our approach, although using only the visual modality, outperformed\nstate-of-the-art methods that utilized audio and visual modalities. Some of our\ndevelopments have been submitted to the OMG-Emotion Challenge, ranking second\namong the technologies which used only visual information for valence\nestimation; ranking third overall. Through extensive experimentation, we\nfurther show that arousal estimation is greatly improved when low-level\nfeatures are combined with high-level ones.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 11:56:41 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 10:28:25 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1910.01432", "submitter": "Erwan Le Merrer", "authors": "Erwan Le Merrer and Gilles Tredan", "title": "The Bouncer Problem: Challenges to Remote Explainability", "comments": null, "journal-ref": "Nat Mach Intell (2020)", "doi": "10.1038/s42256-020-0216-z", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of explainability is envisioned to satisfy society's demands for\ntransparency on machine learning decisions. The concept is simple: like humans,\nalgorithms should explain the rationale behind their decisions so that their\nfairness can be assessed. While this approach is promising in a local context\n(e.g. to explain a model during debugging at training time), we argue that this\nreasoning cannot simply be transposed in a remote context, where a trained\nmodel by a service provider is only accessible through its API. This is\nproblematic as it constitutes precisely the target use-case requiring\ntransparency from a societal perspective. Through an analogy with a club\nbouncer (which may provide untruthful explanations upon customer reject), we\nshow that providing explanations cannot prevent a remote service from lying\nabout the true reasons leading to its decisions. More precisely, we prove the\nimpossibility of remote explainability for single explanations, by constructing\nan attack on explanations that hides discriminatory features to the querying\nuser. We provide an example implementation of this attack. We then show that\nthe probability that an observer spots the attack, using several explanations\nfor attempting to find incoherences, is low in practical settings. This\nundermines the very concept of remote explainability in general.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 12:54:00 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 10:56:33 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Merrer", "Erwan Le", ""], ["Tredan", "Gilles", ""]]}, {"id": "1910.01442", "submitter": "Chuang Gan", "authors": "Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio\n  Torralba, Joshua B. Tenenbaum", "title": "CLEVRER: CoLlision Events for Video REpresentation and Reasoning", "comments": "The first two authors contributed equally to this work. Accepted as\n  Oral Spotlight as ICLR 2020. Project page: http://clevrer.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to reason about temporal and causal events from videos lies at\nthe core of human intelligence. Most video reasoning benchmarks, however, focus\non pattern recognition from complex visual and language input, instead of on\ncausal structure. We study the complementary problem, exploring the temporal\nand causal structures behind videos of objects with simple visual appearance.\nTo this end, we introduce the CoLlision Events for Video REpresentation and\nReasoning (CLEVRER), a diagnostic video dataset for systematic evaluation of\ncomputational models on a wide range of reasoning tasks. Motivated by the\ntheory of human casual judgment, CLEVRER includes four types of questions:\ndescriptive (e.g., \"what color\"), explanatory (\"what is responsible for\"),\npredictive (\"what will happen next\"), and counterfactual (\"what if\"). We\nevaluate various state-of-the-art models for visual reasoning on our benchmark.\nWhile these models thrive on the perception-based task (descriptive), they\nperform poorly on the causal tasks (explanatory, predictive and\ncounterfactual), suggesting that a principled approach for causal reasoning\nshould incorporate the capability of both perceiving complex visual and\nlanguage inputs, and understanding the underlying dynamics and causal\nrelations. We also study an oracle model that explicitly combines these\ncomponents via symbolic representations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 13:16:36 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 00:09:07 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Yi", "Kexin", ""], ["Gan", "Chuang", ""], ["Li", "Yunzhu", ""], ["Kohli", "Pushmeet", ""], ["Wu", "Jiajun", ""], ["Torralba", "Antonio", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1910.01444", "submitter": "Yuta Saito", "authors": "Yuta Saito", "title": "Asymmetric Tri-training for Debiasing Missing-Not-At-Random Explicit\n  Feedback", "comments": "43rd International ACM SIGIR Conference on Research and Development\n  in Information Retrieval (SIGIR '20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most real-world recommender systems, the observed rating data are subject\nto selection bias, and the data are thus missing-not-at-random. Developing a\nmethod to facilitate the learning of a recommender with biased feedback is one\nof the most challenging problems, as it is widely known that naive approaches\nunder selection bias often lead to suboptimal results. A well-established\nsolution for the problem is using propensity scoring techniques. The propensity\nscore is the probability of each data being observed, and unbiased performance\nestimation is possible by weighting each data by the inverse of its propensity.\nHowever, the performance of the propensity-based unbiased estimation approach\nis often affected by choice of the propensity estimation model or the high\nvariance problem. To overcome these limitations, we propose a model-agnostic\nmeta-learning method inspired by the asymmetric tri-training framework for\nunsupervised domain adaptation. The proposed method utilizes two predictors to\ngenerate data with reliable pseudo-ratings and another predictor to make the\nfinal predictions. In a theoretical analysis, a propensity-independent upper\nbound of the true performance metric is derived, and it is demonstrated that\nthe proposed method can minimize this bound. We conduct comprehensive\nexperiments using public real-world datasets. The results suggest that the\nprevious propensity-based methods are largely affected by the choice of\npropensity models and the variance problem caused by the inverse propensity\nweighting. Moreover, we show that the proposed meta-learning method is robust\nto these issues and can facilitate in developing effective recommendations from\nbiased explicit feedback.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 07:23:46 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 06:45:48 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 02:08:10 GMT"}, {"version": "v4", "created": "Wed, 29 Jan 2020 13:34:38 GMT"}, {"version": "v5", "created": "Tue, 18 Feb 2020 01:27:10 GMT"}, {"version": "v6", "created": "Tue, 2 Jun 2020 19:21:41 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Saito", "Yuta", ""]]}, {"id": "1910.01447", "submitter": "Carl Yang", "authors": "Carl Yang, Xiaolin Shi, Jie Luo, Jiawei Han", "title": "I Know You'll Be Back: Interpretable New User Clustering and Churn\n  Prediction on a Mobile Social Application", "comments": "Published at KDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As online platforms are striving to get more users, a critical challenge is\nuser churn, which is especially concerning for new users. In this paper, by\ntaking the anonymous large-scale real-world data from Snapchat as an example,\nwe develop \\textit{ClusChurn}, a systematic two-step framework for\ninterpretable new user clustering and churn prediction, based on the intuition\nthat proper user clustering can help understand and predict user churn.\nTherefore, \\textit{ClusChurn} firstly groups new users into interpretable\ntypical clusters, based on their activities on the platform and ego-network\nstructures. Then we design a novel deep learning pipeline based on LSTM and\nattention to accurately predict user churn with very limited initial behavior\ndata, by leveraging the correlations among users' multi-dimensional activities\nand the underlying user types. \\textit{ClusChurn} is also able to predict user\ntypes, which enables rapid reactions to different types of user churn.\nExtensive data analysis and experiments show that \\textit{ClusChurn} provides\nvaluable insight into user behaviors, and achieves state-of-the-art churn\nprediction performance. The whole framework is deployed as a data analysis\npipeline, delivering real-time data analysis and prediction results to multiple\nrelevant teams for business intelligence uses. It is also general enough to be\nreadily adopted by any online systems with user behavior data.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 02:12:59 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Yang", "Carl", ""], ["Shi", "Xiaolin", ""], ["Luo", "Jie", ""], ["Han", "Jiawei", ""]]}, {"id": "1910.01449", "submitter": "Ramiro Camino", "authors": "Ramiro Camino, Christof Ferreira Torres, Mathis Baden, Radu State", "title": "A Data Science Approach for Honeypot Detection in Ethereum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum smart contracts have recently drawn a considerable amount of\nattention from the media, the financial industry and academia. With the\nincrease in popularity, malicious users found new opportunities to profit by\ndeceiving newcomers. Consequently, attackers started luring other attackers\ninto contracts that seem to have exploitable flaws, but that actually contain a\ncomplex hidden trap that in the end benefits the contract creator. In the\nblockchain community, these contracts are known as honeypots. A recent study\npresented a tool called HONEYBADGER that uses symbolic execution to detect\nhoneypots by analyzing contract bytecode. In this paper, we present a data\nscience detection approach based foremost on the contract transaction behavior.\nWe create a partition of all the possible cases of fund movements between the\ncontract creator, the contract, the transaction sender and other participants.\nTo this end, we add transaction aggregated features, such as the number of\ntransactions and the corresponding mean value and other contract features, for\nexample compilation information and source code length. We find that all\naforementioned categories of features contain useful information for the\ndetection of honeypots. Moreover, our approach allows us to detect new,\npreviously undetected honeypots of already known techniques. We furthermore\nemploy our method to test the detection of unknown honeypot techniques by\nsequentially removing one technique from the training set. We show that our\nmethod is capable of discovering the removed honeypot techniques. Finally, we\ndiscovered two new techniques that were previously not known.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 13:21:35 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 20:16:58 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Camino", "Ramiro", ""], ["Torres", "Christof Ferreira", ""], ["Baden", "Mathis", ""], ["State", "Radu", ""]]}, {"id": "1910.01453", "submitter": "Hao Xu", "authors": "Hao Xu", "title": "D2D-LSTM based Prediction of the D2D Diffusion Path in Mobile Social\n  Networks", "comments": "9 pages, 10 fighures. arXiv admin note: text overlap with\n  arXiv:1705.09275 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, how to expand data transmission to reduce cell data and repeated\ncell transmission has received more and more research attention. In mobile\nsocial networks, content popularity prediction has always been an important\npart of traffic offloading and expanding data dissemination. However, current\nmainstream content popularity prediction methods only use the number of\ndownloads and shares or the distribution of user interests, which do not\nconsider important time and geographic location information in mobile social\nnetworks, and all of data is from OSN which is not same as MSN. In this work,\nwe propose D2D Long Short-Term Memory (D2D-LSTM), a deep neural network based\non LSTM, which is designed to predict a complete D2D diffusion path. Our work\nis the first attempt in the world to use real data of MSN to predict diffusion\npath with deep neural networks which conforms to the D2D structure. Compared to\nlinear sequence networks, only learn users' social features without time\ndistribution or GPS distribution and files' content features, our model can\npredict the propagation path more accurately (up to 85.858\\%) and can reach\nconvergence faster (less than 100 steps) because of the neural network that\nconforms to the D2D structure and combines user social features and files\nfeatures. Moreover, we can simulate generating a D2D propagation tree. After\nexperiment and comparison, it is found to be very similar to the ground-truth\ntrees. Finally, we define a user prototype refinement that can more accurately\ndescribe the propagation sharing habits of a prototype user (including content\npreferences, time preferences, and geographic location preferences), and\nexperimentally validate the predictions when the user prototype is added to\n1000 classes, it is almost identical to the 50 categories.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 03:03:09 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Xu", "Hao", ""]]}, {"id": "1910.01458", "submitter": "Sansiri Tarnpradab", "authors": "Sansiri Tarnpradab, Kien A. Hua", "title": "Attention Based Neural Architecture for Rumor Detection with Author\n  Context Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of social media has made information sharing possible across\nthe globe. The downside, unfortunately, is the wide spread of misinformation.\nMethods applied in most previous rumor classifiers give an equal weight, or\nattention, to words in the microblog, and do not take the context beyond\nmicroblog contents into account; therefore, the accuracy becomes plateaued. In\nthis research, we propose an ensemble neural architecture to detect rumor on\nTwitter. The architecture incorporates word attention and context from the\nauthor to enhance the classification performance. In particular, the word-level\nattention mechanism enables the architecture to put more emphasis on important\nwords when constructing the text representation. To derive further context,\nmicroblog posts composed by individual authors are exploited since they can\nreflect style and characteristics in spreading information, which are\nsignificant cues to help classify whether the shared content is rumor or\nlegitimate news. The experiment on the real-world Twitter dataset collected\nfrom two well-known rumor tracking websites demonstrates promising results.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 21:48:03 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Tarnpradab", "Sansiri", ""], ["Hua", "Kien A.", ""]]}, {"id": "1910.01463", "submitter": "Dorien Herremans", "authors": "Kin Wai Cheuk, Balamurali B. T., Gemma Roig, Dorien Herremans", "title": "Latent space representation for multi-target speaker detection and\n  identification with a sparse dataset using Triplet neural networks", "comments": "Accepted for ASRU 2019", "journal-ref": "Proceedings of IEEE Automatic Speech Recognition and Understanding\n  Workshop (ASRU 2019). Singapore. 2019", "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to tackle the speaker recognition problem using\nTriplet Neural Networks. Currently, the $i$-vector representation with\nprobabilistic linear discriminant analysis (PLDA) is the most commonly used\ntechnique to solve this problem, due to high classification accuracy with a\nrelatively short computation time. In this paper, we explore a neural network\napproach, namely Triplet Neural Networks (TNNs), to built a latent space for\ndifferent classifiers to solve the Multi-Target Speaker Detection and\nIdentification Challenge Evaluation 2018 (MCE 2018) dataset. This training set\ncontains $i$-vectors from 3,631 speakers, with only 3 samples for each speaker,\nthus making speaker recognition a challenging task. When using the train and\ndevelopment set for training both the TNN and baseline model (i.e., similarity\nevaluation directly on the $i$-vector representation), our proposed model\noutperforms the baseline by 23%. When reducing the training data to only using\nthe train set, our method results in 309 confusions for the Multi-target\nspeaker identification task, which is 46% better than the baseline model. These\nresults show that the representational power of TNNs is especially evident when\ntraining on small datasets with few instances available per class.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 04:59:24 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 01:30:22 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Cheuk", "Kin Wai", ""], ["T.", "Balamurali B.", ""], ["Roig", "Gemma", ""], ["Herremans", "Dorien", ""]]}, {"id": "1910.01465", "submitter": "Johannes Ackermann", "authors": "Johannes Ackermann, Volker Gabler, Takayuki Osa, Masashi Sugiyama", "title": "Reducing Overestimation Bias in Multi-Agent Domains Using Double\n  Centralized Critics", "comments": "Accepted for the Deep RL Workshop at NeurIPS 2019; Changes for v2:\n  Changed Figures 3,4, due to an error in the implementation of MATD3. Please\n  refer to this version for fair evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world tasks require multiple agents to work together. Multi-agent\nreinforcement learning (RL) methods have been proposed in recent years to solve\nthese tasks, but current methods often fail to efficiently learn policies. We\nthus investigate the presence of a common weakness in single-agent RL, namely\nvalue function overestimation bias, in the multi-agent setting. Based on our\nfindings, we propose an approach that reduces this bias by using double\ncentralized critics. We evaluate it on six mixed cooperative-competitive tasks,\nshowing a significant advantage over current methods. Finally, we investigate\nthe application of multi-agent methods to high-dimensional robotic tasks and\nshow that our approach can be used to learn decentralized policies in this\ndomain.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 13:40:46 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:00:20 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ackermann", "Johannes", ""], ["Gabler", "Volker", ""], ["Osa", "Takayuki", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1910.01467", "submitter": "Wonpyo Park", "authors": "Wonpyo Park, Paul Hongsuck Seo, Bohyung Han, Minsu Cho", "title": "Regularizing Neural Networks via Stochastic Branch Layers", "comments": "ACML 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel stochastic regularization technique for deep neural\nnetworks, which decomposes a layer into multiple branches with different\nparameters and merges stochastically sampled combinations of the outputs from\nthe branches during training. Since the factorized branches can collapse into a\nsingle branch through a linear operation, inference requires no additional\ncomplexity compared to the ordinary layers. The proposed regularization method,\nreferred to as StochasticBranch, is applicable to any linear layers such as\nfully-connected or convolution layers. The proposed regularizer allows the\nmodel to explore diverse regions of the model parameter space via multiple\ncombinations of branches to find better local minima. An extensive set of\nexperiments shows that our method effectively regularizes networks and further\nimproves the generalization performance when used together with other existing\nregularization techniques.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 13:44:55 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Park", "Wonpyo", ""], ["Seo", "Paul Hongsuck", ""], ["Han", "Bohyung", ""], ["Cho", "Minsu", ""]]}, {"id": "1910.01473", "submitter": "Behrooz Mamandipoor", "authors": "Behrooz Mamandipoor, Mahshid Majd, Monica Moz, Venet Osmani", "title": "Blood lactate concentration prediction in critical care patients:\n  handling missing values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blood lactate concentration is a strong indicator of mortality risk in\ncritically ill patients. While frequent lactate measurements are necessary to\nassess patient's health state, the measurement is an invasive procedure that\ncan increase risk of hospital-acquired infections. For this reason we formally\ndefine the problem of lactate prediction as a clinically relevant benchmark\nproblem for machine learning community so as to assist clinical decision making\nin blood lactate testing. Accordingly, we demonstrate the relevant challenges\nof the problem and its data in addition to the adopted solutions. Also, we\nevaluate the performance of different prediction algorithms on a large dataset\nof ICU patients from the multi-centre eICU database. More specifically, we\nfocus on investigating the impact of missing value imputation methods in\nlactate prediction for each algorithm. The experimental analysis shows\npromising prediction results that encourages further investigation of this\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 13:56:50 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Mamandipoor", "Behrooz", ""], ["Majd", "Mahshid", ""], ["Moz", "Monica", ""], ["Osmani", "Venet", ""]]}, {"id": "1910.01487", "submitter": "Jingwei Zhang", "authors": "Shan Lin, Jingwei Zhang", "title": "Generalization Bounds for Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks (CNNs) have achieved breakthrough performances\nin a wide range of applications including image classification, semantic\nsegmentation, and object detection. Previous research on characterizing the\ngeneralization ability of neural networks mostly focuses on fully connected\nneural networks (FNNs), regarding CNNs as a special case of FNNs without taking\ninto account the special structure of convolutional layers. In this work, we\npropose a tighter generalization bound for CNNs by exploiting the sparse and\npermutation structure of its weight matrices. As the generalization bound\nrelies on the spectral norm of weight matrices, we further study spectral norms\nof three commonly used convolution operations including standard convolution,\ndepthwise convolution, and pointwise convolution. Theoretical and experimental\nresults both demonstrate that our bounds for CNNs are tighter than existing\nbounds.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:08:57 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Lin", "Shan", ""], ["Zhang", "Jingwei", ""]]}, {"id": "1910.01489", "submitter": "Nicolas Dugu\\'e", "authors": "Nicolas Dugu\\'e and Victor Connes", "title": "Complex networks based word embeddings", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the time, the first step to learn word embeddings is to build a word\nco-occurrence matrix. As such matrices are equivalent to graphs, complex\nnetworks theory can naturally be used to deal with such data. In this paper, we\nconsider applying community detection, a main tool of this field, to the\nco-occurrence matrix corresponding to a huge corpus. Community structure is\nused as a way to reduce the dimensionality of the initial space. Using this\ncommunity structure, we propose a method to extract word embeddings that are\ncomparable to the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:12:38 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Dugu\u00e9", "Nicolas", ""], ["Connes", "Victor", ""]]}, {"id": "1910.01491", "submitter": "Kei Nakagawa", "authors": "Kei Nakagawa, Masaya Abe, Junpei Komiyama", "title": "A Robust Transferable Deep Learning Framework for Cross-sectional\n  Investment Strategy", "comments": null, "journal-ref": null, "doi": "10.1109/DSAA49011.2020.00051", "report-no": null, "categories": "q-fin.ST cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock return predictability is an important research theme as it reflects our\neconomic and social organization, and significant efforts are made to explain\nthe dynamism therein. Statistics of strong explanative power, called \"factor\"\nhave been proposed to summarize the essence of predictive stock returns.\nAlthough machine learning methods are increasingly popular in stock return\nprediction, an inference of the stock returns is highly elusive, and still most\ninvestors, if partly, rely on their intuition to build a better decision\nmaking. The challenge here is to make an investment strategy that is consistent\nover a reasonably long period, with the minimum human decision on the entire\nprocess. To this end, we propose a new stock return prediction framework that\nwe call Ranked Information Coefficient Neural Network (RIC-NN). RIC-NN is a\ndeep learning approach and includes the following three novel ideas: (1)\nnonlinear multi-factor approach, (2) stopping criteria with ranked information\ncoefficient (rank IC), and (3) deep transfer learning among multiple regions.\nExperimental comparison with the stocks in the Morgan Stanley Capital\nInternational (MSCI) indices shows that RIC-NN outperforms not only\noff-the-shelf machine learning methods but also the average return of major\nequity investment funds in the last fourteen years.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 11:02:57 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Nakagawa", "Kei", ""], ["Abe", "Masaya", ""], ["Komiyama", "Junpei", ""]]}, {"id": "1910.01492", "submitter": "Sayyed-Ahmad Naghavi-Nozad", "authors": "Sayyed-Ahmad Naghavi-Nozad", "title": "A Grid-based Approach for Convexity Analysis of a Density-based Cluster", "comments": "List of authors modified", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel geometrical approach to investigate the convexity\nof a density-based cluster. Our approach is grid-based and we are about to\ncalibrate the value space of the cluster. However, the cluster objects are\ncoming from an infinite distribution, their number is finite, and thus, the\nregarding shape will not be sharp. Therefore, we establish the precision of the\ngrid properly in a way that, the reliable approximate boundaries of the cluster\nare founded. After that, regarding the simple notion of convex sets and\nmidpoint convexity, we investigate whether or not the density-based cluster is\nconvex. Moreover, our experiments on synthetic datasets demonstrate the\ndesirable performance of our method.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:13:13 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 09:48:52 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Naghavi-Nozad", "Sayyed-Ahmad", ""]]}, {"id": "1910.01493", "submitter": "Duc Le", "authors": "Duc Le, Xiaohui Zhang, Weiyi Zheng, Christian F\\\"ugen, Geoffrey Zweig,\n  Michael L. Seltzer", "title": "From Senones to Chenones: Tied Context-Dependent Graphemes for Hybrid\n  Speech Recognition", "comments": "To appear at ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an implicit assumption that traditional hybrid approaches for\nautomatic speech recognition (ASR) cannot directly model graphemes and need to\nrely on phonetic lexicons to get competitive performance, especially on English\nwhich has poor grapheme-phoneme correspondence. In this work, we show for the\nfirst time that, on English, hybrid ASR systems can in fact model graphemes\neffectively by leveraging tied context-dependent graphemes, i.e., chenones. Our\nchenone-based systems significantly outperform equivalent senone baselines by\n4.5% to 11.1% relative on three different English datasets. Our results on\nLibrispeech are state-of-the-art compared to other hybrid approaches and\ncompetitive with previously published end-to-end numbers. Further analysis\nshows that chenones can better utilize powerful acoustic models and large\ntraining data, and require context- and position-dependent modeling to work\nwell. Chenone-based systems also outperform senone baselines on proper noun and\nrare word recognition, an area where the latter is traditionally thought to\nhave an advantage. Our work provides an alternative for end-to-end ASR and\nestablishes that hybrid systems can be improved by dropping the reliance on\nphonetic knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 04:17:46 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 21:45:56 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Le", "Duc", ""], ["Zhang", "Xiaohui", ""], ["Zheng", "Weiyi", ""], ["F\u00fcgen", "Christian", ""], ["Zweig", "Geoffrey", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "1910.01500", "submitter": "Cody Coleman", "authors": "Peter Mattson, Christine Cheng, Cody Coleman, Greg Diamos, Paulius\n  Micikevicius, David Patterson, Hanlin Tang, Gu-Yeon Wei, Peter Bailis, Victor\n  Bittorf, David Brooks, Dehao Chen, Debojyoti Dutta, Udit Gupta, Kim\n  Hazelwood, Andrew Hock, Xinyuan Huang, Atsushi Ike, Bill Jia, Daniel Kang,\n  David Kanter, Naveen Kumar, Jeffery Liao, Guokai Ma, Deepak Narayanan, Tayo\n  Oguntebi, Gennady Pekhimenko, Lillian Pentecost, Vijay Janapa Reddi, Taylor\n  Robie, Tom St. John, Tsuguchika Tabaru, Carole-Jean Wu, Lingjie Xu, Masafumi\n  Yamazaki, Cliff Young, Matei Zaharia", "title": "MLPerf Training Benchmark", "comments": "MLSys 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) needs industry-standard performance benchmarks to\nsupport design and competitive evaluation of the many emerging software and\nhardware solutions for ML. But ML training presents three unique benchmarking\nchallenges absent from other domains: optimizations that improve training\nthroughput can increase the time to solution, training is stochastic and time\nto solution exhibits high variance, and software and hardware systems are so\ndiverse that fair benchmarking with the same binary, code, and even\nhyperparameters is difficult. We therefore present MLPerf, an ML benchmark that\novercomes these challenges. Our analysis quantitatively evaluates MLPerf's\nefficacy at driving performance and scalability improvements across two rounds\nof results from multiple vendors.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 17:55:34 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 19:31:47 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 17:22:28 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Mattson", "Peter", ""], ["Cheng", "Christine", ""], ["Coleman", "Cody", ""], ["Diamos", "Greg", ""], ["Micikevicius", "Paulius", ""], ["Patterson", "David", ""], ["Tang", "Hanlin", ""], ["Wei", "Gu-Yeon", ""], ["Bailis", "Peter", ""], ["Bittorf", "Victor", ""], ["Brooks", "David", ""], ["Chen", "Dehao", ""], ["Dutta", "Debojyoti", ""], ["Gupta", "Udit", ""], ["Hazelwood", "Kim", ""], ["Hock", "Andrew", ""], ["Huang", "Xinyuan", ""], ["Ike", "Atsushi", ""], ["Jia", "Bill", ""], ["Kang", "Daniel", ""], ["Kanter", "David", ""], ["Kumar", "Naveen", ""], ["Liao", "Jeffery", ""], ["Ma", "Guokai", ""], ["Narayanan", "Deepak", ""], ["Oguntebi", "Tayo", ""], ["Pekhimenko", "Gennady", ""], ["Pentecost", "Lillian", ""], ["Reddi", "Vijay Janapa", ""], ["Robie", "Taylor", ""], ["John", "Tom St.", ""], ["Tabaru", "Tsuguchika", ""], ["Wu", "Carole-Jean", ""], ["Xu", "Lingjie", ""], ["Yamazaki", "Masafumi", ""], ["Young", "Cliff", ""], ["Zaharia", "Matei", ""]]}, {"id": "1910.01508", "submitter": "Jos\\'e Su\\'arez-Varela", "authors": "Krzysztof Rusek, Jos\\'e Su\\'arez-Varela, Paul Almasan, Pere\n  Barlet-Ros, Albert Cabellos-Aparicio", "title": "RouteNet: Leveraging Graph Neural Networks for network modeling and\n  optimization in SDN", "comments": "12 pages", "journal-ref": "IEEE Journal on Selected Areas in Communication (JSAC), vol. 38,\n  no. 10, pp. 2260-2270, 2020", "doi": "10.1109/JSAC.2020.3000405", "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network modeling is a key enabler to achieve efficient network operation in\nfuture self-driving Software-Defined Networks. However, we still lack\nfunctional network models able to produce accurate predictions of Key\nPerformance Indicators (KPI) such as delay, jitter or loss at limited cost. In\nthis paper we propose RouteNet, a novel network model based on Graph Neural\nNetwork (GNN) that is able to understand the complex relationship between\ntopology, routing, and input traffic to produce accurate estimates of the\nper-source/destination per-packet delay distribution and loss. RouteNet\nleverages the ability of GNNs to learn and model graph-structured information\nand as a result, our model is able to generalize over arbitrary topologies,\nrouting schemes and traffic intensity. In our evaluation, we show that RouteNet\nis able to predict accurately the delay distribution (mean delay and jitter)\nand loss even in topologies, routing and traffic unseen in the training (worst\ncase MRE=15.4%). Also, we present several use cases where we leverage the KPI\npredictions of our GNN model to achieve efficient routing optimization and\nnetwork planning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:26:28 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 17:06:04 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Rusek", "Krzysztof", ""], ["Su\u00e1rez-Varela", "Jos\u00e9", ""], ["Almasan", "Paul", ""], ["Barlet-Ros", "Pere", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "1910.01510", "submitter": "David Rohde", "authors": "Finnian Lattimore, David Rohde", "title": "Causal inference with Bayes rule", "comments": "5 pages. arXiv admin note: substantial text overlap with\n  arXiv:1906.07125", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of causality has a controversial history. The question of whether\nit is possible to represent and address causal problems with probability\ntheory, or if fundamentally new mathematics such as the do-calculus is required\nhas been hotly debated, In this paper we demonstrate that, while it is critical\nto explicitly model our assumptions on the impact of intervening in a system,\nprovided we do so, estimating causal effects can be done entirely within the\nstandard Bayesian paradigm. The invariance assumptions underlying causal\ngraphical models can be encoded in ordinary Probabilistic graphical models,\nallowing causal estimation with Bayesian statistics, equivalent to the\ndo-calculus.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 11:32:19 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 22:19:38 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Lattimore", "Finnian", ""], ["Rohde", "David", ""]]}, {"id": "1910.01523", "submitter": "Yixing Xu", "authors": "Yixing Xu, Yunhe Wang, Kai Han, Yehui Tang, Shangling Jui, Chunjing\n  Xu, Chang Xu", "title": "ReNAS:Relativistic Evaluation of Neural Architecture Search", "comments": "CVPR 2021, Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective and efficient architecture performance evaluation scheme is\nessential for the success of Neural Architecture Search (NAS). To save\ncomputational cost, most of existing NAS algorithms often train and evaluate\nintermediate neural architectures on a small proxy dataset with limited\ntraining epochs. But it is difficult to expect an accurate performance\nestimation of an architecture in such a coarse evaluation way. This paper\nadvocates a new neural architecture evaluation scheme, which aims to determine\nwhich architecture would perform better instead of accurately predict the\nabsolute architecture performance. Therefore, we propose a\n\\textbf{relativistic} architecture performance predictor in NAS (ReNAS). We\nencode neural architectures into feature tensors, and further refining the\nrepresentations with the predictor. The proposed relativistic performance\npredictor can be deployed in discrete searching methods to search for the\ndesired architectures without additional evaluation. Experimental results on\nNAS-Bench-101 dataset suggests that, sampling 424 ($0.1\\%$ of the entire search\nspace) neural architectures and their corresponding validation performance is\nalready enough for learning an accurate architecture performance predictor. The\naccuracies of our searched neural architectures on NAS-Bench-101 and\nNAS-Bench-201 datasets are higher than that of the state-of-the-art methods and\nshow the priority of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 02:21:12 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 03:24:46 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 11:36:49 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2019 08:02:22 GMT"}, {"version": "v5", "created": "Wed, 10 Mar 2021 07:27:53 GMT"}, {"version": "v6", "created": "Mon, 22 Mar 2021 09:02:22 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Xu", "Yixing", ""], ["Wang", "Yunhe", ""], ["Han", "Kai", ""], ["Tang", "Yehui", ""], ["Jui", "Shangling", ""], ["Xu", "Chunjing", ""], ["Xu", "Chang", ""]]}, {"id": "1910.01526", "submitter": "Jianan Wang", "authors": "Joel Veness, Tor Lattimore, David Budden, Avishkar Bhoopchand,\n  Christopher Mattern, Agnieszka Grabska-Barwinska, Eren Sezener, Jianan Wang,\n  Peter Toth, Simon Schmitt, Marcus Hutter", "title": "Gated Linear Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1712.01897", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new family of backpropagation-free neural\narchitectures, Gated Linear Networks (GLNs). What distinguishes GLNs from\ncontemporary neural networks is the distributed and local nature of their\ncredit assignment mechanism; each neuron directly predicts the target, forgoing\nthe ability to learn feature representations in favor of rapid online learning.\nIndividual neurons can model nonlinear functions via the use of data-dependent\ngating in conjunction with online convex optimization. We show that this\narchitecture gives rise to universal learning capabilities in the limit, with\neffective model capacity increasing as a function of network size in a manner\ncomparable with deep ReLU networks. Furthermore, we demonstrate that the GLN\nlearning mechanism possesses extraordinary resilience to catastrophic\nforgetting, performing comparably to a MLP with dropout and Elastic Weight\nConsolidation on standard benchmarks. These desirable theoretical and empirical\nproperties position GLNs as a complementary technique to contemporary offline\ndeep learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 18:02:26 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 14:34:55 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Veness", "Joel", ""], ["Lattimore", "Tor", ""], ["Budden", "David", ""], ["Bhoopchand", "Avishkar", ""], ["Mattern", "Christopher", ""], ["Grabska-Barwinska", "Agnieszka", ""], ["Sezener", "Eren", ""], ["Wang", "Jianan", ""], ["Toth", "Peter", ""], ["Schmitt", "Simon", ""], ["Hutter", "Marcus", ""]]}, {"id": "1910.01544", "submitter": "Muhammad Osama", "authors": "Muhammad Osama, Dave Zachariah, Peter Stoica", "title": "Robust Risk Minimization for Statistical Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general statistical learning problem where an unknown fraction\nof the training data is corrupted. We develop a robust learning method that\nonly requires specifying an upper bound on the corrupted data fraction. The\nmethod minimizes a risk function defined by a non-parametric distribution with\nunknown probability weights. We derive and analyse the optimal weights and show\nhow they provide robustness against corrupted data. Furthermore, we give a\ncomputationally efficient coordinate descent algorithm to solve the risk\nminimization problem. We demonstrate the wide range applicability of the\nmethod, including regression, classification, unsupervised learning and classic\nparameter estimation, with state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 15:10:09 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 13:50:51 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Osama", "Muhammad", ""], ["Zachariah", "Dave", ""], ["Stoica", "Peter", ""]]}, {"id": "1910.01545", "submitter": "William Guss", "authors": "William H. Guss, Ruslan Salakhutdinov", "title": "On Universal Approximation by Neural Networks with Uniform Guarantees on\n  Approximation of Infinite Dimensional Maps", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The study of universal approximation of arbitrary functions $f: \\mathcal{X}\n\\to \\mathcal{Y}$ by neural networks has a rich and thorough history dating back\nto Kolmogorov (1957). In the case of learning finite dimensional maps, many\nauthors have shown various forms of the universality of both fixed depth and\nfixed width neural networks. However, in many cases, these classical results\nfail to extend to the recent use of approximations of neural networks with\ninfinitely many units for functional data analysis, dynamical systems\nidentification, and other applications where either $\\mathcal{X}$ or\n$\\mathcal{Y}$ become infinite dimensional. Two questions naturally arise: which\ninfinite dimensional analogues of neural networks are sufficient to approximate\nany map $f: \\mathcal{X} \\to \\mathcal{Y}$, and when do the finite approximations\nto these analogues used in practice approximate $f$ uniformly over its infinite\ndimensional domain $\\mathcal{X}$?\n  In this paper, we answer the open question of universal approximation of\nnonlinear operators when $\\mathcal{X}$ and $\\mathcal{Y}$ are both infinite\ndimensional. We show that for a large class of different infinite analogues of\nneural networks, any continuous map can be approximated arbitrarily closely\nwith some mild topological conditions on $\\mathcal{X}$. Additionally, we\nprovide the first lower-bound on the minimal number of input and output units\nrequired by a finite approximation to an infinite neural network to guarantee\nthat it can uniformly approximate any nonlinear operator using samples from its\ninputs and outputs.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 15:10:43 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Guss", "William H.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1910.01547", "submitter": "Teo Deveney", "authors": "Teo Deveney, Eike Mueller, Tony Shardlow", "title": "A deep surrogate approach to efficient Bayesian inversion in PDE and\n  integral equation models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a deep learning approach to efficiently perform Bayesian\ninference in partial differential equation (PDE) and integral equation models\nover potentially high-dimensional parameter spaces. The contributions of this\npaper are two-fold; the first is the introduction of a neural network approach\nto approximating the solutions of Fredholm and Volterra integral equations of\nthe first and second kind. The second is the development of a new, efficient\ndeep learning-based method for Bayesian inversion applied to problems that can\nbe described by PDEs or integral equations. To achieve this we introduce a\nsurrogate model, and demonstrate how this allows efficient sampling from a\nBayesian posterior distribution in which the likelihood depends on the\nsolutions of PDEs or integral equations. Our method relies on the direct\napproximation of parametric solutions by neural networks, without need of\ntraditional numerical solves. This deep learning approach allows the accurate\nand efficient approximation of parametric solutions in significantly higher\ndimensions than is possible using classical discretisation schemes. Since the\napproximated solutions can be cheaply evaluated, the solutions of Bayesian\ninverse problems over large parameter spaces are efficient using Markov chain\nMonte Carlo. We demonstrate the performance of our method using two real-world\nexamples; these include Bayesian inference in the PDE and integral equation\ncase for an example from electrochemistry, and Bayesian inference of a\nfunction-valued heat-transfer parameter with applications in aviation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 15:12:02 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 16:57:23 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 17:12:46 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 13:18:52 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Deveney", "Teo", ""], ["Mueller", "Eike", ""], ["Shardlow", "Tony", ""]]}, {"id": "1910.01570", "submitter": "Athanasios Vlontzos", "authors": "Kara Lamb, Garima Malhotra, Athanasios Vlontzos, Edward Wagstaff,\n  At{\\i}l{\\i}m G\\\"unes Baydin, Anahita Bhiwandiwalla, Yarin Gal, Alfredo\n  Kalaitzis, Anthony Reina, Asti Bhatt", "title": "Prediction of GNSS Phase Scintillations: A Machine Learning Approach", "comments": "First 4 authors contributed equally Paper accepted in Machine\n  Learning for the Physical Sciences workshop of NeurIPS 2019 Camera Ready\n  Version to Follow", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Global Navigation Satellite System (GNSS) uses a constellation of\nsatellites around the earth for accurate navigation, timing, and positioning.\nNatural phenomena like space weather introduce irregularities in the Earth's\nionosphere, disrupting the propagation of the radio signals that GNSS relies\nupon. Such disruptions affect both the amplitude and the phase of the\npropagated waves. No physics-based model currently exists to predict the time\nand location of these disruptions with sufficient accuracy and at relevant\nscales. In this paper, we focus on predicting the phase fluctuations of GNSS\nradio waves, known as phase scintillations. We propose a novel architecture and\nloss function to predict 1 hour in advance the magnitude of phase\nscintillations within a time window of plus-minus 5 minutes with\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 16:15:55 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Lamb", "Kara", ""], ["Malhotra", "Garima", ""], ["Vlontzos", "Athanasios", ""], ["Wagstaff", "Edward", ""], ["Baydin", "At\u0131l\u0131m G\u00fcnes", ""], ["Bhiwandiwalla", "Anahita", ""], ["Gal", "Yarin", ""], ["Kalaitzis", "Alfredo", ""], ["Reina", "Anthony", ""], ["Bhatt", "Asti", ""]]}, {"id": "1910.01578", "submitter": "Yanqi Zhou", "authors": "Yanqi Zhou, Sudip Roy, Amirali Abdolrashidi, Daniel Wong, Peter C. Ma,\n  Qiumin Xu, Ming Zhong, Hanxiao Liu, Anna Goldie, Azalia Mirhoseini, James\n  Laudon", "title": "GDP: Generalized Device Placement for Dataflow Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Runtime and scalability of large neural networks can be significantly\naffected by the placement of operations in their dataflow graphs on suitable\ndevices. With increasingly complex neural network architectures and\nheterogeneous device characteristics, finding a reasonable placement is\nextremely challenging even for domain experts. Most existing automated device\nplacement approaches are impractical due to the significant amount of compute\nrequired and their inability to generalize to new, previously held-out graphs.\nTo address both limitations, we propose an efficient end-to-end method based on\na scalable sequential attention mechanism over a graph neural network that is\ntransferable to new graphs. On a diverse set of representative deep learning\nmodels, including Inception-v3, AmoebaNet, Transformer-XL, and WaveNet, our\nmethod on average achieves 16% improvement over human experts and 9.2%\nimprovement over the prior art with 15 times faster convergence. To further\nreduce the computation cost, we pre-train the policy network on a set of\ndataflow graphs and use a superposition network to fine-tune it on each\nindividual graph, achieving state-of-the-art performance on large hold-out\ngraphs with over 50k nodes, such as an 8-layer GNMT.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 04:13:57 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Zhou", "Yanqi", ""], ["Roy", "Sudip", ""], ["Abdolrashidi", "Amirali", ""], ["Wong", "Daniel", ""], ["Ma", "Peter C.", ""], ["Xu", "Qiumin", ""], ["Zhong", "Ming", ""], ["Liu", "Hanxiao", ""], ["Goldie", "Anna", ""], ["Mirhoseini", "Azalia", ""], ["Laudon", "James", ""]]}, {"id": "1910.01589", "submitter": "Ping Li", "authors": "Mostafa Rahmani and Ping Li", "title": "Graph Analysis and Graph Pooling in the Spatial Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial convolution layer which is widely used in the Graph Neural\nNetworks (GNNs) aggregates the feature vector of each node with the feature\nvectors of its neighboring nodes. The GNN is not aware of the locations of the\nnodes in the global structure of the graph and when the local structures\ncorresponding to different nodes are similar to each other, the convolution\nlayer maps all those nodes to similar or same feature vectors in the continuous\nfeature space. Therefore, the GNN cannot distinguish two graphs if their\ndifference is not in their local structures. In addition, when the nodes are\nnot labeled/attributed the convolution layers can fail to distinguish even\ndifferent local structures. In this paper, we propose an effective solution to\naddress this problem of the GNNs. The proposed approach leverages a spatial\nrepresentation of the graph which makes the neural network aware of the\ndifferences between the nodes and also their locations in the graph. The\nspatial representation which is equivalent to a point-cloud representation of\nthe graph is obtained by a graph embedding method. Using the proposed approach,\nthe local feature extractor of the GNN distinguishes similar local structures\nin different locations of the graph and the GNN infers the topological\nstructure of the graph from the spatial distribution of the locally extracted\nfeature vectors. Moreover, the spatial representation is utilized to simplify\nthe graph down-sampling problem. A new graph pooling method is proposed and it\nis shown that the proposed pooling method achieves competitive or better\nresults in comparison with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 16:44:21 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Rahmani", "Mostafa", ""], ["Li", "Ping", ""]]}, {"id": "1910.01590", "submitter": "Vincent Fortuin", "authors": "Laura Manduchi, Matthias H\\\"user, Julia Vogt, Gunnar R\\\"atsch, Vincent\n  Fortuin", "title": "DPSOM: Deep Probabilistic Clustering with Self-Organizing Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating interpretable visualizations from complex data is a common problem\nin many applications. Two key ingredients for tackling this issue are\nclustering and representation learning. However, current methods do not yet\nsuccessfully combine the strengths of these two approaches. Existing\nrepresentation learning models which rely on latent topological structure such\nas self-organising maps, exhibit markedly lower clustering performance compared\nto recent deep clustering methods. To close this performance gap, we (a)\npresent a novel way to fit self-organizing maps with probabilistic cluster\nassignments (PSOM), (b) propose a new deep architecture for probabilistic\nclustering (DPSOM) using a VAE, and (c) extend our architecture for time-series\nclustering (T-DPSOM), which also allows forecasting in the latent space using\nLSTMs. We show that DPSOM achieves superior clustering performance compared to\ncurrent deep clustering methods on MNIST/Fashion-MNIST, while maintaining the\nfavourable visualization properties of SOMs. On medical time series, we show\nthat T-DPSOM outperforms baseline methods in time series clustering and time\nseries forecasting, while providing interpretable visualizations of patient\nstate trajectories and uncertainty estimation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 16:47:33 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 14:24:57 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 08:34:05 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Manduchi", "Laura", ""], ["H\u00fcser", "Matthias", ""], ["Vogt", "Julia", ""], ["R\u00e4tsch", "Gunnar", ""], ["Fortuin", "Vincent", ""]]}, {"id": "1910.01592", "submitter": "Alejandro Pozas-Kerstjens", "authors": "Alejandro Pozas-Kerstjens, Gorka Mu\\~noz-Gil, Eloy Pi\\~nol, Miguel\n  \\'Angel Garc\\'ia-March, Antonio Ac\\'in, Maciej Lewenstein, Przemys{\\l}aw R.\n  Grzybowski", "title": "Efficient training of energy-based models via spin-glass control", "comments": "16 pages, 7+1 figures, RevTeX 4.1. Code is available at\n  https://github.com/apozas/rapid/. v4: Updated to match published version", "journal-ref": "Machine Learning: Science and Technology 2, 025026 (2021)", "doi": "10.1088/2632-2153/abe807", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new family of energy-based probabilistic graphical models for\nefficient unsupervised learning. Its definition is motivated by the control of\nthe spin-glass properties of the Ising model described by the weights of\nBoltzmann machines. We use it to learn the Bars and Stripes dataset of various\nsizes and the MNIST dataset, and show how they quickly achieve the performance\noffered by standard methods for unsupervised learning. Our results indicate\nthat the standard initialization of Boltzmann machines with random weights\nequivalent to spin-glass models is an unnecessary bottleneck in the process of\ntraining. Furthermore, this new family allows for very easy access to\nlow-energy configurations, which points to new, efficient training algorithms.\nThe simplest variant of such algorithms approximates the negative phase of the\nlog-likelihood gradient with no Markov chain Monte Carlo sampling costs at all,\nand with an accuracy sufficient to achieve good learning and generalization.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 16:51:26 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 18:00:08 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 18:05:41 GMT"}, {"version": "v4", "created": "Thu, 15 Apr 2021 11:30:15 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Pozas-Kerstjens", "Alejandro", ""], ["Mu\u00f1oz-Gil", "Gorka", ""], ["Pi\u00f1ol", "Eloy", ""], ["Garc\u00eda-March", "Miguel \u00c1ngel", ""], ["Ac\u00edn", "Antonio", ""], ["Lewenstein", "Maciej", ""], ["Grzybowski", "Przemys\u0142aw R.", ""]]}, {"id": "1910.01601", "submitter": "Vahid Pourahmadi Dr.", "authors": "Pooya Khandel, Amir Hossein Rassafi, Vahid Pourahmadi, Saeed\n  Sharifian, and Rong Zheng", "title": "SensorDrop: A Reinforcement Learning Framework for Communication\n  Overhead Reduction on the Edge", "comments": "8 pages, 9 figures, Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In IoT solutions, it is usually desirable to collect data from a large number\nof distributed IoT sensors at a central node in the cloud for further\nprocessing. One of the main design challenges of such solutions is the high\ncommunication overhead between the sensors and the central node (especially for\nmultimedia data). In this paper, we aim to reduce the communication overhead\nand propose a method that is able to determine which sensors should send their\ndata to the central node and which to drop data. The idea is that some sensors\nmay have data which are correlated with others and some may have data that are\nnot essential for the operation to be performed at the central node. As such\ndecisions are application dependent and may change over time, they should be\nlearned during the operation of the system, for that we propose a method based\non Advantage Actor-Critic (A2C) reinforcement learning which gradually learns\nwhich sensor's data is cost-effective to be sent to the central node. The\nproposed approach has been evaluated on a multi-view multi-camera dataset, and\nwe observe a significant reduction in communication overhead with marginal\ndegradation in object classification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:08:05 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Khandel", "Pooya", ""], ["Rassafi", "Amir Hossein", ""], ["Pourahmadi", "Vahid", ""], ["Sharifian", "Saeed", ""], ["Zheng", "Rong", ""]]}, {"id": "1910.01603", "submitter": "Ruben Rodriguez Torrado", "authors": "Ruben Rodriguez Torrado, Ahmed Khalifa, Michael Cerny Green, Niels\n  Justesen, Sebastian Risi and Julian Togelius", "title": "Bootstrapping Conditional GANs for Video Game Level Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown im-pressive results for\nimage generation. However, GANs facechallenges in generating contents with\ncertain types of con-straints, such as game levels. Specifically, it is\ndifficult togenerate levels that have aesthetic appeal and are playable atthe\nsame time. Additionally, because training data usually islimited, it is\nchallenging to generate unique levels with cur-rent GANs. In this paper, we\npropose a new GAN architec-ture namedConditional Embedding Self-Attention\nGenera-tive Adversarial Network(CESAGAN) and a new bootstrap-ping training\nprocedure. The CESAGAN is a modification ofthe self-attention GAN that\nincorporates an embedding fea-ture vector input to condition the training of\nthe discriminatorand generator. This allows the network to model\nnon-localdependency between game objects, and to count objects. Ad-ditionally,\nto reduce the number of levels necessary to trainthe GAN, we propose a\nbootstrapping mechanism in whichplayable generated levels are added to the\ntraining set. Theresults demonstrate that the new approach does not only\ngen-erate a larger number of levels that are playable but also gen-erates fewer\nduplicate levels compared to a standard GAN.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:09:47 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Torrado", "Ruben Rodriguez", ""], ["Khalifa", "Ahmed", ""], ["Green", "Michael Cerny", ""], ["Justesen", "Niels", ""], ["Risi", "Sebastian", ""], ["Togelius", "Julian", ""]]}, {"id": "1910.01612", "submitter": "Adam Oberman", "authors": "Adam M Oberman", "title": "Partial differential equation regularization for supervised machine\n  learning", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is an overview of supervised machine learning problems for\nregression and classification. Topics include: kernel methods, training by\nstochastic gradient descent, deep learning architecture, losses for\nclassification, statistical learning theory, and dimension independent\ngeneralization bounds. Implicit regularization in deep learning examples are\npresented, including data augmentation, adversarial training, and additive\nnoise. These methods are reframed as explicit gradient regularization.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:29:17 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Oberman", "Adam M", ""]]}, {"id": "1910.01618", "submitter": "Alexandre Ren\\'e", "authors": "Alexandre Ren\\'e, Andr\\'e Longtin and Jakob H. Macke", "title": "Inference of a mesoscopic population model from population spike trains", "comments": "1st revision: 48 pages, 13 figures Improved statistical validation of\n  results. Rewrite of Section 4.2 to clarify the link between the mesoscopic\n  model and a transport equation. Multiple small improvements to the\n  presentation Original: 46 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand how rich dynamics emerge in neural populations, we require\nmodels exhibiting a wide range of activity patterns while remaining\ninterpretable in terms of connectivity and single-neuron dynamics. However, it\nhas been challenging to fit such mechanistic spiking networks at the single\nneuron scale to empirical population data. To close this gap, we propose to fit\nsuch data at a meso scale, using a mechanistic but low-dimensional and hence\nstatistically tractable model. The mesoscopic representation is obtained by\napproximating a population of neurons as multiple homogeneous `pools' of\nneurons, and modelling the dynamics of the aggregate population activity within\neach pool. We derive the likelihood of both single-neuron and connectivity\nparameters given this activity, which can then be used to either optimize\nparameters by gradient ascent on the log-likelihood, or to perform Bayesian\ninference using Markov Chain Monte Carlo (MCMC) sampling. We illustrate this\napproach using a model of generalized integrate-and-fire neurons for which\nmesoscopic dynamics have been previously derived, and show that both\nsingle-neuron and connectivity parameters can be recovered from simulated data.\nIn particular, our inference method extracts posterior correlations between\nmodel parameters, which define parameter subsets able to reproduce the data. We\ncompute the Bayesian posterior for combinations of parameters using MCMC\nsampling and investigate how the approximations inherent to a mesoscopic\npopulation model impact the accuracy of the inferred single-neuron parameters.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:37:42 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 22:40:14 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Ren\u00e9", "Alexandre", ""], ["Longtin", "Andr\u00e9", ""], ["Macke", "Jakob H.", ""]]}, {"id": "1910.01619", "submitter": "Yu Bai", "authors": "Yu Bai, Jason D. Lee", "title": "Beyond Linearization: On Quadratic and Higher-Order Approximation of\n  Wide Neural Networks", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical work has established connections between over-parametrized\nneural networks and linearized models governed by he Neural Tangent Kernels\n(NTKs). NTK theory leads to concrete convergence and generalization results,\nyet the empirical performance of neural networks are observed to exceed their\nlinearized models, suggesting insufficiency of this theory.\n  Towards closing this gap, we investigate the training of over-parametrized\nneural networks that are beyond the NTK regime yet still governed by the Taylor\nexpansion of the network. We bring forward the idea of \\emph{randomizing} the\nneural networks, which allows them to escape their NTK and couple with\nquadratic models. We show that the optimization landscape of randomized\ntwo-layer networks are nice and amenable to escaping-saddle algorithms. We\nprove concrete generalization and expressivity results on these randomized\nnetworks, which lead to sample complexity bounds (of learning certain simple\nfunctions) that match the NTK and can in addition be better by a dimension\nfactor when mild distributional assumptions are present. We demonstrate that\nour randomization technique can be generalized systematically beyond the\nquadratic case, by using it to find networks that are coupled with higher-order\nterms in their Taylor series.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:38:10 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 22:55:51 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bai", "Yu", ""], ["Lee", "Jason D.", ""]]}, {"id": "1910.01623", "submitter": "Martin Slawski", "authors": "Martin Slawski, Guoqing Diao, Emanuel Ben-David", "title": "A Pseudo-Likelihood Approach to Linear Regression with Partially\n  Shuffled Data", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been significant interest in linear regression in the\nsituation where predictors and responses are not observed in matching pairs\ncorresponding to the same statistical unit as a consequence of separate data\ncollection and uncertainty in data integration. Mismatched pairs can\nconsiderably impact the model fit and disrupt the estimation of regression\nparameters. In this paper, we present a method to adjust for such mismatches\nunder ``partial shuffling\" in which a sufficiently large fraction of\n(predictors, response)-pairs are observed in their correct correspondence. The\nproposed approach is based on a pseudo-likelihood in which each term takes the\nform of a two-component mixture density. Expectation-Maximization schemes are\nproposed for optimization, which (i) scale favorably in the number of samples,\nand (ii) achieve excellent statistical performance relative to an oracle that\nhas access to the correct pairings as certified by simulations and case\nstudies. In particular, the proposed approach can tolerate considerably larger\nfraction of mismatches than existing approaches, and enables estimation of the\nnoise level as well as the fraction of mismatches. Inference for the resulting\nestimator (standard errors, confidence intervals) can be based on established\ntheory for composite likelihood estimation. Along the way, we also propose a\nstatistical test for the presence of mismatches and establish its consistency\nunder suitable conditions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:43:11 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Slawski", "Martin", ""], ["Diao", "Guoqing", ""], ["Ben-David", "Emanuel", ""]]}, {"id": "1910.01624", "submitter": "Andreas Venzke", "authors": "Andreas Venzke and Spyros Chatzivasileiadis", "title": "Verification of Neural Network Behaviour: Formal Guarantees for Power\n  System Applications", "comments": "published in IEEE Transactions on Smart Grid\n  (https://ieeexplore.ieee.org/abstract/document/9141308)", "journal-ref": null, "doi": "10.1109/TSG.2020.3009401", "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents for the first time, to our knowledge, a framework for\nverifying neural network behavior in power system applications. Up to this\nmoment, neural networks have been applied in power systems as a black-box; this\nhas presented a major barrier for their adoption in practice. Developing a\nrigorous framework based on mixed integer linear programming, our methods can\ndetermine the range of inputs that neural networks classify as safe or unsafe,\nand are able to systematically identify adversarial examples. Such methods have\nthe potential to build the missing trust of power system operators on neural\nnetworks, and unlock a series of new applications in power systems. This paper\npresents the framework, methods to assess and improve neural network robustness\nin power systems, and addresses concerns related to scalability and accuracy.\nWe demonstrate our methods on the IEEE 9-bus, 14-bus, and 162-bus systems,\ntreating both N-1 security and small-signal stability.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:43:42 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 17:57:43 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 18:10:22 GMT"}, {"version": "v4", "created": "Thu, 30 Jul 2020 08:11:06 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Venzke", "Andreas", ""], ["Chatzivasileiadis", "Spyros", ""]]}, {"id": "1910.01634", "submitter": "Rushil Anirudh", "authors": "Rushil Anirudh, Hyojin Kim, Jayaraman J. Thiagarajan, K. Aditya Mohan,\n  Kyle M. Champley", "title": "Improving Limited Angle CT Reconstruction with a Robust GAN Prior", "comments": "NeurIPS 2019 Workshop on Deep Inverse Problems", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited angle CT reconstruction is an under-determined linear inverse problem\nthat requires appropriate regularization techniques to be solved. In this work\nwe study how pre-trained generative adversarial networks (GANs) can be used to\nclean noisy, highly artifact laden reconstructions from conventional\ntechniques, by effectively projecting onto the inferred image manifold. In\nparticular, we use a robust version of the popularly used GAN prior for inverse\nproblems, based on a recent technique called corruption mimicking, that\nsignificantly improves the reconstruction quality. The proposed approach\noperates in the image space directly, as a result of which it does not need to\nbe trained or require access to the measurement model, is scanner agnostic, and\ncan work over a wide range of sensing scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:52:14 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 23:19:21 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 23:22:24 GMT"}, {"version": "v4", "created": "Wed, 29 Jan 2020 17:40:27 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Anirudh", "Rushil", ""], ["Kim", "Hyojin", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Mohan", "K. Aditya", ""], ["Champley", "Kyle M.", ""]]}, {"id": "1910.01635", "submitter": "Greg Ongie", "authors": "Greg Ongie, Rebecca Willett, Daniel Soudry, Nathan Srebro", "title": "A Function Space View of Bounded Norm Infinite Width ReLU Nets: The\n  Multivariate Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key element of understanding the efficacy of overparameterized neural\nnetworks is characterizing how they represent functions as the number of\nweights in the network approaches infinity. In this paper, we characterize the\nnorm required to realize a function $f:\\mathbb{R}^d\\rightarrow\\mathbb{R}$ as a\nsingle hidden-layer ReLU network with an unbounded number of units (infinite\nwidth), but where the Euclidean norm of the weights is bounded, including\nprecisely characterizing which functions can be realized with finite norm. This\nwas settled for univariate univariate functions in Savarese et al. (2019),\nwhere it was shown that the required norm is determined by the L1-norm of the\nsecond derivative of the function. We extend the characterization to\nmultivariate functions (i.e., networks with d input units), relating the\nrequired norm to the L1-norm of the Radon transform of a (d+1)/2-power\nLaplacian of the function. This characterization allows us to show that all\nfunctions in Sobolev spaces $W^{s,1}(\\mathbb{R})$, $s\\geq d+1$, can be\nrepresented with bounded norm, to calculate the required norm for several\nspecific functions, and to obtain a depth separation result. These results have\nimportant implications for understanding generalization performance and the\ndistinction between neural networks and more traditional kernel learning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:56:10 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Ongie", "Greg", ""], ["Willett", "Rebecca", ""], ["Soudry", "Daniel", ""], ["Srebro", "Nathan", ""]]}, {"id": "1910.01636", "submitter": "Florent Chiaroni", "authors": "Florent Chiaroni, Mohamed-Cherif Rahal, Nicolas Hueber, Frederic\n  Dufaux", "title": "Self-supervised learning for autonomous vehicles perception: A\n  conciliation between analytical and learning methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, supervised deep learning techniques yield the best state-of-the-art\nprediction performances for a wide variety of computer vision tasks. However,\nsuch supervised techniques generally require a large amount of manually labeled\ntraining data. In the context of autonomous vehicles perception, this\nrequirement is critical, as the distribution of sensor data can continuously\nchange and include several unexpected variations. It turns out that a category\nof learning techniques, referred to as self-supervised learning (SSL), consists\nof replacing the manual labeling effort by an automatic labeling process.\nThanks to their ability to learn on the application time and in varying\nenvironments, state-of-the-art SSL techniques provide a valid alternative to\nsupervised learning for a variety of different tasks, including long-range\ntraversable area segmentation, moving obstacle instance segmentation, long-term\nmoving obstacle tracking, or depth map prediction. In this tutorial-style\narticle, we present an overview and a general formalization of the concept of\nself-supervised learning (SSL) for autonomous vehicles perception. This\nformalization provides helpful guidelines for developing novel frameworks based\non generic SSL principles. Moreover, it enables to point out significant\nchallenges in the design of future SSL systems.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:56:18 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 21:03:21 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Chiaroni", "Florent", ""], ["Rahal", "Mohamed-Cherif", ""], ["Hueber", "Nicolas", ""], ["Dufaux", "Frederic", ""]]}, {"id": "1910.01663", "submitter": "Dingli Yu", "authors": "Sanjeev Arora, Simon S. Du, Zhiyuan Li, Ruslan Salakhutdinov, Ruosong\n  Wang, Dingli Yu", "title": "Harnessing the Power of Infinitely Wide Deep Nets on Small-data Tasks", "comments": "Code for UCI experiments:\n  https://github.com/LeoYu/neural-tangent-kernel-UCI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research shows that the following two models are equivalent: (a)\ninfinitely wide neural networks (NNs) trained under l2 loss by gradient descent\nwith infinitesimally small learning rate (b) kernel regression with respect to\nso-called Neural Tangent Kernels (NTKs) (Jacot et al., 2018). An efficient\nalgorithm to compute the NTK, as well as its convolutional counterparts,\nappears in Arora et al. (2019a), which allowed studying performance of\ninfinitely wide nets on datasets like CIFAR-10. However, super-quadratic\nrunning time of kernel methods makes them best suited for small-data tasks. We\nreport results suggesting neural tangent kernels perform strongly on low-data\ntasks.\n  1. On a standard testbed of classification/regression tasks from the UCI\ndatabase, NTK SVM beats the previous gold standard, Random Forests (RF), and\nalso the corresponding finite nets.\n  2. On CIFAR-10 with 10 - 640 training samples, Convolutional NTK consistently\nbeats ResNet-34 by 1% - 3%.\n  3. On VOC07 testbed for few-shot image classification tasks on ImageNet with\ntransfer learning (Goyal et al., 2019), replacing the linear SVM currently used\nwith a Convolutional NTK SVM consistently improves performance.\n  4. Comparing the performance of NTK with the finite-width net it was derived\nfrom, NTK behavior starts at lower net widths than suggested by theoretical\nanalysis(Arora et al., 2019a). NTK's efficacy may trace to lower variance of\noutput.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 18:04:17 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 20:51:25 GMT"}, {"version": "v3", "created": "Sun, 27 Oct 2019 17:53:30 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Arora", "Sanjeev", ""], ["Du", "Simon S.", ""], ["Li", "Zhiyuan", ""], ["Salakhutdinov", "Ruslan", ""], ["Wang", "Ruosong", ""], ["Yu", "Dingli", ""]]}, {"id": "1910.01666", "submitter": "Rushil Anirudh", "authors": "Rushil Anirudh, Jayaraman J. Thiagarajan, Shusen Liu, Peer-Timo\n  Bremer, Brian K. Spears", "title": "Exploring Generative Physics Models with Scientific Priors in Inertial\n  Confinement Fusion", "comments": "Machine Learning for Physical Sciences Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is significant interest in using modern neural networks for scientific\napplications due to their effectiveness in modeling highly complex, non-linear\nproblems in a data-driven fashion. However, a common challenge is to verify the\nscientific plausibility or validity of outputs predicted by a neural network.\nThis work advocates the use of known scientific constraints as a lens into\nevaluating, exploring, and understanding such predictions for the problem of\ninertial confinement fusion.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 18:08:31 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Liu", "Shusen", ""], ["Bremer", "Peer-Timo", ""], ["Spears", "Brian K.", ""]]}, {"id": "1910.01671", "submitter": "Matthew Trager", "authors": "Matthew Trager, Kathl\\'en Kohn, Joan Bruna", "title": "Pure and Spurious Critical Points: a Geometric Study of Linear Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The critical locus of the loss function of a neural network is determined by\nthe geometry of the functional space and by the parameterization of this space\nby the network's weights. We introduce a natural distinction between pure\ncritical points, which only depend on the functional space, and spurious\ncritical points, which arise from the parameterization. We apply this\nperspective to revisit and extend the literature on the loss function of linear\nneural networks. For this type of network, the functional space is either the\nset of all linear maps from input to output space, or a determinantal variety,\ni.e., a set of linear maps with bounded rank. We use geometric properties of\ndeterminantal varieties to derive new results on the landscape of linear\nnetworks with different loss functions and different parameterizations. Our\nanalysis clearly illustrates that the absence of \"bad\" local minima in the loss\nlandscape of linear networks is due to two distinct phenomena that apply in\ndifferent settings: it is true for arbitrary smooth convex losses in the case\nof architectures that can express all linear maps (\"filling architectures\") but\nit holds only for the quadratic loss when the functional space is a\ndeterminantal variety (\"non-filling architectures\"). Without any assumption on\nthe architecture, smooth convex losses may lead to landscapes with many bad\nminima.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 18:22:30 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 02:46:46 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Trager", "Matthew", ""], ["Kohn", "Kathl\u00e9n", ""], ["Bruna", "Joan", ""]]}, {"id": "1910.01684", "submitter": "Harshit Gupta", "authors": "Jaejun Yoo, Kyong Hwan Jin, Harshit Gupta, Jerome Yerly, Matthias\n  Stuber, and Michael Unser", "title": "Time-Dependent Deep Image Prior for Dynamic MRI", "comments": "11 pages, 6 figures. First Author has been changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel unsupervised deep-learning-based algorithm for dynamic\nmagnetic resonance imaging (MRI) reconstruction. Dynamic MRI requires rapid\ndata acquisition for the study of moving organs such as the heart. Existing\nreconstruction methods suffer from restrictions either in the model design or\nin the absence of ground-truth data, resulting in low image quality. We\nintroduce a generalized version of the deep-image-prior approach, which\noptimizes the network weights to fit a sequence of sparsely acquired dynamic\nMRI measurements. Our method needs neither prior training nor additional data.\nIn particular, for cardiac images, it does not require the marking of\nheartbeats or the reordering of spokes. The key ingredients of our method are\nthreefold: 1) a fixed low-dimensional manifold that encodes the temporal\nvariations of images; 2) a network that maps the manifold into a more\nexpressive latent space; and 3) a convolutional neural network that generates a\ndynamic series of MRI images from the latent variables and that favors their\nconsistency with the measurements in k-space. Our method outperforms the\nstate-of-the-art methods quantitatively and qualitatively in both retrospective\nand real fetal cardiac datasets. To the best of our knowledge, this is the\nfirst unsupervised deep-learning-based method that can reconstruct the\ncontinuous variation of dynamic MRI sequences with high spatial resolution.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 18:55:47 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 15:47:01 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Yoo", "Jaejun", ""], ["Jin", "Kyong Hwan", ""], ["Gupta", "Harshit", ""], ["Yerly", "Jerome", ""], ["Stuber", "Matthias", ""], ["Unser", "Michael", ""]]}, {"id": "1910.01688", "submitter": "Yichi Zhang", "authors": "Yichi Zhang, Daniel Apley, Wei Chen", "title": "Bayesian Optimization for Materials Design with Mixed Quantitative and\n  Qualitative Variables", "comments": "29 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.mtrl-sci cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although Bayesian Optimization (BO) has been employed for accelerating\nmaterials design in computational materials engineering, existing works are\nrestricted to problems with quantitative variables. However, real designs of\nmaterials systems involve both qualitative and quantitative design variables\nrepresenting material compositions, microstructure morphology, and processing\nconditions. For mixed-variable problems, existing Bayesian Optimization (BO)\napproaches represent qualitative factors by dummy variables first and then fit\na standard Gaussian process (GP) model with numerical variables as the\nsurrogate model. This approach is restrictive theoretically and fails to\ncapture complex correlations between qualitative levels. We present in this\npaper the integration of a novel latent-variable (LV) approach for\nmixed-variable GP modeling with the BO framework for materials design. LVGP is\na fundamentally different approach that maps qualitative design variables to\nunderlying numerical LV in GP, which has strong physical justification. It\nprovides flexible parameterization and representation of qualitative factors\nand shows superior modeling accuracy compared to the existing methods. We\ndemonstrate our approach through testing with numerical examples and materials\ndesign examples. It is found that in all test examples the mapped LVs provide\nintuitive visualization and substantial insight into the nature and effects of\nthe qualitative factors. Though materials designs are used as examples, the\nmethod presented is generic and can be utilized for other mixed variable design\noptimization problems that involve expensive physics-based simulations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 19:05:20 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zhang", "Yichi", ""], ["Apley", "Daniel", ""], ["Chen", "Wei", ""]]}, {"id": "1910.01689", "submitter": "Jordan Guerguiev", "authors": "Jordan Guerguiev, Konrad P. Kording, Blake A. Richards", "title": "Spike-based causal inference for weight alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In artificial neural networks trained with gradient descent, the weights used\nfor processing stimuli are also used during backward passes to calculate\ngradients. For the real brain to approximate gradients, gradient information\nwould have to be propagated separately, such that one set of synaptic weights\nis used for processing and another set is used for backward passes. This\nproduces the so-called \"weight transport problem\" for biological models of\nlearning, where the backward weights used to calculate gradients need to mirror\nthe forward weights used to process stimuli. This weight transport problem has\nbeen considered so hard that popular proposals for biological learning assume\nthat the backward weights are simply random, as in the feedback alignment\nalgorithm. However, such random weights do not appear to work well for large\nnetworks. Here we show how the discontinuity introduced in a spiking system can\nlead to a solution to this problem. The resulting algorithm is a special case\nof an estimator used for causal inference in econometrics, regression\ndiscontinuity design. We show empirically that this algorithm rapidly makes the\nbackward weights approximate the forward weights. As the backward weights\nbecome correct, this improves learning performance over feedback alignment on\ntasks such as Fashion-MNIST, SVHN, CIFAR-10 and VOC. Our results demonstrate\nthat a simple learning rule in a spiking network can allow neurons to produce\nthe right backward connections and thus solve the weight transport problem.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 19:07:58 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 01:05:15 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Guerguiev", "Jordan", ""], ["Kording", "Konrad P.", ""], ["Richards", "Blake A.", ""]]}, {"id": "1910.01694", "submitter": "Jingrong Lin", "authors": "Jingrong Lin, Keegan Lensink, Eldad Haber", "title": "Fluid Flow Mass Transport for Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks have been shown to be powerful in generating\ncontent. To this end, they have been studied intensively in the last few years.\nNonetheless, training these networks requires solving a saddle point problem\nthat is difficult to solve and slowly converging. Motivated from techniques in\nthe registration of point clouds and by the fluid flow formulation of mass\ntransport, we investigate a new formulation that is based on strict\nminimization, without the need for the maximization. The formulation views the\nproblem as a matching problem rather than an adversarial one and thus allows us\nto quickly converge and obtain meaningful metrics in the optimization path.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 19:14:52 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 20:04:45 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Lin", "Jingrong", ""], ["Lensink", "Keegan", ""], ["Haber", "Eldad", ""]]}, {"id": "1910.01705", "submitter": "Khurram Javed Mr", "authors": "Khurram Javed, Hengshuai Yao, Martha White", "title": "Is Fast Adaptation All You Need?", "comments": "Meta Learning Workshop, NeurIPS 2019, 2 figures, MRCL, MAML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based meta-learning has proven to be highly effective at learning\nmodel initializations, representations, and update rules that allow fast\nadaptation from a few samples. The core idea behind these approaches is to use\nfast adaptation and generalization -- two second-order metrics -- as training\nsignals on a meta-training dataset. However, little attention has been given to\nother possible second-order metrics. In this paper, we investigate a different\ntraining signal -- robustness to catastrophic interference -- and demonstrate\nthat representations learned by directing minimizing interference are more\nconducive to incremental learning than those learned by just maximizing fast\nadaptation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 19:52:25 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Javed", "Khurram", ""], ["Yao", "Hengshuai", ""], ["White", "Martha", ""]]}, {"id": "1910.01706", "submitter": "Ryan D'Orazio", "authors": "Ryan D'Orazio, Dustin Morrill, James R. Wright", "title": "Bounds for Approximate Regret-Matching Algorithms", "comments": "4 pages + acknowledgements, references, and appendices (9 pages\n  total)", "journal-ref": "Smooth Games Optimization and Machine Learning Workshop: Bridging\n  Game Theory and Deep Learning (SGO&ML), at the Thirty-third Conference on\n  Neural Information Processing Systems (NeurIPS 2019), Dec 14th, 2019,\n  Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dominant approach to solving large imperfect-information games is\nCounterfactural Regret Minimization (CFR). In CFR, many regret minimization\nproblems are combined to solve the game. For very large games, abstraction is\ntypically needed to render CFR tractable. Abstractions are often manually\ntuned, possibly removing important strategic differences in the full game and\nharming performance. Function approximation provides a natural solution to\nfinding good abstractions to approximate the full game. A common approach to\nincorporating function approximation is to learn the inputs needed for a regret\nminimizing algorithm, allowing for generalization across many regret\nminimization problems. This paper gives regret bounds when a regret minimizing\nalgorithm uses estimates instead of true values. This form of analysis is the\nfirst to generalize to a larger class of $(\\Phi, f)$-regret matching\nalgorithms, and includes different forms of regret such as swap, internal, and\nexternal regret. We demonstrate how these results give a slightly tighter bound\nfor Regression Regret-Matching (RRM), and present a novel bound for combining\nregression with Hedge.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 19:58:28 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 01:25:35 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["D'Orazio", "Ryan", ""], ["Morrill", "Dustin", ""], ["Wright", "James R.", ""]]}, {"id": "1910.01708", "submitter": "Scott Fujimoto", "authors": "Scott Fujimoto, Edoardo Conti, Mohammad Ghavamzadeh, Joelle Pineau", "title": "Benchmarking Batch Deep Reinforcement Learning Algorithms", "comments": "Deep RL Workshop NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widely-used deep reinforcement learning algorithms have been shown to fail in\nthe batch setting--learning from a fixed data set without interaction with the\nenvironment. Following this result, there have been several papers showing\nreasonable performances under a variety of environments and batch settings. In\nthis paper, we benchmark the performance of recent off-policy and batch\nreinforcement learning algorithms under unified settings on the Atari domain,\nwith data generated by a single partially-trained behavioral policy. We find\nthat under these conditions, many of these algorithms underperform DQN trained\nonline with the same amount of data, as well as the partially-trained\nbehavioral policy. To introduce a strong baseline, we adapt the\nBatch-Constrained Q-learning algorithm to a discrete-action setting, and show\nit outperforms all existing algorithms at this task.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 20:15:55 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Fujimoto", "Scott", ""], ["Conti", "Edoardo", ""], ["Ghavamzadeh", "Mohammad", ""], ["Pineau", "Joelle", ""]]}, {"id": "1910.01709", "submitter": "Soroosh Mariooryad", "authors": "Raza Habib, Soroosh Mariooryad, Matt Shannon, Eric Battenberg, RJ\n  Skerry-Ryan, Daisy Stanton, David Kao, Tom Bagby", "title": "Semi-Supervised Generative Modeling for Controllable Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel generative model that combines state-of-the-art neural\ntext-to-speech (TTS) with semi-supervised probabilistic latent variable models.\nBy providing partial supervision to some of the latent variables, we are able\nto force them to take on consistent and interpretable purposes, which\npreviously hasn't been possible with purely unsupervised TTS models. We\ndemonstrate that our model is able to reliably discover and control important\nbut rarely labelled attributes of speech, such as affect and speaking rate,\nwith as little as 1% (30 minutes) supervision. Even at such low supervision\nlevels we do not observe a degradation of synthesis quality compared to a\nstate-of-the-art baseline. Audio samples are available on the web.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 20:18:45 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Habib", "Raza", ""], ["Mariooryad", "Soroosh", ""], ["Shannon", "Matt", ""], ["Battenberg", "Eric", ""], ["Skerry-Ryan", "RJ", ""], ["Stanton", "Daisy", ""], ["Kao", "David", ""], ["Bagby", "Tom", ""]]}, {"id": "1910.01713", "submitter": "Vadim Arzamasov", "authors": "Vadim Arzamasov and Klemens B\\\"ohm", "title": "Scenario Discovery via Rule Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario discovery is the process of finding areas of interest, commonly\nreferred to as scenarios, in data spaces resulting from simulations. For\ninstance, one might search for conditions - which are inputs of the simulation\nmodel - where the system under investigation is unstable. A commonly used\nalgorithm for scenario discovery is PRIM. It yields scenarios in the form of\nhyper-rectangles which are human-comprehensible. When the simulation model has\nmany inputs, and the simulations are computationally expensive, PRIM may not\nproduce good results, given the affordable volume of data. So we propose a new\nprocedure for scenario discovery - we train an intermediate statistical model\nwhich generalizes fast, and use it to label (a lot of) data for PRIM. We\nprovide the statistical intuition behind our idea. Our experimental study shows\nthat this method is much better than PRIM itself. Specifically, our method\nreduces the number of simulations runs necessary by 75% on average.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 20:40:18 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Arzamasov", "Vadim", ""], ["B\u00f6hm", "Klemens", ""]]}, {"id": "1910.01716", "submitter": "Khaza Anuarul Hoque", "authors": "Gautam Raj Mode, Prasad Calyam, Khaza Anuarul Hoque", "title": "False Data Injection Attacks in Internet of Things and Deep Learning\n  enabled Predictive Analytics", "comments": "extended version of the manuscript entitled \"Impact of False Data\n  Injection Attacks on Deep Learning enabled Predictive Analytics\" accepted for\n  publication in the IEEE NOMS 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry 4.0 is the latest industrial revolution primarily merging automation\nwith advanced manufacturing to reduce direct human effort and resources.\nPredictive maintenance (PdM) is an industry 4.0 solution, which facilitates\npredicting faults in a component or a system powered by state-of-the-art\nmachine learning (ML) algorithms and the Internet-of-Things (IoT) sensors.\nHowever, IoT sensors and deep learning (DL) algorithms, both are known for\ntheir vulnerabilities to cyber-attacks. In the context of PdM systems, such\nattacks can have catastrophic consequences as they are hard to detect due to\nthe nature of the attack. To date, the majority of the published literature\nfocuses on the accuracy of DL enabled PdM systems and often ignores the effect\nof such attacks. In this paper, we demonstrate the effect of IoT sensor attacks\non a PdM system. At first, we use three state-of-the-art DL algorithms,\nspecifically, Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and\nConvolutional Neural Network (CNN) for predicting the Remaining Useful Life\n(RUL) of a turbofan engine using NASA's C-MAPSS dataset. The obtained results\nshow that the GRU-based PdM model outperforms some of the recent literature on\nRUL prediction using the C-MAPSS dataset. Afterward, we model two different\ntypes of false data injection attacks (FDIA) on turbofan engine sensor data and\nevaluate their impact on CNN, LSTM, and GRU-based PdM systems. The obtained\nresults demonstrate that FDI attacks on even a few IoT sensors can strongly\ndefect the RUL prediction. However, the GRU-based PdM model performs better in\nterms of accuracy and resiliency. Lastly, we perform a study on the GRU-based\nPdM model using four different GRU networks with different sequence lengths.\nOur experiments reveal an interesting relationship between the accuracy,\nresiliency and sequence length for the GRU-based PdM models.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 20:50:08 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 21:26:54 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 02:57:28 GMT"}, {"version": "v4", "created": "Fri, 13 Dec 2019 00:07:14 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Mode", "Gautam Raj", ""], ["Calyam", "Prasad", ""], ["Hoque", "Khaza Anuarul", ""]]}, {"id": "1910.01723", "submitter": "Kolby Nottingham", "authors": "Kolby Nottingham, Anand Balakrishnan, Jyotirmoy Deshmukh, Connor\n  Christopherson, Joshua Greaves, David Wingate", "title": "Using Logical Specifications of Objectives in Multi-Objective\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the multi-objective reinforcement learning (MORL) paradigm, the relative\nimportance of each environment objective is often unknown prior to training, so\nagents must learn to specialize their behavior to optimize different\ncombinations of environment objectives that are specified post-training. These\nare typically linear combinations, so the agent is effectively parameterized by\na weight vector that describes how to balance competing environment objectives.\nHowever, many real world behaviors require non-linear combinations of\nobjectives. Additionally, the conversion between desired behavior and\nweightings is often unclear.\n  In this work, we explore the use of a language based on propositional logic\nwith quantitative semantics--in place of weight vectors--for specifying\nnon-linear behaviors in an interpretable way. We use a recurrent encoder to\nencode logical combinations of objectives, and train a MORL agent to generalize\nover these encodings. We test our agent in several environments with various\nobjectives and show that our agent can generalize to many never-before-seen\nspecifications with performance comparable to single policy baseline agents. We\nalso demonstrate our agent's ability to generate meaningful policies when\npresented with novel specifications and quickly specialize to novel\nspecifications.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 21:16:04 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 16:15:34 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Nottingham", "Kolby", ""], ["Balakrishnan", "Anand", ""], ["Deshmukh", "Jyotirmoy", ""], ["Christopherson", "Connor", ""], ["Greaves", "Joshua", ""], ["Wingate", "David", ""]]}, {"id": "1910.01726", "submitter": "Jianhong Chen", "authors": "Jianhong Chen, Huang Huang, Wenrui Hao, Jinchao Xu", "title": "A machine learning method correlating pulse pressure wave data with\n  pregnancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pulse feeling, representing the tactile arterial palpation of the heartbeat,\nhas been widely used in traditional Chinese medicine (TCM) to diagnose various\ndiseases. The quantitative relationship between the pulse wave and health\nconditions however has not been investigated in modern medicine. In this paper,\nwe explored the correlation between pulse pressure wave (PPW), rather than the\npulse key features in TCM, and pregnancy by using deep learning technology.\nThis computational approach shows that the accuracy of pregnancy detection by\nthe PPW is 84% with an AUC of 91%. Our study is a proof of concept of pulse\ndiagnosis and will also motivate further sophisticated investigations on pulse\nwaves.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 21:35:05 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Chen", "Jianhong", ""], ["Huang", "Huang", ""], ["Hao", "Wenrui", ""], ["Xu", "Jinchao", ""]]}, {"id": "1910.01727", "submitter": "Edward Grefenstette", "authors": "Edward Grefenstette, Brandon Amos, Denis Yarats, Phu Mon Htut, Artem\n  Molchanov, Franziska Meier, Douwe Kiela, Kyunghyun Cho, Soumith Chintala", "title": "Generalized Inner Loop Meta-Learning", "comments": "17 pages, 3 figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many (but not all) approaches self-qualifying as \"meta-learning\" in deep\nlearning and reinforcement learning fit a common pattern of approximating the\nsolution to a nested optimization problem. In this paper, we give a\nformalization of this shared pattern, which we call GIMLI, prove its general\nrequirements, and derive a general-purpose algorithm for implementing similar\napproaches. Based on this analysis and algorithm, we describe a library of our\ndesign, higher, which we share with the community to assist and enable future\nresearch into these kinds of meta-learning approaches. We end the paper by\nshowcasing the practical applications of this framework and library through\nillustrative experiments and ablation studies which they facilitate.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 21:41:56 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 15:42:14 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Grefenstette", "Edward", ""], ["Amos", "Brandon", ""], ["Yarats", "Denis", ""], ["Htut", "Phu Mon", ""], ["Molchanov", "Artem", ""], ["Meier", "Franziska", ""], ["Kiela", "Douwe", ""], ["Cho", "Kyunghyun", ""], ["Chintala", "Soumith", ""]]}, {"id": "1910.01735", "submitter": "Bo Jiang", "authors": "Bo Jiang, Beibei Wang, Jin Tang and Bin Luo", "title": "GmCN: Graph Mask Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have shown very powerful for graph data\nrepresentation and learning tasks. Existing GCNs usually conduct feature\naggregation on a fixed neighborhood graph in which each node computes its\nrepresentation by aggregating the feature representations of all its neighbors\nwhich is biased by its own representation. However, this fixed aggregation\nstrategy is not guaranteed to be optimal for GCN based graph learning and also\ncan be affected by some graph structure noises, such as incorrect or undesired\nedge connections. To address these issues, we propose a novel Graph mask\nConvolutional Network (GmCN) in which nodes can adaptively select the optimal\nneighbors in their feature aggregation to better serve GCN learning. GmCN can\nbe theoretically interpreted by a regularization framework, based on which we\nderive a simple update algorithm to determine the optimal mask adaptively in\nGmCN training process. Experiments on several datasets validate the\neffectiveness of GmCN.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 02:59:13 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 08:50:58 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Jiang", "Bo", ""], ["Wang", "Beibei", ""], ["Tang", "Jin", ""], ["Luo", "Bin", ""]]}, {"id": "1910.01736", "submitter": "Bo Jiang", "authors": "Bo Jiang, Leiling Wang, Jin Tang and Bin Luo", "title": "Context-Aware Graph Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been widely studied for graph data\nrepresentation and learning. However, existing GNNs generally conduct\ncontext-aware learning on node feature representation only which usually\nignores the learning of edge (weight) representation. In this paper, we propose\na novel unified GNN model, named Context-aware Adaptive Graph Attention Network\n(CaGAT). CaGAT aims to learn a context-aware attention representation for each\ngraph edge by further exploiting the context relationships among different\nedges. In particular, CaGAT conducts context-aware learning on both node\nfeature representation and edge (weight) representation simultaneously and\ncooperatively in a unified manner which can boost their respective performance\nin network training. We apply CaGAT on semi-supervised learning tasks.\nPromising experimental results on several benchmark datasets demonstrate the\neffectiveness and benefits of CaGAT.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:17:30 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Jiang", "Bo", ""], ["Wang", "Leiling", ""], ["Tang", "Jin", ""], ["Luo", "Bin", ""]]}, {"id": "1910.01738", "submitter": "Astrid Merckling", "authors": "Astrid Merckling, Alexandre Coninx, Loic Cressot, Stephane Doncieux\n  and Nicolas Perrin", "title": "State Representation Learning from Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a context where several policies can be observed as black boxes on\ndifferent instances of a control task, we propose a method to derive a state\nrepresentation that can be relied on to reproduce any of the observed policies.\nWe do so via imitation learning on a multi-head neural network consisting of a\nfirst part that outputs a common state representation and then one head per\npolicy to imitate. If the demonstrations contain enough diversity, the state\nrepresentation is general and can be transferred to learn new instances of the\ntask. We present a proof of concept with experimental results on a simulated 2D\nrobotic arm performing a reaching task, with noisy image inputs containing a\ndistractor, and show that the state representations learned provide a greater\nspeed up to end-to-end reinforcement learning on new instances of the task than\nwith other classical representations.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 14:43:01 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Merckling", "Astrid", ""], ["Coninx", "Alexandre", ""], ["Cressot", "Loic", ""], ["Doncieux", "Stephane", ""], ["Perrin", "Nicolas", ""]]}, {"id": "1910.01739", "submitter": "David Eriksson", "authors": "David Eriksson, Michael Pearce, Jacob R Gardner, Ryan Turner, Matthias\n  Poloczek", "title": "Scalable Global Optimization via Local Bayesian Optimization", "comments": "Appears in NeurIPS 2019 as a spotlight paper", "journal-ref": "In Advances in Neural Information Processing Systems 32, pages\n  5497-5508. 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has recently emerged as a popular method for the\nsample-efficient optimization of expensive black-box functions. However, the\napplication to high-dimensional problems with several thousand observations\nremains challenging, and on difficult problems Bayesian optimization is often\nnot competitive with other paradigms. In this paper we take the view that this\nis due to the implicit homogeneity of the global probabilistic models and an\noveremphasized exploration that results from global acquisition. This motivates\nthe design of a local probabilistic approach for global optimization of\nlarge-scale high-dimensional problems. We propose the $\\texttt{TuRBO}$\nalgorithm that fits a collection of local models and performs a principled\nglobal allocation of samples across these models via an implicit bandit\napproach. A comprehensive evaluation demonstrates that $\\texttt{TuRBO}$\noutperforms state-of-the-art methods from machine learning and operations\nresearch on problems spanning reinforcement learning, robotics, and the natural\nsciences.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 22:05:46 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 20:53:18 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 02:56:38 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 20:59:28 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Eriksson", "David", ""], ["Pearce", "Michael", ""], ["Gardner", "Jacob R", ""], ["Turner", "Ryan", ""], ["Poloczek", "Matthias", ""]]}, {"id": "1910.01740", "submitter": "Harsh Shrivastava", "authors": "Samyam Rajbhandari, Harsh Shrivastava, Yuxiong He", "title": "AntMan: Sparse Low-Rank Compression to Accelerate RNN inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide adoption of complex RNN based models is hindered by their inference\nperformance, cost and memory requirements. To address this issue, we develop\nAntMan, combining structured sparsity with low-rank decomposition\nsynergistically, to reduce model computation, size and execution time of RNNs\nwhile attaining desired accuracy. AntMan extends knowledge distillation based\ntraining to learn the compressed models efficiently. Our evaluation shows that\nAntMan offers up to 100x computation reduction with less than 1pt accuracy drop\nfor language and machine reading comprehension models. Our evaluation also\nshows that for a given accuracy target, AntMan produces 5x smaller models than\nthe state-of-art. Lastly, we show that AntMan offers super-linear speed gains\ncompared to theoretical speedup, demonstrating its practical value on commodity\nhardware.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 17:31:09 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Rajbhandari", "Samyam", ""], ["Shrivastava", "Harsh", ""], ["He", "Yuxiong", ""]]}, {"id": "1910.01741", "submitter": "Denis Yarats", "authors": "Denis Yarats, Amy Zhang, Ilya Kostrikov, Brandon Amos, Joelle Pineau,\n  Rob Fergus", "title": "Improving Sample Efficiency in Model-Free Reinforcement Learning from\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training an agent to solve control tasks directly from high-dimensional\nimages with model-free reinforcement learning (RL) has proven difficult. A\npromising approach is to learn a latent representation together with the\ncontrol policy. However, fitting a high-capacity encoder using a scarce reward\nsignal is sample inefficient and leads to poor performance. Prior work has\nshown that auxiliary losses, such as image reconstruction, can aid efficient\nrepresentation learning. However, incorporating reconstruction loss into an\noff-policy learning algorithm often leads to training instability. We explore\nthe underlying reasons and identify variational autoencoders, used by previous\ninvestigations, as the cause of the divergence. Following these findings, we\npropose effective techniques to improve training stability. This results in a\nsimple approach capable of matching state-of-the-art model-free and model-based\nalgorithms on MuJoCo control tasks. Furthermore, our approach demonstrates\nrobustness to observational noise, surpassing existing approaches in this\nsetting. Code, results, and videos are anonymously available at\nhttps://sites.google.com/view/sac-ae/home.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 15:50:03 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 00:34:50 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 15:42:09 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Yarats", "Denis", ""], ["Zhang", "Amy", ""], ["Kostrikov", "Ilya", ""], ["Amos", "Brandon", ""], ["Pineau", "Joelle", ""], ["Fergus", "Rob", ""]]}, {"id": "1910.01742", "submitter": "Wenqi Wei", "authors": "Wenqi Wei, Ling Liu, Margaret Loper, Ka-Ho Chow, Emre Gursoy, Stacey\n  Truex, Yanzhao Wu", "title": "Cross-Layer Strategic Ensemble Defense Against Adversarial Examples", "comments": "To appear in IEEE ICNC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) has demonstrated its success in multiple domains.\nHowever, DNN models are inherently vulnerable to adversarial examples, which\nare generated by adding adversarial perturbations to benign inputs to fool the\nDNN model to misclassify. In this paper, we present a cross-layer strategic\nensemble framework and a suite of robust defense algorithms, which are\nattack-independent, and capable of auto-repairing and auto-verifying the target\nmodel being attacked. Our strategic ensemble approach makes three original\ncontributions. First, we employ input-transformation diversity to design the\ninput-layer strategic transformation ensemble algorithms. Second, we utilize\nmodel-disagreement diversity to develop the output-layer strategic model\nensemble algorithms. Finally, we create an input-output cross-layer strategic\nensemble defense that strengthens the defensibility by combining diverse input\ntransformation based model ensembles with diverse output verification model\nensembles. Evaluated over 10 attacks on ImageNet dataset, we show that our\nstrategic ensemble defense algorithms can achieve high defense success rates\nand are more robust with high attack prevention success rates and low benign\nfalse negative rates, compared to existing representative defense methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 07:57:42 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Wei", "Wenqi", ""], ["Liu", "Ling", ""], ["Loper", "Margaret", ""], ["Chow", "Ka-Ho", ""], ["Gursoy", "Emre", ""], ["Truex", "Stacey", ""], ["Wu", "Yanzhao", ""]]}, {"id": "1910.01743", "submitter": "Shih-Yang Su", "authors": "Shih-Yang Su, Hossein Hajimirsadeghi, Greg Mori", "title": "Graph Generation with Variational Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating graph structures is a challenging problem due to the diverse\nrepresentations and complex dependencies among nodes. In this paper, we\nintroduce Graph Variational Recurrent Neural Network (GraphVRNN), a\nprobabilistic autoregressive model for graph generation. Through modeling the\nlatent variables of graph data, GraphVRNN can capture the joint distributions\nof graph structures and the underlying node attributes. We conduct experiments\non the proposed GraphVRNN in both graph structure learning and attribute\ngeneration tasks. The evaluation results show that the variational component\nallows our network to model complicated distributions, as well as generate\nplausible structures and node attributes.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 03:23:14 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Su", "Shih-Yang", ""], ["Hajimirsadeghi", "Hossein", ""], ["Mori", "Greg", ""]]}, {"id": "1910.01748", "submitter": "Guillermo A. Castillo", "authors": "Guillermo A. Castillo, Bowen Weng, Wei Zhang, Ayonga Hereid", "title": "Hybrid Zero Dynamics Inspired Feedback Control Policy Design for 3D\n  Bipedal Locomotion using Reinforcement Learning", "comments": "Supplemental video: https://youtu.be/GOT6bnxqwuU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel model-free reinforcement learning (RL) framework\nto design feedback control policies for 3D bipedal walking. Existing RL\nalgorithms are often trained in an end-to-end manner or rely on prior knowledge\nof some reference joint trajectories. Different from these studies, we propose\na novel policy structure that appropriately incorporates physical insights\ngained from the hybrid nature of the walking dynamics and the well-established\nhybrid zero dynamics approach for 3D bipedal walking. As a result, the overall\nRL framework has several key advantages, including lightweight network\nstructure, short training time, and less dependence on prior knowledge. We\ndemonstrate the effectiveness of the proposed method on Cassie, a challenging\n3D bipedal robot. The proposed solution produces stable limit walking cycles\nthat can track various walking speed in different directions. Surprisingly,\nwithout specifically trained with disturbances to achieve robustness, it also\nperforms robustly against various adversarial forces applied to the torso\ntowards both the forward and the backward directions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 22:20:04 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Castillo", "Guillermo A.", ""], ["Weng", "Bowen", ""], ["Zhang", "Wei", ""], ["Hereid", "Ayonga", ""]]}, {"id": "1910.01751", "submitter": "Suraj Nair", "authors": "Suraj Nair, Yuke Zhu, Silvio Savarese, Li Fei-Fei", "title": "Causal Induction from Visual Observations for Goal Directed Tasks", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal reasoning has been an indispensable capability for humans and other\nintelligent animals to interact with the physical world. In this work, we\npropose to endow an artificial agent with the capability of causal reasoning\nfor completing goal-directed tasks. We develop learning-based approaches to\ninducing causal knowledge in the form of directed acyclic graphs, which can be\nused to contextualize a learned goal-conditional policy to perform tasks in\nnovel environments with latent causal structures. We leverage attention\nmechanisms in our causal induction model and goal-conditional policy, enabling\nus to incrementally generate the causal graph from the agent's visual\nobservations and to selectively use the induced graph for determining actions.\nOur experiments show that our method effectively generalizes towards completing\nnew tasks in novel environments with previously unseen causal structures.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 22:32:40 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Nair", "Suraj", ""], ["Zhu", "Yuke", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1910.01761", "submitter": "Mike Tian-Jian Jiang", "authors": "Mike Tian-Jian Jiang", "title": "Character Feature Engineering for Japanese Word Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  On word segmentation problems, machine learning architecture engineering\noften draws attention. The problem representation itself, however, has remained\nalmost static as either word lattice ranking or character sequence tagging, for\nat least two decades. The latter of-ten shows stronger predictive power than\nthe former for out-of-vocabulary (OOV) issue. When the issue escalating to\nrapid adaptation, which is a common scenario for industrial applications,\nactive learning of partial annotations or re-training with additional lexical\nre-sources is usually applied, however, from a somewhat word-based perspective.\nNot only it is uneasy for end-users to comply with linguistically consistent\nword boundary decisions, but also the risk/cost of forking models permanently\nwith estimated weights is seldom affordable. To overcome the obstacle, this\nwork provides an alternative, which uses linguistic intuition about character\ncompositions, such that a sophisticated feature set and its derived scheme can\nenable dynamic lexicon expansion with the model remaining intact. Experiment\nresults suggest that the proposed solution, with or without external lexemes,\nperforms competitively in terms of F1 score and OOV recall across various\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 23:39:31 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Jiang", "Mike Tian-Jian", ""]]}, {"id": "1910.01763", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Andriy Myronenko, Ziyue Xu, Wenqi Li, Holger Roth, Yufang\n  Huang, Fausto Milletari, Daguang Xu", "title": "NeurReg: Neural Registration and Its Application to Image Segmentation", "comments": "WACV 2020 first round early accept; supplementary\n  https://drive.google.com/file/d/1kzTLQn8cpoQNAYWUDJMtN5HcqhbWbl7G/view?usp=sharing;\n  code will be released soon under NVIDIA open source; demos\n  https://www.youtube.com/watch?v=GYLD7t7dSAg&t=3s", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Registration is a fundamental task in medical image analysis which can be\napplied to several tasks including image segmentation, intra-operative\ntracking, multi-modal image alignment, and motion analysis. Popular\nregistration tools such as ANTs and NiftyReg optimize an objective function for\neach pair of images from scratch which is time-consuming for large images with\ncomplicated deformation. Facilitated by the rapid progress of deep learning,\nlearning-based approaches such as VoxelMorph have been emerging for image\nregistration. These approaches can achieve competitive performance in a\nfraction of a second on advanced GPUs. In this work, we construct a neural\nregistration framework, called NeurReg, with a hybrid loss of displacement\nfields and data similarity, which substantially improves the current\nstate-of-the-art of registrations. Within the framework, we simulate various\ntransformations by a registration simulator which generates fixed image and\ndisplacement field ground truth for training. Furthermore, we design three\nsegmentation frameworks based on the proposed registration framework: 1)\natlas-based segmentation, 2) joint learning of both segmentation and\nregistration tasks, and 3) multi-task learning with atlas-based segmentation as\nan intermediate feature. Extensive experimental results validate the\neffectiveness of the proposed NeurReg framework based on various metrics: the\nendpoint error (EPE) of the predicted displacement field, mean square error\n(MSE), normalized local cross-correlation (NLCC), mutual information (MI), Dice\ncoefficient, uncertainty estimation, and the interpretability of the\nsegmentation. The proposed NeurReg improves registration accuracy with fast\ninference speed, which can greatly accelerate related medical image analysis\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 00:07:22 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zhu", "Wentao", ""], ["Myronenko", "Andriy", ""], ["Xu", "Ziyue", ""], ["Li", "Wenqi", ""], ["Roth", "Holger", ""], ["Huang", "Yufang", ""], ["Milletari", "Fausto", ""], ["Xu", "Daguang", ""]]}, {"id": "1910.01769", "submitter": "Subhabrata Mukherjee", "authors": "Subhabrata Mukherjee and Ahmed Hassan Awadallah", "title": "Distilling BERT into Simple Neural Networks with Unlabeled Transfer Data", "comments": "Multilingual version of this work, namely XtremeDistil\n  (https://aka.ms/XtremeDistil) appears at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in pre-training huge models on large amounts of text through\nself supervision have obtained state-of-the-art results in various natural\nlanguage processing tasks. However, these huge and expensive models are\ndifficult to use in practise for downstream tasks. Some recent efforts use\nknowledge distillation to compress these models. However, we see a gap between\nthe performance of the smaller student models as compared to that of the large\nteacher. In this work, we leverage large amounts of in-domain unlabeled\ntransfer data in addition to a limited amount of labeled training instances to\nbridge this gap for distilling BERT. We show that simple RNN based student\nmodels even with hard distillation can perform at par with the huge teachers\ngiven the transfer set. The student performance can be further improved with\nsoft distillation and leveraging teacher intermediate representations. We show\nthat our student models can compress the huge teacher by up to 26x while still\nmatching or even marginally exceeding the teacher performance in low-resource\nsettings with small amount of labeled data. Additionally, for the multilingual\nextension of this work with XtremeDistil (Mukherjee and Hassan Awadallah,\n2020), we demonstrate massive distillation of multilingual BERT-like teacher\nmodels by upto 35x in terms of parameter compression and 51x in terms of\nlatency speedup for batch inference while retaining 95% of its F1-score for NER\nover 41 languages.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 01:01:26 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 01:44:14 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Mukherjee", "Subhabrata", ""], ["Awadallah", "Ahmed Hassan", ""]]}, {"id": "1910.01784", "submitter": "Lu Wang", "authors": "Lu Wang, Wenchao Yu, Wei Wang, Wei Cheng, Wei Zhang, Hongyuan Zha,\n  Xiaofeng He, Haifeng Chen", "title": "Learning Robust Representations with Graph Denoising Policy Network", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning, aiming to learn low-dimensional\nrepresentations which capture the geometric dependencies between nodes in the\noriginal graph, has gained increasing popularity in a variety of graph analysis\ntasks, including node classification and link prediction. Existing\nrepresentation learning methods based on graph neural networks and their\nvariants rely on the aggregation of neighborhood information, which makes it\nsensitive to noises in the graph. In this paper, we propose Graph Denoising\nPolicy Network (short for GDPNet) to learn robust representations from noisy\ngraph data through reinforcement learning. GDPNet first selects signal\nneighborhoods for each node, and then aggregates the information from the\nselected neighborhoods to learn node representations for the down-stream tasks.\nSpecifically, in the signal neighborhood selection phase, GDPNet optimizes the\nneighborhood for each target node by formulating the process of removing noisy\nneighborhoods as a Markov decision process and learning a policy with\ntask-specific rewards received from the representation learning phase. In the\nrepresentation learning phase, GDPNet aggregates features from signal neighbors\nto generate node representations for down-stream tasks, and provides\ntask-specific rewards to the signal neighbor selection phase. These two phases\nare jointly trained to select optimal sets of neighbors for target nodes with\nmaximum cumulative task-specific rewards, and to learn robust representations\nfor nodes. Experimental results on node classification task demonstrate the\neffectiveness of GDNet, outperforming the state-of-the-art graph representation\nlearning methods on several well-studied datasets. Additionally, GDPNet is\nmathematically equivalent to solving the submodular maximizing problem, which\ntheoretically guarantees the best approximation to the optimal solution with\nGDPNet.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 02:22:17 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Wang", "Lu", ""], ["Yu", "Wenchao", ""], ["Wang", "Wei", ""], ["Cheng", "Wei", ""], ["Zhang", "Wei", ""], ["Zha", "Hongyuan", ""], ["He", "Xiaofeng", ""], ["Chen", "Haifeng", ""]]}, {"id": "1910.01786", "submitter": "Zhen Zeng Dr.", "authors": "Zhen Zeng, Yuefeng Lu, Judong Shen, Wei Zheng, Peter Shaw, Mary Beth\n  Dorr", "title": "A Random Interaction Forest for Prioritizing Predictive Biomarkers", "comments": "15 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision medicine is becoming a focus in medical research recently, as its\nimplementation brings values to all stakeholders in the healthcare system.\nVarious statistical methodologies have been developed tackling problems in\ndifferent aspects of this field, e.g., assessing treatment heterogeneity,\nidentifying patient subgroups, or building treatment decision models. However,\nthere is a lack of new tools devoted to selecting and prioritizing predictive\nbiomarkers. We propose a novel tree-based ensemble method, random interaction\nforest (RIF), to generate predictive importance scores and prioritize candidate\nbiomarkers for constructing refined treatment decision models. RIF was\nevaluated by comparing with the conventional random forest and univariable\nregression methods and showed favorable properties under various simulation\nscenarios. We applied the proposed RIF method to a biomarker dataset from two\nphase III clinical trials of bezlotoxumab on $\\textit{Clostridium difficile}$\ninfection recurrence and obtained biologically meaningful results.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 02:28:41 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zeng", "Zhen", ""], ["Lu", "Yuefeng", ""], ["Shen", "Judong", ""], ["Zheng", "Wei", ""], ["Shaw", "Peter", ""], ["Dorr", "Mary Beth", ""]]}, {"id": "1910.01788", "submitter": "Ruosong Wang", "authors": "Zhao Song, Ruosong Wang, Lin F. Yang, Hongyang Zhang, Peilin Zhong", "title": "Efficient Symmetric Norm Regression via Linear Sketching", "comments": "To appear in NeurIPS 2019. Fixed accidental missorting of author\n  names", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide efficient algorithms for overconstrained linear regression\nproblems with size $n \\times d$ when the loss function is a symmetric norm (a\nnorm invariant under sign-flips and coordinate-permutations). An important\nclass of symmetric norms are Orlicz norms, where for a function $G$ and a\nvector $y \\in \\mathbb{R}^n$, the corresponding Orlicz norm $\\|y\\|_G$ is defined\nas the unique value $\\alpha$ such that $\\sum_{i=1}^n G(|y_i|/\\alpha) = 1$. When\nthe loss function is an Orlicz norm, our algorithm produces a $(1 +\n\\varepsilon)$-approximate solution for an arbitrarily small constant\n$\\varepsilon > 0$ in input-sparsity time, improving over the previously\nbest-known algorithm which produces a $d \\cdot \\mathrm{polylog} n$-approximate\nsolution. When the loss function is a general symmetric norm, our algorithm\nproduces a $\\sqrt{d} \\cdot \\mathrm{polylog} n \\cdot\n\\mathrm{mmc}(\\ell)$-approximate solution in input-sparsity time, where\n$\\mathrm{mmc}(\\ell)$ is a quantity related to the symmetric norm under\nconsideration. To the best of our knowledge, this is the first input-sparsity\ntime algorithm with provable guarantees for the general class of symmetric norm\nregression problem. Our results shed light on resolving the universal sketching\nproblem for linear regression, and the techniques might be of independent\ninterest to numerical linear algebra problems more broadly.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 02:51:57 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 05:56:03 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Song", "Zhao", ""], ["Wang", "Ruosong", ""], ["Yang", "Lin F.", ""], ["Zhang", "Hongyang", ""], ["Zhong", "Peilin", ""]]}, {"id": "1910.01791", "submitter": "Mohammad Lotfollahi", "authors": "Mohammad Lotfollahi, Mohsen Naghipourfar, Fabian J. Theis, F.\n  Alexander Wolf", "title": "Conditional out-of-sample generation for unpaired data using trVAE", "comments": "Added reference to Johansson et al. (2016) and removed sentences from\n  Lopez et al. (2018) in the background section (see acknowledgements)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.CB q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While generative models have shown great success in generating\nhigh-dimensional samples conditional on low-dimensional descriptors (learning\ne.g. stroke thickness in MNIST, hair color in CelebA, or speaker identity in\nWavenet), their generation out-of-sample poses fundamental problems. The\nconditional variational autoencoder (CVAE) as a simple conditional generative\nmodel does not explicitly relate conditions during training and, hence, has no\nincentive of learning a compact joint distribution across conditions. We\novercome this limitation by matching their distributions using maximum mean\ndiscrepancy (MMD) in the decoder layer that follows the bottleneck. This\nintroduces a strong regularization both for reconstructing samples within the\nsame condition and for transforming samples across conditions, resulting in\nmuch improved generalization. We refer to the architecture as\n\\emph{transformer} VAE (trVAE). Benchmarking trVAE on high-dimensional image\nand tabular data, we demonstrate higher robustness and higher accuracy than\nexisting approaches. In particular, we show qualitatively improved predictions\nfor cellular perturbation response to treatment and disease based on\nhigh-dimensional single-cell gene expression data, by tackling previously\nproblematic minority classes and multiple conditions. For generic tasks, we\nimprove Pearson correlations of high-dimensional estimated means and variances\nwith their ground truths from 0.89 to 0.97 and 0.75 to 0.87, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 03:39:35 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 11:49:58 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lotfollahi", "Mohammad", ""], ["Naghipourfar", "Mohsen", ""], ["Theis", "Fabian J.", ""], ["Wolf", "F. Alexander", ""]]}, {"id": "1910.01795", "submitter": "Bo Wu", "authors": "Bo Wu, Wen-Huang Cheng, Peiye Liu, Bei Liu, Zhaoyang Zeng, Jiebo Luo", "title": "SMP Challenge: An Overview of Social Media Prediction Challenge 2019", "comments": "ACM MM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"SMP Challenge\" aims to discover novel prediction tasks for numerous data on\nsocial multimedia and seek excellent research teams. Making predictions via\nsocial multimedia data (e.g. photos, videos or news) is not only helps us to\nmake better strategic decisions for the future, but also explores advanced\npredictive learning and analytic methods on various problems and scenarios,\nsuch as multimedia recommendation, advertising system, fashion analysis etc.\n  In the SMP Challenge at ACM Multimedia 2019, we introduce a novel prediction\ntask Temporal Popularity Prediction, which focuses on predicting future\ninteraction or attractiveness (in terms of clicks, views or likes etc.) of new\nonline posts in social media feeds before uploading. We also collected and\nreleased a large-scale SMPD benchmark with over 480K posts from 69K users. In\nthis paper, we define the challenge problem, give an overview of the dataset,\npresent statistics of rich information for data and annotation and design the\naccuracy and correlation evaluation metrics for temporal popularity prediction\nto the challenge.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 04:10:43 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 05:06:20 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wu", "Bo", ""], ["Cheng", "Wen-Huang", ""], ["Liu", "Peiye", ""], ["Liu", "Bei", ""], ["Zeng", "Zhaoyang", ""], ["Luo", "Jiebo", ""]]}, {"id": "1910.01803", "submitter": "Sajad Darabi", "authors": "Sajad Darabi, Mohammad Kachuee, Majid Sarrafzadeh", "title": "Unsupervised Representation for EHR Signals and Codes as Patient Status\n  Vector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective modeling of electronic health records presents many challenges as\nthey contain large amounts of irregularity most of which are due to the varying\nprocedures and diagnosis a patient may have. Despite the recent progress in\nmachine learning, unsupervised learning remains largely at open, especially in\nthe healthcare domain. In this work, we present a two-step unsupervised\nrepresentation learning scheme to summarize the multi-modal clinical time\nseries consisting of signals and medical codes into a patient status vector.\nFirst, an auto-encoder step is used to reduce sparse medical codes and clinical\ntime series into a distributed representation. Subsequently, the concatenation\nof the distributed representations is further fine-tuned using a forecasting\ntask. We evaluate the usefulness of the representation on two downstream tasks:\nmortality and readmission. Our proposed method shows improved generalization\nperformance for both short duration ICU visits and long duration ICU visits.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 05:42:50 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Darabi", "Sajad", ""], ["Kachuee", "Mohammad", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1910.01805", "submitter": "Alexander Jung", "authors": "Alexander Jung", "title": "On the Duality between Network Flows and Network Lasso", "comments": "networks, clustering, machine learning, optimization, duality, Lasso", "journal-ref": null, "doi": "10.1109/LSP.2020.2998400", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications generate data with an intrinsic network structure such as\ntime series data, image data or social network data. The network Lasso (nLasso)\nhas been proposed recently as a method for joint clustering and optimization of\nmachine learning models for networked data. The nLasso extends the Lasso from\nsparse linear models to clustered graph signals. This paper explores the\nduality of nLasso and network flow optimization. We show that, in a very\nprecise sense, nLasso is equivalent to a minimum-cost flow problem on the data\nnetwork structure. Our main technical result is a concise characterization of\nnLasso solutions via existence of certain network flows. The main conceptual\nresult is a useful link between nLasso methods and basic graph algorithms such\nas clustering or maximum flow.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 06:04:45 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 07:16:30 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Jung", "Alexander", ""]]}, {"id": "1910.01833", "submitter": "Tanner Bohn", "authors": "Tanner Bohn, Yining Hu, Charles X. Ling", "title": "Few-Shot Abstract Visual Reasoning With Spectral Features", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an image preprocessing technique capable of improving the\nperformance of few-shot classifiers on abstract visual reasoning tasks. Many\nvisual reasoning tasks with abstract features are easy for humans to learn with\nfew examples but very difficult for computer vision approaches with the same\nnumber of samples, despite the ability for deep learning models to learn\nabstract features. Same-different (SD) problems represent a type of visual\nreasoning task requiring knowledge of pattern repetition within individual\nimages, and modern computer vision approaches have largely faltered on these\nclassification problems, even when provided with vast amounts of training data.\nWe propose a simple method for solving these problems based on the insight that\nremoving peaks from the amplitude spectrum of an image is capable of\nemphasizing the unique parts of the image. When combined with several\nclassifiers, our method performs well on the SD SVRT tasks with few-shot\nlearning, improving upon the best comparable results on all tasks, with average\nabsolute accuracy increases nearly 40% for some classifiers. In particular, we\nfind that combining Relational Networks with this image preprocessing approach\nimproves their performance from chance-level to over 90% accuracy on several SD\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 08:15:15 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Bohn", "Tanner", ""], ["Hu", "Yining", ""], ["Ling", "Charles X.", ""]]}, {"id": "1910.01837", "submitter": "Johannes Rabold", "authors": "Johannes Rabold, Hannah Deininger, Michael Siebers, Ute Schmid", "title": "Enriching Visual with Verbal Explanations for Relational Concepts --\n  Combining LIME with Aleph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing number of deep learning applications, there is a growing\ndemand for explanations. Visual explanations provide information about which\nparts of an image are relevant for a classifier's decision. However,\nhighlighting of image parts (e.g., an eye) cannot capture the relevance of a\nspecific feature value for a class (e.g., that the eye is wide open).\nFurthermore, highlighting cannot convey whether the classification depends on\nthe mere presence of parts or on a specific spatial relation between them.\nConsequently, we present an approach that is capable of explaining a\nclassifier's decision in terms of logic rules obtained by the Inductive Logic\nProgramming system Aleph. The examples and the background knowledge needed for\nAleph are based on the explanation generation method LIME. We demonstrate our\napproach with images of a blocksworld domain. First, we show that our approach\nis capable of identifying a single relation as important explanatory construct.\nAfterwards, we present the more complex relational concept of towers. Finally,\nwe show how the generated relational rules can be explicitly related with the\ninput image, resulting in richer explanations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 08:51:41 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Rabold", "Johannes", ""], ["Deininger", "Hannah", ""], ["Siebers", "Michael", ""], ["Schmid", "Ute", ""]]}, {"id": "1910.01842", "submitter": "Duc Tam Nguyen", "authors": "Duc Tam Nguyen, Chaithanya Kumar Mummadi, Thi Phuong Nhung Ngo, Thi\n  Hoai Phuong Nguyen, Laura Beggel, Thomas Brox", "title": "SELF: Learning to Filter Noisy Labels with Self-Ensembling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been shown to over-fit a dataset when being\ntrained with noisy labels for a long enough time. To overcome this problem, we\npresent a simple and effective method self-ensemble label filtering (SELF) to\nprogressively filter out the wrong labels during training. Our method improves\nthe task performance by gradually allowing supervision only from the\npotentially non-noisy (clean) labels and stops learning on the filtered noisy\nlabels. For the filtering, we form running averages of predictions over the\nentire training dataset using the network output at different training epochs.\nWe show that these ensemble estimates yield more accurate identification of\ninconsistent predictions throughout training than the single estimates of the\nnetwork at the most recent training epoch. While filtered samples are removed\nentirely from the supervised training loss, we dynamically leverage them via\nsemi-supervised learning in the unsupervised loss. We demonstrate the positive\neffect of such an approach on various image classification tasks under both\nsymmetric and asymmetric label noise and at different noise ratios. It\nsubstantially outperforms all previous works on noise-aware learning across\ndifferent datasets and can be applied to a broad set of network architectures.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 08:59:54 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Nguyen", "Duc Tam", ""], ["Mummadi", "Chaithanya Kumar", ""], ["Ngo", "Thi Phuong Nhung", ""], ["Nguyen", "Thi Hoai Phuong", ""], ["Beggel", "Laura", ""], ["Brox", "Thomas", ""]]}, {"id": "1910.01845", "submitter": "Yoel Drori", "authors": "Yoel Drori and Ohad Shamir", "title": "The Complexity of Finding Stationary Points with Stochastic Gradient\n  Descent", "comments": "Corrected the attribution of Ghadimi and Lan's result", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the iteration complexity of stochastic gradient descent (SGD) for\nminimizing the gradient norm of smooth, possibly nonconvex functions. We\nprovide several results, implying that the $\\mathcal{O}(\\epsilon^{-4})$ upper\nbound of Ghadimi and Lan~\\cite{ghadimi2013stochastic} (for making the average\ngradient norm less than $\\epsilon$) cannot be improved upon, unless a\ncombination of additional assumptions is made. Notably, this holds even if we\nlimit ourselves to convex quadratic functions. We also show that for nonconvex\nfunctions, the feasibility of minimizing gradients with SGD is surprisingly\nsensitive to the choice of optimality criteria.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 09:10:11 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 17:56:15 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 06:58:32 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Drori", "Yoel", ""], ["Shamir", "Ohad", ""]]}, {"id": "1910.01847", "submitter": "Yuta Saito", "authors": "Yuta Saito, Gota Morishita, Shota Yasui", "title": "Dual Learning Algorithm for Delayed Conversions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In display advertising, predicting the conversion rate (CVR), meaning the\nprobability that a user takes a predefined action on an advertiser's website,\nis a fundamental task for estimating the value of displaying an advertisement\nto a user. There are two main challenges in CVR prediction due to delayed\nfeedback. First, some positive labels are not correctly observed in training\ndata because some conversions do not occur immediately after a click. Second,\ndelay mechanisms are not uniform among instances, meaning some positive\nfeedback are much more frequently observed than others. It is widely\nacknowledged that these problems lead to severe bias in CVR prediction. To\novercome these challenges, we propose two unbiased estimators: one for CVR\nprediction and the other for bias estimation. Subsequently, we propose a dual\nlearning algorithm in which a CVR predictor and a bias estimator are trained in\nalternating fashion using only observable conversions. The proposed algorithm\nis the first of its kind to address the two major challenges in a theoretically\nsophisticated manner. Empirical evaluations using synthetic datasets\ndemonstrate the practical value of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 09:26:48 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 06:44:09 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 01:11:36 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Saito", "Yuta", ""], ["Morishita", "Gota", ""], ["Yasui", "Shota", ""]]}, {"id": "1910.01849", "submitter": "Sylvain Courtain", "authors": "Sylvain Courtain, Pierre Leleux, Ilkka Kivimaki, Guillaume Guex, Marco\n  Saerens", "title": "Randomized Shortest Paths with Net Flows and Capacity Constraints", "comments": null, "journal-ref": null, "doi": "10.1016/j.ins.2020.10.005", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work extends the randomized shortest paths (RSP) model by investigating\nthe net flow RSP and adding capacity constraints on edge flows. The standard\nRSP is a model of movement, or spread, through a network interpolating between\na random-walk and a shortest-path behavior [30, 42, 49]. The framework assumes\na unit flow injected into a source node and collected from a target node with\nflows minimizing the expected transportation cost, together with a relative\nentropy regularization term. In this context, the present work first develops\nthe net flow RSP model considering that edge flows in opposite directions\nneutralize each other (as in electric networks), and proposes an algorithm for\ncomputing the expected routing costs between all pairs of nodes. This quantity\nis called the net flow RSP dissimilarity measure between nodes. Experimental\ncomparisons on node clustering tasks indicate that the net flow RSP\ndissimilarity is competitive with other state-of-the-art dissimilarities. In\nthe second part of the paper, it is shown how to introduce capacity constraints\non edge flows, and a procedure is developed to solve this constrained problem\nby exploiting Lagrangian duality. These two extensions should improve\nsignificantly the scope of applications of the RSP framework.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 09:35:16 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 09:43:03 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 09:15:12 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Courtain", "Sylvain", ""], ["Leleux", "Pierre", ""], ["Kivimaki", "Ilkka", ""], ["Guex", "Guillaume", ""], ["Saerens", "Marco", ""]]}, {"id": "1910.01853", "submitter": "Zied Selmi", "authors": "Zied Selmi, Mohamed Ben Halima, Umapada Pal and M.Adel Alimi", "title": "DELP-DAR System for License Plate Detection and Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic License Plate detection and Recognition (ALPR) is a quite popular\nand active research topic in the field of computer vision, image processing and\nintelligent transport systems. ALPR is used to make detection and recognition\nprocesses more robust and efficient in highly complicated environments and\nbackgrounds. Several research investigations are still necessary due to some\nconstraints such as: completeness of numbering systems of countries, different\ncolors, various languages, multiple sizes and varied fonts. For this, we\npresent in this paper an automatic framework for License Plate (LP) detection\nand recognition from complex scenes. Our framework is based on mask region\nconvolutional neural networks used for LP detection, segmentation and\nrecognition. Although some studies have focused on LP detection, LP\nrecognition, LP segmentation or just two of them, our study uses the maskr-cnn\nin the three stages. The evaluation of our framework is enhanced by four\ndatasets for different countries and consequently with various languages. In\nfact, it tested on four datasets including images captured from multiple scenes\nunder numerous conditions such as varied orientation, poor quality images,\nblurred images and complex environmental backgrounds. Extensive experiments\nshow the robustness and efficiency of our suggested framework in all datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 10:02:57 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Selmi", "Zied", ""], ["Halima", "Mohamed Ben", ""], ["Pal", "Umapada", ""], ["Alimi", "M. Adel", ""]]}, {"id": "1910.01858", "submitter": "Rakesh Katuwal Mr.", "authors": "Rakesh Katuwal, P.N. Suganthan", "title": "Stacked Autoencoder Based Deep Random Vector Functional Link Neural\n  Network for Classification", "comments": "29 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme learning machine (ELM), which can be viewed as a variant of Random\nVector Functional Link (RVFL) network without the input-output direct\nconnections, has been extensively used to create multi-layer (deep) neural\nnetworks. Such networks employ randomization based autoencoders (AE) for\nunsupervised feature extraction followed by an ELM classifier for final\ndecision making. Each randomization based AE acts as an independent feature\nextractor and a deep network is obtained by stacking several such AEs. Inspired\nby the better performance of RVFL over ELM, in this paper, we propose several\ndeep RVFL variants by utilizing the framework of stacked autoencoders.\nSpecifically, we introduce direct connections (feature reuse) from preceding\nlayers to the fore layers of the network as in the original RVFL network. Such\nconnections help to regularize the randomization and also reduce the model\ncomplexity. Furthermore, we also introduce denoising criterion, recovering\nclean inputs from their corrupted versions, in the autoencoders to achieve\nbetter higher level representations than the ordinary autoencoders. Extensive\nexperiments on several classification datasets show that our proposed deep\nnetworks achieve overall better and faster generalization than the other\nrelevant state-of-the-art deep neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 10:25:24 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 13:15:43 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 09:33:35 GMT"}, {"version": "v4", "created": "Thu, 13 Feb 2020 05:25:33 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Katuwal", "Rakesh", ""], ["Suganthan", "P. N.", ""]]}, {"id": "1910.01865", "submitter": "Fabien Petitcolas", "authors": "Marc Joye and Fabien A. P. Petitcolas", "title": "PINFER: Privacy-Preserving Inference for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The foreseen growing role of outsourced machine learning services is raising\nconcerns about the privacy of user data. Several technical solutions are being\nproposed to address the issue. Hardware security modules in cloud data centres\nappear limited to enterprise customers due to their complexity, while general\nmulti-party computation techniques require a large number of message exchanges.\nThis paper proposes a variety of protocols for privacy-preserving regression\nand classification that (i) only require additively homomorphic encryption\nalgorithms, (ii) limit interactions to a mere request and response, and (iii)\nthat can be used directly for important machine-learning algorithms such as\nlogistic regression and SVM classification. The basic protocols are then\nextended and applied to feed-forward neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 10:49:27 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Joye", "Marc", ""], ["Petitcolas", "Fabien A. P.", ""]]}, {"id": "1910.01888", "submitter": "Andreas Madsen", "authors": "Andreas Madsen, Alexander Rosenberg Johansen", "title": "Measuring Arithmetic Extrapolation Performance", "comments": "Published at Science meets Engineering of Deep Learning at 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Neural Arithmetic Logic Unit (NALU) is a neural network layer that can\nlearn exact arithmetic operations between the elements of a hidden state. The\ngoal of NALU is to learn perfect extrapolation, which requires learning the\nexact underlying logic of an unknown arithmetic problem. Evaluating the\nperformance of the NALU is non-trivial as one arithmetic problem might have\nmany solutions. As a consequence, single-instance MSE has been used to evaluate\nand compare performance between models. However, it can be hard to interpret\nwhat magnitude of MSE represents a correct solution and models sensitivity to\ninitialization. We propose using a success-criterion to measure if and when a\nmodel converges. Using a success-criterion we can summarize success-rate over\nmany initialization seeds and calculate confidence intervals. We contribute a\ngeneralized version of the previous arithmetic benchmark to measure models\nsensitivity under different conditions. This is, to our knowledge, the first\nextensive evaluation with respect to convergence of the NALU and its sub-units.\nUsing a success-criterion to summarize 4800 experiments we find that\nconsistently learning arithmetic extrapolation is challenging, in particular\nfor multiplication.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 12:00:36 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 09:31:54 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Madsen", "Andreas", ""], ["Johansen", "Alexander Rosenberg", ""]]}, {"id": "1910.01895", "submitter": "Richlove Frimpong", "authors": "Trivikram Dokka, Richlove Frimpong", "title": "Approximate policy iteration using neural networks for storage problems", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic single node energy storage problem (SNES) and\nrevisit Approximate Policy Iteration (API) to solve SNES. We show that the\nperformance of API can be boosted by using neural networks as an approximation\narchitecture at the policy evaluation stage. To achieve this, we use a model\ndifferent to that in literature with aggregate variables reducing the\ndimensionality of the decision vector, which in turn makes it viable to use\nneural network predictions in the policy improvement stage. We show that\nperformance improvement by neural networks is even more significant in the case\nwhen charging efficiency of storage systems is low.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 12:20:05 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Dokka", "Trivikram", ""], ["Frimpong", "Richlove", ""]]}, {"id": "1910.01907", "submitter": "Adith Boloor", "authors": "Adith Boloor, Karthik Garimella, Xin He, Christopher Gill, Yevgeniy\n  Vorobeychik, Xuan Zhang", "title": "Attacking Vision-based Perception in End-to-End Autonomous Driving\n  Models", "comments": "under review in the Journal of Systems Architecture 2019. arXiv admin\n  note: substantial text overlap with arXiv:1903.05157", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in machine learning, especially techniques such as deep\nneural networks, are enabling a range of emerging applications. One such\nexample is autonomous driving, which often relies on deep learning for\nperception. However, deep learning-based perception has been shown to be\nvulnerable to a host of subtle adversarial manipulations of images.\nNevertheless, the vast majority of such demonstrations focus on perception that\nis disembodied from end-to-end control. We present novel end-to-end attacks on\nautonomous driving in simulation, using simple physically realizable attacks:\nthe painting of black lines on the road. These attacks target deep neural\nnetwork models for end-to-end autonomous driving control. A systematic\ninvestigation shows that such attacks are easy to engineer, and we describe\nscenarios (e.g., right turns) in which they are highly effective. We define\nseveral objective functions that quantify the success of an attack and develop\ntechniques based on Bayesian Optimization to efficiently traverse the search\nspace of higher dimensional attacks. Additionally, we define a novel class of\nhijacking attacks, where painted lines on the road cause the driver-less car to\nfollow a target path. Through the use of network deconvolution, we provide\ninsights into the successful attacks, which appear to work by mimicking\nactivations of entirely different scenarios. Our code is available at\nhttps://github.com/xz-group/AdverseDrive\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 20:56:55 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Boloor", "Adith", ""], ["Garimella", "Karthik", ""], ["He", "Xin", ""], ["Gill", "Christopher", ""], ["Vorobeychik", "Yevgeniy", ""], ["Zhang", "Xuan", ""]]}, {"id": "1910.01911", "submitter": "Junghoon Seo", "authors": "Junghoon Seo, Seungwon Lee, Beomsu Kim, Taegyun Jeon", "title": "Revisiting Classical Bagging with Modern Transfer Learning for\n  On-the-fly Disaster Damage Detector", "comments": "Accepted at the 2019 NeurIPS Workshop on Artificial Intelligence for\n  Humanitarian Assistance and Disaster Response(AI+HADR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic post-disaster damage detection using aerial imagery is crucial for\nquick assessment of damage caused by disaster and development of a recovery\nplan. The main problem preventing us from creating an applicable model in\npractice is that damaged (positive) examples we are trying to detect are much\nharder to obtain than undamaged (negative) examples, especially in short time.\nIn this paper, we revisit the classical bootstrap aggregating approach in the\ncontext of modern transfer learning for data-efficient disaster damage\ndetection. Unlike previous classical ensemble learning articles, our work\npoints out the effectiveness of simple bagging in deep transfer learning that\nhas been underestimated in the context of imbalanced classification. Benchmark\nresults on the AIST Building Change Detection dataset show that our approach\nsignificantly outperforms existing methodologies, including the recently\nproposed disentanglement learning.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 12:47:58 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Seo", "Junghoon", ""], ["Lee", "Seungwon", ""], ["Kim", "Beomsu", ""], ["Jeon", "Taegyun", ""]]}, {"id": "1910.01913", "submitter": "Benjamin Eysenbach", "authors": "Benjamin Eysenbach and Sergey Levine", "title": "If MaxEnt RL is the Answer, What is the Question?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimentally, it has been observed that humans and animals often make\ndecisions that do not maximize their expected utility, but rather choose\noutcomes randomly, with probability proportional to expected utility.\nProbability matching, as this strategy is called, is equivalent to maximum\nentropy reinforcement learning (MaxEnt RL). However, MaxEnt RL does not\noptimize expected utility. In this paper, we formally show that MaxEnt RL does\noptimally solve certain classes of control problems with variability in the\nreward function. In particular, we show (1) that MaxEnt RL can be used to solve\na certain class of POMDPs, and (2) that MaxEnt RL is equivalent to a two-player\ngame where an adversary chooses the reward function. These results suggest a\ndeeper connection between MaxEnt RL, robust control, and POMDPs, and provide\ninsight for the types of problems for which we might expect MaxEnt RL to\nproduce effective solutions. Specifically, our results suggest that domains\nwith uncertainty in the task goal may be especially well-suited for MaxEnt RL\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 12:50:34 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Eysenbach", "Benjamin", ""], ["Levine", "Sergey", ""]]}, {"id": "1910.01914", "submitter": "Hicham Janati", "authors": "Hicham Janati, Thomas Bazeille, Bertrand Thirion, Marco Cuturi,\n  Alexandre Gramfort", "title": "Multi-subject MEG/EEG source imaging with sparse multi-task regression", "comments": "version 2. arXiv admin note: text overlap with arXiv:1902.04812", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetoencephalography and electroencephalography (M/EEG) are non-invasive\nmodalities that measure the weak electromagnetic fields generated by neural\nactivity. Estimating the location and magnitude of the current sources that\ngenerated these electromagnetic fields is a challenging ill-posed regression\nproblem known as \\emph{source imaging}. When considering a group study, a\ncommon approach consists in carrying out the regression tasks independently for\neach subject. An alternative is to jointly localize sources for all subjects\ntaken together, while enforcing some similarity between them. By pooling all\nmeasurements in a single multi-task regression, one makes the problem better\nposed, offering the ability to identify more sources and with greater\nprecision. The Minimum Wasserstein Estimates (MWE) promotes focal activations\nthat do not perfectly overlap for all subjects, thanks to a regularizer based\non Optimal Transport (OT) metrics. MWE promotes spatial proximity on the\ncortical mantel while coping with the varying noise levels across subjects. On\nrealistic simulations, MWE decreases the localization error by up to 4 mm per\nsource compared to individual solutions. Experiments on the Cam-CAN dataset\nshow a considerable improvement in spatial specificity in population imaging.\nOur analysis of a multimodal dataset shows how multi-subject source\nlocalization closes the gap between MEG and fMRI for brain mapping.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 07:20:29 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 08:38:09 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Janati", "Hicham", ""], ["Bazeille", "Thomas", ""], ["Thirion", "Bertrand", ""], ["Cuturi", "Marco", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1910.01918", "submitter": "Mohsen Jafarzadeh", "authors": "Mohsen Jafarzadeh, Yonas Tadesse", "title": "Convolutional Neural Networks for Speech Controlled Prosthetic Hands", "comments": "2019 First International Conference on Transdisciplinary AI\n  (TransAI), Laguna Hills, California, USA, 2019, pp. 35-42", "journal-ref": "2019 First International Conference on Transdisciplinary AI\n  (TransAI)", "doi": "10.1109/TransAI46475.2019.00014", "report-no": null, "categories": "eess.SY cs.HC cs.LG cs.RO cs.SD cs.SY eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition is one of the key topics in artificial intelligence, as it\nis one of the most common forms of communication in humans. Researchers have\ndeveloped many speech-controlled prosthetic hands in the past decades,\nutilizing conventional speech recognition systems that use a combination of\nneural network and hidden Markov model. Recent advancements in general-purpose\ngraphics processing units (GPGPUs) enable intelligent devices to run deep\nneural networks in real-time. Thus, state-of-the-art speech recognition systems\nhave rapidly shifted from the paradigm of composite subsystems optimization to\nthe paradigm of end-to-end optimization. However, a low-power embedded GPGPU\ncannot run these speech recognition systems in real-time. In this paper, we\nshow the development of deep convolutional neural networks (CNN) for speech\ncontrol of prosthetic hands that run in real-time on a NVIDIA Jetson TX2\ndeveloper kit. First, the device captures and converts speech into 2D features\n(like spectrogram). The CNN receives the 2D features and classifies the hand\ngestures. Finally, the hand gesture classes are sent to the prosthetic hand\nmotion control system. The whole system is written in Python with Keras, a deep\nlearning library that has a TensorFlow backend. Our experiments on the CNN\ndemonstrate the 91% accuracy and 2ms running time of hand gestures (text\noutput) from speech commands, which can be used to control the prosthetic hands\nin real-time.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 04:47:40 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Jafarzadeh", "Mohsen", ""], ["Tadesse", "Yonas", ""]]}, {"id": "1910.01919", "submitter": "Yongcan Cao", "authors": "Huixin Zhan and Yongcan Cao", "title": "Relationship Explainable Multi-objective Optimization Via Vector Value\n  Function Based Reinforcement Learning", "comments": "COLT19 submission. arXiv admin note: substantial text overlap with\n  arXiv:1909.12268", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving multi-objective optimization problems is important in various\napplications where users are interested in obtaining optimal policies subject\nto multiple, yet often conflicting objectives. A typical approach to obtain\noptimal policies is to first construct a loss function that is based on the\nscalarization of individual objectives, and then find the optimal policy that\nminimizes the loss. However, optimizing the scalarized (and weighted) loss does\nnot necessarily provide a guarantee of high performance on each possibly\nconflicting objective. In this paper, we propose a vector value based\nreinforcement learning approach that seeks to explicitly learn the\ninter-objective relationship and optimize multiple objectives based on the\nlearned relationship. In particular, the proposed method is to first define\nrelationship matrix, a mathematical representation of the inter-objective\nrelationship, and then create one actor and multiple critics that can co-learn\nthe relationship matrix and action selection. The proposed approach can\nquantify the inter-objective relationship via reinforcement learning when the\nimpact of one objective on another is unknown a prior. We also provide rigorous\nconvergence analysis of the proposed approach and present a quantitative\nevaluation of the approach based on two testing scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 23:10:57 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zhan", "Huixin", ""], ["Cao", "Yongcan", ""]]}, {"id": "1910.01921", "submitter": "Behnaz Moradi-Jamei", "authors": "Behnaz Moradi-Jamei, Heman Shakeri, Pietro Poggi-Corradini and Michael\n  J. Higgins", "title": "A new method for quantifying network cyclic structure to improve\n  community detection", "comments": "arXiv admin note: This paper is the new version of arXiv:1805.07484", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distinguishing property of communities in networks is that cycles are more\nprevalent within communities than across communities. Thus, the detection of\nthese communities may be aided through the incorporation of measures of the\nlocal \"richness\" of the cyclic structure. In this paper, we introduce renewal\nnon-backtracking random walks (RNBRW) as a way of quantifying this structure.\nRNBRW gives a weight to each edge equal to the probability that a\nnon-backtracking random walk completes a cycle with that edge. Hence, edges\nwith larger weights may be thought of as more important to the formation of\ncycles. Of note, since separate random walks can be performed in parallel,\nRNBRW weights can be estimated very quickly, even for large graphs. We give\nsimulation results showing that pre-weighting edges through RNBRW may\nsubstantially improve the performance of common community detection algorithms.\nOur results suggest that RNBRW is especially efficient for the challenging case\nof detecting communities in sparse graphs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 20:49:10 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 20:07:20 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Moradi-Jamei", "Behnaz", ""], ["Shakeri", "Heman", ""], ["Poggi-Corradini", "Pietro", ""], ["Higgins", "Michael J.", ""]]}, {"id": "1910.01931", "submitter": "Marianna Pensky", "authors": "Majid Noroozi, Marianna Pensky and Ramchandra Rimal", "title": "Sparse Popularity Adjusted Stochastic Block Model", "comments": "4 figures. arXiv admin note: text overlap with arXiv:1902.00431", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we study a sparse stochastic network enabled with a\nblock structure. The popular Stochastic Block Model (SBM) and the Degree\nCorrected Block Model (DCBM) address sparsity by placing an upper bound on the\nmaximum probability of connections between any pair of nodes. As a result,\nsparsity describes only the behavior of network as a whole, without\ndistinguishing between the block-dependent sparsity patterns. To the best of\nour knowledge, the recently introduced Popularity Adjusted Block Model (PABM)\nis the only block model that allows to introduce a {\\it structural sparsity}\nwhere some probabilities of connections are identically equal to zero while the\nrest of them remain above a certain threshold. The latter presents a more\nnuanced view of the network.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:20:05 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 00:06:34 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Noroozi", "Majid", ""], ["Pensky", "Marianna", ""], ["Rimal", "Ramchandra", ""]]}, {"id": "1910.01963", "submitter": "Sedigheh Mahdavi", "authors": "Sedigheh Mahdavi, Shima Khoshraftar, and Aijun An", "title": "Dynamic Joint Variational Graph Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning network representations is a fundamental task for many graph\napplications such as link prediction, node classification, graph clustering,\nand graph visualization. Many real-world networks are interpreted as dynamic\nnetworks and evolve over time. Most existing graph embedding algorithms were\ndeveloped for static graphs mainly and cannot capture the evolution of a large\ndynamic network. In this paper, we propose Dynamic joint Variational Graph\nAutoencoders (Dyn-VGAE) that can learn both local structures and temporal\nevolutionary patterns in a dynamic network. Dyn-VGAE provides a joint learning\nframework for computing temporal representations of all graph snapshots\nsimultaneously. Each auto-encoder embeds a graph snapshot based on its local\nstructure and can also learn temporal dependencies by collaborating with other\nautoencoders. We conduct experimental studies on dynamic real-world graph\ndatasets and the results demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 14:13:46 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Mahdavi", "Sedigheh", ""], ["Khoshraftar", "Shima", ""], ["An", "Aijun", ""]]}, {"id": "1910.01968", "submitter": "Florent Chiaroni", "authors": "Florent Chiaroni, Ghazaleh Khodabandelou, Mohamed-Cherif Rahal,\n  Nicolas Hueber, Frederic Dufaux", "title": "Generating Relevant Counter-Examples from a Positive Unlabeled Dataset\n  for Image Classification", "comments": "Submitted to Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With surge of available but unlabeled data, Positive Unlabeled (PU) learning\nis becoming a thriving challenge. This work deals with this demanding task for\nwhich recent GAN-based PU approaches have demonstrated promising results.\nGenerative adversarial Networks (GANs) are not hampered by deterministic bias\nor need for specific dimensionality. However, existing GAN-based PU approaches\nalso present some drawbacks such as sensitive dependence to prior knowledge, a\ncumbersome architecture or first-stage overfitting. To settle these issues, we\npropose to incorporate a biased PU risk within the standard GAN discriminator\nloss function. In this manner, the discriminator is constrained to request the\ngenerator to converge towards the unlabeled samples distribution while\ndiverging from the positive samples distribution. This enables the proposed\nmodel, referred to as D-GAN, to exclusively learn the counter-examples\ndistribution without prior knowledge. Experiments demonstrate that our approach\noutperforms state-of-the-art PU methods without prior by overcoming their\nissues.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 14:33:24 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Chiaroni", "Florent", ""], ["Khodabandelou", "Ghazaleh", ""], ["Rahal", "Mohamed-Cherif", ""], ["Hueber", "Nicolas", ""], ["Dufaux", "Frederic", ""]]}, {"id": "1910.01991", "submitter": "Felix Sattler", "authors": "Felix Sattler, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Clustered Federated Learning: Model-Agnostic Distributed Multi-Task\n  Optimization under Privacy Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is currently the most widely adopted framework for\ncollaborative training of (deep) machine learning models under privacy\nconstraints. Albeit it's popularity, it has been observed that Federated\nLearning yields suboptimal results if the local clients' data distributions\ndiverge. To address this issue, we present Clustered Federated Learning (CFL),\na novel Federated Multi-Task Learning (FMTL) framework, which exploits\ngeometric properties of the FL loss surface, to group the client population\ninto clusters with jointly trainable data distributions. In contrast to\nexisting FMTL approaches, CFL does not require any modifications to the FL\ncommunication protocol to be made, is applicable to general non-convex\nobjectives (in particular deep neural networks) and comes with strong\nmathematical guarantees on the clustering quality. CFL is flexible enough to\nhandle client populations that vary over time and can be implemented in a\nprivacy preserving way. As clustering is only performed after Federated\nLearning has converged to a stationary point, CFL can be viewed as a\npost-processing method that will always achieve greater or equal performance\nthan conventional FL by allowing clients to arrive at more specialized models.\nWe verify our theoretical analysis in experiments with deep convolutional and\nrecurrent neural networks on commonly used Federated Learning datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:31:09 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Sattler", "Felix", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1910.01992", "submitter": "Zhen Huang", "authors": "Zhen Huang, Tim Ng, Leo Liu, Henry Mason, Xiaodan Zhuang, Daben Liu", "title": "SNDCNN: Self-normalizing deep CNNs with scaled exponential linear units\n  for speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very deep CNNs achieve state-of-the-art results in both computer vision and\nspeech recognition, but are difficult to train. The most popular way to train\nvery deep CNNs is to use shortcut connections (SC) together with batch\nnormalization (BN). Inspired by Self- Normalizing Neural Networks, we propose\nthe self-normalizing deep CNN (SNDCNN) based acoustic model topology, by\nremoving the SC/BN and replacing the typical RELU activations with scaled\nexponential linear unit (SELU) in ResNet-50. SELU activations make the network\nself-normalizing and remove the need for both shortcut connections and batch\nnormalization. Compared to ResNet- 50, we can achieve the same or lower (up to\n4.5% relative) word error rate (WER) while boosting both training and inference\nspeed by 60%-80%. We also explore other model inference optimization schemes to\nfurther reduce latency for production use.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:31:48 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 14:39:52 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 20:39:17 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Huang", "Zhen", ""], ["Ng", "Tim", ""], ["Liu", "Leo", ""], ["Mason", "Henry", ""], ["Zhuang", "Xiaodan", ""], ["Liu", "Daben", ""]]}, {"id": "1910.01994", "submitter": "Robert Kwiatkowski", "authors": "Robert Kwiatkowski and Hod Lipson", "title": "Zero Shot Learning on Simulated Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a method for leveraging data from one source to learn\nhow to do multiple new tasks. Task transfer is achieved using a self-model that\nencapsulates the dynamics of a system and serves as an environment for\nreinforcement learning. To study this approach, we train a self-models on\nvarious robot morphologies, using randomly sampled actions. Using a self-model,\nan initial state and corresponding actions, we can predict the next state. This\npredictive self-model is then used by a standard reinforcement learning\nalgorithm to accomplish tasks without ever seeing a state from the \"real\"\nenvironment. These trained policies allow the robots to successfully achieve\ntheir goals in the \"real\" environment. We demonstrate that not only is training\non the self-model far more data efficient than learning even a single task, but\nalso that it allows for learning new tasks without necessitating any additional\ndata collection, essentially allowing zero-shot learning of new tasks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:35:40 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Kwiatkowski", "Robert", ""], ["Lipson", "Hod", ""]]}, {"id": "1910.02007", "submitter": "Yi Liu", "authors": "Yi Liu, Jialiang Peng, James J.Q Yu, Yi Wu", "title": "PPGAN: Privacy-preserving Generative Adversarial Network", "comments": "This paper was accepted by IEEE ICPADS 2019 Workshop. This paper\n  contains 10 pages, 3 figures", "journal-ref": null, "doi": "10.1109/ICPADS47876.2019.00150", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) and its variants serve as a perfect\nrepresentation of the data generation model, providing researchers with a large\namount of high-quality generated data. They illustrate a promising direction\nfor research with limited data availability. When GAN learns the semantic-rich\ndata distribution from a dataset, the density of the generated distribution\ntends to concentrate on the training data. Due to the gradient parameters of\nthe deep neural network contain the data distribution of the training samples,\nthey can easily remember the training samples. When GAN is applied to private\nor sensitive data, for instance, patient medical records, as private\ninformation may be leakage. To address this issue, we propose a\nPrivacy-preserving Generative Adversarial Network (PPGAN) model, in which we\nachieve differential privacy in GANs by adding well-designed noise to the\ngradient during the model learning procedure. Besides, we introduced the\nMoments Accountant strategy in the PPGAN training process to improve the\nstability and compatibility of the model by controlling privacy loss. We also\ngive a mathematical proof of the differential privacy discriminator. Through\nextensive case studies of the benchmark datasets, we demonstrate that PPGAN can\ngenerate high-quality synthetic data while retaining the required data\navailable under a reasonable privacy budget.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:01:22 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Liu", "Yi", ""], ["Peng", "Jialiang", ""], ["Yu", "James J. Q", ""], ["Wu", "Yi", ""]]}, {"id": "1910.02008", "submitter": "Ying Zhang", "authors": "Ying Zhang, \\\"Omer Deniz Akyildiz, Theodoros Damoulas, Sotirios\n  Sabanis", "title": "Nonasymptotic estimates for Stochastic Gradient Langevin Dynamics under\n  local conditions in nonconvex optimization", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the context of empirical risk minimization, see Raginsky, Rakhlin, and\nTelgarsky (2017), we are concerned with a non-asymptotic analysis of sampling\nalgorithms used in optimization. In particular, we obtain non-asymptotic error\nbounds for a popular class of algorithms called Stochastic Gradient Langevin\nDynamics (SGLD). These results are derived in Wasserstein-1 and Wasserstein-2\ndistances in the absence of log-concavity of the target distribution. More\nprecisely, the stochastic gradient $H(\\theta, x)$ is assumed to be locally\nLipschitz continuous in both variables, and furthermore, the dissipativity\ncondition is relaxed by removing its uniform dependence in $x$. This relaxation\nallows us to present two key paradigms within the framework of scalable\nposterior sampling for Bayesian inference and of nonconvex optimization;\nnamely, examples from minibatch logistic regression and from variational\ninference are given by providing theoretical guarantees for the sampling\nbehaviour of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:02:44 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 15:37:03 GMT"}, {"version": "v3", "created": "Tue, 21 Jan 2020 19:46:42 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 05:26:44 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zhang", "Ying", ""], ["Akyildiz", "\u00d6mer Deniz", ""], ["Damoulas", "Theodoros", ""], ["Sabanis", "Sotirios", ""]]}, {"id": "1910.02010", "submitter": "Hao Wang", "authors": "Hao Wang", "title": "Detection of fraudulent users in P2P financial market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial fraud detection is one of the core technological assets of Fintech\ncompanies. It saves tens of millions of money fro m Chinese Fintech companies\nsince the bad loan rate is more than 10%. HC Financial Service Group is the 3rd\nlargest company in the Chinese P2P financial market. In this paper we\nillustrate how we tackle the fraud detection problem at HC Financial. We\nutilize two powerful workhorses in the machine learning field - random forest\nand gradient boosting decision tree to detect fraudulent users . We demonstrate\nthat by carefully select features and tune model parameters , we could\neffectively filter out fraudulent users in the P2P market.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 07:58:04 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Wang", "Hao", ""]]}, {"id": "1910.02018", "submitter": "Emiliano Dall'Anese", "authors": "Amirhossein Ajalloeian, Andrea Simonetto, Emiliano Dall'Anese", "title": "Inexact Online Proximal-gradient Method for Time-varying Convex\n  Optimization", "comments": "In Proceedings of ACC-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers an online proximal-gradient method to track the\nminimizers of a composite convex function that may continuously evolve over\ntime. The online proximal-gradient method is inexact, in the sense that: (i) it\nrelies on an approximate first-order information of the smooth component of the\ncost; and, (ii) the proximal operator (with respect to the non-smooth term) may\nbe computed only up to a certain precision. Under suitable assumptions,\nconvergence of the error iterates is established for strongly convex cost\nfunctions. On the other hand, the dynamic regret is investigated when the cost\nis not strongly convex, under the additional assumption that the problem\nincludes feasibility sets that are compact. Bounds are expressed in terms of\nthe cumulative error and the path length of the optimal solutions. This\nsuggests how to allocate resources to strike a balance between performance and\nprecision in the gradient computation and in the proximal operator.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:22:43 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 22:44:54 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 21:52:26 GMT"}, {"version": "v4", "created": "Wed, 22 Apr 2020 23:36:41 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Ajalloeian", "Amirhossein", ""], ["Simonetto", "Andrea", ""], ["Dall'Anese", "Emiliano", ""]]}, {"id": "1910.02021", "submitter": "Viktor Zenkov", "authors": "Viktor Zenkov and Jason Laska", "title": "Dynamic data fusion using multi-input models for malware classification", "comments": "6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Criminals use malware to disrupt cyber-systems. The number of these\nmalware-vulnerable systems is increasing quickly as common systems, such as\nvehicles, routers, and lightbulbs, become increasingly interconnected\ncyber-systems. To address the scale of this problem, analysts divide malware\ninto classes and develop, for each class, a specialized defense. In this\nproject we classified malware with machine learning. In particular, we used a\nsupervised multi-class long short term memory (LSTM) model. We trained the\nalgorithm with thousands of malware files annotated with class labels (the\ntraining set), and the algorithm learned patterns indicative of each class. We\nused disassembled malware files (provided by Microsoft) and separated the\nconstituent data into parsed instructions, which look like human-readable\nmachine code text, and raw bytes, which are hexadecimal values. We are\ninterested in which format, text or hex, is more valuable as input for\nclassification. To solve this, we investigated four cases: a text-only model, a\nhexadecimal-only model, a multi-input model using both text and hexadecimal\ninputs, and a model based on combining the individual results. We performed\nthis investigation using the machine learning Python package Keras, which\nallows easily configurable deep learning architectures and training. We hoped\nto understand the trade-offs between the different formats. Due to the class\nimbalance in the data, we used multiple methods to compare the formats, using\ntest accuracies, balanced accuracies (taking into account weights of classes),\nand an accuracy derived from tables of confusion. We found that the multi-input\nmodel, which allows learning on both input types simultaneously, resulted in\nthe best performance. Our finding expedites malware classification research by\nproviding researchers a suitable deep learning architecture to train a tailored\nversion to their malware.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 16:00:29 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zenkov", "Viktor", ""], ["Laska", "Jason", ""]]}, {"id": "1910.02034", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Ahmed Farahat, Chetan Gupta", "title": "Generative Adversarial Networks for Failure Prediction", "comments": "ECML PKDD 2019 (The European Conference on Machine Learning and\n  Principles and Practice of Knowledge Discovery in Databases, 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prognostics and Health Management (PHM) is an emerging engineering discipline\nwhich is concerned with the analysis and prediction of equipment health and\nperformance. One of the key challenges in PHM is to accurately predict\nimpending failures in the equipment. In recent years, solutions for failure\nprediction have evolved from building complex physical models to the use of\nmachine learning algorithms that leverage the data generated by the equipment.\nHowever, failure prediction problems pose a set of unique challenges that make\ndirect application of traditional classification and prediction algorithms\nimpractical. These challenges include the highly imbalanced training data, the\nextremely high cost of collecting more failure samples, and the complexity of\nthe failure patterns. Traditional oversampling techniques will not be able to\ncapture such complexity and accordingly result in overfitting the training\ndata. This paper addresses these challenges by proposing a novel algorithm for\nfailure prediction using Generative Adversarial Networks (GAN-FP). GAN-FP first\nutilizes two GAN networks to simultaneously generate training samples and build\nan inference network that can be used to predict failures for new samples.\nGAN-FP first adopts an infoGAN to generate realistic failure and non-failure\nsamples, and initialize the weights of the first few layers of the inference\nnetwork. The inference network is then tuned by optimizing a weighted loss\nobjective using only real failure and non-failure samples. The inference\nnetwork is further tuned using a second GAN whose purpose is to guarantee the\nconsistency between the generated samples and corresponding labels. GAN-FP can\nbe used for other imbalanced classification problems as well.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:51:55 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zheng", "Shuai", ""], ["Farahat", "Ahmed", ""], ["Gupta", "Chetan", ""]]}, {"id": "1910.02035", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Chetan Gupta, Susumu Serita", "title": "Manufacturing Dispatching using Reinforcement and Transfer Learning", "comments": "ECML PKDD 2019 (The European Conference on Machine Learning and\n  Principles and Practice of Knowledge Discovery in Databases, 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient dispatching rule in manufacturing industry is key to ensure product\non-time delivery and minimum past-due and inventory cost. Manufacturing,\nespecially in the developed world, is moving towards on-demand manufacturing\nmeaning a high mix, low volume product mix. This requires efficient dispatching\nthat can work in dynamic and stochastic environments, meaning it allows for\nquick response to new orders received and can work over a disparate set of shop\nfloor settings. In this paper we address this problem of dispatching in\nmanufacturing. Using reinforcement learning (RL), we propose a new design to\nformulate the shop floor state as a 2-D matrix, incorporate job slack time into\nstate representation, and design lateness and tardiness rewards function for\ndispatching purpose. However, maintaining a separate RL model for each\nproduction line on a manufacturing shop floor is costly and often infeasible.\nTo address this, we enhance our deep RL model with an approach for dispatching\npolicy transfer. This increases policy generalization and saves time and cost\nfor model training and data collection. Experiments show that: (1) our approach\nperforms the best in terms of total discounted reward and average lateness,\ntardiness, (2) the proposed policy transfer approach reduces training time and\nincreases policy generalization.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:52:46 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zheng", "Shuai", ""], ["Gupta", "Chetan", ""], ["Serita", "Susumu", ""]]}, {"id": "1910.02043", "submitter": "Eduardo Soares Mr", "authors": "Eduardo Soares, Plamen Angelov", "title": "Fair-by-design explainable models for prediction of recidivism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recidivism prediction provides decision makers with an assessment of the\nlikelihood that a criminal defendant will reoffend that can be used in\npre-trial decision-making. It can also be used for prediction of locations\nwhere crimes most occur, profiles that are more likely to commit violent\ncrimes. While such instruments are gaining increasing popularity, their use is\ncontroversial as they may present potential discriminatory bias in the risk\nassessment. In this paper we propose a new fair-by-design approach to predict\nrecidivism. It is prototype-based, learns locally and extracts empirically the\ndata distribution. The results show that the proposed method is able to reduce\nthe bias and provide human interpretable rules to assist specialists in the\nexplanation of the given results.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 23:13:20 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Soares", "Eduardo", ""], ["Angelov", "Plamen", ""]]}, {"id": "1910.02047", "submitter": "Erich Kummerfeld", "authors": "Erich Kummerfeld and Alexander Rix", "title": "Simulations evaluating resampling methods for causal discovery: ensemble\n  performance and calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery can be a powerful tool for investigating causality when a\nsystem can be observed but is inaccessible to experiments in practice. Despite\nthis, it is rarely used in any scientific or medical fields. One of the major\nhurdles preventing the field of causal discovery from having a larger impact is\nthat it is difficult to determine when the output of a causal discovery method\ncan be trusted in a real-world setting. Trust is especially critical when human\nhealth is on the line.\n  In this paper, we report the results of a series of simulation studies\ninvestigating the performance of different resampling methods as indicators of\nconfidence in discovered graph features. We found that subsampling and sampling\nwith replacement both performed surprisingly well, suggesting that they can\nserve as grounds for confidence in graph features. We also found that the\ncalibration of subsampling and sampling with replacement had different\nconvergence properties, suggesting that one's choice of which to use should\ndepend on the sample size.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 17:19:27 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Kummerfeld", "Erich", ""], ["Rix", "Alexander", ""]]}, {"id": "1910.02049", "submitter": "Rui Guo", "authors": "Rui Guo, Dorien Herremans, Thor Magnusson", "title": "Midi Miner -- A Python library for tonal tension and track\n  classification", "comments": "2 pages. ISMIR - Late Breaking Demo, Delft, The Netherlands. November\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a Python library, called Midi Miner, that can calculate tonal\ntension and classify different tracks. MIDI (Music Instrument Digital\nInterface) is a hardware and software standard for communicating musical events\nbetween digital music devices. It is often used for tasks such as music\nrepresentation, communication between devices, and even music generation [5].\nTension is an essential element of the music listening experience, which can\ncome from a number of musical features including timbre, loudness and harmony\n[3]. Midi Miner provides a Python implementation for the tonal tension model\nbased on the spiral array [1] as presented by Herremans and Chew [4]. Midi\nMiner also performs key estimation and includes a track classifier that can\ndisentangle melody, bass, and harmony tracks. Even though tracks are often\nseparated in MIDI files, the musical function of each track is not always\nclear. The track classifier keeps the identified tracks and discards messy\ntracks, which can enable further analysis and training tasks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 08:09:55 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 08:35:20 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Guo", "Rui", ""], ["Herremans", "Dorien", ""], ["Magnusson", "Thor", ""]]}, {"id": "1910.02050", "submitter": "Junho Cho", "authors": "Junho Cho, Sethumadhavan Chandrasekhar, Erixhen Sula, Samuel Olsson,\n  Ellsworth Burrows, Greg Raybon, Roland Ryf, Nicolas Fontaine, Jean-Christophe\n  Antona, Steve Grubb, Peter Winzer, Andrew Chraplyvy", "title": "Supply-Power-Constrained Cable Capacity Maximization Using Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We experimentally achieve a 19% capacity gain per Watt of electrical supply\npower in a 12-span link by eliminating gain flattening filters and optimizing\nlaunch powers using machine learning by deep neural networks in a massively\nparallel fiber context.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 13:37:35 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Cho", "Junho", ""], ["Chandrasekhar", "Sethumadhavan", ""], ["Sula", "Erixhen", ""], ["Olsson", "Samuel", ""], ["Burrows", "Ellsworth", ""], ["Raybon", "Greg", ""], ["Ryf", "Roland", ""], ["Fontaine", "Nicolas", ""], ["Antona", "Jean-Christophe", ""], ["Grubb", "Steve", ""], ["Winzer", "Peter", ""], ["Chraplyvy", "Andrew", ""]]}, {"id": "1910.02052", "submitter": "V Ratna Saripalli", "authors": "V. Ratna Saripalli, Gopal Avinash, Dibyajyoti Pati, Michael Potter,\n  Charles W. Anderson", "title": "AI Assisted Annotator using Reinforcement Learning", "comments": "10 pages", "journal-ref": null, "doi": "10.1007/s42979-020-00356-z", "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Healthcare data suffers from both noise and lack of ground truth. The cost of\ndata increases as it is cleaned and annotated in healthcare. Unlike other data\nsets, medical data annotation, which is critical to accurate ground truth,\nrequires medical domain expertise for a better patient outcome. In this work,\nwe report on the use of reinforcement learning to mimic the decision making\nprocess of annotators for medical events, to automate annotation and labelling.\nThe reinforcement agent learns to annotate alarm data based on annotations done\nby an expert. Our method shows promising results on medical alarm data sets. We\ntrained DQN and A2C agents using the data from monitoring devices annotated by\nan expert. Initial results from these RL agents learning the expert annotation\nbehavior are promising. The A2C agent performs better in terms of learning the\nsparse events in a given state, thereby choosing more right actions compared to\nDQN agent. To the best of our knowledge, this is the first reinforcement\nlearning application for the automation of medical events annotation, which has\nfar-reaching practical use.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 22:57:42 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 00:33:28 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 21:38:28 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Saripalli", "V. Ratna", ""], ["Avinash", "Gopal", ""], ["Pati", "Dibyajyoti", ""], ["Potter", "Michael", ""], ["Anderson", "Charles W.", ""]]}, {"id": "1910.02054", "submitter": "Jeff Rasley", "authors": "Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, Yuxiong He", "title": "ZeRO: Memory Optimizations Toward Training Trillion Parameter Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large deep learning models offer significant accuracy gains, but training\nbillions to trillions of parameters is challenging. Existing solutions such as\ndata and model parallelisms exhibit fundamental limitations to fit these models\ninto limited device memory, while obtaining computation, communication and\ndevelopment efficiency. We develop a novel solution, Zero Redundancy Optimizer\n(ZeRO), to optimize memory, vastly improving training speed while increasing\nthe model size that can be efficiently trained. ZeRO eliminates memory\nredundancies in data- and model-parallel training while retaining low\ncommunication volume and high computational granularity, allowing us to scale\nthe model size proportional to the number of devices with sustained high\nefficiency. Our analysis on memory requirements and communication volume\ndemonstrates: ZeRO has the potential to scale beyond 1 Trillion parameters\nusing today's hardware.\n  We implement and evaluate ZeRO: it trains large models of over 100B parameter\nwith super-linear speedup on 400 GPUs, achieving throughput of 15 Petaflops.\nThis represents an 8x increase in model size and 10x increase in achievable\nperformance over state-of-the-art. In terms of usability, ZeRO can train large\nmodels of up to 13B parameters (e.g., larger than Megatron GPT 8.3B and T5 11B)\nwithout requiring model parallelism which is harder for scientists to apply.\nLast but not the least, researchers have used the system breakthroughs of ZeRO\nto create the world's largest language model (Turing-NLG, 17B parameters) with\nrecord breaking accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 17:29:39 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 16:55:13 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 06:45:15 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Rajbhandari", "Samyam", ""], ["Rasley", "Jeff", ""], ["Ruwase", "Olatunji", ""], ["He", "Yuxiong", ""]]}, {"id": "1910.02055", "submitter": "Hang Chu", "authors": "Hang Chu, Daiqing Li, David Acuna, Amlan Kar, Maria Shugrina, Xinkai\n  Wei, Ming-Yu Liu, Antonio Torralba, Sanja Fidler", "title": "Neural Turtle Graphics for Modeling City Road Layouts", "comments": "ICCV-2019 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Neural Turtle Graphics (NTG), a novel generative model for spatial\ngraphs, and demonstrate its applications in modeling city road layouts.\nSpecifically, we represent the road layout using a graph where nodes in the\ngraph represent control points and edges in the graph represent road segments.\nNTG is a sequential generative model parameterized by a neural network. It\niteratively generates a new node and an edge connecting to an existing node\nconditioned on the current graph. We train NTG on Open Street Map data and show\nthat it outperforms existing approaches using a set of diverse performance\nmetrics. Moreover, our method allows users to control styles of generated road\nlayouts mimicking existing cities as well as to sketch parts of the city road\nlayout to be synthesized. In addition to synthesis, the proposed NTG finds uses\nin an analytical task of aerial road parsing. Experimental results show that it\nachieves state-of-the-art performance on the SpaceNet dataset.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 17:30:00 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Chu", "Hang", ""], ["Li", "Daiqing", ""], ["Acuna", "David", ""], ["Kar", "Amlan", ""], ["Shugrina", "Maria", ""], ["Wei", "Xinkai", ""], ["Liu", "Ming-Yu", ""], ["Torralba", "Antonio", ""], ["Fidler", "Sanja", ""]]}, {"id": "1910.02060", "submitter": "Omid Poursaeed", "authors": "Omid Poursaeed, Vladimir G. Kim, Eli Shechtman, Jun Saito, Serge\n  Belongie", "title": "Neural Puppet: Generative Layered Cartoon Characters", "comments": "WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a learning based method for generating new animations of a cartoon\ncharacter given a few example images. Our method is designed to learn from a\ntraditionally animated sequence, where each frame is drawn by an artist, and\nthus the input images lack any common structure, correspondences, or labels. We\nexpress pose changes as a deformation of a layered 2.5D template mesh, and\ndevise a novel architecture that learns to predict mesh deformations matching\nthe template to a target image. This enables us to extract a common\nlow-dimensional structure from a diverse set of character poses. We combine\nrecent advances in differentiable rendering as well as mesh-aware models to\nsuccessfully align common template even if only a few character images are\navailable during training. In addition to coarse poses, character appearance\nalso varies due to shading, out-of-plane motions, and artistic effects. We\ncapture these subtle changes by applying an image translation network to refine\nthe mesh rendering, providing an end-to-end model to generate new animations of\na character with high visual quality. We demonstrate that our generative model\ncan be used to synthesize in-between frames and to create data-driven\ndeformation. Our template fitting procedure outperforms state-of-the-art\ngeneric techniques for detecting image correspondences.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 17:40:51 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 22:07:00 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 23:54:09 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Poursaeed", "Omid", ""], ["Kim", "Vladimir G.", ""], ["Shechtman", "Eli", ""], ["Saito", "Jun", ""], ["Belongie", "Serge", ""]]}, {"id": "1910.02065", "submitter": "Oana-Maria Camburu", "authors": "Oana-Maria Camburu, Eleonora Giunchiglia, Jakob Foerster, Thomas\n  Lukasiewicz, Phil Blunsom", "title": "Can I Trust the Explainer? Verifying Post-hoc Explanatory Methods", "comments": null, "journal-ref": "NeurIPS 2019 Workshop on Safety and Robustness in Decision Making,\n  Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For AI systems to garner widespread public acceptance, we must develop\nmethods capable of explaining the decisions of black-box models such as neural\nnetworks. In this work, we identify two issues of current explanatory methods.\nFirst, we show that two prevalent perspectives on explanations ---\nfeature-additivity and feature-selection --- lead to fundamentally different\ninstance-wise explanations. In the literature, explainers from different\nperspectives are currently being directly compared, despite their distinct\nexplanation goals. The second issue is that current post-hoc explainers are\neither validated under simplistic scenarios (on simple models such as linear\nregression, or on models trained on syntactic datasets), or, when applied to\nreal-world neural networks, explainers are commonly validated under the\nassumption that the learned models behave reasonably. However, neural networks\noften rely on unreasonable correlations, even when producing correct decisions.\nWe introduce a verification framework for explanatory methods under the\nfeature-selection perspective. Our framework is based on a non-trivial neural\nnetwork architecture trained on a real-world task, and for which we are able to\nprovide guarantees on its inner workings. We validate the efficacy of our\nevaluation by showing the failure modes of current explainers. We aim for this\nframework to provide a publicly available, off-the-shelf evaluation when the\nfeature-selection perspective on explanations is needed.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 17:44:36 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 14:58:47 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 13:41:46 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Camburu", "Oana-Maria", ""], ["Giunchiglia", "Eleonora", ""], ["Foerster", "Jakob", ""], ["Lukasiewicz", "Thomas", ""], ["Blunsom", "Phil", ""]]}, {"id": "1910.02071", "submitter": "Stefan Leichenauer", "authors": "Guillaume Verdon, Jacob Marks, Sasha Nanda, Stefan Leichenauer, Jack\n  Hidary", "title": "Quantum Hamiltonian-Based Models and the Variational Quantum Thermalizer\n  Algorithm", "comments": "13 + 8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new class of generative quantum-neural-network-based models\ncalled Quantum Hamiltonian-Based Models (QHBMs). In doing so, we establish a\nparadigmatic approach for quantum-probabilistic hybrid variational learning,\nwhere we efficiently decompose the tasks of learning classical and quantum\ncorrelations in a way which maximizes the utility of both classical and quantum\nprocessors. In addition, we introduce the Variational Quantum Thermalizer (VQT)\nfor generating the thermal state of a given Hamiltonian and target temperature,\na task for which QHBMs are naturally well-suited. The VQT can be seen as a\ngeneralization of the Variational Quantum Eigensolver (VQE) to thermal states:\nwe show that the VQT converges to the VQE in the zero temperature limit. We\nprovide numerical results demonstrating the efficacy of these techniques in\nillustrative examples. We use QHBMs and the VQT on Heisenberg spin systems, we\napply QHBMs to learn entanglement Hamiltonians and compression codes in\nsimulated free Bosonic systems, and finally we use the VQT to prepare thermal\nFermionic Gaussian states for quantum simulation.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 17:58:08 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Verdon", "Guillaume", ""], ["Marks", "Jacob", ""], ["Nanda", "Sasha", ""], ["Leichenauer", "Stefan", ""], ["Hidary", "Jack", ""]]}, {"id": "1910.02076", "submitter": "Preslav Nakov", "authors": "Mitra Mohtarami, James Glass, Preslav Nakov", "title": "Contrastive Language Adaptation for Cross-Lingual Stance Detection", "comments": null, "journal-ref": "EMNLP-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study cross-lingual stance detection, which aims to leverage labeled data\nin one language to identify the relative perspective (or stance) of a given\ndocument with respect to a claim in a different target language. In particular,\nwe introduce a novel contrastive language adaptation approach applied to memory\nnetworks, which ensures accurate alignment of stances in the source and target\nlanguages, and can effectively deal with the challenge of limited labeled data\nin the target language. The evaluation results on public benchmark datasets and\ncomparison against current state-of-the-art approaches demonstrate the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:01:23 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Mohtarami", "Mitra", ""], ["Glass", "James", ""], ["Nakov", "Preslav", ""]]}, {"id": "1910.02078", "submitter": "Mathieu Seurin", "authors": "Mathieu Seurin, Philippe Preux, Olivier Pietquin", "title": "I'm sorry Dave, I'm afraid I can't do that, Deep Q-learning from\n  forbidden action", "comments": "Accepted at Internationnal Joint Conference on Neural Networks\n  (IJCNN'2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Reinforcement Learning (RL) is still restricted to simulation or\nto enhance human-operated systems through recommendations. Real-world\nenvironments (e.g. industrial robots or power grids) are generally designed\nwith safety constraints in mind implemented in the shape of valid actions masks\nor contingency controllers. For example, the range of motion and the angles of\nthe motors of a robot can be limited to physical boundaries. Violating\nconstraints thus results in rejected actions or entering in a safe mode driven\nby an external controller, making RL agents incapable of learning from their\nmistakes. In this paper, we propose a simple modification of a state-of-the-art\ndeep RL algorithm (DQN), enabling learning from forbidden actions. To do so,\nthe standard Q-learning update is enhanced with an extra safety loss inspired\nby structured classification. We empirically show that it reduces the number of\nhit constraints during the learning phase and accelerates convergence to\nnear-optimal policies compared to using standard DQN. Experiments are done on a\nVisual Grid World Environment and Text-World domain.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:43:06 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 15:24:06 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 14:58:53 GMT"}, {"version": "v4", "created": "Thu, 13 Aug 2020 12:21:07 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Seurin", "Mathieu", ""], ["Preux", "Philippe", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1910.02095", "submitter": "Andrew Lohn", "authors": "Gavin S. Hartnett, Andrew J. Lohn, Alexander P. Sedlack", "title": "Adversarial Examples for Cost-Sensitive Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by safety-critical classification problems, we investigate\nadversarial attacks against cost-sensitive classifiers. We use current\nstate-of-the-art adversarially-resistant neural network classifiers [1] as the\nunderlying models. Cost-sensitive predictions are then achieved via a final\nprocessing step in the feed-forward evaluation of the network. We evaluate the\neffectiveness of cost-sensitive classifiers against a variety of attacks and we\nintroduce a new cost-sensitive attack which performs better than targeted\nattacks in some cases. We also explored the measures a defender can take in\norder to limit their vulnerability to these attacks. This attacker/defender\nscenario is naturally framed as a two-player zero-sum finite game which we\nanalyze using game theory.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 18:16:11 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Hartnett", "Gavin S.", ""], ["Lohn", "Andrew J.", ""], ["Sedlack", "Alexander P.", ""]]}, {"id": "1910.02096", "submitter": "Hongteng Xu", "authors": "Dixin Luo, Hongteng Xu, Lawrence Carin", "title": "Fused Gromov-Wasserstein Alignment for Hawkes Processes", "comments": "The workshop on learning with temporal point processes in NeurIPS\n  2019 (WTPP19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel fused Gromov-Wasserstein alignment method to jointly learn\nthe Hawkes processes in different event spaces, and align their event types.\nGiven two Hawkes processes, we use fused Gromov-Wasserstein discrepancy to\nmeasure their dissimilarity, which considers both the Wasserstein discrepancy\nbased on their base intensities and the Gromov-Wasserstein discrepancy based on\ntheir infectivity matrices. Accordingly, the learned optimal transport reflects\nthe correspondence between the event types of these two Hawkes processes. The\nHawkes processes and their optimal transport are learned jointly via maximum\nlikelihood estimation, with a fused Gromov-Wasserstein regularizer.\nExperimental results show that the proposed method works well on synthetic and\nreal-world data.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 18:17:43 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Luo", "Dixin", ""], ["Xu", "Hongteng", ""], ["Carin", "Lawrence", ""]]}, {"id": "1910.02097", "submitter": "Heinrich Jiang", "authors": "Ofir Nachum, Heinrich Jiang", "title": "Group-based Fair Learning Leads to Counter-intuitive Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of machine learning (ML) methods have been proposed recently to\nmaximize model predictive accuracy while enforcing notions of group parity or\nfairness across sub-populations. We propose a desirable property for these\nprocedures, slack-consistency: For any individual, the predictions of the model\nshould be monotonic with respect to allowed slack (i.e., maximum allowed\ngroup-parity violation). Such monotonicity can be useful for individuals to\nunderstand the impact of enforcing fairness on their predictions. Surprisingly,\nwe find that standard ML methods for enforcing fairness violate this basic\nproperty. Moreover, this undesirable behavior arises in situations agnostic to\nthe complexity of the underlying model or approximate optimizations, suggesting\nthat the simple act of incorporating a constraint can lead to drastically\nunintended behavior in ML. We present a simple theoretical method for enforcing\nslack-consistency, while encouraging further discussions on the unintended\nbehaviors potentially induced when enforcing group-based parity.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 18:20:50 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Nachum", "Ofir", ""], ["Jiang", "Heinrich", ""]]}, {"id": "1910.02100", "submitter": "Abishek Sankararaman", "authors": "Abishek Sankararaman, Ayalvadi Ganesh, Sanjay Shakkottai", "title": "Social Learning in Multi Agent Multi Armed Bandits", "comments": "Minor Corrections from before", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI cs.SI math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a distributed version of the classical stochastic\nMulti-Arm Bandit (MAB) problem. Our setting consists of a large number of\nagents $n$ that collaboratively and simultaneously solve the same instance of\n$K$ armed MAB to minimize the average cumulative regret over all agents. The\nagents can communicate and collaborate among each other \\emph{only} through a\npairwise asynchronous gossip based protocol that exchange a limited number of\nbits. In our model, agents at each point decide on (i) which arm to play, (ii)\nwhether to, and if so (iii) what and whom to communicate with. Agents in our\nmodel are decentralized, namely their actions only depend on their observed\nhistory in the past.\n  We develop a novel algorithm in which agents, whenever they choose,\ncommunicate only arm-ids and not samples, with another agent chosen uniformly\nand independently at random. The per-agent regret scaling achieved by our\nalgorithm is $O \\left( \\frac{\\lceil\\frac{K}{n}\\rceil+\\log(n)}{\\Delta}\n  \\log(T) + \\frac{\\log^3(n) \\log \\log(n)}{\\Delta^2}\n  \\right)$. Furthermore, any agent in our algorithm communicates only a total\nof $\\Theta(\\log(T))$ times over a time interval of $T$.\n  We compare our results to two benchmarks - one where there is no\ncommunication among agents and one corresponding to complete interaction. We\nshow both theoretically and empirically, that our algorithm experiences a\nsignificant reduction both in per-agent regret when compared to the case when\nagents do not collaborate and in communication complexity when compared to the\nfull interaction setting which requires $T$ communication attempts by an agent\nover $T$ arm pulls.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 18:34:04 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 15:12:18 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 01:20:10 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Sankararaman", "Abishek", ""], ["Ganesh", "Ayalvadi", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1910.02107", "submitter": "Tengfei Ma", "authors": "Tengfei Ma, Junyuan Shang, Cao Xiao, Jimeng Sun", "title": "GENN: Predicting Correlated Drug-drug Interactions with Graph Energy\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaining more comprehensive knowledge about drug-drug interactions (DDIs) is\none of the most important tasks in drug development and medical practice.\nRecently graph neural networks have achieved great success in this task by\nmodeling drugs as nodes and drug-drug interactions as links and casting DDI\npredictions as link prediction problems. However, correlations between link\nlabels (e.g., DDI types) were rarely considered in existing works. We propose\nthe graph energy neural network (GENN) to explicitly model link type\ncorrelations. We formulate the DDI prediction task as a structure prediction\nproblem and introduce a new energy-based model where the energy function is\ndefined by graph neural networks. Experiments on two real-world DDI datasets\ndemonstrated that GENN is superior to many baselines without consideration of\nlink type correlations and achieved $13.77\\%$ and $5.01\\%$ PR-AUC improvement\non the two datasets, respectively. We also present a case study in which \\mname\ncan better capture meaningful DDI correlations compared with baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 19:03:12 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 02:50:56 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Ma", "Tengfei", ""], ["Shang", "Junyuan", ""], ["Xiao", "Cao", ""], ["Sun", "Jimeng", ""]]}, {"id": "1910.02109", "submitter": "Dianbo Liu Dr", "authors": "Dianbo Liu, Kathe Fox, Griffin Weber, Tim Miller", "title": "Confederated Machine Learning on Horizontally and Vertically Separated\n  Medical Data for Large-Scale Health System Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health information is generally fragmented across silos. Though it is\ntechnically feasible to unite data for analysis in a manner that underpins a\nrapid learning healthcare system, privacy concerns and regulatory barriers\nlimit data centralization. Machine learning can be conducted in a federated\nmanner on patient datasets with the same set of variables, but separated across\nsites of care. But federated learning cannot handle the situation where\ndifferent data types for a given patient are separated vertically across\ndifferent organizations and when patient ID matching across different\ninstitutions is difficult. We call methods that enable machine learning model\ntraining on data separated by two or more degrees confederated machine\nlearning. We proposed and evaluated a confederated learning to training machine\nlearning model to stratify the risk of several diseases among when data are\nhorizontally separated by individual, vertically separated by data type, and\nseparated by identity without patient ID matching.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 19:14:46 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 02:46:02 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 17:42:03 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Liu", "Dianbo", ""], ["Fox", "Kathe", ""], ["Weber", "Griffin", ""], ["Miller", "Tim", ""]]}, {"id": "1910.02114", "submitter": "Katherine Kempfert", "authors": "Katherine C. Kempfert, Yishi Wang, Cuixian Chen, and Samuel W.K. Wong", "title": "A Comparison Study on Nonlinear Dimension Reduction Methods with Kernel\n  Variations: Visualization, Optimization and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of high dimensionality, correlation among covariates, and noise\ncontained in data, dimension reduction (DR) techniques are often employed to\nthe application of machine learning algorithms. Principal Component Analysis\n(PCA), Linear Discriminant Analysis (LDA), and their kernel variants (KPCA,\nKLDA) are among the most popular DR methods. Recently, Supervised Kernel\nPrincipal Component Analysis (SKPCA) has been shown as another successful\nalternative. In this paper, brief reviews of these popular techniques are\npresented first. We then conduct a comparative performance study based on three\nsimulated datasets, after which the performance of the techniques are evaluated\nthrough application to a pattern recognition problem in face image analysis.\nThe gender classification problem is considered on MORPH-II and FG-NET, two\npopular longitudinal face aging databases. Several feature extraction methods\nare used, including biologically-inspired features (BIF), local binary patterns\n(LBP), histogram of oriented gradients (HOG), and the Active Appearance Model\n(AAM). After applications of DR methods, a linear support vector machine (SVM)\nis deployed with gender classification accuracy rates exceeding 95% on\nMORPH-II, competitive with benchmark results. A parallel computational approach\nis also proposed, attaining faster processing speeds and similar recognition\nrates on MORPH-II. Our computational approach can be applied to practical\ngender classification systems and generalized to other face analysis tasks,\nsuch as race classification and age prediction.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 19:33:20 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Kempfert", "Katherine C.", ""], ["Wang", "Yishi", ""], ["Chen", "Cuixian", ""], ["Wong", "Samuel W. K.", ""]]}, {"id": "1910.02115", "submitter": "Dianbo Liu Dr", "authors": "Rulin Shao, Hui Liu, Dianbo Liu", "title": "Privacy Preserving Stochastic Channel-Based Federated Learning with\n  Neural Network Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural network has achieved unprecedented success in a wide\nvariety of domains such as classifying, predicting and recognizing objects.\nThis success depends on the availability of big data since the training process\nrequires massive and representative data sets. However, data collection is\noften prevented by privacy concerns and people want to take control over their\nsensitive information during both training and using processes. To address this\nproblem, we propose a privacy-preserving method for the distributed system,\nStochastic Channel-Based Federated Learning (SCBF), which enables the\nparticipants to train a high-performance model cooperatively without sharing\ntheir inputs. We design, implement and evaluate a channel-based update\nalgorithm for the central server in a distributed system, which selects the\nchannels with regard to the most active features in a training loop and uploads\nthem as learned information from local datasets. A pruning process is applied\nto the algorithm based on the validation set, which serves as a model\naccelerator. In the experiment, our model presents equal performances and\nhigher saturating speed than the Federated Averaging method which reveals all\nthe parameters of local models to the server when updating. We also demonstrate\nthat the converging rates could be increased by introducing a pruning process.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 19:35:09 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Shao", "Rulin", ""], ["Liu", "Hui", ""], ["Liu", "Dianbo", ""]]}, {"id": "1910.02119", "submitter": "Hao Yan", "authors": "Hao Yan, Kamran Paynabar, Jianjun Shi", "title": "AKM$^2$D : An Adaptive Framework for Online Sensing and Anomaly\n  Quantification", "comments": "Under review in IISE Transaction", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In point-based sensing systems such as coordinate measuring machines (CMM)\nand laser ultrasonics where complete sensing is impractical due to the high\nsensing time and cost, adaptive sensing through a systematic exploration is\nvital for online inspection and anomaly quantification. Most of the existing\nsequential sampling methodologies focus on reducing the overall fitting error\nfor the entire sampling space. However, in many anomaly quantification\napplications, the main goal is to estimate sparse anomalous regions in the\npixel-level accurately. In this paper, we develop a novel framework named\nAdaptive Kernelized Maximum-Minimum Distance AKM$^2$D to speed up the\ninspection and anomaly detection process through an intelligent sequential\nsampling scheme integrated with fast estimation and detection. The proposed\nmethod balances the sampling efforts between the space-filling sampling\n(exploration) and focused sampling near the anomalous region (exploitation).\nThe proposed methodology is validated by conducting simulations and a case\nstudy of anomaly detection in composite sheets using a guided wave test.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 19:45:58 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Yan", "Hao", ""], ["Paynabar", "Kamran", ""], ["Shi", "Jianjun", ""]]}, {"id": "1910.02120", "submitter": "Binhang Yuan", "authors": "Binhang Yuan and Cameron R. Wolfe and Chen Dun and Yuxin Tang and\n  Anastasios Kyrillidis and Christopher M. Jermaine", "title": "Distributed Learning of Deep Neural Networks using Independent Subnet\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning (ML) can bring more computational resources to\nbear than single-machine learning, reducing training time. Further,\ndistribution allows models to be partitioned over many machines, allowing very\nlarge models to be trained -- models that may be much larger than the available\nmemory of any individual machine. However, in practice, distributed ML remains\nchallenging, primarily due to high communication costs. We propose a new\napproach to distributed neural network learning, called independent subnet\ntraining (IST). In IST, a neural network is decomposed into a set of\nsubnetworks of the same depth as the original network, each of which is trained\nlocally, before the various subnets are exchanged and the process is repeated.\nIST training has many advantages over standard data parallel approaches.\nBecause the subsets are independent, communication frequency is reduced.\nBecause the original network is decomposed into independent parts,\ncommunication volume is reduced. Further, the decomposition makes IST naturally\nmodel parallel, and so IST scales to very large models that cannot fit on any\nsingle machine. We show experimentally that IST results in training time that\nare much lower than data parallel approaches to distributed learning, and that\nit scales to large models that cannot be learned using standard approaches.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 19:46:16 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 20:01:11 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 02:17:29 GMT"}, {"version": "v4", "created": "Mon, 8 Jun 2020 23:29:57 GMT"}, {"version": "v5", "created": "Thu, 5 Nov 2020 15:11:47 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Yuan", "Binhang", ""], ["Wolfe", "Cameron R.", ""], ["Dun", "Chen", ""], ["Tang", "Yuxin", ""], ["Kyrillidis", "Anastasios", ""], ["Jermaine", "Christopher M.", ""]]}, {"id": "1910.02125", "submitter": "Michael Lee", "authors": "John S. Hyatt and Michael S. Lee", "title": "Requirements for Developing Robust Neural Networks", "comments": "4 pages. Presented at AAAI FSS-19: Artificial Intelligence in\n  Government and Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Validation accuracy is a necessary, but not sufficient, measure of a neural\nnetwork classifier's quality. High validation accuracy during development does\nnot guarantee that a model is free of serious flaws, such as vulnerability to\nadversarial attacks or a tendency to misclassify (with high confidence) data it\nwas not trained on. The model may also be incomprehensible to a human or base\nits decisions on unreasonable criteria. These problems, which are not unique to\nclassifiers, have been the focus of a substantial amount of recent research.\nHowever, they are not prioritized during model development, which almost always\noptimizes on validation accuracy to the exclusion of everything else. The\nproduct of this approach is likely to fail in unexpected ways outside of the\ntraining environment. We believe that, in addition to validation accuracy, the\nmodel development process must give added weight to other performance metrics\nsuch as explainability, resistance to adversarial attacks, and overconfidence\non out-of-distribution data.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 20:00:12 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Hyatt", "John S.", ""], ["Lee", "Michael S.", ""]]}, {"id": "1910.02133", "submitter": "Biswadip Dey", "authors": "Akshay Iyer, Biswadip Dey, Arindam Dasgupta, Wei Chen, Amit\n  Chakraborty", "title": "A Conditional Generative Model for Predicting Material Microstructures\n  from Processing Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microstructures of a material form the bridge linking processing conditions -\nwhich can be controlled, to the material property - which is the primary\ninterest in engineering applications. Thus a critical task in material design\nis establishing the processing-structure relationship, which requires domain\nexpertise and techniques that can model the high-dimensional material\nmicrostructure. This work proposes a deep learning based approach that models\nthe processing-structure relationship as a conditional image synthesis problem.\nIn particular, we develop an auxiliary classifier Wasserstein GAN with gradient\npenalty (ACWGAN-GP) to synthesize microstructures under a given processing\ncondition. This approach is free of feature engineering, requires modest domain\nknowledge and is applicable to a wide range of material systems. We demonstrate\nthis approach using the ultra high carbon steel (UHCS) database, where each\nmicrostructure is annotated with a label describing the cooling method it was\nsubjected to. Our results show that ACWGAN-GP can synthesize high-quality\nmultiphase microstructures for a given cooling method.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 20:13:11 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Iyer", "Akshay", ""], ["Dey", "Biswadip", ""], ["Dasgupta", "Arindam", ""], ["Chen", "Wei", ""], ["Chakraborty", "Amit", ""]]}, {"id": "1910.02136", "submitter": "Sumit Mukherjee", "authors": "Anusua Trivedi, Sumit Mukherjee, Edmund Tse, Anne Ewing, Juan Lavista\n  Ferres", "title": "Risks of Using Non-verified Open Data: A case study on using Machine\n  Learning techniques for predicting Pregnancy Outcomes in India", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) has evolved considerably in the last few years.\nWhile applications of AI is now becoming more common in fields like retail and\nmarketing, application of AI in solving problems related to developing\ncountries is still an emerging topic. Specially, AI applications in\nresource-poor settings remains relatively nascent. There is a huge scope of AI\nbeing used in such settings. For example, researchers have started exploring AI\napplications to reduce poverty and deliver a broad range of critical public\nservices. However, despite many promising use cases, there are many dataset\nrelated challenges that one has to overcome in such projects. These challenges\noften take the form of missing data, incorrectly collected data and improperly\nlabeled variables, among other factors. As a result, we can often end up using\ndata that is not representative of the problem we are trying to solve. In this\ncase study, we explore the challenges of using such an open dataset from India,\nto predict an important health outcome. We highlight how the use of AI without\nproper understanding of reporting metrics can lead to erroneous conclusions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 20:27:20 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 20:21:56 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Trivedi", "Anusua", ""], ["Mukherjee", "Sumit", ""], ["Tse", "Edmund", ""], ["Ewing", "Anne", ""], ["Ferres", "Juan Lavista", ""]]}, {"id": "1910.02142", "submitter": "Hong Jiang", "authors": "Hong Jiang, Jong-Hoon Ahn and Xiaoyang Wang", "title": "Lipschitz Learning for Signal Recovery", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the recovery of signals from their observations, which are\nsamples of a transform of the signals rather than the signals themselves, by\nusing machine learning (ML). We will develop a theoretical framework to\ncharacterize the signals that can be robustly recovered from their observations\nby an ML algorithm, and establish a Lipschitz condition on signals and\nobservations that is both necessary and sufficient for the existence of a\nrobust recovery. We will compare the Lipschitz condition with the well-known\nrestricted isometry property of the sparse recovery of compressive sensing, and\nshow the former is more general and less restrictive. For linear observations,\nour work also suggests an ML method in which the output space is reduced to the\nlowest possible dimension.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 21:00:03 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Jiang", "Hong", ""], ["Ahn", "Jong-Hoon", ""], ["Wang", "Xiaoyang", ""]]}, {"id": "1910.02150", "submitter": "Stefan Klus", "authors": "Stefan Klus, Patrick Gel{\\ss}", "title": "Tensor-based algorithms for image classification", "comments": null, "journal-ref": "Algorithms, 12(11), 240, 2019", "doi": "10.3390/a12110240", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interest in machine learning with tensor networks has been growing\nrapidly in recent years. We show that tensor-based methods developed for\nlearning the governing equations of dynamical systems from data can, in the\nsame way, be used for supervised learning problems and propose two novel\napproaches for image classification. One is a kernel-based reformulation of the\npreviously introduced MANDy (multidimensional approximation of nonlinear\ndynamics), the other an alternating ridge regression in the tensor-train\nformat. We apply both methods to the MNIST and fashion MNIST data set and show\nthat the approaches are competitive with state-of-the-art neural network-based\nclassifiers.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 21:16:33 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 22:31:02 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Klus", "Stefan", ""], ["Gel\u00df", "Patrick", ""]]}, {"id": "1910.02155", "submitter": "Abdallah Chehade", "authors": "Abdallah Chehade, Zunya Shi", "title": "The Sparse Reverse of Principal Component Analysis for Fast Low-Rank\n  Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion constantly receives tremendous attention from many research\nfields. It is commonly applied for recommender systems such as movie ratings,\ncomputer vision such as image reconstruction or completion, multi-task learning\nsuch as collaboratively modeling time-series trends of multiple sensors, and\nmany other applications. Matrix completion techniques are usually\ncomputationally exhaustive and/or fail to capture the heterogeneity in the\ndata. For example, images usually contain a heterogeneous set of objects, and\nthus it is a challenging task to reconstruct images with high levels of missing\ndata. In this paper, we propose the sparse reverse of principal component\nanalysis for matrix completion. The proposed approach maintains smoothness\nacross the matrix, produces accurate estimates of the missing data, converges\niteratively, and it is computationally tractable with a controllable upper\nbound on the number of iterations until convergence. The accuracy of the\nproposed technique is validated on natural images, movie ratings, and\nmultisensor data. It is also compared with common benchmark methods used for\nmatrix completion.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 21:44:55 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Chehade", "Abdallah", ""], ["Shi", "Zunya", ""]]}, {"id": "1910.02175", "submitter": "Deepta Rajan", "authors": "Deepta Rajan, David Beymer, Shafiqul Abedin and Ehsan Dehghan", "title": "Pi-PE: A Pipeline for Pulmonary Embolism Detection using Sparsely\n  Annotated 3D CT Images", "comments": "2019 NeurIPS ML4H (Proceedings of Machine Learning Research)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pulmonary embolisms (PE) are known to be one of the leading causes for\ncardiac-related mortality. Due to inherent variabilities in how PE manifests\nand the cumbersome nature of manual diagnosis, there is growing interest in\nleveraging AI tools for detecting PE. In this paper, we build a two-stage\ndetection pipeline that is accurate, computationally efficient, robust to\nvariations in PE types and kernels used for CT reconstruction, and most\nimportantly, does not require dense annotations. Given the challenges in\nacquiring expert annotations in large-scale datasets, our approach produces\nstate-of-the-art results with very sparse emboli contours (at 10mm slice\nspacing), while using models with significantly lower number of parameters. We\nachieve AUC scores of 0.94 on the validation set and 0.85 on the test set of\nhighly severe PEs. Using a large, real-world dataset characterized by complex\nPE types and patients from multiple hospitals, we present an elaborate\nempirical study and provide guidelines for designing highly generalizable\npipelines.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 00:01:28 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 16:37:22 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2019 20:56:02 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Rajan", "Deepta", ""], ["Beymer", "David", ""], ["Abedin", "Shafiqul", ""], ["Dehghan", "Ehsan", ""]]}, {"id": "1910.02176", "submitter": "Pengyu Cheng", "authors": "Pengyu Cheng, Chang Liu, Chunyuan Li, Dinghan Shen, Ricardo Henao and\n  Lawrence Carin", "title": "Straight-Through Estimator as Projected Wasserstein Gradient Flow", "comments": "Accepted as NeurIPS 2018 Bayesian Deep Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Straight-Through (ST) estimator is a widely used technique for\nback-propagating gradients through discrete random variables. However, this\neffective method lacks theoretical justification. In this paper, we show that\nST can be interpreted as the simulation of the projected Wasserstein gradient\nflow (pWGF). Based on this understanding, a theoretical foundation is\nestablished to justify the convergence properties of ST. Further, another pWGF\nestimator variant is proposed, which exhibits superior performance on\ndistributions with infinite support,e.g., Poisson distributions. Empirically,\nwe show that ST and our proposed estimator, while applied to different types of\ndiscrete structures (including both Bernoulli and Poisson latent variables),\nexhibit comparable or even better performances relative to other\nstate-of-the-art methods. Our results uncover the origin of the widespread\nadoption of the ST estimator and represent a helpful step towards exploring\nalternative gradient estimators for discrete variables.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 00:06:34 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Cheng", "Pengyu", ""], ["Liu", "Chang", ""], ["Li", "Chunyuan", ""], ["Shen", "Dinghan", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1910.02182", "submitter": "Pasha Khosravi", "authors": "Pasha Khosravi, YooJung Choi, Yitao Liang, Antonio Vergari, Guy Van\n  den Broeck", "title": "On Tractable Computation of Expected Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing expected predictions of discriminative models is a fundamental task\nin machine learning that appears in many interesting applications such as\nfairness, handling missing values, and data analysis. Unfortunately, computing\nexpectations of a discriminative model with respect to a probability\ndistribution defined by an arbitrary generative model has been proven to be\nhard in general. In fact, the task is intractable even for simple models such\nas logistic regression and a naive Bayes distribution. In this paper, we\nidentify a pair of generative and discriminative models that enables tractable\ncomputation of expectations, as well as moments of any order, of the latter\nwith respect to the former in case of regression. Specifically, we consider\nexpressive probabilistic circuits with certain structural constraints that\nsupport tractable probabilistic inference. Moreover, we exploit the tractable\ncomputation of high-order moments to derive an algorithm to approximate the\nexpectations for classification scenarios in which exact computations are\nintractable. Our framework to compute expected predictions allows for handling\nof missing data during prediction time in a principled and accurate way and\nenables reasoning about the behavior of discriminative models. We empirically\nshow our algorithm to consistently outperform standard imputation techniques on\na variety of datasets. Finally, we illustrate how our framework can be used for\nexploratory data analysis.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 00:20:41 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 21:47:20 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Khosravi", "Pasha", ""], ["Choi", "YooJung", ""], ["Liang", "Yitao", ""], ["Vergari", "Antonio", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1910.02185", "submitter": "KyungHyun Sung", "authors": "Ruiming Cao, Xinran Zhong, Fabien Scalzo, Steven Raman, Kyung hyun\n  Sung", "title": "Prostate cancer inference via weakly-supervised learning using a large\n  collection of negative MRI", "comments": "6 pages, 5 figures, 2019 International Conference on Computer Vision\n  - Visual Recognition for Medical Images Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in medical imaging techniques have led to significant\nimprovements in the management of prostate cancer (PCa). In particular,\nmulti-parametric MRI (mp-MRI) continues to gain clinical acceptance as the\npreferred imaging technique for non-invasive detection and grading of PCa.\nHowever, the machine learning-based diagnosis systems for PCa are often\nconstrained by the limited access to accurate lesion ground truth annotations\nfor training. The performance of the machine learning system is highly\ndependable on both quality and quantity of lesion annotations associated with\nhistopathologic findings, resulting in limited scalability and clinical\nvalidation. Here, we propose the baseline MRI model to alternatively learn the\nappearance of mp-MRI using radiology-confirmed negative MRI cases via weakly\nsupervised learning. Since PCa lesions are case-specific and highly\nheterogeneous, it is assumed to be challenging to synthesize PCa lesions using\nthe baseline MRI model, while it would be relatively easier to synthesize the\nnormal appearance in mp-MRI. We then utilize the baseline MRI model to infer\nthe pixel-wise suspiciousness of PCa by comparing the original and synthesized\nMRI with two distance functions. We trained and validated the baseline MRI\nmodel using 1,145 negative prostate mp-MRI scans. For evaluation, we used\nseparated 232 mp-MRI scans, consisting of both positive and negative MRI cases.\nThe 116 positive MRI scans were annotated by radiologists, confirmed with\npost-surgical whole-gland specimens. The suspiciousness map was evaluated by\nreceiver operating characteristic (ROC) analysis for PCa lesions versus non-PCa\nregions classification and free-response receiver operating characteristic\n(FROC) analysis for PCa localization. Our proposed method achieved 0.84 area\nunder the ROC curve and 77.0% sensitivity at one false positive per patient in\nFROC analysis.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 00:40:09 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Cao", "Ruiming", ""], ["Zhong", "Xinran", ""], ["Scalzo", "Fabien", ""], ["Raman", "Steven", ""], ["Sung", "Kyung hyun", ""]]}, {"id": "1910.02187", "submitter": "Pengyu Cheng", "authors": "Pengyu Cheng, Yitong Li, Xinyuan Zhang, Liqun Cheng, David Carlson,\n  Lawrence Carin", "title": "Dynamic Embedding on Textual Networks via a Gaussian Process", "comments": "Accepted for presentation at the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual network embedding aims to learn low-dimensional representations of\ntext-annotated nodes in a graph. Prior work in this area has typically focused\non fixed graph structures; however, real-world networks are often dynamic. We\naddress this challenge with a novel end-to-end node-embedding model, called\nDynamic Embedding for Textual Networks with a Gaussian Process (DetGP). After\ntraining, DetGP can be applied efficiently to dynamic graphs without\nre-training or backpropagation. The learned representation of each node is a\ncombination of textual and structural embeddings. Because the structure is\nallowed to be dynamic, our method uses the Gaussian process to take advantage\nof its non-parametric properties. To use both local and global graph\nstructures, diffusion is used to model multiple hops between neighbors. The\nrelative importance of global versus local structure for the embeddings is\nlearned automatically. With the non-parametric nature of the Gaussian process,\nupdating the embeddings for a changed graph structure requires only a forward\npass through the learned model. Considering link prediction and node\nclassification, experiments demonstrate the empirical effectiveness of our\nmethod compared to baseline approaches. We further show that DetGP can be\nstraightforwardly and efficiently applied to dynamic textual networks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 01:16:33 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 20:44:42 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 20:52:01 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Cheng", "Pengyu", ""], ["Li", "Yitong", ""], ["Zhang", "Xinyuan", ""], ["Cheng", "Liqun", ""], ["Carlson", "David", ""], ["Carin", "Lawrence", ""]]}, {"id": "1910.02206", "submitter": "Xingjian Zhen", "authors": "Xingjian Zhen, Rudrasis Chakraborty, Nicholas Vogt, Barbara B.\n  Bendlin, Vikas Singh", "title": "Dilated Convolutional Neural Networks for Sequential Manifold-valued\n  Data", "comments": null, "journal-ref": "ICCV 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efforts are underway to study ways via which the power of deep neural\nnetworks can be extended to non-standard data types such as structured data\n(e.g., graphs) or manifold-valued data (e.g., unit vectors or special\nmatrices). Often, sizable empirical improvements are possible when the geometry\nof such data spaces are incorporated into the design of the model,\narchitecture, and the algorithms. Motivated by neuroimaging applications, we\nstudy formulations where the data are {\\em sequential manifold-valued\nmeasurements}. This case is common in brain imaging, where the samples\ncorrespond to symmetric positive definite matrices or orientation distribution\nfunctions. Instead of a recurrent model which poses computational/technical\nissues, and inspired by recent results showing the viability of dilated\nconvolutional models for sequence prediction, we develop a dilated\nconvolutional neural network architecture for this task. On the technical side,\nwe show how the modules needed in our network can be derived while explicitly\ntaking the Riemannian manifold structure into account. We show how the\noperations needed can leverage known results for calculating the weighted\nFr\\'{e}chet Mean (wFM). Finally, we present scientific results for group\ndifference analysis in Alzheimer's disease (AD) where the groups are derived\nusing AD pathology load: here the model finds several brain fiber bundles that\nare related to AD even when the subjects are all still cognitively healthy.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 04:09:37 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhen", "Xingjian", ""], ["Chakraborty", "Rudrasis", ""], ["Vogt", "Nicholas", ""], ["Bendlin", "Barbara B.", ""], ["Singh", "Vikas", ""]]}, {"id": "1910.02208", "submitter": "Yanqiu Wu", "authors": "Che Wang, Yanqiu Wu, Quan Vuong, Keith Ross", "title": "Striving for Simplicity and Performance in Off-Policy DRL: Output\n  Normalization and Non-Uniform Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to develop off-policy DRL algorithms that not only exceed\nstate-of-the-art performance but are also simple and minimalistic. For standard\ncontinuous control benchmarks, Soft Actor-Critic (SAC), which employs entropy\nmaximization, currently provides state-of-the-art performance. We first\ndemonstrate that the entropy term in SAC addresses action saturation due to the\nbounded nature of the action spaces, with this insight, we propose a\nstreamlined algorithm with a simple normalization scheme or with inverted\ngradients. We show that both approaches can match SAC's sample efficiency\nperformance without the need of entropy maximization, we then propose a simple\nnon-uniform sampling method for selecting transitions from the replay buffer\nduring training. Extensive experimental results demonstrate that our proposed\nsampling scheme leads to state of the art sample efficiency on challenging\ncontinuous control tasks. We combine all of our findings into one simple\nalgorithm, which we call Streamlined Off Policy with Emphasizing Recent\nExperience, for which we provide robust public-domain code.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 04:22:35 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 14:02:08 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 15:22:40 GMT"}, {"version": "v4", "created": "Sat, 5 Dec 2020 09:02:08 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wang", "Che", ""], ["Wu", "Yanqiu", ""], ["Vuong", "Quan", ""], ["Ross", "Keith", ""]]}, {"id": "1910.02211", "submitter": "Vikas Raunak", "authors": "Vikas Raunak, Vaibhav Kumar, Vivek Gupta, Florian Metze", "title": "On Dimensional Linguistic Properties of the Word Embedding Space", "comments": "Published at ACL RepL4NLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have become a staple of several natural language processing\ntasks, yet much remains to be understood about their properties. In this work,\nwe analyze word embeddings in terms of their principal components and arrive at\na number of novel and counterintuitive observations. In particular, we\ncharacterize the utility of variance explained by the principal components as a\nproxy for downstream performance. Furthermore, through syntactic probing of the\nprincipal embedding space, we show that the syntactic information captured by a\nprincipal component does not correlate with the amount of variance it explains.\nConsequently, we investigate the limitations of variance based embedding\npost-processing and demonstrate that such post-processing is counter-productive\nin sentence classification and machine translation tasks. Finally, we offer a\nfew precautionary guidelines on applying variance based embedding\npost-processing and explain why non-isotropic geometry might be integral to\nword embedding performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 05:03:30 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 20:56:04 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Raunak", "Vikas", ""], ["Kumar", "Vaibhav", ""], ["Gupta", "Vivek", ""], ["Metze", "Florian", ""]]}, {"id": "1910.02213", "submitter": "Luke Snyder", "authors": "Luke S. Snyder, Morteza Karimzadeh, Ray Chen, and David S. Ebert", "title": "City-level Geolocation of Tweets for Real-time Visual Analytics", "comments": "4 pages, 2 tables, 1 figure, SIGSPATIAL GeoAI Workshop", "journal-ref": null, "doi": "10.1145/3356471.3365243", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time tweets can provide useful information on evolving events and\nsituations. Geotagged tweets are especially useful, as they indicate the\nlocation of origin and provide geographic context. However, only a small\nportion of tweets are geotagged, limiting their use for situational awareness.\nIn this paper, we adapt, improve, and evaluate a state-of-the-art deep learning\nmodel for city-level geolocation prediction, and integrate it with a visual\nanalytics system tailored for real-time situational awareness. We provide\ncomputational evaluations to demonstrate the superiority and utility of our\ngeolocation prediction model within an interactive system.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 05:34:40 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Snyder", "Luke S.", ""], ["Karimzadeh", "Morteza", ""], ["Chen", "Ray", ""], ["Ebert", "David S.", ""]]}, {"id": "1910.02216", "submitter": "Rajas Agashe", "authors": "Rajas Agashe, Srinivasan Iyer and Luke Zettlemoyer", "title": "JuICe: A Large Scale Distantly Supervised Dataset for Open Domain\n  Context-based Code Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive programming with interleaved code snippet cells and natural\nlanguage markdown is recently gaining popularity in the form of Jupyter\nnotebooks, which accelerate prototyping and collaboration. To study code\ngeneration conditioned on a long context history, we present JuICe, a corpus of\n1.5 million examples with a curated test set of 3.7K instances based on online\nprogramming assignments. Compared with existing contextual code generation\ndatasets, JuICe provides refined human-curated data, open-domain code, and an\norder of magnitude more training data. Using JuICe, we train models for two\ntasks: (1) generation of the API call sequence in a code cell, and (2) full\ncode cell generation, both conditioned on the NL-Code history up to a\nparticular code cell. Experiments using current baseline code generation models\nshow that both context and distant supervision aid in generation, and that the\ndataset is challenging for current systems.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 05:51:45 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 02:56:46 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Agashe", "Rajas", ""], ["Iyer", "Srinivasan", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1910.02217", "submitter": "Hari Prasanna Das", "authors": "Hari Prasanna Das, Ioannis C. Konstantakopoulos, Aummul Baneen\n  Manasawala, Tanya Veeravalli, Huihan Liu and Costas J. Spanos", "title": "A Novel Graphical Lasso based approach towards Segmentation Analysis in\n  Energy Game-Theoretic Frameworks", "comments": "Proceedings of the Special Session on Machine Learning in Energy\n  Application, International Conference on Machine Learning and Applications\n  (ICMLA) 2019. arXiv admin note: text overlap with arXiv:1810.10533", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy game-theoretic frameworks have emerged to be a successful strategy to\nencourage energy efficient behavior in large scale by leveraging\nhuman-in-the-loop strategy. A number of such frameworks have been introduced\nover the years which formulate the energy saving process as a competitive game\nwith appropriate incentives for energy efficient players. However, prior works\ninvolve an incentive design mechanism which is dependent on knowledge of\nutility functions for all the players in the game, which is hard to compute\nespecially when the number of players is high, common in energy game-theoretic\nframeworks. Our research proposes that the utilities of players in such a\nframework can be grouped together to a relatively small number of clusters, and\nthe clusters can then be targeted with tailored incentives. The key to above\nsegmentation analysis is to learn the features leading to human decision making\ntowards energy usage in competitive environments. We propose a novel graphical\nlasso based approach to perform such segmentation, by studying the feature\ncorrelations in a real-world energy social game dataset. To further improve the\nexplainability of the model, we perform causality study using grangers\ncausality. Proposed segmentation analysis results in characteristic clusters\ndemonstrating different energy usage behaviors. We also present avenues to\nimplement intelligent incentive design using proposed segmentation method.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 06:04:40 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Das", "Hari Prasanna", ""], ["Konstantakopoulos", "Ioannis C.", ""], ["Manasawala", "Aummul Baneen", ""], ["Veeravalli", "Tanya", ""], ["Liu", "Huihan", ""], ["Spanos", "Costas J.", ""]]}, {"id": "1910.02219", "submitter": "Abiodun Ayodeji", "authors": "Abiodun Ayodeji, Yong-kuo Liu", "title": "Recurrent neural network based decision support system", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision Support Systems (DSS) in complex installations play a crucial role\nin assisting operators in decision making during abnormal transients and\nprocess disturbances, by actively displaying the status of the system and\nrecording events, time of occurrence and suggesting relevant actions. The\ncomplexity and dynamics of complex systems require a careful selection of\nsuitable neural network architecture, so as to improve diagnostic accuracy. In\nthis work, we present a technique to develop a fault diagnostic decision\nsupport using recurrent neural network and Principal Component Analysis (PCA).\nWe utilized the PCA method for noise filtering in the pre-diagnostic stage, and\nevaluate the predictive capability of radial basis recurrent network on a\nrepresentative data derived from the simulation of a pressurized nuclear\nreactor. The process was validated using data from different fault scenarios,\nand the fault signatures were used as the input. The predictive outputs\nrequired are the location and sizes of the faults. The result shows that the\nradial basis network gives accurate predictions. Selected hyperparameters and\ndiagnostic results are also presented in this paper.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 06:30:57 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ayodeji", "Abiodun", ""], ["Liu", "Yong-kuo", ""]]}, {"id": "1910.02224", "submitter": "Limeng Qiao", "authors": "Limeng Qiao, Yemin Shi, Jia Li, Yaowei Wang, Tiejun Huang, Yonghong\n  Tian", "title": "Transductive Episodic-Wise Adaptive Metric for Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning, which aims at extracting new concepts rapidly from\nextremely few examples of novel classes, has been featured into the\nmeta-learning paradigm recently. Yet, the key challenge of how to learn a\ngeneralizable classifier with the capability of adapting to specific tasks with\nseverely limited data still remains in this domain. To this end, we propose a\nTransductive Episodic-wise Adaptive Metric (TEAM) framework for few-shot\nlearning, by integrating the meta-learning paradigm with both deep metric\nlearning and transductive inference. With exploring the pairwise constraints\nand regularization prior within each task, we explicitly formulate the\nadaptation procedure into a standard semi-definite programming problem. By\nsolving the problem with its closed-form solution on the fly with the setup of\ntransduction, our approach efficiently tailors an episodic-wise metric for each\ntask to adapt all features from a shared task-agnostic embedding space into a\nmore discriminative task-specific metric space. Moreover, we further leverage\nan attention-based bi-directional similarity strategy for extracting the more\nrobust relationship between queries and prototypes. Extensive experiments on\nthree benchmark datasets show that our framework is superior to other existing\napproaches and achieves the state-of-the-art performance in the few-shot\nliterature.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 07:07:53 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Qiao", "Limeng", ""], ["Shi", "Yemin", ""], ["Li", "Jia", ""], ["Wang", "Yaowei", ""], ["Huang", "Tiejun", ""], ["Tian", "Yonghong", ""]]}, {"id": "1910.02241", "submitter": "Xinrui Zhuang", "authors": "Xinrui Zhuang, Yuexiang Li, Yifan Hu, Kai Ma, Yujiu Yang, Yefeng Zheng", "title": "Self-supervised Feature Learning for 3D Medical Images by Playing a\n  Rubik's Cube", "comments": "MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Witnessed the development of deep learning, increasing number of studies try\nto build computer aided diagnosis systems for 3D volumetric medical data.\nHowever, as the annotations of 3D medical data are difficult to acquire, the\nnumber of annotated 3D medical images is often not enough to well train the\ndeep learning networks. The self-supervised learning deeply exploiting the\ninformation of raw data is one of the potential solutions to loose the\nrequirement of training data. In this paper, we propose a self-supervised\nlearning framework for the volumetric medical images. A novel proxy task, i.e.,\nRubik's cube recovery, is formulated to pre-train 3D neural networks. The proxy\ntask involves two operations, i.e., cube rearrangement and cube rotation, which\nenforce networks to learn translational and rotational invariant features from\nraw 3D data. Compared to the train-from-scratch strategy, fine-tuning from the\npre-trained network leads to a better accuracy on various tasks, e.g., brain\nhemorrhage classification and brain tumor segmentation. We show that our\nself-supervised learning approach can substantially boost the accuracies of 3D\ndeep learning networks on the volumetric medical datasets without using extra\ndata. To our best knowledge, this is the first work focusing on the\nself-supervised learning of 3D neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 10:02:13 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhuang", "Xinrui", ""], ["Li", "Yuexiang", ""], ["Hu", "Yifan", ""], ["Ma", "Kai", ""], ["Yang", "Yujiu", ""], ["Zheng", "Yefeng", ""]]}, {"id": "1910.02244", "submitter": "Laurent Meunier", "authors": "Laurent Meunier, Jamal Atif, Olivier Teytaud", "title": "Yet another but more efficient black-box adversarial attack: tiling and\n  evolution strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new black-box attack achieving state of the art performances.\nOur approach is based on a new objective function, borrowing ideas from\n$\\ell_\\infty$-white box attacks, and particularly designed to fit\nderivative-free optimization requirements. It only requires to have access to\nthe logits of the classifier without any other information which is a more\nrealistic scenario. Not only we introduce a new objective function, we extend\nprevious works on black box adversarial attacks to a larger spectrum of\nevolution strategies and other derivative-free optimization methods. We also\nhighlight a new intriguing property that deep neural networks are not robust to\nsingle shot tiled attacks. Our models achieve, with a budget limited to\n$10,000$ queries, results up to $99.2\\%$ of success rate against InceptionV3\nclassifier with $630$ queries to the network on average in the untargeted\nattacks setting, which is an improvement by $90$ queries of the current state\nof the art. In the targeted setting, we are able to reach, with a limited\nbudget of $100,000$, $100\\%$ of success rate with a budget of $6,662$ queries\non average, i.e. we need $800$ queries less than the current state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 10:36:47 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 10:48:51 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Meunier", "Laurent", ""], ["Atif", "Jamal", ""], ["Teytaud", "Olivier", ""]]}, {"id": "1910.02249", "submitter": "Bingzhe Wu", "authors": "Bingzhe Wu, Chaochao Chen, Shiwan Zhao, Cen Chen, Yuan Yao, Guangyu\n  Sun, Li Wang, Xiaolu Zhang, Jun Zhou", "title": "Characterizing Membership Privacy in Stochastic Gradient Langevin\n  Dynamics", "comments": "Under review of AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian deep learning is recently regarded as an intrinsic way to\ncharacterize the weight uncertainty of deep neural networks~(DNNs). Stochastic\nGradient Langevin Dynamics~(SGLD) is an effective method to enable Bayesian\ndeep learning on large-scale datasets. Previous theoretical studies have shown\nvarious appealing properties of SGLD, ranging from the convergence properties\nto the generalization bounds. In this paper, we study the properties of SGLD\nfrom a novel perspective of membership privacy protection (i.e., preventing the\nmembership attack). The membership attack, which aims to determine whether a\nspecific sample is used for training a given DNN model, has emerged as a common\nthreat against deep learning algorithms. To this end, we build a theoretical\nframework to analyze the information leakage (w.r.t. the training dataset) of a\nmodel trained using SGLD. Based on this framework, we demonstrate that SGLD can\nprevent the information leakage of the training dataset to a certain extent.\nMoreover, our theoretical analysis can be naturally extended to other types of\nStochastic Gradient Markov Chain Monte Carlo (SG-MCMC) methods. Empirical\nresults on different datasets and models verify our theoretical findings and\nsuggest that the SGLD algorithm can not only reduce the information leakage but\nalso improve the generalization ability of the DNN models in real-world\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 11:26:54 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Wu", "Bingzhe", ""], ["Chen", "Chaochao", ""], ["Zhao", "Shiwan", ""], ["Chen", "Cen", ""], ["Yao", "Yuan", ""], ["Sun", "Guangyu", ""], ["Wang", "Li", ""], ["Zhang", "Xiaolu", ""], ["Zhou", "Jun", ""]]}, {"id": "1910.02270", "submitter": "Sam Ade Jacobs", "authors": "Sam Ade Jacobs, Brian Van Essen, David Hysom, Jae-Seung Yeom, Tim\n  Moon, Rushil Anirudh, Jayaraman J. Thiagaranjan, Shusen Liu, Peer-Timo\n  Bremer, Jim Gaffney, Tom Benson, Peter Robinson, Luc Peterson, Brian Spears", "title": "Parallelizing Training of Deep Generative Models on Massive Scientific\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG hep-ex physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks on large scientific data is a challenging task\nthat requires enormous compute power, especially if no pre-trained models exist\nto initialize the process. We present a novel tournament method to train\ntraditional as well as generative adversarial networks built on LBANN, a\nscalable deep learning framework optimized for HPC systems. LBANN combines\nmultiple levels of parallelism and exploits some of the worlds largest\nsupercomputers. We demonstrate our framework by creating a complex predictive\nmodel based on multi-variate data from high-energy-density physics containing\nhundreds of millions of images and hundreds of millions of scalar values\nderived from tens of millions of simulations of inertial confinement fusion.\nOur approach combines an HPC workflow and extends LBANN with optimized data\ningestion and the new tournament-style training algorithm to produce a scalable\nneural network architecture using a CORAL-class supercomputer. Experimental\nresults show that 64 trainers (1024 GPUs) achieve a speedup of 70.2 over a\nsingle trainer (16 GPUs) baseline, and an effective 109% parallel efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 13:39:07 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Jacobs", "Sam Ade", ""], ["Van Essen", "Brian", ""], ["Hysom", "David", ""], ["Yeom", "Jae-Seung", ""], ["Moon", "Tim", ""], ["Anirudh", "Rushil", ""], ["Thiagaranjan", "Jayaraman J.", ""], ["Liu", "Shusen", ""], ["Bremer", "Peer-Timo", ""], ["Gaffney", "Jim", ""], ["Benson", "Tom", ""], ["Robinson", "Peter", ""], ["Peterson", "Luc", ""], ["Spears", "Brian", ""]]}, {"id": "1910.02285", "submitter": "Xukun Li", "authors": "Wei Wu, Xukun Li, Peng Du, Guanjing Lang, Min Xu, Kaijin Xu, Lanjuan\n  Li", "title": "A Deep Learning System That Generates Quantitative CT Reports for\n  Diagnosing Pulmonary Tuberculosis", "comments": null, "journal-ref": null, "doi": "10.1007/s10489-020-02051-1", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a deep learning model-based system to automatically generate a\nquantitative Computed Tomography (CT) diagnostic report for Pulmonary\nTuberculosis (PTB) cases.501 CT imaging datasets from 223 patients with active\nPTB were collected, and another 501 cases from a healthy population served as\nnegative samples.2884 lesions of PTB were carefully labeled and classified\nmanually by professional radiologists.Three state-of-the-art 3D convolution\nneural network (CNN) models were trained and evaluated in the inspection of PTB\nCT images. Transfer learning method was also utilized during this process. The\nbest model was selected to annotate the spatial location of lesions and\nclassify them into miliary, infiltrative, caseous, tuberculoma and cavitary\ntypes simultaneously.Then the Noisy-Or Bayesian function was used to generate\nan overall infection probability.Finally, a quantitative diagnostic report was\nexported.The results showed that the recall and precision rates, from the\nperspective of a single lesion region of PTB, were 85.9% and 89.2%\nrespectively. The overall recall and precision rates,from the perspective of\none PTB case, were 98.7% and 93.7%, respectively. Moreover, the precision rate\nof the PTB lesion type classification was 90.9%.The new method might serve as\nan effective reference for decision making by clinical doctors.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 15:55:25 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Wu", "Wei", ""], ["Li", "Xukun", ""], ["Du", "Peng", ""], ["Lang", "Guanjing", ""], ["Xu", "Min", ""], ["Xu", "Kaijin", ""], ["Li", "Lanjuan", ""]]}, {"id": "1910.02290", "submitter": "Anna Kruspe", "authors": "Anna Kruspe", "title": "Few-shot tweet detection in emerging disaster events", "comments": "Accepted to AI+HADR workshop @ NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media sources can provide crucial information in crisis situations,\nbut discovering relevant messages is not trivial. Methods have so far focused\non universal detection models for all kinds of crises or for certain crisis\ntypes (e.g. floods). Event-specific models could implement a more focused\nsearch area, but collecting data and training new models for a crisis that is\nalready in progress is costly and may take too much time for a prompt response.\nAs a compromise, manually collecting a small amount of example messages is\nfeasible. Few-shot models can generalize to unseen classes with such a small\nhandful of examples, and do not need be trained anew for each event. We compare\nhow few-shot approaches (matching networks and prototypical networks) perform\nfor this task. Since this is essentially a one-class problem, we also\ndemonstrate how a modified one-class version of prototypical models can be used\nfor this application.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 16:25:56 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Kruspe", "Anna", ""]]}, {"id": "1910.02291", "submitter": "Sahand Rezaei-Shoshtari Mr.", "authors": "Sahand Rezaei-Shoshtari, David Meger, Inna Sharf", "title": "Cascaded Gaussian Processes for Data-efficient Robot Dynamics Learning", "comments": "IROS2019. Copyright 20xx IEEE. Personal use of this material is\n  permitted. Permission from IEEE must be obtained for all other uses, in any\n  current or future media, including reprinting/republishing this material for\n  advertising or promotional purposes, creating new collective works, for\n  resale or redistribution to servers or lists, or reuse of any copyrighted\n  component of this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recursive Newton-Euler formulation, we propose a novel\ncascaded Gaussian process learning framework for the inverse dynamics of robot\nmanipulators. This approach leads to a significant dimensionality reduction\nwhich in turn results in better learning and data efficiency. We explore two\nformulations for the cascading: the inward and outward, both along the\nmanipulator chain topology. The learned modeling is tested in conjunction with\nthe classical inverse dynamics model (semi-parametric) and on its own\n(non-parametric) in the context of feed-forward control of the arm.\nExperimental results are obtained with Jaco 2 six-DOF and SARCOS seven-DOF\nmanipulators for randomly defined sinusoidal motions of the joints in order to\nevaluate the performance of cascading against the standard GP learning. In\naddition, experiments are conducted using Jaco 2 on a task emulating a pouring\nmaneuver. Results indicate a consistent improvement in learning speed with the\ninward cascaded GP model and an overall improvement in data efficiency and\ngeneralization.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 16:28:09 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Rezaei-Shoshtari", "Sahand", ""], ["Meger", "David", ""], ["Sharf", "Inna", ""]]}, {"id": "1910.02301", "submitter": "Isuru Hewapathirana", "authors": "Isuru Udayangani Hewapathirana, Dominic Lee, Elena Moltchanova and\n  Jeanette McLeod", "title": "Change Detection in Noisy Dynamic Networks: A Spectral Embedding\n  Approach", "comments": "44 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change detection in dynamic networks is an important problem in many areas,\nsuch as fraud detection, cyber intrusion detection and health care monitoring.\nIt is a challenging problem because it involves a time sequence of graphs, each\nof which is usually very large and sparse with heterogeneous vertex degrees,\nresulting in a complex, high dimensional mathematical object. Spectral\nembedding methods provide an effective way to transform a graph to a lower\ndimensional latent Euclidean space that preserves the underlying structure of\nthe network. Although change detection methods that use spectral embedding are\navailable, they do not address sparsity and degree heterogeneity that usually\noccur in noisy real-world graphs and a majority of these methods focus on\nchanges in the behaviour of the overall network.\n  In this paper, we adapt previously developed techniques in spectral graph\ntheory and propose a novel concept of applying Procrustes techniques to\nembedded points for vertices in a graph to detect changes in entity behaviour.\nOur spectral embedding approach not only addresses sparsity and degree\nheterogeneity issues, but also obtains an estimate of the appropriate embedding\ndimension. We call this method CDP (change detection using Procrustes\nanalysis). We demonstrate the performance of CDP through extensive simulation\nexperiments and a real-world application. CDP successfully detects various\ntypes of vertex-based changes including (i) changes in vertex degree, (ii)\nchanges in community membership of vertices, and (iii) unusual increase or\ndecrease in edge weight between vertices. The change detection performance of\nCDP is compared with two other baseline methods that employ alternative\nspectral embedding approaches. In both cases, CDP generally shows superior\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 18:02:18 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Hewapathirana", "Isuru Udayangani", ""], ["Lee", "Dominic", ""], ["Moltchanova", "Elena", ""], ["McLeod", "Jeanette", ""]]}, {"id": "1910.02304", "submitter": "Nazreen P M", "authors": "Nazreen P.M., Shantanu Chakrabartty and Chetan Singh Thakur", "title": "Multiplierless and Sparse Machine Learning based on Margin Propagation\n  Networks", "comments": "New results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new generation of machine learning processors have evolved from\nmulti-core and parallel architectures that were designed to efficiently\nimplement matrix-vector-multiplications (MVMs). This is because at the\nfundamental level, neural network and machine learning operations extensively\nuse MVM operations and hardware compilers exploit the inherent parallelism in\nMVM operations to achieve hardware acceleration on GPUs and FPGAs. However,\nmany IoT and edge computing platforms require embedded ML devices close to the\nnetwork in order to compensate for communication cost and latency. Hence a\nnatural question to ask is whether MVM operations are even necessary to\nimplement ML algorithms and whether simpler hardware primitives can be used to\nimplement an ultra-energy-efficient ML processor/architecture. In this paper we\npropose an alternate hardware-software codesign of ML and neural network\narchitectures where instead of using MVM operations and non-linear activation\nfunctions, the architecture only uses simple addition and thresholding\noperations to implement inference and learning. At the core of the proposed\napproach is margin-propagation (MP) based computation that maps multiplications\ninto additions and additions into a dynamic rectifying-linear-unit (ReLU)\noperations. This mapping results in significant improvement in computational\nand hence energy cost. In this paper, we show how the MP network formulation\ncan be applied for designing linear classifiers, shallow multi-layer\nperceptrons and support vector networks suitable fot IoT platforms and tiny ML\napplications. We show that these MP based classifiers give comparable results\nto that of their traditional counterparts for benchmark UCI datasets, with the\nadded advantage of reduction in computational complexity enabling an\nimprovement in energy efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 18:09:57 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 12:43:48 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["M.", "Nazreen P.", ""], ["Chakrabartty", "Shantanu", ""], ["Thakur", "Chetan Singh", ""]]}, {"id": "1910.02312", "submitter": "Vivek Sharma", "authors": "Vivek Sharma, Praneeth Vepakomma, Tristan Swedish, Ken Chang,\n  Jayashree Kalpathy-Cramer, Ramesh Raskar", "title": "ExpertMatcher: Automating ML Model Selection for Users in Resource\n  Constrained Countries", "comments": "In NeurIPS Workshop on Machine learning for the Developing World\n  (ML4D)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we introduce ExpertMatcher, a method for automating deep\nlearning model selection using autoencoders. Specifically, we are interested in\nperforming inference on data sources that are distributed across many clients\nusing pretrained expert ML networks on a centralized server. The ExpertMatcher\nassigns the most relevant model(s) in the central server given the client's\ndata representation. This allows resource-constrained clients in developing\ncountries to utilize the most relevant ML models for their given task without\nhaving to evaluate the performance of each ML model. The method is generic and\ncan be beneficial in any setup where there are local clients and numerous\ncentralized expert ML models.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 18:58:59 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Sharma", "Vivek", ""], ["Vepakomma", "Praneeth", ""], ["Swedish", "Tristan", ""], ["Chang", "Ken", ""], ["Kalpathy-Cramer", "Jayashree", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1910.02319", "submitter": "Artur Jordao", "authors": "Artur Jordao, Maiko Lie, Victor Hugo Cunha de Melo and William Robson\n  Schwartz", "title": "Covariance-free Partial Least Squares: An Incremental Dimensionality\n  Reduction Method", "comments": "Accepted for publication at Winter Conference on Applications of\n  Computer Vision (WACV) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction plays an important role in computer vision problems\nsince it reduces computational cost and is often capable of yielding more\ndiscriminative data representation. In this context, Partial Least Squares\n(PLS) has presented notable results in tasks such as image classification and\nneural network optimization. However, PLS is infeasible on large datasets, such\nas ImageNet, because it requires all the data to be in memory in advance, which\nis often impractical due to hardware limitations. Additionally, this\nrequirement prevents us from employing PLS on streaming applications where the\ndata are being continuously generated. Motivated by this, we propose a novel\nincremental PLS, named Covariance-free Incremental Partial Least Squares\n(CIPLS), which learns a low-dimensional representation of the data using a\nsingle sample at a time. In contrast to other state-of-the-art approaches,\ninstead of adopting a partially-discriminative or SGD-based model, we extend\nNonlinear Iterative Partial Least Squares (NIPALS) -- the standard algorithm\nused to compute PLS -- for incremental processing. Among the advantages of this\napproach are the preservation of discriminative information across all\ncomponents, the possibility of employing its score matrices for feature\nselection, and its computational efficiency. We validate CIPLS on face\nverification and image classification tasks, where it outperforms several other\nincremental dimensionality reduction techniques. In the context of feature\nselection, CIPLS achieves comparable results when compared to state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 19:45:50 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 14:23:13 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Jordao", "Artur", ""], ["Lie", "Maiko", ""], ["de Melo", "Victor Hugo Cunha", ""], ["Schwartz", "William Robson", ""]]}, {"id": "1910.02321", "submitter": "Nuno Louren\\c{c}o", "authors": "In\\^es Valentim, Nuno Louren\\c{c}o, Nuno Antunes", "title": "The Impact of Data Preparation on the Fairness of Software Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are widely adopted in scenarios that directly affect\npeople. The development of software systems based on these models raises\nsocietal and legal concerns, as their decisions may lead to the unfair\ntreatment of individuals based on attributes like race or gender. Data\npreparation is key in any machine learning pipeline, but its effect on fairness\nis yet to be studied in detail. In this paper, we evaluate how the fairness and\neffectiveness of the learned models are affected by the removal of the\nsensitive attribute, the encoding of the categorical attributes, and instance\nselection methods (including cross-validators and random undersampling). We\nused the Adult Income and the German Credit Data datasets, which are widely\nstudied and known to have fairness concerns. We applied each data preparation\ntechnique individually to analyse the difference in predictive performance and\nfairness, using statistical parity difference, disparate impact, and the\nnormalised prejudice index. The results show that fairness is affected by\ntransformations made to the training data, particularly in imbalanced datasets.\nRemoving the sensitive attribute is insufficient to eliminate all the\nunfairness in the predictions, as expected, but it is key to achieve fairer\nmodels. Additionally, the standard random undersampling with respect to the\ntrue labels is sometimes more prejudicial than performing no random\nundersampling.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 19:50:16 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Valentim", "In\u00eas", ""], ["Louren\u00e7o", "Nuno", ""], ["Antunes", "Nuno", ""]]}, {"id": "1910.02325", "submitter": "David D. Fan", "authors": "David D. Fan, Jennifer Nguyen, Rohan Thakker, Nikhilesh Alatur,\n  Ali-akbar Agha-mohammadi, Evangelos A. Theodorou", "title": "Bayesian Learning-Based Adaptive Control for Safety Critical Systems", "comments": "Corrected an error in section II, where previously the problem was\n  introduced in a non-stochastic setting and wrongly assumed the solution to an\n  ODE with Gaussian distributed parametric uncertainty was equivalent to an SDE\n  with a learned diffusion term. See Lew, T et al. \"On the Problem of\n  Reformulating Systems with Uncertain Dynamics as a Stochastic Differential\n  Equation\"", "journal-ref": "IEEE International Conference on Robotics and Automation (ICRA)\n  2020 May 31 (pp. 4093-4099)", "doi": "10.1109/ICRA40945.2020.9196709", "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has enjoyed much recent success, and applying state-of-the-art\nmodel learning methods to controls is an exciting prospect. However, there is a\nstrong reluctance to use these methods on safety-critical systems, which have\nconstraints on safety, stability, and real-time performance. We propose a\nframework which satisfies these constraints while allowing the use of deep\nneural networks for learning model uncertainties. Central to our method is the\nuse of Bayesian model learning, which provides an avenue for maintaining\nappropriate degrees of caution in the face of the unknown. In the proposed\napproach, we develop an adaptive control framework leveraging the theory of\nstochastic CLFs (Control Lyapunov Functions) and stochastic CBFs (Control\nBarrier Functions) along with tractable Bayesian model learning via Gaussian\nProcesses or Bayesian neural networks. Under reasonable assumptions, we\nguarantee stability and safety while adapting to unknown dynamics with\nprobability 1. We demonstrate this architecture for high-speed terrestrial\nmobility targeting potential applications in safety-critical high-speed Mars\nrover missions.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 20:19:10 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 06:21:37 GMT"}, {"version": "v3", "created": "Sun, 4 Jul 2021 15:37:05 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Fan", "David D.", ""], ["Nguyen", "Jennifer", ""], ["Thakker", "Rohan", ""], ["Alatur", "Nikhilesh", ""], ["Agha-mohammadi", "Ali-akbar", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "1910.02330", "submitter": "Adish Singla", "authors": "Ahana Ghosh, Sebastian Tschiatschek, Hamed Mahdavi, Adish Singla", "title": "Towards Deployment of Robust AI Agents for Human-Machine Partnerships", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of designing AI agents that can robustly cooperate with\npeople in human-machine partnerships. Our work is inspired by real-life\nscenarios in which an AI agent, e.g., a virtual assistant, has to cooperate\nwith new users after its deployment. We model this problem via a parametric MDP\nframework where the parameters correspond to a user's type and characterize her\nbehavior. In the test phase, the AI agent has to interact with a user of\nunknown type. Our approach to designing a robust AI agent relies on observing\nthe user's actions to make inferences about the user's type and adapting its\npolicy to facilitate efficient cooperation. We show that without being\nadaptive, an AI agent can end up performing arbitrarily bad in the test phase.\nWe develop two algorithms for computing policies that automatically adapt to\nthe user in the test phase. We demonstrate the effectiveness of our approach in\nsolving a two-agent collaborative task.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 21:04:27 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 23:19:40 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Ghosh", "Ahana", ""], ["Tschiatschek", "Sebastian", ""], ["Mahdavi", "Hamed", ""], ["Singla", "Adish", ""]]}, {"id": "1910.02332", "submitter": "Mhd Wesam Al-Nabki", "authors": "Mhd Wesam Al-Nabki, Eduardo Fidalgo, Enrique Alegre, and Deisy Chaves", "title": "Content-Based Features to Rank Influential Hidden Services of the Tor\n  Darknet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unevenness importance of criminal activities in the onion domains of the\nTor Darknet and the different levels of their appeal to the end-user make them\ntangled to measure their influence. To this end, this paper presents a novel\ncontent-based ranking framework to detect the most influential onion domains.\nOur approach comprises a modeling unit that represents an onion domain using\nforty features extracted from five different resources: user-visible text, HTML\nmarkup, Named Entities, network topology, and visual content. And also, a\nranking unit that, using the Learning-to-Rank (LtR) approach, automatically\nlearns a ranking function by integrating the previously obtained features.\nUsing a case-study based on drugs-related onion domains, we obtained the\nfollowing results. (1) Among the explored LtR schemes, the listwise approach\noutperforms the benchmarked methods with an NDCG of 0.95 for the top-10 ranked\ndomains. (2) We proved quantitatively that our framework surpasses the\nlink-based ranking techniques. Also, (3) with the selected feature, we observed\nthat the textual content, composed by text, NER, and HTML features, is the most\nbalanced approach, in terms of efficiency and score obtained. The proposed\nframework might support Law Enforcement Agencies in detecting the most\ninfluential domains related to possible suspicious activities.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 21:39:20 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Al-Nabki", "Mhd Wesam", ""], ["Fidalgo", "Eduardo", ""], ["Alegre", "Enrique", ""], ["Chaves", "Deisy", ""]]}, {"id": "1910.02333", "submitter": "Rahul Parhi", "authors": "Rahul Parhi and Robert D. Nowak", "title": "The Role of Neural Network Activation Functions", "comments": "update to published version", "journal-ref": "IEEE Signal Processing Letters, vol. 27, pp. 1779-1783, 2020", "doi": "10.1109/LSP.2020.3027517", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of activation functions have been proposed for neural\nnetworks. The Rectified Linear Unit (ReLU) is especially popular today. There\nare many practical reasons that motivate the use of the ReLU. This paper\nprovides new theoretical characterizations that support the use of the ReLU,\nits variants such as the leaky ReLU, as well as other activation functions in\nthe case of univariate, single-hidden layer feedforward neural networks. Our\nresults also explain the importance of commonly used strategies in the design\nand training of neural networks such as \"weight decay\" and \"path-norm\"\nregularization, and provide a new justification for the use of \"skip\nconnections\" in network architectures. These new insights are obtained through\nthe lens of spline theory. In particular, we show how neural network training\nproblems are related to infinite-dimensional optimizations posed over Banach\nspaces of functions whose solutions are well-known to be fractional and\npolynomial splines, where the particular Banach space (which controls the order\nof the spline) depends on the choice of activation function.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 21:57:32 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 17:26:37 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 14:37:26 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Parhi", "Rahul", ""], ["Nowak", "Robert D.", ""]]}, {"id": "1910.02339", "submitter": "Kezhen Chen", "authors": "Kezhen Chen, Qiuyuan Huang, Hamid Palangi, Paul Smolensky, Kenneth D.\n  Forbus and Jianfeng Gao", "title": "Mapping Natural-language Problems to Formal-language Solutions Using\n  Structured Neural Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating formal-language programs represented by relational tuples, such as\nLisp programs or mathematical operations, to solve problems stated in natural\nlanguage is a challenging task because it requires explicitly capturing\ndiscrete symbolic structural information implicit in the input. However, most\ngeneral neural sequence models do not explicitly capture such structural\ninformation, limiting their performance on these tasks. In this paper, we\npropose a new encoder-decoder model based on a structured neural\nrepresentation, Tensor Product Representations (TPRs), for mapping\nNatural-language problems to Formal-language solutions, called TP-N2F. The\nencoder of TP-N2F employs TPR `binding' to encode natural-language symbolic\nstructure in vector space and the decoder uses TPR `unbinding' to generate, in\nsymbolic space, a sequential program represented by relational tuples, each\nconsisting of a relation (or operation) and a number of arguments. TP-N2F\nconsiderably outperforms LSTM-based seq2seq models on two benchmarks and\ncreates new state-of-the-art results. Ablation studies show that improvements\ncan be attributed to the use of structured TPRs explicitly in both the encoder\nand decoder. Analysis of the learned structures shows how TPRs enhance the\ninterpretability of TP-N2F.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 22:57:04 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 04:20:45 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 03:18:59 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Chen", "Kezhen", ""], ["Huang", "Qiuyuan", ""], ["Palangi", "Hamid", ""], ["Smolensky", "Paul", ""], ["Forbus", "Kenneth D.", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1910.02342", "submitter": "Keith Dillon", "authors": "Keith Dillon", "title": "Clustering Gaussian Graphical Models", "comments": "arXiv admin note: text overlap with arXiv:1903.07181", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an efficient method to perform clustering of nodes in Gaussian\ngraphical models directly from sample data. Nodes are clustered based on the\nsimilarity of their network neighborhoods, with edge weights defined by partial\ncorrelations. In the limited-data scenario, where the covariance matrix would\nbe rank-deficient, we are able to make use of matrix factors, and never need to\nestimate the actual covariance or precision matrix. We demonstrate the method\non functional MRI data from the Human Connectome Project. A matlab\nimplementation of the algorithm is provided.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 23:48:05 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Dillon", "Keith", ""]]}, {"id": "1910.02344", "submitter": "Jae Hyun Lim", "authors": "Jae Hyun Lim, Pedro O. Pinheiro, Negar Rostamzadeh, Christopher Pal,\n  Sungjin Ahn", "title": "Neural Multisensory Scene Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For embodied agents to infer representations of the underlying 3D physical\nworld they inhabit, they should efficiently combine multisensory cues from\nnumerous trials, e.g., by looking at and touching objects. Despite its\nimportance, multisensory 3D scene representation learning has received less\nattention compared to the unimodal setting. In this paper, we propose the\nGenerative Multisensory Network (GMN) for learning latent representations of 3D\nscenes which are partially observable through multiple sensory modalities. We\nalso introduce a novel method, called the Amortized Product-of-Experts, to\nimprove the computational efficiency and the robustness to unseen combinations\nof modalities at test time. Experimental results demonstrate that the proposed\nmodel can efficiently infer robust modality-invariant 3D-scene representations\nfrom arbitrary combinations of modalities and perform accurate cross-modal\ngeneration. To perform this exploration, we also develop the Multisensory\nEmbodied 3D-Scene Environment (MESE).\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 00:14:38 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 02:07:33 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Lim", "Jae Hyun", ""], ["Pinheiro", "Pedro O.", ""], ["Rostamzadeh", "Negar", ""], ["Pal", "Christopher", ""], ["Ahn", "Sungjin", ""]]}, {"id": "1910.02352", "submitter": "Zenan Li", "authors": "Zenan Li, Xiaoxing Ma, Chang Xu, Jingwei Xu, Chun Cao and Jian L\\\"u", "title": "Operational Calibration: Debugging Confidence Errors for DNNs in the\n  Field", "comments": "Published in the Proceedings of the 28th ACM Joint European Software\n  Engineering Conference and Symposium on the Foundations of Software\n  Engineering (ESEC/FSE 2020)", "journal-ref": null, "doi": "10.1145/3368089.3409696", "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trained DNN models are increasingly adopted as integral parts of software\nsystems, but they often perform deficiently in the field. A particularly\ndamaging problem is that DNN models often give false predictions with high\nconfidence, due to the unavoidable slight divergences between operation data\nand training data. To minimize the loss caused by inaccurate confidence,\noperational calibration, i.e., calibrating the confidence function of a DNN\nclassifier against its operation domain, becomes a necessary debugging step in\nthe engineering of the whole system.\n  Operational calibration is difficult considering the limited budget of\nlabeling operation data and the weak interpretability of DNN models. We propose\na Bayesian approach to operational calibration that gradually corrects the\nconfidence given by the model under calibration with a small number of labeled\noperation data deliberately selected from a larger set of unlabeled operation\ndata. The approach is made effective and efficient by leveraging the locality\nof the learned representation of the DNN model and modeling the calibration as\nGaussian Process Regression. Comprehensive experiments with various practical\ndatasets and DNN models show that it significantly outperformed alternative\nmethods, and in some difficult tasks it eliminated about 71% to 97%\nhigh-confidence (>0.9) errors with only about 10\\% of the minimal amount of\nlabeled operation data needed for practical learning techniques to barely work.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 01:21:14 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 02:28:32 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Li", "Zenan", ""], ["Ma", "Xiaoxing", ""], ["Xu", "Chang", ""], ["Xu", "Jingwei", ""], ["Cao", "Chun", ""], ["L\u00fc", "Jian", ""]]}, {"id": "1910.02354", "submitter": "Guangyu Shen", "authors": "Guangyu Shen, Chengzhi Mao, Junfeng Yang, Baishakhi Ray", "title": "AdvSPADE: Realistic Unrestricted Attacks for Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the inherent robustness of segmentation models, traditional\nnorm-bounded attack methods show limited effect on such type of models. In this\npaper, we focus on generating unrestricted adversarial examples for semantic\nsegmentation models. We demonstrate a simple and effective method to generate\nunrestricted adversarial examples using conditional generative adversarial\nnetworks (CGAN) without any hand-crafted metric. The na\\\"ive implementation of\nCGAN, however, yields inferior image quality and low attack success rate.\nInstead, we leverage the SPADE (Spatially-adaptive denormalization) structure\nwith an additional loss item to generate effective adversarial attacks in a\nsingle step. We validate our approach on the popular Cityscapes and ADE20K\ndatasets, and demonstrate that our synthetic adversarial examples are not only\nrealistic, but also improve the attack success rate by up to 41.0\\% compared\nwith the state of the art adversarial attack methods including PGD.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 02:16:18 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 19:53:09 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 02:38:18 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Shen", "Guangyu", ""], ["Mao", "Chengzhi", ""], ["Yang", "Junfeng", ""], ["Ray", "Baishakhi", ""]]}, {"id": "1910.02358", "submitter": "Kyung-Wha Park", "authors": "Kyung-Wha Park, JungHoon Lee, Sunyoung Kwon, Jung-Woo Ha, Kyung-Min\n  Kim, Byoung-Tak Zhang", "title": "Which Ads to Show? Advertisement Image Assessment with Auxiliary\n  Information via Multi-step Modality Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing aesthetic preference is a fundamental task related to human\ncognition. It can also contribute to various practical applications such as\nimage creation for online advertisements. Despite crucial influences of image\nquality, auxiliary information of ad images such as tags and target subjects\ncan also determine image preference. Existing studies mainly focus on images\nand thus are less useful for advertisement scenarios where rich auxiliary data\nare available. Here we propose a modality fusion-based neural network that\nevaluates the aesthetic preference of images with auxiliary information. Our\nmethod fully utilizes auxiliary data by introducing multi-step modality fusion\nusing both conditional batch normalization-based low-level and attention-based\nhigh-level fusion mechanisms, inspired by the findings from statistical\nanalyses on real advertisement data. Our approach achieved state-of-the-art\nperformance on the AVA dataset, a widely used dataset for aesthetic assessment.\nBesides, the proposed method is evaluated on large-scale real-world\nadvertisement image data with rich auxiliary attributes, providing promising\npreference prediction results. Through extensive experiments, we investigate\nhow image and auxiliary information together influence click-through rate.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 03:17:38 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Park", "Kyung-Wha", ""], ["Lee", "JungHoon", ""], ["Kwon", "Sunyoung", ""], ["Ha", "Jung-Woo", ""], ["Kim", "Kyung-Min", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1910.02366", "submitter": "Dilin Wang", "authors": "Qiang Liu, Lemeng Wu, Dilin Wang", "title": "Splitting Steepest Descent for Growing Neural Architectures", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a progressive training approach for neural networks which\nadaptively grows the network structure by splitting existing neurons to\nmultiple off-springs. By leveraging a functional steepest descent idea, we\nderive a simple criterion for deciding the best subset of neurons to split and\na splitting gradient for optimally updating the off-springs. Theoretically, our\nsplitting strategy is a second-order functional steepest descent for escaping\nsaddle points in an $\\infty$-Wasserstein metric space, on which the standard\nparametric gradient descent is a first-order steepest descent. Our method\nprovides a new computationally efficient approach for optimizing neural network\nstructures, especially for learning lightweight neural architectures in\nresource-constrained settings.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 04:15:23 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 17:17:16 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 22:25:12 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Liu", "Qiang", ""], ["Wu", "Lemeng", ""], ["Wang", "Dilin", ""]]}, {"id": "1910.02370", "submitter": "Chenhui Deng", "authors": "Chenhui Deng, Zhiqiang Zhao, Yongyu Wang, Zhiru Zhang, Zhuo Feng", "title": "GraphZoom: A multi-level spectral approach for accurate and scalable\n  graph embedding", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": "International Conference on Learning Representations, ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding techniques have been increasingly deployed in a multitude of\ndifferent applications that involve learning on non-Euclidean data. However,\nexisting graph embedding models either fail to incorporate node attribute\ninformation during training or suffer from node attribute noise, which\ncompromises the accuracy. Moreover, very few of them scale to large graphs due\nto their high computational complexity and memory usage. In this paper we\npropose GraphZoom, a multi-level framework for improving both accuracy and\nscalability of unsupervised graph embedding algorithms. GraphZoom first\nperforms graph fusion to generate a new graph that effectively encodes the\ntopology of the original graph and the node attribute information. This fused\ngraph is then repeatedly coarsened into much smaller graphs by merging nodes\nwith high spectral similarities. GraphZoom allows any existing embedding\nmethods to be applied to the coarsened graph, before it progressively refine\nthe embeddings obtained at the coarsest level to increasingly finer graphs. We\nhave evaluated our approach on a number of popular graph datasets for both\ntransductive and inductive tasks. Our experiments show that GraphZoom can\nsubstantially increase the classification accuracy and significantly accelerate\nthe entire graph embedding process by up to 40.8x, when compared to the\nstate-of-the-art unsupervised embedding methods.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 04:43:46 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 18:35:53 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Deng", "Chenhui", ""], ["Zhao", "Zhiqiang", ""], ["Wang", "Yongyu", ""], ["Zhang", "Zhiru", ""], ["Feng", "Zhuo", ""]]}, {"id": "1910.02376", "submitter": "Wei Ma", "authors": "Wei Ma, Sean Qian", "title": "High-Resolution Traffic Sensing with Autonomous Vehicles", "comments": "submitted to Transportation Research Part C: Emerging Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decades have witnessed the breakthrough of autonomous vehicles\n(AVs), and the perception capabilities of AVs have been dramatically improved.\nVarious sensors installed on AVs, including, but are not limited to, LiDAR,\nradar, camera and stereovision, will be collecting massive data and perceiving\nthe surrounding traffic states continuously. In fact, a fleet of AVs can serve\nas floating (or probe) sensors, which can be utilized to infer traffic\ninformation while cruising around the roadway networks. In contrast,\nconventional traffic sensing methods rely on fixed traffic sensors such as loop\ndetectors, cameras and microwave vehicle detectors. Due to the high cost of\nconventional traffic sensors, traffic state data are usually obtained in a\nlow-frequency and sparse manner. In view of this, this paper leverages rich\ndata collected through AVs to propose the high-resolution traffic sensing\nframework. The proposed framework estimates the fundamental traffic state\nvariables, namely, flow, density and speed in high spatio-temporal resolution,\nand it is developed under different levels of AV perception capabilities and\nlow AV market penetration rate. The Next Generation Simulation (NGSIM) data is\nadopted to examine the accuracy and robustness of the proposed framework.\nExperimental results show that the proposed estimation framework achieves high\naccuracy even with low AV market penetration rate. Sensitivity analysis\nregarding AV penetration rate, sensor configuration, and perception accuracy\nwill also be studied. This study will help policymakers and private sectors\n(e.g Uber, Waymo) to understand the values of AVs, especially the values of\nmassive data collected by AVs, in traffic operation and management.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 05:07:29 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ma", "Wei", ""], ["Qian", "Sean", ""]]}, {"id": "1910.02380", "submitter": "Gregory Dobler", "authors": "Gregory Dobler, Jordan Vani, Trang Tran Linh Dam", "title": "Patterns of Urban Foot Traffic Dynamics", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using publicly available traffic camera data in New York City, we quantify\ntime-dependent patterns in aggregate pedestrian foot traffic. These patterns\nexhibit repeatable diurnal behaviors that differ for weekdays and weekends but\nare broadly consistent across neighborhoods in the borough of Manhattan.\nWeekday patterns contain a characteristic 3-peak structure with increased foot\ntraffic around 9:00am, 12:00-1:00pm, and 5:00pm aligned with the \"9-to-5\" work\nday in which pedestrians are on the street during their morning commute, during\nlunch hour, and then during their evening commute. Weekend days do not show a\npeaked structure, but rather increase steadily until sunset. Our study period\nof June 28, 2017 to September 11, 2017 contains two holidays, the 4th of July\nand Labor Day, and their foot traffic patterns are quantitatively similar to\nweekend days despite the fact that they fell on weekdays. Projecting all days\nin our study period onto the weekday/weekend phase space (by regressing against\nthe average weekday and weekend day) we find that Friday foot traffic can be\nrepresented as a mixture of both the 3-peak weekday structure and non-peaked\nweekend structure. We also show that anomalies in the foot traffic patterns can\nbe used for detection of events and network-level disruptions. Finally, we show\nthat clustering of foot traffic time series generates associations between\ncameras that are spatially aligned with Manhattan neighborhood boundaries\nindicating that foot traffic dynamics encode information about neighborhood\ncharacter.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 05:39:57 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Dobler", "Gregory", ""], ["Vani", "Jordan", ""], ["Dam", "Trang Tran Linh", ""]]}, {"id": "1910.02384", "submitter": "Jindong Jiang", "authors": "Jindong Jiang, Sepehr Janghorbani, Gerard de Melo, Sungjin Ahn", "title": "SCALOR: Generative World Models with Scalable Object Representations", "comments": "First two authors contributed equally. Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalability in terms of object density in a scene is a primary challenge in\nunsupervised sequential object-oriented representation learning. Most of the\nprevious models have been shown to work only on scenes with a few objects. In\nthis paper, we propose SCALOR, a probabilistic generative world model for\nlearning SCALable Object-oriented Representation of a video. With the proposed\nspatially-parallel attention and proposal-rejection mechanisms, SCALOR can deal\nwith orders of magnitude larger numbers of objects compared to the previous\nstate-of-the-art models. Additionally, we introduce a background module that\nallows SCALOR to model complex dynamic backgrounds as well as many foreground\nobjects in the scene. We demonstrate that SCALOR can deal with crowded scenes\ncontaining up to a hundred objects while jointly modeling complex dynamic\nbackgrounds. Importantly, SCALOR is the first unsupervised object\nrepresentation model shown to work for natural scenes containing several tens\nof moving objects.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 06:26:31 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 16:56:45 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 05:43:36 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 19:09:24 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Jiang", "Jindong", ""], ["Janghorbani", "Sepehr", ""], ["de Melo", "Gerard", ""], ["Ahn", "Sungjin", ""]]}, {"id": "1910.02390", "submitter": "Amber Nigam", "authors": "Amber Nigam, Pragati Jaiswal, Uma Girkar, Teertha Arora, and Leo A.\n  Celi", "title": "Migration through Machine Learning Lens -- Predicting Sexual and\n  Reproductive Health Vulnerability of Young Migrants", "comments": "Accepted for Machine Learning for Health (ML4H) at NeurIPS 2019 -\n  Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have discussed initial findings and results of our\nexperiment to predict sexual and reproductive health vulnerabilities of\nmigrants in a data-constrained environment. Notwithstanding the limited\nresearch and data about migrants and migration cities, we propose a solution\nthat simultaneously focuses on data gathering from migrants, augmenting\nawareness of the migrants to reduce mishaps, and setting up a mechanism to\npresent insights to the key stakeholders in migration to act upon. We have\ndesigned a webapp for the stakeholders involved in migration: migrants, who\nwould participate in data gathering process and can also use the app for\ngetting to know safety and awareness tips based on analysis of the data\nreceived; public health workers, who would have an access to the database of\nmigrants on the app; policy makers, who would have a greater understanding of\nthe ground reality, and of the patterns of migration through machine-learned\nanalysis. Finally, we have experimented with different machine learning models\non an artificially curated dataset. We have shown, through experiments, how\nmachine learning can assist in predicting the migrants at risk and can also\nhelp in identifying the critical factors that make migration dangerous for\nmigrants. The results for identifying vulnerable migrants through machine\nlearning algorithms are statistically significant at an alpha of 0.05.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 07:09:13 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 03:56:45 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 20:14:39 GMT"}, {"version": "v4", "created": "Fri, 22 Nov 2019 10:00:02 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Nigam", "Amber", ""], ["Jaiswal", "Pragati", ""], ["Girkar", "Uma", ""], ["Arora", "Teertha", ""], ["Celi", "Leo A.", ""]]}, {"id": "1910.02409", "submitter": "Terence Broad", "authors": "Terence Broad, Mick Grierson", "title": "Searching for an (un)stable equilibrium: experiments in training\n  generative models without data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper details a developing artistic practice around an ongoing series of\nworks called (un)stable equilibrium. These works are the product of using\nmodern machine toolkits to train generative models without data, an approach\nakin to traditional generative art where dynamical systems are explored\nintuitively for their latent generative possibilities. We discuss some of the\nguiding principles that have been learnt in the process of experimentation,\npresent details of the implementation of the first series of works and discuss\npossibilities for future experimentation.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 10:23:06 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Broad", "Terence", ""], ["Grierson", "Mick", ""]]}, {"id": "1910.02411", "submitter": "Terence Broad", "authors": "Terence Broad, Mick Grierson", "title": "Transforming the output of GANs by fine-tuning them with features from\n  different datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work we present a method for fine-tuning pre-trained GANs with\nfeatures from different datasets, resulting in the transformation of the output\ndistribution into a new distribution with novel characteristics. The weights of\nthe generator are updated using the weighted sum of the losses from a\ncross-dataset classifier and the frozen weights of the pre-trained\ndiscriminator. We discuss details of the technical implementation and share\nsome of the visual results from this training process.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 10:29:11 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Broad", "Terence", ""], ["Grierson", "Mick", ""]]}, {"id": "1910.02420", "submitter": "Essam Rashed", "authors": "Essam A. Rashed, Jose Gomez-Tames, Akimasa Hirata", "title": "Deep learning-based development of personalized human head model with\n  non-uniform conductivity for brain stimulation", "comments": null, "journal-ref": "IEEE Transactions on Medical Imaging, 2020", "doi": "10.1109/TMI.2020.2969682", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electromagnetic stimulation of the human brain is a key tool for the\nneurophysiological characterization and diagnosis of several neurological\ndisorders. Transcranial magnetic stimulation (TMS) is one procedure that is\ncommonly used clinically. However, personalized TMS requires a pipeline for\naccurate head model generation to provide target-specific stimulation. This\nprocess includes intensive segmentation of several head tissues based on\nmagnetic resonance imaging (MRI), which has significant potential for\nsegmentation error, especially for low-contrast tissues. Additionally, a\nuniform electrical conductivity is assigned to each tissue in the model, which\nis an unrealistic assumption based on conventional volume conductor modeling.\nThis paper proposes a novel approach to the automatic estimation of electric\nconductivity in the human head for volume conductor models without anatomical\nsegmentation. A convolutional neural network is designed to estimate\npersonalized electrical conductivity values based on anatomical information\nobtained from T1- and T2-weighted MRI scans. This approach can avoid the\ntime-consuming process of tissue segmentation and maximize the advantages of\nposition-dependent conductivity assignment based on water content values\nestimated from MRI intensity values. The computational results of the proposed\napproach provide similar but smoother electric field results for the brain when\ncompared to conventional approaches.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 11:33:13 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 06:00:57 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Rashed", "Essam A.", ""], ["Gomez-Tames", "Jose", ""], ["Hirata", "Akimasa", ""]]}, {"id": "1910.02421", "submitter": "Nimrod Segol", "authors": "Nimrod Segol, Yaron Lipman", "title": "On Universal Equivariant Set Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using deep neural networks that are either invariant or equivariant to\npermutations in order to learn functions on unordered sets has become\nprevalent. The most popular, basic models are DeepSets [Zaheer et al. 2017] and\nPointNet [Qi et al. 2017]. While known to be universal for approximating\ninvariant functions, DeepSets and PointNet are not known to be universal when\napproximating \\emph{equivariant} set functions. On the other hand, several\nrecent equivariant set architectures have been proven equivariant universal\n[Sannai et al. 2019], [Keriven et al. 2019], however these models either use\nlayers that are not permutation equivariant (in the standard sense) and/or use\nhigher order tensor variables which are less practical.\n  There is, therefore, a gap in understanding the universality of popular\nequivariant set models versus theoretical ones.\n  In this paper we close this gap by proving that: (i) PointNet is not\nequivariant universal; and (ii) adding a single linear transmission layer makes\nPointNet universal. We call this architecture PointNetST and argue it is the\nsimplest permutation equivariant universal model known to date. Another\nconsequence is that DeepSets is universal, and also PointNetSeg, a popular\npoint cloud segmentation network (used eg, in [Qi et al. 2017]) is universal.\n  The key theoretical tool used to prove the above results is an explicit\ncharacterization of all permutation equivariant polynomial layers. Lastly, we\nprovide numerical experiments validating the theoretical results and comparing\ndifferent permutation equivariant models.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 11:37:56 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 20:15:00 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Segol", "Nimrod", ""], ["Lipman", "Yaron", ""]]}, {"id": "1910.02423", "submitter": "Harikrishnan Nellippallil Balakrishnan", "authors": "Harikrishnan Nellippallil Balakrishnan, Aditi Kathpalia, Snehanshu\n  Saha, Nithin Nagaraj", "title": "ChaosNet: A Chaos based Artificial Neural Network Architecture for\n  Classification", "comments": "27 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by chaotic firing of neurons in the brain, we propose ChaosNet -- a\nnovel chaos based artificial neural network architecture for classification\ntasks. ChaosNet is built using layers of neurons, each of which is a 1D chaotic\nmap known as the Generalized Luroth Series (GLS) which has been shown in\nearlier works to possess very useful properties for compression, cryptography\nand for computing XOR and other logical operations. In this work, we design a\nnovel learning algorithm on ChaosNet that exploits the topological transitivity\nproperty of the chaotic GLS neurons. The proposed learning algorithm gives\nconsistently good performance accuracy in a number of classification tasks on\nwell known publicly available datasets with very limited training samples. Even\nwith as low as 7 (or fewer) training samples/class (which accounts for less\nthan 0.05% of the total available data), ChaosNet yields performance accuracies\nin the range 73.89 % - 98.33 %. We demonstrate the robustness of ChaosNet to\nadditive parameter noise and also provide an example implementation of a\n2-layer ChaosNet for enhancing classification accuracy. We envisage the\ndevelopment of several other novel learning algorithms on ChaosNet in the near\nfuture.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 11:40:40 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Balakrishnan", "Harikrishnan Nellippallil", ""], ["Kathpalia", "Aditi", ""], ["Saha", "Snehanshu", ""], ["Nagaraj", "Nithin", ""]]}, {"id": "1910.02425", "submitter": "Jannik Kossen", "authors": "Jannik Kossen, Karl Stelzner, Marcel Hussing, Claas Voelcker, Kristian\n  Kersting", "title": "Structured Object-Aware Physics Prediction for Video Modeling and\n  Planning", "comments": "Published as a conference paper at 2020 International Conference for\n  Learning Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When humans observe a physical system, they can easily locate objects,\nunderstand their interactions, and anticipate future behavior, even in settings\nwith complicated and previously unseen interactions. For computers, however,\nlearning such models from videos in an unsupervised fashion is an unsolved\nresearch problem. In this paper, we present STOVE, a novel state-space model\nfor videos, which explicitly reasons about objects and their positions,\nvelocities, and interactions. It is constructed by combining an image model and\na dynamics model in compositional manner and improves on previous work by\nreusing the dynamics model for inference, accelerating and regularizing\ntraining. STOVE predicts videos with convincing physical behavior over hundreds\nof timesteps, outperforms previous unsupervised models, and even approaches the\nperformance of supervised baselines. We further demonstrate the strength of our\nmodel as a simulator for sample efficient model-based control in a task with\nheavily interacting objects.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 11:48:26 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:38:20 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kossen", "Jannik", ""], ["Stelzner", "Karl", ""], ["Hussing", "Marcel", ""], ["Voelcker", "Claas", ""], ["Kersting", "Kristian", ""]]}, {"id": "1910.02426", "submitter": "Dimitri Bertsekas", "authors": "Dimitri Bertsekas", "title": "Biased Aggregation, Rollout, and Enhanced Policy Improvement for\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new aggregation framework for approximate dynamic programming,\nwhich provides a connection with rollout algorithms, approximate policy\niteration, and other single and multistep lookahead methods. The central novel\ncharacteristic is the use of a bias function $V$ of the state, which biases the\nvalues of the aggregate cost function towards their correct levels. The\nclassical aggregation framework is obtained when $V\\equiv0$, but our scheme\nworks best when $V$ is a known reasonably good approximation to the optimal\ncost function $J^*$.\n  When $V$ is equal to the cost function $J_{\\mu}$ of some known policy $\\mu$\nand there is only one aggregate state, our scheme is equivalent to the rollout\nalgorithm based on $\\mu$ (i.e., the result of a single policy improvement\nstarting with the policy $\\mu$). When $V=J_{\\mu}$ and there are multiple\naggregate states, our aggregation approach can be used as a more powerful form\nof improvement of $\\mu$. Thus, when combined with an approximate policy\nevaluation scheme, our approach can form the basis for a new and enhanced form\nof approximate policy iteration.\n  When $V$ is a generic bias function, our scheme is equivalent to\napproximation in value space with lookahead function equal to $V$ plus a local\ncorrection within each aggregate state. The local correction levels are\nobtained by solving a low-dimensional aggregate DP problem, yielding an\narbitrarily close approximation to $J^*$, when the number of aggregate states\nis sufficiently large. Except for the bias function, the aggregate DP problem\nis similar to the one of the classical aggregation framework, and its\nalgorithmic solution by simulation or other methods is nearly identical to one\nfor classical aggregation, assuming values of $V$ are available when needed.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 11:51:00 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Bertsekas", "Dimitri", ""]]}, {"id": "1910.02434", "submitter": "Yuguang Wang", "authors": "Shao-Bo Lin, Yu Guang Wang, Ding-Xuan Zhou", "title": "Distributed filtered hyperinterpolation for noisy data on the sphere", "comments": "26 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CA cs.DC cs.LG cs.NA math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems in astrophysics, space weather research and geophysics usually need\nto analyze noisy big data on the sphere. This paper develops distributed\nfiltered hyperinterpolation for noisy data on the sphere, which assigns the\ndata fitting task to multiple servers to find a good approximation of the\nmapping of input and output data. For each server, the approximation is a\nfiltered hyperinterpolation on the sphere by a small proportion of quadrature\nnodes. The distributed strategy allows parallel computing for data processing\nand model selection and thus reduces computational cost for each server while\npreserves the approximation capability compared to the filtered\nhyperinterpolation. We prove quantitative relation between the approximation\ncapability of distributed filtered hyperinterpolation and the numbers of input\ndata and servers. Numerical examples show the efficiency and accuracy of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 12:28:08 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Lin", "Shao-Bo", ""], ["Wang", "Yu Guang", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1910.02450", "submitter": "Dan Wang", "authors": "Hekai Zhang, Jibing Gong, Zhiyong Teng, Dan Wang, Hongfei Wang,\n  Linfeng Du and Zakirul Alam Bhuiyan", "title": "Mobile APP User Attribute Prediction by Heterogeneous Information\n  Network Modeling", "comments": "10 pages,3 figures,International Conference on Dependability in\n  Sensor, Cloud, and Big Data Systems and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-based attribute information, such as age and gender, is usually\nconsidered as user privacy information. It is difficult for enterprises to\nobtain user-based privacy attribute information. However, user-based privacy\nattribute information has a wide range of applications in personalized\nservices, user behavior analysis and other aspects. this paper advances the\nHetPathMine model and puts forward TPathMine model. With applying the number of\nclicks of attributes under each node to express the user's emotional preference\ninformation, optimizations of the solution of meta-path weight are also\npresented. Based on meta-path in heterogeneous information networks, the new\nmodel integrates all relationships among objects into isomorphic relationships\nof classified objects. Matrix is used to realize the knowledge dissemination of\ncategory knowledge among isomorphic objects. The experimental results show\nthat: (1) the prediction of user attributes based on heterogeneous information\nnetworks can achieve higher accuracy than traditional machine learning\nclassification methods; (2) TPathMine model based on the number of clicks is\nmore accurate in classifying users of different age groups, and the weight of\neach meta-path is consistent with human intuition or the real world situation.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 13:41:58 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhang", "Hekai", ""], ["Gong", "Jibing", ""], ["Teng", "Zhiyong", ""], ["Wang", "Dan", ""], ["Wang", "Hongfei", ""], ["Du", "Linfeng", ""], ["Bhuiyan", "Zakirul Alam", ""]]}, {"id": "1910.02483", "submitter": "Daniel Saromo", "authors": "Daniel Saromo, Elizabeth Villota and Edwin Villanueva", "title": "Auto-Rotating Perceptrons", "comments": "LatinX in AI Research Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an improved design of the perceptron unit to mitigate the\nvanishing gradient problem. This nuisance appears when training deep multilayer\nperceptron networks with bounded activation functions. The new neuron design,\nnamed auto-rotating perceptron (ARP), has a mechanism to ensure that the node\nalways operates in the dynamic region of the activation function, by avoiding\nsaturation of the perceptron. The proposed method does not change the inference\nstructure learned at each neuron. We test the effect of using ARP units in some\nnetwork architectures which use the sigmoid activation function. The results\nsupport our hypothesis that neural networks with ARP units can achieve better\nlearning performance than equivalent models with classic perceptrons.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 17:38:47 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 03:24:09 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Saromo", "Daniel", ""], ["Villota", "Elizabeth", ""], ["Villanueva", "Edwin", ""]]}, {"id": "1910.02488", "submitter": "Zhengling Qi", "authors": "Zhengling Qi, Ying Cui, Yufeng Liu, Jong-Shi Pang", "title": "Statistical Analysis of Stationary Solutions of Coupled Nonconvex\n  Nonsmooth Empirical Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has two main goals: (a) establish several statistical\nproperties---consistency, asymptotic distributions, and convergence rates---of\nstationary solutions and values of a class of coupled nonconvex and\nnonsmoothempirical risk minimization problems, and (b) validate these\nproperties by a noisy amplitude-based phase retrieval problem, the latter being\nof much topical interest.Derived from available data via sampling, these\nempirical risk minimization problems are the computational workhorse of a\npopulation risk model which involves the minimization of an expected value of a\nrandom functional. When these minimization problems are nonconvex, the\ncomputation of their globally optimal solutions is elusive. Together with the\nfact that the expectation operator cannot be evaluated for general probability\ndistributions, it becomes necessary to justify whether the stationary solutions\nof the empirical problems are practical approximations of the stationary\nsolution of the population problem. When these two features, general\ndistribution and nonconvexity, are coupled with nondifferentiability that often\nrenders the problems \"non-Clarke regular\", the task of the justification\nbecomes challenging. Our work aims to address such a challenge within an\nalgorithm-free setting. The resulting analysis is therefore different from the\nmuch of the analysis in the recent literature that is based on local search\nalgorithms. Furthermore, supplementing the classical minimizer-centric\nanalysis, our results offer a first step to close the gap between computational\noptimization and asymptotic analysis of coupled nonconvex nonsmooth statistical\nestimation problems, expanding the former with statistical properties of the\npractically obtained solution and providing the latter with a more practical\nfocus pertaining to computational tractability.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 18:25:33 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Qi", "Zhengling", ""], ["Cui", "Ying", ""], ["Liu", "Yufeng", ""], ["Pang", "Jong-Shi", ""]]}, {"id": "1910.02497", "submitter": "Anirban Chaudhuri", "authors": "Anirban Chaudhuri, Alexandre N. Marques, Karen E. Willcox", "title": "mfEGRA: Multifidelity Efficient Global Reliability Analysis through\n  Active Learning for Failure Boundary Location", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops mfEGRA, a multifidelity active learning method using\ndata-driven adaptively refined surrogates for failure boundary location in\nreliability analysis. This work addresses the issue of prohibitive cost of\nreliability analysis using Monte Carlo sampling for expensive-to-evaluate\nhigh-fidelity models by using cheaper-to-evaluate approximations of the\nhigh-fidelity model. The method builds on the Efficient Global Reliability\nAnalysis (EGRA) method, which is a surrogate-based method that uses adaptive\nsampling for refining Gaussian process surrogates for failure boundary location\nusing a single-fidelity model. Our method introduces a two-stage adaptive\nsampling criterion that uses a multifidelity Gaussian process surrogate to\nleverage multiple information sources with different fidelities. The method\ncombines expected feasibility criterion from EGRA with one-step lookahead\ninformation gain to refine the surrogate around the failure boundary. The\ncomputational savings from mfEGRA depends on the discrepancy between the\ndifferent models, and the relative cost of evaluating the different models as\ncompared to the high-fidelity model. We show that accurate estimation of\nreliability using mfEGRA leads to computational savings of $\\sim$46% for an\nanalytic multimodal test problem and 24% for a three-dimensional acoustic horn\nproblem, when compared to single-fidelity EGRA. We also show the effect of\nusing a priori drawn Monte Carlo samples in the implementation for the acoustic\nhorn problem, where mfEGRA leads to computational savings of 45% for the\nthree-dimensional case and 48% for a rarer event four-dimensional case as\ncompared to single-fidelity EGRA.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 18:37:12 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 22:08:27 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 15:32:10 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 19:35:03 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Chaudhuri", "Anirban", ""], ["Marques", "Alexandre N.", ""], ["Willcox", "Karen E.", ""]]}, {"id": "1910.02498", "submitter": "Milan Straka", "authors": "Milan Straka, Pasquale De Falco, Gabriella Ferruzzi, Daniela Proto,\n  Gijs van der Poel, Shahab Khormali, \\v{L}ubo\\v{s} Buzna", "title": "Predicting popularity of EV charging infrastructure from GIS data", "comments": null, "journal-ref": "IEEE Access ( Volume: 8 ) 2020", "doi": "10.1109/ACCESS.2020.2965621", "report-no": null, "categories": "stat.AP cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of charging infrastructure is essential for large-scale\nadoption of electric vehicles (EV). Charging patterns and the utilization of\ninfrastructure have consequences not only for the energy demand, loading local\npower grids but influence the economic returns, parking policies and further\nadoption of EVs. We develop a data-driven approach that is exploiting\npredictors compiled from GIS data describing the urban context and urban\nactivities near charging infrastructure to explore correlations with a\ncomprehensive set of indicators measuring the performance of charging\ninfrastructure. The best fit was identified for the size of the unique group of\nvisitors (popularity) attracted by the charging infrastructure. Consecutively,\ncharging infrastructure is ranked by popularity. The question of whether or not\na given charging spot belongs to the top tier is posed as a binary\nclassification problem and predictive performance of logistic regression\nregularized with an l-1 penalty, random forests and gradient boosted regression\ntrees is evaluated. Obtained results indicate that the collected predictors\ncontain information that can be used to predict the popularity of charging\ninfrastructure. The significance of predictors and how they are linked with the\npopularity are explored as well. The proposed methodology can be used to inform\ncharging infrastructure deployment strategies.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 18:38:40 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Straka", "Milan", ""], ["De Falco", "Pasquale", ""], ["Ferruzzi", "Gabriella", ""], ["Proto", "Daniela", ""], ["van der Poel", "Gijs", ""], ["Khormali", "Shahab", ""], ["Buzna", "\u013dubo\u0161", ""]]}, {"id": "1910.02505", "submitter": "Philip Versteeg", "authors": "Philip Versteeg, Joris M. Mooij", "title": "Boosting Local Causal Discovery in High-Dimensional Expression Data", "comments": "Accepted at BIBM / CABB 2019", "journal-ref": "2019 IEEE Intl. Conf. Bioinf. and Biomed. (BIBM 2019) pp.\n  2599-2604", "doi": "10.1109/BIBM47256.2019.8983232", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of Local Causal Discovery (LCD), a simple and\nefficient constraint-based method for causal discovery, in predicting causal\neffects in large-scale gene expression data. We construct practical estimators\nspecific to the high-dimensional regime. Inspired by the ICP algorithm, we use\nan optional preselection method and two different statistical tests.\nEmpirically, the resulting LCD estimator is seen to closely approach the\naccuracy of ICP, the state-of-the-art method, while it is algorithmically\nsimpler and computationally more efficient.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 19:16:23 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 16:19:35 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Versteeg", "Philip", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1910.02509", "submitter": "Tyler Hayes", "authors": "Tyler L. Hayes, Kushal Kafle, Robik Shrestha, Manoj Acharya,\n  Christopher Kanan", "title": "REMIND Your Neural Network to Prevent Catastrophic Forgetting", "comments": "To appear in the European Conference on Computer Vision (ECCV-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People learn throughout life. However, incrementally updating conventional\nneural networks leads to catastrophic forgetting. A common remedy is replay,\nwhich is inspired by how the brain consolidates memory. Replay involves\nfine-tuning a network on a mixture of new and old instances. While there is\nneuroscientific evidence that the brain replays compressed memories, existing\nmethods for convolutional networks replay raw images. Here, we propose REMIND,\na brain-inspired approach that enables efficient replay with compressed\nrepresentations. REMIND is trained in an online manner, meaning it learns one\nexample at a time, which is closer to how humans learn. Under the same\nconstraints, REMIND outperforms other methods for incremental class learning on\nthe ImageNet ILSVRC-2012 dataset. We probe REMIND's robustness to data ordering\nschemes known to induce catastrophic forgetting. We demonstrate REMIND's\ngenerality by pioneering online learning for Visual Question Answering (VQA).\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 19:48:23 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 16:58:09 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 17:10:44 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Hayes", "Tyler L.", ""], ["Kafle", "Kushal", ""], ["Shrestha", "Robik", ""], ["Acharya", "Manoj", ""], ["Kanan", "Christopher", ""]]}, {"id": "1910.02519", "submitter": "Donglin Zhan", "authors": "Shiyu Yi, Donglin Zhan, Wenqing Zhang, Denglin Jiang, Hao Wang", "title": "FIS-GAN: GAN with Flow-based Importance Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) training process, in most cases, apply\nUniform or Gaussian sampling methods in the latent space, which probably spends\nmost of the computation on examples that can be properly handled and easy to\ngenerate. Theoretically, importance sampling speeds up stochastic optimization\nin supervised learning by prioritizing training examples. In this paper, we\nexplore the possibility of adapting importance sampling into adversarial\nlearning. We use importance sampling to replace Uniform and Gaussian sampling\nmethods in the latent space and employ normalizing flow to approximate latent\nspace posterior distribution by density estimation. Empirically, results on\nMNIST and Fashion-MNIST demonstrate that our method significantly accelerates\nGAN's optimization while retaining visual fidelity in generated samples.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 20:34:52 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 09:20:36 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Yi", "Shiyu", ""], ["Zhan", "Donglin", ""], ["Zhang", "Wenqing", ""], ["Jiang", "Denglin", ""], ["Wang", "Hao", ""]]}, {"id": "1910.02532", "submitter": "Jesse Geerts", "authors": "Jesse P. Geerts, Kimberly L. Stachenfeld, Neil Burgess", "title": "Probabilistic Successor Representations with Kalman Temporal Differences", "comments": "Conference on Cognitive Computational Neuroscience", "journal-ref": null, "doi": "10.32470/CCN.2019.1323-0", "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of Reinforcement Learning (RL) depends on an animal's\nability to assign credit for rewards to the appropriate preceding stimuli. One\naspect of understanding the neural underpinnings of this process involves\nunderstanding what sorts of stimulus representations support generalisation.\nThe Successor Representation (SR), which enforces generalisation over states\nthat predict similar outcomes, has become an increasingly popular model in this\nspace of inquiries. Another dimension of credit assignment involves\nunderstanding how animals handle uncertainty about learned associations, using\nprobabilistic methods such as Kalman Temporal Differences (KTD). Combining\nthese approaches, we propose using KTD to estimate a distribution over the SR.\nKTD-SR captures uncertainty about the estimated SR as well as covariances\nbetween different long-term predictions. We show that because of this, KTD-SR\nexhibits partial transition revaluation as humans do in this experiment without\nadditional replay, unlike the standard TD-SR algorithm. We conclude by\ndiscussing future applications of the KTD-SR as a model of the interaction\nbetween predictive and probabilistic animal reasoning.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 21:32:46 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Geerts", "Jesse P.", ""], ["Stachenfeld", "Kimberly L.", ""], ["Burgess", "Neil", ""]]}, {"id": "1910.02544", "submitter": "Yikuan Li", "authors": "Haotian Liu, Lin Xi, Ying Zhao and Zhixiang Li", "title": "Using Deep Learning and Machine Learning to Detect Epileptic Seizure\n  with Electroencephalography (EEG) Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of epileptic seizure has always been extremely challenging in\nmedical domain. However, as the development of computer technology, the\napplication of machine learning introduced new ideas for seizure forecasting.\nApplying machine learning model onto the predication of epileptic seizure could\nhelp us obtain a better result and there have been plenty of scientists who\nhave been doing such works so that there are sufficient medical data provided\nfor researchers to do training of machine learning models.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 22:53:28 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Liu", "Haotian", ""], ["Xi", "Lin", ""], ["Zhao", "Ying", ""], ["Li", "Zhixiang", ""]]}, {"id": "1910.02545", "submitter": "Yikuan Li", "authors": "Zhiheng Li, Xinyue Xing, Bingzhang Lu and Zhixiang Li", "title": "Early Prediction of 30-day ICU Re-admissions Using Natural Language\n  Processing and Machine Learning", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ICU readmission is associated with longer hospitalization, mortality and\nadverse outcomes. An early recognition of ICU re-admission can help prevent\npatients from worse situation and lower treatment cost. As the abundance of\nElectronics Health Records (EHR), it is popular to design clinical decision\ntools with machine learning technique manipulating on healthcare large scale\ndata. We designed data-driven predictive models to estimate the risk of ICU\nreadmission. The discharge summary of each hospital admission was carefully\nrepresented by natural language processing techniques. Unified Medical Language\nSystem (UMLS) was further used to standardize inconsistency of discharge\nsummaries. 5 machine learning classifiers were adopted to construct predictive\nmodels. The best configuration yielded a competitive AUC of 0.748. Our work\nsuggests that natural language processing of discharge summaries is capable to\nsend clinicians warning of unplanned 30-day readmission upon discharge.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 22:54:00 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Li", "Zhiheng", ""], ["Xing", "Xinyue", ""], ["Lu", "Bingzhang", ""], ["Li", "Zhixiang", ""]]}, {"id": "1910.02548", "submitter": "Long Zhao", "authors": "Yu Tian, Long Zhao, Xi Peng, Dimitris N. Metaxas", "title": "Rethinking Kernel Methods for Node Representation Learning on Graphs", "comments": "Accepted to NeurIPS 2019. The first two authors contributed equally.\n  The source code is publicly available at\n  https://github.com/bluer555/KernelGCN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph kernels are kernel methods measuring graph similarity and serve as a\nstandard tool for graph classification. However, the use of kernel methods for\nnode classification, which is a related problem to graph representation\nlearning, is still ill-posed and the state-of-the-art methods are heavily based\non heuristics. Here, we present a novel theoretical kernel-based framework for\nnode classification that can bridge the gap between these two representation\nlearning problems on graphs. Our approach is motivated by graph kernel\nmethodology but extended to learn the node representations capturing the\nstructural information in a graph. We theoretically show that our formulation\nis as powerful as any positive semidefinite kernels. To efficiently learn the\nkernel, we propose a novel mechanism for node feature aggregation and a\ndata-driven similarity metric employed during the training phase. More\nimportantly, our framework is flexible and complementary to other graph-based\ndeep learning models, e.g., Graph Convolutional Networks (GCNs). We empirically\nevaluate our approach on a number of standard node classification benchmarks,\nand demonstrate that our model sets the new state of the art.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 23:06:49 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Tian", "Yu", ""], ["Zhao", "Long", ""], ["Peng", "Xi", ""], ["Metaxas", "Dimitris N.", ""]]}, {"id": "1910.02551", "submitter": "Ilia Sucholutsky", "authors": "Ilia Sucholutsky, Matthias Schonlau", "title": "Soft-Label Dataset Distillation and Text Dataset Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataset distillation is a method for reducing dataset sizes by learning a\nsmall number of synthetic samples containing all the information of a large\ndataset. This has several benefits like speeding up model training, reducing\nenergy consumption, and reducing required storage space. Currently, each\nsynthetic sample is assigned a single `hard' label, and also, dataset\ndistillation can currently only be used with image data.\n  We propose to simultaneously distill both images and their labels, thus\nassigning each synthetic sample a `soft' label (a distribution of labels). Our\nalgorithm increases accuracy by 2-4% over the original algorithm for several\nimage classification tasks. Using `soft' labels also enables distilled datasets\nto consist of fewer samples than there are classes as each sample can encode\ninformation for multiple classes. For example, training a LeNet model with 10\ndistilled images (one per class) results in over 96% accuracy on MNIST, and\nalmost 92% accuracy when trained on just 5 distilled images.\n  We also extend the dataset distillation algorithm to distill sequential\ndatasets including texts. We demonstrate that text distillation outperforms\nother methods across multiple datasets. For example, models attain almost their\noriginal accuracy on the IMDB sentiment analysis task using just 20 distilled\nsentences.\n  Our code can be found at\n$\\href{https://github.com/ilia10000/dataset-distillation}{\\text{https://github.com/ilia10000/dataset-distillation}}$.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 23:57:22 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 21:01:12 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 04:09:03 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Sucholutsky", "Ilia", ""], ["Schonlau", "Matthias", ""]]}, {"id": "1910.02558", "submitter": "Urmish Thakker", "authors": "Urmish Thakker, Igor Fedorov, Jesse Beu, Dibakar Gope, Chu Zhou,\n  Ganesh Dasika, Matthew Mattina", "title": "Pushing the limits of RNN Compression", "comments": "6 pages. arXiv admin note: substantial text overlap with\n  arXiv:1906.02876", "journal-ref": "5th edition of Workshop on Energy Efficient Machine Learning and\n  Cognitive Computing at NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNN) can be difficult to deploy on resource\nconstrained devices due to their size. As a result, there is a need for\ncompression techniques that can significantly compress RNNs without negatively\nimpacting task accuracy. This paper introduces a method to compress RNNs for\nresource constrained environments using Kronecker product (KP). KPs can\ncompress RNN layers by 16-38x with minimal accuracy loss. We show that KP can\nbeat the task accuracy achieved by other state-of-the-art compression\ntechniques (pruning and low-rank matrix factorization) across 4 benchmarks\nspanning 3 different applications, while simultaneously improving inference\nrun-time.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 04:00:33 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 16:29:36 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Thakker", "Urmish", ""], ["Fedorov", "Igor", ""], ["Beu", "Jesse", ""], ["Gope", "Dibakar", ""], ["Zhou", "Chu", ""], ["Dasika", "Ganesh", ""], ["Mattina", "Matthew", ""]]}, {"id": "1910.02560", "submitter": "Wenju Xu", "authors": "Wenju Xu and Shawn Keshmiri and Guanghui Wang", "title": "Stacked Wasserstein Autoencoder", "comments": "arXiv admin note: text overlap with arXiv:1902.05581", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximating distributions over complicated manifolds, such as natural\nimages, are conceptually attractive. The deep latent variable model, trained\nusing variational autoencoders and generative adversarial networks, is now a\nkey technique for representation learning. However, it is difficult to unify\nthese two models for exact latent-variable inference and parallelize both\nreconstruction and sampling, partly due to the regularization under the latent\nvariables, to match a simple explicit prior distribution. These approaches are\nprone to be oversimplified, and can only characterize a few modes of the true\ndistribution. Based on the recently proposed Wasserstein autoencoder (WAE) with\na new regularization as an optimal transport. The paper proposes a stacked\nWasserstein autoencoder (SWAE) to learn a deep latent variable model. SWAE is a\nhierarchical model, which relaxes the optimal transport constraints at two\nstages. At the first stage, the SWAE flexibly learns a representation\ndistribution, i.e., the encoded prior; and at the second stage, the encoded\nrepresentation distribution is approximated with a latent variable model under\nthe regularization encouraging the latent distribution to match the explicit\nprior. This model allows us to generate natural textual outputs as well as\nperform manipulations in the latent space to induce changes in the output\nspace. Both quantitative and qualitative results demonstrate the superior\nperformance of SWAE compared with the state-of-the-art approaches in terms of\nfaithful reconstruction and generation quality.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 17:07:42 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Xu", "Wenju", ""], ["Keshmiri", "Shawn", ""], ["Wang", "Guanghui", ""]]}, {"id": "1910.02574", "submitter": "Tong Wu", "authors": "Tong Wu, Yunlong Wang, Yue Wang, Emily Zhao, Yilian Yuan, Zhi Yang", "title": "Representation Learning of EHR Data via Graph-Based Medical Entity\n  Embedding", "comments": "5 pages, 2 figures, NeurIPS 2019 Graph Representation Learning\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic representation learning of key entities in electronic health record\n(EHR) data is a critical step for healthcare informatics that turns\nheterogeneous medical records into structured and actionable information. Here\nwe propose ME2Vec, an algorithmic framework for learning low-dimensional\nvectors of the most common entities in EHR: medical services, doctors, and\npatients. ME2Vec leverages diverse graph embedding techniques to cater for the\nunique characteristic of each medical entity. Using real-world clinical data,\nwe demonstrate the efficacy of ME2Vec over competitive baselines on disease\ndiagnosis prediction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 02:01:32 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Wu", "Tong", ""], ["Wang", "Yunlong", ""], ["Wang", "Yue", ""], ["Zhao", "Emily", ""], ["Yuan", "Yilian", ""], ["Yang", "Zhi", ""]]}, {"id": "1910.02575", "submitter": "Yuening Li", "authors": "Yuening Li, Daochen Zha, Na Zou, Xia Hu", "title": "PyODDS: An End-to-End Outlier Detection System", "comments": "6 Pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PyODDS is an end-to end Python system for outlier detection with database\nsupport. PyODDS provides outlier detection algorithms which meet the demands\nfor users in different fields, w/wo data science or machine learning\nbackground. PyODDS gives the ability to execute machine learning algorithms\nin-database without moving data out of the database server or over the network.\nIt also provides access to a wide range of outlier detection algorithms,\nincluding statistical analysis and more recent deep learning based approaches.\nPyODDS is released under the MIT open-source license, and currently available\nat (https://github.com/datamllab/pyodds) with official documentations at\n(https://pyodds.github.io/).\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 02:01:34 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 04:49:16 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Li", "Yuening", ""], ["Zha", "Daochen", ""], ["Zou", "Na", ""], ["Hu", "Xia", ""]]}, {"id": "1910.02578", "submitter": "Olivia Choudhury", "authors": "Olivia Choudhury, Aris Gkoulalas-Divanis, Theodoros Salonidis, Issa\n  Sylla, Yoonyoung Park, Grace Hsu, Amar Das", "title": "Differential Privacy-enabled Federated Learning for Sensitive Health\n  Data", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging real-world health data for machine learning tasks requires\naddressing many practical challenges, such as distributed data silos, privacy\nconcerns with creating a centralized database from person-specific sensitive\ndata, resource constraints for transferring and integrating data from multiple\nsites, and risk of a single point of failure. In this paper, we introduce a\nfederated learning framework that can learn a global model from distributed\nhealth data held locally at different sites. The framework offers two levels of\nprivacy protection. First, it does not move or share raw data across sites or\nwith a centralized server during the model training process. Second, it uses a\ndifferential privacy mechanism to further protect the model from potential\nprivacy attacks. We perform a comprehensive evaluation of our approach on two\nhealthcare applications, using real-world electronic health data of 1 million\npatients. We demonstrate the feasibility and effectiveness of the federated\nlearning framework in offering an elevated level of privacy and maintaining\nutility of the global model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 02:10:30 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 08:29:33 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 15:59:56 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Choudhury", "Olivia", ""], ["Gkoulalas-Divanis", "Aris", ""], ["Salonidis", "Theodoros", ""], ["Sylla", "Issa", ""], ["Park", "Yoonyoung", ""], ["Hsu", "Grace", ""], ["Das", "Amar", ""]]}, {"id": "1910.02591", "submitter": "Ming Zhou", "authors": "Ming Zhou, Jiarui Jin, Weinan Zhang, Zhiwei Qin, Yan Jiao, Chenxi\n  Wang, Guobin Wu, Yong Yu, Jieping Ye", "title": "Multi-Agent Reinforcement Learning for Order-dispatching via\n  Order-Vehicle Distribution Matching", "comments": "9 pages,13 figures", "journal-ref": null, "doi": "10.1145/3357384.3357799", "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the efficiency of dispatching orders to vehicles is a research\nhotspot in online ride-hailing systems. Most of the existing solutions for\norder-dispatching are centralized controlling, which require to consider all\npossible matches between available orders and vehicles. For large-scale\nride-sharing platforms, there are thousands of vehicles and orders to be\nmatched at every second which is of very high computational cost. In this\npaper, we propose a decentralized execution order-dispatching method based on\nmulti-agent reinforcement learning to address the large-scale order-dispatching\nproblem. Different from the previous cooperative multi-agent reinforcement\nlearning algorithms, in our method, all agents work independently with the\nguidance from an evaluation of the joint policy since there is no need for\ncommunication or explicit cooperation between agents. Furthermore, we use\nKL-divergence optimization at each time step to speed up the learning process\nand to balance the vehicles (supply) and orders (demand). Experiments on both\nthe explanatory environment and real-world simulator show that the proposed\nmethod outperforms the baselines in terms of accumulated driver income (ADI)\nand Order Response Rate (ORR) in various traffic environments. Besides, with\nthe support of the online platform of Didi Chuxing, we designed a hybrid system\nto deploy our model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 03:32:41 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhou", "Ming", ""], ["Jin", "Jiarui", ""], ["Zhang", "Weinan", ""], ["Qin", "Zhiwei", ""], ["Jiao", "Yan", ""], ["Wang", "Chenxi", ""], ["Wu", "Guobin", ""], ["Yu", "Yong", ""], ["Ye", "Jieping", ""]]}, {"id": "1910.02594", "submitter": "Jun Li", "authors": "Hongyu Guo, Khalique Newaz, Scott Emrich, Tijana Milenkovic, Jun Li", "title": "Weighted graphlets and deep neural networks for protein structure\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As proteins with similar structures often have similar functions, analysis of\nprotein structures can help predict protein functions and is thus important. We\nconsider the problem of protein structure classification, which computationally\nclassifies the structures of proteins into pre-defined groups. We develop a\nweighted network that depicts the protein structures, and more importantly, we\npropose the first graphlet-based measure that applies to weighted networks.\nFurther, we develop a deep neural network (DNN) composed of both convolutional\nand recurrent layers to use this measure for classification. Put together, our\napproach shows dramatic improvements in performance over existing\ngraphlet-based approaches on 36 real datasets. Even comparing with the\nstate-of-the-art approach, it almost halves the classification error. In\naddition to protein structure networks, our weighted-graphlet measure and DNN\nclassifier can potentially be applied to classification of other weighted\nnetworks in computational biology as well as in other domains.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 03:36:25 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Guo", "Hongyu", ""], ["Newaz", "Khalique", ""], ["Emrich", "Scott", ""], ["Milenkovic", "Tijana", ""], ["Li", "Jun", ""]]}, {"id": "1910.02600", "submitter": "Alexander Amini", "authors": "Alexander Amini, Wilko Schwarting, Ava Soleimany, Daniela Rus", "title": "Deep Evidential Regression", "comments": "Code available on: https://github.com/aamini/evidential-deep-learning", "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deterministic neural networks (NNs) are increasingly being deployed in safety\ncritical domains, where calibrated, robust, and efficient measures of\nuncertainty are crucial. In this paper, we propose a novel method for training\nnon-Bayesian NNs to estimate a continuous target as well as its associated\nevidence in order to learn both aleatoric and epistemic uncertainty. We\naccomplish this by placing evidential priors over the original Gaussian\nlikelihood function and training the NN to infer the hyperparameters of the\nevidential distribution. We additionally impose priors during training such\nthat the model is regularized when its predicted evidence is not aligned with\nthe correct output. Our method does not rely on sampling during inference or on\nout-of-distribution (OOD) examples for training, thus enabling efficient and\nscalable uncertainty learning. We demonstrate learning well-calibrated measures\nof uncertainty on various benchmarks, scaling to complex computer vision tasks,\nas well as robustness to adversarial and OOD test samples.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 04:11:34 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 16:37:04 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Amini", "Alexander", ""], ["Schwarting", "Wilko", ""], ["Soleimany", "Ava", ""], ["Rus", "Daniela", ""]]}, {"id": "1910.02612", "submitter": "Yuanpeng Li", "authors": "Yuanpeng Li, Liang Zhao, Jianyu Wang, Joel Hestness", "title": "Compositional Generalization for Primitive Substitutions", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositional generalization is a basic mechanism in human language learning,\nbut current neural networks lack such ability. In this paper, we conduct\nfundamental research for encoding compositionality in neural networks.\nConventional methods use a single representation for the input sentence, making\nit hard to apply prior knowledge of compositionality. In contrast, our approach\nleverages such knowledge with two representations, one generating attention\nmaps, and the other mapping attended input words to output symbols. We reduce\nthe entropy in each representation to improve generalization. Our experiments\ndemonstrate significant improvements over the conventional methods in five NLP\ntasks including instruction learning and machine translation. In the SCAN\ndomain, it boosts accuracies from 14.0% to 98.8% in Jump task, and from 92.0%\nto 99.7% in TurnLeft task. It also beats human performance on a few-shot\nlearning task. We hope the proposed approach can help ease future research\ntowards human-level compositional language learning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 05:27:27 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Li", "Yuanpeng", ""], ["Zhao", "Liang", ""], ["Wang", "Jianyu", ""], ["Hestness", "Joel", ""]]}, {"id": "1910.02629", "submitter": "Zhenyue Qin", "authors": "Zhenyue Qin and Dongwoo Kim", "title": "Softmax Is Not an Artificial Trick: An Information-Theoretic View of\n  Softmax in Neural Networks", "comments": "Withdrawn due to Zhenyue Qin uploading the manuscript without consent\n  of the other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite great popularity of applying softmax to map the non-normalised\noutputs of a neural network to a probability distribution over predicting\nclasses, this normalised exponential transformation still seems to be\nartificial. A theoretic framework that incorporates softmax as an intrinsic\ncomponent is still lacking. In this paper, we view neural networks embedding\nsoftmax from an information-theoretic perspective. Under this view, we can\nnaturally and mathematically derive log-softmax as an inherent component in a\nneural network for evaluating the conditional mutual information between\nnetwork output vectors and labels given an input datum. We show that training\ndeterministic neural networks through maximising log-softmax is equivalent to\nenlarging the conditional mutual information, i.e., feeding label information\ninto network outputs. We also generalise our informative-theoretic perspective\nto neural networks with stochasticity and derive information upper and lower\nbounds of log-softmax. In theory, such an information-theoretic view offers\nrationality support for embedding softmax in neural networks; in practice, we\neventually demonstrate a computer vision application example of how to employ\nour information-theoretic view to filter out targeted objects on images.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 06:46:06 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 00:34:56 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 05:59:37 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Qin", "Zhenyue", ""], ["Kim", "Dongwoo", ""]]}, {"id": "1910.02633", "submitter": "Josh Payne", "authors": "Josh Payne", "title": "Deep Hyperedges: a Framework for Transductive and Inductive Learning on\n  Hypergraphs", "comments": "9 pages, 4 appendices, accepted at NeurIPS '19 workshop on Sets and\n  Partitions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From social networks to protein complexes to disease genomes to visual data,\nhypergraphs are everywhere. However, the scope of research studying deep\nlearning on hypergraphs is still quite sparse and nascent, as there has not yet\nexisted an effective, unified framework for using hyperedge and vertex\nembeddings jointly in the hypergraph context, despite a large body of prior\nwork that has shown the utility of deep learning over graphs and sets. Building\nupon these recent advances, we propose \\textit{Deep Hyperedges} (DHE), a\nmodular framework that jointly uses contextual and permutation-invariant vertex\nmembership properties of hyperedges in hypergraphs to perform classification\nand regression in transductive and inductive learning settings. In our\nexperiments, we use a novel random walk procedure and show that our model\nachieves and, in most cases, surpasses state-of-the-art performance on\nbenchmark datasets. Additionally, we study our framework's performance on a\nvariety of diverse, non-standard hypergraph datasets and propose several\navenues of future work to further enhance DHE.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 06:56:02 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Payne", "Josh", ""]]}, {"id": "1910.02635", "submitter": "D. H. S. Maithripala", "authors": "Pathmanathan Pankayaraj and D. H. S. Maithripala", "title": "A Decentralized Communication Policy for Multi Agent Multi Armed Bandit\n  Problems", "comments": "This is the full version of a preprint that will appear in the\n  proceedings of the 2020 European Control Conference (ECC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel policy for a group of agents to, individually as\nwell as collectively, solve a multi armed bandit (MAB) problem. The policy\nrelies solely on the information that an agent has obtained through sampling of\nthe options on its own and through communication with neighbors. The option\nselection policy is based on an Upper Confidence Based (UCB) strategy while the\ncommunication strategy that is proposed forces agents to communicate with other\nagents who they believe are most likely to be exploring than exploiting. The\noverall strategy is shown to significantly outperform an independent\nErd\\H{o}s-R\\'{e}nyi (ER) graph based random communication policy. The policy is\nshown to be cost effective in terms of communication and thus to be easily\nscalable to a large network of agents.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 07:05:36 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 06:08:42 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 16:18:33 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Pankayaraj", "Pathmanathan", ""], ["Maithripala", "D. H. S.", ""]]}, {"id": "1910.02646", "submitter": "Mustafa Mukadam", "authors": "Mustafa Mukadam, Ching-An Cheng, Dieter Fox, Byron Boots, Nathan\n  Ratliff", "title": "Riemannian Motion Policy Fusion through Learnable Lyapunov Function\n  Reshaping", "comments": "Conference on Robot Learning (CoRL), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RMPflow is a recently proposed policy-fusion framework based on differential\ngeometry. While RMPflow has demonstrated promising performance, it requires the\nuser to provide sensible subtask policies as Riemannian motion policies (RMPs:\na motion policy and an importance matrix function), which can be a difficult\ndesign problem in its own right. We propose RMPfusion, a variation of RMPflow,\nto address this issue. RMPfusion supplements RMPflow with weight functions that\ncan hierarchically reshape the Lyapunov functions of the subtask RMPs according\nto the current configuration of the robot and environment. This extra\nflexibility can remedy imperfect subtask RMPs provided by the user, improving\nthe combined policy's performance. These weight functions can be learned by\nback-propagation. Moreover, we prove that, under mild restrictions on the\nweight functions, RMPfusion always yields a globally Lyapunov-stable motion\npolicy. This implies that we can treat RMPfusion as a structured policy class\nin policy optimization that is guaranteed to generate stable policies, even\nduring the immature phase of learning. We demonstrate these properties of\nRMPfusion in imitation learning experiments both in simulation and on a\nreal-world robot.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 07:37:34 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 05:34:04 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Mukadam", "Mustafa", ""], ["Cheng", "Ching-An", ""], ["Fox", "Dieter", ""], ["Boots", "Byron", ""], ["Ratliff", "Nathan", ""]]}, {"id": "1910.02653", "submitter": "Ajay Jain", "authors": "Paras Jain, Ajay Jain, Aniruddha Nrusimha, Amir Gholami, Pieter\n  Abbeel, Kurt Keutzer, Ion Stoica, Joseph E. Gonzalez", "title": "Checkmate: Breaking the Memory Wall with Optimal Tensor\n  Rematerialization", "comments": "In Proceedings of 3rd Conference Machine Learning and Systems 2020\n  (MLSys 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We formalize the problem of trading-off DNN training time and memory\nrequirements as the tensor rematerialization optimization problem, a\ngeneralization of prior checkpointing strategies. We introduce Checkmate, a\nsystem that solves for optimal rematerialization schedules in reasonable times\n(under an hour) using off-the-shelf MILP solvers or near-optimal schedules with\nan approximation algorithm, then uses these schedules to accelerate millions of\ntraining iterations. Our method scales to complex, realistic architectures and\nis hardware-aware through the use of accelerator-specific, profile-based cost\nmodels. In addition to reducing training cost, Checkmate enables real-world\nnetworks to be trained with up to 5.1x larger input sizes. Checkmate is an\nopen-source project, available at https://github.com/parasj/checkmate.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 07:54:06 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 17:57:45 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 17:46:43 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Jain", "Paras", ""], ["Jain", "Ajay", ""], ["Nrusimha", "Aniruddha", ""], ["Gholami", "Amir", ""], ["Abbeel", "Pieter", ""], ["Keutzer", "Kurt", ""], ["Stoica", "Ion", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "1910.02660", "submitter": "Jiaxuan Xie", "authors": "Jiaxuan Xie, Fanghui Liu, Kaijie Wang, Xiaolin Huang", "title": "Deep Kernel Learning via Random Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel learning methods are among the most effective learning methods and\nhave been vigorously studied in the past decades. However, when tackling with\ncomplicated tasks, classical kernel methods are not flexible or \"rich\" enough\nto describe the data and hence could not yield satisfactory performance. In\nthis paper, via Random Fourier Features (RFF), we successfully incorporate the\ndeep architecture into kernel learning, which significantly boosts the\nflexibility and richness of kernel machines while keeps kernels' advantage of\npairwise handling small data. With RFF, we could establish a deep structure and\nmake every kernel in RFF layers could be trained end-to-end. Since RFF with\ndifferent distributions could represent different kernels, our model has the\ncapability of finding suitable kernels for each layer, which is much more\nflexible than traditional kernel-based methods where the kernel is\npre-selected. This fact also helps yield a more sophisticated kernel cascade\nconnection in the architecture. On small datasets (less than 1000 samples), for\nwhich deep learning is generally not suitable due to overfitting, our method\nachieves superior performance compared to advanced kernel methods. On\nlarge-scale datasets, including non-image and image classification tasks, our\nmethod also has competitive performance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 08:20:07 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Xie", "Jiaxuan", ""], ["Liu", "Fanghui", ""], ["Wang", "Kaijie", ""], ["Huang", "Xiaolin", ""]]}, {"id": "1910.02672", "submitter": "Wei Qiu", "authors": "Wei Qiu, Jiaming Guo, Xiang Li, Mengjia Xu, Mo Zhang, Ning Guo and\n  Quanzheng Li", "title": "Multi-label Detection and Classification of Red Blood Cells in\n  Microscopic Images", "comments": "Wei Qiu, Jiaming Guo and Xiang Li contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell detection and cell type classification from biomedical images play an\nimportant role for high-throughput imaging and various clinical application.\nWhile classification of single cell sample can be performed with standard\ncomputer vision and machine learning methods, analysis of multi-label samples\n(region containing congregating cells) is more challenging, as separation of\nindividual cells can be difficult (e.g. touching cells) or even impossible\n(e.g. overlapping cells). As multi-instance images are common in analyzing Red\nBlood Cell (RBC) for Sickle Cell Disease (SCD) diagnosis, we develop and\nimplement a multi-instance cell detection and classification framework to\naddress this challenge. The framework firstly trains a region proposal model\nbased on Region-based Convolutional Network (RCNN) to obtain bounding-boxes of\nregions potentially containing single or multiple cells from input microscopic\nimages, which are extracted as image patches. High-level image features are\nthen calculated from image patches through a pre-trained Convolutional Neural\nNetwork (CNN) with ResNet-50 structure. Using these image features inputs, six\nnetworks are then trained to make multi-label prediction of whether a given\npatch contains cells belonging to a specific cell type. As the six networks are\ntrained with image patches consisting of both individual cells and\ntouching/overlapping cells, they can effectively recognize cell types that are\npresented in multi-instance image samples. Finally, for the purpose of SCD\ntesting, we train another machine learning classifier to predict whether the\ngiven image patch contains abnormal cell type based on outputs from the six\nnetworks. Testing result of the proposed framework shows that it can achieve\ngood performance in automatic cell detection and classification.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 08:40:49 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 12:44:04 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Qiu", "Wei", ""], ["Guo", "Jiaming", ""], ["Li", "Xiang", ""], ["Xu", "Mengjia", ""], ["Zhang", "Mo", ""], ["Guo", "Ning", ""], ["Li", "Quanzheng", ""]]}, {"id": "1910.02673", "submitter": "Yulong Wang", "authors": "Yulong Wang, Xiaolin Hu, Hang Su", "title": "Interpretable Disentanglement of Neural Networks by Extracting\n  Class-Specific Subnetwork", "comments": "Accepted to 2019 ICCV Workshop on Interpreting and Explaining Visual\n  Artificial Intelligence Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a novel perspective to understand deep neural networks in an\ninterpretable disentanglement form. For each semantic class, we extract a\nclass-specific functional subnetwork from the original full model, with\ncompressed structure while maintaining comparable prediction performance. The\nstructure representations of extracted subnetworks display a resemblance to\ntheir corresponding class semantic similarities. We also apply extracted\nsubnetworks in visual explanation and adversarial example detection tasks by\nmerely replacing the original full model with class-specific subnetworks.\nExperiments demonstrate that this intuitive operation can effectively improve\nexplanation saliency accuracy for gradient-based explanation methods, and\nincrease the detection rate for confidence score-based adversarial example\ndetection methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 08:42:45 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Wang", "Yulong", ""], ["Hu", "Xiaolin", ""], ["Su", "Hang", ""]]}, {"id": "1910.02675", "submitter": "Nico Lang", "authors": "Steve Branson, Jan Dirk Wegner, David Hall, Nico Lang, Konrad\n  Schindler, Pietro Perona", "title": "From Google Maps to a Fine-Grained Catalog of Street trees", "comments": null, "journal-ref": "ISPRS Journal of Photogrammetry and Remote Sensing, Volume 135,\n  January 2018, Pages 13-30", "doi": "10.1016/j.isprsjprs.2017.11.008", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Up-to-date catalogs of the urban tree population are important for\nmunicipalities to monitor and improve quality of life in cities. Despite much\nresearch on automation of tree mapping, mainly relying on dedicated airborne\nLiDAR or hyperspectral campaigns, trees are still mostly mapped manually in\npractice. We present a fully automated tree detection and species recognition\npipeline to process thousands of trees within a few hours using publicly\navailable aerial and street view images of Google MapsTM. These data provide\nrich information (viewpoints, scales) from global tree shapes to bark textures.\nOur work-flow is built around a supervised classification that automatically\nlearns the most discriminative features from thousands of trees and\ncorresponding, public tree inventory data. In addition, we introduce a change\ntracker to keep urban tree inventories up-to-date. Changes of individual trees\nare recognized at city-scale by comparing street-level images of the same tree\nlocation at two different times. Drawing on recent advances in computer vision\nand machine learning, we apply convolutional neural networks (CNN) for all\nclassification tasks. We propose the following pipeline: download all available\npanoramas and overhead images of an area of interest, detect trees per image\nand combine multi-view detections in a probabilistic framework, adding prior\nknowledge; recognize fine-grained species of detected trees. In a later,\nseparate module, track trees over time and identify the type of change. We\nbelieve this is the first work to exploit publicly available image data for\nfine-grained tree mapping at city-scale, respectively over many thousands of\ntrees. Experiments in the city of Pasadena, California, USA show that we can\ndetect > 70% of the street trees, assign correct species to > 80% for 40\ndifferent species, and correctly detect and classify changes in > 90% of the\ncases.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 08:52:50 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Branson", "Steve", ""], ["Wegner", "Jan Dirk", ""], ["Hall", "David", ""], ["Lang", "Nico", ""], ["Schindler", "Konrad", ""], ["Perona", "Pietro", ""]]}, {"id": "1910.02678", "submitter": "Bruno Apolloni", "authors": "Bruno Apolloni", "title": "An Algorithmic Inference Approach to Learn Copulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a new method for estimating the parameter of the bivariate\nClayton copulas within the framework of Algorithmic Inference. The method\nconsists of a variant of the standard boot-strapping procedure for inferring\nrandom parameters, which we expressly devise to bypass the two pitfalls of this\nspecific instance: the non independence of the Kendall statistics, customarily\nat the basis of this inference task, and the absence of a sufficient statistic\nw.r.t. \\alpha. The variant is rooted on a numerical procedure in order to find\nthe \\alpha estimate at a fixed point of an iterative routine. Although paired\nwith the customary complexity of the program which computes them, numerical\nresults show an outperforming accuracy of the estimates.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 09:06:04 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Apolloni", "Bruno", ""]]}, {"id": "1910.02684", "submitter": "Zhou Ziang", "authors": "Ziang Zhou, Jieming Shi, Shengzhong Zhang, Zengfeng Huang, Qing Li", "title": "Effective Semi-Supervised Node Classification on Few-Labeled Graph Data", "comments": "12pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are designed for semi-supervised node\nclassification on graphs where only a small subset of nodes have class labels.\nHowever, under extreme cases when very few labels are available (e.g., 1\nlabeled node per class), GNNs suffer from severe result quality degradation.\nSeveral existing studies make an initial effort to ease this situation, but are\nstill far from satisfactory.\n  In this paper, on few-labeled graph data, we propose an effective framework\nABN that is readily applicable to both shallow and deep GNN architectures and\nsignificantly boosts classification accuracy. In particular, on a benchmark\ndataset Cora with only 1 labeled node per class, while the classic graph\nconvolutional network (GCN) only has 44.6% accuracy, an immediate instantiation\nof ABN over GCN achieves 62.5% accuracy; when applied to a deep architecture\nDAGNN, ABN improves accuracy from 59.8% to 66.4%, which is state of the art.\n  ABN obtains superior performance through three main algorithmic designs.\nFirst, it selects high-quality unlabeled nodes via an adaptive pseudo labeling\ntechnique, so as to adaptively enhance the training process of GNNs. Second,\nABN balances the labels of the selected nodes on real-world skewed graph data\nby pseudo label balancing. Finally, a negative sampling regularizer is designed\nfor ABN to further utilize the unlabeled nodes. The effectiveness of the three\ntechniques in ABN is well-validated by both theoretical and empirical analysis.\nExtensive experiments, comparing 12 existing approaches on 4 benchmark\ndatasets, demonstrate that ABN achieves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 09:21:49 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 06:40:08 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Zhou", "Ziang", ""], ["Shi", "Jieming", ""], ["Zhang", "Shengzhong", ""], ["Huang", "Zengfeng", ""], ["Li", "Qing", ""]]}, {"id": "1910.02686", "submitter": "Yuhui Zhang", "authors": "Zhang Yuhui, Greg Gutmann, Konagaya Akihiko", "title": "Irregular Convolutional Auto-Encoder on Point Clouds", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed a novel graph convolutional neural network that could construct a\ncoarse, sparse latent point cloud from a dense, raw point cloud. With a novel\nnon-isotropic convolution operation defined on irregular geometries, the model\nthen can reconstruct the original point cloud from this latent cloud with fine\ndetails. Furthermore, we proposed that it is even possible to perform particle\nsimulation using the latent cloud encoded from some simulated particle cloud\n(e.g. fluids), to accelerate the particle simulation process. Our model has\nbeen tested on ShapeNetCore dataset for Auto-Encoding with a limited latent\ndimension and tested on a synthesis dataset for fluids simulation. We also\ncompare the model with other state-of-the-art models, and several\nvisualizations were done to intuitively understand the model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 09:24:08 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Yuhui", "Zhang", ""], ["Gutmann", "Greg", ""], ["Akihiko", "Konagaya", ""]]}, {"id": "1910.02702", "submitter": "Ilja Manakov", "authors": "Ilja Manakov, Markus Rohm, Christoph Kern, Benedikt Schworm, Karsten\n  Kortuem, Volker Tresp", "title": "Noise as Domain Shift: Denoising Medical Images by Unpaired Image\n  Translation", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-33391-1_1", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We cast the problem of image denoising as a domain translation problem\nbetween high and low noise domains. By modifying the cycleGAN model, we are\nable to learn a mapping between these domains on unpaired retinal optical\ncoherence tomography images. In quantitative measurements and a qualitative\nevaluation by ophthalmologists, we show how this approach outperforms other\nestablished methods. The results indicate that the network differentiates\nsubtle changes in the level of noise in the image. Further investigation of the\nmodel's feature maps reveals that it has learned to distinguish retinal layers\nand other distinct regions of the images.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 10:16:31 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Manakov", "Ilja", ""], ["Rohm", "Markus", ""], ["Kern", "Christoph", ""], ["Schworm", "Benedikt", ""], ["Kortuem", "Karsten", ""], ["Tresp", "Volker", ""]]}, {"id": "1910.02713", "submitter": "Ilja Manakov", "authors": "Ilja Manakov, Volker Tresp", "title": "Push it to the Limit: Discover Edge-Cases in Image Data with\n  Autoencoders", "comments": "Accepted as a workshop paper at MEDNeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we focus on the problem of identifying semantic factors of\nvariation in large image datasets. By training a convolutional Autoencoder on\nthe image data, we create encodings, which describe each datapoint at a higher\nlevel of abstraction than pixel-space. We then apply Principal Component\nAnalysis to the encodings to disentangle the factors of variation in the data.\nSorting the dataset according to the values of individual principal components,\nwe find that samples at the high and low ends of the distribution often share\nspecific semantic characteristics. We refer to these groups of samples as\nsemantic groups. When applied to real-world data, this method can help discover\nunwanted edge-cases.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 10:36:40 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Manakov", "Ilja", ""], ["Tresp", "Volker", ""]]}, {"id": "1910.02717", "submitter": "Daniele Loiacono", "authors": "Edoardo Giacomello, Daniele Loiacono, Luca Mainardi", "title": "Brain MRI Tumor Segmentation with Adversarial Networks", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207220", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning is a promising approach to either automate or simplify several\ntasks in the healthcare domain. In this work, we introduce SegAN-CAT, an\napproach to brain tumor segmentation in Magnetic Resonance Images (MRI), based\non Adversarial Networks. In particular, we extend SegAN, successfully applied\nto the same task in a previous work, in two respects: (i) we used a different\nmodel input and (ii) we employed a modified loss function to train the model.\nWe tested our approach on two large datasets, made available by the Brain Tumor\nImage Segmentation Benchmark (BraTS). First, we trained and tested some\nsegmentation models assuming the availability of all the major MRI contrast\nmodalities, i.e., T1-weighted, T1 weighted contrast-enhanced, T2-weighted, and\nT2-FLAIR. However, as these four modalities are not always all available for\neach patient, we also trained and tested four segmentation models that take as\ninput MRIs acquired only with a single contrast modality. Finally, we proposed\nto apply transfer learning across different contrast modalities to improve the\nperformance of these single-modality models. Our results are promising and show\nthat not SegAN-CAT is able to outperform SegAN when all the four modalities are\navailable, but also that transfer learning can actually lead to better\nperformances when only a single modality is available.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 10:51:56 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 17:23:27 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Giacomello", "Edoardo", ""], ["Loiacono", "Daniele", ""], ["Mainardi", "Luca", ""]]}, {"id": "1910.02718", "submitter": "Rahaf Aljundi", "authors": "Rahaf Aljundi", "title": "Continual Learning in Neural Networks", "comments": "PhD Thesis, Supervisor: Tinne Tuytelaars", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks have exceeded human-level performance in\naccomplishing several individual tasks (e.g. voice recognition, object\nrecognition, and video games). However, such success remains modest compared to\nhuman intelligence that can learn and perform an unlimited number of tasks.\nHumans' ability of learning and accumulating knowledge over their lifetime is\nan essential aspect of their intelligence. Continual machine learning aims at a\nhigher level of machine intelligence through providing the artificial agents\nwith the ability to learn online from a non-stationary and never-ending stream\nof data. A key component of such a never-ending learning process is to overcome\nthe catastrophic forgetting of previously seen data, a problem that neural\nnetworks are well known to suffer from. The work described in this thesis has\nbeen dedicated to the investigation of continual learning and solutions to\nmitigate the forgetting phenomena in neural networks. To approach the continual\nlearning problem, we first assume a task incremental setting where tasks are\nreceived one at a time and data from previous tasks are not stored. Since the\ntask incremental setting can't be assumed in all continual learning scenarios,\nwe also study the more general online continual setting. We consider an\ninfinite stream of data drawn from a non-stationary distribution with a\nsupervisory or self-supervisory training signal. The proposed methods in this\nthesis have tackled important aspects of continual learning. They were\nevaluated on different benchmarks and over various learning sequences. Advances\nin the state of the art of continual learning have been shown and challenges\nfor bringing continual learning into application were critically identified.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 10:52:14 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 09:48:14 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Aljundi", "Rahaf", ""]]}, {"id": "1910.02720", "submitter": "Sergey Bartunov", "authors": "Sergey Bartunov, Jack W Rae, Simon Osindero, Timothy P Lillicrap", "title": "Meta-Learning Deep Energy-Based Memory Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning associative memory -- a system which is able\nto retrieve a remembered pattern based on its distorted or incomplete version.\nAttractor networks provide a sound model of associative memory: patterns are\nstored as attractors of the network dynamics and associative retrieval is\nperformed by running the dynamics starting from a query pattern until it\nconverges to an attractor. In such models the dynamics are often implemented as\nan optimization procedure that minimizes an energy function, such as in the\nclassical Hopfield network. In general it is difficult to derive a writing rule\nfor a given dynamics and energy that is both compressive and fast. Thus, most\nresearch in energy-based memory has been limited either to tractable energy\nmodels not expressive enough to handle complex high-dimensional objects such as\nnatural images, or to models that do not offer fast writing. We present a novel\nmeta-learning approach to energy-based memory models (EBMM) that allows one to\nuse an arbitrary neural architecture as an energy model and quickly store\npatterns in its weights. We demonstrate experimentally that our EBMM approach\ncan build compressed memories for synthetic and natural data, and is capable of\nassociative retrieval that outperforms existing memory systems in terms of the\nreconstruction error and compression rate.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 10:58:08 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 08:34:53 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Bartunov", "Sergey", ""], ["Rae", "Jack W", ""], ["Osindero", "Simon", ""], ["Lillicrap", "Timothy P", ""]]}, {"id": "1910.02724", "submitter": "Pengfei Li", "authors": "Pengfei Li, Kezhi Mao, Xuefeng Yang, and Qi Li", "title": "Improving Relation Extraction with Knowledge-attention", "comments": "Paper presented at 2019 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2019)", "journal-ref": null, "doi": "10.18653/v1/D19-1022", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While attention mechanisms have been proven to be effective in many NLP\ntasks, majority of them are data-driven. We propose a novel knowledge-attention\nencoder which incorporates prior knowledge from external lexical resources into\ndeep neural networks for relation extraction task. Furthermore, we present\nthree effective ways of integrating knowledge-attention with self-attention to\nmaximize the utilization of both knowledge and data. The proposed relation\nextraction system is end-to-end and fully attention-based. Experiment results\nshow that the proposed knowledge-attention mechanism has complementary\nstrengths with self-attention, and our integrated models outperform existing\nCNN, RNN, and self-attention based models. State-of-the-art performance is\nachieved on TACRED, a complex and large-scale relation extraction dataset.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 11:08:24 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 11:55:18 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Li", "Pengfei", ""], ["Mao", "Kezhi", ""], ["Yang", "Xuefeng", ""], ["Li", "Qi", ""]]}, {"id": "1910.02743", "submitter": "Anton Dereventsov", "authors": "Armenak Petrosyan, Anton Dereventsov, Clayton Webster", "title": "Neural network integral representations with the ReLU activation\n  function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this effort, we derive a formula for the integral representation of a\nshallow neural network with the ReLU activation function. We assume that the\nouter weighs admit a finite $L_1$-norm with respect to Lebesgue measure on the\nsphere. For univariate target functions we further provide a closed-form\nformula for all possible representations. Additionally, in this case our\nformula allows one to explicitly solve the least $L_1$-norm neural network\nrepresentation for a given function.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 12:00:37 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 08:05:43 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 03:13:22 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Petrosyan", "Armenak", ""], ["Dereventsov", "Anton", ""], ["Webster", "Clayton", ""]]}, {"id": "1910.02754", "submitter": "Vikas Raunak", "authors": "Vikas Raunak, Sang Keun Choe, Quanyang Lu, Yi Xu, Florian Metze", "title": "On Leveraging the Visual Modality for Neural Machine Translation", "comments": "Accepted to INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging the visual modality effectively for Neural Machine Translation\n(NMT) remains an open problem in computational linguistics. Recently, Caglayan\net al. posit that the observed gains are limited mainly due to the very simple,\nshort, repetitive sentences of the Multi30k dataset (the only multimodal MT\ndataset available at the time), which renders the source text sufficient for\ncontext. In this work, we further investigate this hypothesis on a new large\nscale multimodal Machine Translation (MMT) dataset, How2, which has 1.57 times\nlonger mean sentence length than Multi30k and no repetition. We propose and\nevaluate three novel fusion techniques, each of which is designed to ensure the\nutilization of visual context at different stages of the Sequence-to-Sequence\ntransduction pipeline, even under full linguistic context. However, we still\nobtain only marginal gains under full linguistic context and posit that visual\nembeddings extracted from deep vision models (ResNet for Multi30k, ResNext for\nHow2) do not lend themselves to increasing the discriminativeness between the\nvocabulary elements at token level prediction in NMT. We demonstrate this\nqualitatively by analyzing attention distribution and quantitatively through\nPrincipal Component Analysis, arriving at the conclusion that it is the quality\nof the visual embeddings rather than the length of sentences, which need to be\nimproved in existing MMT datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 12:42:09 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Raunak", "Vikas", ""], ["Choe", "Sang Keun", ""], ["Lu", "Quanyang", ""], ["Xu", "Yi", ""], ["Metze", "Florian", ""]]}, {"id": "1910.02757", "submitter": "Leonardo Cella", "authors": "Leonardo Cella and Nicol\\`o Cesa-Bianchi", "title": "Stochastic Bandits with Delay-Dependent Payoffs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recommendation problems in music streaming platforms, we propose\na nonstationary stochastic bandit model in which the expected reward of an arm\ndepends on the number of rounds that have passed since the arm was last pulled.\nAfter proving that finding an optimal policy is NP-hard even when all model\nparameters are known, we introduce a class of ranking policies provably\napproximating, to within a constant factor, the expected reward of the optimal\npolicy. We show an algorithm whose regret with respect to the best ranking\npolicy is bounded by $\\widetilde{\\mathcal{O}}\\big(\\!\\sqrt{kT}\\big)$, where $k$\nis the number of arms and $T$ is time. Our algorithm uses only\n$\\mathcal{O}\\big(k\\ln\\ln T\\big)$ switches, which helps when switching between\npolicies is costly. As constructing the class of learning policies requires\nordering the arms according to their expectations, we also bound the number of\npulls required to do so. Finally, we run experiments to compare our algorithm\nagainst UCB on different problem instances.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 12:48:39 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 18:28:04 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 19:20:10 GMT"}, {"version": "v4", "created": "Wed, 19 Feb 2020 10:38:37 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Cella", "Leonardo", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""]]}, {"id": "1910.02758", "submitter": "Hector Zenil", "authors": "Santiago Hern\\'andez-Orozco, Hector Zenil, J\\\"urgen Riedel, Adam\n  Uccello, Narsis A. Kiani, Jesper Tegn\\'er", "title": "Algorithmic Probability-guided Supervised Machine Learning on\n  Non-differentiable Spaces", "comments": "33 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how complexity theory can be introduced in machine learning to help\nbring together apparently disparate areas of current research. We show that\nthis new approach requires less training data and is more generalizable as it\nshows greater resilience to random attacks. We investigate the shape of the\ndiscrete algorithmic space when performing regression or classification using a\nloss function parametrized by algorithmic complexity, demonstrating that the\nproperty of differentiation is not necessary to achieve results similar to\nthose obtained using differentiable programming approaches such as deep\nlearning. In doing so we use examples which enable the two approaches to be\ncompared (small, given the computational power required for estimations of\nalgorithmic complexity). We find and report that (i) machine learning can\nsuccessfully be performed on a non-smooth surface using algorithmic complexity;\n(ii) that parameter solutions can be found using an algorithmic-probability\nclassifier, establishing a bridge between a fundamentally discrete theory of\ncomputability and a fundamentally continuous mathematical theory of\noptimization methods; (iii) a formulation of an algorithmically directed search\ntechnique in non-smooth manifolds can be defined and conducted; (iv)\nexploitation techniques and numerical methods for algorithmic search to\nnavigate these discrete non-differentiable spaces can be performed; in\napplication of the (a) identification of generative rules from data\nobservations; (b) solutions to image classification problems more resilient\nagainst pixel attacks compared to neural networks; (c) identification of\nequation parameters from a small data-set in the presence of noise in\ncontinuous ODE system problem, (d) classification of Boolean NK networks by (1)\nnetwork topology, (2) underlying Boolean function, and (3) number of incoming\nedges.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 12:48:58 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 23:41:44 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Hern\u00e1ndez-Orozco", "Santiago", ""], ["Zenil", "Hector", ""], ["Riedel", "J\u00fcrgen", ""], ["Uccello", "Adam", ""], ["Kiani", "Narsis A.", ""], ["Tegn\u00e9r", "Jesper", ""]]}, {"id": "1910.02760", "submitter": "Adri\\'an Csisz\\'arik", "authors": "Adri\\'an Csisz\\'arik, Beatrix Benk\\H{o}, D\\'aniel Varga", "title": "Negative Sampling in Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose negative sampling as an approach to improve the notoriously bad\nout-of-distribution likelihood estimates of Variational Autoencoder models. Our\nmodel pushes latent images of negative samples away from the prior. When the\nsource of negative samples is an auxiliary dataset, such a model can vastly\nimprove on baselines when evaluated on OOD detection tasks. Perhaps more\nsurprisingly, we present a fully unsupervised version of employing negative\nsampling in VAEs: when the generator is trained in an adversarial manner, using\nthe generator's own outputs as negative samples can also significantly improve\nthe robustness of OOD likelihood estimates.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 12:57:45 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 17:05:27 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Csisz\u00e1rik", "Adri\u00e1n", ""], ["Benk\u0151", "Beatrix", ""], ["Varga", "D\u00e1niel", ""]]}, {"id": "1910.02776", "submitter": "Maciej Wo{\\l}czyk", "authors": "Maciej Wo{\\l}czyk, Jacek Tabor, Marek \\'Smieja, Szymon Maszke", "title": "Biologically-Inspired Spatial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce bio-inspired artificial neural networks consisting of neurons\nthat are additionally characterized by spatial positions. To simulate\nproperties of biological systems we add the costs penalizing long connections\nand the proximity of neurons in a two-dimensional space. Our experiments show\nthat in the case where the network performs two different tasks, the neurons\nnaturally split into clusters, where each cluster is responsible for processing\na different task. This behavior not only corresponds to the biological systems,\nbut also allows for further insight into interpretability or continual\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 13:22:13 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Wo\u0142czyk", "Maciej", ""], ["Tabor", "Jacek", ""], ["\u015amieja", "Marek", ""], ["Maszke", "Szymon", ""]]}, {"id": "1910.02779", "submitter": "Alexander Khoperskov V.", "authors": "Vladislav Levshinskii, Maxim Polyakov, Alexander Losev, Alexander\n  Khoperskov", "title": "Verification and Validation of Computer Models for Diagnosing Breast\n  Cancer Based on Machine Learning for Medical Data Analysis", "comments": "15 pages, 9 figures, Creativity in Intelligent Technologies and Data\n  Science (CIT&DS 2019), Volgograd, September, 2019", "journal-ref": "Communications in Computer and Information Science, 2019, v. 1083,\n  pp.63-77", "doi": "10.1007/978-3-030-29743-5_5", "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of microwave radiometry is one of the areas of medical diagnosis\nof breast cancer. It is based on analysis of the spatial distribution of\ninternal and surface tissue temperatures, which are measured in the microwave\n(RTM) and infrared (IR) ranges. Complex mathematical and computer models\ndescribing complex physical and biological processes within biotissue increase\nthe efficiency of this method. Physical and biological processes are related to\ntemperature dynamics and microwave electromagnetic radiation. Verification and\nvalidation of the numerical model is a key challenge to ensure consistency with\nmedical big data. These data are obtained by medical measurements of patients.\nWe present an original approach to verification and validation of simulation\nmodels of physical processes in biological tissues. Our approach is based on\ndeep analysis of medical data and we use machine learning algorithms. We have\nachieved impressive success for the model of dynamics of thermal processes in a\nbreast with cancer foci. This method allows us to carry out a significant\nrefinement of almost all parameters of the mathematical model in order to\nachieve the maximum possible adequacy.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 08:03:31 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Levshinskii", "Vladislav", ""], ["Polyakov", "Maxim", ""], ["Losev", "Alexander", ""], ["Khoperskov", "Alexander", ""]]}, {"id": "1910.02785", "submitter": "Kaleel Mahmood", "authors": "Kaleel Mahmood, Phuong Ha Nguyen, Lam M. Nguyen, Thanh Nguyen, Marten\n  van Dijk", "title": "BUZz: BUffer Zones for defending adversarial examples in image\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel defense against all existing gradient based adversarial\nattacks on deep neural networks for image classification problems. Our defense\nis based on a combination of deep neural networks and simple image\ntransformations. While straightforward in implementation, this defense yields a\nunique security property which we term buffer zones. We argue that our defense\nbased on buffer zones offers significant improvements over state-of-the-art\ndefenses. We are able to achieve this improvement even when the adversary has\naccess to the {\\em entire} original training data set and unlimited query\naccess to the defense. We verify our claim through experimentation using\nFashion-MNIST and CIFAR-10: We demonstrate $<11\\%$ attack success rate --\nsignificantly lower than what other well-known state-of-the-art defenses offer\n-- at only a price of a $11-18\\%$ drop in clean accuracy. By using a new\nintuitive metric, we explain why this trade-off offers a significant\nimprovement over prior work.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 18:15:10 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 20:15:28 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Mahmood", "Kaleel", ""], ["Nguyen", "Phuong Ha", ""], ["Nguyen", "Lam M.", ""], ["Nguyen", "Thanh", ""], ["van Dijk", "Marten", ""]]}, {"id": "1910.02787", "submitter": "Cristian Bodnar", "authors": "Cristian Bodnar, Adrian Li, Karol Hausman, Peter Pastor, Mrinal\n  Kalakrishnan", "title": "Quantile QT-Opt for Risk-Aware Vision-Based Robotic Grasping", "comments": "Camera-ready version for RSS 2020. Contains 8 pages, 7 figures", "journal-ref": "Proceedings of Robotics: Science and Systems (2020)", "doi": "10.15607/RSS.2020.XVI.075", "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distributional perspective on reinforcement learning (RL) has given rise\nto a series of successful Q-learning algorithms, resulting in state-of-the-art\nperformance in arcade game environments. However, it has not yet been analyzed\nhow these findings from a discrete setting translate to complex practical\napplications characterized by noisy, high dimensional and continuous\nstate-action spaces. In this work, we propose Quantile QT-Opt (Q2-Opt), a\ndistributional variant of the recently introduced distributed Q-learning\nalgorithm for continuous domains, and examine its behaviour in a series of\nsimulated and real vision-based robotic grasping tasks. The absence of an actor\nin Q2-Opt allows us to directly draw a parallel to the previous discrete\nexperiments in the literature without the additional complexities induced by an\nactor-critic architecture. We demonstrate that Q2-Opt achieves a superior\nvision-based object grasping success rate, while also being more sample\nefficient. The distributional formulation also allows us to experiment with\nvarious risk distortion metrics that give us an indication of how robots can\nconcretely manage risk in practice using a Deep RL control policy. As an\nadditional contribution, we perform batch RL experiments in our virtual\nenvironment and compare them with the latest findings from discrete settings.\nSurprisingly, we find that the previous batch RL findings from the literature\nobtained on arcade game environments do not generalise to our setup.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 22:12:00 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 13:48:14 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 12:56:16 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Bodnar", "Cristian", ""], ["Li", "Adrian", ""], ["Hausman", "Karol", ""], ["Pastor", "Peter", ""], ["Kalakrishnan", "Mrinal", ""]]}, {"id": "1910.02789", "submitter": "Guy Tennenholtz", "authors": "Erez Schwartz, Guy Tennenholtz, Chen Tessler, Shie Mannor", "title": "Language is Power: Representing States Using Natural Language in\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in reinforcement learning have shown its potential to tackle\ncomplex real-life tasks. However, as the dimensionality of the task increases,\nreinforcement learning methods tend to struggle. To overcome this, we explore\nmethods for representing the semantic information embedded in the state. While\nprevious methods focused on information in its raw form (e.g., raw visual\ninput), we propose to represent the state using natural language. Language can\nrepresent complex scenarios and concepts, making it a favorable candidate for\nrepresentation. Empirical evidence, within the domain of ViZDoom, suggests that\nnatural language based agents are more robust, converge faster and perform\nbetter than vision based agents, showing the benefit of using natural language\nrepresentations for reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 11:06:17 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 07:16:02 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Schwartz", "Erez", ""], ["Tennenholtz", "Guy", ""], ["Tessler", "Chen", ""], ["Mannor", "Shie", ""]]}, {"id": "1910.02793", "submitter": "Eric Hofesmann", "authors": "Madan Ravi Ganesh, Eric Hofesmann, Nathan Louis, Jason Corso", "title": "ViP: Video Platform for PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents the Video Platform for PyTorch (ViP), a deep\nlearning-based framework designed to handle and extend to any problem domain\nbased on videos. ViP supports (1) a single unified interface applicable to all\nvideo problem domains, (2) quick prototyping of video models, (3) executing\nlarge-batch operations with reduced memory consumption, and (4) easy and\nreproducible experimental setups. ViP's core functionality is built with\nflexibility and modularity in mind to allow for smooth data flow between\ndifferent parts of the platform and benchmarking against existing methods. In\nproviding a software platform that supports multiple video-based problem\ndomains, we allow for more cross-pollination of models, ideas and stronger\ngeneralization in the video understanding research community.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 13:49:50 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ganesh", "Madan Ravi", ""], ["Hofesmann", "Eric", ""], ["Louis", "Nathan", ""], ["Corso", "Jason", ""]]}, {"id": "1910.02804", "submitter": "Shahar Harel", "authors": "Shahar Harel, Meir Maor, Amir Ronen", "title": "Semantic Preserving Generative Adversarial Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce generative adversarial models in which the discriminator is\nreplaced by a calibrated (non-differentiable) classifier repeatedly enhanced by\ndomain relevant features. The role of the classifier is to prove that the\nactual and generated data differ over a controlled semantic space. We\ndemonstrate that such models have the ability to generate objects with strong\nguarantees on their properties in a wide range of domains. They require less\ndata than ordinary GANs, provide natural stopping conditions, uncover important\nproperties of the data, and enhance transfer learning. Our techniques can be\ncombined with standard generative models. We demonstrate the usefulness of our\napproach by applying it to several unrelated domains: generating good locations\nfor cellular antennae, molecule generation preserving key chemical properties,\nand generating and extrapolating lines from very few data points. Intriguing\nopen problems are presented as well.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:06:38 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Harel", "Shahar", ""], ["Maor", "Meir", ""], ["Ronen", "Amir", ""]]}, {"id": "1910.02806", "submitter": "Hyojin Bahng", "authors": "Hyojin Bahng, Sanghyuk Chun, Sangdoo Yun, Jaegul Choo, Seong Joon Oh", "title": "Learning De-biased Representations with Biased Representations", "comments": "Accepted to ICML 2020. Code available at\n  https://github.com/clovaai/rebias", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning algorithms are trained and evaluated by splitting data\nfrom a single source into training and test sets. While such focus on\nin-distribution learning scenarios has led to interesting advancement, it has\nnot been able to tell if models are relying on dataset biases as shortcuts for\nsuccessful prediction (e.g., using snow cues for recognising snowmobiles),\nresulting in biased models that fail to generalise when the bias shifts to a\ndifferent class. The cross-bias generalisation problem has been addressed by\nde-biasing training data through augmentation or re-sampling, which are often\nprohibitive due to the data collection cost (e.g., collecting images of a\nsnowmobile on a desert) and the difficulty of quantifying or expressing biases\nin the first place. In this work, we propose a novel framework to train a\nde-biased representation by encouraging it to be different from a set of\nrepresentations that are biased by design. This tactic is feasible in many\nscenarios where it is much easier to define a set of biased representations\nthan to define and quantify bias. We demonstrate the efficacy of our method\nacross a variety of synthetic and real-world biases; our experiments show that\nthe method discourages models from taking bias shortcuts, resulting in improved\ngeneralisation. Source code is available at https://github.com/clovaai/rebias.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:11:13 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 16:46:24 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 11:51:02 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Bahng", "Hyojin", ""], ["Chun", "Sanghyuk", ""], ["Yun", "Sangdoo", ""], ["Choo", "Jaegul", ""], ["Oh", "Seong Joon", ""]]}, {"id": "1910.02812", "submitter": "Atil Iscen", "authors": "Atil Iscen, Ken Caluwaerts, Jie Tan, Tingnan Zhang, Erwin Coumans,\n  Vikas Sindhwani, Vincent Vanhoucke", "title": "Policies Modulating Trajectory Generators", "comments": null, "journal-ref": "In Proceedings of The 2nd Conference on Robot Learning, volume 87\n  of Proceedings of Machine Learning Research, pages 916-926. PMLR, 29-31 Oct\n  2018", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an architecture for learning complex controllable behaviors by\nhaving simple Policies Modulate Trajectory Generators (PMTG), a powerful\ncombination that can provide both memory and prior knowledge to the controller.\nThe result is a flexible architecture that is applicable to a class of problems\nwith periodic motion for which one has an insight into the class of\ntrajectories that might lead to a desired behavior. We illustrate the basics of\nour architecture using a synthetic control problem, then go on to learn\nspeed-controlled locomotion for a quadrupedal robot by using Deep Reinforcement\nLearning and Evolutionary Strategies. We demonstrate that a simple linear\npolicy, when paired with a parametric Trajectory Generator for quadrupedal\ngaits, can induce walking behaviors with controllable speed from 4-dimensional\nIMU observations alone, and can be learned in under 1000 rollouts. We also\ntransfer these policies to a real robot and show locomotion with controllable\nforward velocity.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:20:05 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Iscen", "Atil", ""], ["Caluwaerts", "Ken", ""], ["Tan", "Jie", ""], ["Zhang", "Tingnan", ""], ["Coumans", "Erwin", ""], ["Sindhwani", "Vikas", ""], ["Vanhoucke", "Vincent", ""]]}, {"id": "1910.02818", "submitter": "Iulia Paraicu", "authors": "Iulia Paraicu and Marius Leordeanu", "title": "Learning Navigation by Visual Localization and Trajectory Prediction", "comments": "Submitted to ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When driving, people make decisions based on current traffic as well as their\ndesired route. They have a mental map of known routes and are often able to\nnavigate without needing directions. Current self-driving models improve their\nperformances when using additional GPS information. Here we aim to push forward\nself-driving research and perform route planning even in the absence of GPS.\nOur system learns to predict in real-time vehicle's current location and future\ntrajectory, as a function of time, on a known map, given only the raw video\nstream and the intended destination. The GPS signal is available only at\ntraining time, with training data annotation being fully automatic. Different\nfrom other published models, we predict the vehicle's trajectory for up to\nseven seconds ahead, from which complete steering, speed and acceleration\ninformation can be derived for the entire time span. Trajectories capture\nnavigational information on multiple levels, from instant steering commands\nthat depend on present traffic and obstacles ahead, to longer-term navigation\ndecisions, towards a specific destination. We collect our dataset with a\nregular car and a smartphone that records video and GPS streams. The GPS data\nis used to derive ground-truth supervision labels and create an analytical\nrepresentation of the traversed map. In tests, our system outperforms published\nmethods on visual localization and steering and gives accurate navigation\nassistance between any two known locations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:31:38 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Paraicu", "Iulia", ""], ["Leordeanu", "Marius", ""]]}, {"id": "1910.02822", "submitter": "Pei Wang", "authors": "Pei Wang, Junqi Wang, Pushpi Paranamana, and Patrick Shafto", "title": "A mathematical theory of cooperative communication", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33 (NIPS 2030)", "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative communication plays a central role in theories of human\ncognition, language, development, culture, and human-robot interaction. Prior\nmodels of cooperative communication are algorithmic in nature and do not shed\nlight on why cooperation may yield effective belief transmission and what\nlimitations may arise due to differences between beliefs of agents. Through a\nconnection to the theory of optimal transport, we establishing a mathematical\nframework for cooperative communication. We derive prior models as special\ncases, statistical interpretations of belief transfer plans, and proofs of\nrobustness and instability. Computational simulations support and elaborate our\ntheoretical results, and demonstrate fit to human behavior. The results show\nthat cooperative communication provably enables effective, robust belief\ntransmission which is required to explain feats of human learning and improve\nhuman-machine interaction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:35:22 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 20:26:33 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wang", "Pei", ""], ["Wang", "Junqi", ""], ["Paranamana", "Pushpi", ""], ["Shafto", "Patrick", ""]]}, {"id": "1910.02826", "submitter": "Pascal Klink", "authors": "Pascal Klink, Hany Abdulsamad, Boris Belousov, Jan Peters", "title": "Self-Paced Contextual Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization and adaptation of learned skills to novel situations is a core\nrequirement for intelligent autonomous robots. Although contextual\nreinforcement learning provides a principled framework for learning and\ngeneralization of behaviors across related tasks, it generally relies on\nuninformed sampling of environments from an unknown, uncontrolled context\ndistribution, thus missing the benefits of structured, sequential learning. We\nintroduce a novel relative entropy reinforcement learning algorithm that gives\nthe agent the freedom to control the intermediate task distribution, allowing\nfor its gradual progression towards the target context distribution. Empirical\nevaluation shows that the proposed curriculum learning scheme drastically\nimproves sample efficiency and enables learning in scenarios with both broad\nand sharp target context distributions in which classical approaches perform\nsub-optimally.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:40:53 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Klink", "Pascal", ""], ["Abdulsamad", "Hany", ""], ["Belousov", "Boris", ""], ["Peters", "Jan", ""]]}, {"id": "1910.02830", "submitter": "Viraj Prabhu", "authors": "Viraj Prabhu, Anitha Kannan, Geoffrey J. Tso, Namit Katariya, Manish\n  Chablani, David Sontag, Xavier Amatriain", "title": "Open Set Medical Diagnosis", "comments": "Abbreviated version to appear at Machine Learning for Healthcare\n  (ML4H) Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learned diagnosis models have shown promise as medical aides but are\ntrained under a closed-set assumption, i.e. that models will only encounter\nconditions on which they have been trained. However, it is practically\ninfeasible to obtain sufficient training data for every human condition, and\nonce deployed such models will invariably face previously unseen conditions. We\nframe machine-learned diagnosis as an open-set learning problem, and study how\nstate-of-the-art approaches compare. Further, we extend our study to a setting\nwhere training data is distributed across several healthcare sites that do not\nallow data pooling, and experiment with different strategies of building\nopen-set diagnostic ensembles. Across both settings, we observe consistent\ngains from explicitly modeling unseen conditions, but find the optimal training\nstrategy to vary across settings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:45:47 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Prabhu", "Viraj", ""], ["Kannan", "Anitha", ""], ["Tso", "Geoffrey J.", ""], ["Katariya", "Namit", ""], ["Chablani", "Manish", ""], ["Sontag", "David", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1910.02835", "submitter": "Steve Heim", "authors": "Steve Heim, Alexander von Rohr, Sebastian Trimpe, and Alexander\n  Badri-Spr\\\"owitz", "title": "A Learnable Safety Measure", "comments": "10 pages, Conference on Robot Learning CoRL 2019, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Failures are challenging for learning to control physical systems since they\nrisk damage, time-consuming resets, and often provide little gradient\ninformation. Adding safety constraints to exploration typically requires a lot\nof prior knowledge and domain expertise. We present a safety measure which\nimplicitly captures how the system dynamics relate to a set of failure states.\nNot only can this measure be used as a safety function, but also to directly\ncompute the set of safe state-action pairs. Further, we show a model-free\napproach to learn this measure by active sampling using Gaussian processes.\nWhile safety can only be guaranteed after learning the safety measure, we show\nthat failures can already be greatly reduced by using the estimated measure\nduring learning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:53:15 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Heim", "Steve", ""], ["von Rohr", "Alexander", ""], ["Trimpe", "Sebastian", ""], ["Badri-Spr\u00f6witz", "Alexander", ""]]}, {"id": "1910.02840", "submitter": "Chris Finlay", "authors": "Aram-Alexandre Pooladian and Chris Finlay and Adam M Oberman", "title": "Farkas layers: don't shift the data, fix the geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successfully training deep neural networks often requires either batch\nnormalization, appropriate weight initialization, both of which come with their\nown challenges. We propose an alternative, geometrically motivated method for\ntraining. Using elementary results from linear programming, we introduce Farkas\nlayers: a method that ensures at least one neuron is active at a given layer.\nFocusing on residual networks with ReLU activation, we empirically demonstrate\na significant improvement in training capacity in the absence of batch\nnormalization or methods of initialization across a broad range of network\nsizes on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:24:37 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Pooladian", "Aram-Alexandre", ""], ["Finlay", "Chris", ""], ["Oberman", "Adam M", ""]]}, {"id": "1910.02844", "submitter": "Sripad Krishna Devalla", "authors": "Haris Cheong, Sripad Krishna Devalla, Tan Hung Pham, Zhang Liang, Tin\n  Aung Tun, Xiaofei Wang, Shamira Perera, Leopold Schmetterer, Aung Tin, Craig\n  Boote, Alexandre H.Thiery, Michael J. A. Girard", "title": "DeshadowGAN: A Deep Learning Approach to Remove Shadows from Optical\n  Coherence Tomography Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Purpose: To remove retinal shadows from optical coherence tomography (OCT)\nimages of the optic nerve head(ONH).\n  Methods:2328 OCT images acquired through the center of the ONH using a\nSpectralis OCT machine for both eyes of 13 subjects were used to train a\ngenerative adversarial network (GAN) using a custom loss function. Image\nquality was assessed qualitatively (for artifacts) and quantitatively using the\nintralayer contrast: a measure of shadow visibility ranging from 0\n(shadow-free) to 1 (strong shadow) and compared to compensated images. This was\ncomputed in the Retinal Nerve Fiber Layer (RNFL), the Inner Plexiform Layer\n(IPL), the Photoreceptor layer (PR) and the Retinal Pigment Epithelium (RPE)\nlayers.\n  Results: Output images had improved intralayer contrast in all ONH tissue\nlayers. On average the intralayer contrast decreased by 33.7$\\pm$6.81%,\n28.8$\\pm$10.4%, 35.9$\\pm$13.0%, and43.0$\\pm$19.5%for the RNFL, IPL, PR, and RPE\nlayers respectively, indicating successful shadow removal across all depths.\nThis compared to 70.3$\\pm$22.7%, 33.9$\\pm$11.5%, 47.0$\\pm$11.2%,\n26.7$\\pm$19.0%for compensation. Output images were also free from artifacts\ncommonly observed with compensation.\n  Conclusions: DeshadowGAN significantly corrected blood vessel shadows in OCT\nimages of the ONH. Our algorithm may be considered as a pre-processing step to\nimprove the performance of a wide range of algorithms including those currently\nbeing used for OCT image segmentation, denoising, and classification.\n  Translational Relevance: DeshadowGAN could be integrated to existing OCT\ndevices to improve the diagnosis and prognosis of ocular pathologies.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 15:11:45 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Cheong", "Haris", ""], ["Devalla", "Sripad Krishna", ""], ["Pham", "Tan Hung", ""], ["Liang", "Zhang", ""], ["Tun", "Tin Aung", ""], ["Wang", "Xiaofei", ""], ["Perera", "Shamira", ""], ["Schmetterer", "Leopold", ""], ["Tin", "Aung", ""], ["Boote", "Craig", ""], ["Thiery", "Alexandre H.", ""], ["Girard", "Michael J. A.", ""]]}, {"id": "1910.02875", "submitter": "Arthur Jacot", "authors": "Arthur Jacot and Franck Gabriel and Cl\\'ement Hongler", "title": "The asymptotic spectrum of the Hessian of DNN throughout training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of DNNs during gradient descent is described by the so-called\nNeural Tangent Kernel (NTK). In this article, we show that the NTK allows one\nto gain precise insight into the Hessian of the cost of DNNs. When the NTK is\nfixed during training, we obtain a full characterization of the asymptotics of\nthe spectrum of the Hessian, at initialization and during training. In the\nso-called mean-field limit, where the NTK is not fixed during training, we\ndescribe the first two moments of the Hessian at initialization.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:04:14 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 07:57:49 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Jacot", "Arthur", ""], ["Gabriel", "Franck", ""], ["Hongler", "Cl\u00e9ment", ""]]}, {"id": "1910.02876", "submitter": "Ali Shafti", "authors": "Petros Christodoulou, Robert Tjarko Lange, Ali Shafti, A. Aldo Faisal", "title": "Reinforcement Learning with Structured Hierarchical Grammar\n  Representations of Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From a young age humans learn to use grammatical principles to hierarchically\ncombine words into sentences. Action grammars is the parallel idea, that there\nis an underlying set of rules (a \"grammar\") that govern how we hierarchically\ncombine actions to form new, more complex actions. We introduce the Action\nGrammar Reinforcement Learning (AG-RL) framework which leverages the concept of\naction grammars to consistently improve the sample efficiency of Reinforcement\nLearning agents. AG-RL works by using a grammar inference algorithm to infer\nthe \"action grammar\" of an agent midway through training. The agent's action\nspace is then augmented with macro-actions identified by the grammar. We apply\nthis framework to Double Deep Q-Learning (AG-DDQN) and a discrete action\nversion of Soft Actor-Critic (AG-SAC) and find that it improves performance in\n8 out of 8 tested Atari games (median +31%, max +668%) and 19 out of 20 tested\nAtari games (median +96%, maximum +3,756%) respectively without substantive\nhyperparameter tuning. We also show that AG-SAC beats the model-free\nstate-of-the-art for sample efficiency in 17 out of the 20 tested Atari games\n(median +62%, maximum +13,140%), again without substantive hyperparameter\ntuning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 15:59:20 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 10:23:19 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Christodoulou", "Petros", ""], ["Lange", "Robert Tjarko", ""], ["Shafti", "Ali", ""], ["Faisal", "A. Aldo", ""]]}, {"id": "1910.02884", "submitter": "Kumar Abhishek", "authors": "Kumar Abhishek, Sneha Maheshwari, Sujit Gujar", "title": "Introduction to Concentration Inequalities", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we aim to exemplify concentration inequalities and provide\neasy to understand proofs for it. Our focus is on the inequalities which are\nhelpful in the design and analysis of machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 06:50:41 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Abhishek", "Kumar", ""], ["Maheshwari", "Sneha", ""], ["Gujar", "Sujit", ""]]}, {"id": "1910.02893", "submitter": "Abhijeet Awasthi", "authors": "Abhijeet Awasthi, Sunita Sarawagi, Rasna Goyal, Sabyasachi Ghosh,\n  Vihari Piratla", "title": "Parallel Iterative Edit Models for Local Sequence Transduction", "comments": "Accepted at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Parallel Iterative Edit (PIE) model for the problem of local\nsequence transduction arising in tasks like Grammatical error correction (GEC).\nRecent approaches are based on the popular encoder-decoder (ED) model for\nsequence to sequence learning. The ED model auto-regressively captures full\ndependency among output tokens but is slow due to sequential decoding. The PIE\nmodel does parallel decoding, giving up the advantage of modelling full\ndependency in the output, yet it achieves accuracy competitive with the ED\nmodel for four reasons: 1.~predicting edits instead of tokens, 2.~labeling\nsequences instead of generating sequences, 3.~iteratively refining predictions\nto capture dependencies, and 4.~factorizing logits over edits and their token\nargument to harness pre-trained language models like BERT. Experiments on tasks\nspanning GEC, OCR correction and spell correction demonstrate that the PIE\nmodel is an accurate and significantly faster alternative for local sequence\ntransduction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 16:37:31 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 16:04:00 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Awasthi", "Abhijeet", ""], ["Sarawagi", "Sunita", ""], ["Goyal", "Rasna", ""], ["Ghosh", "Sabyasachi", ""], ["Piratla", "Vihari", ""]]}, {"id": "1910.02898", "submitter": "Alessandro Greco", "authors": "Alessandro Greco, Vladimir Starostin, Christos Karapanagiotis,\n  Alexander Hinderhofer, Alexander Gerlach, Linus Pithan, Sascha Liehr, Frank\n  Schreiber, Stefan Kowarik", "title": "Fast Fitting of Reflectivity Data of Growing Thin Films Using Neural\n  Networks", "comments": "including supporting information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  X-ray reflectivity (XRR) is a powerful and popular scattering technique that\ncan give valuable insight into the growth behavior of thin films. In this\nstudy, we show how a simple artificial neural network model can be used to\npredict the thickness, roughness and density of thin films of different organic\nsemiconductors (diindenoperylene, copper(II) phthalocyanine and\n$\\alpha$-sexithiophene) on silica from their XRR data with millisecond\ncomputation time and with minimal user input or a priori knowledge. For a large\nexperimental dataset of 372 XRR curves, we show that a simple fully connected\nmodel can already provide good predictions with a mean absolute percentage\nerror of 8-18 % when compared to the results obtained by a genetic least mean\nsquares fit using the classical Parratt formalism. Furthermore, current\ndrawbacks and prospects for improvement are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 16:40:02 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Greco", "Alessandro", ""], ["Starostin", "Vladimir", ""], ["Karapanagiotis", "Christos", ""], ["Hinderhofer", "Alexander", ""], ["Gerlach", "Alexander", ""], ["Pithan", "Linus", ""], ["Liehr", "Sascha", ""], ["Schreiber", "Frank", ""], ["Kowarik", "Stefan", ""]]}, {"id": "1910.02902", "submitter": "Vitalii Zhelezniak", "authors": "Vitalii Zhelezniak, April Shen, Daniel Busbridge, Aleksandar Savkov,\n  Nils Hammerla", "title": "Correlations between Word Vector Sets", "comments": "Accepted as a long paper at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity measures based purely on word embeddings are comfortably competing\nwith much more sophisticated deep learning and expert-engineered systems on\nunsupervised semantic textual similarity (STS) tasks. In contrast to commonly\nused geometric approaches, we treat a single word embedding as e.g. 300\nobservations from a scalar random variable. Using this paradigm, we first\nillustrate that similarities derived from elementary pooling operations and\nclassic correlation coefficients yield excellent results on standard STS\nbenchmarks, outperforming many recently proposed methods while being much\nfaster and trivial to implement. Next, we demonstrate how to avoid pooling\noperations altogether and compare sets of word embeddings directly via\ncorrelation operators between reproducing kernel Hilbert spaces. Just like\ncosine similarity is used to compare individual word vectors, we introduce a\nnovel application of the centered kernel alignment (CKA) as a natural\ngeneralisation of squared cosine similarity for sets of word vectors. Likewise,\nCKA is very easy to implement and enjoys very strong empirical results.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 16:44:32 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhelezniak", "Vitalii", ""], ["Shen", "April", ""], ["Busbridge", "Daniel", ""], ["Savkov", "Aleksandar", ""], ["Hammerla", "Nils", ""]]}, {"id": "1910.02910", "submitter": "Siddharth Reddy", "authors": "Gokul Swamy, Siddharth Reddy, Sergey Levine, Anca D. Dragan", "title": "Scaled Autonomy: Enabling Human Operators to Control Robot Fleets", "comments": "Accepted to International Conference on Robotics and Automation\n  (ICRA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous robots often encounter challenging situations where their control\npolicies fail and an expert human operator must briefly intervene, e.g.,\nthrough teleoperation. In settings where multiple robots act in separate\nenvironments, a single human operator can manage a fleet of robots by\nidentifying and teleoperating one robot at any given time. The key challenge is\nthat users have limited attention: as the number of robots increases, users\nlose the ability to decide which robot requires teleoperation the most. Our\ngoal is to automate this decision, thereby enabling users to supervise more\nrobots than their attention would normally allow for. Our insight is that we\ncan model the user's choice of which robot to control as an approximately\noptimal decision that maximizes the user's utility function. We learn a model\nof the user's preferences from observations of the user's choices in easy\nsettings with a few robots, and use it in challenging settings with more robots\nto automatically identify which robot the user would most likely choose to\ncontrol, if they were able to evaluate the states of all robots at all times.\nWe run simulation experiments and a user study with twelve participants that\nshow our method can be used to assist users in performing a simulated\nnavigation task. We also run a hardware demonstration that illustrates how our\nmethod can be applied to a real-world mobile robot navigation task.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 01:00:49 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 22:36:53 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Swamy", "Gokul", ""], ["Reddy", "Siddharth", ""], ["Levine", "Sergey", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1910.02912", "submitter": "Tim R. Davidson", "authors": "Tim R. Davidson, Jakub M. Tomczak, Efstratios Gavves", "title": "Increasing Expressivity of a Hyperspherical VAE", "comments": "NeurIPS 2019, in Workshop on Bayesian Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning suitable latent representations for observed, high-dimensional data\nis an important research topic underlying many recent advances in machine\nlearning. While traditionally the Gaussian normal distribution has been the\ngo-to latent parameterization, recently a variety of works have successfully\nproposed the use of manifold-valued latents. In one such work (Davidson et al.,\n2018), the authors empirically show the potential benefits of using a\nhyperspherical von Mises-Fisher (vMF) distribution in low dimensionality.\nHowever, due to the unique distributional form of the vMF, expressivity in\nhigher dimensional space is limited as a result of its scalar concentration\nparameter leading to a 'hyperspherical bottleneck'. In this work we propose to\nextend the usability of hyperspherical parameterizations to higher dimensions\nusing a product-space instead, showing improved results on a selection of image\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 16:59:59 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Davidson", "Tim R.", ""], ["Tomczak", "Jakub M.", ""], ["Gavves", "Efstratios", ""]]}, {"id": "1910.02919", "submitter": "Manan Tomar Mr.", "authors": "Manan Tomar, Yonathan Efroni, Mohammad Ghavamzadeh", "title": "Multi-step Greedy Reinforcement Learning Algorithms", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-step greedy policies have been extensively used in model-based\nreinforcement learning (RL), both when a model of the environment is available\n(e.g.,~in the game of Go) and when it is learned. In this paper, we explore\ntheir benefits in model-free RL, when employed using multi-step dynamic\nprogramming algorithms: $\\kappa$-Policy Iteration ($\\kappa$-PI) and\n$\\kappa$-Value Iteration ($\\kappa$-VI). These methods iteratively compute the\nnext policy ($\\kappa$-PI) and value function ($\\kappa$-VI) by solving a\nsurrogate decision problem with a shaped reward and a smaller discount factor.\nWe derive model-free RL algorithms based on $\\kappa$-PI and $\\kappa$-VI in\nwhich the surrogate problem can be solved by any discrete or continuous action\nRL method, such as DQN and TRPO. We identify the importance of a\nhyper-parameter that controls the extent to which the surrogate problem is\nsolved and suggest a way to set this parameter. When evaluated on a range of\nAtari and MuJoCo benchmark tasks, our results indicate that for the right range\nof $\\kappa$, our algorithms outperform DQN and TRPO. This shows that our\nmulti-step greedy algorithms are general enough to be applied over any existing\nRL algorithm and can significantly improve its performance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 17:20:25 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 17:25:19 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 00:00:32 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Tomar", "Manan", ""], ["Efroni", "Yonathan", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "1910.02923", "submitter": "Samuel Budd", "authors": "Samuel Budd, Emma C Robinson, Bernhard Kainz", "title": "A Survey on Active Learning and Human-in-the-Loop Deep Learning for\n  Medical Image Analysis", "comments": "Medical Image Analysis Volume 71 2021\n  https://doi.org/10.1016/j.media.2021.102062", "journal-ref": "Medical Image Analysis, Volume 71, 2021, 102062, ISSN 1361-8415", "doi": "10.1016/j.media.2021.102062", "report-no": null, "categories": "cs.LG cs.CV cs.HC eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Fully automatic deep learning has become the state-of-the-art technique for\nmany tasks including image acquisition, analysis and interpretation, and for\nthe extraction of clinically useful information for computer-aided detection,\ndiagnosis, treatment planning, intervention and therapy. However, the unique\nchallenges posed by medical image analysis suggest that retaining a human end\nuser in any deep learning enabled system will be beneficial. In this review we\ninvestigate the role that humans might play in the development and deployment\nof deep learning enabled diagnostic applications and focus on techniques that\nwill retain a significant input from a human end user. Human-in-the-Loop\ncomputing is an area that we see as increasingly important in future research\ndue to the safety-critical nature of working in the medical domain. We evaluate\nfour key areas that we consider vital for deep learning in the clinical\npractice: (1) Active Learning to choose the best data to annotate for optimal\nmodel performance; (2) Interaction with model outputs - using iterative\nfeedback to steer models to optima for a given prediction and offering\nmeaningful ways to interpret and respond to predictions; (3) Practical\nconsiderations - developing full scale applications and the key considerations\nthat need to be made before deployment; (4) Future Prospective and Unanswered\nQuestions - knowledge gaps and related research fields that will benefit\nhuman-in-the-loop computing as they evolve. We offer our opinions on the most\npromising directions of research and how various aspects of each area might be\nunified towards common goals.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 17:24:33 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 12:07:48 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Budd", "Samuel", ""], ["Robinson", "Emma C", ""], ["Kainz", "Bernhard", ""]]}, {"id": "1910.02934", "submitter": "Quanquan Gu", "authors": "Spencer Frei and Yuan Cao and Quanquan Gu", "title": "Algorithm-Dependent Generalization Bounds for Overparameterized Deep\n  Residual Networks", "comments": "37 pages. In NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The skip-connections used in residual networks have become a standard\narchitecture choice in deep learning due to the increased training stability\nand generalization performance with this architecture, although there has been\nlimited theoretical understanding for this improvement. In this work, we\nanalyze overparameterized deep residual networks trained by gradient descent\nfollowing random initialization, and demonstrate that (i) the class of networks\nlearned by gradient descent constitutes a small subset of the entire neural\nnetwork function class, and (ii) this subclass of networks is sufficiently\nlarge to guarantee small training error. By showing (i) we are able to\ndemonstrate that deep residual networks trained with gradient descent have a\nsmall generalization gap between training and test error, and together with\n(ii) this guarantees that the test error will be small. Our optimization and\ngeneralization guarantees require overparameterization that is only logarithmic\nin the depth of the network, while all known generalization bounds for deep\nnon-residual networks have overparameterization requirements that are at least\npolynomial in the depth. This provides an explanation for why residual networks\nare preferable to non-residual ones.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 17:52:20 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Frei", "Spencer", ""], ["Cao", "Yuan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1910.02935", "submitter": "Aydan Gasimova", "authors": "Aydan Gasimova", "title": "Automated Enriched Medical Concept Generation for Chest X-ray Images", "comments": "MICCAI ML-CDS Workshop 2019", "journal-ref": null, "doi": "10.1007/978-3-030-33850-3_10", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decision support tools that rely on supervised learning require large amounts\nof expert annotations. Using past radiological reports obtained from hospital\narchiving systems has many advantages as training data above manual\nsingle-class labels: they are expert annotations available in large quantities,\ncovering a population-representative variety of pathologies, and they provide\nadditional context to pathology diagnoses, such as anatomical location and\nseverity. Learning to auto-generate such reports from images present many\nchallenges such as the difficulty in representing and generating long,\nunstructured textual information, accounting for spelling errors and\nrepetition/redundancy, and the inconsistency across different annotators. We\ntherefore propose to first learn visually-informative medical concepts from raw\nreports, and, using the concept predictions as image annotations, learn to\nauto-generate structured reports directly from images. We validate our approach\non the OpenI [2] chest x-ray dataset, which consists of frontal and lateral\nviews of chest x-ray images, their corresponding raw textual reports and manual\nmedical subject heading (MeSH ) annotations made by radiologists.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 17:52:37 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Gasimova", "Aydan", ""]]}, {"id": "1910.02951", "submitter": "Nicolo' Savioli", "authors": "Shihao Jin, Nicol\\`o Savioli, Antonio de Marvao, Timothy JW Dawes,\n  Axel Gandy, Daniel Rueckert, Declan P O'Regan", "title": "Joint analysis of clinical risk factors and 4D cardiac motion for\n  survival prediction using a hybrid deep learning network", "comments": "4 pages, 2 figures", "journal-ref": "NeurIPS 2019, Medical Imaging meets NIPS", "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a novel approach is proposed for joint analysis of high\ndimensional time-resolved cardiac motion features obtained from segmented\ncardiac MRI and low dimensional clinical risk factors to improve survival\nprediction in heart failure. Different methods are evaluated to find the\noptimal way to insert conventional covariates into deep prediction networks.\nCorrelation analysis between autoencoder latent codes and covariate features is\nused to examine how these predictors interact. We believe that similar\napproaches could also be used to introduce knowledge of genetic variants to\nsuch survival networks to improve outcome prediction by jointly analysing\ncardiac motion traits with inheritable risk factors.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:04:17 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Jin", "Shihao", ""], ["Savioli", "Nicol\u00f2", ""], ["de Marvao", "Antonio", ""], ["Dawes", "Timothy JW", ""], ["Gandy", "Axel", ""], ["Rueckert", "Daniel", ""], ["O'Regan", "Declan P", ""]]}, {"id": "1910.03002", "submitter": "Michael Bohlke-Schneider", "authors": "David Salinas, Michael Bohlke-Schneider, Laurent Callot, Roberto\n  Medico, Jan Gasthaus", "title": "High-Dimensional Multivariate Forecasting with Low-Rank Gaussian Copula\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the dependencies between observations from multiple time series is\ncritical for applications such as anomaly detection, financial risk management,\ncausal analysis, or demand forecasting. However, the computational and\nnumerical difficulties of estimating time-varying and high-dimensional\ncovariance matrices often limits existing methods to handling at most a few\nhundred dimensions or requires making strong assumptions on the dependence\nbetween series. We propose to combine an RNN-based time series model with a\nGaussian copula process output model with a low-rank covariance structure to\nreduce the computational complexity and handle non-Gaussian marginal\ndistributions. This permits to drastically reduce the number of parameters and\nconsequently allows the modeling of time-varying correlations of thousands of\ntime series. We show on several real-world datasets that our method provides\nsignificant accuracy improvements over state-of-the-art baselines and perform\nan ablation study analyzing the contributions of the different components of\nour model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 18:41:00 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 20:16:30 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Salinas", "David", ""], ["Bohlke-Schneider", "Michael", ""], ["Callot", "Laurent", ""], ["Medico", "Roberto", ""], ["Gasthaus", "Jan", ""]]}, {"id": "1910.03003", "submitter": "Joe Watson", "authors": "Joe Watson, Hany Abdulsamad, Jan Peters", "title": "Stochastic Optimal Control as Approximate Input Inference", "comments": "Conference on Robot Learning (CoRL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal control of stochastic nonlinear dynamical systems is a major\nchallenge in the domain of robot learning. Given the intractability of the\nglobal control problem, state-of-the-art algorithms focus on approximate\nsequential optimization techniques, that heavily rely on heuristics for\nregularization in order to achieve stable convergence. By building upon the\nduality between inference and control, we develop the view of Optimal Control\nas Input Estimation, devising a probabilistic stochastic optimal control\nformulation that iteratively infers the optimal input distributions by\nminimizing an upper bound of the control cost. Inference is performed through\nExpectation Maximization and message passing on a probabilistic graphical model\nof the dynamical system, and time-varying linear Gaussian feedback controllers\nare extracted from the joint state-action distribution. This perspective\nincorporates uncertainty quantification, effective initialization through\npriors, and the principled regularization inherent to the Bayesian treatment.\nMoreover, it can be shown that for deterministic linearized systems, our\nframework derives the maximum entropy linear quadratic optimal control law. We\nprovide a complete and detailed derivation of our probabilistic approach and\nhighlight its advantages in comparison to other deterministic and probabilistic\nsolvers.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 18:41:52 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 11:36:15 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Watson", "Joe", ""], ["Abdulsamad", "Hany", ""], ["Peters", "Jan", ""]]}, {"id": "1910.03016", "submitter": "Ruosong Wang", "authors": "Simon S. Du and Sham M. Kakade and Ruosong Wang and Lin F. Yang", "title": "Is a Good Representation Sufficient for Sample Efficient Reinforcement\n  Learning?", "comments": "To appear in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning methods provide effective means to learn good\nrepresentations. However, is a good representation itself sufficient for sample\nefficient reinforcement learning? This question has largely been studied only\nwith respect to (worst-case) approximation error, in the more classical\napproximate dynamic programming literature. With regards to the statistical\nviewpoint, this question is largely unexplored, and the extant body of\nliterature mainly focuses on conditions which permit sample efficient\nreinforcement learning with little understanding of what are necessary\nconditions for efficient reinforcement learning.\n  This work shows that, from the statistical viewpoint, the situation is far\nsubtler than suggested by the more traditional approximation viewpoint, where\nthe requirements on the representation that suffice for sample efficient RL are\neven more stringent. Our main results provide sharp thresholds for\nreinforcement learning methods, showing that there are hard limitations on what\nconstitutes good function approximation (in terms of the dimensionality of the\nrepresentation), where we focus on natural representational conditions relevant\nto value-based, model-based, and policy-based learning. These lower bounds\nhighlight that having a good (value-based, model-based, or policy-based)\nrepresentation in and of itself is insufficient for efficient reinforcement\nlearning, unless the quality of this approximation passes certain hard\nthresholds. Furthermore, our lower bounds also imply exponential separations on\nthe sample complexity between 1) value-based learning with perfect\nrepresentation and value-based learning with a good-but-not-perfect\nrepresentation, 2) value-based learning and policy-based learning, 3)\npolicy-based learning and supervised learning and 4) reinforcement learning and\nimitation learning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 19:04:43 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 04:04:19 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 01:00:13 GMT"}, {"version": "v4", "created": "Fri, 28 Feb 2020 03:31:55 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Du", "Simon S.", ""], ["Kakade", "Sham M.", ""], ["Wang", "Ruosong", ""], ["Yang", "Lin F.", ""]]}, {"id": "1910.03019", "submitter": "Atilim Gunes Baydin", "authors": "Gonzalo Mateo-Garcia, Silviu Oprea, Lewis Smith, Josh\n  Veitch-Michaelis, Guy Schumann, Yarin Gal, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin,\n  Dietmar Backes", "title": "Flood Detection On Low Cost Orbital Hardware", "comments": null, "journal-ref": "Artificial Intelligence for Humanitarian Assistance and Disaster\n  Response Workshop, 33rd Conference on Neural Information Processing Systems\n  (NeurIPS 2019), Vancouver, Canada", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satellite imaging is a critical technology for monitoring and responding to\nnatural disasters such as flooding. Despite the capabilities of modern\nsatellites, there is still much to be desired from the perspective of first\nresponse organisations like UNICEF. Two main challenges are rapid access to\ndata, and the ability to automatically identify flooded regions in images. We\ndescribe a prototypical flood segmentation system, identifying cloud, water and\nland, that could be deployed on a constellation of small satellites, performing\nprocessing on board to reduce downlink bandwidth by 2 orders of magnitude. We\ntarget PhiSat-1, part of the FSSCAT mission, which is planned to be launched by\nthe European Space Agency (ESA) near the start of 2020 as a proof of concept\nfor this new technology.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 13:29:46 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 12:54:40 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 21:03:29 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Mateo-Garcia", "Gonzalo", ""], ["Oprea", "Silviu", ""], ["Smith", "Lewis", ""], ["Veitch-Michaelis", "Josh", ""], ["Schumann", "Guy", ""], ["Gal", "Yarin", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Backes", "Dietmar", ""]]}, {"id": "1910.03023", "submitter": "Youzhi Liang", "authors": "Zeyu Bai, Ruizhi Yang, Youzhi Liang", "title": "Mental Task Classification Using Electroencephalogram Signal", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the classification problem on electroencephalogram (EEG)\ndata of mental tasks, using standard architecture of three-layer CNN, stacked\nLSTM, stacked GRU. We further propose a novel classifier - a mixed LSTM model\nwith a CNN decoder. A hyperparameter optimization on CNN shows validation\naccuracy of 72% and testing accuracy of 62%. The stacked LSTM and GRU models\nwith FFT preprocessing and downsampling on data achieve 55% and 51% testing\naccuracy respectively. As for the mixed LSTM model with CNN decoder, validation\naccuracy of 75% and testing accuracy of 70% are obtained. We believe the mixed\nmodel is more robust and accurate than both CNN and LSTM individually, by using\nthe CNN layer as a decoder for following LSTM layers. The code is completed in\nthe framework of Pytorch and Keras. Results and code can be found at\nhttps://github.com/theyou21/BigProject.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 02:14:07 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Bai", "Zeyu", ""], ["Yang", "Ruizhi", ""], ["Liang", "Youzhi", ""]]}, {"id": "1910.03025", "submitter": "Hyenkyun Woo", "authors": "Hyenkyun Woo", "title": "Bregman-divergence-guided Legendre exponential dispersion model with\n  finite cumulants (K-LED)", "comments": "21pages, 2figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CV cs.IT cs.LG math.IT math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential dispersion model is a useful framework in machine learning and\nstatistics. Primarily, thanks to the additive structure of the model, it can be\nachieved without difficulty to estimate parameters including mean. However,\ntight conditions on cumulant function, such as analyticity, strict convexity,\nand steepness, reduce the class of exponential dispersion model. In this work,\nwe present relaxed exponential dispersion model K-LED (Legendre exponential\ndispersion model with K cumulants). The cumulant function of the proposed model\nis a convex function of Legendre type having continuous partial derivatives of\nK-th order on the interior of a convex domain. Most of the K-LED models are\ndeveloped via Bregman-divergence-guided log-concave density function with\ncoercivity shape constraints. The main advantage of the proposed model is that\nthe first cumulant (or the mean parameter space) of the 1-LED model is easily\ncomputed through the extended global optimum property of Bregman divergence. An\nextended normal distribution is introduced as an example of 1-LED based on\nTweedie distribution. On top of that, we present 2-LED satisfying mean-variance\nrelation of quasi-likelihood function. There is an equivalence between a\nsubclass of quasi-likelihood function and a regular 2-LED model, of which the\ncanonical parameter space is open. A typical example is a regular 2-LED model\nwith power variance function, i.e., a variance is in proportion to the power of\nthe mean of observations. This model is equivalent to a subclass of\nbeta-divergence (or a subclass of quasi-likelihood function with power variance\nfunction). Furthermore, a new parameterized K-LED model, the cumulant function\nof which is the convex extended logistic loss function, is proposed. This model\nincludes Bernoulli distribution and Poisson distribution.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 11:24:31 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Woo", "Hyenkyun", ""]]}, {"id": "1910.03033", "submitter": "Erik Altman", "authors": "Erik R. Altman", "title": "Synthesizing Credit Card Transactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two elements have been essential to AI's recent boom: (1) deep neural nets\nand the theory and practice behind them; and (2) cloud computing with its\nabundant labeled data and large computing resources.\n  Abundant labeled data is available for key domains such as images, speech,\nnatural language processing, and recommendation engines. However, there are\nmany other domains where such data is not available, or access to it is highly\nrestricted for privacy reasons, as with health and financial data. Even when\nabundant data is available, it is often not labeled. Doing such labeling is\nlabor-intensive and non-scalable.\n  As a result, to the best of our knowledge, key domains still lack labeled\ndata or have at most toy data; or the synthetic data must have access to real\ndata from which it can mimic new data. This paper outlines work to generate\nrealistic synthetic data for an important domain: credit card transactions.\n  Some challenges: there are many patterns and correlations in real purchases.\nThere are millions of merchants and innumerable locations. Those merchants\noffer a wide variety of goods. Who shops where and when? How much do people\npay? What is a realistic fraudulent transaction?\n  We use a mixture of technical approaches and domain knowledge including\nmechanics of credit card processing, a broad set of consumer domains:\nelectronics, clothing, hair styling, etc. Connecting everything is a virtual\nworld. This paper outlines some of our key techniques and provides evidence\nthat the data generated is indeed realistic.\n  Beyond the scope of this paper: (1) use of our data to develop and train\nmodels to predict fraud; (2) coupling models and the synthetic dataset to\nassess performance in designing accelerators such as GPUs and TPUs.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 01:18:57 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Altman", "Erik R.", ""]]}, {"id": "1910.03053", "submitter": "Huaxiu Yao", "authors": "Huaxiu Yao, Chuxu Zhang, Ying Wei, Meng Jiang, Suhang Wang, Junzhou\n  Huang, Nitesh V. Chawla, Zhenhui Li", "title": "Graph Few-shot Learning via Knowledge Transfer", "comments": "Full paper (with Appendix) of AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards the challenging problem of semi-supervised node classification, there\nhave been extensive studies. As a frontier, Graph Neural Networks (GNNs) have\naroused great interest recently, which update the representation of each node\nby aggregating information of its neighbors. However, most GNNs have shallow\nlayers with a limited receptive field and may not achieve satisfactory\nperformance especially when the number of labeled nodes is quite small. To\naddress this challenge, we innovatively propose a graph few-shot learning (GFL)\nalgorithm that incorporates prior knowledge learned from auxiliary graphs to\nimprove classification accuracy on the target graph. Specifically, a\ntransferable metric space characterized by a node embedding and a\ngraph-specific prototype embedding function is shared between auxiliary graphs\nand the target, facilitating the transfer of structural knowledge. Extensive\nexperiments and ablation studies on four real-world graph datasets demonstrate\nthe effectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 19:52:11 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 22:12:52 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 14:46:03 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Yao", "Huaxiu", ""], ["Zhang", "Chuxu", ""], ["Wei", "Ying", ""], ["Jiang", "Meng", ""], ["Wang", "Suhang", ""], ["Huang", "Junzhou", ""], ["Chawla", "Nitesh V.", ""], ["Li", "Zhenhui", ""]]}, {"id": "1910.03055", "submitter": "Teny Handhayani", "authors": "Teny Handhayani and James Cussens", "title": "Kernel-based Approach to Handle Mixed Data for Inferring Causal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal learning is a beneficial approach to analyze the cause and effect\nrelationships among variables in a dataset. A causal graph can be generated\nfrom a dataset using a particular causal algorithm, for instance, the PC\nalgorithm or Fast Causal Inference (FCI). Generating a causal graph from a\ndataset that contains different data types (mixed data) is not trivial. This\nresearch offers an easy way to handle the mixed data so that it can be used to\nlearn causal graphs using the existing application of the PC algorithm and FCI.\nThis research proposes using kernel functions and Kernel Alignment to handle\nmixed data. Two main steps of this approach are computing a kernel matrix for\neach variable and calculating a pseudo-correlation matrix using Kernel\nAlignment. Kernel Alignment is used as a substitute for the correlation matrix\nfor the conditional independence test for Gaussian data in the PC Algorithm and\nFCI. The advantage of this idea is that is possible to handle any data type by\nusing a suitable kernel function to compute a kernel matrix for an observed\nvariable. The proposed method is successfully applied to learn a causal graph\nfrom mixed data containing categorical, binary, ordinal, and continuous\nvariables.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 19:57:08 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Handhayani", "Teny", ""], ["Cussens", "James", ""]]}, {"id": "1910.03058", "submitter": "Kevin Corder", "authors": "Kevin Corder, Manuel M. Vindiola, Keith Decker", "title": "Decentralized Multi-Agent Actor-Critic with Generative Inference", "comments": "8 pages. Accepted to Deep Reinforcement Learning Workshop at NeurIPS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent multi-agent actor-critic methods have utilized centralized training\nwith decentralized execution to address the non-stationarity of co-adapting\nagents. This training paradigm constrains learning to the centralized phase\nsuch that only pre-learned policies may be used during the decentralized phase,\nwhich performs poorly when agent communications are delayed, noisy, or\ndisrupted. In this work, we propose a new system that can gracefully handle\npartially-observable information due to communication disruptions during\ndecentralized execution. Our approach augments the multi-agent actor-critic\nmethod's centralized training phase with generative modeling so that agents may\ninfer other agents' observations when provided with locally available context.\nOur method is evaluated on three tasks that require agents to combine local and\nremote observations communicated by other agents. We evaluate our approach by\nintroducing both partial observability during decentralized execution, and show\nthat decentralized training on inferred observations performs as well or better\nthan existing actor-critic methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 20:02:46 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Corder", "Kevin", ""], ["Vindiola", "Manuel M.", ""], ["Decker", "Keith", ""]]}, {"id": "1910.03060", "submitter": "Dibyajyoti Pati", "authors": "Dibyajyoti Pati, Caroline Favart, Purujit Bahl, Vivek Soni, Yun-chan\n  Tsai, Michael Potter, Jiahui Guan, Xiaomeng Dong, V. Ratna Saripalli", "title": "Impact of Inference Accelerators on hardware selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As opportunities for AI-assisted healthcare grow steadily, model deployment\nfaces challenges due to the specific characteristics of the industry. The\nconfiguration choice for a production device can impact model performance while\ninfluencing operational costs. Moreover, in healthcare some situations might\nrequire fast, but not real time, inference. We study different configurations\nand conduct a cost-performance analysis to determine the optimized hardware for\nthe deployment of a model subject to healthcare domain constraints. We observe\nthat a naive performance comparison may not lead to an optimal configuration\nselection. In fact, given realistic domain constraints, CPU execution might be\npreferable to GPU accelerators. Hence, defining beforehand precise expectations\nfor model deployment is crucial.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 20:06:38 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Pati", "Dibyajyoti", ""], ["Favart", "Caroline", ""], ["Bahl", "Purujit", ""], ["Soni", "Vivek", ""], ["Tsai", "Yun-chan", ""], ["Potter", "Michael", ""], ["Guan", "Jiahui", ""], ["Dong", "Xiaomeng", ""], ["Saripalli", "V. Ratna", ""]]}, {"id": "1910.03072", "submitter": "Alexey Zaytsev", "authors": "I. Fursov, A. Zaytsev, R. Khasyanov, M. Spindler, E. Burnaev", "title": "Sequence embeddings help to identify fraudulent cases in healthcare\n  insurance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraud causes substantial costs and losses for companies and clients in the\nfinance and insurance industries. Examples are fraudulent credit card\ntransactions or fraudulent claims. It has been estimated that roughly $10$\npercent of the insurance industry's incurred losses and loss adjustment\nexpenses each year stem from fraudulent claims. The rise and proliferation of\ndigitization in finance and insurance have lead to big data sets, consisting in\nparticular of text data, which can be used for fraud detection. In this paper,\nwe propose architectures for text embeddings via deep learning, which help to\nimprove the detection of fraudulent claims compared to other machine learning\nmethods. We illustrate our methods using a data set from a large international\nhealth insurance company. The empirical results show that our approach\noutperforms other state-of-the-art methods and can help make the claims\nmanagement process more efficient. As (unstructured) text data become\nincreasingly available to economists and econometricians, our proposed methods\nwill be valuable for many similar applications, particularly when variables\nhave a large number of categories as is typical for example of the\nInternational Classification of Disease (ICD) codes in health economics and\nhealth services.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 20:37:02 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Fursov", "I.", ""], ["Zaytsev", "A.", ""], ["Khasyanov", "R.", ""], ["Spindler", "M.", ""], ["Burnaev", "E.", ""]]}, {"id": "1910.03081", "submitter": "Keegan Hines E", "authors": "Antonia Gogoglou and C. Bayan Bruss and Keegan E. Hines", "title": "On the Interpretability and Evaluation of Graph Representation Learning", "comments": "NeurIPS 2019 Graph Representation Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rising interest in graph representation learning, a variety of\napproaches have been proposed to effectively capture a graph's properties.\nWhile these approaches have improved performance in graph machine learning\ntasks compared to traditional graph techniques, they are still perceived as\ntechniques with limited insight into the information encoded in these\nrepresentations. In this work, we explore methods to interpret node embeddings\nand propose the creation of a robust evaluation framework for comparing graph\nrepresentation learning algorithms and hyperparameters. We test our methods on\ngraphs with different properties and investigate the relationship between\nembedding training parameters and the ability of the produced embedding to\nrecover the structure of the original graph in a downstream task.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 21:02:13 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Gogoglou", "Antonia", ""], ["Bruss", "C. Bayan", ""], ["Hines", "Keegan E.", ""]]}, {"id": "1910.03084", "submitter": "Kamran Kowsari", "authors": "Rasoul Sali, Lubaina Ehsan, Kamran Kowsari, Marium Khan, Christopher\n  A. Moskaluk, Sana Syed, Donald E. Brown", "title": "CeliacNet: Celiac Disease Severity Diagnosis on Duodenal\n  Histopathological Images Using Deep Residual Networks", "comments": "accepted at IEEE International Conference on Bioinformatics and\n  Biomedicine (IEEE BIBM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Celiac Disease (CD) is a chronic autoimmune disease that affects the small\nintestine in genetically predisposed children and adults. Gluten exposure\ntriggers an inflammatory cascade which leads to compromised intestinal barrier\nfunction. If this enteropathy is unrecognized, this can lead to anemia,\ndecreased bone density, and, in longstanding cases, intestinal cancer. The\nprevalence of the disorder is 1% in the United States. An intestinal (duodenal)\nbiopsy is considered the \"gold standard\" for diagnosis. The mild CD might go\nunnoticed due to non-specific clinical symptoms or mild histologic features. In\nour current work, we trained a model based on deep residual networks to\ndiagnose CD severity using a histological scoring system called the modified\nMarsh score. The proposed model was evaluated using an independent set of 120\nwhole slide images from 15 CD patients and achieved an AUC greater than 0.96 in\nall classes. These results demonstrate the diagnostic power of the proposed\nmodel for CD severity classification using histological images.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 21:06:41 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Sali", "Rasoul", ""], ["Ehsan", "Lubaina", ""], ["Kowsari", "Kamran", ""], ["Khan", "Marium", ""], ["Moskaluk", "Christopher A.", ""], ["Syed", "Sana", ""], ["Brown", "Donald E.", ""]]}, {"id": "1910.03085", "submitter": "Athanasios Vlontzos", "authors": "Kara Lamb, Garima Malhotra, Athanasios Vlontzos, Edward Wagstaff,\n  At{\\i}l{\\i}m G\\\"unes Baydin, Anahita Bhiwandiwalla, Yarin Gal, Alfredo\n  Kalaitzis, Anthony Reina, Asti Bhatt", "title": "Correlation of Auroral Dynamics and GNSS Scintillation with an\n  Autoencoder", "comments": "Four first authors contributed equally; Paper accepted in Machine\n  Learning for the Physical Sciences workshop of NeurIPS 2019; Camera Ready\n  Version to Follow", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.space-ph astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High energy particles originating from solar activity travel along the the\nEarth's magnetic field and interact with the atmosphere around the higher\nlatitudes. These interactions often manifest as aurora in the form of visible\nlight in the Earth's ionosphere. These interactions also result in\nirregularities in the electron density, which cause disruptions in the\namplitude and phase of the radio signals from the Global Navigation Satellite\nSystems (GNSS), known as 'scintillation'. In this paper we use a multi-scale\nresidual autoencoder (Res-AE) to show the correlation between specific dynamic\nstructures of the aurora and the magnitude of the GNSS phase scintillations\n($\\sigma_{\\phi}$). Auroral images are encoded in a lower dimensional feature\nspace using the Res-AE, which in turn are clustered with t-SNE and UMAP. Both\nmethods produce similar clusters, and specific clusters demonstrate greater\ncorrelations with observed phase scintillations. Our results suggest that\nspecific dynamic structures of auroras are highly correlated with GNSS phase\nscintillations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 08:43:56 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Lamb", "Kara", ""], ["Malhotra", "Garima", ""], ["Vlontzos", "Athanasios", ""], ["Wagstaff", "Edward", ""], ["Baydin", "At\u0131l\u0131m G\u00fcnes", ""], ["Bhiwandiwalla", "Anahita", ""], ["Gal", "Yarin", ""], ["Kalaitzis", "Alfredo", ""], ["Reina", "Anthony", ""], ["Bhatt", "Asti", ""]]}, {"id": "1910.03088", "submitter": "Wei Zhan", "authors": "Wei Zhan, Liting Sun, Di Wang, Haojie Shi, Aubrey Clausse, Maximilian\n  Naumann, Julius Kummerle, Hendrik Konigshof, Christoph Stiller, Arnaud de La\n  Fortelle, and Masayoshi Tomizuka", "title": "INTERACTION Dataset: An INTERnational, Adversarial and Cooperative\n  moTION Dataset in Interactive Driving Scenarios with Semantic Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior-related research areas such as motion prediction/planning,\nrepresentation/imitation learning, behavior modeling/generation, and algorithm\ntesting, require support from high-quality motion datasets containing\ninteractive driving scenarios with different driving cultures. In this paper,\nwe present an INTERnational, Adversarial and Cooperative moTION dataset\n(INTERACTION dataset) in interactive driving scenarios with semantic maps. Five\nfeatures of the dataset are highlighted. 1) The interactive driving scenarios\nare diverse, including urban/highway/ramp merging and lane changes, roundabouts\nwith yield/stop signs, signalized intersections, intersections with\none/two/all-way stops, etc. 2) Motion data from different countries and\ndifferent continents are collected so that driving preferences and styles in\ndifferent cultures are naturally included. 3) The driving behavior is highly\ninteractive and complex with adversarial and cooperative motions of various\ntraffic participants. Highly complex behavior such as negotiations,\naggressive/irrational decisions and traffic rule violations are densely\ncontained in the dataset, while regular behavior can also be found from\ncautious car-following, stop, left/right/U-turn to rational lane-change and\ncycling and pedestrian crossing, etc. 4) The levels of criticality span wide,\nfrom regular safe operations to dangerous, near-collision maneuvers. Real\ncollision, although relatively slight, is also included. 5) Maps with complete\nsemantic information are provided with physical layers, reference lines,\nlanelet connections and traffic rules. The data is recorded from drones and\ntraffic cameras. Statistics of the dataset in terms of number of entities and\ninteraction density are also provided, along with some utilization examples in\na variety of behavior-related research areas. The dataset can be downloaded via\nhttps://interaction-dataset.com.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:26:51 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Zhan", "Wei", ""], ["Sun", "Liting", ""], ["Wang", "Di", ""], ["Shi", "Haojie", ""], ["Clausse", "Aubrey", ""], ["Naumann", "Maximilian", ""], ["Kummerle", "Julius", ""], ["Konigshof", "Hendrik", ""], ["Stiller", "Christoph", ""], ["de La Fortelle", "Arnaud", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1910.03090", "submitter": "Fatih Cagatay Akyon", "authors": "Fatih Cagatay Akyon, Esat Kalfaoglu", "title": "Instagram Fake and Automated Account Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fake engagement is one of the significant problems in Online Social Networks\n(OSNs) which is used to increase the popularity of an account in an inorganic\nmanner. The detection of fake engagement is crucial because it leads to loss of\nmoney for businesses, wrong audience targeting in advertising, wrong product\npredictions systems, and unhealthy social network environment. This study is\nrelated with the detection of fake and automated accounts which leads to fake\nengagement on Instagram. Prior to this work, there were no publicly available\ndataset for fake and automated accounts. For this purpose, two datasets have\nbeen published for the detection of fake and automated accounts. For the\ndetection of these accounts, machine learning algorithms like Naive Bayes,\nLogistic Regression, Support Vector Machines and Neural Networks are applied.\nAdditionally, for the detection of automated accounts, cost sensitive genetic\nalgorithm is proposed to handle the unnatural bias in the dataset. To deal with\nthe unevenness problem in the fake dataset, Smote-nc algorithm is implemented.\nFor the automated and fake account detection datasets, 86% and 96%\nclassification accuracies are obtained, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 12:51:01 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 10:08:35 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Akyon", "Fatih Cagatay", ""], ["Kalfaoglu", "Esat", ""]]}, {"id": "1910.03094", "submitter": "Michael V Sullins", "authors": "Ian A. Kash, Michael Sullins, Katja Hofmann", "title": "Combining No-regret and Q-learning", "comments": "Presented as conference paper at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Regret Minimization (CFR) has found success in settings like\npoker which have both terminal states and perfect recall. We seek to understand\nhow to relax these requirements. As a first step, we introduce a simple\nalgorithm, local no-regret learning (LONR), which uses a Q-learning-like update\nrule to allow learning without terminal states or perfect recall. We prove its\nconvergence for the basic case of MDPs (and limited extensions of them) and\npresent empirical results showing that it achieves last iterate convergence in\na number of settings, most notably NoSDE games, a class of Markov games\nspecifically designed to be challenging to learn where no prior algorithm is\nknown to achieve convergence to a stationary equilibrium even on average.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 21:13:55 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 16:58:54 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Kash", "Ian A.", ""], ["Sullins", "Michael", ""], ["Hofmann", "Katja", ""]]}, {"id": "1910.03097", "submitter": "Pedro M. Milani", "authors": "Pedro M. Milani, Julia Ling, John K. Eaton", "title": "Generalization of machine-learned turbulent heat flux models applied to\n  film cooling flows", "comments": "Presented at ASME Turbo Expo 2019, accepted to the Journal of\n  Turbomachinery", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of film cooling systems relies heavily on Reynolds-Averaged\nNavier-Stokes (RANS) simulations, which solve for mean quantities and model all\nturbulent scales. Most turbulent heat flux models, which are based on isotropic\ndiffusion with a fixed turbulent Prandtl number ($Pr_t$), fail to accurately\npredict heat transfer in film cooling flows. In the present work, machine\nlearning models are trained to predict a non-uniform $Pr_t$ field, using\nvarious datasets as training sets. The ability of these models to generalize\nbeyond the flows on which they were trained is explored. Furthermore,\nvisualization techniques are employed to compare distinct datasets and to help\nexplain the cross-validation results.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 21:26:53 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Milani", "Pedro M.", ""], ["Ling", "Julia", ""], ["Eaton", "John K.", ""]]}, {"id": "1910.03103", "submitter": "Dilin Wang", "authors": "Dilin Wang, Meng Li, Lemeng Wu, Vikas Chandra, Qiang Liu", "title": "Energy-Aware Neural Architecture Optimization with Fast Splitting\n  Steepest Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing energy-efficient networks is of critical importance for enabling\nstate-of-the-art deep learning in mobile and edge settings where the\ncomputation and energy budgets are highly limited. Recently, Liu et al. (2019)\nframed the search of efficient neural architectures into a continuous splitting\nprocess: it iteratively splits existing neurons into multiple off-springs to\nachieve progressive loss minimization, thus finding novel architectures by\ngradually growing the neural network. However, this method was not specifically\ntailored for designing energy-efficient networks, and is computationally\nexpensive on large-scale benchmarks. In this work, we substantially improve Liu\net al. (2019) in two significant ways: 1) we incorporate the energy cost of\nsplitting different neurons to better guide the splitting process, thereby\ndiscovering more energy-efficient network architectures; 2) we substantially\nspeed up the splitting process of Liu et al. (2019), which requires expensive\neigen-decomposition, by proposing a highly scalable Rayleigh-quotient\nstochastic gradient algorithm. Our fast algorithm allows us to reduce the\ncomputational cost of splitting to the same level of typical back-propagation\nupdates and enables efficient implementation on GPU. Extensive empirical\nresults show that our method can train highly accurate and energy-efficient\nnetworks on challenging datasets such as ImageNet, improving a variety of\nbaselines, including the pruning-based methods and expert-designed\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 21:45:17 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 17:20:13 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 20:58:06 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Wang", "Dilin", ""], ["Li", "Meng", ""], ["Wu", "Lemeng", ""], ["Chandra", "Vikas", ""], ["Liu", "Qiang", ""]]}, {"id": "1910.03112", "submitter": "Feras Batarseh", "authors": "Feras Batarseh, Munisamy Gopinath, Ganesh Nalluru, Jayson Beckman", "title": "Application of Machine Learning in Forecasting International Trade\n  Trends", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  International trade policies have recently garnered attention for limiting\ncross-border exchange of essential goods (e.g. steel, aluminum, soybeans, and\nbeef). Since trade critically affects employment and wages, predicting future\npatterns of trade is a high-priority for policy makers around the world. While\ntraditional economic models aim to be reliable predictors, we consider the\npossibility that Machine Learning (ML) techniques allow for better predictions\nto inform policy decisions. Open-government data provide the fuel to power the\nalgorithms that can explain and forecast trade flows to inform policies. Data\ncollected in this article describe international trade transactions and\ncommonly associated economic factors. Machine learning (ML) models deployed\ninclude: ARIMA, GBoosting, XGBoosting, and LightGBM for predicting future trade\npatterns, and K-Means clustering of countries according to economic factors.\nUnlike short-term and subjective (straight-line) projections and medium-term\n(aggre-gated) projections, ML methods provide a range of data-driven and\ninterpretable projections for individual commodities. Models, their results,\nand policies are introduced and evaluated for prediction quality.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 22:05:45 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Batarseh", "Feras", ""], ["Gopinath", "Munisamy", ""], ["Nalluru", "Ganesh", ""], ["Beckman", "Jayson", ""]]}, {"id": "1910.03127", "submitter": "Gabriele Scalia", "authors": "Gabriele Scalia, Colin A. Grambow, Barbara Pernici, Yi-Pei Li, William\n  H. Green", "title": "Evaluating Scalable Uncertainty Estimation Methods for DNN-Based\n  Molecular Property Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep neural network (DNN) based molecular property prediction\nhave recently led to the development of models of remarkable accuracy and\ngeneralization ability, with graph convolution neural networks (GCNNs)\nreporting state-of-the-art performance for this task. However, some challenges\nremain and one of the most important that needs to be fully addressed concerns\nuncertainty quantification. DNN performance is affected by the volume and the\nquality of the training samples. Therefore, establishing when and to what\nextent a prediction can be considered reliable is just as important as\noutputting accurate predictions, especially when out-of-domain molecules are\ntargeted. Recently, several methods to account for uncertainty in DNNs have\nbeen proposed, most of which are based on approximate Bayesian inference. Among\nthese, only a few scale to the large datasets required in applications.\nEvaluating and comparing these methods has recently attracted great interest,\nbut results are generally fragmented and absent for molecular property\nprediction. In this paper, we aim to quantitatively compare scalable techniques\nfor uncertainty estimation in GCNNs. We introduce a set of quantitative\ncriteria to capture different uncertainty aspects, and then use these criteria\nto compare MC-Dropout, deep ensembles, and bootstrapping, both theoretically in\na unified framework that separates aleatoric/epistemic uncertainty and\nexperimentally on the QM9 dataset. Our experiments quantify the performance of\nthe different uncertainty estimation methods and their impact on\nuncertainty-related error reduction. Our findings indicate that ensembling and\nbootstrapping consistently outperform MC-Dropout, with different\ncontext-specific pros and cons. Our analysis also leads to a better\nunderstanding of the role of aleatoric/epistemic uncertainty and highlights the\nchallenge posed by out-of-domain uncertainty.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 23:04:43 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Scalia", "Gabriele", ""], ["Grambow", "Colin A.", ""], ["Pernici", "Barbara", ""], ["Li", "Yi-Pei", ""], ["Green", "William H.", ""]]}, {"id": "1910.03131", "submitter": "Moritz Hoffmann", "authors": "Moritz Hoffmann, Frank No\\'e", "title": "Generating valid Euclidean distance matrices", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating point clouds, e.g., molecular structures, in arbitrary rotations,\ntranslations, and enumerations remains a challenging task. Meanwhile, neural\nnetworks utilizing symmetry invariant layers have been shown to be able to\noptimize their training objective in a data-efficient way. In this spirit, we\npresent an architecture which allows to produce valid Euclidean distance\nmatrices, which by construction are already invariant under rotation and\ntranslation of the described object. Motivated by the goal to generate\nmolecular structures in Cartesian space, we use this architecture to construct\na Wasserstein GAN utilizing a permutation invariant critic network. This makes\nit possible to generate molecular structures in a one-shot fashion by producing\nEuclidean distance matrices which have a three-dimensional embedding.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 23:30:05 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 00:59:42 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Hoffmann", "Moritz", ""], ["No\u00e9", "Frank", ""]]}, {"id": "1910.03135", "submitter": "Ankur Handa", "authors": "Ankur Handa, Karl Van Wyk, Wei Yang, Jacky Liang, Yu-Wei Chao, Qian\n  Wan, Stan Birchfield, Nathan Ratliff, Dieter Fox", "title": "DexPilot: Vision Based Teleoperation of Dexterous Robotic Hand-Arm\n  System", "comments": "17 pages, first version of DexPilot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Teleoperation offers the possibility of imparting robotic systems with\nsophisticated reasoning skills, intuition, and creativity to perform tasks.\nHowever, current teleoperation solutions for high degree-of-actuation (DoA),\nmulti-fingered robots are generally cost-prohibitive, while low-cost offerings\nusually provide reduced degrees of control. Herein, a low-cost, vision based\nteleoperation system, DexPilot, was developed that allows for complete control\nover the full 23 DoA robotic system by merely observing the bare human hand.\nDexPilot enables operators to carry out a variety of complex manipulation tasks\nthat go beyond simple pick-and-place operations. This allows for collection of\nhigh dimensional, multi-modality, state-action data that can be leveraged in\nthe future to learn sensorimotor policies for challenging manipulation tasks.\nThe system performance was measured through speed and reliability metrics\nacross two human demonstrators on a variety of tasks. The videos of the\nexperiments can be found at https://sites.google.com/view/dex-pilot.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 23:43:32 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 20:58:22 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Handa", "Ankur", ""], ["Van Wyk", "Karl", ""], ["Yang", "Wei", ""], ["Liang", "Jacky", ""], ["Chao", "Yu-Wei", ""], ["Wan", "Qian", ""], ["Birchfield", "Stan", ""], ["Ratliff", "Nathan", ""], ["Fox", "Dieter", ""]]}, {"id": "1910.03137", "submitter": "Xiaojun Xu", "authors": "Xiaojun Xu, Qi Wang, Huichen Li, Nikita Borisov, Carl A. Gunter, Bo Li", "title": "Detecting AI Trojans Using Meta Neural Analysis", "comments": "Accepted by IEEE S&P 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning Trojan attacks, an adversary trains a corrupted model\nthat obtains good performance on normal data but behaves maliciously on data\nsamples with certain trigger patterns. Several approaches have been proposed to\ndetect such attacks, but they make undesirable assumptions about the attack\nstrategies or require direct access to the trained models, which restricts\ntheir utility in practice.\n  This paper addresses these challenges by introducing a Meta Neural Trojan\nDetection (MNTD) pipeline that does not make assumptions on the attack\nstrategies and only needs black-box access to models. The strategy is to train\na meta-classifier that predicts whether a given target model is Trojaned. To\ntrain the meta-model without knowledge of the attack strategy, we introduce a\ntechnique called jumbo learning that samples a set of Trojaned models following\na general distribution. We then dynamically optimize a query set together with\nthe meta-classifier to distinguish between Trojaned and benign models.\n  We evaluate MNTD with experiments on vision, speech, tabular data and natural\nlanguage text datasets, and against different Trojan attacks such as data\npoisoning attack, model manipulation attack, and latent attack. We show that\nMNTD achieves 97% detection AUC score and significantly outperforms existing\ndetection approaches. In addition, MNTD generalizes well and achieves high\ndetection performance against unforeseen attacks. We also propose a robust MNTD\npipeline which achieves 90% detection AUC even when the attacker aims to evade\nthe detection with full knowledge of the system.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 00:00:23 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 15:35:55 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 00:24:01 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 17:06:03 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Xu", "Xiaojun", ""], ["Wang", "Qi", ""], ["Li", "Huichen", ""], ["Borisov", "Nikita", ""], ["Gunter", "Carl A.", ""], ["Li", "Bo", ""]]}, {"id": "1910.03143", "submitter": "Ryan Cory-Wright", "authors": "Dimitris Bertsimas, Ryan Cory-Wright", "title": "On Polyhedral and Second-Order Cone Decompositions of Semidefinite\n  Optimization Problems", "comments": "Submitted minor revision to Operations Research Letters; removed\n  footnotes and corrected some minor typos in previous version", "journal-ref": "Operations Research Letters 48(1):78-85 (2020)", "doi": "10.1016/j.orl.2019.12.003", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a cutting-plane method for semidefinite optimization problems\n(SDOs), and supply a proof of the method's convergence, under a boundedness\nassumption. By relating the method's rate of convergence to an initial outer\napproximation's diameter, we argue that the method performs well when\ninitialized with a second-order-cone approximation, instead of a linear\napproximation. We invoke the method to provide bound gaps of 0.5-6.5% for\nsparse PCA problems with $1000$s of covariates, and solve nuclear norm problems\nover 500x500 matrices.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 00:33:19 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 20:32:51 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Cory-Wright", "Ryan", ""]]}, {"id": "1910.03155", "submitter": "Jiaheng Wei", "authors": "Jiaheng Wei, Zuyue Fu, Yang Liu, Xingyu Li, Zhuoran Yang, Zhaoran Wang", "title": "Sample Elicitation", "comments": "To appear at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to collect credible training samples $(x,y)$ for building\ndata-intensive learning systems (e.g., a deep learning system). Asking people\nto report complex distribution $p(x)$, though theoretically viable, is\nchallenging in practice. This is primarily due to the cognitive loads required\nfor human agents to form the report of this highly complicated information.\nWhile classical elicitation mechanisms apply to eliciting a complex and\ngenerative (and continuous) distribution $p(x)$, we are interested in eliciting\nsamples $x_i \\sim p(x)$ from agents directly. We coin the above problem \"sample\nelicitation\". This paper introduces a deep learning aided method to incentivize\ncredible sample contributions from self-interested and rational agents. We show\nthat with an accurate estimation of a certain $f$-divergence function we can\nachieve approximate incentive compatibility in eliciting truthful samples. We\nthen present an efficient estimator with theoretical guarantees via studying\nthe variational forms of the $f$-divergence function. We also show a connection\nbetween this sample elicitation problem and $f$-GAN, and how this connection\ncan help reconstruct an estimator of the distribution based on collected\nsamples. Experiments on synthetic data, MNIST, and CIFAR-10 datasets\ndemonstrate that our mechanism elicits truthful samples. Our implementation is\navailable at https://github.com/weijiaheng/Credible-sample-elicitation.git.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 01:23:11 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 20:38:52 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 09:05:19 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Wei", "Jiaheng", ""], ["Fu", "Zuyue", ""], ["Liu", "Yang", ""], ["Li", "Xingyu", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1910.03159", "submitter": "Daniel Barry", "authors": "Daniel Barry and Munir Shah and Merel Keijsers and Humayun Khan and\n  Banon Hopman", "title": "xYOLO: A Model For Real-Time Object Detection In Humanoid Soccer On\n  Low-End Hardware", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of onboard vision processing for areas such as the\ninternet of things (IoT), edge computing and autonomous robots, there is\nincreasing demand for computationally efficient convolutional neural network\n(CNN) models to perform real-time object detection on resource constraints\nhardware devices. Tiny-YOLO is generally considered as one of the faster object\ndetectors for low-end devices and is the basis for our work. Our experiments on\nthis network have shown that Tiny-YOLO can achieve 0.14 frames per second(FPS)\non the Raspberry Pi 3 B, which is too slow for soccer playing autonomous\nhumanoid robots detecting goal and ball objects. In this paper we propose an\nadaptation to the YOLO CNN model named xYOLO, that can achieve object detection\nat a speed of 9.66 FPS on the Raspberry Pi 3 B. This is achieved by trading an\nacceptable amount of accuracy, making the network approximately 70 times faster\nthan Tiny-YOLO. Greater inference speed-ups were also achieved on a desktop CPU\nand GPU. Additionally we contribute an annotated Darknet dataset for goal and\nball detection.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 01:33:52 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Barry", "Daniel", ""], ["Shah", "Munir", ""], ["Keijsers", "Merel", ""], ["Khan", "Humayun", ""], ["Hopman", "Banon", ""]]}, {"id": "1910.03175", "submitter": "Micha Livne", "authors": "Micha Livne, Kevin Swersky, David J. Fleet", "title": "MIM: Mutual Information Machine", "comments": "Pre-print. Project webpage:\n  https://research.seraphlabs.ca/projects/mim/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Mutual Information Machine (MIM), a probabilistic\nauto-encoder for learning joint distributions over observations and latent\nvariables. MIM reflects three design principles: 1) low divergence, to\nencourage the encoder and decoder to learn consistent factorizations of the\nsame underlying distribution; 2) high mutual information, to encourage an\ninformative relation between data and latent variables; and 3) low marginal\nentropy, or compression, which tends to encourage clustered latent\nrepresentations. We show that a combination of the Jensen-Shannon divergence\nand the joint entropy of the encoding and decoding distributions satisfies\nthese criteria, and admits a tractable cross-entropy bound that can be\noptimized directly with Monte Carlo and stochastic gradient descent. We\ncontrast MIM learning with maximum likelihood and VAEs. Experiments show that\nMIM learns representations with high mutual information, consistent encoding\nand decoding distributions, effective latent clustering, and data log\nlikelihood comparable to VAE, while avoiding posterior collapse.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 02:31:29 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 16:44:24 GMT"}, {"version": "v3", "created": "Sun, 15 Dec 2019 01:40:54 GMT"}, {"version": "v4", "created": "Thu, 20 Feb 2020 05:09:28 GMT"}, {"version": "v5", "created": "Fri, 21 Feb 2020 15:45:19 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Livne", "Micha", ""], ["Swersky", "Kevin", ""], ["Fleet", "David J.", ""]]}, {"id": "1910.03176", "submitter": "Ta-Chun Su", "authors": "Ta-Chun Su, Hsiang-Chih Cheng", "title": "SesameBERT: Attention for Anywhere", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning with pre-trained models has achieved exceptional results for many\nlanguage tasks. In this study, we focused on one such self-attention network\nmodel, namely BERT, which has performed well in terms of stacking layers across\ndiverse language-understanding benchmarks. However, in many downstream tasks,\ninformation between layers is ignored by BERT for fine-tuning. In addition,\nalthough self-attention networks are well-known for their ability to capture\nglobal dependencies, room for improvement remains in terms of emphasizing the\nimportance of local contexts. In light of these advantages and disadvantages,\nthis paper proposes SesameBERT, a generalized fine-tuning method that (1)\nenables the extraction of global information among all layers through Squeeze\nand Excitation and (2) enriches local information by capturing neighboring\ncontexts via Gaussian blurring. Furthermore, we demonstrated the effectiveness\nof our approach in the HANS dataset, which is used to determine whether models\nhave adopted shallow heuristics instead of learning underlying generalizations.\nThe experiments revealed that SesameBERT outperformed BERT with respect to GLUE\nbenchmark and the HANS evaluation set.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 02:31:35 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Su", "Ta-Chun", ""], ["Cheng", "Hsiang-Chih", ""]]}, {"id": "1910.03177", "submitter": "Rajeev Bhatt Ambati", "authors": "Rajeev Bhatt Ambati, Saptarashmi Bandyopadhyay and Prasenjit Mitra", "title": "Read, Highlight and Summarize: A Hierarchical Neural Semantic\n  Encoder-based Approach", "comments": "Submitted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional sequence-to-sequence (seq2seq) models and other variations of the\nattention-mechanism such as hierarchical attention have been applied to the\ntext summarization problem. Though there is a hierarchy in the way humans use\nlanguage by forming paragraphs from sentences and sentences from words,\nhierarchical models have usually not worked that much better than their\ntraditional seq2seq counterparts. This effect is mainly because either the\nhierarchical attention mechanisms are too sparse using hard attention or noisy\nusing soft attention. In this paper, we propose a method based on extracting\nthe highlights of a document; a key concept that is conveyed in a few\nsentences. In a typical text summarization dataset consisting of documents that\nare 800 tokens in length (average), capturing long-term dependencies is very\nimportant, e.g., the last sentence can be grouped with the first sentence of a\ndocument to form a summary. LSTMs (Long Short-Term Memory) proved useful for\nmachine translation. However, they often fail to capture long-term dependencies\nwhile modeling long sequences. To address these issues, we have adapted Neural\nSemantic Encoders (NSE) to text summarization, a class of memory-augmented\nneural networks by improving its functionalities and proposed a novel\nhierarchical NSE that outperforms similar previous models significantly. The\nquality of summarization was improved by augmenting linguistic factors, namely\nlemma, and Part-of-Speech (PoS) tags, to each word in the dataset for improved\nvocabulary coverage and generalization. The hierarchical NSE model on factored\ndataset outperformed the state-of-the-art by nearly 4 ROUGE points. We further\ndesigned and used the first GPU-based self-critical Reinforcement Learning\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 02:36:02 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 04:54:54 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Ambati", "Rajeev Bhatt", ""], ["Bandyopadhyay", "Saptarashmi", ""], ["Mitra", "Prasenjit", ""]]}, {"id": "1910.03188", "submitter": "Rahul-Vigneswaran K", "authors": "Rahul-Vigneswaran K, Sachin-Kumar S, Neethu Mohan, Soman KP", "title": "Dynamic Mode Decomposition based feature for Image Classification", "comments": "Selected for Spotlight presentation at TENCON 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Irrespective of the fact that Machine learning has produced groundbreaking\nresults, it demands an enormous amount of data in order to perform so. Even\nthough data production has been in its all-time high, almost all the data is\nunlabelled, hence making them unsuitable for training the algorithms. This\npaper proposes a novel method of extracting the features using Dynamic Mode\nDecomposition (DMD). The experiment is performed using data samples from\nImagenet. The learning is done using SVM-linear, SVM-RBF, Random Kitchen Sink\napproach (RKS). The results have shown that DMD features with RKS give\ncompeting results.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 03:09:42 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["K", "Rahul-Vigneswaran", ""], ["S", "Sachin-Kumar", ""], ["Mohan", "Neethu", ""], ["KP", "Soman", ""]]}, {"id": "1910.03191", "submitter": "Matthew Hancock PhD", "authors": "Matthew C Hancock and Jerry F Magnan", "title": "Level set image segmentation with velocity term learned from data with\n  applications to lung nodule segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Lung nodule segmentation, i.e., the algorithmic delineation of the\nlung nodule surface, is a fundamental component of computational nodule\nanalysis pipelines. We propose a new method for segmentation that is a machine\nlearning based extension of current approaches, using labeled image examples to\nimprove its accuracy.\n  Approach: We introduce an extension of the standard level set image\nsegmentation method where the velocity function is learned from data via\nmachine learning regression methods, rather than a priori designed. Instead,\nthe method employs a set of features to learn a velocity function that guides\nthe level set evolution from initialization.\n  Results: We apply the method to image volumes of lung nodules from CT scans\nin the publicly available LIDC dataset, obtaining an average intersection over\nunion score of 0.7185($\\pm$0.1114), which is competitive with other methods. We\nanalyze segmentation performance by anatomical and appearance-based categories\nof the nodules, finding that the method performs better for isolated nodules\nwith well-defined margins. We find that the segmentation performance for\nnodules in more complex surroundings and having more complex CT appearance is\nimproved with the addition of combined global-local features.\n  Conclusions: The level set machine learning segmentation approach proposed\nherein is competitive with current methods. It provides accurate lung nodule\nsegmentation results in a variety of anatomical contexts.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 03:13:17 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 02:26:22 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 01:42:22 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Hancock", "Matthew C", ""], ["Magnan", "Jerry F", ""]]}, {"id": "1910.03193", "submitter": "Lu Lu", "authors": "Lu Lu, Pengzhan Jin, George Em Karniadakis", "title": "DeepONet: Learning nonlinear operators for identifying differential\n  equations based on the universal approximation theorem of operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While it is widely known that neural networks are universal approximators of\ncontinuous functions, a less known and perhaps more powerful result is that a\nneural network with a single hidden layer can approximate accurately any\nnonlinear continuous operator. This universal approximation theorem is\nsuggestive of the potential application of neural networks in learning\nnonlinear operators from data. However, the theorem guarantees only a small\napproximation error for a sufficient large network, and does not consider the\nimportant optimization and generalization errors. To realize this theorem in\npractice, we propose deep operator networks (DeepONets) to learn operators\naccurately and efficiently from a relatively small dataset. A DeepONet consists\nof two sub-networks, one for encoding the input function at a fixed number of\nsensors $x_i, i=1,\\dots,m$ (branch net), and another for encoding the locations\nfor the output functions (trunk net). We perform systematic simulations for\nidentifying two types of operators, i.e., dynamic systems and partial\ndifferential equations, and demonstrate that DeepONet significantly reduces the\ngeneralization error compared to the fully-connected networks. We also derive\ntheoretically the dependence of the approximation error in terms of the number\nof sensors (where the input function is defined) as well as the input function\ntype, and we verify the theorem with computational results. More importantly,\nwe observe high-order error convergence in our computational tests, namely\npolynomial rates (from half order to fourth order) and even exponential\nconvergence with respect to the training dataset size.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 03:21:14 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 02:31:17 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 00:51:54 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Lu", "Lu", ""], ["Jin", "Pengzhan", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1910.03196", "submitter": "Xiangxiang Xu", "authors": "Shao-Lun Huang, Xiangxiang Xu, Lizhong Zheng", "title": "An Information-theoretic Approach to Unsupervised Feature Selection for\n  High-Dimensional Data", "comments": "35 pages; Submitted to IEEE Journal on Selected Areas in Information\n  Theory (JSAIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an information-theoretic approach to design the\nfunctional representations to extract the hidden common structure shared by a\nset of random variables. The main idea is to measure the common information\nbetween the random variables by Watanabe's total correlation, and then find the\nhidden attributes of these random variables such that the common information is\nreduced the most given these attributes. We show that these attributes can be\ncharacterized by an exponential family specified by the eigen-decomposition of\nsome pairwise joint distribution matrix. Then, we adopt the log-likelihood\nfunctions for estimating these attributes as the desired functional\nrepresentations of the random variables, and show that such representations are\ninformative to describe the common structure. Moreover, we design both the\nmultivariate alternating conditional expectation (MACE) algorithm to compute\nthe proposed functional representations for discrete data, and a novel neural\nnetwork training approach for continuous or high-dimensional data. Furthermore,\nwe show that our approach has deep connections to existing techniques, such as\nHirschfeld-Gebelein-R\\'{e}nyi (HGR) maximal correlation, linear principal\ncomponent analysis (PCA), and consistent functional map, which establishes\ninsightful connections between information theory and machine learning.\nFinally, the performances of our algorithms are validated by numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 03:36:27 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Huang", "Shao-Lun", ""], ["Xu", "Xiangxiang", ""], ["Zheng", "Lizhong", ""]]}, {"id": "1910.03197", "submitter": "Wei Liu", "authors": "Wei Liu, Li Chen, Yunfei Chen and Wenyi Zhang", "title": "Accelerating Federated Learning via Momentum Gradient Descent", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) provides a communication-efficient approach to solve\nmachine learning problems concerning distributed data, without sending raw data\nto a central server. However, existing works on FL only utilize first-order\ngradient descent (GD) and do not consider the preceding iterations to gradient\nupdate which can potentially accelerate convergence. In this paper, we consider\nmomentum term which relates to the last iteration. The proposed momentum\nfederated learning (MFL) uses momentum gradient descent (MGD) in the local\nupdate step of FL system. We establish global convergence properties of MFL and\nderive an upper bound on MFL convergence rate. Comparing the upper bounds on\nMFL and FL convergence rate, we provide conditions in which MFL accelerates the\nconvergence. For different machine learning models, the convergence performance\nof MFL is evaluated based on experiments with MNIST dataset. Simulation results\ncomfirm that MFL is globally convergent and further reveal significant\nconvergence improvement over FL.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 03:42:58 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 08:16:34 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Liu", "Wei", ""], ["Chen", "Li", ""], ["Chen", "Yunfei", ""], ["Zhang", "Wenyi", ""]]}, {"id": "1910.03201", "submitter": "Yongjin Lee", "authors": "Yognjin Lee", "title": "Differentiable Sparsification for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have relieved a great deal of burden on human experts in\nrelation to feature engineering. However, comparable efforts are instead\nrequired to determine effective architectures. In addition, as the sizes of\nnetworks have grown overly large, a considerable amount of resources is also\ninvested in reducing the sizes. The sparsification of an over-complete model\naddresses these problems as it removes redundant components and connections. In\nthis study, we propose a fully differentiable sparsification method for deep\nneural networks which allows parameters to be zero during training via\nstochastic gradient descent. Thus, the proposed method can learn the sparsified\nstructure and weights of a network in an end-to-end manner. The method is\ndirectly applicable to various modern deep neural networks and imposes minimum\nmodification to existing models. To the best of our knowledge, this is the\nfirst fully [sub-]differentiable sparsification method that zeroes out\nparameters. It provides a foundation for future structure learning and model\ncompression methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 03:57:04 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 05:29:13 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 02:38:35 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 01:40:03 GMT"}, {"version": "v5", "created": "Thu, 1 Jul 2021 09:42:57 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Lee", "Yognjin", ""]]}, {"id": "1910.03203", "submitter": "Amanda Kowalczyk", "authors": "Zijian Gao and Amanda Kowalczyk", "title": "Random forest model identifies serve strength as a key predictor of\n  tennis match outcome", "comments": "12 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tennis is a popular sport worldwide, boasting millions of fans and numerous\nnational and international tournaments. Like many sports, tennis has benefitted\nfrom the popularity of rigorous record-keeping of game and player information,\nas well as the growth of machine learning methods for use in sports analytics.\nOf particular interest to bettors and betting companies alike is potential use\nof sports records to predict tennis match outcomes prior to match start. We\ncompiled, cleaned, and used the largest database of tennis match information to\ndate to predict match outcome using fairly simple machine learning methods.\nUsing such methods allows for rapid fit and prediction times to readily\nincorporate new data and make real-time predictions. We were able to predict\nmatch outcomes with upwards of 80% accuracy, much greater than predictions\nusing betting odds alone, and identify serve strength as a key predictor of\nmatch outcome. By combining prediction accuracies from three models, we were\nable to nearly recreate a probability distribution based on average betting\nodds from betting companies, which indicates that betting companies are using\nsimilar information to assign odds to matches. These results demonstrate the\ncapability of relatively simple machine learning models to quite accurately\npredict tennis match outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 04:05:59 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Gao", "Zijian", ""], ["Kowalczyk", "Amanda", ""]]}, {"id": "1910.03206", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Shriphani Palakodety, Ashiqur R. KhudaBukhsh, Jaime G. Carbonell", "title": "Voice for the Voiceless: Active Sampling to Detect Comments Supporting\n  the Rohingyas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Rohingya refugee crisis is one of the biggest humanitarian crises of\nmodern times with more than 600,000 Rohingyas rendered homeless according to\nthe United Nations High Commissioner for Refugees. While it has received\nsustained press attention globally, no comprehensive research has been\nperformed on social media pertaining to this large evolving crisis. In this\nwork, we construct a substantial corpus of YouTube video comments (263,482\ncomments from 113,250 users in 5,153 relevant videos) with an aim to analyze\nthe possible role of AI in helping a marginalized community. Using a novel\ncombination of multiple Active Learning strategies and a novel active sampling\nstrategy based on nearest-neighbors in the comment-embedding space, we\nconstruct a classifier that can detect comments defending the Rohingyas among\nlarger numbers of disparaging and neutral ones. We advocate that beyond the\nburgeoning field of hate-speech detection, automatic detection of\n\\emph{help-speech} can lend voice to the voiceless people and make the internet\nsafer for marginalized communities.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 04:17:33 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 19:33:00 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Palakodety", "Shriphani", ""], ["KhudaBukhsh", "Ashiqur R.", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "1910.03225", "submitter": "Alejandro Schuler", "authors": "Tony Duan, Anand Avati, Daisy Yi Ding, Khanh K. Thai, Sanjay Basu,\n  Andrew Y. Ng, Alejandro Schuler", "title": "NGBoost: Natural Gradient Boosting for Probabilistic Prediction", "comments": "Accepted for ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Natural Gradient Boosting (NGBoost), an algorithm for generic\nprobabilistic prediction via gradient boosting. Typical regression models\nreturn a point estimate, conditional on covariates, but probabilistic\nregression models output a full probability distribution over the outcome\nspace, conditional on the covariates. This allows for predictive uncertainty\nestimation -- crucial in applications like healthcare and weather forecasting.\nNGBoost generalizes gradient boosting to probabilistic regression by treating\nthe parameters of the conditional distribution as targets for a multiparameter\nboosting algorithm. Furthermore, we show how the Natural Gradient is required\nto correct the training dynamics of our multiparameter boosting approach.\nNGBoost can be used with any base learner, any family of distributions with\ncontinuous parameters, and any scoring rule. NGBoost matches or exceeds the\nperformance of existing methods for probabilistic prediction while offering\nadditional benefits in flexibility, scalability, and usability. An open-source\nimplementation is available at github.com/stanfordmlgroup/ngboost.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 06:07:13 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 21:56:50 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 20:52:49 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 17:25:09 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Duan", "Tony", ""], ["Avati", "Anand", ""], ["Ding", "Daisy Yi", ""], ["Thai", "Khanh K.", ""], ["Basu", "Sanjay", ""], ["Ng", "Andrew Y.", ""], ["Schuler", "Alejandro", ""]]}, {"id": "1910.03230", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Zhe Gan, Linjie Li, Yu Cheng, William Wang, Jingjing Liu", "title": "Meta Module Network for Compositional Visual Reasoning", "comments": "Accepted to WACV 21 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Module Network (NMN) exhibits strong interpretability and\ncompositionality thanks to its handcrafted neural modules with explicit\nmulti-hop reasoning capability. However, most NMNs suffer from two critical\ndrawbacks: 1) scalability: customized module for specific function renders it\nimpractical when scaling up to a larger set of functions in complex tasks; 2)\ngeneralizability: rigid pre-defined module inventory makes it difficult to\ngeneralize to unseen functions in new tasks/domains. To design a more powerful\nNMN architecture for practical use, we propose Meta Module Network (MMN)\ncentered on a novel meta module, which can take in function recipes and morph\ninto diverse instance modules dynamically. The instance modules are then woven\ninto an execution graph for complex visual reasoning, inheriting the strong\nexplainability and compositionality of NMN. With such a flexible instantiation\nmechanism, the parameters of instance modules are inherited from the central\nmeta module, retaining the same model complexity as the function set grows,\nwhich promises better scalability. Meanwhile, as functions are encoded into the\nembedding space, unseen functions can be readily represented based on its\nstructural similarity with previously observed ones, which ensures better\ngeneralizability. Experiments on GQA and CLEVR datasets validate the\nsuperiority of MMN over state-of-the-art NMN designs. Synthetic experiments on\nheld-out unseen functions from GQA dataset also demonstrate the strong\ngeneralizability of MMN. Our code and model are released in Github\nhttps://github.com/wenhuchen/Meta-Module-Network.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 06:28:24 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 19:39:46 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 20:28:29 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 17:55:05 GMT"}, {"version": "v5", "created": "Sun, 8 Nov 2020 02:52:51 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chen", "Wenhu", ""], ["Gan", "Zhe", ""], ["Li", "Linjie", ""], ["Cheng", "Yu", ""], ["Wang", "William", ""], ["Liu", "Jingjing", ""]]}, {"id": "1910.03231", "submitter": "Yang Liu", "authors": "Yang Liu and Hongyi Guo", "title": "Peer Loss Functions: Learning from Noisy Labels without Knowing Noise\n  Rates", "comments": "ICML 2020. Corrected typos in the Appendix", "journal-ref": "International Conference on Machine Learning, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with noisy labels is a common challenge in supervised learning.\nExisting approaches often require practitioners to specify noise rates, i.e., a\nset of parameters controlling the severity of label noises in the problem, and\nthe specifications are either assumed to be given or estimated using additional\nsteps. In this work, we introduce a new family of loss functions that we name\nas peer loss functions, which enables learning from noisy labels and does not\nrequire a priori specification of the noise rates. Peer loss functions work\nwithin the standard empirical risk minimization (ERM) framework. We show that,\nunder mild conditions, performing ERM with peer loss functions on the noisy\ndataset leads to the optimal or a near-optimal classifier as if performing ERM\nover the clean training data, which we do not have access to. We pair our\nresults with an extensive set of experiments. Peer loss provides a way to\nsimplify model development when facing potentially noisy training labels, and\ncan be promoted as a robust candidate loss function in such situations.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 06:34:11 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 21:57:23 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 04:32:34 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 08:23:27 GMT"}, {"version": "v5", "created": "Wed, 24 Jun 2020 19:05:39 GMT"}, {"version": "v6", "created": "Mon, 29 Jun 2020 20:55:13 GMT"}, {"version": "v7", "created": "Fri, 14 Aug 2020 20:28:47 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Liu", "Yang", ""], ["Guo", "Hongyi", ""]]}, {"id": "1910.03253", "submitter": "Hitoshi Kusano", "authors": "Kyo Kutsuzawa, Hitoshi Kusano, Ayaka Kume, and Shoichiro Yamaguchi", "title": "Motion Generation Considering Situation with Conditional Generative\n  Adversarial Networks for Throwing Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When robots work in a cluttered environment, the constraints for motions\nchange frequently and the required action can change even for the same task.\nHowever, planning complex motions from direct calculation has the risk of\nresulting in poor performance local optima. In addition, machine learning\napproaches often require relearning for novel situations. In this paper, we\npropose a method of searching appropriate motions by using conditional\nGenerative Adversarial Networks (cGANs), which can generate motions based on\nthe conditions by mimicking training datasets. By training cGANs with various\nmotions for a task, its latent space is fulfilled with the valid motions for\nthe task. The appropriate motions can be found efficiently by searching the\nlatent space of the trained cGANs instead of the motion space, while avoiding\npoor local optima. We demonstrate that the proposed method successfully works\nfor an object-throwing task to given target positions in both numerical\nsimulation and real-robot experiments. The proposed method resulted in three\ntimes higher accuracy with 2.5 times faster calculation time than searching the\naction space directly.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 07:31:49 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Kutsuzawa", "Kyo", ""], ["Kusano", "Hitoshi", ""], ["Kume", "Ayaka", ""], ["Yamaguchi", "Shoichiro", ""]]}, {"id": "1910.03276", "submitter": "Michela Moschella", "authors": "Michela Moschella, Mauro Tucci, Emanuele Crisostomi, and Alessandro\n  Betti", "title": "A Machine Learning Model for Long-Term Power Generation Forecasting at\n  Bidding Zone Level", "comments": "Paper presented at IEEE PES ISGT 2019 Conference (29 Sept - 2 Oct,\n  Bucharest, Romania)", "journal-ref": "2019 IEEE PES Innovative Smart Grid Technologies Europe\n  (ISGT-Europe)", "doi": "10.1109/ISGTEurope.2019.8905453", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing penetration level of energy generation from renewable sources\nis demanding for more accurate and reliable forecasting tools to support\nclassic power grid operations (e.g., unit commitment, electricity market\nclearing or maintenance planning). For this purpose, many physical models have\nbeen employed, and more recently many statistical or machine learning\nalgorithms, and data-driven methods in general, are becoming subject of intense\nresearch. While generally the power research community focuses on power\nforecasting at the level of single plants, in a short future horizon of time,\nin this time we are interested in aggregated macro-area power generation (i.e.,\nin a territory of size greater than 100000 km^2) with a future horizon of\ninterest up to 15 days ahead. Real data are used to validate the proposed\nforecasting methodology on a test set of several months.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 08:45:46 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:04:20 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Moschella", "Michela", ""], ["Tucci", "Mauro", ""], ["Crisostomi", "Emanuele", ""], ["Betti", "Alessandro", ""]]}, {"id": "1910.03291", "submitter": "Alireza Mohammadshahi", "authors": "Alireza Mohammadshahi, Remi Lebret, Karl Aberer", "title": "Aligning Multilingual Word Embeddings for Cross-Modal Retrieval Task", "comments": null, "journal-ref": null, "doi": "10.18653/v1/D19-6605", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new approach to learn multimodal multilingual\nembeddings for matching images and their relevant captions in two languages. We\ncombine two existing objective functions to make images and captions close in a\njoint embedding space while adapting the alignment of word embeddings between\nexisting languages in our model. We show that our approach enables better\ngeneralization, achieving state-of-the-art performance in text-to-image and\nimage-to-text retrieval task, and caption-caption similarity task. Two\nmultimodal multilingual datasets are used for evaluation: Multi30k with German\nand English captions and Microsoft-COCO with English and Japanese captions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 09:13:39 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Mohammadshahi", "Alireza", ""], ["Lebret", "Remi", ""], ["Aberer", "Karl", ""]]}, {"id": "1910.03305", "submitter": "Oliver G\\\"afvert", "authors": "Oliver G\\\"afvert", "title": "Computational complexity of learning algebraic varieties", "comments": null, "journal-ref": null, "doi": "10.1016/j.aam.2020.102100", "report-no": null, "categories": "math.AG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the complexity of fitting a variety, coming from a class of\nvarieties, to a configuration of points in $\\Bbb C^n$. The complexity measure,\ncalled the algebraic complexity, computes the Euclidean Distance Degree\n(EDdegree) of a certain variety called the hypothesis variety as the number of\npoints in the configuration increases. For the problem of fitting an\n$(n-1)$-sphere to a configuration of $m$ points in $\\Bbb C^n$, we give a closed\nformula of the algebraic complexity of the hypothesis variety as $m$ grows for\nthe case of $n=1$. For the case $n>1$ we conjecture a generalization of this\nformula supported by numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 09:50:13 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 04:37:31 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["G\u00e4fvert", "Oliver", ""]]}, {"id": "1910.03336", "submitter": "Kai Fischer", "authors": "Victor Vaquero, Kai Fischer, Francesc Moreno-Noguer, Alberto Sanfeliu,\n  Stefan Milz", "title": "Improving Map Re-localization with Deep 'Movable' Objects Segmentation\n  on 3D LiDAR Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization and Mapping is an essential component to enable Autonomous\nVehicles navigation, and requires an accuracy exceeding that of commercial\nGPS-based systems. Current odometry and mapping algorithms are able to provide\nthis accurate information. However, the lack of robustness of these algorithms\nagainst dynamic obstacles and environmental changes, even for short time\nperiods, forces the generation of new maps on every session without taking\nadvantage of previously obtained ones. In this paper we propose the use of a\ndeep learning architecture to segment movable objects from 3D LiDAR point\nclouds in order to obtain longer-lasting 3D maps. This will in turn allow for\nbetter, faster and more accurate re-localization and trajectoy estimation on\nsubsequent days. We show the effectiveness of our approach in a very dynamic\nand cluttered scenario, a supermarket parking lot. For that, we record several\nsequences on different days and compare localization errors with and without\nour movable objects segmentation method. Results show that we are able to\naccurately re-locate over a filtered map, consistently reducing trajectory\nerrors between an average of 35.1% with respect to a non-filtered map version\nand of 47.9% with respect to a standalone map created on the current session.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 11:11:27 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Vaquero", "Victor", ""], ["Fischer", "Kai", ""], ["Moreno-Noguer", "Francesc", ""], ["Sanfeliu", "Alberto", ""], ["Milz", "Stefan", ""]]}, {"id": "1910.03343", "submitter": "Jean-Benoit Delbrouck", "authors": "Jean-Benoit Delbrouck and Antoine Maiorca and Nathan Hubens and\n  St\\'ephane Dupont", "title": "Modulated Self-attention Convolutional Network for VQA", "comments": "Accepted at NeurIPS 2019 workshop: ViGIL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As new data-sets for real-world visual reasoning and compositional question\nanswering are emerging, it might be needed to use the visual feature extraction\nas a end-to-end process during training. This small contribution aims to\nsuggest new ideas to improve the visual processing of traditional convolutional\nnetwork for visual question answering (VQA). In this paper, we propose to\nmodulate by a linguistic input a CNN augmented with self-attention. We show\nencouraging relative improvements for future research in this direction.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 11:28:38 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 16:59:23 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Delbrouck", "Jean-Benoit", ""], ["Maiorca", "Antoine", ""], ["Hubens", "Nathan", ""], ["Dupont", "St\u00e9phane", ""]]}, {"id": "1910.03344", "submitter": "Anastasis Kratsios", "authors": "Anastasis Kratsios", "title": "The Universal Approximation Property", "comments": null, "journal-ref": "Annals of Mathematics and Artificial Intelligence, 2020", "doi": "10.1007/s10472-020-09723-1", "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The universal approximation property of various machine learning models is\ncurrently only understood on a case-by-case basis, limiting the rapid\ndevelopment of new theoretically justified neural network architectures and\nblurring our understanding of our current models' potential. This paper works\ntowards overcoming these challenges by presenting a characterization, a\nrepresentation, a construction method, and an existence result, each of which\napplies to any universal approximator on most function spaces of practical\ninterest. Our characterization result is used to describe which activation\nfunctions allow the feed-forward architecture to maintain its universal\napproximation capabilities when multiple constraints are imposed on its final\nlayers and its remaining layers are only sparsely connected. These include a\nrescaled and shifted Leaky ReLU activation function but not the ReLU activation\nfunction. Our construction and representation result is used to exhibit a\nsimple modification of the feed-forward architecture, which can approximate any\ncontinuous function with non-pathological growth, uniformly on the entire\nEuclidean input space. This improves the known capabilities of the feed-forward\narchitecture.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 11:30:33 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 09:20:21 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 20:52:07 GMT"}, {"version": "v4", "created": "Sat, 28 Nov 2020 11:17:47 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kratsios", "Anastasis", ""]]}, {"id": "1910.03358", "submitter": "David Hoeller", "authors": "Farbod Farshidian, David Hoeller, Marco Hutter", "title": "Deep Value Model Predictive Control", "comments": "Accepted for publication in the Conference on Robotic Learning (CoRL)\n  2019, Osaka. 10 pages (+5 supplementary)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an actor-critic algorithm called Deep Value Model\nPredictive Control (DMPC), which combines model-based trajectory optimization\nwith value function estimation. The DMPC actor is a Model Predictive Control\n(MPC) optimizer with an objective function defined in terms of a value function\nestimated by the critic. We show that our MPC actor is an importance sampler,\nwhich minimizes an upper bound of the cross-entropy to the state distribution\nof the optimal sampling policy. In our experiments with a Ballbot system, we\nshow that our algorithm can work with sparse and binary reward signals to\nefficiently solve obstacle avoidance and target reaching tasks. Compared to\nprevious work, we show that including the value function in the running cost of\nthe trajectory optimizer speeds up the convergence. We also discuss the\nnecessary strategies to robustify the algorithm in practice.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 12:19:50 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Farshidian", "Farbod", ""], ["Hoeller", "David", ""], ["Hutter", "Marco", ""]]}, {"id": "1910.03374", "submitter": "Dan Garber", "authors": "Dan Garber, Ben Kretzu", "title": "Improved Regret Bounds for Projection-free Bandit Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the challenge of designing online algorithms for the bandit convex\noptimization problem (BCO) which are also scalable to high dimensional\nproblems. Hence, we consider algorithms that are \\textit{projection-free},\ni.e., based on the conditional gradient method whose only access to the\nfeasible decision set, is through a linear optimization oracle (as opposed to\nother methods which require potentially much more computationally-expensive\nsubprocedures, such as computing Euclidean projections). We present the first\nsuch algorithm that attains $O(T^{3/4})$ expected regret using only $O(T)$\noverall calls to the linear optimization oracle, in expectation, where $T$ is\nthe number of prediction rounds. This improves over the $O(T^{4/5})$ expected\nregret bound recently obtained by \\cite{Karbasi19}, and actually matches the\ncurrent best regret bound for projection-free online learning in the\n\\textit{full information} setting.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 13:04:59 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Garber", "Dan", ""], ["Kretzu", "Ben", ""]]}, {"id": "1910.03387", "submitter": "Manuel Stoeckel", "authors": "Manuel Stoeckel, Wahed Hemati, Alexander Mehler", "title": "When Specialization Helps: Using Pooled Contextualized Embeddings to\n  Detect Chemical and Biomedical Entities in Spanish", "comments": "EMNLP-IJCNLP 2019: International Workshop on BioNLP Open Shared Tasks\n  2019, 5, pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recognition of pharmacological substances, compounds and proteins is an\nessential preliminary work for the recognition of relations between chemicals\nand other biomedically relevant units. In this paper, we describe an approach\nto Task 1 of the PharmaCoNER Challenge, which involves the recognition of\nmentions of chemicals and drugs in Spanish medical texts. We train a\nstate-of-the-art BiLSTM-CRF sequence tagger with stacked Pooled Contextualized\nEmbeddings, word and sub-word embeddings using the open-source framework FLAIR.\nWe present a new corpus composed of articles and papers from Spanish health\nscience journals, termed the Spanish Health Corpus, and use it to train\ndomain-specific embeddings which we incorporate in our model training. We\nachieve a result of 89.76% F1-score using pre-trained embeddings and are able\nto improve these results to 90.52% F1-score using specialized embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 13:38:39 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Stoeckel", "Manuel", ""], ["Hemati", "Wahed", ""], ["Mehler", "Alexander", ""]]}, {"id": "1910.03398", "submitter": "Sahba Aghajani Pedram", "authors": "Sahba Aghajani Pedram, Peter Walker Ferguson, Changyeob Shin, Ankur\n  Mehta, Erik P. Dutson, Farshid Alambeigi, Jacob Rosen", "title": "Toward Synergic Learning for Autonomous Manipulation of Deformable\n  Tissues via Surgical Robots: An Approximate Q-Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a synergic learning algorithm to address the task\nof indirect manipulation of an unknown deformable tissue. Tissue manipulation\nis a common yet challenging task in various surgical interventions, which makes\nit a good candidate for robotic automation. We propose using a linear\napproximate Q-learning method in which human knowledge contributes to selecting\nuseful yet simple features of tissue manipulation while the algorithm learns to\ntake optimal actions and accomplish the task. The algorithm is implemented and\nevaluated on a simulation using the OpenCV and CHAI3D libraries. Successful\nsimulation results for four different configurations which are based on\nrealistic tissue manipulation scenarios are presented. Results indicate that\nwith a careful selection of relatively simple and intuitive features, the\ndeveloped Q-learning algorithm can successfully learn an optimal policy without\nany prior knowledge of tissue dynamics or camera intrinsic/extrinsic\ncalibration parameters.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 13:53:35 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 17:27:24 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Pedram", "Sahba Aghajani", ""], ["Ferguson", "Peter Walker", ""], ["Shin", "Changyeob", ""], ["Mehta", "Ankur", ""], ["Dutson", "Erik P.", ""], ["Alambeigi", "Farshid", ""], ["Rosen", "Jacob", ""]]}, {"id": "1910.03432", "submitter": "Ananda Theertha Suresh", "authors": "Mingqing Chen, Ananda Theertha Suresh, Rajiv Mathews, Adeline Wong,\n  Cyril Allauzen, Fran\\c{c}oise Beaufays, Michael Riley", "title": "Federated Learning of N-gram Language Models", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose algorithms to train production-quality n-gram language models\nusing federated learning. Federated learning is a distributed computation\nplatform that can be used to train global models for portable devices such as\nsmart phones. Federated learning is especially relevant for applications\nhandling privacy-sensitive data, such as virtual keyboards, because training is\nperformed without the users' data ever leaving their devices. While the\nprinciples of federated learning are fairly generic, its methodology assumes\nthat the underlying models are neural networks. However, virtual keyboards are\ntypically powered by n-gram language models for latency reasons.\n  We propose to train a recurrent neural network language model using the\ndecentralized FederatedAveraging algorithm and to approximate this federated\nmodel server-side with an n-gram model that can be deployed to devices for fast\ninference. Our technical contributions include ways of handling large\nvocabularies, algorithms to correct capitalization errors in user data, and\nefficient finite state transducer algorithms to convert word language models to\nword-piece language models and vice versa. The n-gram language models trained\nwith federated learning are compared to n-grams trained with traditional\nserver-based algorithms using A/B tests on tens of millions of users of virtual\nkeyboard. Results are presented for two languages, American English and\nBrazilian Portuguese. This work demonstrates that high-quality n-gram language\nmodels can be trained directly on client mobile devices without sensitive\ntraining data ever leaving the devices.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 14:48:43 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Chen", "Mingqing", ""], ["Suresh", "Ananda Theertha", ""], ["Mathews", "Rajiv", ""], ["Wong", "Adeline", ""], ["Allauzen", "Cyril", ""], ["Beaufays", "Fran\u00e7oise", ""], ["Riley", "Michael", ""]]}, {"id": "1910.03434", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Marcus de Carvalho, Renchunzi Xie, Edwin Lughofer\n  and Jie Lu", "title": "ATL: Autonomous Knowledge Transfer from Many Streaming Processes", "comments": "This paper has been accepted for publication in CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transferring knowledge across many streaming processes remains an uncharted\nterritory in the existing literature and features unique characteristics: no\nlabelled instance of the target domain, covariate shift of source and target\ndomain, different period of drifts in the source and target domains. Autonomous\ntransfer learning (ATL) is proposed in this paper as a flexible deep learning\napproach for the online unsupervised transfer learning problem across many\nstreaming processes. ATL offers an online domain adaptation strategy via the\ngenerative and discriminative phases coupled with the KL divergence based\noptimization strategy to produce a domain invariant network while putting\nforward an elastic network structure. It automatically evolves its network\nstructure from scratch with/without the presence of ground truth to overcome\nindependent concept drifts in the source and target domain. The rigorous\nnumerical evaluation has been conducted along with a comparison against\nrecently published works. ATL demonstrates improved performance while showing\nsignificantly faster training speed than its counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 14:54:30 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 05:41:29 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Pratama", "Mahardhika", ""], ["de Carvalho", "Marcus", ""], ["Xie", "Renchunzi", ""], ["Lughofer", "Edwin", ""], ["Lu", "Jie", ""]]}, {"id": "1910.03437", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Choiru Za'in, Andri Ashfahani, Yew Soon Ong and\n  Weiping Ding", "title": "Automatic Construction of Multi-layer Perceptron Network from Streaming\n  Examples", "comments": "This paper has been accepted for publication in CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Autonomous construction of deep neural network (DNNs) is desired for data\nstreams because it potentially offers two advantages: proper model's capacity\nand quick reaction to drift and shift. While the self-organizing mechanism of\nDNNs remains an open issue, this task is even more challenging to be developed\nfor standard multi-layer DNNs than that using the different-depth structures,\nbecause the addition of a new layer results in information loss of previously\ntrained knowledge. A Neural Network with Dynamically Evolved Capacity (NADINE)\nis proposed in this paper. NADINE features a fully open structure where its\nnetwork structure, depth and width, can be automatically evolved from scratch\nin an online manner and without the use of problem-specific thresholds. NADINE\nis structured under a standard MLP architecture and the catastrophic forgetting\nissue during the hidden layer addition phase is resolved using the proposal of\nsoft-forgetting and adaptive memory methods. The advantage of NADINE, namely\nelastic structure and online learning trait, is numerically validated using\nnine data stream classification and regression problems where it demonstrates\nperformance improvement over prominent algorithms in all problems. In addition,\nit is capable of dealing with data stream regression and classification\nproblems equally well.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 14:55:28 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 12:31:01 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Za'in", "Choiru", ""], ["Ashfahani", "Andri", ""], ["Ong", "Yew Soon", ""], ["Ding", "Weiping", ""]]}, {"id": "1910.03452", "submitter": "Suprosanna Shit", "authors": "Suprosanna Shit, Abinav Ravi Venkatakrishnan, Ivan Ezhov, Jana\n  Lipkova, Marie Piraud, Bjoern Menze", "title": "Implicit Neural Solver for Time-dependent Linear PDEs with Convergence\n  Guarantee", "comments": "Accepted in NeurIPS 2019 Workshop on Machine Learning with Guarantees", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and accurate solution of time-dependent partial differential equations\n(PDEs) is of key interest in many research fields including physics,\nengineering, and biology. Generally, implicit schemes are preferred over the\nexplicit ones for better stability and correctness. The existing implicit\nschemes are usually iterative and employ a general-purpose solver which may be\nsub-optimal for a specific class of PDEs. In this paper, we propose a neural\nsolver to learn an optimal iterative scheme for a class of PDEs, in a\ndata-driven fashion. We attain this objective by modifying an iteration of an\nexisting semi-implicit solver using a deep neural network. Further, we prove\ntheoretically that our approach preserves the correctness and convergence\nguarantees provided by the existing iterative-solvers. We also demonstrate that\nour model generalizes to a different parameter setting than the one seen during\ntraining and achieves faster convergence compared to the semi-implicit schemes.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:20:01 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 15:36:23 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 13:47:48 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Shit", "Suprosanna", ""], ["Venkatakrishnan", "Abinav Ravi", ""], ["Ezhov", "Ivan", ""], ["Lipkova", "Jana", ""], ["Piraud", "Marie", ""], ["Menze", "Bjoern", ""]]}, {"id": "1910.03455", "submitter": "Abby Stylianou", "authors": "Abby Stylianou, Richard Souvenir and Robert Pless", "title": "TraffickCam: Explainable Image Matching For Sex Trafficking\n  Investigations", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investigations of sex trafficking sometimes have access to photographs of\nvictims in hotel rooms. These images directly link victims to places, which can\nhelp verify where victims have been trafficked or where traffickers might\noperate in the future. Current machine learning approaches give promising\nresults in image search to find the matching hotel. This paper explores\napproaches to make this end-to-end system better support government and law\nenforcement requirements, including improved performance, visualization\napproaches that explain what parts of the image led to a match, and\ninfrastructure to support exporting the results of a query.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:24:30 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Stylianou", "Abby", ""], ["Souvenir", "Richard", ""], ["Pless", "Robert", ""]]}, {"id": "1910.03466", "submitter": "Paul Kantor", "authors": "Vicki Bier, Paul B. Kantor, Gary Lupyan, Xiaojin Zhu", "title": "Can We Distinguish Machine Learning from Human Learning?", "comments": "14pp. 5 fig. Working Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What makes a task relatively more or less difficult for a machine compared to\na human? Much AI/ML research has focused on expanding the range of tasks that\nmachines can do, with a focus on whether machines can beat humans. Allowing for\ndifferences in scale, we can seek interesting (anomalous) pairs of tasks T, T'.\nWe define interesting in this way: The \"harder to learn\" relation is reversed\nwhen comparing human intelligence (HI) to AI. While humans seems to be able to\nunderstand problems by formulating rules, ML using neural networks does not\nrely on constructing rules. We discuss a novel approach where the challenge is\nto \"perform well under rules that have been created by human beings.\" We\nsuggest that this provides a rigorous and precise pathway for understanding the\ndifference between the two kinds of learning. Specifically, we suggest a large\nand extensible class of learning tasks, formulated as learning under rules.\nWith these tasks, both the AI and HI will be studied with rigor and precision.\nThe immediate goal is to find interesting groundtruth rule pairs. In the long\nterm, the goal will be to understand, in a generalizable way, what\ndistinguishes interesting pairs from ordinary pairs, and to define saliency\nbehind interesting pairs. This may open new ways of thinking about AI, and\nprovide unexpected insights into human learning.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:37:03 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Bier", "Vicki", ""], ["Kantor", "Paul B.", ""], ["Lupyan", "Gary", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1910.03467", "submitter": "Ngo Thi-Vinh", "authors": "Thi-Vinh Ngo, Thanh-Le Ha, Phuong-Thai Nguyen, Le-Minh Nguyen", "title": "Overcoming the Rare Word Problem for Low-Resource Language Pairs in\n  Neural Machine Translation", "comments": null, "journal-ref": "Proceedings of the 6th Workshop on Asian Translation, WAT 2019", "doi": "10.18653/v1/D19-5228", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Among the six challenges of neural machine translation (NMT) coined by (Koehn\nand Knowles, 2017), rare-word problem is considered the most severe one,\nespecially in translation of low-resource languages. In this paper, we propose\nthree solutions to address the rare words in neural machine translation\nsystems. First, we enhance source context to predict the target words by\nconnecting directly the source embeddings to the output of the attention\ncomponent in NMT. Second, we propose an algorithm to learn morphology of\nunknown words for English in supervised way in order to minimize the adverse\neffect of rare-word problem. Finally, we exploit synonymous relation from the\nWordNet to overcome out-of-vocabulary (OOV) problem of NMT. We evaluate our\napproaches on two low-resource language pairs: English-Vietnamese and\nJapanese-Vietnamese. In our experiments, we have achieved significant\nimprovements of up to roughly +1.0 BLEU points in both language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 03:11:13 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:02:55 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Ngo", "Thi-Vinh", ""], ["Ha", "Thanh-Le", ""], ["Nguyen", "Phuong-Thai", ""], ["Nguyen", "Le-Minh", ""]]}, {"id": "1910.03468", "submitter": "Matteo Terzi", "authors": "Matteo Terzi, Gian Antonio Susto and Pratik Chaudhari", "title": "Directional Adversarial Training for Cost Sensitive Deep Learning\n  Classification Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications of Machine Learning it is of paramount\nimportance not only to provide accurate predictions, but also to ensure certain\nlevels of robustness. Adversarial Training is a training procedure aiming at\nproviding models that are robust to worst-case perturbations around predefined\npoints. Unfortunately, one of the main issues in adversarial training is that\nrobustness w.r.t. gradient-based attackers is always achieved at the cost of\nprediction accuracy. In this paper, a new algorithm, called Wasserstein\nProjected Gradient Descent (WPGD), for adversarial training is proposed. WPGD\nprovides a simple way to obtain cost-sensitive robustness, resulting in a finer\ncontrol of the robustness-accuracy trade-off. Moreover, WPGD solves an optimal\ntransport problem on the output space of the network and it can efficiently\ndiscover directions where robustness is required, allowing to control the\ndirectional trade-off between accuracy and robustness. The proposed WPGD is\nvalidated in this work on image recognition tasks with different benchmark\ndatasets and architectures. Moreover, real world-like datasets are often\nunbalanced: this paper shows that when dealing with such type of datasets, the\nperformance of adversarial training are mainly affected in term of standard\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:40:09 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Terzi", "Matteo", ""], ["Susto", "Gian Antonio", ""], ["Chaudhari", "Pratik", ""]]}, {"id": "1910.03471", "submitter": "Dominik Schmidt", "authors": "Dominik Schmidt, Georgia Koppe, Zahra Monfared, Max Beutelspacher,\n  Daniel Durstewitz", "title": "Identifying nonlinear dynamical systems with multiple time scales and\n  long-range dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main theoretical interest in biology and physics is to identify the\nnonlinear dynamical system (DS) that generated observed time series. Recurrent\nNeural Networks (RNNs) are, in principle, powerful enough to approximate any\nunderlying DS, but in their vanilla form suffer from the exploding vs.\nvanishing gradients problem. Previous attempts to alleviate this problem\nresulted either in more complicated, mathematically less tractable RNN\narchitectures, or strongly limited the dynamical expressiveness of the RNN.\nHere we address this issue by suggesting a simple regularization scheme for\nvanilla RNNs with ReLU activation which enables them to solve long-range\ndependency problems and express slow time scales, while retaining a simple\nmathematical structure which makes their DS properties partly analytically\naccessible. We prove two theorems that establish a tight connection between the\nregularized RNN dynamics and its gradients, illustrate on DS benchmarks that\nour regularization approach strongly eases the reconstruction of DS which\nharbor widely differing time scales, and show that our method is also en par\nwith other long-range architectures like LSTMs on several tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:41:50 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 08:55:31 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 15:33:07 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Schmidt", "Dominik", ""], ["Koppe", "Georgia", ""], ["Monfared", "Zahra", ""], ["Beutelspacher", "Max", ""], ["Durstewitz", "Daniel", ""]]}, {"id": "1910.03472", "submitter": "Maurice Weber", "authors": "Maurice Weber, Cedric Renggli, Helmut Grabner, Ce Zhang", "title": "Observer Dependent Lossy Image Compression", "comments": "@German Conference on Pattern Recognition (DAGM GCPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have recently advanced the state-of-the-art in image\ncompression and surpassed many traditional compression algorithms. The training\nof such networks involves carefully trading off entropy of the latent\nrepresentation against reconstruction quality. The term quality crucially\ndepends on the observer of the images which, in the vast majority of\nliterature, is assumed to be human. In this paper, we aim to go beyond this\nnotion of compression quality and look at human visual perception and image\nclassification simultaneously. To that end, we use a family of loss functions\nthat allows to optimize deep image compression depending on the observer and to\ninterpolate between human perceived visual quality and classification accuracy,\nenabling a more unified view on image compression. Our extensive experiments\nshow that using perceptual loss functions to train a compression system\npreserves classification accuracy much better than traditional codecs such as\nBPG without requiring retraining of classifiers on compressed images. For\nexample, compressing ImageNet to 0.25 bpp reduces Inception-ResNet\nclassification accuracy by only 2%. At the same time, when using a human\nfriendly loss function, the same compression system achieves competitive\nperformance in terms of MS-SSIM. By combining these two objective functions, we\nshow that there is a pronounced trade-off in compression quality between the\nhuman visual system and classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:43:29 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 10:11:58 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Weber", "Maurice", ""], ["Renggli", "Cedric", ""], ["Grabner", "Helmut", ""], ["Zhang", "Ce", ""]]}, {"id": "1910.03474", "submitter": "Manish Munikar", "authors": "Manish Munikar, Sushil Shakya, Aakash Shrestha", "title": "Fine-grained Sentiment Classification using BERT", "comments": "Submitted to IEEE International Conference on Artificial Intelligence\n  for Transforming Business and Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment classification is an important process in understanding people's\nperception towards a product, service, or topic. Many natural language\nprocessing models have been proposed to solve the sentiment classification\nproblem. However, most of them have focused on binary sentiment classification.\nIn this paper, we use a promising deep learning model called BERT to solve the\nfine-grained sentiment classification task. Experiments show that our model\noutperforms other popular models for this task without sophisticated\narchitecture. We also demonstrate the effectiveness of transfer learning in\nnatural language processing in the process.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 09:20:48 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Munikar", "Manish", ""], ["Shakya", "Sushil", ""], ["Shrestha", "Aakash", ""]]}, {"id": "1910.03476", "submitter": "Sam Shleifer", "authors": "Sam Shleifer, Manish Chablani, Namit Katariya, Anitha Kannan, Xavier\n  Amatriain", "title": "Classification As Decoder: Trading Flexibility For Control In Neural\n  Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative seq2seq dialogue systems are trained to predict the next word in\ndialogues that have already occurred. They can learn from large unlabeled\nconversation datasets, build a deep understanding of conversational context,\nand generate a wide variety of responses. This flexibility comes at the cost of\ncontrol. Undesirable responses in the training data will be reproduced by the\nmodel at inference time, and longer generations often don't make sense. Instead\nof generating responses one word at a time, we train a classifier to choose\nfrom a predefined list of full responses. The classifier is trained on\n(conversation context, response class) pairs, where each response class is a\nnoisily labeled group of interchangeable responses. At inference, we generate\nthe exemplar response associated with the predicted response class. Experts can\nedit and improve these exemplar responses over time without retraining the\nclassifier or invalidating old training data. Human evaluation of 775 unseen\ndoctor/patient conversations shows that this tradeoff improves responses. Only\n12% of our discriminative approach's responses are worse than the doctor's\nresponse in the same conversational context, compared to 18% for the generative\nmodel. A discriminative model trained without any manual labeling of response\nclasses achieves equal performance to the generative model.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 21:04:20 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 23:56:03 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 23:09:14 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Shleifer", "Sam", ""], ["Chablani", "Manish", ""], ["Katariya", "Namit", ""], ["Kannan", "Anitha", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1910.03477", "submitter": "Glen Chou", "authors": "Glen Chou, Necmiye Ozay, Dmitry Berenson", "title": "Learning Parametric Constraints in High Dimensions from Demonstrations", "comments": "3rd Conference on Robot Learning (CoRL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scalable algorithm for learning parametric constraints in high\ndimensions from safe expert demonstrations. To reduce the ill-posedness of the\nconstraint recovery problem, our method uses hit-and-run sampling to generate\nlower cost, and thus unsafe, trajectories. Both safe and unsafe trajectories\nare used to obtain a representation of the unsafe set that is compatible with\nthe data by solving an integer program in that representation's parameter\nspace. Our method can either leverage a known parameterization or incrementally\ngrow a parameterization while remaining consistent with the data, and we\nprovide theoretical guarantees on the conservativeness of the recovered unsafe\nset. We evaluate our method on high-dimensional constraints for\nhigh-dimensional systems by learning constraints for 7-DOF arm, quadrotor, and\nplanar pushing examples, and show that our method outperforms baseline\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:46:36 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Chou", "Glen", ""], ["Ozay", "Necmiye", ""], ["Berenson", "Dmitry", ""]]}, {"id": "1910.03483", "submitter": "Mariella Dimiccoli", "authors": "Mariella Dimiccoli, Herwig Wendt", "title": "Learning event representations for temporal segmentation of image\n  sequences by dynamic graph embedding", "comments": "Accepted in IEEE Transactions on Image Processing, 2020. To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, self-supervised learning has proved to be effective to learn\nrepresentations of events suitable for temporal segmentation in image\nsequences, where events are understood as sets of temporally adjacent images\nthat are semantically perceived as a whole. However, although this approach\ndoes not require expensive manual annotations, it is data hungry and suffers\nfrom domain adaptation problems. As an alternative, in this work, we propose a\nnovel approach for learning event representations named Dynamic Graph Embedding\n(DGE). The assumption underlying our model is that a sequence of images can be\nrepresented by a graph that encodes both semantic and temporal similarity. The\nkey novelty of DGE is to learn jointly the graph and its graph embedding. At\nits core, DGE works by iterating over two steps: 1) updating the graph\nrepresenting the semantic and temporal similarity of the data based on the\ncurrent data representation, and 2) updating the data representation to take\ninto account the current data graph structure. The main advantage of DGE over\nstate-of-the-art self-supervised approaches is that it does not require any\ntraining set, but instead learns iteratively from the data itself a\nlow-dimensional embedding that reflects their temporal and semantic similarity.\nExperimental results on two benchmark datasets of real image sequences captured\nat regular time intervals demonstrate that the proposed DGE leads to event\nrepresentations effective for temporal segmentation. In particular, it achieves\nrobust temporal segmentation on the EDUBSeg and EDUBSeg-Desc benchmark\ndatasets, outperforming the state of the art. Additional experiments on two\nHuman Motion Segmentation benchmark datasets demonstrate the generalization\ncapabilities of the proposed DGE.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:48:50 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 10:42:25 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 11:03:37 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Dimiccoli", "Mariella", ""], ["Wendt", "Herwig", ""]]}, {"id": "1910.03487", "submitter": "Minmin Shen", "authors": "Nikolaos Malandrakis, Minmin Shen, Anuj Goyal, Shuyang Gao, Abhishek\n  Sethi, Angeliki Metallinou", "title": "Controlled Text Generation for Data Augmentation in Intelligent\n  Artificial Agents", "comments": "EMNLP WNGT workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data availability is a bottleneck during early stages of development of new\ncapabilities for intelligent artificial agents. We investigate the use of text\ngeneration techniques to augment the training data of a popular commercial\nartificial agent across categories of functionality, with the goal of faster\ndevelopment of new functionality. We explore a variety of encoder-decoder\ngenerative models for synthetic training data generation and propose using\nconditional variational auto-encoders. Our approach requires only direct\noptimization, works well with limited data and significantly outperforms the\nprevious controlled text generation techniques. Further, the generated data are\nused as additional training samples in an extrinsic intent classification task,\nleading to improved performance by up to 5\\% absolute f-score in low-resource\ncases, validating the usefulness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 20:44:21 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Malandrakis", "Nikolaos", ""], ["Shen", "Minmin", ""], ["Goyal", "Anuj", ""], ["Gao", "Shuyang", ""], ["Sethi", "Abhishek", ""], ["Metallinou", "Angeliki", ""]]}, {"id": "1910.03492", "submitter": "Dan Busbridge", "authors": "Joseph Enguehard, Dan Busbridge, Vitalii Zhelezniak, Nils Hammerla", "title": "Neural Language Priors", "comments": "4 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of sentence encoder architecture reflects assumptions about how a\nsentence's meaning is composed from its constituent words. We examine the\ncontribution of these architectures by holding them randomly initialised and\nfixed, effectively treating them as as hand-crafted language priors, and\nevaluating the resulting sentence encoders on downstream language tasks. We\nfind that even when encoders are presented with additional information that can\nbe used to solve tasks, the corresponding priors do not leverage this\ninformation, except in an isolated case. We also find that apparently\nuninformative priors are just as good as seemingly informative priors on almost\nall tasks, indicating that learning is a necessary component to leverage\ninformation provided by architecture choice.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:44:33 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Enguehard", "Joseph", ""], ["Busbridge", "Dan", ""], ["Zhelezniak", "Vitalii", ""], ["Hammerla", "Nils", ""]]}, {"id": "1910.03493", "submitter": "Lorenzo De Stefani", "authors": "Lorenzo De Stefani and Eli Upfal", "title": "A Rademacher Complexity Based Method fo rControlling Power and\n  Confidence Level in Adaptive Statistical Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While standard statistical inference techniques and machine learning\ngeneralization bounds assume that tests are run on data selected independently\nof the hypotheses, practical data analysis and machine learning are usually\niterative and adaptive processes where the same holdout data is often used for\ntesting a sequence of hypotheses (or models), which may each depend on the\noutcome of the previous tests on the same data. In this work, we present\nRadaBound a rigorous, efficient and practical procedure for controlling the\ngeneralization error when using a holdout sample for multiple adaptive testing.\nOur solution is based on a new application of the Rademacher Complexity\ngeneralization bounds, adapted to dependent tests. We demonstrate the\nstatistical power and practicality of our method through extensive simulations\nand comparisons to alternative approaches.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 05:24:16 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["De Stefani", "Lorenzo", ""], ["Upfal", "Eli", ""]]}, {"id": "1910.03497", "submitter": "Seyed Amjad Seyedi", "authors": "Seyed Amjad Seyedi, S.Siamak Ghodsi, Fardin Akhlaghian, Mahdi Jalili,\n  Parham Moradi", "title": "Self-Paced Multi-Label Learning with Diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The major challenge of learning from multi-label data has arisen from the\noverwhelming size of label space which makes this problem NP-hard. This problem\ncan be alleviated by gradually involving easy to hard tags into the learning\nprocess. Besides, the utilization of a diversity maintenance approach avoids\noverfitting on a subset of easy labels. In this paper, we propose a self-paced\nmulti-label learning with diversity (SPMLD) which aims to cover diverse labels\nwith respect to its learning pace. In addition, the proposed framework is\napplied to an efficient correlation-based multi-label method. The non-convex\nobjective function is optimized by an extension of the block coordinate descent\nalgorithm. Empirical evaluations on real-world datasets with different\ndimensions of features and labels imply the effectiveness of the proposed\npredictive model.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:59:57 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Seyedi", "Seyed Amjad", ""], ["Ghodsi", "S. Siamak", ""], ["Akhlaghian", "Fardin", ""], ["Jalili", "Mahdi", ""], ["Moradi", "Parham", ""]]}, {"id": "1910.03498", "submitter": "Dominique Mercier", "authors": "Dominique Mercier, Akansha Bhardwaj, Andreas Dengel, Sheraz Ahmed", "title": "SentiCite: An Approach for Publication Sentiment Analysis", "comments": "Preprint, 8 pages, 2 figures, 10th International Conference on Agents\n  and Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth in the number of scientific publications, year after\nyear, it is becoming increasingly difficult to identify quality authoritative\nwork on a single topic. Though there is an availability of scientometric\nmeasures which promise to offer a solution to this problem, these measures are\nmostly quantitative and rely, for instance, only on the number of times an\narticle is cited. With this approach, it becomes irrelevant if an article is\ncited 10 times in a positive, negative or neutral way. In this context, it is\nquite important to study the qualitative aspect of a citation to understand its\nsignificance. This paper presents a novel system for sentiment analysis of\ncitations in scientific documents (SentiCite) and is also capable of detecting\nnature of citations by targeting the motivation behind a citation, e.g.,\nreference to a dataset, reading reference. Furthermore, the paper also presents\ntwo datasets (SentiCiteDB and IntentCiteDB) containing about 2,600 citations\nwith their ground truth for sentiment and nature of citation. SentiCite along\nwith other state-of-the-art methods for sentiment analysis are evaluated on the\npresented datasets. Evaluation results reveal that SentiCite outperforms\nstate-of-the-art methods for sentiment analysis in scientific publications by\nachieving a F1-measure of 0.71.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 06:49:52 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Mercier", "Dominique", ""], ["Bhardwaj", "Akansha", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "1910.03505", "submitter": "Jinghui Lu", "authors": "Jinghui Lu, Maeve Henchion, Brian Mac Namee", "title": "Investigating the Effectiveness of Representations Based on\n  Word-Embeddings in Active Learning for Labelling Text Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually labelling large collections of text data is a time-consuming,\nexpensive, and laborious task, but one that is necessary to support machine\nlearning based on text datasets. Active learning has been shown to be an\neffective way to alleviate some of the effort required in utilising large\ncollections of unlabelled data for machine learning tasks without needing to\nfully label them. The representation mechanism used to represent text documents\nwhen performing active learning, however, has a significant influence on how\neffective the process will be. While simple vector representations such as bag\nof words have been shown to be an effective way to represent documents during\nactive learning, the emergence of representation mechanisms based on the word\nembeddings prevalent in neural network research (e.g. word2vec and\ntransformer-based models like BERT) offer a promising, and as yet not fully\nexplored, alternative. This paper describes a large-scale evaluation of the\neffectiveness of different text representation mechanisms for active learning\nacross 8 datasets from varied domains. This evaluation shows that using\nrepresentations based on modern word embeddings---especially BERT---, which\nhave not yet been widely used in active learning, achieves a significant\nimprovement over more commonly used vector-based methods like bag of words.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 11:00:36 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 11:15:27 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Lu", "Jinghui", ""], ["Henchion", "Maeve", ""], ["Mac Namee", "Brian", ""]]}, {"id": "1910.03506", "submitter": "Pan Li", "authors": "Pan Li, Alexander Tuzhilin", "title": "Towards Controllable and Personalized Review Generation", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel model RevGAN that automatically generates\ncontrollable and personalized user reviews based on the arbitrarily given\nsentimental and stylistic information. RevGAN utilizes the combination of three\nnovel components, including self-attentive recursive autoencoders, conditional\ndiscriminators, and personalized decoders. We test its performance on the\nseveral real-world datasets, where our model significantly outperforms\nstate-of-the-art generation models in terms of sentence quality, coherence,\npersonalization and human evaluations. We also empirically show that the\ngenerated reviews could not be easily distinguished from the organically\nproduced reviews and that they follow the same statistical linguistics laws.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 19:12:10 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 15:05:45 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Li", "Pan", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "1910.03524", "submitter": "Stanislav Morozov", "authors": "Denis Mazur, Vage Egiazarian, Stanislav Morozov, Artem Babenko", "title": "Beyond Vector Spaces: Compact Data Representation as Differentiable\n  Weighted Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning useful representations is a key ingredient to the success of modern\nmachine learning. Currently, representation learning mostly relies on embedding\ndata into Euclidean space. However, recent work has shown that data in some\ndomains is better modeled by non-euclidean metric spaces, and inappropriate\ngeometry can result in inferior performance. In this paper, we aim to eliminate\nthe inductive bias imposed by the embedding space geometry. Namely, we propose\nto map data into more general non-vector metric spaces: a weighted graph with a\nshortest path distance. By design, such graphs can model arbitrary geometry\nwith a proper configuration of edges and weights. Our main contribution is\nPRODIGE: a method that learns a weighted graph representation of data\nend-to-end by gradient descent. Greater generality and fewer model assumptions\nmake PRODIGE more powerful than existing embedding-based approaches. We confirm\nthe superiority of our method via extensive experiments on a wide range of\ntasks, including classification, compression, and collaborative filtering.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 16:31:11 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 13:08:06 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 13:46:56 GMT"}, {"version": "v4", "created": "Wed, 16 Oct 2019 16:43:20 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Mazur", "Denis", ""], ["Egiazarian", "Vage", ""], ["Morozov", "Stanislav", ""], ["Babenko", "Artem", ""]]}, {"id": "1910.03534", "submitter": "Leonid Boytsov", "authors": "Leonid Boytsov, Eric Nyberg", "title": "Accurate and Fast Retrieval for Complex Non-metric Data via Neighborhood\n  Graphs", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-32047-8_12", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that a graph-based search algorithm-relying on the\nconstruction of an approximate neighborhood graph-can directly work with\nchallenging non-metric and/or non-symmetric distances without resorting to\nmetric-space mapping and/or distance symmetrization, which, in turn, lead to\nsubstantial performance degradation. Although the straightforward metrization\nand symmetrization is usually ineffective, we find that constructing an index\nusing a modified, e.g., symmetrized, distance can improve performance. This\nobservation paves a way to a new line of research of designing index-specific\ngraph-construction distance functions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 16:45:20 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Boytsov", "Leonid", ""], ["Nyberg", "Eric", ""]]}, {"id": "1910.03539", "submitter": "Leonid Boytsov", "authors": "Leonid Boytsov, Eric Nyberg", "title": "Pruning Algorithms for Low-Dimensional Non-metric k-NN Search: A Case\n  Study", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-32047-8_7", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on low-dimensional non-metric search, where tree-based approaches\npermit efficient and accurate retrieval while having short indexing time. These\nmethods rely on space partitioning and require a pruning rule to avoid visiting\nunpromising parts. We consider two known data-driven approaches to extend these\nrules to non-metric spaces: TriGen and a piece-wise linear approximation of the\npruning rule. We propose and evaluate two adaptations of TriGen to\nnon-symmetric similarities (TriGen does not support non-symmetric distances).\nWe also evaluate a hybrid of TriGen and the piece-wise linear approximation\npruning. We find that this hybrid approach is often more effective than either\nof the pruning rules. We make our software publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 16:50:50 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Boytsov", "Leonid", ""], ["Nyberg", "Eric", ""]]}, {"id": "1910.03552", "submitter": "Heinrich K\\\"uttler", "authors": "Heinrich K\\\"uttler, Nantas Nardelli, Thibaut Lavril, Marco Selvatici,\n  Viswanath Sivakumar, Tim Rockt\\\"aschel, Edward Grefenstette", "title": "TorchBeast: A PyTorch Platform for Distributed RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TorchBeast is a platform for reinforcement learning (RL) research in PyTorch.\nIt implements a version of the popular IMPALA algorithm for fast, asynchronous,\nparallel training of RL agents. Additionally, TorchBeast has simplicity as an\nexplicit design goal: We provide both a pure-Python implementation\n(\"MonoBeast\") as well as a multi-machine high-performance version\n(\"PolyBeast\"). In the latter, parts of the implementation are written in C++,\nbut all parts pertaining to machine learning are kept in simple Python using\nPyTorch, with the environments provided using the OpenAI Gym interface. This\nenables researchers to conduct scalable RL research using TorchBeast without\nany programming knowledge beyond Python and PyTorch. In this paper, we describe\nthe TorchBeast design principles and implementation and demonstrate that it\nperforms on-par with IMPALA on Atari. TorchBeast is released as an open-source\npackage under the Apache 2.0 license and is available at\n\\url{https://github.com/facebookresearch/torchbeast}.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 17:24:28 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["K\u00fcttler", "Heinrich", ""], ["Nardelli", "Nantas", ""], ["Lavril", "Thibaut", ""], ["Selvatici", "Marco", ""], ["Sivakumar", "Viswanath", ""], ["Rockt\u00e4schel", "Tim", ""], ["Grefenstette", "Edward", ""]]}, {"id": "1910.03553", "submitter": "Ananda Theertha Suresh", "authors": "Ananda Theertha Suresh", "title": "Differentially private anonymized histograms", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a dataset of label-count pairs, an anonymized histogram is the multiset\nof counts. Anonymized histograms appear in various potentially sensitive\ncontexts such as password-frequency lists, degree distribution in social\nnetworks, and estimation of symmetric properties of discrete distributions.\nMotivated by these applications, we propose the first differentially private\nmechanism to release anonymized histograms that achieves near-optimal privacy\nutility trade-off both in terms of number of items and the privacy parameter.\nFurther, if the underlying histogram is given in a compact format, the proposed\nalgorithm runs in time sub-linear in the number of items. For anonymized\nhistograms generated from unknown discrete distributions, we show that the\nreleased histogram can be directly used for estimating symmetric properties of\nthe underlying distribution.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 17:24:32 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 20:54:42 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Suresh", "Ananda Theertha", ""]]}, {"id": "1910.03560", "submitter": "Jong-Chyi Su", "authors": "Jong-Chyi Su, Subhransu Maji, Bharath Hariharan", "title": "When Does Self-supervision Improve Few-shot Learning?", "comments": "ECCV 2020 camera ready. This is an updated version of \"Boosting\n  Supervision with Self-Supervision for Few-shot Learning\" arXiv:1906.07079", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the role of self-supervised learning (SSL) in the context of\nfew-shot learning. Although recent research has shown the benefits of SSL on\nlarge unlabeled datasets, its utility on small datasets is relatively\nunexplored. We find that SSL reduces the relative error rate of few-shot\nmeta-learners by 4%-27%, even when the datasets are small and only utilizing\nimages within the datasets. The improvements are greater when the training set\nis smaller or the task is more challenging. Although the benefits of SSL may\nincrease with larger training sets, we observe that SSL can hurt the\nperformance when the distributions of images used for meta-learning and SSL are\ndifferent. We conduct a systematic study by varying the degree of domain shift\nand analyzing the performance of several meta-learners on a multitude of\ndomains. Based on this analysis we present a technique that automatically\nselects images for SSL from a large, generic pool of unlabeled images for a\ngiven dataset that provides further improvements.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 17:47:14 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 06:08:35 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Su", "Jong-Chyi", ""], ["Maji", "Subhransu", ""], ["Hariharan", "Bharath", ""]]}, {"id": "1910.03561", "submitter": "John Zarka", "authors": "John Zarka, Louis Thiry, Tom\\'as Angles, St\\'ephane Mallat", "title": "Deep Network Classification by Scattering and Homotopy Dictionary\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a sparse scattering deep convolutional neural network, which\nprovides a simple model to analyze properties of deep representation learning\nfor classification. Learning a single dictionary matrix with a classifier\nyields a higher classification accuracy than AlexNet over the ImageNet 2012\ndataset. The network first applies a scattering transform that linearizes\nvariabilities due to geometric transformations such as translations and small\ndeformations. A sparse $\\ell^1$ dictionary coding reduces intra-class\nvariability while preserving class separation through projections over unions\nof linear spaces. It is implemented in a deep convolutional network with a\nhomotopy algorithm having an exponential convergence. A convergence proof is\ngiven in a general framework that includes ALISTA. Classification results are\nanalyzed on ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 17:47:44 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 23:16:15 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 17:32:42 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Zarka", "John", ""], ["Thiry", "Louis", ""], ["Angles", "Tom\u00e1s", ""], ["Mallat", "St\u00e9phane", ""]]}, {"id": "1910.03581", "submitter": "Daliang Li Dr.", "authors": "Daliang Li, Junpu Wang", "title": "FedMD: Heterogenous Federated Learning via Model Distillation", "comments": "4 pages, 2 figures, NeurIPS 2019 Workshop on Federated Learning for\n  Data Privacy and Confidentiality", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables the creation of a powerful centralized model\nwithout compromising data privacy of multiple participants. While successful,\nit does not incorporate the case where each participant independently designs\nits own model. Due to intellectual property concerns and heterogeneous nature\nof tasks and data, this is a widespread requirement in applications of\nfederated learning to areas such as health care and AI as a service. In this\nwork, we use transfer learning and knowledge distillation to develop a\nuniversal framework that enables federated learning when each agent owns not\nonly their private data, but also uniquely designed models. We test our\nframework on the MNIST/FEMNIST dataset and the CIFAR10/CIFAR100 dataset and\nobserve fast improvement across all participating models. With 10 distinct\nparticipants, the final test accuracy of each model on average receives a 20%\ngain on top of what's possible without collaboration and is only a few percent\nlower than the performance each model would have obtained if all private\ndatasets were pooled and made directly available for all participants.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 18:00:00 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Li", "Daliang", ""], ["Wang", "Junpu", ""]]}, {"id": "1910.03620", "submitter": "Matthias Schultheis", "authors": "Matthias Schultheis, Boris Belousov, Hany Abdulsamad, Jan Peters", "title": "Receding Horizon Curiosity", "comments": "Published at Conference on Robot Learning (CoRL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sample-efficient exploration is crucial not only for discovering rewarding\nexperiences but also for adapting to environment changes in a task-agnostic\nfashion. A principled treatment of the problem of optimal input synthesis for\nsystem identification is provided within the framework of sequential Bayesian\nexperimental design. In this paper, we present an effective\ntrajectory-optimization-based approximate solution of this otherwise\nintractable problem that models optimal exploration in an unknown Markov\ndecision process (MDP). By interleaving episodic exploration with Bayesian\nnonlinear system identification, our algorithm takes advantage of the inductive\nbias to explore in a directed manner, without assuming prior knowledge of the\nMDP. Empirical evaluations indicate a clear advantage of the proposed algorithm\nin terms of the rate of convergence and the final model fidelity when compared\nto intrinsic-motivation-based algorithms employing exploration bonuses such as\nprediction error and information gain. Moreover, our method maintains a\ncomputational advantage over a recent model-based active exploration (MAX)\nalgorithm, by focusing on the information gain along trajectories instead of\nseeking a global exploration policy. A reference implementation of our\nalgorithm and the conducted experiments is publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 18:11:50 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Schultheis", "Matthias", ""], ["Belousov", "Boris", ""], ["Abdulsamad", "Hany", ""], ["Peters", "Jan", ""]]}, {"id": "1910.03624", "submitter": "Ali Dabouei", "authors": "Ali Dabouei, Sobhan Soleymani, Fariborz Taherkhani, Jeremy Dawson,\n  Nasser M. Nasrabadi", "title": "SmoothFool: An Efficient Framework for Computing Smooth Adversarial\n  Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are susceptible to adversarial manipulations in the\ninput domain. The extent of vulnerability has been explored intensively in\ncases of $\\ell_p$-bounded and $\\ell_p$-minimal adversarial perturbations.\nHowever, the vulnerability of DNNs to adversarial perturbations with specific\nstatistical properties or frequency-domain characteristics has not been\nsufficiently explored. In this paper, we study the smoothness of perturbations\nand propose SmoothFool, a general and computationally efficient framework for\ncomputing smooth adversarial perturbations. Through extensive experiments, we\nvalidate the efficacy of the proposed method for both the white-box and\nblack-box attack scenarios. In particular, we demonstrate that: (i) there exist\nextremely smooth adversarial perturbations for well-established and widely used\nnetwork architectures, (ii) smoothness significantly enhances the robustness of\nperturbations against state-of-the-art defense mechanisms, (iii) smoothness\nimproves the transferability of adversarial perturbations across both data\npoints and network architectures, and (iv) class categories exhibit a variable\nrange of susceptibility to smooth perturbations. Our results suggest that\nsmooth APs can play a significant role in exploring the vulnerability extent of\nDNNs to adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 18:22:21 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Dabouei", "Ali", ""], ["Soleymani", "Sobhan", ""], ["Taherkhani", "Fariborz", ""], ["Dawson", "Jeremy", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "1910.03633", "submitter": "Weiyang Zhang", "authors": "Weiyang Zhang, Wenshuo Wang, Ding Zhao", "title": "Multi-Vehicle Interaction Scenarios Generation with Interpretable\n  Traffic Primitives and Gaussian Process Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating multi-vehicle interaction scenarios can benefit motion planning\nand decision making of autonomous vehicles when on-road data is insufficient.\nThis paper presents an efficient approach to generate varied multi-vehicle\ninteraction scenarios that can both adapt to different road geometries and\ninherit the key interaction patterns in real-world driving. Towards this end,\nthe available multi-vehicle interaction scenarios are temporally segmented into\nseveral interpretable fundamental building blocks, called traffic primitives,\nvia the Bayesian nonparametric learning. Then, the changepoints of traffic\nprimitives are transformed into the desired road to generate collision-free\ninteraction trajectories through a sampling-based path planning algorithm. The\nGaussian process regression is finally introduced to control the variance and\nsmoothness of the generated multi-vehicle interaction trajectories. Experiments\nwith simulation results of three typical multi-vehicle trajectories at\ndifferent road conditions are carried out. The experimental results demonstrate\nthat our proposed method can generate a bunch of human-like multi-vehicle\ninteraction trajectories that can fit different road conditions remaining the\nkey interaction patterns of agents in the provided scenarios, which is import\nto the development of autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 18:39:14 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Zhang", "Weiyang", ""], ["Wang", "Wenshuo", ""], ["Zhao", "Ding", ""]]}, {"id": "1910.03634", "submitter": "Prerna Kashyap", "authors": "Prerna Kashyap, Samrat Phatale, Iddo Drori", "title": "Prose for a Painting", "comments": null, "journal-ref": "ICCV Workshop on Closing the Loop Between Vision and Language,\n  2019", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Painting captions are often dry and simplistic which motivates us to describe\na painting creatively in the style of Shakespearean prose. This is a difficult\nproblem, since there does not exist a large supervised dataset from paintings\nto Shakespearean prose. Our solution is to use an intermediate English poem\ndescription of the painting and then apply language style transfer which\nresults in Shakespearean prose describing the painting. We rate our results by\nhuman evaluation on a Likert scale, and evaluate the quality of language style\ntransfer using BLEU score as a function of prose length. We demonstrate the\napplicability and limitations of our approach by generating Shakespearean prose\nfor famous paintings. We make our models and code publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 18:39:49 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Kashyap", "Prerna", ""], ["Phatale", "Samrat", ""], ["Drori", "Iddo", ""]]}, {"id": "1910.03638", "submitter": "Mahesh Chandra Mukkamala", "authors": "Mahesh Chandra Mukkamala, Felix Westerkamp, Emanuel Laude, Daniel\n  Cremers, Peter Ochs", "title": "Bregman Proximal Framework for Deep Linear Neural Networks", "comments": "34 pages, 54 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical assumption for the analysis of first order optimization methods is\nthe Lipschitz continuity of the gradient of the objective function. However,\nfor many practical applications this assumption is violated, including loss\nfunctions in deep learning. To overcome this issue, certain extensions based on\ngeneralized proximity measures known as Bregman distances were introduced. This\ninitiated the development of the Bregman proximal gradient (BPG) algorithm and\nan inertial variant (momentum based) CoCaIn BPG, which however rely on problem\ndependent Bregman distances. In this paper, we develop Bregman distances for\nusing BPG methods to train Deep Linear Neural Networks. The main implications\nof our results are strong convergence guarantees for these algorithms. We also\npropose several strategies for their efficient implementation, for example,\nclosed form updates and a closed form expression for the inertial parameter of\nCoCaIn BPG. Moreover, the BPG method requires neither diminishing step sizes\nnor line search, unlike its corresponding Euclidean version. We numerically\nillustrate the competitiveness of the proposed methods compared to existing\nstate of the art schemes.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 18:45:34 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Mukkamala", "Mahesh Chandra", ""], ["Westerkamp", "Felix", ""], ["Laude", "Emanuel", ""], ["Cremers", "Daniel", ""], ["Ochs", "Peter", ""]]}, {"id": "1910.03641", "submitter": "Haoqi Li", "authors": "Haoqi Li, Brian Baucom and Panayiotis Georgiou", "title": "Linking emotions to behaviors through deep transfer learning", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.HC eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human behavior refers to the way humans act and interact. Understanding human\nbehavior is a cornerstone of observational practice, especially in\npsychotherapy. An important cue of behavior analysis is the dynamical changes\nof emotions during the conversation. Domain experts integrate emotional\ninformation in a highly nonlinear manner, thus, it is challenging to explicitly\nquantify the relationship between emotions and behaviors. In this work, we\nemploy deep transfer learning to analyze their inferential capacity and\ncontextual importance. We first train a network to quantify emotions from\nacoustic signals and then use information from the emotion recognition network\nas features for behavior recognition. We treat this emotion-related information\nas behavioral primitives and further train higher level layers towards behavior\nquantification. Through our analysis, we find that emotion-related information\nis an important cue for behavior recognition. Further, we investigate the\nimportance of emotional-context in the expression of behavior by constraining\n(or not) the neural networks' contextual view of the data. This demonstrates\nthat the sequence of emotions is critical in behavior expression. To achieve\nthese frameworks we employ hybrid architectures of convolutional networks and\nrecurrent networks to extract emotion-related behavior primitives and\nfacilitate automatic behavior recognition from speech.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 18:55:08 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Li", "Haoqi", ""], ["Baucom", "Brian", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1910.03643", "submitter": "Denis Belomestny", "authors": "D. Belomestny, L. Iosipoi, E. Moulines, A. Naumov and S. Samsonov", "title": "Variance reduction for Markov chains with application to MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel variance reduction approach for additive\nfunctionals of Markov chains based on minimization of an estimate for the\nasymptotic variance of these functionals over suitable classes of control\nvariates. A distinctive feature of the proposed approach is its ability to\nsignificantly reduce the overall finite sample variance. This feature is\ntheoretically demonstrated by means of a deep non asymptotic analysis of a\nvariance reduced functional as well as by a thorough simulation study. In\nparticular we apply our method to various MCMC Bayesian estimation problems\nwhere it favourably compares to the existing variance reduction approaches.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 19:05:36 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 08:37:54 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Belomestny", "D.", ""], ["Iosipoi", "L.", ""], ["Moulines", "E.", ""], ["Naumov", "A.", ""], ["Samsonov", "S.", ""]]}, {"id": "1910.03644", "submitter": "Clint D. Lombard Dr", "authors": "Clint D. Lombard, Corn\\'e E. van Daalen", "title": "Stochastic triangular mesh mapping: A terrain mapping technique for\n  autonomous mobile robots", "comments": null, "journal-ref": "Robotics and Autonomous Systems (2020)", "doi": "10.1016/j.robot.2020.103449", "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For mobile robots to operate autonomously in general environments, perception\nis required in the form of a dense metric map. For this purpose, we present the\nstochastic triangular mesh (STM) mapping technique: a 2.5-D representation of\nthe surface of the environment using a continuous mesh of triangular surface\nelements, where each surface element models the mean plane and roughness of the\nunderlying surface. In contrast to existing mapping techniques, a STM map\nmodels the structure of the environment by ensuring a continuous model, while\nalso being able to be incrementally updated with linear computational cost in\nthe number of measurements. We reduce the effect of uncertainty in the robot\npose (position and orientation) by using landmark-relative submaps. The\nuncertainty in the measurements and robot pose are accounted for by the use of\nBayesian inference techniques during the map update. We demonstrate that a STM\nmap can be used with sensors that generate point measurements, such as light\ndetection and ranging (LiDAR) sensors and stereo cameras. We show that a STM\nmap is a more accurate model than the only comparable online surface mapping\ntechnique$\\unicode{x2014}$a standard elevation map$\\unicode{x2014}$and we also\nprovide qualitative results on practical datasets.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 19:06:05 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 15:33:35 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lombard", "Clint D.", ""], ["van Daalen", "Corn\u00e9 E.", ""]]}, {"id": "1910.03648", "submitter": "Qianru Sun", "authors": "Qianru Sun, Yaoyao Liu, Zhaozheng Chen, Tat-Seng Chua, and Bernt\n  Schiele", "title": "Meta-Transfer Learning through Hard Tasks", "comments": "An extended version of a paper published in CVPR2019. Under review.\n  arXiv admin note: substantial text overlap with arXiv:1812.02391", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Meta-learning has been proposed as a framework to address the challenging\nfew-shot learning setting. The key idea is to leverage a large number of\nsimilar few-shot tasks in order to learn how to adapt a base-learner to a new\ntask for which only a few labeled samples are available. As deep neural\nnetworks (DNNs) tend to overfit using a few samples only, typical meta-learning\nmodels use shallow neural networks, thus limiting its effectiveness. In order\nto achieve top performance, some recent works tried to use the DNNs pre-trained\non large-scale datasets but mostly in straight-forward manners, e.g., (1)\ntaking their weights as a warm start of meta-training, and (2) freezing their\nconvolutional layers as the feature extractor of base-learners. In this paper,\nwe propose a novel approach called meta-transfer learning (MTL) which learns to\ntransfer the weights of a deep NN for few-shot learning tasks. Specifically,\nmeta refers to training multiple tasks, and transfer is achieved by learning\nscaling and shifting functions of DNN weights for each task. In addition, we\nintroduce the hard task (HT) meta-batch scheme as an effective learning\ncurriculum that further boosts the learning efficiency of MTL. We conduct\nfew-shot learning experiments and report top performance for five-class\nfew-shot recognition tasks on three challenging benchmarks: miniImageNet,\ntieredImageNet and Fewshot-CIFAR100 (FC100). Extensive comparisons to related\nworks validate that our MTL approach trained with the proposed HT meta-batch\nscheme achieves top performance. An ablation study also shows that both\ncomponents contribute to fast convergence and high accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 06:05:18 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Sun", "Qianru", ""], ["Liu", "Yaoyao", ""], ["Chen", "Zhaozheng", ""], ["Chua", "Tat-Seng", ""], ["Schiele", "Bernt", ""]]}, {"id": "1910.03650", "submitter": "Jean Mercat", "authors": "Jean Mercat, Thomas Gilles, Nicole El Zoghby, Guillaume Sandou,\n  Dominique Beauvois, Guillermo Pita Gil", "title": "Multi-Head Attention for Multi-Modal Joint Vehicle Motion Forecasting", "comments": "7 pages, 4 figures, under review at ICRA and RA-L", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel vehicle motion forecasting method based on\nmulti-head attention. It produces joint forecasts for all vehicles on a road\nscene as sequences of multi-modal probability density functions of their\npositions. Its architecture uses multi-head attention to account for complete\ninteractions between all vehicles, and long short-term memory layers for\nencoding and forecasting. It relies solely on vehicle position tracks, does not\nneed maneuver definitions, and does not represent the scene with a spatial\ngrid. This allows it to be more versatile than similar model while combining\nany forecasting capabilities, namely joint forecast with interactions,\nuncertainty estimation, and multi-modality. The resulting prediction likelihood\noutperforms state-of-the-art models on the same dataset.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 19:16:56 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 22:03:23 GMT"}, {"version": "v3", "created": "Fri, 20 Dec 2019 12:36:57 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Mercat", "Jean", ""], ["Gilles", "Thomas", ""], ["Zoghby", "Nicole El", ""], ["Sandou", "Guillaume", ""], ["Beauvois", "Dominique", ""], ["Gil", "Guillermo Pita", ""]]}, {"id": "1910.03655", "submitter": "Alane Suhr", "authors": "Alane Suhr, Claudia Yan, Jacob Schluger, Stanley Yu, Hadi Khader,\n  Marwa Mouallem, Iris Zhang, Yoav Artzi", "title": "Executing Instructions in Situated Collaborative Interactions", "comments": "EMNLP 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a collaborative scenario where a user not only instructs a system to\ncomplete tasks, but also acts alongside it. This allows the user to adapt to\nthe system abilities by changing their language or deciding to simply\naccomplish some tasks themselves, and requires the system to effectively\nrecover from errors as the user strategically assigns it new goals. We build a\ngame environment to study this scenario, and learn to map user instructions to\nsystem actions. We introduce a learning approach focused on recovery from\ncascading errors between instructions, and modeling methods to explicitly\nreason about instructions with multiple goals. We evaluate with a new\nevaluation protocol using recorded interactions and online games with human\nusers, and observe how users adapt to the system abilities.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 19:22:58 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 14:25:12 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 15:27:46 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Suhr", "Alane", ""], ["Yan", "Claudia", ""], ["Schluger", "Jacob", ""], ["Yu", "Stanley", ""], ["Khader", "Hadi", ""], ["Mouallem", "Marwa", ""], ["Zhang", "Iris", ""], ["Artzi", "Yoav", ""]]}, {"id": "1910.03676", "submitter": "Ehsan Adeli", "authors": "Ehsan Adeli, Qingyu Zhao, Adolf Pfefferbaum, Edith V. Sullivan, Li\n  Fei-Fei, Juan Carlos Niebles, Kilian M. Pohl", "title": "Representation Learning with Statistical Independence to Mitigate Bias", "comments": "WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presence of bias (in datasets or tasks) is inarguably one of the most\ncritical challenges in machine learning applications that has alluded to\npivotal debates in recent years. Such challenges range from spurious\nassociations between variables in medical studies to the bias of race in gender\nor face recognition systems. Controlling for all types of biases in the dataset\ncuration stage is cumbersome and sometimes impossible. The alternative is to\nuse the available data and build models incorporating fair representation\nlearning. In this paper, we propose such a model based on adversarial training\nwith two competing objectives to learn features that have (1) maximum\ndiscriminative power with respect to the task and (2) minimal statistical mean\ndependence with the protected (bias) variable(s). Our approach does so by\nincorporating a new adversarial loss function that encourages a vanished\ncorrelation between the bias and the learned features. We apply our method to\nsynthetic data, medical images (containing task bias), and a dataset for gender\nclassification (containing dataset bias). Our results show that the learned\nfeatures by our method not only result in superior prediction performance but\nalso are unbiased. The code is available at\nhttps://github.com/QingyuZhao/BR-Net/.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 20:33:58 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 06:27:59 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 22:30:34 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2020 17:57:38 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Adeli", "Ehsan", ""], ["Zhao", "Qingyu", ""], ["Pfefferbaum", "Adolf", ""], ["Sullivan", "Edith V.", ""], ["Fei-Fei", "Li", ""], ["Niebles", "Juan Carlos", ""], ["Pohl", "Kilian M.", ""]]}, {"id": "1910.03678", "submitter": "Muhammad Mahbubur Rahman", "authors": "Muhammad Mahbubur Rahman, Tim Finin", "title": "Unfolding the Structure of a Document using Deep Learning", "comments": "16 pages, 16 figures and 10 tables. arXiv admin note: text overlap\n  with arXiv:1709.00770", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and extracting of information from large documents, such as\nbusiness opportunities, academic articles, medical documents and technical\nreports, poses challenges not present in short documents. Such large documents\nmay be multi-themed, complex, noisy and cover diverse topics. We describe a\nframework that can analyze large documents and help people and computer systems\nlocate desired information in them. We aim to automatically identify and\nclassify different sections of documents and understand their purpose within\nthe document. A key contribution of our research is modeling and extracting the\nlogical and semantic structure of electronic documents using deep learning\ntechniques. We evaluate the effectiveness and robustness of our framework\nthrough extensive experiments on two collections: more than one million\nscholarly articles from arXiv and a collection of requests for proposal\ndocuments from government sources.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:33:46 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Rahman", "Muhammad Mahbubur", ""], ["Finin", "Tim", ""]]}, {"id": "1910.03695", "submitter": "Sehyun Chun", "authors": "Sehyun Chun, Nima Hamidi Ghalehjegh, Joseph B. Choi, Chris W. Schwarz,\n  John G. Gaspar, Daniel V. McGehee, Stephen S. Baek", "title": "NADS-Net: A Nimble Architecture for Driver and Seat Belt Detection via\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new convolutional neural network (CNN) architecture for 2D driver/passenger\npose estimation and seat belt detection is proposed in this paper. The new\narchitecture is more nimble and thus more suitable for in-vehicle monitoring\ntasks compared to other generic pose estimation algorithms. The new\narchitecture, named NADS-Net, utilizes the feature pyramid network (FPN)\nbackbone with multiple detection heads to achieve the optimal performance for\ndriver/passenger state detection tasks. The new architecture is validated on a\nnew data set containing video clips of 100 drivers in 50 driving sessions that\nare collected for this study. The detection performance is analyzed under\ndifferent demographic, appearance, and illumination conditions. The results\npresented in this paper may provide meaningful insights for the autonomous\ndriving research community and automotive industry for future algorithm\ndevelopment and data collection.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 21:16:28 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Chun", "Sehyun", ""], ["Ghalehjegh", "Nima Hamidi", ""], ["Choi", "Joseph B.", ""], ["Schwarz", "Chris W.", ""], ["Gaspar", "John G.", ""], ["McGehee", "Daniel V.", ""], ["Baek", "Stephen S.", ""]]}, {"id": "1910.03698", "submitter": "Iddo Drori", "authors": "Iddo Drori, Lu Liu, Yi Nian, Sharath C. Koorathota, Jie S. Li, Antonio\n  Khalil Moretti, Juliana Freire, Madeleine Udell", "title": "AutoML using Metadata Language Embeddings", "comments": null, "journal-ref": "NeurIPS Workshop on Meta-Learning, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a human choosing a supervised learning algorithm, it is natural to begin\nby reading a text description of the dataset and documentation for the\nalgorithms you might use. We demonstrate that the same idea improves the\nperformance of automated machine learning methods. We use language embeddings\nfrom modern NLP to improve state-of-the-art AutoML systems by augmenting their\nrecommendations with vector embeddings of datasets and of algorithms. We use\nthese embeddings in a neural architecture to learn the distance between\nbest-performing pipelines. The resulting (meta-)AutoML framework improves on\nthe performance of existing AutoML frameworks. Our zero-shot AutoML system\nusing dataset metadata embeddings provides good solutions instantaneously,\nrunning in under one second of computation. Performance is competitive with\nAutoML systems OBOE, AutoSklearn, AlphaD3M, and TPOT when each framework is\nallocated a minute of computation. We make our data, models, and code publicly\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 21:28:47 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Drori", "Iddo", ""], ["Liu", "Lu", ""], ["Nian", "Yi", ""], ["Koorathota", "Sharath C.", ""], ["Li", "Jie S.", ""], ["Moretti", "Antonio Khalil", ""], ["Freire", "Juliana", ""], ["Udell", "Madeleine", ""]]}, {"id": "1910.03701", "submitter": "Brian Ichter", "authors": "Brian Ichter, Edward Schmerling, Tsang-Wei Edward Lee, and Aleksandra\n  Faust", "title": "Learned Critical Probabilistic Roadmaps for Robotic Motion Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling-based motion planning techniques have emerged as an efficient\nalgorithmic paradigm for solving complex motion planning problems. These\napproaches use a set of probing samples to construct an implicit graph\nrepresentation of the robot's state space, allowing arbitrarily accurate\nrepresentations as the number of samples increases to infinity. In practice,\nhowever, solution trajectories only rely on a few critical states, often\ndefined by structure in the state space (e.g., doorways). In this work we\npropose a general method to identify these critical states via graph-theoretic\ntechniques (betweenness centrality) and learn to predict criticality from only\nlocal environment features. These states are then leveraged more heavily via\nglobal connections within a hierarchical graph, termed Critical Probabilistic\nRoadmaps. Critical PRMs are demonstrated to achieve up to three orders of\nmagnitude improvement over uniform sampling, while preserving the guarantees\nand complexity of sampling-based motion planning. A video is available at\nhttps://youtu.be/AYoD-pGd9ms.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 21:46:34 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Ichter", "Brian", ""], ["Schmerling", "Edward", ""], ["Lee", "Tsang-Wei Edward", ""], ["Faust", "Aleksandra", ""]]}, {"id": "1910.03713", "submitter": "Marco Pasini", "authors": "Marco Pasini", "title": "MelGAN-VC: Voice Conversion and Audio Style Transfer on arbitrarily long\n  samples using Spectrograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional voice conversion methods rely on parallel recordings of multiple\nspeakers pronouncing the same sentences. For real-world applications however,\nparallel data is rarely available. We propose MelGAN-VC, a voice conversion\nmethod that relies on non-parallel speech data and is able to convert audio\nsignals of arbitrary length from a source voice to a target voice. We firstly\ncompute spectrograms from waveform data and then perform a domain translation\nusing a Generative Adversarial Network (GAN) architecture. An additional\nsiamese network helps preserving speech information in the translation process,\nwithout sacrificing the ability to flexibly model the style of the target\nspeaker. We test our framework with a dataset of clean speech recordings, as\nwell as with a collection of noisy real-world speech examples. Finally, we\napply the same method to perform music style transfer, translating arbitrarily\nlong music samples from one genre to another, and showing that our framework is\nflexible and can be used for audio manipulation applications different from\nvoice conversion.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 23:22:50 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 16:28:50 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Pasini", "Marco", ""]]}, {"id": "1910.03718", "submitter": "Min-Hsiu Hsieh", "authors": "Chao Zhang, Min-Hsiu Hsieh, Dacheng Tao", "title": "On Dimension-free Tail Inequalities for Sums of Random Matrices and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math-ph math.MP math.ST quant-ph stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new framework to obtain tail inequalities for\nsums of random matrices. Compared with existing works, our tail inequalities\nhave the following characteristics: 1) high feasibility--they can be used to\nstudy the tail behavior of various matrix functions, e.g., arbitrary matrix\nnorms, the absolute value of the sum of the sum of the $j$ largest singular\nvalues (resp. eigenvalues) of complex matrices (resp. Hermitian matrices); and\n2) independence of matrix dimension --- they do not have the matrix-dimension\nterm as a product factor, and thus are suitable to the scenario of\nhigh-dimensional or infinite-dimensional random matrices. The price we pay to\nobtain these advantages is that the convergence rate of the resulting\ninequalities will become slow when the number of summand random matrices is\nlarge. We also develop the tail inequalities for matrix random series and\nmatrix martingale difference sequence. We also demonstrate usefulness of our\ntail bounds in several fields. In compressed sensing, we employ the resulted\ntail inequalities to achieve a proof of the restricted isometry property when\nthe measurement matrix is the sum of random matrices without any assumption on\nthe distributions of matrix entries. In probability theory, we derive a new\nupper bound to the supreme of stochastic processes. In machine learning, we\nprove new expectation bounds of sums of random matrices matrix and obtain\nmatrix approximation schemes via random sampling. In quantum information, we\nshow a new analysis relating to the fractional cover number of quantum\nhypergraphs. In theoretical computer science, we obtain randomness-efficient\nsamplers using matrix expander graphs that can be efficiently implemented in\ntime without dependence on matrix dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 23:38:51 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Zhang", "Chao", ""], ["Hsieh", "Min-Hsiu", ""], ["Tao", "Dacheng", ""]]}, {"id": "1910.03728", "submitter": "Nil Stolt Anso", "authors": "Nil Stolt Ans\\'o", "title": "Investigation on the generalization of the Sampled Policy Gradient\n  algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sampled Policy Gradient (SPG) algorithm is a new offline actor-critic\nvariant that samples in the action space to approximate the policy gradient. It\ndoes so by using the critic to evaluate the sampled actions. SPG offers\ntheoretical promise over similar algorithms such as DPG as it searches the\naction-Q-value space independently of the local gradient, enabling it to avoid\nlocal minima. This paper aims to compare SPG to two similar actor-critic\nalgorithms, CACLA and DPG. The comparison is made across two different\nenvironments, two different network architectures, as well as training on\non-policy transitions in contrast to using an experience buffer. Results seem\nto show that although SPG does often not perform the worst, it doesn't always\nmatch the performance of the best performing algorithm at a particular task.\nFurther experiments are required to get a better estimate of the qualities of\nSPG.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 00:26:13 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Ans\u00f3", "Nil Stolt", ""]]}, {"id": "1910.03731", "submitter": "Vivek Sharma", "authors": "Vivek Sharma, Praneeth Vepakomma, Tristan Swedish, Ken Chang,\n  Jayashree Kalpathy-Cramer, Ramesh Raskar", "title": "ExpertMatcher: Automating ML Model Selection for Clients using Hidden\n  Representations", "comments": "In NeurIPS Workshop on Robust AI in Financial Services: Data,\n  Fairness, Explainability, Trustworthiness, and Privacy, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, there has been the development of Split Learning, a framework for\ndistributed computation where model components are split between the client and\nserver (Vepakomma et al., 2018b). As Split Learning scales to include many\ndifferent model components, there needs to be a method of matching client-side\nmodel components with the best server-side model components. A solution to this\nproblem was introduced in the ExpertMatcher (Sharma et al., 2019) framework,\nwhich uses autoencoders to match raw data to models. In this work, we propose\nan extension of ExpertMatcher, where matching can be performed without the need\nto share the client's raw data representation. The technique is applicable to\nsituations where there are local clients and centralized expert ML models, but\nthe sharing of raw data is constrained.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 00:42:16 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Sharma", "Vivek", ""], ["Vepakomma", "Praneeth", ""], ["Swedish", "Tristan", ""], ["Chang", "Ken", ""], ["Kalpathy-Cramer", "Jayashree", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1910.03732", "submitter": "Vibhavari Dasagi", "authors": "Vibhavari Dasagi, Jake Bruce, Thierry Peynot and J\\\"urgen Leitner", "title": "Ctrl-Z: Recovering from Instability in Reinforcement Learning", "comments": "Submitted to ICRA2020, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning behavior, training data is often generated by the learner\nitself; this can result in unstable training dynamics, and this problem has\nparticularly important applications in safety-sensitive real-world control\ntasks such as robotics. In this work, we propose a principled and\nmodel-agnostic approach to mitigate the issue of unstable learning dynamics by\nmaintaining a history of a reinforcement learning agent over the course of\ntraining, and reverting to the parameters of a previous agent whenever\nperformance significantly decreases. We develop techniques for evaluating this\nperformance through statistical hypothesis testing of continued improvement,\nand evaluate them on a standard suite of challenging benchmark tasks involving\ncontinuous control of simulated robots. We show improvements over\nstate-of-the-art reinforcement learning algorithms in performance and\nrobustness to hyperparameters, outperforming DDPG in 5 out of 6 evaluation\nenvironments and showing no decrease in performance with TD3, which is known to\nbe relatively stable. In this way, our approach takes an important step towards\nincreasing data efficiency and stability in training for real-world robotic\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 00:45:53 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Dasagi", "Vibhavari", ""], ["Bruce", "Jake", ""], ["Peynot", "Thierry", ""], ["Leitner", "J\u00fcrgen", ""]]}, {"id": "1910.03741", "submitter": "Haoran Wei", "authors": "Haoran Wei, Mariefel Olarte, Garrett B. Goh", "title": "Multiple-objective Reinforcement Learning for Inverse Design and\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the inverse chemical design is to develop new molecules with given\noptimized molecular properties or objectives. Recently, generative deep\nlearning (DL) networks are considered as the state-of-the-art in inverse\nchemical design and have achieved early success in generating molecular\nstructures with desired properties in the pharmaceutical and material chemistry\nfields. However, satisfying a large number (larger than 10 objectives) of\nmolecular objectives is a limitation of current generative models. To improve\nthe model's ability to handle a large number of molecule design objectives, we\ndeveloped a Reinforcement Learning (RL) based generative framework to optimize\nchemical molecule generation. Our use of Curriculum Learning (CL) to fine-tune\nthe pre-trained generative network allowed the model to satisfy up to 21\nobjectives and increase the generative network's robustness. The experiments\nshow that the proposed multiple-objective RL-based generative model can\ncorrectly identify unknown molecules with an 83 to 100 percent success rate,\ncompared to the baseline approach of 0 percent. Additionally, this proposed\ngenerative model is not limited to just chemistry research challenges; we\nanticipate that problems that utilize RL with multiple-objectives will benefit\nfrom this framework.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 01:40:17 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Wei", "Haoran", ""], ["Olarte", "Mariefel", ""], ["Goh", "Garrett B.", ""]]}, {"id": "1910.03742", "submitter": "Tan Nguyen", "authors": "Tan Nguyen, Nan Ye, Peter L. Bartlett", "title": "Greedy Convex Ensemble", "comments": "Replace the previous version with the camera ready version accepted\n  for IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning a convex combination of basis models, and present some\nnew theoretical and empirical results that demonstrate the effectiveness of a\ngreedy approach. Theoretically, we first consider whether we can use linear,\ninstead of convex, combinations, and obtain generalization results similar to\nexisting ones for learning from a convex hull. We obtain a negative result that\neven the linear hull of very simple basis functions can have unbounded\ncapacity, and is thus prone to overfitting; on the other hand, convex hulls are\nstill rich but have bounded capacities. Secondly, we obtain a generalization\nbound for a general class of Lipschitz loss functions. Empirically, we first\ndiscuss how a convex combination can be greedily learned with early stopping,\nand how a convex combination can be non-greedily learned when the number of\nbasis models is known a priori. Our experiments suggest that the greedy scheme\nis competitive with or better than several baselines, including boosting and\nrandom forests. The greedy algorithm requires little effort in hyper-parameter\ntuning, and also seems able to adapt to the underlying complexity of the\nproblem. Our code is available at https://github.com/tan1889/gce.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 01:41:56 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 04:18:52 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Nguyen", "Tan", ""], ["Ye", "Nan", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "1910.03746", "submitter": "Ao Zheng", "authors": "Ao Zheng, Hewei Gao, Li Zhang and Yuxiang Xing", "title": "A cascaded dual-domain deep learning reconstruction method for sparsely\n  spaced multidetector helical CT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Helical CT has been widely used in clinical diagnosis. Sparsely spaced\nmultidetector in z direction can increase the coverage of the detector provided\nlimited detector rows. It can speed up volumetric CT scan, lower the radiation\ndose and reduce motion artifacts. However, it leads to insufficient data for\nreconstruction. That means reconstructions from general analytical methods will\nhave severe artifacts. Iterative reconstruction methods might be able to deal\nwith this situation but with the cost of huge computational load. In this work,\nwe propose a cascaded dual-domain deep learning method that completes both data\ntransformation in projection domain and error reduction in image domain. First,\na convolutional neural network (CNN) in projection domain is constructed to\nestimate missing helical projection data and converting helical projection data\nto 2D fan-beam projection data. This step is to suppress helical artifacts and\nreduce the following computational cost. Then, an analytical linear operator is\nfollowed to transfer the data from projection domain to image domain. Finally,\nan image domain CNN is added to improve image quality further. These three\nsteps work as an entirety and can be trained end to end. The overall network is\ntrained using a simulated lung CT dataset with Poisson noise from 25 patients.\nWe evaluate the trained network on another three patients and obtain very\nencouraging results with both visual examination and quantitative comparison.\nThe resulting RRMSE is 6.56% and the SSIM is 99.60%. In addition, we test the\ntrained network on the lung CT dataset with different noise level and a new\ndental CT dataset to demonstrate the generalization and robustness of our\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 01:48:48 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 05:06:27 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Zheng", "Ao", ""], ["Gao", "Hewei", ""], ["Zhang", "Li", ""], ["Xing", "Yuxiang", ""]]}, {"id": "1910.03749", "submitter": "Benjam\\'in B\\'ejar", "authors": "Benjam\\'in B\\'ejar, Ivan Dokmani\\'c, Ren\\'e Vidal", "title": "The fastest $\\ell_{1,\\infty}$ prox in the west", "comments": "9 pages, 2 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal operators are of particular interest in optimization problems\ndealing with non-smooth objectives because in many practical cases they lead to\noptimization algorithms whose updates can be computed in closed form or very\nefficiently. A well-known example is the proximal operator of the vector\n$\\ell_1$ norm, which is given by the soft-thresholding operator. In this paper\nwe study the proximal operator of the mixed $\\ell_{1,\\infty}$ matrix norm and\nshow that it can be computed in closed form by applying the well-known\nsoft-thresholding operator to each column of the matrix. However, unlike the\nvector $\\ell_1$ norm case where the threshold is constant, in the mixed\n$\\ell_{1,\\infty}$ norm case each column of the matrix might require a different\nthreshold and all thresholds depend on the given matrix. We propose a general\niterative algorithm for computing these thresholds, as well as two efficient\nimplementations that further exploit easy to compute lower bounds for the mixed\nnorm of the optimal solution. Experiments on large-scale synthetic and real\ndata indicate that the proposed methods can be orders of magnitude faster than\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 01:56:04 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["B\u00e9jar", "Benjam\u00edn", ""], ["Dokmani\u0107", "Ivan", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "1910.03751", "submitter": "Behzad Asadi", "authors": "Behzad Asadi, Vijay Varadharajan", "title": "An MDL-Based Classifier for Transactional Datasets with Application in\n  Malware Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a classifier for transactional datasets with application in malware\ndetection. We build the classifier based on the minimum description length\n(MDL) principle. This involves selecting a model that best compresses the\ntraining dataset for each class considering the MDL criterion. To select a\nmodel for a dataset, we first use clustering followed by closed frequent\npattern mining to extract a subset of closed frequent patterns (CFPs). We show\nthat this method acts as a pattern summarization method to avoid pattern\nexplosion; this is done by giving priority to longer CFPs, and without\nrequiring to extract all CFPs. We then use the MDL criterion to further\nsummarize extracted patterns, and construct a code table of patterns. This code\ntable is considered as the selected model for the compression of the dataset.\nWe evaluate our classifier for the problem of static malware detection in\nportable executable (PE) files. We consider API calls of PE files as their\ndistinguishing features. The presence-absence of API calls forms a\ntransactional dataset. Using our proposed method, we construct two code tables,\none for the benign training dataset, and one for the malware training dataset.\nOur dataset consists of 19696 benign, and 19696 malware samples, each a binary\nsequence of size 22761. We compare our classifier with deep neural networks\nproviding us with the state-of-the-art performance. The comparison shows that\nour classifier performs very close to deep neural networks. We also discuss\nthat our classifier is an interpretable classifier. This provides the\nmotivation to use this type of classifiers where some degree of explanation is\nrequired as to why a sample is classified under one class rather than the other\nclass.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 02:08:03 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 23:55:56 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Asadi", "Behzad", ""], ["Varadharajan", "Vijay", ""]]}, {"id": "1910.03779", "submitter": "Juntao Wang Mr", "authors": "Juntao Wang, Yang Liu, Yiling Chen", "title": "Forecast Aggregation via Peer Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.HC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing is a popular paradigm for soliciting forecasts on future\nevents. As people may have different forecasts, how to aggregate solicited\nforecasts into a single accurate prediction remains to be an important\nchallenge, especially when no historical accuracy information is available for\nidentifying experts. In this paper, we borrow ideas from the peer prediction\nliterature and assess the prediction accuracy of participants using solely the\ncollected forecasts. This approach leverages the correlations among peer\nreports to cross-validate each participant's forecasts and allows us to assign\na \"peer assessment score (PAS)\" for each agent as a proxy for the agent's\nprediction accuracy. We identify several empirically effective methods to\ngenerate PAS and propose an aggregation framework that uses PAS to identify\nexperts and to boost existing aggregators' prediction accuracy. We evaluate our\nmethods over 14 real-world datasets and show that i) PAS generated from peer\nprediction methods can approximately reflect the prediction accuracy of agents,\nand ii) our aggregation framework demonstrates consistent and significant\nimprovement in the prediction accuracy over existing aggregators for both\nbinary and multi-choice questions under three popular accuracy measures: Brier\nscore (mean square error), log score (cross-entropy loss) and AUC-ROC.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 04:07:13 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 00:27:10 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 19:39:40 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 05:03:42 GMT"}, {"version": "v5", "created": "Thu, 4 Mar 2021 07:28:11 GMT"}, {"version": "v6", "created": "Tue, 27 Apr 2021 21:11:44 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Wang", "Juntao", ""], ["Liu", "Yang", ""], ["Chen", "Yiling", ""]]}, {"id": "1910.03783", "submitter": "Alexandre Tartakovsky", "authors": "Tong Ma and Renke Huang and David Barajas-Solano and Ramakrishna\n  Tipireddy and Alexandre M. Tartakovsky", "title": "Electric Load and Power Forecasting Using Ensemble Gaussian Process\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new forecasting method for predicting load demand and generation\nscheduling. Accurate week-long forecasting of load demand and optimal power\ngeneration is critical for efficient operation of power grid systems. In this\nwork, we use a synthetic data set describing a power grid with 700 buses and\n134 generators over a 365-days period with data synthetically generated at an\nhourly rate. The proposed approach for week-long forecasting is based on the\nGaussian process regression (GPR) method, with prior covariance matrices of the\nquantities of interest (QoI) computed from ensembles formed by up to twenty\npreceding weeks of QoI observations. Then, we use these covariances within the\nGPR framework to forecast the QoIs for the following week. We demonstrate that\nthe the proposed ensemble GPR (EGPR) method is capable of accurately\nforecasting weekly total load demand and power generation profiles. The EGPR\nmethod is shown to outperform traditional forecasting methods including the\nstandard GPR and autoregressive integrated moving average (ARIMA) methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 04:13:51 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Ma", "Tong", ""], ["Huang", "Renke", ""], ["Barajas-Solano", "David", ""], ["Tipireddy", "Ramakrishna", ""], ["Tartakovsky", "Alexandre M.", ""]]}, {"id": "1910.03787", "submitter": "Xueyuan Xu", "authors": "Xia Wu, Xueyuan Xu, Jianhong Liu, Hailing Wang, Bin Hu, Feiping Nie", "title": "Supervised feature selection with orthogonal regression and feature\n  weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective features can improve the performance of a model, which can thus\nhelp us understand the characteristics and underlying structure of complex\ndata. Previous feature selection methods usually cannot keep more local\nstructure information. To address the defects previously mentioned, we propose\na novel supervised orthogonal least square regression model with feature\nweighting for feature selection. The optimization problem of the objection\nfunction can be solved by employing generalized power iteration (GPI) and\naugmented Lagrangian multiplier (ALM) methods. Experimental results show that\nthe proposed method can more effectively reduce the feature dimensionality and\nobtain better classification results than traditional feature selection\nmethods. The convergence of our iterative method is proved as well.\nConsequently, the effectiveness and superiority of the proposed method are\nverified both theoretically and experimentally.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 04:39:09 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Wu", "Xia", ""], ["Xu", "Xueyuan", ""], ["Liu", "Jianhong", ""], ["Wang", "Hailing", ""], ["Hu", "Bin", ""], ["Nie", "Feiping", ""]]}, {"id": "1910.03802", "submitter": "Hoang Nt", "authors": "Takanori Maehara and Hoang NT", "title": "A Simple Proof of the Universality of Invariant/Equivariant Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple proof for the universality of invariant and equivariant\ntensorized graph neural networks. Our approach considers a restricted\nintermediate hypothetical model named Graph Homomorphism Model to reach the\nuniversality conclusions including an open case for higher-order output. We\nfind that our proposed technique not only leads to simple proofs of the\nuniversality properties but also gives a natural explanation for the\ntensorization of the previously studied models. Finally, we give some remarks\non the connection between our model and the continuous representation of\ngraphs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 06:07:53 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Maehara", "Takanori", ""], ["NT", "Hoang", ""]]}, {"id": "1910.03804", "submitter": "Mahesh Pal Dr.", "authors": "Mahesh Pal", "title": "Deep neural network for pier scour prediction", "comments": "7 pages, 2 figure, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement in computing power over last decades, deep neural\nnetworks (DNN), consisting of two or more hidden layers with large number of\nnodes, are being suggested as an alternate to commonly used single-hidden-layer\nneural networks (ANN). DNN are found to be flexible models with a very large\nnumber of parameters, thus making them capable of modelling very complex and\nhighly nonlinear relationships existing between inputs and outputs. This paper\ninvestigates the potential of a DNN consisting of 3 hidden layers (100, 80 and\n50 nodes) to predict the local scour around bridge piers using field data. To\nupdate the weights and bias of DNN, an adaptive learning rate optimization\nalgorithm was used. The dataset consists of 232 pier scour measurements, out of\nwhich a total of 154 data were used to train whereas remaining 78 data to test\nthe created model. A correlation coefficient value of 0.957 (root mean square\nerror = 0.306m) was achieved by DNN in comparison to 0.938 (0.388m) by ANN,\nindicating an improved performance by DNN for scour depth perdition.\nEncouraging performance on the used dataset in the work suggests the need of\nmore studies on the use of DNN for various civil engineering applications.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 06:18:59 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Pal", "Mahesh", ""]]}, {"id": "1910.03806", "submitter": "Samuel R\\\"onnqvist", "authors": "Samuel R\\\"onnqvist, Jenna Kanerva, Tapio Salakoski, Filip Ginter", "title": "Is Multilingual BERT Fluent in Language Generation?", "comments": null, "journal-ref": "In proceedings of the First NLPL Workshop on Deep Learning for\n  Natural Language Processing (2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The multilingual BERT model is trained on 104 languages and meant to serve as\na universal language model and tool for encoding sentences. We explore how well\nthe model performs on several languages across several tasks: a diagnostic\nclassification probing the embeddings for a particular syntactic property, a\ncloze task testing the language modelling ability to fill in gaps in a\nsentence, and a natural language generation task testing for the ability to\nproduce coherent text fitting a given context. We find that the currently\navailable multilingual BERT model is clearly inferior to the monolingual\ncounterparts, and cannot in many cases serve as a substitute for a well-trained\nmonolingual model. We find that the English and German models perform well at\ngeneration, whereas the multilingual model is lacking, in particular, for\nNordic languages.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 06:35:59 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["R\u00f6nnqvist", "Samuel", ""], ["Kanerva", "Jenna", ""], ["Salakoski", "Tapio", ""], ["Ginter", "Filip", ""]]}, {"id": "1910.03810", "submitter": "Marco Schreyer", "authors": "Marco Schreyer, Timur Sattarov, Bernd Reimer, Damian Borth", "title": "Adversarial Learning of Deepfakes in Accounting", "comments": "17 pages, 10 figures, and, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, organizations collect vast quantities of accounting relevant\ntransactions, referred to as 'journal entries', in 'Enterprise Resource\nPlanning' (ERP) systems. The aggregation of those entries ultimately defines an\norganization's financial statement. To detect potential misstatements and\nfraud, international audit standards demand auditors to directly assess journal\nentries using 'Computer Assisted AuditTechniques' (CAATs). At the same time,\ndiscoveries in deep learning research revealed that machine learning models are\nvulnerable to 'adversarial attacks'. It also became evident that such attack\ntechniques can be misused to generate 'Deepfakes' designed to directly attack\nthe perception of humans by creating convincingly altered media content. The\nresearch of such developments and their potential impact on the finance and\naccounting domain is still in its early stage. We believe that it is of vital\nrelevance to investigate how such techniques could be maliciously misused in\nthis sphere. In this work, we show an adversarial attack against CAATs using\ndeep neural networks. We first introduce a real-world 'thread model' designed\nto camouflage accounting anomalies such as fraudulent journal entries. Second,\nwe show that adversarial autoencoder neural networks are capable of learning a\nhuman interpretable model of journal entries that disentangles the entries\nlatent generative factors. Finally, we demonstrate how such a model can be\nmaliciously misused by a perpetrator to generate robust 'adversarial' journal\nentries that mislead CAATs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 06:44:23 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Schreyer", "Marco", ""], ["Sattarov", "Timur", ""], ["Reimer", "Bernd", ""], ["Borth", "Damian", ""]]}, {"id": "1910.03818", "submitter": "Run-Qing Chen", "authors": "Run-Qing Chen and Guang-Hui Shi and Wan-Lei Zhao and Chang-Hui Liang", "title": "A Joint Model for IT Operation Series Prediction and Anomaly Detection", "comments": "This paper has been published in Neurocomputing", "journal-ref": "Volume 448, 11 August 2021, Pages 130-139", "doi": "10.1016/j.neucom.2021.03.062", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Status prediction and anomaly detection are two fundamental tasks in\nautomatic IT systems monitoring. In this paper, a joint model Predictor &\nAnomaly Detector (PAD) is proposed to address these two issues under one\nframework. In our design, the variational auto-encoder (VAE) and long\nshort-term memory (LSTM) are joined together. The prediction block (LSTM) takes\nclean input from the reconstructed time series by VAE, which makes it robust to\nthe anomalies and noise for prediction task. In the meantime, the LSTM block\nmaintains the long-term sequential patterns, which are out of the sight of a\nVAE encoding window. This leads to the better performance of VAE in anomaly\ndetection than it is trained alone. In the whole processing pipeline, the\nspectral residual analysis is integrated with VAE and LSTM to boost the\nperformance of both. The superior performance on two tasks is confirmed with\nthe experiments on two challenging evaluation benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 07:25:33 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 07:21:37 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 13:20:57 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 01:54:56 GMT"}, {"version": "v5", "created": "Thu, 22 Apr 2021 03:26:59 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Chen", "Run-Qing", ""], ["Shi", "Guang-Hui", ""], ["Zhao", "Wan-Lei", ""], ["Liang", "Chang-Hui", ""]]}, {"id": "1910.03833", "submitter": "Yubei Chen", "authors": "Juexiao Zhang, Yubei Chen, Brian Cheung, Bruno A Olshausen", "title": "Word Embedding Visualization Via Dictionary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-occurrence statistics based word embedding techniques have proved to be\nvery useful in extracting the semantic and syntactic representation of words as\nlow dimensional continuous vectors. In this work, we discovered that dictionary\nlearning can open up these word vectors as a linear combination of more\nelementary word factors. We demonstrate many of the learned factors have\nsurprisingly strong semantic or syntactic meaning corresponding to the factors\npreviously identified manually by human inspection. Thus dictionary learning\nprovides a powerful visualization tool for understanding word embedding\nrepresentations. Furthermore, we show that the word factors can help in\nidentifying key semantic and syntactic differences in word analogy tasks and\nimprove upon the state-of-the-art word embedding techniques in these tasks by a\nlarge margin.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 08:14:48 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 09:57:44 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zhang", "Juexiao", ""], ["Chen", "Yubei", ""], ["Cheung", "Brian", ""], ["Olshausen", "Bruno A", ""]]}, {"id": "1910.03834", "submitter": "Song Liu Dr.", "authors": "Song Liu, Takafumi Kanamori, Daniel J. Williams", "title": "Estimating Density Models with Truncation Boundaries using Score\n  Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truncated densities are probability density functions defined on truncated\ndomains. They share the same parametric form with their non-truncated\ncounterparts up to a normalizing constant. Since the computation of their\nnormalizing constants is usually infeasible, Maximum Likelihood Estimation\ncannot be easily applied to estimate truncated density models. Score Matching\n(SM) is a powerful tool for fitting parameters using only unnormalized models.\nHowever, it cannot be directly applied here as boundary conditions used to\nderive a tractable SM objective are not satisfied by truncated densities. In\nthis paper, we study parameter estimation for truncated probability densities\nusing SM. The estimator minimizes a weighted Fisher divergence. The weight\nfunction is simply the shortest distance from the data point to the boundary of\nthe domain. We show this choice of weight function naturally arises from\nminimizing the Stein discrepancy as well as upperbounding the finite-sample\nstatistical estimation error. The usefulness of our method is demonstrated by\nnumerical experiments and a Chicago crime dataset. We also show that proposed\ndensity estimation can correct the outlier-trimming bias caused by aggressive\noutlier detection methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 08:18:20 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 18:01:45 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 00:22:22 GMT"}, {"version": "v4", "created": "Mon, 1 Mar 2021 15:01:35 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Liu", "Song", ""], ["Kanamori", "Takafumi", ""], ["Williams", "Daniel J.", ""]]}, {"id": "1910.03835", "submitter": "Zili Meng", "authors": "Zili Meng, Minhu Wang, Jiasong Bai, Mingwei Xu, Hongzi Mao, Hongxin Hu", "title": "Interpreting Deep Learning-Based Networking Systems", "comments": "To appear at ACM SIGCOMM 2020", "journal-ref": null, "doi": "10.1145/3387514.3405859", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many deep learning (DL)-based networking systems have demonstrated\nsuperior performance, the underlying Deep Neural Networks (DNNs) remain\nblackboxes and stay uninterpretable for network operators. The lack of\ninterpretability makes DL-based networking systems prohibitive to deploy in\npractice. In this paper, we propose Metis, a framework that provides\ninterpretability for two general categories of networking problems spanning\nlocal and global control. Accordingly, Metis introduces two different\ninterpretation methods based on decision tree and hypergraph, where it converts\nDNN policies to interpretable rule-based controllers and highlight critical\ncomponents based on analysis over hypergraph. We evaluate Metis over several\nstate-of-the-art DL-based networking systems and show that Metis provides\nhuman-readable interpretations while preserving nearly no degradation in\nperformance. We further present four concrete use cases of Metis, showcasing\nhow Metis helps network operators to design, debug, deploy, and ad-hoc adjust\nDL-based networking systems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 08:19:57 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 13:45:24 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 11:55:28 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Meng", "Zili", ""], ["Wang", "Minhu", ""], ["Bai", "Jiasong", ""], ["Xu", "Mingwei", ""], ["Mao", "Hongzi", ""], ["Hu", "Hongxin", ""]]}, {"id": "1910.03846", "submitter": "Qiang Tang", "authors": "Qiang Tang", "title": "Privacy-preserving and yet Robust Collaborative Filtering Recommender as\n  a Service", "comments": "19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering recommenders provide effective personalization\nservices at the cost of sacrificing the privacy of their end users. Due to the\nincreasing concerns from the society and stricter privacy regulations, it is an\nurgent research challenge to design privacy-preserving and yet robust\nrecommenders which offer recommendation services to privacy-aware users. Our\nanalysis shows that existing solutions fall short in several aspects, including\nlacking attention to the precise output to end users and ignoring the\ncorrelated robustness issues. In this paper, we provide a general system\nstructure for latent factor based collaborative filtering recommenders by\nformulating them into model training and prediction computing stages, and also\ndescribe a new security model. Aiming at pragmatic solutions, we first show how\nto construct privacy-preserving and yet robust model training stage based on\nexisting solutions. Then, we propose two cryptographic protocols to realize a\nprivacy-preserving prediction computing stage, depending on whether or not an\nextra proxy is involved. Different from standard Top-k recommendations, we\nalternatively let the end user retrieve the unrated items whose predictions are\nabove a threshold, as a result of our privacy by design strategy. Experimental\nresults show that our new protocols are quite efficient.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 08:43:46 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Tang", "Qiang", ""]]}, {"id": "1910.03857", "submitter": "Marcin B. Tomczak", "authors": "Marcin B. Tomczak, Dongho Kim, Peter Vrancx and Kee-Eung Kim", "title": "Policy Optimization Through Approximate Importance Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent policy optimization approaches (Schulman et al., 2015a; 2017) have\nachieved substantial empirical successes by constructing new proxy optimization\nobjectives. These proxy objectives allow stable and low variance policy\nlearning, but require small policy updates to ensure that the proxy objective\nremains an accurate approximation of the target policy value. In this paper we\nderive an alternative objective that obtains the value of the target policy by\napplying importance sampling (IS). However, the basic importance sampled\nobjective is not suitable for policy optimization, as it incurs too high\nvariance in policy updates. We therefore introduce an approximation that allows\nus to directly trade-off the bias of approximation with the variance in policy\nupdates. We show that our approximation unifies previously developed approaches\nand allows us to interpolate between them. We develop a practical algorithm by\noptimizing the introduced objective with proximal policy optimization\ntechniques (Schulman et al., 2017). We also provide a theoretical analysis of\nthe introduced policy optimization objective demonstrating bias-variance\ntrade-off. We empirically demonstrate that the resulting algorithm improves\nupon state of the art on-policy policy optimization on continuous control\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 09:06:35 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 16:14:43 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Tomczak", "Marcin B.", ""], ["Kim", "Dongho", ""], ["Vrancx", "Peter", ""], ["Kim", "Kee-Eung", ""]]}, {"id": "1910.03860", "submitter": "Hicham Janati", "authors": "Hicham Janati, Marco Cuturi, Alexandre Gramfort", "title": "Spatio-Temporal Alignments: Optimal transport through space and time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing data defined over space and time is notoriously hard, because it\ninvolves quantifying both spatial and temporal variability, while at the same\ntime taking into account the chronological structure of data. Dynamic Time\nWarping (DTW) computes an optimal alignment between time series in agreement\nwith the chronological order, but is inherently blind to spatial shifts. In\nthis paper, we propose Spatio-Temporal Alignments (STA), a new differentiable\nformulation of DTW, in which spatial differences between time samples are\naccounted for using regularized optimal transport (OT). Our temporal alignments\nare handled through a smooth variant of DTW called soft-DTW, for which we prove\na new property: soft-DTW increases quadratically with time shifts. The cost\nmatrix within soft-DTW that we use are computed using unbalanced OT, to handle\nthe case in which observations are not normalized probabilities. Experiments on\nhandwritten letters and brain imaging data confirm our theoretical findings and\nillustrate the effectiveness of STA as a dissimilarity for spatio-temporal\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 09:22:41 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 17:14:23 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 14:00:01 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Janati", "Hicham", ""], ["Cuturi", "Marco", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1910.03861", "submitter": "Aur\\'elien Bellet", "authors": "James Bell and Aur\\'elien Bellet and Adri\\`a Gasc\\'on and Tejas\n  Kulkarni", "title": "Private Protocols for U-Statistics in the Local Model and Beyond", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of computing $U$-statistics of degree\n$2$, i.e., quantities that come in the form of averages over pairs of data\npoints, in the local model of differential privacy (LDP). The class of\n$U$-statistics covers many statistical estimates of interest, including Gini\nmean difference, Kendall's tau coefficient and Area under the ROC Curve (AUC),\nas well as empirical risk measures for machine learning problems such as\nranking, clustering and metric learning. We first introduce an LDP protocol\nbased on quantizing the data into bins and applying randomized response, which\nguarantees an $\\epsilon$-LDP estimate with a Mean Squared Error (MSE) of\n$O(1/\\sqrt{n}\\epsilon)$ under regularity assumptions on the $U$-statistic or\nthe data distribution. We then propose a specialized protocol for AUC based on\na novel use of hierarchical histograms that achieves MSE of\n$O(\\alpha^3/n\\epsilon^2)$ for arbitrary data distribution. We also show that\n2-party secure computation allows to design a protocol with MSE of\n$O(1/n\\epsilon^2)$, without any assumption on the kernel function or data\ndistribution and with total communication linear in the number of users $n$.\nFinally, we evaluate the performance of our protocols through experiments on\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 09:24:53 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 20:26:02 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Bell", "James", ""], ["Bellet", "Aur\u00e9lien", ""], ["Gasc\u00f3n", "Adri\u00e0", ""], ["Kulkarni", "Tejas", ""]]}, {"id": "1910.03865", "submitter": "Yuqing Du", "authors": "Yuqing Du, Sheng Yang and Kaibin Huang", "title": "High-Dimensional Stochastic Gradient Quantization for\n  Communication-Efficient Edge Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.2983166", "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge machine learning involves the deployment of learning algorithms at the\nwireless network edge so as to leverage massive mobile data for enabling\nintelligent applications. The mainstream edge learning approach, federated\nlearning, has been developed based on distributed gradient descent. Based on\nthe approach, stochastic gradients are computed at edge devices and then\ntransmitted to an edge server for updating a global AI model. Since each\nstochastic gradient is typically high-dimensional (with millions to billions of\ncoefficients), communication overhead becomes a bottleneck for edge learning.\nTo address this issue, we propose in this work a novel framework of\nhierarchical stochastic gradient quantization and study its effect on the\nlearning performance. First, the framework features a practical hierarchical\narchitecture for decomposing the stochastic gradient into its norm and\nnormalized block gradients, and efficiently quantizes them using a uniform\nquantizer and a low-dimensional codebook on a Grassmann manifold, respectively.\nSubsequently, the quantized normalized block gradients are scaled and cascaded\nto yield the quantized normalized stochastic gradient using a so-called hinge\nvector designed under the criterion of minimum distortion. The hinge vector is\nalso efficiently compressed using another low-dimensional Grassmannian\nquantizer. The other feature of the framework is a bit-allocation scheme for\nreducing the quantization error. The scheme determines the resolutions of the\nlow-dimensional quantizers in the proposed framework. The framework is proved\nto guarantee model convergency by analyzing the convergence rate as a function\nof the quantization bits. Furthermore, by simulation, our design is shown to\nsubstantially reduce the communication overhead compared with the\nstate-of-the-art signSGD scheme, while both achieve similar learning\naccuracies.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 09:37:40 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Du", "Yuqing", ""], ["Yang", "Sheng", ""], ["Huang", "Kaibin", ""]]}, {"id": "1910.03867", "submitter": "Ivan Skorokhodov", "authors": "Ivan Skorokhodov, Mikhail Burtsev", "title": "Loss Landscape Sightseeing with Multi-Point Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present multi-point optimization: an optimization technique that allows to\ntrain several models simultaneously without the need to keep the parameters of\neach one individually. The proposed method is used for a thorough empirical\nanalysis of the loss landscape of neural networks. By extensive experiments on\nFashionMNIST and CIFAR10 datasets we demonstrate two things: 1) loss surface is\nsurprisingly diverse and intricate in terms of landscape patterns it contains,\nand 2) adding batch normalization makes it more smooth. Source code to\nreproduce all the reported results is available on GitHub:\nhttps://github.com/universome/loss-patterns.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 09:44:27 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 11:21:24 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Skorokhodov", "Ivan", ""], ["Burtsev", "Mikhail", ""]]}, {"id": "1910.03875", "submitter": "Anton Mallasto", "authors": "Anton Mallasto, Guido Mont\\'ufar and Augusto Gerolin", "title": "How Well Do WGANs Estimate the Wasserstein Metric?", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative modelling is often cast as minimizing a similarity measure between\na data distribution and a model distribution. Recently, a popular choice for\nthe similarity measure has been the Wasserstein metric, which can be expressed\nin the Kantorovich duality formulation as the optimum difference of the\nexpected values of a potential function under the real data distribution and\nthe model hypothesis. In practice, the potential is approximated with a neural\nnetwork and is called the discriminator. Duality constraints on the function\nclass of the discriminator are enforced approximately, and the expectations are\nestimated from samples. This gives at least three sources of errors: the\napproximated discriminator and constraints, the estimation of the expectation\nvalue, and the optimization required to find the optimal potential. In this\nwork, we study how well the methods, that are used in generative adversarial\nnetworks to approximate the Wasserstein metric, perform. We consider, in\nparticular, the $c$-transform formulation, which eliminates the need to enforce\nthe constraints explicitly. We demonstrate that the $c$-transform allows for a\nmore accurate estimation of the true Wasserstein metric from samples, but\nsurprisingly, does not perform the best in the generative setting.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 10:00:34 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Mallasto", "Anton", ""], ["Mont\u00fafar", "Guido", ""], ["Gerolin", "Augusto", ""]]}, {"id": "1910.03876", "submitter": "Younkwan Lee", "authors": "Younkwan Lee, Juhyun Lee, Hoyeon Ahn, Moongu Jeon", "title": "SNIDER: Single Noisy Image Denoising and Rectification for Improving\n  License Plate Recognition", "comments": "accepted to ICCV 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an algorithm for real-world license plate\nrecognition (LPR) from a low-quality image. Our method is built upon a\nframework that includes denoising and rectification, and each task is conducted\nby Convolutional Neural Networks. Existing denoising and rectification have\nbeen treated separately as a single network in previous research. In contrast\nto the previous work, we here propose an end-to-end trainable network for image\nrecovery, Single Noisy Image DEnoising and Rectification (SNIDER), which\nfocuses on solving both the problems jointly. It overcomes those obstacles by\ndesigning a novel network to address the denoising and rectification jointly.\nMoreover, we propose a way to leverage optimization with the auxiliary tasks\nfor multi-task fitting and novel training losses. Extensive experiments on two\nchallenging LPR datasets demonstrate the effectiveness of our proposed method\nin recovering the high-quality license plate image from the low-quality one and\nshow that the the proposed method outperforms other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 10:01:07 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Lee", "Younkwan", ""], ["Lee", "Juhyun", ""], ["Ahn", "Hoyeon", ""], ["Jeon", "Moongu", ""]]}, {"id": "1910.03879", "submitter": "Haakon Robinson", "authors": "Haakon Robinson, Adil Rasheed, Omer San", "title": "Dissecting Deep Neural Networks", "comments": "12 pages, 10 figures (not including bio pics), submitted to IEEE\n  Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In exchange for large quantities of data and processing power, deep neural\nnetworks have yielded models that provide state of the art predication\ncapabilities in many fields. However, a lack of strong guarantees on their\nbehaviour have raised concerns over their use in safety-critical applications.\nA first step to understanding these networks is to develop alternate\nrepresentations that allow for further analysis. It has been shown that neural\nnetworks with piecewise affine activation functions are themselves piecewise\naffine, with their domains consisting of a vast number of linear regions. So\nfar, the research on this topic has focused on counting the number of linear\nregions, rather than obtaining explicit piecewise affine representations. This\nwork presents a novel algorithm that can compute the piecewise affine form of\nany fully connected neural network with rectified linear unit activations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 10:05:23 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 12:33:32 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Robinson", "Haakon", ""], ["Rasheed", "Adil", ""], ["San", "Omer", ""]]}, {"id": "1910.03880", "submitter": "Marcin B. Tomczak", "authors": "Marcin B. Tomczak, Sergio Valcarcel Macua, Enrique Munoz de Cote and\n  Peter Vrancx", "title": "Compatible features for Monotonic Policy Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent policy optimization approaches have achieved substantial empirical\nsuccess by constructing surrogate optimization objectives. The Approximate\nPolicy Iteration objective (Schulman et al., 2015a; Kakade and Langford, 2002)\nhas become a standard optimization target for reinforcement learning problems.\nUsing this objective in practice requires an estimator of the advantage\nfunction. Policy optimization methods such as those proposed in Schulman et al.\n(2015b) estimate the advantages using a parametric critic. In this work we\nestablish conditions under which the parametric approximation of the critic\ndoes not introduce bias to the updates of surrogate objective. These results\nhold for a general class of parametric policies, including deep neural\nnetworks. We obtain a result analogous to the compatible features derived for\nthe original Policy Gradient Theorem (Sutton et al., 1999). As a result, we\nalso identify a previously unknown bias that current state-of-the-art policy\noptimization algorithms (Schulman et al., 2015a, 2017) have introduced by not\nemploying these compatible features.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 10:16:19 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 12:49:10 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Tomczak", "Marcin B.", ""], ["Macua", "Sergio Valcarcel", ""], ["de Cote", "Enrique Munoz", ""], ["Vrancx", "Peter", ""]]}, {"id": "1910.03906", "submitter": "\\\"Omer Deniz Akyildiz", "authors": "\\\"Omer Deniz Akyildiz, Gerrit J.J. van den Burg, Theodoros Damoulas,\n  Mark F. J. Steel", "title": "Probabilistic sequential matrix factorization", "comments": "Accepted for publication at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the probabilistic sequential matrix factorization (PSMF) method\nfor factorizing time-varying and non-stationary datasets consisting of\nhigh-dimensional time-series. In particular, we consider nonlinear Gaussian\nstate-space models where sequential approximate inference results in the\nfactorization of a data matrix into a dictionary and time-varying coefficients\nwith potentially nonlinear Markovian dependencies. The assumed Markovian\nstructure on the coefficients enables us to encode temporal dependencies into a\nlow-dimensional feature space. The proposed inference method is solely based on\nan approximate extended Kalman filtering scheme, which makes the resulting\nmethod particularly efficient. PSMF can account for temporal nonlinearities\nand, more importantly, can be used to calibrate and estimate generic\ndifferentiable nonlinear subspace models. We also introduce a robust version of\nPSMF, called rPSMF, which uses Student-t filters to handle model\nmisspecification. We show that PSMF can be used in multiple contexts: modeling\ntime series with a periodic subspace, robustifying changepoint detection\nmethods, and imputing missing data in several high-dimensional time-series,\nsuch as measurements of pollutants across London.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 11:30:29 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 19:01:46 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 17:08:19 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Akyildiz", "\u00d6mer Deniz", ""], ["Burg", "Gerrit J. J. van den", ""], ["Damoulas", "Theodoros", ""], ["Steel", "Mark F. J.", ""]]}, {"id": "1910.03916", "submitter": "Giulio Zizzo", "authors": "Giulio Zizzo, Chris Hankin, Sergio Maffeis, Kevin Jones", "title": "Deep Latent Defence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have shown state of the art performance in a range of\ntasks from computer vision to natural language processing. However, it is well\nknown that such systems are vulnerable to attackers who craft inputs in order\nto cause misclassification. The level of perturbation an attacker needs to\nintroduce in order to cause such a misclassification can be extremely small,\nand often imperceptible. This is of significant security concern, particularly\nwhere misclassification can cause harm to humans.\n  We thus propose Deep Latent Defence, an architecture which seeks to combine\nadversarial training with a detection system. At its core Deep Latent Defence\nhas a adversarially trained neural network. A series of encoders take the\nintermediate layer representation of data as it passes though the network and\nproject it to a latent space which we use for detecting adversarial samples via\na $k$-nn classifier. We present results using both grey and white box\nattackers, as well as an adaptive $L_{\\infty}$ bounded attack which was\nconstructed specifically to try and evade our defence. We find that even under\nthe strongest attacker model that we have investigated our defence is able to\noffer significant defensive benefits.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 12:00:52 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 11:59:17 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zizzo", "Giulio", ""], ["Hankin", "Chris", ""], ["Maffeis", "Sergio", ""], ["Jones", "Kevin", ""]]}, {"id": "1910.03935", "submitter": "Frank Nielsen", "authors": "Frank Nielsen", "title": "On geodesic triangles with right angles in a dually flat space", "comments": "40 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dualistic structure of statistical manifolds in information geometry\nyields eight types of geodesic triangles passing through three given points,\nthe triangle vertices. The interior angles of geodesic triangles can sum up to\n$\\pi$ like in Euclidean/Mahalanobis flat geometry, or exhibit otherwise angle\nexcesses or angle defects. In this paper, we initiate the study of geodesic\ntriangles in dually flat spaces, termed Bregman manifolds, where a generalized\nPythagorean theorem holds. We consider non-self dual Bregman manifolds since\nMahalanobis self-dual manifolds amount to Euclidean geometry. First, we show\nhow to construct geodesic triangles with either one, two, or three interior\nright angles, whenever it is possible. Second, we report a construction of\ntriples of points for which the dual Pythagorean theorems hold simultaneously\nat a point, yielding two dual pairs of dual-type geodesics with right angles at\nthat point.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 12:25:24 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 06:35:58 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 08:35:45 GMT"}, {"version": "v4", "created": "Tue, 11 May 2021 01:57:29 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Nielsen", "Frank", ""]]}, {"id": "1910.03937", "submitter": "Mathukumalli Vidyasagar", "authors": "Shantanu Prasad Burnwal, Kaneenika Sinha and Mathukumalli Vidyasagar", "title": "New and Explicit Constructions of Unbalanced Ramanujan Bipartite Graphs", "comments": "This paper is a partial replacement of 1910.03937v1. The phase\n  transition part of 1910.03937v1 will be uploaded as a separate submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.CO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objectives of this article are three-fold. Firstly, we present for the\nfirst time explicit constructions of an infinite family of \\textit{unbalanced}\nRamanujan bigraphs. Secondly, we revisit some of the known methods for\nconstructing Ramanujan graphs and discuss the computational work required in\nactually implementing the various construction methods. The third goal of this\narticle is to address the following question: can we construct a bipartite\nRamanujan graph with specified degrees, but with the restriction that the edge\nset of this graph must be distinct from a given set of \"prohibited\" edges? We\nprovide an affirmative answer in many cases, as long as the set of prohibited\nedges is not too large.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 16:46:31 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 11:32:52 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Burnwal", "Shantanu Prasad", ""], ["Sinha", "Kaneenika", ""], ["Vidyasagar", "Mathukumalli", ""]]}, {"id": "1910.03943", "submitter": "Ali Sadeghian", "authors": "Ali Sadeghian, Shervin Minaee, Ioannis Partalas, Xinxin Li, Daisy Zhe\n  Wang, Brooke Cowan", "title": "Hotel2vec: Learning Attribute-Aware Hotel Embeddings with\n  Self-Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural network architecture for learning vector representations\nof hotels. Unlike previous works, which typically only use user click\ninformation for learning item embeddings, we propose a framework that combines\nseveral sources of data, including user clicks, hotel attributes (e.g.,\nproperty type, star rating, average user rating), amenity information (e.g.,\nthe hotel has free Wi-Fi or free breakfast), and geographic information. During\nmodel training, a joint embedding is learned from all of the above information.\nWe show that including structured attributes about hotels enables us to make\nbetter predictions in a downstream task than when we rely exclusively on click\ndata. We train our embedding model on more than 40 million user click sessions\nfrom a leading online travel platform and learn embeddings for more than one\nmillion hotels. Our final learned embeddings integrate distinct sub-embeddings\nfor user clicks, hotel attributes, and geographic information, providing an\ninterpretable representation that can be used flexibly depending on the\napplication. We show empirically that our model generates high-quality\nrepresentations that boost the performance of a hotel recommendation system in\naddition to other applications. An important advantage of the proposed neural\nmodel is that it addresses the cold-start problem for hotels with insufficient\nhistorical click information by incorporating additional hotel attributes which\nare available for all hotels.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 23:47:55 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Sadeghian", "Ali", ""], ["Minaee", "Shervin", ""], ["Partalas", "Ioannis", ""], ["Li", "Xinxin", ""], ["Wang", "Daisy Zhe", ""], ["Cowan", "Brooke", ""]]}, {"id": "1910.03948", "submitter": "ChaeHwan Song", "authors": "Armin Eftekhari, ChaeHwan Song, Volkan Cevher", "title": "Nearly Minimal Over-Parametrization of Shallow Neural Networks", "comments": "This paper is submitted without consent of the co-authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of work has shown that an overparametrized neural network can\nperfectly fit the training data, an otherwise often intractable nonconvex\noptimization problem. For (fully-connected) shallow networks, in the best case\nscenario, the existing theory requires quadratic over-parametrization as a\nfunction of the number of training samples. This paper establishes that linear\noverparametrization is sufficient to fit the training data, using a simple\nvariant of the (stochastic) gradient descent. Crucially, unlike several related\nworks, the training considered in this paper is not limited to the lazy regime\nin the sense cautioned against in [1, 2]. Beyond shallow networks, the\nframework developed in this work for over-parametrization is applicable to a\nvariety of learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 12:31:49 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 16:45:37 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Eftekhari", "Armin", ""], ["Song", "ChaeHwan", ""], ["Cevher", "Volkan", ""]]}, {"id": "1910.03962", "submitter": "Julius von K\\\"ugelgen", "authors": "Julius von K\\\"ugelgen, Paul K Rubenstein, Bernhard Sch\\\"olkopf, Adrian\n  Weller", "title": "Optimal experimental design via Bayesian optimization: active causal\n  structure learning for Gaussian process networks", "comments": "Working paper. Accepted as a poster at the NeurIPS 2019 workshop, \"Do\n  the right thing\": machine learning and causal inference for improved decision\n  making. (6 pages + references + appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of causal discovery through targeted interventions.\nStarting from few observational measurements, we follow a Bayesian active\nlearning approach to perform those experiments which, in expectation with\nrespect to the current model, are maximally informative about the underlying\ncausal structure. Unlike previous work, we consider the setting of continuous\nrandom variables with non-linear functional relationships, modelled with\nGaussian process priors. To address the arising problem of choosing from an\nuncountable set of possible interventions, we propose to use Bayesian\noptimisation to efficiently maximise a Monte Carlo estimate of the expected\ninformation gain.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 12:57:35 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["von K\u00fcgelgen", "Julius", ""], ["Rubenstein", "Paul K", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Weller", "Adrian", ""]]}, {"id": "1910.03970", "submitter": "Marcin Straczkiewicz", "authors": "Marcin Straczkiewicz, Peter James, Jukka-Pekka Onnela", "title": "A systematic review of smartphone-based human activity recognition for\n  health research", "comments": "47 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Smartphones are now nearly ubiquitous; their numerous built-in\nsensors enable continuous measurement of activities of daily living, making\nthem especially well-suited for health research. Researchers have proposed\nvarious human activity recognition (HAR) systems aimed at translating\nmeasurements from smartphones into various types of physical activity. In this\nreview, we summarize the existing approaches to smartphone-based HAR. Methods:\nWe systematically searched Scopus, PubMed, and Web of Science for peer-reviewed\narticles published up to December 2020 on the use of smartphones for HAR. We\nextracted information on smartphone body location, sensors, and physical\nactivity types studied and the data transformation techniques and\nclassification schemes used for activity recognition. Results: We identified\n108 articles and described the various approaches used for data acquisition,\ndata preprocessing, feature extraction, and activity classification,\nidentifying the most common practices and their alternatives. Conclusions:\nSmartphones are well-suited for HAR research in the health sciences. For\npopulation-level impact, future studies should focus on improving quality of\ncollected data, address missing data, incorporate more diverse participants and\nactivities, relax requirements about phone placement, provide more complete\ndocumentation on study participants, and share the source code of the\nimplemented methods and algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 18:45:10 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 04:21:41 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Straczkiewicz", "Marcin", ""], ["James", "Peter", ""], ["Onnela", "Jukka-Pekka", ""]]}, {"id": "1910.03973", "submitter": "Yazhan Zhang", "authors": "Yazhan Zhang, Weihao Yuan, Zicheng Kan, Michael Yu Wang", "title": "Towards Learning to Detect and Predict Contact Events on Vision-based\n  Tactile Sensors", "comments": "10 pages, 7 figures, Accepted to conference on Robot Learning (CoRL\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In essence, successful grasp boils down to correct responses to multiple\ncontact events between fingertips and objects. In most scenarios, tactile\nsensing is adequate to distinguish contact events. Due to the nature of high\ndimensionality of tactile information, classifying spatiotemporal tactile\nsignals using conventional model-based methods is difficult. In this work, we\npropose to predict and classify tactile signal using deep learning methods,\nseeking to enhance the adaptability of the robotic grasp system to external\nevent changes that may lead to grasping failure. We develop a deep learning\nframework and collect 6650 tactile image sequences with a vision-based tactile\nsensor, and the neural network is integrated into a contact-event-based robotic\ngrasping system. In grasping experiments, we achieved 52% increase in terms of\nobject lifting success rate with contact detection, significantly higher\nrobustness under unexpected loads with slip prediction compared with open-loop\ngrasps, demonstrating that integration of the proposed framework into robotic\ngrasping system substantially improves picking success rate and capability to\nwithstand external disturbances.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 13:25:12 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Zhang", "Yazhan", ""], ["Yuan", "Weihao", ""], ["Kan", "Zicheng", ""], ["Wang", "Michael Yu", ""]]}, {"id": "1910.03976", "submitter": "Lorenzo Nespoli", "authors": "Lorenzo Nespoli, Vasco Medici, Kristijan Lopatichki, Fabrizio Sossan", "title": "Hierarchical Demand Forecasting Benchmark for the Distribution Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comparative study of different probabilistic forecasting\ntechniques on the task of predicting the electrical load of secondary\nsubstations and cabinets located in a low voltage distribution grid, as well as\ntheir aggregated power profile. The methods are evaluated using standard KPIs\nfor deterministic and probabilistic forecasts. We also compare the ability of\ndifferent hierarchical techniques in improving the bottom level forecasters'\nperformances. Both the raw and cleaned datasets, including meteorological data,\nare made publicly available to provide a standard benchmark for evaluating\nforecasting algorithms for demand-side management applications.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:38:56 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 08:11:46 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Nespoli", "Lorenzo", ""], ["Medici", "Vasco", ""], ["Lopatichki", "Kristijan", ""], ["Sossan", "Fabrizio", ""]]}, {"id": "1910.03980", "submitter": "Andrea Giorgetti", "authors": "Andrea Mariani and Andrea Giorgetti and Marco Chiani", "title": "Model Order Selection Based on Information Theoretic Criteria: Design of\n  the Penalty", "comments": "11 pages, 8 figures, journal", "journal-ref": "IEEE Trans. on Signal Processing, vol. 63, no. 11, pp. 2779-2789,\n  June 2015", "doi": "10.1109/TSP.2015.2414900", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theoretic criteria (ITC) have been widely adopted in engineering\nand statistics for selecting, among an ordered set of candidate models, the one\nthat better fits the observed sample data. The selected model minimizes a\npenalized likelihood metric, where the penalty is determined by the criterion\nadopted. While rules for choosing a penalty that guarantees a consistent\nestimate of the model order are known, theoretical tools for its design with\nfinite samples have never been provided in a general setting. In this paper, we\nstudy model order selection for finite samples under a design perspective,\nfocusing on the generalized information criterion (GIC), which embraces the\nmost common ITC. The theory is general, and as case studies we consider: a) the\nproblem of estimating the number of signals embedded in additive white Gaussian\nnoise (AWGN) by using multiple sensors; b) model selection for the general\nlinear model (GLM), which includes e.g. the problem of estimating the number of\nsinusoids in AWGN. The analysis reveals a trade-off between the probabilities\nof overestimating and underestimating the order of the model. We then propose\nto design the GIC penalty to minimize underestimation while keeping the\noverestimation probability below a specified level. For the considered\nproblems, this method leads to analytical derivation of the optimal penalty for\na given sample size. A performance comparison between the penalty optimized GIC\nand common AIC and BIC is provided, demonstrating the effectiveness of the\nproposed design strategy.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 14:48:16 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Mariani", "Andrea", ""], ["Giorgetti", "Andrea", ""], ["Chiani", "Marco", ""]]}, {"id": "1910.03997", "submitter": "Martin Hahner", "authors": "Martin Hahner, Dengxin Dai, Christos Sakaridis, Jan-Nico Zaech, Luc\n  Van Gool", "title": "Semantic Understanding of Foggy Scenes with Purely Synthetic Data", "comments": "independent class IoU scores corrected for BiSiNet architecture", "journal-ref": null, "doi": "10.1109/ITSC.2019.8917518", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the problem of semantic scene understanding under foggy\nroad conditions. Although marked progress has been made in semantic scene\nunderstanding over the recent years, it is mainly concentrated on clear weather\noutdoor scenes. Extending semantic segmentation methods to adverse weather\nconditions like fog is crucially important for outdoor applications such as\nself-driving cars. In this paper, we propose a novel method, which uses purely\nsynthetic data to improve the performance on unseen real-world foggy scenes\ncaptured in the streets of Zurich and its surroundings. Our results highlight\nthe potential and power of photo-realistic synthetic images for training and\nespecially fine-tuning deep neural nets. Our contributions are threefold, 1) we\ncreated a purely synthetic, high-quality foggy dataset of 25,000 unique outdoor\nscenes, that we call Foggy Synscapes and plan to release publicly 2) we show\nthat with this data we outperform previous approaches on real-world foggy test\ndata 3) we show that a combination of our data and previously used data can\neven further improve the performance on real-world foggy data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 14:04:59 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 07:42:58 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Hahner", "Martin", ""], ["Dai", "Dengxin", ""], ["Sakaridis", "Christos", ""], ["Zaech", "Jan-Nico", ""], ["Van Gool", "Luc", ""]]}, {"id": "1910.04023", "submitter": "Ignacio Arroyo-Fern\\'andez", "authors": "Ignacio Arroyo-Fern\\'andez and Mauricio Carrasco-Ru\\'iz and J. Anibal\n  Arias-Aguilar", "title": "On the Possibility of Rewarding Structure Learning Agents: Mutual\n  Information on Linguistic Random Sets", "comments": "Paper accepted to the Workshop on Sets & Partitions (NeurIPS 2019,\n  Vancouver, Canada)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a first attempt to elucidate a theoretical and empirical approach\nto design the reward provided by a natural language environment to some\nstructure learning agent. To this end, we revisit the Information Theory of\nunsupervised induction of phrase-structure grammars to characterize the\nbehavior of simulated actions modeled as set-valued random variables (random\nsets of linguistic samples) constituting semantic structures. Our results\nshowed empirical evidence of that simulated semantic structures (Open\nInformation Extraction triplets) can be distinguished from randomly constructed\nones by observing the Mutual Information among their constituents. This\nsuggests the possibility of rewarding structure learning agents without using\npretrained structural analyzers (oracle actors/experts).\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 14:33:37 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 01:34:52 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 01:48:19 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 16:56:56 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Arroyo-Fern\u00e1ndez", "Ignacio", ""], ["Carrasco-Ru\u00edz", "Mauricio", ""], ["Arias-Aguilar", "J. Anibal", ""]]}, {"id": "1910.04034", "submitter": "Victor Gabillon", "authors": "Victor Gabillon, Rasul Tutunov, Michal Valko, Haitham Bou Ammar", "title": "Derivative-Free & Order-Robust Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formalise order-robust optimisation as an instance of\nonline learning minimising simple regret, and propose Vroom, a zero'th order\noptimisation algorithm capable of achieving vanishing regret in non-stationary\nenvironments, while recovering favorable rates under stochastic\nreward-generating processes. Our results are the first to target simple regret\ndefinitions in adversarial scenarios unveiling a challenge that has been rarely\nconsidered in prior work.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 14:51:23 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 13:01:50 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 08:49:05 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Gabillon", "Victor", ""], ["Tutunov", "Rasul", ""], ["Valko", "Michal", ""], ["Ammar", "Haitham Bou", ""]]}, {"id": "1910.04041", "submitter": "Ramy E. Ali", "authors": "Ramy E. Ali, Bilgehan Erman, Ejder Ba\\c{s}tu\\u{g} and Bruce Cilli", "title": "Hierarchical Deep Double Q-Routing", "comments": "IEEE ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.IT cs.LG cs.MA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a deep reinforcement learning approach applied to the\npacket routing problem with high-dimensional constraints instigated by dynamic\nand autonomous communication networks. Our approach is motivated by the fact\nthat centralized path calculation approaches are often not scalable, whereas\nthe distributed approaches with locally acting nodes are not fully aware of the\nend-to-end performance. We instead hierarchically distribute the path\ncalculation over designated nodes in the network while taking into account the\nend-to-end performance. Specifically, we develop a hierarchical\ncluster-oriented adaptive per-flow path calculation mechanism by leveraging the\nDeep Double Q-network (DDQN) algorithm, where the end-to-end paths are\ncalculated by the source nodes with the assistance of cluster (group) leaders\nat different hierarchical levels. In our approach, a deferred composite reward\nis designed to capture the end-to-end performance through a feedback signal\nfrom the source nodes to the group leaders and captures the local network\nperformance through the local resource assessments by the group leaders. This\napproach scales in large networks, adapts to the dynamic demand, utilizes the\nnetwork resources efficiently and can be applied to segment routing.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:03:07 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 19:15:59 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 20:41:06 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Ali", "Ramy E.", ""], ["Erman", "Bilgehan", ""], ["Ba\u015ftu\u011f", "Ejder", ""], ["Cilli", "Bruce", ""]]}, {"id": "1910.04054", "submitter": "Olivier Delalleau", "authors": "Viswanath Sivakumar, Olivier Delalleau, Tim Rockt\\\"aschel, Alexander\n  H. Miller, Heinrich K\\\"uttler, Nantas Nardelli, Mike Rabbat, Joelle Pineau,\n  Sebastian Riedel", "title": "MVFST-RL: An Asynchronous RL Framework for Congestion Control with\n  Delayed Actions", "comments": "Workshop on ML for Systems at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective network congestion control strategies are key to keeping the\nInternet (or any large computer network) operational. Network congestion\ncontrol has been dominated by hand-crafted heuristics for decades. Recently,\nReinforcementLearning (RL) has emerged as an alternative to automatically\noptimize such control strategies. Research so far has primarily considered RL\ninterfaces which block the sender while an agent considers its next action.\nThis is largely an artifact of building on top of frameworks designed for RL in\ngames (e.g. OpenAI Gym). However, this does not translate to real-world\nnetworking environments, where a network sender waiting on a policy without\nsending data leads to under-utilization of bandwidth. We instead propose to\nformulate congestion control with an asynchronous RL agent that handles delayed\nactions. We present MVFST-RL, a scalable framework for congestion control in\nthe QUIC transport protocol that leverages state-of-the-art in asynchronous RL\ntraining with off-policy correction. We analyze modeling improvements to\nmitigate the deviation from Markovian dynamics, and evaluate our method on\nemulated networks from the Pantheon benchmark platform. The source code is\npublicly available at https://github.com/facebookresearch/mvfst-rl.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:12:30 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 14:49:47 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 17:02:53 GMT"}, {"version": "v4", "created": "Wed, 26 May 2021 21:52:10 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Sivakumar", "Viswanath", ""], ["Delalleau", "Olivier", ""], ["Rockt\u00e4schel", "Tim", ""], ["Miller", "Alexander H.", ""], ["K\u00fcttler", "Heinrich", ""], ["Nardelli", "Nantas", ""], ["Rabbat", "Mike", ""], ["Pineau", "Joelle", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1910.04056", "submitter": "Saida Mahmoud", "authors": "Marco Menardi, Alex Falcon, Saida S.Mohamed, Lorenzo Seidenari,\n  Giuseppe Serra, Alberto Del Bimbo and Carlo Tasso", "title": "Text-to-Image Synthesis Based on Machine Generated Captions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text to Image Synthesis refers to the process of automatic generation of a\nphoto-realistic image starting from a given text and is revolutionizing many\nreal-world applications. In order to perform such process it is necessary to\nexploit datasets containing captioned images, meaning that each image is\nassociated with one (or more) captions describing it. Despite the abundance of\nuncaptioned images datasets, the number of captioned datasets is limited. To\naddress this issue, in this paper we propose an approach capable of generating\nimages starting from a given text using conditional GANs trained on uncaptioned\nimages dataset. In particular, uncaptioned images are fed to an Image\nCaptioning Module to generate the descriptions. Then, the GAN Module is trained\non both the input image and the machine-generated caption. To evaluate the\nresults, the performance of our solution is compared with the results obtained\nby the unconditional GAN. For the experiments, we chose to use the uncaptioned\ndataset LSUN bedroom. The results obtained in our study are preliminary but\nstill promising.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:14:09 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Menardi", "Marco", ""], ["Falcon", "Alex", ""], ["Mohamed", "Saida S.", ""], ["Seidenari", "Lorenzo", ""], ["Serra", "Giuseppe", ""], ["Del Bimbo", "Alberto", ""], ["Tasso", "Carlo", ""]]}, {"id": "1910.04057", "submitter": "Usman Khan", "authors": "Ran Xin and Usman A. Khan and Soummya Kar", "title": "Variance-Reduced Decentralized Stochastic Optimization with Gradient\n  Tracking -- Part II: GT-SVRG", "comments": "arXiv admin note: text overlap with arXiv:1909.11774", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized stochastic optimization has recently benefited from gradient\ntracking methods \\cite{DSGT_Pu,DSGT_Xin} providing efficient solutions for\nlarge-scale empirical risk minimization problems. In Part I \\cite{GT_SAGA} of\nthis work, we develop \\textbf{\\texttt{GT-SAGA}} that is based on a\ndecentralized implementation of SAGA \\cite{SAGA} using gradient tracking and\ndiscuss regimes of practical interest where \\textbf{\\texttt{GT-SAGA}}\noutperforms existing decentralized approaches in terms of the total number of\nlocal gradient computations. In this paper, we describe\n\\textbf{\\texttt{GT-SVRG}} that develops a decentralized gradient tracking based\nimplementation of SVRG \\cite{SVRG}, another well-known variance-reduction\ntechnique. We show that the convergence rate of \\textbf{\\texttt{GT-SVRG}}\nmatches that of \\textbf{\\texttt{GT-SAGA}} for smooth and strongly-convex\nfunctions and highlight different trade-offs between the two algorithms in\nvarious settings.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 02:47:16 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 21:29:36 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Xin", "Ran", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "1910.04059", "submitter": "Kezhi Li", "authors": "Taiyu Zhu, Kezhi Li, Pantelis Georgiou", "title": "A Dual-Hormone Closed-Loop Delivery System for Type 1 Diabetes Using\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dual-hormone delivery strategy by exploiting deep reinforcement\nlearning (RL) for people with Type 1 Diabetes (T1D). Specifically, double\ndilated recurrent neural networks (RNN) are used to learn the hormone delivery\nstrategy, trained by a variant of Q-learning, whose inputs are raw data of\nglucose \\& meal carbohydrate and outputs are dual-hormone (insulin and\nglucagon) delivery. Without prior knowledge of the glucose-insulin metabolism,\nwe run the method on the UVA/Padova simulator. Hundreds days of self-play are\nperformed to obtain a generalized model, then importance sampling is adopted to\ncustomize the model for personal use. \\emph{In-silico} the proposed strategy\nachieves glucose time in target range (TIR) $93\\%$ for adults and $83\\%$ for\nadolescents given standard bolus, outperforming previous approaches\nsignificantly. The results indicate that deep RL is effective in building\npersonalized hormone delivery strategy for people with T1D.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:14:55 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Zhu", "Taiyu", ""], ["Li", "Kezhi", ""], ["Georgiou", "Pantelis", ""]]}, {"id": "1910.04062", "submitter": "Andri Ashfahani", "authors": "Andri Ashfahani, Mahardhika Pratama, Edwin Lughofer and Yew Soon Ong", "title": "DEVDAN: Deep Evolving Denoising Autoencoder", "comments": "This paper has been accepted for publication in Neurocomputing 2019.\n  arXiv admin note: substantial text overlap with arXiv:1809.09081", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Denoising Autoencoder (DAE) enhances the flexibility of the data stream\nmethod in exploiting unlabeled samples. Nonetheless, the feasibility of DAE for\ndata stream analytic deserves an in-depth study because it characterizes a\nfixed network capacity that cannot adapt to rapidly changing environments. Deep\nevolving denoising autoencoder (DEVDAN), is proposed in this paper. It features\nan open structure in the generative phase and the discriminative phase where\nthe hidden units can be automatically added and discarded on the fly. The\ngenerative phase refines the predictive performance of the discriminative model\nexploiting unlabeled data. Furthermore, DEVDAN is free of the problem-specific\nthreshold and works fully in the single-pass learning fashion. We show that\nDEVDAN can find competitive network architecture compared with state-of-the-art\nmethods on the classification task using ten prominent datasets simulated under\nthe prequential test-then-train protocol.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:02:19 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 12:22:54 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ashfahani", "Andri", ""], ["Pratama", "Mahardhika", ""], ["Lughofer", "Edwin", ""], ["Ong", "Yew Soon", ""]]}, {"id": "1910.04067", "submitter": "Weiwei Li", "authors": "Weiwei Li, Jan Hannig, Corbin Jones", "title": "A Note on Optimal Sampling Strategy for Structural Variant Detection\n  Using Optical Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural variants compose the majority of human genetic variation, but are\ndifficult to assess using current genomic sequencing technologies. Optical\nmapping technologies, which measure the size of chromosomal fragments between\nlabeled markers, offer an alternative approach. As these technologies mature\ntowards becoming clinical tools, there is a need to develop an approach for\ndetermining the optimal strategy for sampling biological material in order to\ndetect a variant at some threshold. Here we develop an optimization approach\nusing a simple, yet realistic, model of the genomic mapping process using a\nhyper-geometric distribution and {probabilistic} concentration inequalities.\nOur approach is both computationally and analytically tractable and includes a\nnovel approach to getting tail bounds of hyper-geometric distribution. We show\nthat if a genomic mapping technology can sample most of the chromosomal\nfragments within a sample, comparatively little biological material is needed\nto detect a variant at high confidence.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 19:18:13 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Li", "Weiwei", ""], ["Hannig", "Jan", ""], ["Jones", "Corbin", ""]]}, {"id": "1910.04069", "submitter": "Emilia Oikarinen", "authors": "Henri Tiittanen, Emilia Oikarinen, Andreas Henelius, Kai Puolam\\\"aki", "title": "Estimating regression errors without ground truth values", "comments": "33 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression analysis is a standard supervised machine learning method used to\nmodel an outcome variable in terms of a set of predictor variables. In most\nreal-world applications we do not know the true value of the outcome variable\nbeing predicted outside the training data, i.e., the ground truth is unknown.\nIt is hence not straightforward to directly observe when the estimate from a\nmodel potentially is wrong, due to phenomena such as overfitting and concept\ndrift. In this paper we present an efficient framework for estimating the\ngeneralization error of regression functions, applicable to any family of\nregression functions when the ground truth is unknown. We present a theoretical\nderivation of the framework and empirically evaluate its strengths and\nlimitations. We find that it performs robustly and is useful for detecting\nconcept drift in datasets in several real-world domains.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:29:37 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Tiittanen", "Henri", ""], ["Oikarinen", "Emilia", ""], ["Henelius", "Andreas", ""], ["Puolam\u00e4ki", "Kai", ""]]}, {"id": "1910.04076", "submitter": "Senthil Yogamani", "authors": "Varun Ravi Kumar, Sandesh Athni Hiremath, Stefan Milz, Christian Witt,\n  Clement Pinnard, Senthil Yogamani and Patrick Mader", "title": "FisheyeDistanceNet: Self-Supervised Scale-Aware Distance Estimation\n  using Monocular Fisheye Camera for Autonomous Driving", "comments": "Minor fixes added after ICRA 2020 camera ready submission. ICRA 2020\n  presentation video - https://www.youtube.com/watch?v=qAsdpHP5e8c&t", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fisheye cameras are commonly used in applications like autonomous driving and\nsurveillance to provide a large field of view ($>180^{\\circ}$). However, they\ncome at the cost of strong non-linear distortions which require more complex\nalgorithms. In this paper, we explore Euclidean distance estimation on fisheye\ncameras for automotive scenes. Obtaining accurate and dense depth supervision\nis difficult in practice, but self-supervised learning approaches show\npromising results and could potentially overcome the problem. We present a\nnovel self-supervised scale-aware framework for learning Euclidean distance and\nego-motion from raw monocular fisheye videos without applying rectification.\nWhile it is possible to perform piece-wise linear approximation of fisheye\nprojection surface and apply standard rectilinear models, it has its own set of\nissues like re-sampling distortion and discontinuities in transition regions.\nTo encourage further research in this area, we will release our dataset as part\nof the WoodScape project \\cite{yogamani2019woodscape}. We further evaluated the\nproposed algorithm on the KITTI dataset and obtained state-of-the-art results\ncomparable to other self-supervised monocular methods. Qualitative results on\nan unseen fisheye video demonstrate impressive performance\nhttps://youtu.be/Sgq1WzoOmXg.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 14:51:38 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 12:06:13 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 18:11:34 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 19:29:03 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Kumar", "Varun Ravi", ""], ["Hiremath", "Sandesh Athni", ""], ["Milz", "Stefan", ""], ["Witt", "Christian", ""], ["Pinnard", "Clement", ""], ["Yogamani", "Senthil", ""], ["Mader", "Patrick", ""]]}, {"id": "1910.04077", "submitter": "M. Sadegh Talebi", "authors": "Mahsa Asadi, Mohammad Sadegh Talebi, Hippolyte Bourel and\n  Odalric-Ambrym Maillard", "title": "Model-Based Reinforcement Learning Exploiting State-Action Equivalence", "comments": "ACML 2019. Recipient of the Best Student Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging an equivalence property in the state-space of a Markov Decision\nProcess (MDP) has been investigated in several studies. This paper studies\nequivalence structure in the reinforcement learning (RL) setup, where\ntransition distributions are no longer assumed to be known. We present a notion\nof similarity between transition probabilities of various state-action pairs of\nan MDP, which naturally defines an equivalence structure in the state-action\nspace. We present equivalence-aware confidence sets for the case where the\nlearner knows the underlying structure in advance. These sets are provably\nsmaller than their corresponding equivalence-oblivious counterparts. In the\nmore challenging case of an unknown equivalence structure, we present an\nalgorithm called ApproxEquivalence that seeks to find an (approximate)\nequivalence structure, and define confidence sets using the approximate\nequivalence. To illustrate the efficacy of the presented confidence sets, we\npresent C-UCRL, as a natural modification of UCRL2 for RL in undiscounted MDPs.\nIn the case of a known equivalence structure, we show that C-UCRL improves over\nUCRL2 in terms of regret by a factor of $\\sqrt{SA/C}$, in any communicating MDP\nwith $S$ states, $A$ actions, and $C$ classes, which corresponds to a massive\nimprovement when $C \\ll SA$. To the best of our knowledge, this is the first\nwork providing regret bounds for RL when an equivalence structure in the MDP is\nefficiently exploited. In the case of an unknown equivalence structure, we show\nthrough numerical experiments that C-UCRL combined with ApproxEquivalence\noutperforms UCRL2 in ergodic MDPs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:50:05 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Asadi", "Mahsa", ""], ["Talebi", "Mohammad Sadegh", ""], ["Bourel", "Hippolyte", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "1910.04081", "submitter": "Zhengchun Liu", "authors": "Zhengchun Liu, Tekin Bicer, Rajkumar Kettimuthu, Ian Foster", "title": "Deep Learning Accelerated Light Source Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental protocols at synchrotron light sources typically process and\nvalidate data only after an experiment has completed, which can lead to\nundetected errors and cannot enable online steering. Real-time data analysis\ncan enable both detection of, and recovery from, errors, and optimization of\ndata acquisition. However, modern scientific instruments, such as detectors at\nsynchrotron light sources, can generate data at GBs/sec rates. Data processing\nmethods such as the widely used computational tomography usually require\nconsiderable computational resources, and yield poor quality reconstructions in\nthe early stages of data acquisition when available views are sparse. We\ndescribe here how a deep convolutional neural network can be integrated into\nthe real-time streaming tomography pipeline to enable better-quality images in\nthe early stages of data acquisition. Compared with conventional streaming\ntomography processing, our method can significantly improve tomography image\nquality, deliver comparable images using only 32% of the data needed for\nconventional streaming processing, and save 68% experiment time for data\nacquisition.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:55:54 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Liu", "Zhengchun", ""], ["Bicer", "Tekin", ""], ["Kettimuthu", "Rajkumar", ""], ["Foster", "Ian", ""]]}, {"id": "1910.04085", "submitter": "Guillaume Staerman", "authors": "Guillaume Staerman, Pavlo Mozharovskyi and Stephan Cl\\'emen\\c{c}on", "title": "The Area of the Convex Hull of Sampled Curves: a Robust Functional\n  Statistical Depth Measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the ubiquity of sensors in the IoT era, statistical observations are\nbecoming increasingly available in the form of massive (multivariate)\ntime-series. Formulated as unsupervised anomaly detection tasks, an abundance\nof applications like aviation safety management, the health monitoring of\ncomplex infrastructures or fraud detection can now rely on such functional\ndata, acquired and stored with an ever finer granularity. The concept of\nstatistical depth, which reflects centrality of an arbitrary observation w.r.t.\na statistical population may play a crucial role in this regard, anomalies\ncorresponding to observations with 'small' depth. Supported by sound\ntheoretical and computational developments in the recent decades, it has proven\nto be extremely useful, in particular in functional spaces. However, most\napproaches documented in the literature consist in evaluating independently the\ncentrality of each point forming the time series and consequently exhibit a\ncertain insensitivity to possible shape changes. In this paper, we propose a\nnovel notion of functional depth based on the area of the convex hull of\nsampled curves, capturing gradual departures from centrality, even beyond the\nenvelope of the data, in a natural fashion. We discuss practical relevance of\ncommonly imposed axioms on functional depths and investigate which of them are\nsatisfied by the notion of depth we promote here. Estimation and computational\nissues are also addressed and various numerical experiments provide empirical\nevidence of the relevance of the approach proposed.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:06:13 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 07:14:32 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Staerman", "Guillaume", ""], ["Mozharovskyi", "Pavlo", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""]]}, {"id": "1910.04086", "submitter": "David Ginsbourger", "authors": "Poompol Buathong, David Ginsbourger, Tipaluck Krityakierne", "title": "Kernels over Sets of Finite Sets using RKHS Embeddings, with Application\n  to Bayesian (Combinatorial) Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on kernel methods for set-valued inputs and their application to\nBayesian set optimization, notably combinatorial optimization. We investigate\ntwo classes of set kernels that both rely on Reproducing Kernel Hilbert Space\nembeddings, namely the ``Double Sum'' (DS) kernels recently considered in\nBayesian set optimization, and a class introduced here called ``Deep\nEmbedding'' (DE) kernels that essentially consists in applying a radial kernel\non Hilbert space on top of the canonical distance induced by another kernel\nsuch as a DS kernel. We establish in particular that while DS kernels typically\nsuffer from a lack of strict positive definiteness, vast subclasses of DE\nkernels built upon DS kernels do possess this property, enabling in turn\ncombinatorial optimization without requiring to introduce a jitter parameter.\nProofs of theoretical results about considered kernels are complemented by a\nfew practicalities regarding hyperparameter fitting. We furthermore demonstrate\nthe applicability of our approach in prediction and optimization tasks, relying\nboth on toy examples and on two test cases from mechanical engineering and\nhydrogeology, respectively. Experimental results highlight the applicability\nand compared merits of the considered approaches while opening new perspectives\nin prediction and sequential design with set inputs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:06:38 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 14:55:58 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Buathong", "Poompol", ""], ["Ginsbourger", "David", ""], ["Krityakierne", "Tipaluck", ""]]}, {"id": "1910.04091", "submitter": "Kilian Fatras", "authors": "Kilian Fatras, Younes Zine, R\\'emi Flamary, R\\'emi Gribonval, Nicolas\n  Courty", "title": "Learning with minibatch Wasserstein : asymptotic and gradient properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport distances are powerful tools to compare probability\ndistributions and have found many applications in machine learning. Yet their\nalgorithmic complexity prevents their direct use on large scale datasets. To\novercome this challenge, practitioners compute these distances on minibatches\n{\\em i.e.} they average the outcome of several smaller optimal transport\nproblems. We propose in this paper an analysis of this practice, which effects\nare not well understood so far. We notably argue that it is equivalent to an\nimplicit regularization of the original problem, with appealing properties such\nas unbiased estimators, gradients and a concentration bound around the\nexpectation, but also with defects such as loss of distance property. Along\nwith this theoretical analysis, we also conduct empirical experiments on\ngradient flows, GANs or color transfer that highlight the practical interest of\nthis strategy.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:08:43 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 08:26:40 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 09:34:48 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Fatras", "Kilian", ""], ["Zine", "Younes", ""], ["Flamary", "R\u00e9mi", ""], ["Gribonval", "R\u00e9mi", ""], ["Courty", "Nicolas", ""]]}, {"id": "1910.04093", "submitter": "Johannes Lehner", "authors": "Johannes Lehner, Andreas Mitterecker, Thomas Adler, Markus Hofmarcher,\n  Bernhard Nessler, Sepp Hochreiter", "title": "Patch Refinement -- Localized 3D Object Detection", "comments": "Machine Learning for Autonomous Driving Workshop at the 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Patch Refinement a two-stage model for accurate 3D object\ndetection and localization from point cloud data. Patch Refinement is composed\nof two independently trained Voxelnet-based networks, a Region Proposal Network\n(RPN) and a Local Refinement Network (LRN). We decompose the detection task\ninto a preliminary Bird's Eye View (BEV) detection step and a local 3D\ndetection step. Based on the proposed BEV locations by the RPN, we extract\nsmall point cloud subsets (\"patches\"), which are then processed by the LRN,\nwhich is less limited by memory constraints due to the small area of each\npatch. Therefore, we can apply encoding with a higher voxel resolution locally.\nThe independence of the LRN enables the use of additional augmentation\ntechniques and allows for an efficient, regression focused training as it uses\nonly a small fraction of each scene. Evaluated on the KITTI 3D object detection\nbenchmark, our submission from January 28, 2019, outperformed all previous\nentries on all three difficulties of the class car, using only 50 % of the\navailable training data and only LiDAR information.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:11:17 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Lehner", "Johannes", ""], ["Mitterecker", "Andreas", ""], ["Adler", "Thomas", ""], ["Hofmarcher", "Markus", ""], ["Nessler", "Bernhard", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "1910.04098", "submitter": "Louis Kirsch", "authors": "Louis Kirsch, Sjoerd van Steenkiste, J\\\"urgen Schmidhuber", "title": "Improving Generalization in Meta Reinforcement Learning using Learned\n  Objectives", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biological evolution has distilled the experiences of many learners into the\ngeneral learning algorithms of humans. Our novel meta reinforcement learning\nalgorithm MetaGenRL is inspired by this process. MetaGenRL distills the\nexperiences of many complex agents to meta-learn a low-complexity neural\nobjective function that decides how future individuals will learn. Unlike\nrecent meta-RL algorithms, MetaGenRL can generalize to new environments that\nare entirely different from those used for meta-training. In some cases, it\neven outperforms human-engineered RL algorithms. MetaGenRL uses off-policy\nsecond-order gradients during meta-training that greatly increase its sample\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:20:48 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 16:56:33 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Kirsch", "Louis", ""], ["van Steenkiste", "Sjoerd", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1910.04099", "submitter": "Chuhang Zou", "authors": "Chuhang Zou, Jheng-Wei Su, Chi-Han Peng, Alex Colburn, Qi Shan, Peter\n  Wonka, Hung-Kuo Chu, Derek Hoiem", "title": "Manhattan Room Layout Reconstruction from a Single 360 image: A\n  Comparative Study of State-of-the-art Methods", "comments": "Accepted by International Journal of Computer Vision (IJCV), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches for predicting layouts from 360 panoramas produce excellent\nresults. These approaches build on a common framework consisting of three\nsteps: a pre-processing step based on edge-based alignment, prediction of\nlayout elements, and a post-processing step by fitting a 3D layout to the\nlayout elements. Until now, it has been difficult to compare the methods due to\nmultiple different design decisions, such as the encoding network (e.g. SegNet\nor ResNet), type of elements predicted (e.g. corners, wall/floor boundaries, or\nsemantic segmentation), or method of fitting the 3D layout. To address this\nchallenge, we summarize and describe the common framework, the variants, and\nthe impact of the design decisions. For a complete evaluation, we also propose\nextended annotations for the Matterport3D dataset [3], and introduce two\ndepth-based evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:22:04 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 04:59:25 GMT"}, {"version": "v3", "created": "Fri, 25 Dec 2020 05:15:51 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Zou", "Chuhang", ""], ["Su", "Jheng-Wei", ""], ["Peng", "Chi-Han", ""], ["Colburn", "Alex", ""], ["Shan", "Qi", ""], ["Wonka", "Peter", ""], ["Chu", "Hung-Kuo", ""], ["Hoiem", "Derek", ""]]}, {"id": "1910.04102", "submitter": "Jonathan Huggins", "authors": "Jonathan H. Huggins, Miko{\\l}aj Kasprzak, Trevor Campbell, Tamara\n  Broderick", "title": "Validated Variational Inference via Practical Posterior Error Bounds", "comments": "A python package for carrying out our validated variational inference\n  workflow -- including doing black-box variational inference and computing the\n  bounds we develop in this paper -- is available at\n  https://github.com/jhuggins/viabel. The same repository also contains code\n  for reproducing all of our experiments", "journal-ref": "Proceedings of the 23rd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2020, Palermo, Italy. PMLR: Volume 108", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational inference has become an increasingly attractive fast alternative\nto Markov chain Monte Carlo methods for approximate Bayesian inference.\nHowever, a major obstacle to the widespread use of variational methods is the\nlack of post-hoc accuracy measures that are both theoretically justified and\ncomputationally efficient. In this paper, we provide rigorous bounds on the\nerror of posterior mean and uncertainty estimates that arise from\nfull-distribution approximations, as in variational inference. Our bounds are\nwidely applicable, as they require only that the approximating and exact\nposteriors have polynomial moments. Our bounds are also computationally\nefficient for variational inference because they require only standard values\nfrom variational objectives, straightforward analytic calculations, and simple\nMonte Carlo estimates. We show that our analysis naturally leads to a new and\nimproved workflow for validated variational inference. Finally, we demonstrate\nthe utility of our proposed workflow and error bounds on a robust regression\nproblem and on a real-data example with a widely used multilevel hierarchical\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:29:21 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 14:44:19 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 16:04:06 GMT"}, {"version": "v4", "created": "Sat, 29 Feb 2020 04:06:03 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Huggins", "Jonathan H.", ""], ["Kasprzak", "Miko\u0142aj", ""], ["Campbell", "Trevor", ""], ["Broderick", "Tamara", ""]]}, {"id": "1910.04109", "submitter": "Razieh Nabi", "authors": "Razieh Nabi, Daniel Malinsky, Ilya Shpitser", "title": "Optimal Training of Fair Predictive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been sustained interest in modifying prediction algorithms\nto satisfy fairness constraints. These constraints are typically complex\nnonlinear functionals of the observed data distribution. Focusing on the causal\nconstraints proposed by Nabi and Shpitser (2018), we introduce new theoretical\nresults and optimization techniques to make model training easier and more\naccurate. Specifically, we show how to reparameterize the observed data\nlikelihood such that fairness constraints correspond directly to parameters\nthat appear in the likelihood, transforming a complex constrained optimization\nobjective into a simple optimization problem with box constraints. We also\nexploit methods from empirical likelihood theory in statistics to improve\npredictive performance, without requiring parametric models for\nhigh-dimensional feature vectors.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:44:03 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:28:41 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Nabi", "Razieh", ""], ["Malinsky", "Daniel", ""], ["Shpitser", "Ilya", ""]]}, {"id": "1910.04112", "submitter": "Honglin Li", "authors": "HongLin Li, Payam Barnaghi, Shirin Enshaeifar, Frieder Ganz", "title": "Continual Learning Using Bayesian Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continual learning models allow to learn and adapt to new changes and tasks\nover time. However, in continual and sequential learning scenarios in which the\nmodels are trained using different data with various distributions, neural\nnetworks tend to forget the previously learned knowledge. This phenomenon is\noften referred to as catastrophic forgetting. The catastrophic forgetting is an\ninevitable problem in continual learning models for dynamic environments. To\naddress this issue, we propose a method, called Continual Bayesian Learning\nNetworks (CBLN), which enables the networks to allocate additional resources to\nadapt to new tasks without forgetting the previously learned tasks. Using a\nBayesian Neural Network, CBLN maintains a mixture of Gaussian posterior\ndistributions that are associated with different tasks. The proposed method\ntries to optimise the number of resources that are needed to learn each task\nand avoids an exponential increase in the number of resources that are involved\nin learning multiple tasks. The proposed method does not need to access the\npast training data and can choose suitable weights to classify the data points\nduring the test time automatically based on an uncertainty criterion. We have\nevaluated our method on the MNIST and UCR time-series datasets. The evaluation\nresults show that our method can address the catastrophic forgetting problem at\na promising rate compared to the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:50:20 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 10:37:37 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Li", "HongLin", ""], ["Barnaghi", "Payam", ""], ["Enshaeifar", "Shirin", ""], ["Ganz", "Frieder", ""]]}, {"id": "1910.04115", "submitter": "Gregory Canal", "authors": "Gregory Canal, Stefano Fenu, Christopher Rozell", "title": "Active Ordinal Querying for Tuplewise Similarity Learning", "comments": "Canal and Fenu contributed equally; correction in metadata title -\n  metadata title now matches manuscript title; updated to camera-ready version\n  to appear in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning tasks such as clustering, classification, and dataset\nsearch benefit from embedding data points in a space where distances reflect\nnotions of relative similarity as perceived by humans. A common way to\nconstruct such an embedding is to request triplet similarity queries to an\noracle, comparing two objects with respect to a reference. This work\ngeneralizes triplet queries to tuple queries of arbitrary size that ask an\noracle to rank multiple objects against a reference, and introduces an\nefficient and robust adaptive selection method called InfoTuple that uses a\nnovel approach to mutual information maximization. We show that the performance\nof InfoTuple at various tuple sizes exceeds that of the state-of-the-art\nadaptive triplet selection method on synthetic tests and new human response\ndatasets, and empirically demonstrate the significant gains in efficiency and\nquery consistency achieved by querying larger tuples instead of triplets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:55:30 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 00:49:36 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 00:47:12 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Canal", "Gregory", ""], ["Fenu", "Stefano", ""], ["Rozell", "Christopher", ""]]}, {"id": "1910.04142", "submitter": "Arunkumar Byravan", "authors": "Arunkumar Byravan, Jost Tobias Springenberg, Abbas Abdolmaleki, Roland\n  Hafner, Michael Neunert, Thomas Lampe, Noah Siegel, Nicolas Heess, Martin\n  Riedmiller", "title": "Imagined Value Gradients: Model-Based Policy Optimization with\n  Transferable Latent Dynamics Models", "comments": "To appear at the 3rd annual Conference on Robot Learning, Osaka,\n  Japan (CoRL 2019). 24 pages including appendix (main paper - 8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are masters at quickly learning many complex tasks, relying on an\napproximate understanding of the dynamics of their environments. In much the\nsame way, we would like our learning agents to quickly adapt to new tasks. In\nthis paper, we explore how model-based Reinforcement Learning (RL) can\nfacilitate transfer to new tasks. We develop an algorithm that learns an\naction-conditional, predictive model of expected future observations, rewards\nand values from which a policy can be derived by following the gradient of the\nestimated value along imagined trajectories. We show how robust policy\noptimization can be achieved in robot manipulation tasks even with approximate\nmodels that are learned directly from vision and proprioception. We evaluate\nthe efficacy of our approach in a transfer learning scenario, re-using\npreviously learned models on tasks with different reward structures and visual\ndistractors, and show a significant improvement in learning speed compared to\nstrong off-policy baselines. Videos with results can be found at\nhttps://sites.google.com/view/ivg-corl19\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 17:37:52 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Byravan", "Arunkumar", ""], ["Springenberg", "Jost Tobias", ""], ["Abdolmaleki", "Abbas", ""], ["Hafner", "Roland", ""], ["Neunert", "Michael", ""], ["Lampe", "Thomas", ""], ["Siegel", "Noah", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1910.04153", "submitter": "Micha Livne", "authors": "Micha Livne, Kevin Swersky, David J. Fleet", "title": "High Mutual Information in Representation Learning with Symmetric\n  Variational Inference", "comments": "Bayesian Deep Learning Workshop (NeurIPS 2019). arXiv admin note:\n  substantial text overlap with arXiv:1910.03175", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Mutual Information Machine (MIM), a novel formulation of\nrepresentation learning, using a joint distribution over the observations and\nlatent state in an encoder/decoder framework. Our key principles are symmetry\nand mutual information, where symmetry encourages the encoder and decoder to\nlearn different factorizations of the same underlying distribution, and mutual\ninformation, to encourage the learning of useful representations for downstream\ntasks. Our starting point is the symmetric Jensen-Shannon divergence between\nthe encoding and decoding joint distributions, plus a mutual information\nencouraging regularizer. We show that this can be bounded by a tractable cross\nentropy loss function between the true model and a parameterized approximation,\nand relate this to the maximum likelihood framework. We also relate MIM to\nvariational autoencoders (VAEs) and demonstrate that MIM is capable of learning\nsymmetric factorizations, with high mutual information that avoids posterior\ncollapse.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 01:37:50 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Livne", "Micha", ""], ["Swersky", "Kevin", ""], ["Fleet", "David J.", ""]]}, {"id": "1910.04176", "submitter": "Varun Kumar", "authors": "Varun Kumar, Hadrien Glaude, Cyprien de Lichy, William Campbell", "title": "A Closer Look At Feature Space Data Augmentation For Few-Shot Intent\n  Classification", "comments": "Accepted at Deep Learning for low-resource NLP workshop @ EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  New conversation topics and functionalities are constantly being added to\nconversational AI agents like Amazon Alexa and Apple Siri. As data collection\nand annotation is not scalable and is often costly, only a handful of examples\nfor the new functionalities are available, which results in poor generalization\nperformance. We formulate it as a Few-Shot Integration (FSI) problem where a\nfew examples are used to introduce a new intent. In this paper, we study six\nfeature space data augmentation methods to improve classification performance\nin FSI setting in combination with both supervised and unsupervised\nrepresentation learning methods such as BERT. Through realistic experiments on\ntwo public conversational datasets, SNIPS, and the Facebook Dialog corpus, we\nshow that data augmentation in feature space provides an effective way to\nimprove intent classification performance in few-shot setting beyond\ntraditional transfer learning approaches. In particular, we show that (a)\nupsampling in latent space is a competitive baseline for feature space\naugmentation (b) adding the difference between two examples to a new example is\na simple yet effective data augmentation method.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 18:00:04 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Kumar", "Varun", ""], ["Glaude", "Hadrien", ""], ["de Lichy", "Cyprien", ""], ["Campbell", "William", ""]]}, {"id": "1910.04183", "submitter": "Yining Wang", "authors": "Xi Chen, Akshay Krishnamurthy, Yining Wang", "title": "Robust Dynamic Assortment Optimization in the Presence of Outlier\n  Customers", "comments": "27 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the dynamic assortment optimization problem under the multinomial\nlogit model (MNL) with unknown utility parameters. The main question\ninvestigated in this paper is model mis-specification under the\n$\\varepsilon$-contamination model, which is a fundamental model in robust\nstatistics and machine learning. In particular, throughout a selling horizon of\nlength $T$, we assume that customers make purchases according to a well\nspecified underlying multinomial logit choice model in a\n($1-\\varepsilon$)-fraction of the time periods, and make arbitrary purchasing\ndecisions instead in the remaining $\\varepsilon$-fraction of the time periods.\nIn this model, we develop a new robust online assortment optimization policy\nvia an active elimination strategy. We establish both upper and lower bounds on\nthe regret, and show that our policy is optimal up to logarithmic factor in T\nwhen the assortment capacity is constant. Furthermore, we develop a fully\nadaptive policy that does not require any prior knowledge of the contamination\nparameter $\\varepsilon$. Our simulation study shows that our policy outperforms\nthe existing policies based on upper confidence bounds (UCB) and Thompson\nsampling.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 18:02:15 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Chen", "Xi", ""], ["Krishnamurthy", "Akshay", ""], ["Wang", "Yining", ""]]}, {"id": "1910.04192", "submitter": "Clara McCreery", "authors": "Clara McCreery, Namit Katariya, Anitha Kannan, Manish Chablani, Xavier\n  Amatriain", "title": "Domain-Relevant Embeddings for Medical Question Similarity", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rate at which medical questions are asked online far exceeds the capacity\nof qualified people to answer them, and many of these questions are not unique.\nIdentifying same-question pairs could enable questions to be answered more\neffectively. While many research efforts have focused on the problem of general\nquestion similarity for non-medical applications, these approaches do not\ngeneralize well to the medical domain, where medical expertise is often\nrequired to determine semantic similarity. In this paper, we show how a\nsemi-supervised approach of pre-training a neural network on medical\nquestion-answer pairs is a particularly useful intermediate task for the\nultimate goal of determining medical question similarity. While other\npre-training tasks yield an accuracy below 78.7% on this task, our model\nachieves an accuracy of 82.6% with the same number of training examples, and an\naccuracy of 80.0% with a much smaller training set.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 18:19:48 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 01:06:47 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["McCreery", "Clara", ""], ["Katariya", "Namit", ""], ["Kannan", "Anitha", ""], ["Chablani", "Manish", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1910.04194", "submitter": "Melanie Weber", "authors": "Melanie Weber and Suvrit Sra", "title": "Projection-free nonconvex stochastic optimization on Riemannian\n  manifolds", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic projection-free methods for constrained optimization of\nsmooth functions on Riemannian manifolds, i.e., with additional constraints\nbeyond the parameter domain being a manifold. Specifically, we introduce\nstochastic Riemannian Frank-Wolfe methods for nonconvex and geodesically convex\nproblems. We present algorithms for both purely stochastic optimization and\nfinite-sum problems. For the latter, we develop variance-reduced methods,\nincluding a Riemannian adaptation of the recently proposed Spider technique.\nFor all settings, we recover convergence rates that are comparable to the\nbest-known rates for their Euclidean counterparts. Finally, we discuss\napplications to two classic tasks: The computation of the Karcher mean of\npositive definite matrices and Wasserstein barycenters for multivariate normal\ndistributions. For both tasks, stochastic Fw methods yield state-of-the-art\nempirical performance.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 18:27:25 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 15:18:46 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 16:38:56 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Weber", "Melanie", ""], ["Sra", "Suvrit", ""]]}, {"id": "1910.04195", "submitter": "Ahmed Alamer", "authors": "Ahmed Alamer, Ben Soh", "title": "A new neural-network-based model for measuring the strength of a\n  pseudorandom binary sequence", "comments": "15 pages to be submitted to Logical \"Methods in Computer Science\"\n  Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum order complexity is an important tool for measuring the nonlinearity\nof a pseudorandom sequence. There is a lack of tools for predicting the\nstrength of a pseudorandom binary sequence in an effective and efficient\nmanner. To this end, this paper proposes a neural-network-based model for\nmeasuring the strength of a pseudorandom binary sequence. Using the Shrinking\nGenerator (SG) keystream as pseudorandom binary sequences, then calculating the\nUnique Window Size (UWS) as a representation of Maximum order complexity, we\ndemonstrate that the proposed model provides more accurate and efficient\npredictions (measurements) than a classical method for predicting the maximum\norder complexity.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 18:28:05 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Alamer", "Ahmed", ""], ["Soh", "Ben", ""]]}, {"id": "1910.04209", "submitter": "Jerry Ma", "authors": "Jerry Ma, Denis Yarats", "title": "On the adequacy of untuned warmup for adaptive optimization", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adaptive optimization algorithms such as Adam are widely used in deep\nlearning. The stability of such algorithms is often improved with a warmup\nschedule for the learning rate. Motivated by the difficulty of choosing and\ntuning warmup schedules, recent work proposes automatic variance rectification\nof Adam's adaptive learning rate, claiming that this rectified approach\n(\"RAdam\") surpasses the vanilla Adam algorithm and reduces the need for\nexpensive tuning of Adam with warmup. In this work, we refute this analysis and\nprovide an alternative explanation for the necessity of warmup based on the\nmagnitude of the update term, which is of greater relevance to training\nstability. We then provide some \"rule-of-thumb\" warmup schedules, and we\ndemonstrate that simple untuned warmup of Adam performs more-or-less\nidentically to RAdam in typical practical settings. We conclude by suggesting\nthat practitioners stick to linear warmup with Adam, with a sensible default\nbeing linear warmup over $2 / (1 - \\beta_2)$ training iterations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 19:25:03 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 01:58:24 GMT"}, {"version": "v3", "created": "Sat, 20 Mar 2021 03:43:16 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Ma", "Jerry", ""], ["Yarats", "Denis", ""]]}, {"id": "1910.04214", "submitter": "Gal Yona", "authors": "Gal Yona and Amirata Ghorbani and James Zou", "title": "Who's responsible? Jointly quantifying the contribution of the learning\n  algorithm and training data", "comments": "To appear in AAAI/ACM Conference on AI, Ethics, and Society (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A learning algorithm $A$ trained on a dataset $D$ is revealed to have poor\nperformance on some subpopulation at test time. Where should the responsibility\nfor this lay? It can be argued that the data is responsible, if for example\ntraining $A$ on a more representative dataset $D'$ would have improved the\nperformance. But it can similarly be argued that $A$ itself is at fault, if\ntraining a different variant $A'$ on the same dataset $D$ would have improved\nperformance. As ML becomes widespread and such failure cases more common, these\ntypes of questions are proving to be far from hypothetical. With this\nmotivation in mind, in this work we provide a rigorous formulation of the joint\ncredit assignment problem between a learning algorithm $A$ and a dataset $D$.\nWe propose Extended Shapley as a principled framework for this problem, and\nexperiment empirically with how it can be used to address questions of ML\naccountability.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 19:39:08 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 08:28:05 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Yona", "Gal", ""], ["Ghorbani", "Amirata", ""], ["Zou", "James", ""]]}, {"id": "1910.04223", "submitter": "Renan Souza", "authors": "Renan Souza, Leonardo Azevedo, V\\'itor Louren\\c{c}o, Elton Soares,\n  Raphael Thiago, Rafael Brand\\~ao, Daniel Civitarese, Emilio Vital Brazil,\n  Marcio Moreno, Patrick Valduriez, Marta Mattoso, Renato Cerqueira, Marco A.\n  S. Netto", "title": "Provenance Data in the Machine Learning Lifecycle in Computational\n  Science and Engineering", "comments": "10 pages, 7 figures, Accepted at Workflows in Support of Large-scale\n  Science (WORKS) co-located with the ACM/IEEE International Conference for\n  High Performance Computing, Networking, Storage, and Analysis (SC) 2019,\n  Denver, Colorado", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has become essential in several industries. In\nComputational Science and Engineering (CSE), the complexity of the ML lifecycle\ncomes from the large variety of data, scientists' expertise, tools, and\nworkflows. If data are not tracked properly during the lifecycle, it becomes\nunfeasible to recreate a ML model from scratch or to explain to stakeholders\nhow it was created. The main limitation of provenance tracking solutions is\nthat they cannot cope with provenance capture and integration of domain and ML\ndata processed in the multiple workflows in the lifecycle while keeping the\nprovenance capture overhead low. To handle this problem, in this paper we\ncontribute with a detailed characterization of provenance data in the ML\nlifecycle in CSE; a new provenance data representation, called PROV-ML, built\non top of W3C PROV and ML Schema; and extensions to a system that tracks\nprovenance from multiple workflows to address the characteristics of ML and\nCSE, and to allow for provenance queries with a standard vocabulary. We show a\npractical use in a real case in the Oil and Gas industry, along with its\nevaluation using 48 GPUs in parallel.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 19:52:40 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 15:19:18 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Souza", "Renan", ""], ["Azevedo", "Leonardo", ""], ["Louren\u00e7o", "V\u00edtor", ""], ["Soares", "Elton", ""], ["Thiago", "Raphael", ""], ["Brand\u00e3o", "Rafael", ""], ["Civitarese", "Daniel", ""], ["Brazil", "Emilio Vital", ""], ["Moreno", "Marcio", ""], ["Valduriez", "Patrick", ""], ["Mattoso", "Marta", ""], ["Cerqueira", "Renato", ""], ["Netto", "Marco A. S.", ""]]}, {"id": "1910.04233", "submitter": "Kevin Liang", "authors": "Kevin J Liang, Guoyin Wang, Yitong Li, Ricardo Henao, Lawrence Carin", "title": "Kernel-Based Approaches for Sequence Modeling: Connections to Neural\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate time-dependent data analysis from the perspective of recurrent\nkernel machines, from which models with hidden units and gated memory cells\narise naturally. By considering dynamic gating of the memory cell, a model\nclosely related to the long short-term memory (LSTM) recurrent neural network\nis derived. Extending this setup to $n$-gram filters, the convolutional neural\nnetwork (CNN), Gated CNN, and recurrent additive network (RAN) are also\nrecovered as special cases. Our analysis provides a new perspective on the\nLSTM, while also extending it to $n$-gram convolutional filters. Experiments\nare performed on natural language processing tasks and on analysis of local\nfield potentials (neuroscience). We demonstrate that the variants we derive\nfrom kernels perform on par or even better than traditional neural methods. For\nthe neuroscience application, the new models demonstrate significant\nimprovements relative to the prior state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 20:15:53 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Liang", "Kevin J", ""], ["Wang", "Guoyin", ""], ["Li", "Yitong", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1910.04235", "submitter": "Zhouyuan Huo", "authors": "Zhouyuan Huo, Heng Huang", "title": "Straggler-Agnostic and Communication-Efficient Distributed Primal-Dual\n  Algorithm for High-Dimensional Data Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, reducing communication time between machines becomes the main focus\nof distributed data mining. Previous methods propose to make workers do more\ncomputation locally before aggregating local solutions in the server such that\nfewer communication rounds between server and workers are required. However,\nthese methods do not consider reducing the communication time per round and\nwork very poor under certain conditions, for example, when there are straggler\nproblems or the dataset is of high dimension. In this paper, we target to\nreduce communication time per round as well as the required communication\nrounds. We propose a communication-efficient distributed primal-dual method\nwith straggler-agnostic server and bandwidth-efficient workers. We analyze the\nconvergence property and prove that the proposed method guarantees linear\nconvergence rate to the optimal solution for convex problems. Finally, we\nconduct large-scale experiments in simulated and real distributed systems and\nexperimental results demonstrate that the proposed method is much faster than\ncompared methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 20:23:39 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Huo", "Zhouyuan", ""], ["Huang", "Heng", ""]]}, {"id": "1910.04241", "submitter": "Sachin Vernekar", "authors": "Sachin Vernekar, Ashish Gaurav, Vahdat Abdelzad, Taylor Denouden, Rick\n  Salay, Krzysztof Czarnecki", "title": "Out-of-distribution Detection in Classifiers via Generation", "comments": "NeurIPS 2019, Safety and Robustness in Decision Making Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By design, discriminatively trained neural network classifiers produce\nreliable predictions only for in-distribution samples. For their real-world\ndeployments, detecting out-of-distribution (OOD) samples is essential. Assuming\nOOD to be outside the closed boundary of in-distribution, typical neural\nclassifiers do not contain the knowledge of this boundary for OOD detection\nduring inference. There have been recent approaches to instill this knowledge\nin classifiers by explicitly training the classifier with OOD samples close to\nthe in-distribution boundary. However, these generated samples fail to cover\nthe entire in-distribution boundary effectively, thereby resulting in a\nsub-optimal OOD detector. In this paper, we analyze the feasibility of such\napproaches by investigating the complexity of producing such \"effective\" OOD\nsamples. We also propose a novel algorithm to generate such samples using a\nmanifold learning network (e.g., variational autoencoder) and then train an n+1\nclassifier for OOD detection, where the $n+1^{th}$ class represents the OOD\nsamples. We compare our approach against several recent classifier-based OOD\ndetectors on MNIST and Fashion-MNIST datasets. Overall the proposed approach\nconsistently performs better than the others.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 20:38:56 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Vernekar", "Sachin", ""], ["Gaurav", "Ashish", ""], ["Abdelzad", "Vahdat", ""], ["Denouden", "Taylor", ""], ["Salay", "Rick", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1910.04249", "submitter": "Mahyar Fazlyab", "authors": "Mahyar Fazlyab, Manfred Morari, George J. Pappas", "title": "Probabilistic Verification and Reachability Analysis of Neural Networks\n  via Semidefinite Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the robustness of neural networks or verifying their safety\nproperties against input uncertainties or adversarial attacks have become an\nimportant research area in learning-enabled systems. Most results concentrate\naround the worst-case scenario where the input of the neural network is\nperturbed within a norm-bounded uncertainty set. In this paper, we consider a\nprobabilistic setting in which the uncertainty is random with known first two\nmoments. In this context, we discuss two relevant problems: (i) probabilistic\nsafety verification, in which the goal is to find an upper bound on the\nprobability of violating a safety specification; and (ii) confidence ellipsoid\nestimation, in which given a confidence ellipsoid for the input of the neural\nnetwork, our goal is to compute a confidence ellipsoid for the output. Due to\nthe presence of nonlinear activation functions, these two problems are very\ndifficult to solve exactly. To simplify the analysis, our main idea is to\nabstract the nonlinear activation functions by a combination of affine and\nquadratic constraints they impose on their input-output pairs. We then show\nthat the safety of the abstracted network, which is sufficient for the safety\nof the original network, can be analyzed using semidefinite programming. We\nillustrate the performance of our approach with numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 21:02:10 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Fazlyab", "Mahyar", ""], ["Morari", "Manfred", ""], ["Pappas", "George J.", ""]]}, {"id": "1910.04254", "submitter": "Alexander Preuhs", "authors": "Alexander Preuhs, Michael Manhart, Philipp Roser, Bernhard Stimpel,\n  Christopher Syben, Marios Psychogios, Markus Kowarschik, Andreas Maier", "title": "Image Quality Assessment for Rigid Motion Compensation", "comments": "Accepted at MedNeurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnostic stroke imaging with C-arm cone-beam computed tomography (CBCT)\nenables reduction of time-to-therapy for endovascular procedures. However, the\nprolonged acquisition time compared to helical CT increases the likelihood of\nrigid patient motion. Rigid motion corrupts the geometry alignment assumed\nduring reconstruction, resulting in image blurring or streaking artifacts. To\nreestablish the geometry, we estimate the motion trajectory by an autofocus\nmethod guided by a neural network, which was trained to regress the\nreprojection error, based on the image information of a reconstructed slice.\nThe network was trained with CBCT scans from 19 patients and evaluated using an\nadditional test patient. It adapts well to unseen motion amplitudes and\nachieves superior results in a motion estimation benchmark compared to the\ncommonly used entropy-based method.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 21:03:45 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 16:01:13 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Preuhs", "Alexander", ""], ["Manhart", "Michael", ""], ["Roser", "Philipp", ""], ["Stimpel", "Bernhard", ""], ["Syben", "Christopher", ""], ["Psychogios", "Marios", ""], ["Kowarschik", "Markus", ""], ["Maier", "Andreas", ""]]}, {"id": "1910.04255", "submitter": "Elena Giusarma", "authors": "Elena Giusarma, Mauricio Reyes Hurtado, Francisco Villaescusa-Navarro,\n  Siyu He, Shirley Ho, ChangHoon Hahn", "title": "Learning neutrino effects in Cosmology with Convolutional Neural\n  Networks", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO cs.LG hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the sum of the three active neutrino masses, $M_\\nu$, is one of the\nmost important challenges in modern cosmology. Massive neutrinos imprint\ncharacteristic signatures on several cosmological observables in particular on\nthe large-scale structure of the Universe. In order to maximize the information\nthat can be retrieved from galaxy surveys, accurate theoretical predictions in\nthe non-linear regime are needed. Currently, one way to achieve those\npredictions is by running cosmological numerical simulations. Unfortunately,\nproducing those simulations requires high computational resources -- seven\nhundred CPU hours for each neutrino mass case. In this work, we propose a new\nmethod, based on a deep learning network (U-Net), to quickly generate\nsimulations with massive neutrinos from standard $\\Lambda$CDM simulations\nwithout neutrinos. We computed multiple relevant statistical measures of\ndeep-learning generated simulations, and conclude that our method accurately\nreproduces the 3-dimensional spatial distribution of matter down to non-linear\nscales: $k < 0.7$ h/Mpc. Finally, our method allows us to generate massive\nneutrino simulations 10,000 times faster than the traditional methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 21:04:33 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Giusarma", "Elena", ""], ["Hurtado", "Mauricio Reyes", ""], ["Villaescusa-Navarro", "Francisco", ""], ["He", "Siyu", ""], ["Ho", "Shirley", ""], ["Hahn", "ChangHoon", ""]]}, {"id": "1910.04256", "submitter": "Chirag Agarwal", "authors": "Chirag Agarwal, Anh Nguyen", "title": "Explaining image classifiers by removing input features using generative\n  models", "comments": "Accepted to Asian Conference on Computer Vision (ACCV), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perturbation-based explanation methods often measure the contribution of an\ninput feature to an image classifier's outputs by heuristically removing it via\ne.g. blurring, adding noise, or graying out, which often produce unrealistic,\nout-of-samples. Instead, we propose to integrate a generative inpainter into\nthree representative attribution methods to remove an input feature. Our\nproposed change improved all three methods in (1) generating more plausible\ncounterfactual samples under the true data distribution; (2) being more\naccurate according to three metrics: object localization, deletion, and\nsaliency metrics; and (3) being more robust to hyperparameter changes. Our\nfindings were consistent across both ImageNet and Places365 datasets and two\ndifferent pairs of classifiers and inpainters.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 21:08:25 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 03:36:07 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 17:52:27 GMT"}, {"version": "v4", "created": "Sat, 25 Jul 2020 09:14:35 GMT"}, {"version": "v5", "created": "Thu, 30 Jul 2020 01:27:39 GMT"}, {"version": "v6", "created": "Sun, 4 Oct 2020 19:27:15 GMT"}, {"version": "v7", "created": "Tue, 6 Oct 2020 16:08:42 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Agarwal", "Chirag", ""], ["Nguyen", "Anh", ""]]}, {"id": "1910.04257", "submitter": "Samyadeep Basu", "authors": "Samyadeep Basu, Rauf Izmailov and Chris Mesterharm", "title": "Membership Model Inversion Attacks for Deep Networks", "comments": "NeurIPS 2019, Workshop on Privacy in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing adoption of AI, inherent security and privacy\nvulnerabilities formachine learning systems are being discovered. One such\nvulnerability makes itpossible for an adversary to obtain private information\nabout the types of instancesused to train the targeted machine learning model.\nThis so-called model inversionattack is based on sequential leveraging of\nclassification scores towards obtaininghigh confidence representations for\nvarious classes. However, for deep networks,such procedures usually lead to\nunrecognizable representations that are uselessfor the adversary. In this\npaper, we introduce a more realistic definition of modelinversion, where the\nadversary is aware of the general purpose of the attackedmodel (for instance,\nwhether it is an OCR system or a facial recognition system),and the goal is to\nfind realistic class representations within the corresponding lower-dimensional\nmanifold (of, respectively, general symbols or general faces). To thatend, we\nleverage properties of generative adversarial networks for constructinga\nconnected lower-dimensional manifold, and demonstrate the efficiency of\nourmodel inversion attack that is carried out within that manifold.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 21:18:53 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Basu", "Samyadeep", ""], ["Izmailov", "Rauf", ""], ["Mesterharm", "Chris", ""]]}, {"id": "1910.04267", "submitter": "Changxiao Cai", "authors": "Changxiao Cai, Gen Li, Yuejie Chi, H. Vincent Poor, Yuxin Chen", "title": "Subspace Estimation from Unbalanced and Incomplete Data Matrices:\n  $\\ell_{2,\\infty}$ Statistical Guarantees", "comments": "Accepted to Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with estimating the column space of an unknown\nlow-rank matrix $\\boldsymbol{A}^{\\star}\\in\\mathbb{R}^{d_{1}\\times d_{2}}$,\ngiven noisy and partial observations of its entries. There is no shortage of\nscenarios where the observations -- while being too noisy to support faithful\nrecovery of the entire matrix -- still convey sufficient information to enable\nreliable estimation of the column space of interest. This is particularly\nevident and crucial for the highly unbalanced case where the column dimension\n$d_{2}$ far exceeds the row dimension $d_{1}$, which is the focal point of the\ncurrent paper. We investigate an efficient spectral method, which operates upon\nthe sample Gram matrix with diagonal deletion. While this algorithmic idea has\nbeen studied before, we establish new statistical guarantees for this method in\nterms of both $\\ell_{2}$ and $\\ell_{2,\\infty}$ estimation accuracy, which\nimprove upon prior results if $d_{2}$ is substantially larger than $d_{1}$. To\nillustrate the effectiveness of our findings, we derive matching minimax lower\nbounds with respect to the noise levels, and develop consequences of our\ngeneral theory for three applications of practical importance: (1) tensor\ncompletion from noisy data, (2) covariance estimation / principal component\nanalysis with missing data, and (3) community recovery in bipartite graphs. Our\ntheory leads to improved performance guarantees for all three cases.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 21:39:04 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 22:16:18 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 14:01:08 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 00:25:35 GMT"}, {"version": "v5", "created": "Sun, 15 Nov 2020 21:04:24 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Cai", "Changxiao", ""], ["Li", "Gen", ""], ["Chi", "Yuejie", ""], ["Poor", "H. Vincent", ""], ["Chen", "Yuxin", ""]]}, {"id": "1910.04269", "submitter": "Govind Mittal", "authors": "Sarthak, Shikhar Shukla, Govind Mittal", "title": "Spoken Language Identification using ConvNets", "comments": "2019 European Conference on Ambient Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language Identification (LI) is an important first step in several speech\nprocessing systems. With a growing number of voice-based assistants, speech LI\nhas emerged as a widely researched field. To approach the problem of\nidentifying languages, we can either adopt an implicit approach where only the\nspeech for a language is present or an explicit one where text is available\nwith its corresponding transcript. This paper focuses on an implicit approach\ndue to the absence of transcriptive data. This paper benchmarks existing models\nand proposes a new attention based model for language identification which uses\nlog-Mel spectrogram images as input. We also present the effectiveness of raw\nwaveforms as features to neural network models for LI tasks. For training and\nevaluation of models, we classified six languages (English, French, German,\nSpanish, Russian and Italian) with an accuracy of 95.4% and four languages\n(English, French, German, Spanish) with an accuracy of 96.3% obtained from the\nVoxForge dataset. This approach can further be scaled to incorporate more\nlanguages.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 21:43:36 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Sarthak", "", ""], ["Shukla", "Shikhar", ""], ["Mittal", "Govind", ""]]}, {"id": "1910.04279", "submitter": "Shixian Wen", "authors": "Shixian Wen, Laurent Itti", "title": "Adversarial Training: embedding adversarial perturbations into the\n  parameter space of a neural network to build a robust system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training, in which a network is trained on both adversarial and\nclean examples, is one of the most trusted defense methods against adversarial\nattacks. However, there are three major practical difficulties in implementing\nand deploying this method - expensive in terms of extra memory and computation\ncosts; accuracy trade-off between clean and adversarial examples; and lack of\ndiversity of adversarial perturbations. Classical adversarial training uses\nfixed, precomputed perturbations in adversarial examples (input space). In\ncontrast, we introduce dynamic adversarial perturbations into the parameter\nspace of the network, by adding perturbation biases to the fully connected\nlayers of deep convolutional neural network. During training, using only clean\nimages, the perturbation biases are updated in the Fast Gradient Sign Direction\nto automatically create and store adversarial perturbations by recycling the\ngradient information computed. The network learns and adjusts itself\nautomatically to these learned adversarial perturbations. Thus, we can achieve\nadversarial training with negligible cost compared to requiring a training set\nof adversarial example images. In addition, if combined with classical\nadversarial training, our perturbation biases can alleviate accuracy trade-off\ndifficulties, and diversify adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 22:16:09 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Wen", "Shixian", ""], ["Itti", "Laurent", ""]]}, {"id": "1910.04281", "submitter": "Nicholas Waytowich", "authors": "Vinicius G. Goecks, Gregory M. Gremillion, Vernon J. Lawhern, John\n  Valasek, Nicholas R. Waytowich", "title": "Integrating Behavior Cloning and Reinforcement Learning for Improved\n  Performance in Dense and Sparse Reward Environments", "comments": "9 pages, 5 Figures. AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how to efficiently transition and update policies,\ntrained initially with demonstrations, using off-policy actor-critic\nreinforcement learning. It is well-known that techniques based on Learning from\nDemonstrations, for example behavior cloning, can lead to proficient policies\ngiven limited data. However, it is currently unclear how to efficiently update\nthat policy using reinforcement learning as these approaches are inherently\noptimizing different objective functions. Previous works have used loss\nfunctions, which combine behavior cloning losses with reinforcement learning\nlosses to enable this update. However, the components of these loss functions\nare often set anecdotally, and their individual contributions are not well\nunderstood. In this work, we propose the Cycle-of-Learning (CoL) framework that\nuses an actor-critic architecture with a loss function that combines behavior\ncloning and 1-step Q-learning losses with an off-policy pre-training step from\nhuman demonstrations. This enables transition from behavior cloning to\nreinforcement learning without performance degradation and improves\nreinforcement learning in terms of overall performance and training time.\nAdditionally, we carefully study the composition of these combined losses and\ntheir impact on overall policy learning. We show that our approach outperforms\nstate-of-the-art techniques for combining behavior cloning and reinforcement\nlearning for both dense and sparse reward scenarios. Our results also suggest\nthat directly including the behavior cloning loss on demonstration data helps\nto ensure stable learning and ground future policy updates.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 22:32:23 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 19:08:25 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Goecks", "Vinicius G.", ""], ["Gremillion", "Gregory M.", ""], ["Lawhern", "Vernon J.", ""], ["Valasek", "John", ""], ["Waytowich", "Nicholas R.", ""]]}, {"id": "1910.04284", "submitter": "Colin Wei", "authors": "Colin Wei, Tengyu Ma", "title": "Improved Sample Complexities for Deep Networks and Robust Classification\n  via an All-Layer Margin", "comments": "Code for all-layer margin optimization is available at the following\n  link: https://github.com/cwein3/all-layer-margin-opt. Version 4: Re-organized\n  proofs for more clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For linear classifiers, the relationship between (normalized) output margin\nand generalization is captured in a clear and simple bound -- a large output\nmargin implies good generalization. Unfortunately, for deep models, this\nrelationship is less clear: existing analyses of the output margin give\ncomplicated bounds which sometimes depend exponentially on depth. In this work,\nwe propose to instead analyze a new notion of margin, which we call the\n\"all-layer margin.\" Our analysis reveals that the all-layer margin has a clear\nand direct relationship with generalization for deep models. This enables the\nfollowing concrete applications of the all-layer margin: 1) by analyzing the\nall-layer margin, we obtain tighter generalization bounds for neural nets which\ndepend on Jacobian and hidden layer norms and remove the exponential dependency\non depth 2) our neural net results easily translate to the adversarially robust\nsetting, giving the first direct analysis of robust test error for deep\nnetworks, and 3) we present a theoretically inspired training algorithm for\nincreasing the all-layer margin. Our algorithm improves both clean and\nadversarially robust test performance over strong baselines in practice.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 22:45:45 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 08:52:51 GMT"}, {"version": "v3", "created": "Sat, 25 Apr 2020 06:24:54 GMT"}, {"version": "v4", "created": "Sun, 11 Apr 2021 08:30:15 GMT"}, {"version": "v5", "created": "Wed, 16 Jun 2021 05:12:53 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Wei", "Colin", ""], ["Ma", "Tengyu", ""]]}, {"id": "1910.04287", "submitter": "Saeed Anwar", "authors": "Muhammad Tahir, Saeed Anwar, and Ajmal Mian", "title": "Deep localization of protein structures in fluorescence microscopy\n  images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate localization of proteins from fluorescence microscopy images is a\nchallenging task due to the inter-class similarities and intra-class\ndisparities introducing grave concerns in addressing multi-class classification\nproblems. Conventional machine learning-based image prediction relies heavily\non pre-processing such as normalization and segmentation followed by\nhand-crafted feature extraction before classification to identify useful and\ninformative as well as application specific features.We propose an end-to-end\nProtein Localization Convolutional Neural Network (PLCNN) that classifies\nprotein localization images more accurately and reliably. PLCNN directly\nprocesses raw imagery without involving any pre-processing steps and produces\noutputs without any customization or parameter adjustment for a particular\ndataset. The output of our approach is computed from probabilities produced by\nthe network. Experimental analysis is performed on five publicly available\nbenchmark datasets. PLCNN consistently outperformed the existing\nstate-of-the-art approaches from machine learning and deep architectures.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 22:53:19 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 01:16:04 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Tahir", "Muhammad", ""], ["Anwar", "Saeed", ""], ["Mian", "Ajmal", ""]]}, {"id": "1910.04289", "submitter": "Bill Yuchen Lin", "authors": "Ouyu Lan, Xiao Huang, Bill Yuchen Lin, He Jiang, Liyuan Liu, Xiang Ren", "title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence\n  Labeling", "comments": "Accepted to the ACL 2020, code: https://github.com/INK-USC/ConNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labeling is a fundamental framework for various natural language\nprocessing problems. Its performance is largely influenced by the annotation\nquality and quantity in supervised learning scenarios, and obtaining ground\ntruth labels is often costly. In many cases, ground truth labels do not exist,\nbut noisy annotations or annotations from different domains are accessible. In\nthis paper, we propose a novel framework Consensus Network (ConNet) that can be\ntrained on annotations from multiple sources (e.g., crowd annotation,\ncross-domain data...). It learns individual representation for every source and\ndynamically aggregates source-specific knowledge by a context-aware attention\nmodule. Finally, it leads to a model reflecting the agreement (consensus) among\nmultiple sources. We evaluate the proposed framework in two practical settings\nof multi-source learning: learning with crowd annotations and unsupervised\ncross-domain model adaptation. Extensive experimental results show that our\nmodel achieves significant improvements over existing methods in both settings.\nWe also demonstrate that the method can apply to various tasks and cope with\ndifferent encoders.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 22:54:43 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 07:21:02 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lan", "Ouyu", ""], ["Huang", "Xiao", ""], ["Lin", "Bill Yuchen", ""], ["Jiang", "He", ""], ["Liu", "Liyuan", ""], ["Ren", "Xiang", ""]]}, {"id": "1910.04295", "submitter": "Mathieu Lauri\\`ere", "authors": "Ren\\'e Carmona, Mathieu Lauri\\`ere, Zongjun Tan", "title": "Linear-Quadratic Mean-Field Reinforcement Learning: Convergence of\n  Policy Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate reinforcement learning for mean field control problems in\ndiscrete time, which can be viewed as Markov decision processes for a large\nnumber of exchangeable agents interacting in a mean field manner. Such problems\narise, for instance when a large number of robots communicate through a central\nunit dispatching the optimal policy computed by minimizing the overall social\ncost. An approximate solution is obtained by learning the optimal policy of a\ngeneric agent interacting with the statistical distribution of the states of\nthe other agents. We prove rigorously the convergence of exact and model-free\npolicy gradient methods in a mean-field linear-quadratic setting. We also\nprovide graphical evidence of the convergence based on implementations of our\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 23:19:39 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Carmona", "Ren\u00e9", ""], ["Lauri\u00e8re", "Mathieu", ""], ["Tan", "Zongjun", ""]]}, {"id": "1910.04297", "submitter": "Joshua Smith", "authors": "Joshua Smith, Michael Mistry", "title": "Online Simultaneous Semi-Parametric Dynamics Model Learning", "comments": "\\c{opyright} 2020 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate models of robots' dynamics are critical for control, stability,\nmotion optimization, and interaction. Semi-Parametric approaches to dynamics\nlearning combine physics-based Parametric models with unstructured\nNon-Parametric regression with the hope to achieve both accuracy and\ngeneralizablity. In this paper we highlight the non-stationary problem created\nwhen attempting to adapt both Parametric and Non-Parametric components\nsimultaneously. We present a consistency transform designed to compensate for\nthis non-stationary effect, such that the contributions of both models can\nadapt simultaneously without adversely affecting the performance of the\nplatform. Thus we are able to apply the Semi-Parametric learning approach for\ncontinuous iterative online adaptation, without relying on batch or offline\nupdates. We validate the transform via a perfect virtual model as well as by\napplying the overall system on a Kuka LWR IV manipulator. We demonstrate\nimproved tracking performance during online learning and show a clear\ntransference of contribution between the two components with a learning bias\ntowards the Parametric component.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 23:28:16 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 16:12:00 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Smith", "Joshua", ""], ["Mistry", "Michael", ""]]}, {"id": "1910.04301", "submitter": "Yueming Lyu", "authors": "Yueming Lyu and Ivor W. Tsang", "title": "Black-box Optimizer with Implicit Natural Gradient", "comments": "Black-box Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box optimization is primarily important for many compute-intensive\napplications, including reinforcement learning (RL), robot control, etc. This\npaper presents a novel theoretical framework for black-box optimization, in\nwhich our method performs stochastic update with the implicit natural gradient\nof an exponential-family distribution. Theoretically, we prove the convergence\nrate of our framework with full matrix update for convex functions. Our\ntheoretical results also hold for continuous non-differentiable black-box\nfunctions. Our methods are very simple and contain less hyper-parameters than\nCMA-ES \\cite{hansen2006cma}. Empirically, our method with full matrix update\nachieves competitive performance compared with one of the state-of-the-art\nmethod CMA-ES on benchmark test problems. Moreover, our methods can achieve\nhigh optimization precision on some challenging test functions (e.g.,\n$l_1$-norm ellipsoid test problem and Levy test problem), while methods with\nexplicit natural gradient, i.e., IGO \\cite{ollivier2017information} with full\nmatrix update can not. This shows the efficiency of our methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 23:34:36 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 23:22:51 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 10:46:10 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Lyu", "Yueming", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "1910.04302", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng, Francisco J. R. Ruiz, David M. Blei, Michalis K.\n  Titsias", "title": "Prescribed Generative Adversarial Networks", "comments": "Code for this paper can be found at\n  https://github.com/adjidieng/PresGANs", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a powerful approach to\nunsupervised learning. They have achieved state-of-the-art performance in the\nimage domain. However, GANs are limited in two ways. They often learn\ndistributions with low support---a phenomenon known as mode collapse---and they\ndo not guarantee the existence of a probability density, which makes evaluating\ngeneralization using predictive log-likelihood impossible. In this paper, we\ndevelop the prescribed GAN (PresGAN) to address these shortcomings. PresGANs\nadd noise to the output of a density network and optimize an\nentropy-regularized adversarial loss. The added noise renders tractable\napproximations of the predictive log-likelihood and stabilizes the training\nprocedure. The entropy regularizer encourages PresGANs to capture all the modes\nof the data distribution. Fitting PresGANs involves computing the intractable\ngradients of the entropy regularization term; PresGANs sidestep this\nintractability using unbiased stochastic estimates. We evaluate PresGANs on\nseveral datasets and found they mitigate mode collapse and generate samples\nwith high perceptual quality. We further found that PresGANs reduce the gap in\nperformance in terms of predictive log-likelihood between traditional GANs and\nvariational autoencoders (VAEs).\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 23:40:05 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Dieng", "Adji B.", ""], ["Ruiz", "Francisco J. R.", ""], ["Blei", "David M.", ""], ["Titsias", "Michalis K.", ""]]}, {"id": "1910.04308", "submitter": "Tom Needham", "authors": "Samir Chowdhury, Tom Needham", "title": "Gromov-Wasserstein Averaging in a Riemannian Framework", "comments": "To appear in CVPR conference workshop proceedings for DIFF-CVML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a theoretical framework for performing statistical\ntasks---including, but not limited to, averaging and principal component\nanalysis---on the space of (possibly asymmetric) matrices with arbitrary\nentries and sizes. This is carried out under the lens of the Gromov-Wasserstein\n(GW) distance, and our methods translate the Riemannian framework of GW\ndistances developed by Sturm into practical, implementable tools for network\ndata analysis. Our methods are illustrated on datasets of letter graphs,\nasymmetric stochastic blockmodel networks, and planar shapes viewed as metric\nspaces. On the theoretical front, we supplement the work of Sturm by producing\nadditional results on the tangent structure of this \"space of spaces\", as well\nas on the gradient flow of the Fr\\'{e}chet functional on this space.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 00:34:23 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 13:30:08 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Chowdhury", "Samir", ""], ["Needham", "Tom", ""]]}, {"id": "1910.04322", "submitter": "Mingrui Zhang", "authors": "Mingrui Zhang, Zebang Shen, Aryan Mokhtari, Hamed Hassani, Amin\n  Karbasi", "title": "One Sample Stochastic Frank-Wolfe", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the beauties of the projected gradient descent method lies in its\nrather simple mechanism and yet stable behavior with inexact, stochastic\ngradients, which has led to its wide-spread use in many machine learning\napplications. However, once we replace the projection operator with a simpler\nlinear program, as is done in the Frank-Wolfe method, both simplicity and\nstability take a serious hit. The aim of this paper is to bring them back\nwithout sacrificing the efficiency. In this paper, we propose the first\none-sample stochastic Frank-Wolfe algorithm, called 1-SFW, that avoids the need\nto carefully tune the batch size, step size, learning rate, and other\ncomplicated hyper parameters. In particular, 1-SFW achieves the optimal\nconvergence rate of $\\mathcal{O}(1/\\epsilon^2)$ for reaching an\n$\\epsilon$-suboptimal solution in the stochastic convex setting, and a\n$(1-1/e)-\\epsilon$ approximate solution for a stochastic monotone DR-submodular\nmaximization problem. Moreover, in a general non-convex setting, 1-SFW finds an\n$\\epsilon$-first-order stationary point after at most\n$\\mathcal{O}(1/\\epsilon^3)$ iterations, achieving the current best known\nconvergence rate. All of this is possible by designing a novel unbiased\nmomentum estimator that governs the stability of the optimization process while\nusing a single sample at each iteration.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 01:35:31 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Zhang", "Mingrui", ""], ["Shen", "Zebang", ""], ["Mokhtari", "Aryan", ""], ["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""]]}, {"id": "1910.04324", "submitter": "Younkwan Lee", "authors": "Younkwan Lee, Jiwon Jun, Yoojin Hong, Moongu Jeon", "title": "Practical License Plate Recognition in Unconstrained Surveillance\n  Systems with Adversarial Super-Resolution", "comments": "Accepted at VISAPP, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although most current license plate (LP) recognition applications have been\nsignificantly advanced, they are still limited to ideal environments where\ntraining data are carefully annotated with constrained scenes. In this paper,\nwe propose a novel license plate recognition method to handle unconstrained\nreal world traffic scenes. To overcome these difficulties, we use adversarial\nsuper-resolution (SR), and one-stage character segmentation and recognition.\nCombined with a deep convolutional network based on VGG-net, our method\nprovides simple but reasonable training procedure. Moreover, we introduce\nGIST-LP, a challenging LP dataset where image samples are effectively collected\nfrom unconstrained surveillance scenes. Experimental results on AOLP and\nGIST-LP dataset illustrate that our method, without any scene-specific\nadaptation, outperforms current LP recognition approaches in accuracy and\nprovides visual enhancement in our SR results that are easier to understand\nthan original data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 01:37:21 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Lee", "Younkwan", ""], ["Jun", "Jiwon", ""], ["Hong", "Yoojin", ""], ["Jeon", "Moongu", ""]]}, {"id": "1910.04329", "submitter": "Keizo Kato", "authors": "Keizo Kato, Jing Zhou, Tomotake Sasaki, and Akira Nakagawa", "title": "Rate-Distortion Optimization Guided Autoencoder for Isometric Embedding\n  in Euclidean Latent Space", "comments": "Accepted to the International Conference on Machine Learning (ICML)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To analyze high-dimensional and complex data in the real world, deep\ngenerative models, such as variational autoencoder (VAE) embed data in a\nlow-dimensional space (latent space) and learn a probabilistic model in the\nlatent space. However, they struggle to accurately reproduce the probability\ndistribution function (PDF) in the input space from that in the latent space.\nIf the embedding were isometric, this issue can be solved, because the relation\nof PDFs can become tractable. To achieve isometric property, we propose Rate-\nDistortion Optimization guided autoencoder inspired by orthonormal transform\ncoding. We show our method has the following properties: (i) the Jacobian\nmatrix between the input space and a Euclidean latent space forms a\nconstantlyscaled orthonormal system and enables isometric data embedding; (ii)\nthe relation of PDFs in both spaces can become tractable one such as\nproportional relation. Furthermore, our method outperforms state-of-the-art\nmethods in unsupervised anomaly detection with four public datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 02:03:22 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 10:33:15 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 08:49:29 GMT"}, {"version": "v4", "created": "Mon, 31 Aug 2020 03:32:25 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kato", "Keizo", ""], ["Zhou", "Jing", ""], ["Sasaki", "Tomotake", ""], ["Nakagawa", "Akira", ""]]}, {"id": "1910.04331", "submitter": "Haoran Dou", "authors": "Haoran Dou, Xin Yang, Jikuan Qian, Wufeng Xue, Hao Qin, Xu Wang,\n  Lequan Yu, Shujun Wang, Yi Xiong, Pheng-Ann Heng, Dong Ni", "title": "Agent with Warm Start and Active Termination for Plane Localization in\n  3D Ultrasound", "comments": "9 pages, 5 figures, 1 table. Accepted by MICCAI 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard plane localization is crucial for ultrasound (US) diagnosis. In\nprenatal US, dozens of standard planes are manually acquired with a 2D probe.\nIt is time-consuming and operator-dependent. In comparison, 3D US containing\nmultiple standard planes in one shot has the inherent advantages of less\nuser-dependency and more efficiency. However, manual plane localization in US\nvolume is challenging due to the huge search space and large fetal posture\nvariation. In this study, we propose a novel reinforcement learning (RL)\nframework to automatically localize fetal brain standard planes in 3D US. Our\ncontribution is two-fold. First, we equip the RL framework with a\nlandmark-aware alignment module to provide warm start and strong spatial bounds\nfor the agent actions, thus ensuring its effectiveness. Second, instead of\npassively and empirically terminating the agent inference, we propose a\nrecurrent neural network based strategy for active termination of the agent's\ninteraction procedure. This improves both the accuracy and efficiency of the\nlocalization system. Extensively validated on our in-house large dataset, our\napproach achieves the accuracy of 3.4mm/9.6{\\deg} and 2.7mm/9.1{\\deg} for the\ntranscerebellar and transthalamic plane localization, respectively. Ourproposed\nRL framework is general and has the potential to improve the efficiency and\nstandardization of US scanning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 02:21:52 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Dou", "Haoran", ""], ["Yang", "Xin", ""], ["Qian", "Jikuan", ""], ["Xue", "Wufeng", ""], ["Qin", "Hao", ""], ["Wang", "Xu", ""], ["Yu", "Lequan", ""], ["Wang", "Shujun", ""], ["Xiong", "Yi", ""], ["Heng", "Pheng-Ann", ""], ["Ni", "Dong", ""]]}, {"id": "1910.04332", "submitter": "Zachary Sunberg", "authors": "Michael H. Lim, Claire J. Tomlin, Zachary N. Sunberg", "title": "Sparse tree search optimality guarantees in POMDPs with continuous\n  observation spaces", "comments": null, "journal-ref": null, "doi": "10.24963/ijcai.2020/572", "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially observable Markov decision processes (POMDPs) with continuous state\nand observation spaces have powerful flexibility for representing real-world\ndecision and control problems but are notoriously difficult to solve. Recent\nonline sampling-based algorithms that use observation likelihood weighting have\nshown unprecedented effectiveness in domains with continuous observation\nspaces. However there has been no formal theoretical justification for this\ntechnique. This work offers such a justification, proving that a simplified\nalgorithm, partially observable weighted sparse sampling (POWSS), will estimate\nQ-values accurately with high probability and can be made to perform\narbitrarily near the optimal solution by increasing computational power.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 02:22:55 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 07:17:55 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 23:16:44 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lim", "Michael H.", ""], ["Tomlin", "Claire J.", ""], ["Sunberg", "Zachary N.", ""]]}, {"id": "1910.04335", "submitter": "Marvin Chanc\\'an", "authors": "Marvin Chanc\\'an and Michael Milford", "title": "CityLearn: Diverse Real-World Environments for Sample-Efficient\n  Navigation Policy Learning", "comments": "Preprint version of article accepted to ICRA 2020", "journal-ref": "2020 IEEE International Conference on Robotics and Automation\n  (ICRA)", "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Visual navigation tasks in real-world environments often require both\nself-motion and place recognition feedback. While deep reinforcement learning\nhas shown success in solving these perception and decision-making problems in\nan end-to-end manner, these algorithms require large amounts of experience to\nlearn navigation policies from high-dimensional data, which is generally\nimpractical for real robots due to sample complexity. In this paper, we address\nthese problems with two main contributions. We first leverage place recognition\nand deep learning techniques combined with goal destination feedback to\ngenerate compact, bimodal image representations that can then be used to\neffectively learn control policies from a small amount of experience. Second,\nwe present an interactive framework, CityLearn, that enables for the first time\ntraining and deployment of navigation algorithms across city-sized, realistic\nenvironments with extreme visual appearance changes. CityLearn features more\nthan 10 benchmark datasets, often used in visual place recognition and\nautonomous driving research, including over 100 recorded traversals across 60\ncities around the world. We evaluate our approach on two CityLearn\nenvironments, training our navigation policy on a single traversal. Results\nshow our method can be over 2 orders of magnitude faster than when using raw\nimages, and can also generalize across extreme visual changes including day to\nnight and summer to winter transitions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 02:34:34 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 10:24:13 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chanc\u00e1n", "Marvin", ""], ["Milford", "Michael", ""]]}, {"id": "1910.04341", "submitter": "Chang Wei Tan", "authors": "Chang Wei Tan, Francois Petitjean, Eamonn Keogh, Geoffrey I. Webb", "title": "Time series classification for varying length series", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research into time series classification has tended to focus on the case of\nseries of uniform length. However, it is common for real-world time series data\nto have unequal lengths. Differing time series lengths may arise from a number\nof fundamentally different mechanisms. In this work, we identify and evaluate\ntwo classes of such mechanisms -- variations in sampling rate relative to the\nrelevant signal and variations between the start and end points of one time\nseries relative to one another. We investigate how time series generated by\neach of these classes of mechanism are best addressed for time series\nclassification. We perform extensive experiments and provide practical\nrecommendations on how variations in length should be handled in time series\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 02:53:28 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Tan", "Chang Wei", ""], ["Petitjean", "Francois", ""], ["Keogh", "Eamonn", ""], ["Webb", "Geoffrey I.", ""]]}, {"id": "1910.04345", "submitter": "Wanzheng Zhu", "authors": "Wanzheng Zhu, Hongyu Gong, Jiaming Shen, Chao Zhang, Jingbo Shang,\n  Suma Bhat, Jiawei Han", "title": "FUSE: Multi-Faceted Set Expansion by Coherent Clustering of Skip-grams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Set expansion aims to expand a small set of seed entities into a complete set\nof relevant entities. Most existing approaches assume the input seed set is\nunambiguous and completely ignore the multi-faceted semantics of seed entities.\nAs a result, given the seed set {\"Canon\", \"Sony\", \"Nikon\"}, previous models\nreturn one mixed set of entities that are either Camera Brands or Japanese\nCompanies. In this paper, we study the task of multi-faceted set expansion,\nwhich aims to capture all semantic facets in the seed set and return multiple\nsets of entities, one for each semantic facet. We propose an unsupervised\nframework, FUSE, which consists of three major components: (1) facet discovery\nmodule: identifies all semantic facets of each seed entity by extracting and\nclustering its skip-grams, and (2) facet fusion module: discovers shared\nsemantic facets of the entire seed set by an optimization formulation, and (3)\nentity expansion module: expands each semantic facet by utilizing a masked\nlanguage model with pre-trained BERT models. Extensive experiments demonstrate\nthat FUSE can accurately identify multiple semantic facets of the seed set and\ngenerate quality entities for each facet.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 03:06:46 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 22:12:29 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 15:30:06 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Zhu", "Wanzheng", ""], ["Gong", "Hongyu", ""], ["Shen", "Jiaming", ""], ["Zhang", "Chao", ""], ["Shang", "Jingbo", ""], ["Bhat", "Suma", ""], ["Han", "Jiawei", ""]]}, {"id": "1910.04357", "submitter": "Wei Xu", "authors": "Xinyi Huang, Suphanut Jamonnak, Ye Zhao, Boyu Wang, Minh Hoai, Kevin\n  Yager, Wei Xu", "title": "Visual Understanding of Multiple Attributes Learning Model of X-Ray\n  Scattering Images", "comments": "5 pages, 2 figures, ICCV conference co-held XAIC workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This extended abstract presents a visualization system, which is designed for\ndomain scientists to visually understand their deep learning model of\nextracting multiple attributes in x-ray scattering images. The system focuses\non studying the model behaviors related to multiple structural attributes. It\nallows users to explore the images in the feature space, the classification\noutput of different attributes, with respect to the actual attributes labelled\nby domain scientists. Abundant interactions allow users to flexibly select\ninstance images, their clusters, and compare them visually in details. Two\npreliminary case studies demonstrate its functionalities and usefulness.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 03:51:58 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Huang", "Xinyi", ""], ["Jamonnak", "Suphanut", ""], ["Zhao", "Ye", ""], ["Wang", "Boyu", ""], ["Hoai", "Minh", ""], ["Yager", "Kevin", ""], ["Xu", "Wei", ""]]}, {"id": "1910.04365", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Malayandi Palan, Nicholas C. Landolfi, Dylan P.\n  Losey, Dorsa Sadigh", "title": "Asking Easy Questions: A User-Friendly Approach to Active Reward\n  Learning", "comments": "Proceedings of the 3rd Conference on Robot Learning (CoRL), October\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots can learn the right reward function by querying a human expert.\nExisting approaches attempt to choose questions where the robot is most\nuncertain about the human's response; however, they do not consider how easy it\nwill be for the human to answer! In this paper we explore an information gain\nformulation for optimally selecting questions that naturally account for the\nhuman's ability to answer. Our approach identifies questions that optimize the\ntrade-off between robot and human uncertainty, and determines when these\nquestions become redundant or costly. Simulations and a user study show our\nmethod not only produces easy questions, but also ultimately results in faster\nreward learning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 04:52:46 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Palan", "Malayandi", ""], ["Landolfi", "Nicholas C.", ""], ["Losey", "Dylan P.", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "1910.04366", "submitter": "Peijun Xiao", "authors": "Peijun Xiao, Zhisheng Xiao, Ruoyu Sun", "title": "Understanding Limitation of Two Symmetrized Orders by Worst-case\n  Complexity", "comments": "31 pages, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Update order is one of the major design choices of block decomposition\nalgorithms. There are at least two classes of deterministic update orders:\nnonsymmetric (e.g. cyclic order) and symmetric (e.g. Gaussian back substitution\nor symmetric Gauss-Seidel). Recently, Coordinate Descent (CD) with cyclic order\nwas shown to be $O(n^2)$ times slower than randomized versions in the\nworst-case. A natural question arises: can the symmetrized orders achieve\nfaster convergence rates than the cyclic order, or even getting close to the\nrandomized versions? In this paper, we give a negative answer to this question.\nWe show that both Gaussian back substitution (GBS) and symmetric Gauss-Seidel\n(sGS) suffer from the same slow convergence issue as the cyclic order in the\nworst case. In particular, we prove that for unconstrained problems, both\nGBS-CD and sGS-CD can be $O(n^2)$ times slower than R-CD. Despite unconstrained\nproblems, we also empirically study linearly constrained problems with\nquadratic objective: we empirically demonstrate that the convergence speed of\nGBS-ADMM and sGS-ADMM can be roughly $O(n^2)$ times slower than randomly\npermuted ADMM.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 04:56:31 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 01:01:59 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Xiao", "Peijun", ""], ["Xiao", "Zhisheng", ""], ["Sun", "Ruoyu", ""]]}, {"id": "1910.04371", "submitter": "Vishnu Suresh Lokhande", "authors": "Muni Sreenivas Pydi and Vishnu Suresh Lokhande", "title": "Active Learning with Importance Sampling", "comments": "NeurIPS 2019 Workshop on Machine Learning with Guarantees, Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an active learning setting where the algorithm has access to a\nlarge pool of unlabeled data and a small pool of labeled data. In each\niteration, the algorithm chooses few unlabeled data points and obtains their\nlabels from an oracle. In this paper, we consider a probabilistic querying\nprocedure to choose the points to be labeled. We propose an algorithm for\nActive Learning with Importance Sampling (ALIS), and derive upper bounds on the\ntrue loss incurred by the algorithm for any arbitrary probabilistic sampling\nprocedure. Further, we propose an optimal sampling distribution that minimizes\nthe upper bound on the true loss.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 05:11:08 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Pydi", "Muni Sreenivas", ""], ["Lokhande", "Vishnu Suresh", ""]]}, {"id": "1910.04375", "submitter": "Jian Ma", "authors": "Jian Ma", "title": "Estimating Transfer Entropy via Copula Entropy", "comments": "17 pages, 5 figures. with new experiments, discussion, and section on\n  related research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery is a fundamental problem in statistics and has wide\napplications in different fields. Transfer Entropy (TE) is a important notion\ndefined for measuring causality, which is essentially conditional Mutual\nInformation (MI). Copula Entropy (CE) is a theory on measurement of statistical\nindependence and is equivalent to MI. In this paper, we prove that TE can be\nrepresented with only CE and then propose a non-parametric method for\nestimating TE via CE. The proposed method was applied to analyze the Beijing\nPM2.5 data in the experiments. Experimental results show that the proposed\nmethod can infer causality relationships from data effectively and hence help\nto understand the data better.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 05:49:03 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 00:39:33 GMT"}, {"version": "v3", "created": "Sat, 6 Mar 2021 09:39:26 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Ma", "Jian", ""]]}, {"id": "1910.04382", "submitter": "Yang Liu", "authors": "Yang Liu and David P. Helmbold", "title": "Online Learning Using Only Peer Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a variant of the classical online learning problem with\nexpert predictions. Our model's differences and challenges are due to lacking\nany direct feedback on the loss each expert incurs at each time step $t$. We\npropose an approach that uses peer prediction and identify conditions where it\nsucceeds. Our techniques revolve around a carefully designed peer score\nfunction $s()$ that scores experts' predictions based on the peer consensus. We\nshow a sufficient condition, that we call \\emph{peer calibration}, under which\nstandard online learning algorithms using loss feedback computed by the\ncarefully crafted $s()$ have bounded regret with respect to the unrevealed\nground truth values. We then demonstrate how suitable $s()$ functions can be\nderived for different assumptions and models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 06:19:30 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 06:48:27 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Liu", "Yang", ""], ["Helmbold", "David P.", ""]]}, {"id": "1910.04385", "submitter": "Nontawat Charoenphakdee", "authors": "Nontawat Charoenphakdee, Jongyeong Lee, Yiping Jin, Dittaya Wanvarie,\n  Masashi Sugiyama", "title": "Learning Only from Relevant Keywords and Unlabeled Documents", "comments": "EMNLP-IJCNLP2019, fix typos in Theorem 1: change $\\pi$ and $\\pi'$ to\n  $\\theta$ and $\\theta'$", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a document classification problem where document labels are\nabsent but only relevant keywords of a target class and unlabeled documents are\ngiven. Although heuristic methods based on pseudo-labeling have been\nconsidered, theoretical understanding of this problem has still been limited.\nMoreover, previous methods cannot easily incorporate well-developed techniques\nin supervised text classification. In this paper, we propose a theoretically\nguaranteed learning framework that is simple to implement and has flexible\nchoices of models, e.g., linear models or neural networks. We demonstrate how\nto optimize the area under the receiver operating characteristic curve (AUC)\neffectively and also discuss how to adjust it to optimize other well-known\nevaluation metrics such as the accuracy and F1-measure. Finally, we show the\neffectiveness of our framework using benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 06:29:22 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 03:40:51 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Charoenphakdee", "Nontawat", ""], ["Lee", "Jongyeong", ""], ["Jin", "Yiping", ""], ["Wanvarie", "Dittaya", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1910.04388", "submitter": "Yuma Koizumi", "authors": "Luca Mazzon, Yuma Koizumi, Masahiro Yasuda, Noboru Harada", "title": "First Order Ambisonics Domain Spatial Augmentation for DNN-based\n  Direction of Arrival Estimation", "comments": "5 pages, to appear in DCASE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel data augmentation method for training\nneural networks for Direction of Arrival (DOA) estimation. This method focuses\non expanding the representation of the DOA subspace of a dataset. Given some\ninput data, it applies a transformation to it in order to change its DOA\ninformation and simulate new potentially unseen one. Such transformation, in\ngeneral, is a combination of a rotation and a reflection. It is possible to\napply such transformation due to a well-known property of First Order\nAmbisonics (FOA). The same transformation is applied also to the labels, in\norder to maintain consistency between input data and target labels. Three\nmethods with different level of generality are proposed for applying this\naugmentation principle. Experiments are conducted on two different DOA\nnetworks. Results of both experiments demonstrate the effectiveness of the\nnovel augmentation strategy by improving the DOA error by around 40%.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 06:38:57 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Mazzon", "Luca", ""], ["Koizumi", "Yuma", ""], ["Yasuda", "Masahiro", ""], ["Harada", "Noboru", ""]]}, {"id": "1910.04394", "submitter": "Yivan Zhang", "authors": "Yivan Zhang, Nontawat Charoenphakdee, Masashi Sugiyama", "title": "Learning from Indirect Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly-supervised learning is a paradigm for alleviating the scarcity of\nlabeled data by leveraging lower-quality but larger-scale supervision signals.\nWhile existing work mainly focuses on utilizing a certain type of weak\nsupervision, we present a probabilistic framework, learning from indirect\nobservations, for learning from a wide range of weak supervision in real-world\nproblems, e.g., noisy labels, complementary labels and coarse-grained labels.\nWe propose a general method based on the maximum likelihood principle, which\nhas desirable theoretical properties and can be straightforwardly implemented\nfor deep neural networks. Concretely, a discriminative model for the true\ntarget is used for modeling the indirect observation, which is a random\nvariable entirely depending on the true target stochastically or\ndeterministically. Then, maximizing the likelihood given indirect observations\nleads to an estimator of the true target implicitly. Comprehensive experiments\nfor two novel problem settings --- learning from multiclass label proportions\nand learning from coarse-grained labels, illustrate practical usefulness of our\nmethod and demonstrate how to integrate various sources of weak supervision.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 07:15:02 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Zhang", "Yivan", ""], ["Charoenphakdee", "Nontawat", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1910.04415", "submitter": "Yuma Koizumi", "authors": "Masahiro Yasuda, Yuma Koizumi, Luca Mazzon, Shoichiro Saito, Hisashi\n  Uematsu", "title": "DOA Estimation by DNN-based Denoising and Dereverberation from Sound\n  Intensity Vector", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a direction of arrival (DOA) estimation method that combines\nsound-intensity vector (IV)-based DOA estimation and DNN-based denoising and\ndereverberation. Since the accuracy of IV-based DOA estimation degrades due to\nenvironmental noise and reverberation, two DNNs are used to remove such effects\nfrom the observed IVs. DOA is then estimated from the refined IVs based on the\nphysics of wave propagation. Experiments on an open dataset showed that the\naverage DOA error of the proposed method was 0.528 degrees, and it outperformed\na conventional IV-based and DNN-based DOA estimation method.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 07:57:31 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Yasuda", "Masahiro", ""], ["Koizumi", "Yuma", ""], ["Mazzon", "Luca", ""], ["Saito", "Shoichiro", ""], ["Uematsu", "Hisashi", ""]]}, {"id": "1910.04417", "submitter": "Xiaojian Ma", "authors": "Chao Yang, Xiaojian Ma, Wenbing Huang, Fuchun Sun, Huaping Liu,\n  Junzhou Huang, Chuang Gan", "title": "Imitation Learning from Observations by Minimizing Inverse Dynamics\n  Disagreement", "comments": "Accepted to NeurIPS 2019 as a spotlight. Chao Yang and Xiaojian Ma\n  contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies Learning from Observations (LfO) for imitation learning\nwith access to state-only demonstrations. In contrast to Learning from\nDemonstration (LfD) that involves both action and state supervision, LfO is\nmore practical in leveraging previously inapplicable resources (e.g. videos),\nyet more challenging due to the incomplete expert guidance. In this paper, we\ninvestigate LfO and its difference with LfD in both theoretical and practical\nperspectives. We first prove that the gap between LfD and LfO actually lies in\nthe disagreement of inverse dynamics models between the imitator and the\nexpert, if following the modeling approach of GAIL. More importantly, the upper\nbound of this gap is revealed by a negative causal entropy which can be\nminimized in a model-free way. We term our method as\nInverse-Dynamics-Disagreement-Minimization (IDDM) which enhances the\nconventional LfO method through further bridging the gap to LfD. Considerable\nempirical results on challenging benchmarks indicate that our method attains\nconsistent improvements over other LfO counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 08:07:17 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 20:10:53 GMT"}, {"version": "v3", "created": "Sun, 20 Oct 2019 19:21:27 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 00:17:12 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yang", "Chao", ""], ["Ma", "Xiaojian", ""], ["Huang", "Wenbing", ""], ["Sun", "Fuchun", ""], ["Liu", "Huaping", ""], ["Huang", "Junzhou", ""], ["Gan", "Chuang", ""]]}, {"id": "1910.04420", "submitter": "Changying Du", "authors": "Changying Du, Fuzhen Zhuang, Jia He, Qing He and Guoping Long", "title": "Learning beyond Predefined Label Space via Bayesian Nonparametric Topic\n  Modelling", "comments": "Learning beyond predefined labels; Generalized zero-shot learning;\n  Semi-supervised learning; Generative model; Nonparametric Bayesian learning;\n  Hierarchical Dirichlet process; Topic modelling; Collapsed Gibbs sampling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real world machine learning applications, testing data may contain some\nmeaningful new categories that have not been seen in labeled training data. To\nsimultaneously recognize new data categories and assign most appropriate\ncategory labels to the data actually from known categories, existing models\nassume the number of unknown new categories is pre-specified, though it is\ndifficult to determine in advance. In this paper, we propose a Bayesian\nnonparametric topic model to automatically infer this number, based on the\nhierarchical Dirichlet process and the notion of latent Dirichlet allocation.\nExact inference in our model is intractable, so we provide an efficient\ncollapsed Gibbs sampling algorithm for approximate posterior inference.\nExtensive experiments on various text data sets show that: (a) compared with\nparametric approaches that use pre-specified true number of new categories, the\nproposed nonparametric approach can yield comparable performance; and (b) when\nthe exact number of new categories is unavailable, i.e. the parametric\napproaches only have a rough idea about the new categories, our approach has\nevident performance advantages.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 08:15:08 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Du", "Changying", ""], ["Zhuang", "Fuzhen", ""], ["He", "Jia", ""], ["He", "Qing", ""], ["Long", "Guoping", ""]]}, {"id": "1910.04426", "submitter": "Ying-Cheng Lai", "authors": "Junjie Jiang, Ying-Cheng Lai", "title": "Model-free prediction of spatiotemporal dynamical systems with recurrent\n  neural networks: Role of network spectral radius", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.CD physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common difficulty in applications of machine learning is the lack of any\ngeneral principle for guiding the choices of key parameters of the underlying\nneural network. Focusing on a class of recurrent neural networks - reservoir\ncomputing systems that have recently been exploited for model-free prediction\nof nonlinear dynamical systems, we uncover a surprising phenomenon: the\nemergence of an interval in the spectral radius of the neural network in which\nthe prediction error is minimized. In a three-dimensional representation of the\nerror versus time and spectral radius, the interval corresponds to the bottom\nregion of a \"valley.\" Such a valley arises for a variety of spatiotemporal\ndynamical systems described by nonlinear partial differential equations,\nregardless of the structure and the edge-weight distribution of the underlying\nreservoir network. We also find that, while the particular location and size of\nthe valley would depend on the details of the target system to be predicted,\nthe interval tends to be larger for undirected than for directed networks. The\nvalley phenomenon can be beneficial to the design of optimal reservoir\ncomputing, representing a small step forward in understanding these\nmachine-learning systems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 08:27:59 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Jiang", "Junjie", ""], ["Lai", "Ying-Cheng", ""]]}, {"id": "1910.04439", "submitter": "Haohao Li", "authors": "Haohao Li, Huibing Wang", "title": "A Multi-view Dimensionality Reduction Algorithm Based on Smooth\n  Representation Model", "comments": "Revise some experimental results and formulates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few decades, we have witnessed a large family of algorithms\nthat have been designed to provide different solutions to the problem of\ndimensionality reduction (DR). The DR is an essential tool to excavate the\nimportant information from the high-dimensional data by mapping the data to a\nlow-dimensional subspace. Furthermore, for the diversity of varied\nhigh-dimensional data, the multi-view features can be utilized for improving\nthe learning performance. However, many DR methods fail to integrating multiple\nviews. Although the features from different views are extracted by different\nmanners, they are utilized to describe the same sample, which implies that they\nare highly related. Therefore, how to learn the subspace for high-dimensional\nfeatures by utilizing the consistency and complementary properties of\nmulti-view features is important in the present. In this paper, we propose an\neffective multi-view dimensionality reduction algorithm named Multi-view Smooth\nPreserve Projection. Firstly, we construct a single view DR method named Smooth\nPreserve Projection based on the Smooth Representation model. The proposed\nmethod aims to find a subspace for the high-dimensional data, in which the\nsmooth reconstructive weights are preserved as much as possible. Then, we\nextend it to a multi-view version in which we exploits Hilbert-Schmidt\nIndependence Criterion to jointly learn one common subspace for all views. A\nplenty of experiments on multi-view datasets show the excellent performance of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 09:02:46 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 09:56:12 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 09:37:48 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Li", "Haohao", ""], ["Wang", "Huibing", ""]]}, {"id": "1910.04450", "submitter": "Siyuan Li", "authors": "Siyuan Li, Rui Wang, Minxue Tang, Chongjie Zhang", "title": "Hierarchical Reinforcement Learning with Advantage-Based Auxiliary\n  Rewards", "comments": "Camera ready version for NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Reinforcement Learning (HRL) is a promising approach to solving\nlong-horizon problems with sparse and delayed rewards. Many existing HRL\nalgorithms either use pre-trained low-level skills that are unadaptable, or\nrequire domain-specific information to define low-level rewards. In this paper,\nwe aim to adapt low-level skills to downstream tasks while maintaining the\ngenerality of reward design. We propose an HRL framework which sets auxiliary\nrewards for low-level skill training based on the advantage function of the\nhigh-level policy. This auxiliary reward enables efficient, simultaneous\nlearning of the high-level policy and low-level skills without using\ntask-specific knowledge. In addition, we also theoretically prove that\noptimizing low-level skills with this auxiliary reward will increase the task\nreturn for the joint policy. Experimental results show that our algorithm\ndramatically outperforms other state-of-the-art HRL methods in Mujoco domains.\nWe also find both low-level and high-level policies trained by our algorithm\ntransferable.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 09:39:15 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Li", "Siyuan", ""], ["Wang", "Rui", ""], ["Tang", "Minxue", ""], ["Zhang", "Chongjie", ""]]}, {"id": "1910.04460", "submitter": "Benjamin Guedj", "authors": "Benjamin Guedj and Louis Pujol", "title": "Still no free lunches: the price to pay for tighter PAC-Bayes bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  \"No free lunch\" results state the impossibility of obtaining meaningful\nbounds on the error of a learning algorithm without prior assumptions and\nmodelling. Some models are expensive (strong assumptions, such as as\nsubgaussian tails), others are cheap (simply finite variance). As it is well\nknown, the more you pay, the more you get: in other words, the most expensive\nmodels yield the more interesting bounds. Recent advances in robust statistics\nhave investigated procedures to obtain tight bounds while keeping the cost\nminimal. The present paper explores and exhibits what the limits are for\nobtaining tight PAC-Bayes bounds in a robust setting for cheap models,\naddressing the question: is PAC-Bayes good value for money?\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 10:01:02 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Guedj", "Benjamin", ""], ["Pujol", "Louis", ""]]}, {"id": "1910.04462", "submitter": "Tam Le", "authors": "Tam Le, Nhat Ho, Makoto Yamada", "title": "Flow-based Alignment Approaches for Probability Measures in Different\n  Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gromov-Wasserstein (GW) is a powerful tool to compare probability measures\nwhose supports are in different metric spaces. GW suffers however from a\ncomputational drawback since it requires to solve a complex non-convex\nquadratic program. We consider in this work a specific family of cost metrics,\nnamely \\textit{tree metrics} for a space of supports of each probability\nmeasure, and aim for developing efficient and scalable discrepancies between\nthe probability measures. By leveraging a tree structure, we propose to align\n\\textit{flows} from a root to each support instead of pair-wise tree metrics of\nsupports, i.e., flows from a support to another, in GW. Consequently, we\npropose a novel discrepancy, named Flow-based Alignment (\\FlowAlign), by\nmatching the flows of the probability measures. We show that \\FlowAlign~shares\na similar structure as a univariate optimal transport distance. Therefore,\n\\FlowAlign~is fast for computation and scalable for large-scale applications.\nBy further exploring tree structures, we propose a variant of \\FlowAlign, named\nDepth-based Alignment (\\DepthAlign), by aligning the flows hierarchically along\neach depth level of the tree structures. Theoretically, we prove that both\n\\FlowAlign~and \\DepthAlign~are pseudo-distances. Moreover, we also derive\ntree-sliced variants, computed by averaging the corresponding \\FlowAlign~/\n\\DepthAlign~using random tree metrics, built adaptively in spaces of supports.\nEmpirically, we test our proposed discrepancies against other baselines on some\nbenchmark tasks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 10:04:13 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 05:59:07 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 08:00:25 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2020 10:30:26 GMT"}, {"version": "v5", "created": "Wed, 17 Jun 2020 07:40:50 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Le", "Tam", ""], ["Ho", "Nhat", ""], ["Yamada", "Makoto", ""]]}, {"id": "1910.04464", "submitter": "Benjamin Guedj", "authors": "Kento Nozawa and Pascal Germain and Benjamin Guedj", "title": "PAC-Bayesian Contrastive Unsupervised Representation Learning", "comments": "Published in the proceedings of the Conference on Uncertainty in\n  Artificial Intelligence 2020 (UAI)", "journal-ref": "PMLR, volume 124 (UAI 2020), 2020", "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Contrastive unsupervised representation learning (CURL) is the\nstate-of-the-art technique to learn representations (as a set of features) from\nunlabelled data. While CURL has collected several empirical successes recently,\ntheoretical understanding of its performance was still missing. In a recent\nwork, Arora et al. (2019) provide the first generalisation bounds for CURL,\nrelying on a Rademacher complexity. We extend their framework to the flexible\nPAC-Bayes setting, allowing us to deal with the non-iid setting. We present\nPAC-Bayesian generalisation bounds for CURL, which are then used to derive a\nnew representation learning algorithm. Numerical experiments on real-life\ndatasets illustrate that our algorithm achieves competitive accuracy, and\nyields non-vacuous generalisation bounds.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 10:13:01 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 05:21:33 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 18:30:17 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 13:41:05 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Nozawa", "Kento", ""], ["Germain", "Pascal", ""], ["Guedj", "Benjamin", ""]]}, {"id": "1910.04476", "submitter": "Zhi-Song Liu", "authors": "Zhi-Song Liu, Li-Wen Wang, Chu-Tak Li, Wan-Chi Siu, Yui-Lam Chan", "title": "Image Super-Resolution via Attention based Back Projection Networks", "comments": "9 pages, 7 figures, ABPN", "journal-ref": "IEEE International Conference on Computer Vision 2019", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based image Super-Resolution (SR) has shown rapid development\ndue to its ability of big data digestion. Generally, deeper and wider networks\ncan extract richer feature maps and generate SR images with remarkable quality.\nHowever, the more complex network we have, the more time consumption is\nrequired for practical applications. It is important to have a simplified\nnetwork for efficient image SR. In this paper, we propose an Attention based\nBack Projection Network (ABPN) for image super-resolution. Similar to some\nrecent works, we believe that the back projection mechanism can be further\ndeveloped for SR. Enhanced back projection blocks are suggested to iteratively\nupdate low- and high-resolution feature residues. Inspired by recent studies on\nattention models, we propose a Spatial Attention Block (SAB) to learn the\ncross-correlation across features at different layers. Based on the assumption\nthat a good SR image should be close to the original LR image after\ndown-sampling. We propose a Refined Back Projection Block (RBPB) for final\nreconstruction. Extensive experiments on some public and AIM2019 Image\nSuper-Resolution Challenge datasets show that the proposed ABPN can provide\nstate-of-the-art or even better performance in both quantitative and\nqualitative measurements.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 10:49:20 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Liu", "Zhi-Song", ""], ["Wang", "Li-Wen", ""], ["Li", "Chu-Tak", ""], ["Siu", "Wan-Chi", ""], ["Chan", "Yui-Lam", ""]]}, {"id": "1910.04483", "submitter": "Tam Le", "authors": "Tam Le, Viet Huynh, Nhat Ho, Dinh Phung, Makoto Yamada", "title": "Tree-Wasserstein Barycenter for Large-Scale Multilevel Clustering and\n  Scalable Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study in this paper a variant of Wasserstein barycenter problem, which we\nrefer to as tree-Wasserstein barycenter, by leveraging a specific class of\nground metrics, namely tree metrics, for Wasserstein distance. Drawing on the\ntree structure, we propose an efficient algorithmic approach to solve the\ntree-Wasserstein barycenter and its variants. The proposed approach is not only\nfast for computation but also efficient for memory usage. Exploiting the\ntree-Wasserstein barycenter and its variants, we scale up multi-level\nclustering and scalable Bayes, especially for large-scale applications where\nthe number of supports in probability measures is large. Empirically, we test\nour proposed approach against other baselines on large-scale synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 11:09:26 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 10:51:54 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 03:20:03 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Le", "Tam", ""], ["Huynh", "Viet", ""], ["Ho", "Nhat", ""], ["Phung", "Dinh", ""], ["Yamada", "Makoto", ""]]}, {"id": "1910.04499", "submitter": "Nezihe Merve G\\\"urel", "authors": "Xupeng Miao, Nezihe Merve G\\\"urel, Wentao Zhang, Zhichao Han, Bo Li,\n  Wei Min, Xi Rao, Hansheng Ren, Yinan Shan, Yingxia Shao, Yujie Wang, Fan Wu,\n  Hui Xue, Yaming Yang, Zitao Zhang, Yang Zhao, Shuai Zhang, Yujing Wang, Bin\n  Cui, Ce Zhang", "title": "DeGNN: Characterizing and Improving Graph Neural Networks with Graph\n  Decomposition", "comments": "20 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the wide application of Graph Convolutional Network (GCN), one major\nlimitation is that it does not benefit from the increasing depth and suffers\nfrom the oversmoothing problem. In this work, we first characterize this\nphenomenon from the information-theoretic perspective and show that under\ncertain conditions, the mutual information between the output after $l$ layers\nand the input of GCN converges to 0 exponentially with respect to $l$. We also\nshow that, on the other hand, graph decomposition can potentially weaken the\ncondition of such convergence rate, which enabled our analysis for GraphCNN.\nWhile different graph structures can only benefit from the corresponding\ndecomposition, in practice, we propose an automatic connectivity-aware graph\ndecomposition algorithm, DeGNN, to improve the performance of general graph\nneural networks. Extensive experiments on widely adopted benchmark datasets\ndemonstrate that DeGNN can not only significantly boost the performance of\ncorresponding GNNs, but also achieves the state-of-the-art performances.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 11:52:36 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 13:50:26 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 12:06:41 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 08:21:25 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Miao", "Xupeng", ""], ["G\u00fcrel", "Nezihe Merve", ""], ["Zhang", "Wentao", ""], ["Han", "Zhichao", ""], ["Li", "Bo", ""], ["Min", "Wei", ""], ["Rao", "Xi", ""], ["Ren", "Hansheng", ""], ["Shan", "Yinan", ""], ["Shao", "Yingxia", ""], ["Wang", "Yujie", ""], ["Wu", "Fan", ""], ["Xue", "Hui", ""], ["Yang", "Yaming", ""], ["Zhang", "Zitao", ""], ["Zhao", "Yang", ""], ["Zhang", "Shuai", ""], ["Wang", "Yujing", ""], ["Cui", "Bin", ""], ["Zhang", "Ce", ""]]}, {"id": "1910.04500", "submitter": "Mingu Lee", "authors": "Mingu Lee, Jinkyu Lee, Hye Jin Jang, Byeonggeun Kim, Wonil Chang and\n  Kyuwoong Hwang", "title": "Orthogonality Constrained Multi-Head Attention For Keyword Spotting", "comments": "Accepted to ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-head attention mechanism is capable of learning various representations\nfrom sequential data while paying attention to different subsequences, e.g.,\nword-pieces or syllables in a spoken word. From the subsequences, it retrieves\nricher information than a single-head attention which only summarizes the whole\nsequence into one context vector. However, a naive use of the multi-head\nattention does not guarantee such richness as the attention heads may have\npositional and representational redundancy. In this paper, we propose a\nregularization technique for multi-head attention mechanism in an end-to-end\nneural keyword spotting system. Augmenting regularization terms which penalize\npositional and contextual non-orthogonality between the attention heads\nencourages to output different representations from separate subsequences,\nwhich in turn enables leveraging structured information without explicit\nsequence models such as hidden Markov models. In addition, intra-head\ncontextual non-orthogonality regularization encourages each attention head to\nhave similar representations across keyword examples, which helps\nclassification by reducing feature variability. The experimental results\ndemonstrate that the proposed regularization technique significantly improves\nthe keyword spotting performance for the keyword \"Hey Snapdragon\".\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 12:00:33 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Lee", "Mingu", ""], ["Lee", "Jinkyu", ""], ["Jang", "Hye Jin", ""], ["Kim", "Byeonggeun", ""], ["Chang", "Wonil", ""], ["Hwang", "Kyuwoong", ""]]}, {"id": "1910.04514", "submitter": "Sebastian Szyller", "authors": "Samuel Marchal and Sebastian Szyller", "title": "Detecting organized eCommerce fraud using scalable categorical\n  clustering", "comments": "14 pages, 6 figures, Annual Computer Security Applications Conference\n  (ACSAC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online retail, eCommerce, frequently falls victim to fraud conducted by\nmalicious customers (fraudsters) who obtain goods or services through\ndeception. Fraud coordinated by groups of professional fraudsters that place\nseveral fraudulent orders to maximize their gain is referred to as organized\nfraud. Existing approaches to fraud detection typically analyze orders in\nisolation and they are not effective at identifying groups of fraudulent orders\nlinked to organized fraud. These also wrongly identify many legitimate orders\nas fraud, which hinders their usage for automated fraud cancellation. We\nintroduce a novel solution to detect organized fraud by analyzing orders in\nbulk. Our approach is based on clustering and aims to group together fraudulent\norders placed by the same group of fraudsters. It selectively uses two existing\ntechniques, agglomerative clustering and sampling to recursively group orders\ninto small clusters in a reasonable amount of time. We assess our clustering\ntechnique on real-world orders placed on the Zalando website, the largest\nonline apparel retailer in Europe1. Our clustering processes 100,000s of orders\nin a few hours and groups 35-45% of fraudulent orders together. We propose a\nsimple technique built on top of our clustering that detects 26.2% of fraud\nwhile raising false alarms for only 0.1% of legitimate orders.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 12:34:02 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Marchal", "Samuel", ""], ["Szyller", "Sebastian", ""]]}, {"id": "1910.04519", "submitter": "Patrick Schrempf", "authors": "Mattias Appelgren, Patrick Schrempf, Mat\\'u\\v{s} Falis, Satoshi Ikeda,\n  Alison Q O'Neil", "title": "Language Transfer for Early Warning of Epidemics from Social Media", "comments": "Artificial Intelligence for Humanitarian Assistance and Disaster\n  Response Workshop (AI+HADR) at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statements on social media can be analysed to identify individuals who are\nexperiencing red flag medical symptoms, allowing early detection of the spread\nof disease such as influenza. Since disease does not respect cultural borders\nand may spread between populations speaking different languages, we would like\nto build multilingual models. However, the data required to train models for\nevery language may be difficult, expensive and time-consuming to obtain,\nparticularly for low-resource languages. Taking Japanese as our target\nlanguage, we explore methods by which data in one language might be used to\nbuild models for a different language. We evaluate strategies of training on\nmachine translated data and of zero-shot transfer through the use of\nmultilingual models. We find that the choice of source language impacts the\nperformance, with Chinese-Japanese being a better language pair than\nEnglish-Japanese. Training on machine translated data shows promise, especially\nwhen used in conjunction with a small amount of target language data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 12:42:19 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Appelgren", "Mattias", ""], ["Schrempf", "Patrick", ""], ["Falis", "Mat\u00fa\u0161", ""], ["Ikeda", "Satoshi", ""], ["O'Neil", "Alison Q", ""]]}, {"id": "1910.04522", "submitter": "Matilde Gargiani", "authors": "Matilde Gargiani and Aaron Klein and Stefan Falkner and Frank Hutter", "title": "Probabilistic Rollouts for Learning Curve Extrapolation Across\n  Hyperparameter Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose probabilistic models that can extrapolate learning curves of\niterative machine learning algorithms, such as stochastic gradient descent for\ntraining deep networks, based on training data with variable-length learning\ncurves. We study instantiations of this framework based on random forests and\nBayesian recurrent neural networks. Our experiments show that these models\nyield better predictions than state-of-the-art models from the hyperparameter\noptimization literature when extrapolating the performance of neural networks\ntrained with different hyperparameter settings.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 12:49:22 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Gargiani", "Matilde", ""], ["Klein", "Aaron", ""], ["Falkner", "Stefan", ""], ["Hutter", "Frank", ""]]}, {"id": "1910.04536", "submitter": "Martin Trapp", "authors": "Martin Trapp, Robert Peharz, Franz Pernkopf, Carl E. Rasmussen", "title": "Deep Structured Mixtures of Gaussian Processes", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Processes (GPs) are powerful non-parametric Bayesian regression\nmodels that allow exact posterior inference, but exhibit high computational and\nmemory costs. In order to improve scalability of GPs, approximate posterior\ninference is frequently employed, where a prominent class of approximation\ntechniques is based on local GP experts. However, local-expert techniques\nproposed so far are either not well-principled, come with limited approximation\nguarantees, or lead to intractable models. In this paper, we introduce deep\nstructured mixtures of GP experts, a stochastic process model which i) allows\nexact posterior inference, ii) has attractive computational and memory costs,\nand iii) when used as GP approximation, captures predictive uncertainties\nconsistently better than previous expert-based approximations. In a variety of\nexperiments, we show that deep structured mixtures have a low approximation\nerror and often perform competitive or outperform prior work.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 13:16:13 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 18:08:56 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Trapp", "Martin", ""], ["Peharz", "Robert", ""], ["Pernkopf", "Franz", ""], ["Rasmussen", "Carl E.", ""]]}, {"id": "1910.04537", "submitter": "Arpit Garg", "authors": "Arpit Garg, Yazied A. Hasan, Adam Ya\\~nez and Lydia Tapia", "title": "Defensive Escort Teams via Multi-Agent Deep Reinforcement Learning", "comments": "IEEE Robotics and Automation Letters with International Conference on\n  Robotics and Automation (ICRA) option, 2020, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordinated defensive escorts can aid a navigating payload by positioning\nthemselves in order to maintain the safety of the payload from obstacles. In\nthis paper, we present a novel, end-to-end solution for coordinating an escort\nteam for protecting high-value payloads. Our solution employs deep\nreinforcement learning (RL) in order to train a team of escorts to maintain\npayload safety while navigating alongside the payload. This is done in a\ndistributed fashion, relying only on limited range positional information of\nother escorts, the payload, and the obstacles. When compared to a state-of-art\nalgorithm for obstacle avoidance, our solution with a single escort increases\nnavigation success up to 31%. Additionally, escort teams increase success rate\nby up to 75% percent over escorts in static formations. We also show that this\nlearned solution is general to several adaptations in the scenario including: a\nchanging number of escorts in the team, changing obstacle density, and changes\nin payload conformation. Video: https://youtu.be/SoYesKti4VA.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:57:49 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Garg", "Arpit", ""], ["Hasan", "Yazied A.", ""], ["Ya\u00f1ez", "Adam", ""], ["Tapia", "Lydia", ""]]}, {"id": "1910.04540", "submitter": "Tianyi Zhang", "authors": "Tianyi Zhang, Zhiqiu Lin, Guandao Yang, Christopher De Sa", "title": "QPyTorch: A Low-Precision Arithmetic Simulation Framework", "comments": "NeurIPS 2019 EMC^2 Workshop on Energy Efficient Machine Learning and\n  Cognitive Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-precision training reduces computational cost and produces efficient\nmodels. Recent research in developing new low-precision training algorithms\noften relies on simulation to empirically evaluate the statistical effects of\nquantization while avoiding the substantial overhead of building specific\nhardware. To support this empirical research, we introduce QPyTorch, a\nlow-precision arithmetic simulation framework. Built natively in PyTorch,\nQPyTorch provides a convenient interface that minimizes the efforts needed to\nreliably convert existing codes to study low-precision training. QPyTorch is\ngeneral, and supports a variety of combinations of precisions, number formats,\nand rounding options. Additionally, it leverages an efficient fused-kernel\napproach to reduce simulator overhead, which enables simulation of large-scale,\nrealistic problems. QPyTorch is publicly available at\nhttps://github.com/Tiiiger/QPyTorch.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:15:08 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Zhang", "Tianyi", ""], ["Lin", "Zhiqiu", ""], ["Yang", "Guandao", ""], ["De Sa", "Christopher", ""]]}, {"id": "1910.04543", "submitter": "Matteo Degiacomi", "authors": "Venkata K. Ramaswamy, Chris G. Willcocks, Matteo T. Degiacomi", "title": "Learning protein conformational space by enforcing physics with\n  convolutions and latent interpolations", "comments": null, "journal-ref": "Phys. Rev. X 11, 011052 (2021)", "doi": "10.1103/PhysRevX.11.011052", "report-no": null, "categories": "physics.bio-ph cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Determining the different conformational states of a protein and the\ntransition paths between them is key to fully understanding the relationship\nbetween biomolecular structure and function. This can be accomplished by\nsampling protein conformational space with molecular simulation methodologies.\nDespite advances in computing hardware and sampling techniques, simulations\nalways yield a discretized representation of this space, with transition states\nundersampled proportionally to their associated energy barrier. We present a\nconvolutional neural network that learns a continuous conformational space\nrepresentation from example structures, and loss functions that ensure\nintermediates between examples are physically plausible. We show that this\nnetwork, trained with simulations of distinct protein states, can correctly\npredict a biologically relevant non-linear transition path, without any example\non the path provided. We also show we can transfer features learnt from one\nprotein to others, which results in superior performances, and requires a\nsurprisingly small number of training examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 13:23:38 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 09:31:39 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Ramaswamy", "Venkata K.", ""], ["Willcocks", "Chris G.", ""], ["Degiacomi", "Matteo T.", ""]]}, {"id": "1910.04581", "submitter": "Xueru Zhang", "authors": "Xueru Zhang, Mohammad Mahdi Khalili, Mingyan Liu", "title": "Recycled ADMM: Improving the Privacy and Accuracy of Distributed\n  Algorithms", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.03197", "journal-ref": "In IEEE Transactions on Information Forensics and Security (TIFS),\n  2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating direction method of multiplier (ADMM) is a powerful method to\nsolve decentralized convex optimization problems. In distributed settings, each\nnode performs computation with its local data and the local results are\nexchanged among neighboring nodes in an iterative fashion. During this\niterative process the leakage of data privacy arises and can accumulate\nsignificantly over many iterations, making it difficult to balance the\nprivacy-accuracy tradeoff. We propose Recycled ADMM (R-ADMM), where a linear\napproximation is applied to every even iteration, its solution directly\ncalculated using only results from the previous, odd iteration. It turns out\nthat under such a scheme, half of the updates incur no privacy loss and require\nmuch less computation compared to the conventional ADMM. Moreover, R-ADMM can\nbe further modified (MR-ADMM) such that each node independently determines its\nown penalty parameter over iterations. We obtain a sufficient condition for the\nconvergence of both algorithms and provide the privacy analysis based on\nobjective perturbation. It can be shown that the privacy-accuracy tradeoff can\nbe improved significantly compared with conventional ADMM.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 23:56:12 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Zhang", "Xueru", ""], ["Khalili", "Mohammad Mahdi", ""], ["Liu", "Mingyan", ""]]}, {"id": "1910.04586", "submitter": "Mengye Ren", "authors": "Abbas Sadat, Mengye Ren, Andrei Pokrovsky, Yen-Chen Lin, Ersin Yumer,\n  Raquel Urtasun", "title": "Jointly Learnable Behavior and Trajectory Planning for Self-Driving\n  Vehicles", "comments": "IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The motion planners used in self-driving vehicles need to generate\ntrajectories that are safe, comfortable, and obey the traffic rules. This is\nusually achieved by two modules: behavior planner, which handles high-level\ndecisions and produces a coarse trajectory, and trajectory planner that\ngenerates a smooth, feasible trajectory for the duration of the planning\nhorizon. These planners, however, are typically developed separately, and\nchanges in the behavior planner might affect the trajectory planner in\nunexpected ways. Furthermore, the final trajectory outputted by the trajectory\nplanner might differ significantly from the one generated by the behavior\nplanner, as they do not share the same objective. In this paper, we propose a\njointly learnable behavior and trajectory planner. Unlike most existing\nlearnable motion planners that address either only behavior planning, or use an\nuninterpretable neural network to represent the entire logic from sensors to\ndriving commands, our approach features an interpretable cost function on top\nof perception, prediction and vehicle dynamics, and a joint learning algorithm\nthat learns a shared cost function employed by our behavior and trajectory\ncomponents. Experiments on real-world self-driving data demonstrate that\njointly learned planner performs significantly better in terms of both\nsimilarity to human driving and other safety metrics, compared to baselines\nthat do not adopt joint behavior and trajectory learning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:10:03 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Sadat", "Abbas", ""], ["Ren", "Mengye", ""], ["Pokrovsky", "Andrei", ""], ["Lin", "Yen-Chen", ""], ["Yumer", "Ersin", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1910.04597", "submitter": "Ben Glocker", "authors": "Ben Glocker, Robert Robinson, Daniel C. Castro, Qi Dou, Ender\n  Konukoglu", "title": "Machine Learning with Multi-Site Imaging Data: An Empirical Study on the\n  Impact of Scanner Effects", "comments": "Presented at the Medical Imaging meets NeurIPS Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is an empirical study to investigate the impact of scanner effects when\nusing machine learning on multi-site neuroimaging data. We utilize structural\nT1-weighted brain MRI obtained from two different studies, Cam-CAN and UK\nBiobank. For the purpose of our investigation, we construct a dataset\nconsisting of brain scans from 592 age- and sex-matched individuals, 296\nsubjects from each original study. Our results demonstrate that even after\ncareful pre-processing with state-of-the-art neuroimaging pipelines a\nclassifier can easily distinguish between the origin of the data with very high\naccuracy. Our analysis on the example application of sex classification\nsuggests that current approaches to harmonize data are unable to remove\nscanner-specific bias leading to overly optimistic performance estimates and\npoor generalization. We conclude that multi-site data harmonization remains an\nopen challenge and particular care needs to be taken when using such data with\nadvanced machine learning methods for predictive modelling.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:24:42 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Glocker", "Ben", ""], ["Robinson", "Robert", ""], ["Castro", "Daniel C.", ""], ["Dou", "Qi", ""], ["Konukoglu", "Ender", ""]]}, {"id": "1910.04603", "submitter": "Bijun Tang", "authors": "Manzhang Xu, Bijun Tang, Chao Zhu, Yuhao Lu, Chao Zhu, Lu Zheng,\n  Jingyu Zhang, Nannan Han, Yuxi Guo, Jun Di, Pin Song, Yongmin He, Lixing\n  Kang, Zhiyong Zhang, Wu Zhao, Cuntai Guan, Xuewen Wang, Zheng Liu", "title": "Machine learning driven synthesis of few-layered WTe2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing the lateral scale of two-dimensional (2D) materials to\none-dimensional (1D) has attracted substantial research interest not only to\nachieve competitive electronic device applications but also for the exploration\nof fundamental physical properties. Controllable synthesis of high-quality 1D\nnanoribbons (NRs) is thus highly desirable and essential for the further study.\nTraditional exploration of the optimal synthesis conditions of novel materials\nis based on the trial-and-error approach, which is time consuming, costly and\nlaborious. Recently, machine learning (ML) has demonstrated promising\ncapability in guiding material synthesis through effectively learning from the\npast data and then making recommendations. Here, we report the implementation\nof supervised ML for the chemical vapor deposition (CVD) synthesis of\nhigh-quality 1D few-layered WTe2 nanoribbons (NRs). The synthesis parameters of\nthe WTe2 NRs are optimized by the trained ML model. On top of that, the growth\nmechanism of as-synthesized 1T' few-layered WTe2 NRs is further proposed, which\nmay inspire the growth strategies for other 1D nanostructures. Our findings\nsuggest that ML is a powerful and efficient approach to aid the synthesis of 1D\nnanostructures, opening up new opportunities for intelligent material\ndevelopment.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:31:05 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Xu", "Manzhang", ""], ["Tang", "Bijun", ""], ["Zhu", "Chao", ""], ["Lu", "Yuhao", ""], ["Zhu", "Chao", ""], ["Zheng", "Lu", ""], ["Zhang", "Jingyu", ""], ["Han", "Nannan", ""], ["Guo", "Yuxi", ""], ["Di", "Jun", ""], ["Song", "Pin", ""], ["He", "Yongmin", ""], ["Kang", "Lixing", ""], ["Zhang", "Zhiyong", ""], ["Zhao", "Wu", ""], ["Guan", "Cuntai", ""], ["Wang", "Xuewen", ""], ["Liu", "Zheng", ""]]}, {"id": "1910.04615", "submitter": "Pei Wang", "authors": "Pei Wang, Arash Givchi, and Patrick Shafto", "title": "Learning a manifold from a teacher's demonstrations", "comments": "NeurIPS 2020 TDA workshop version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a manifold from a teacher's\ndemonstration. Extending existing approaches of learning from randomly sampled\ndata points, we consider contexts where data may be chosen by a teacher. We\nanalyze learning from teachers who can provide structured data such as\nindividual examples (isolated data points) and demonstrations (sequences of\npoints). Our analysis shows that for the purpose of teaching the topology of a\nmanifold, demonstrations can yield remarkable decreases in the amount of data\npoints required in comparison to teaching with randomly sampled points. We also\ndiscuss the implications of our analysis for learning in humans and machines.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:45:49 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 21:27:56 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 22:14:01 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Wang", "Pei", ""], ["Givchi", "Arash", ""], ["Shafto", "Patrick", ""]]}, {"id": "1910.04618", "submitter": "Hang Gao", "authors": "Hang Gao and Tim Oates", "title": "Universal Adversarial Perturbation for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a state-of-the-art deep neural network text classifier, we show the\nexistence of a universal and very small perturbation vector (in the embedding\nspace) that causes natural text to be misclassified with high probability.\nUnlike images on which a single fixed-size adversarial perturbation can be\nfound, text is of variable length, so we define the \"universality\" as\n\"token-agnostic\", where a single perturbation is applied to each token,\nresulting in different perturbations of flexible sizes at the sequence level.\nWe propose an algorithm to compute universal adversarial perturbations, and\nshow that the state-of-the-art deep neural networks are highly vulnerable to\nthem, even though they keep the neighborhood of tokens mostly preserved. We\nalso show how to use these adversarial perturbations to generate adversarial\ntext samples. The surprising existence of universal \"token-agnostic\"\nadversarial perturbations may reveal important properties of a text classifier.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:48:22 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Gao", "Hang", ""], ["Oates", "Tim", ""]]}, {"id": "1910.04621", "submitter": "Pierre Laforgue", "authors": "Pierre Laforgue, Alex Lambert, Luc Brogat-Motte, Florence\n  d'Alch\\'e-Buc", "title": "Duality in RKHSs with Infinite Dimensional Outputs: Application to\n  Robust Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operator-Valued Kernels (OVKs) and associated vector-valued Reproducing\nKernel Hilbert Spaces provide an elegant way to extend scalar kernel methods\nwhen the output space is a Hilbert space. Although primarily used in finite\ndimension for problems like multi-task regression, the ability of this\nframework to deal with infinite dimensional output spaces unlocks many more\napplications, such as functional regression, structured output prediction, and\nstructured data representation. However, these sophisticated schemes crucially\nrely on the kernel trick in the output space, so that most of previous works\nhave focused on the square norm loss function, completely neglecting robustness\nissues that may arise in such surrogate problems. To overcome this limitation,\nthis paper develops a duality approach that allows to solve OVK machines for a\nwide range of loss functions. The infinite dimensional Lagrange multipliers are\nhandled through a Double Representer Theorem, and algorithms for\n$\\epsilon$-insensitive losses and the Huber loss are thoroughly detailed.\nRobustness benefits are emphasized by a theoretical stability analysis, as well\nas empirical improvements on structured data applications.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:59:28 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 15:45:37 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 09:06:10 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Laforgue", "Pierre", ""], ["Lambert", "Alex", ""], ["Brogat-Motte", "Luc", ""], ["d'Alch\u00e9-Buc", "Florence", ""]]}, {"id": "1910.04636", "submitter": "Yicheng Hong", "authors": "Yicheng (Katherine) Hong", "title": "Comparison of Generative Adversarial Networks Architectures Which Reduce\n  Mode Collapse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks are known for their high quality outputs and\nversatility. However, they also suffer the mode collapse in their output data\ndistribution. There have been many efforts to revamp GANs model and reduce mode\ncollapse. This paper focuses on two of these models, PacGAN and VEEGAN. This\npaper explains the mathematical theory behind aforementioned models, and\ncompare their degree of mode collapse with vanilla GAN using MNIST digits as\ninput data. The result indicates that PacGAN performs slightly better than\nvanilla GAN in terms of mode collapse, and VEEGAN performs worse than both\nPacGAN and vanilla GAN. VEEGAN's poor performance may be attributed to average\nautoencoder loss in its objective function and small penalty for blurry\nfeatures.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 15:17:12 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Yicheng", "", "", "Katherine"], ["Hong", "", ""]]}, {"id": "1910.04650", "submitter": "Yuwen Xiong", "authors": "Yuwen Xiong, Mengye Ren, Raquel Urtasun", "title": "Learning to Remember from a Multi-Task Teacher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on catastrophic forgetting during sequential learning\ntypically focus on fixing the accuracy of the predictions for a previously\nlearned task. In this paper we argue that the outputs of neural networks are\nsubject to rapid changes when learning a new data distribution, and networks\nthat appear to \"forget\" everything still contain useful representation towards\nprevious tasks. Instead of enforcing the output accuracy to stay the same, we\npropose to reduce the effect of catastrophic forgetting on the representation\nlevel, as the output layer can be quickly recovered later with a small number\nof examples. Towards this goal, we propose an experimental setup that measures\nthe amount of representational forgetting, and develop a novel meta-learning\nalgorithm to overcome this issue. The proposed meta-learner produces weight\nupdates of a sequential learning network, mimicking a multi-task teacher\nnetwork's representation. We show that our meta-learner can improve its learned\nrepresentations on new tasks, while maintaining a good representation for old\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 15:33:19 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 07:27:07 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Xiong", "Yuwen", ""], ["Ren", "Mengye", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1910.04658", "submitter": "Rameshwar Pratap", "authors": "Rameshwar Pratap, Debajyoti Bera, Karthik Revanuru", "title": "Efficient Sketching Algorithm for Sparse Binary Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancement of the WWW, IOT, social network, e-commerce, etc. have\ngenerated a large volume of data. These datasets are mostly represented by high\ndimensional and sparse datasets. Many fundamental subroutines of common data\nanalytic tasks such as clustering, classification, ranking, nearest neighbour\nsearch, etc. scale poorly with the dimension of the dataset. In this work, we\naddress this problem and propose a sketching (alternatively, dimensionality\nreduction) algorithm -- $\\binsketch$ (Binary Data Sketch) -- for sparse binary\ndatasets. $\\binsketch$ preserves the binary version of the dataset after\nsketching and maintains estimates for multiple similarity measures such as\nJaccard, Cosine, Inner-Product similarities, and Hamming distance, on the same\nsketch. We present a theoretical analysis of our algorithm and complement it\nwith extensive experimentation on several real-world datasets. We compare the\nperformance of our algorithm with the state-of-the-art algorithms on the task\nof mean-square-error and ranking. Our proposed algorithm offers a comparable\naccuracy while suggesting a significant speedup in the dimensionality reduction\ntime, with respect to the other candidate algorithms. Our proposal is simple,\neasy to implement, and therefore can be adopted in practice.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 15:43:11 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Pratap", "Rameshwar", ""], ["Bera", "Debajyoti", ""], ["Revanuru", "Karthik", ""]]}, {"id": "1910.04665", "submitter": "Clayton Scott", "authors": "Clayton Scott and Jianxin Zhang", "title": "Learning from Multiple Corrupted Sources, with Application to Learning\n  from Label Proportions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study binary classification in the setting where the learner is presented\nwith multiple corrupted training samples, with possibly different sample sizes\nand degrees of corruption, and introduce an approach based on minimizing a\nweighted combination of corruption-corrected empirical risks. We establish a\ngeneralization error bound, and further show that the bound is optimized when\nthe weights are certain interpretable and intuitive functions of the sample\nsizes and degrees of corruptions. We then apply this setting to the problem of\nlearning with label proportions (LLP), and propose an algorithm that enjoys the\nmost general statistical performance guarantees known for LLP. Experiments\ndemonstrate the utility of our theory.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 16:01:42 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Scott", "Clayton", ""], ["Zhang", "Jianxin", ""]]}, {"id": "1910.04689", "submitter": "Paul Bendich", "authors": "Lihan Yao and Paul Bendich", "title": "Graph Spectral Embedding for Parsimonious Transmission of Multivariate\n  Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a graph spectral representation of time series data that 1) is\nparsimoniously encoded to user-demanded resolution; 2) is unsupervised and\nperformant in data-constrained scenarios; 3) captures event and\nevent-transition structure within the time series; and 4) has near-linear\ncomputational complexity in both signal length and ambient dimension. This\nrepresentation, which we call Laplacian Events Signal Segmentation (LESS), can\nbe computed on time series of arbitrary dimension and originating from sensors\nof arbitrary type. Hence, time series originating from sensors of heterogeneous\ntype can be compressed to levels demanded by constrained-communication\nenvironments, before being fused at a common center.\n  Temporal dynamics of the data is summarized without explicit partitioning or\nprobabilistic modeling. As a proof-of-principle, we apply this technique on\nhigh dimensional wavelet coefficients computed from the Free Spoken Digit\nDataset to generate a memory efficient representation that is interpretable.\nDue to its unsupervised and non-parametric nature, LESS representations remain\nperformant in the digit classification task despite the absence of labels and\nlimited data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 16:49:18 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Yao", "Lihan", ""], ["Bendich", "Paul", ""]]}, {"id": "1910.04695", "submitter": "Ethan Shaotran", "authors": "Ethan Shaotran, Jonathan J. Cruz, Vijay Janapa Reddi", "title": "GLADAS: Gesture Learning for Advanced Driver Assistance Systems", "comments": "9 Pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-computer interaction (HCI) is crucial for the safety of lives as\nautonomous vehicles (AVs) become commonplace. Yet, little effort has been put\ntoward ensuring that AVs understand humans on the road. In this paper, we\npresent GLADAS, a simulator-based research platform designed to teach AVs to\nunderstand pedestrian hand gestures. GLADAS supports the training, testing, and\nvalidation of deep learning-based self-driving car gesture recognition systems.\nWe focus on gestures as they are a primordial (i.e, natural and common) way to\ninteract with cars. To the best of our knowledge, GLADAS is the first system of\nits kind designed to provide an infrastructure for further research into\nhuman-AV interaction. We also develop a hand gesture recognition algorithm for\nself-driving cars, using GLADAS to evaluate its performance. Our results show\nthat an AV understands human gestures 85.91% of the time, reinforcing the need\nfor further research into human-AV interaction.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 03:55:45 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Shaotran", "Ethan", ""], ["Cruz", "Jonathan J.", ""], ["Reddi", "Vijay Janapa", ""]]}, {"id": "1910.04700", "submitter": "Zackory Erickson", "authors": "Zackory Erickson, Vamsee Gangaram, Ariel Kapusta, C. Karen Liu, and\n  Charles C. Kemp", "title": "Assistive Gym: A Physics Simulation Framework for Assistive Robotics", "comments": "8 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous robots have the potential to serve as versatile caregivers that\nimprove quality of life for millions of people worldwide. Yet, conducting\nresearch in this area presents numerous challenges, including the risks of\nphysical interaction between people and robots. Physics simulations have been\nused to optimize and train robots for physical assistance, but have typically\nfocused on a single task. In this paper, we present Assistive Gym, an open\nsource physics simulation framework for assistive robots that models multiple\ntasks. It includes six simulated environments in which a robotic manipulator\ncan attempt to assist a person with activities of daily living (ADLs): itch\nscratching, drinking, feeding, body manipulation, dressing, and bathing.\nAssistive Gym models a person's physical capabilities and preferences for\nassistance, which are used to provide a reward function. We present baseline\npolicies trained using reinforcement learning for four different commercial\nrobots in the six environments. We demonstrate that modeling human motion\nresults in better assistance and we compare the performance of different\nrobots. Overall, we show that Assistive Gym is a promising tool for assistive\nrobotics research.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 16:56:55 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Erickson", "Zackory", ""], ["Gangaram", "Vamsee", ""], ["Kapusta", "Ariel", ""], ["Liu", "C. Karen", ""], ["Kemp", "Charles C.", ""]]}, {"id": "1910.04701", "submitter": "Jordan J. Bird", "authors": "Jordan J. Bird, Anik\\'o Ek\\'art, Diego R. Faria", "title": "On the Effects of Pseudo and Quantum Random Number Generators in Soft\n  Computing", "comments": null, "journal-ref": "Soft Computing 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.ET stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we argue that the implications of Pseudo and Quantum Random\nNumber Generators (PRNG and QRNG) inexplicably affect the performances and\nbehaviours of various machine learning models that require a random input.\nThese implications are yet to be explored in Soft Computing until this work. We\nuse a CPU and a QPU to generate random numbers for multiple Machine Learning\ntechniques. Random numbers are employed in the random initial weight\ndistributions of Dense and Convolutional Neural Networks, in which results show\na profound difference in learning patterns for the two. In 50 Dense Neural\nNetworks (25 PRNG/25 QRNG), QRNG increases over PRNG for accent classification\nat +0.1%, and QRNG exceeded PRNG for mental state EEG classification by +2.82%.\nIn 50 Convolutional Neural Networks (25 PRNG/25 QRNG), the MNIST and CIFAR-10\nproblems are benchmarked, in MNIST the QRNG experiences a higher starting\naccuracy than the PRNG but ultimately only exceeds it by 0.02%. In CIFAR-10,\nthe QRNG outperforms PRNG by +0.92%. The n-random split of a Random Tree is\nenhanced towards and new Quantum Random Tree (QRT) model, which has differing\nclassification abilities to its classical counterpart, 200 trees are trained\nand compared (100 PRNG/100 QRNG). Using the accent and EEG classification\ndatasets, a QRT seemed inferior to a RT as it performed on average worse by\n-0.12%. This pattern is also seen in the EEG classification problem, where a\nQRT performs worse than a RT by -0.28%. Finally, the QRT is ensembled into a\nQuantum Random Forest (QRF), which also has a noticeable effect when compared\nto the standard Random Forest (RF)... ABSTRACT SHORTENED DUE TO ARXIV LIMIT\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 16:57:17 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Bird", "Jordan J.", ""], ["Ek\u00e1rt", "Anik\u00f3", ""], ["Faria", "Diego R.", ""]]}, {"id": "1910.04708", "submitter": "Zirui Wang", "authors": "Zirui Wang, Jiateng Xie, Ruochen Xu, Yiming Yang, Graham Neubig, Jaime\n  Carbonell", "title": "Cross-lingual Alignment vs Joint Training: A Comparative Study and A\n  Simple Unified Framework", "comments": "Published as a conference paper at ICLR 2020. First two authors\n  contributed equally. Source code is available at\n  https://github.com/thespectrewithin/joint-align", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning multilingual representations of text has proven a successful method\nfor many cross-lingual transfer learning tasks. There are two main paradigms\nfor learning such representations: (1) alignment, which maps different\nindependently trained monolingual representations into a shared space, and (2)\njoint training, which directly learns unified multilingual representations\nusing monolingual and cross-lingual objectives jointly. In this paper, we first\nconduct direct comparisons of representations learned using both of these\nmethods across diverse cross-lingual tasks. Our empirical results reveal a set\nof pros and cons for both methods, and show that the relative performance of\nalignment versus joint training is task-dependent. Stemming from this analysis,\nwe propose a simple and novel framework that combines these two previously\nmutually-exclusive approaches. Extensive experiments demonstrate that our\nproposed framework alleviates limitations of both approaches, and outperforms\nexisting methods on the MUSE bilingual lexicon induction (BLI) benchmark. We\nfurther show that this framework can generalize to contextualized\nrepresentations such as Multilingual BERT, and produces state-of-the-art\nresults on the CoNLL cross-lingual NER benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:04:30 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 16:34:25 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 20:48:45 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 00:59:03 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Wang", "Zirui", ""], ["Xie", "Jiateng", ""], ["Xu", "Ruochen", ""], ["Yang", "Yiming", ""], ["Neubig", "Graham", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1910.04709", "submitter": "Andrea Moscatelli", "authors": "Andrea Moscatelli", "title": "Modeling of negative protein-protein interactions: methods and\n  experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Protein-protein interactions (PPIs) are of fundamental importance for the\nhuman body, and the knowledge of their existence can facilitate very important\ntasks like drug target developing and therapy design. The high-throughput\nexperiments for detecting new PPIs are costly and time-consuming, stressing the\nneed for new computational systems able to generate high-quality PPIs\npredictions. These systems have to face two main problems: the high\nincompleteness of the human interactome and the lack of high-quality negative\nprotein-protein interactions (i.e. proteins that are known to not interact).\nThe latter is usually overlooked by the PPIs prediction systems, causing a\nsignificant bias in the performances and metrics. In this work, we compare\nmethods for simulating negative knowledge using highly reliable training and\ntest sets. Moreover, we measure the performances of two state-of-the-art\nsystems when very reliable settings are adopted.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:06:36 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Moscatelli", "Andrea", ""]]}, {"id": "1910.04721", "submitter": "David Wood", "authors": "David Wood, James Cole, Thomas Booth", "title": "NEURO-DRAM: a 3D recurrent visual attention model for interpretable\n  neuroimaging classification", "comments": "Improved network figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is attracting significant interest in the neuroimaging\ncommunity as a means to diagnose psychiatric and neurological disorders from\nstructural magnetic resonance images. However, there is a tendency amongst\nresearchers to adopt architectures optimized for traditional computer vision\ntasks, rather than design networks customized for neuroimaging data. We address\nthis by introducing NEURO-DRAM, a 3D recurrent visual attention model tailored\nfor neuroimaging classification. The model comprises an agent which, trained by\nreinforcement learning, learns to navigate through volumetric images,\nselectively attending to the most informative regions for a given task. When\napplied to Alzheimer's disease prediction, NEURODRAM achieves state-of-the-art\nclassification accuracy on an out-of-sample dataset, significantly\noutperforming a baseline convolutional neural network. When further applied to\nthe task of predicting which patients with mild cognitive impairment will be\ndiagnosed with Alzheimer's disease within two years, the model achieves\nstate-of-the-art accuracy with no additional training. Encouragingly, the agent\nlearns, without explicit instruction, a search policy in agreement with\nstandardized radiological hallmarks of Alzheimer's disease, suggesting a route\nto automated biomarker discovery for more poorly understood disorders.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:28:35 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 14:44:50 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 18:55:12 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Wood", "David", ""], ["Cole", "James", ""], ["Booth", "Thomas", ""]]}, {"id": "1910.04724", "submitter": "Hang Gao", "authors": "Karan K. Budhraja and Hang Gao and Tim Oates", "title": "Using Neural Networks for Programming by Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based modeling is a paradigm of modeling dynamic systems of interacting\nagents that are individually governed by specified behavioral rules. Training a\nmodel of such agents to produce an emergent behavior by specification of the\nemergent (as opposed to agent) behavior is easier from a demonstration\nperspective. Without the involvement of manual behavior specification via code\nor reliance on a defined taxonomy of possible behaviors, the demonstrator\nspecifies the desired emergent behavior of the system over time, and retrieves\nagent-level parameters required to execute that motion. A low time-complexity\nand data requirement favoring framework for reproducing emergent behavior,\ngiven an abstract demonstration, is discussed in [1], [2]. The existing\nframework does, however, observe an inherent limitation in scalability because\nof an exponentially growing search space (with the number of agent-level\nparameters). Our work addresses this limitation by pursuing a more scalable\narchitecture with the use of neural networks. While the (proof-of-concept)\narchitecture is not suitable for many evaluated domains because of its lack of\nrepresentational capacity for that domain, it is more suitable than existing\nwork for larger datasets for the Civil Violence agent-based model.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:32:59 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Budhraja", "Karan K.", ""], ["Gao", "Hang", ""], ["Oates", "Tim", ""]]}, {"id": "1910.04728", "submitter": "Jialin Ding", "authors": "Darryl Ho, Jialin Ding, Sanchit Misra, Nesime Tatbul, Vikram Nathan,\n  Vasimuddin Md, Tim Kraska", "title": "LISA: Towards Learned DNA Sequence Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next-generation sequencing (NGS) technologies have enabled affordable\nsequencing of billions of short DNA fragments at high throughput, paving the\nway for population-scale genomics. Genomics data analytics at this scale\nrequires overcoming performance bottlenecks, such as searching for short DNA\nsequences over long reference sequences. In this paper, we introduce LISA\n(Learned Indexes for Sequence Analysis), a novel learning-based approach to DNA\nsequence search. As a first proof of concept, we focus on accelerating one of\nthe most essential flavors of the problem, called exact search. LISA builds on\nand extends FM-index, which is the state-of-the-art technique widely deployed\nin genomics tool-chains. Initial experiments with human genome datasets\nindicate that LISA achieves up to a factor of 4X performance speedup against\nits traditional counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:41:53 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Ho", "Darryl", ""], ["Ding", "Jialin", ""], ["Misra", "Sanchit", ""], ["Tatbul", "Nesime", ""], ["Nathan", "Vikram", ""], ["Md", "Vasimuddin", ""], ["Kraska", "Tim", ""]]}, {"id": "1910.04729", "submitter": "Muhammad Burhan Hafez", "authors": "Muhammad Burhan Hafez, Cornelius Weber, Matthias Kerzel and Stefan\n  Wermter", "title": "Efficient Intrinsically Motivated Robotic Grasping with\n  Learning-Adaptive Imagination in Latent Space", "comments": "In: Proceedings of the Joint IEEE International Conference on\n  Development and Learning and on Epigenetic Robotics (ICDL-EpiRob), Oslo,\n  Norway, Aug. 19-22, 2019", "journal-ref": null, "doi": "10.1109/DEVLRN.2019.8850723", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining model-based and model-free deep reinforcement learning has shown\ngreat promise for improving sample efficiency on complex control tasks while\nstill retaining high performance. Incorporating imagination is a recent effort\nin this direction inspired by human mental simulation of motor behavior. We\npropose a learning-adaptive imagination approach which, unlike previous\napproaches, takes into account the reliability of the learned dynamics model\nused for imagining the future. Our approach learns an ensemble of disjoint\nlocal dynamics models in latent space and derives an intrinsic reward based on\nlearning progress, motivating the controller to take actions leading to data\nthat improves the models. The learned models are used to generate imagined\nexperiences, augmenting the training set of real experiences. We evaluate our\napproach on learning vision-based robotic grasping and show that it\nsignificantly improves sample efficiency and achieves near-optimal performance\nin a sparse reward environment.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:43:05 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Hafez", "Muhammad Burhan", ""], ["Weber", "Cornelius", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "1910.04732", "submitter": "Jeremy Wohlwend", "authors": "Ziheng Wang, Jeremy Wohlwend, Tao Lei", "title": "Structured Pruning of Large Language Models", "comments": null, "journal-ref": null, "doi": "10.18653/v1/2020.emnlp-main.496", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large language models have recently achieved state of the art performance\nacross a wide variety of natural language tasks. Meanwhile, the size of these\nmodels and their latency have significantly increased, which makes their usage\ncostly, and raises an interesting question: do language models need to be\nlarge? We study this question through the lens of model compression. We present\na generic, structured pruning approach by parameterizing each weight matrix\nusing its low-rank factorization, and adaptively removing rank-1 components\nduring training. On language modeling tasks, our structured approach\noutperforms other unstructured and block-structured pruning baselines at\nvarious compression levels, while achieving significant speedups during both\ntraining and inference. We also demonstrate that our method can be applied to\npruning adaptive word embeddings in large language models, and to pruning the\nBERT model on several downstream fine-tuning classification benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:44:18 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 19:04:25 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Wang", "Ziheng", ""], ["Wohlwend", "Jeremy", ""], ["Lei", "Tao", ""]]}, {"id": "1910.04736", "submitter": "Hironori Washizaki", "authors": "Hironori Washizaki, Hiromu Uchida, Foutse Khomh, Yann-Gael Gueheneuc", "title": "Studying Software Engineering Patterns for Designing Machine Learning\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning (ML) techniques have become popular in the recent years. ML\ntechniques rely on mathematics and on software engineering. Researchers and\npractitioners studying best practices for designing ML application systems and\nsoftware to address the software complexity and quality of ML techniques. Such\ndesign practices are often formalized as architecture patterns and design\npatterns by encapsulating reusable solutions to commonly occurring problems\nwithin given contexts. However, to the best of our knowledge, there has been no\nwork collecting, classifying, and discussing these software-engineering (SE)\ndesign patterns for ML techniques systematically. Thus, we set out to collect\ngood/bad SE design patterns for ML techniques to provide developers with a\ncomprehensive and ordered classification of such patterns. We report here\npreliminary results of a systematic-literature review (SLR) of good/bad design\npatterns for ML.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:45:51 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 13:55:48 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Washizaki", "Hironori", ""], ["Uchida", "Hiromu", ""], ["Khomh", "Foutse", ""], ["Gueheneuc", "Yann-Gael", ""]]}, {"id": "1910.04739", "submitter": "Bj\\\"orn Friedrich", "authors": "Bj\\\"orn Friedrich, Benjamin Cauchy, Andreas Hein, Sebastian Fudickar", "title": "Transportation Mode Classification from Smartphone Sensors via a\n  Long-Short-Term-Memory Network", "comments": "5 pages, 6 figures, 2 tables, ubicomp19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces the architecture of a Long-Short-Term Memory network\nfor classifying transportation-modes via Smartphone data and evaluates its\naccuracy. By using a Long-Short-Term-Memory Network with common preprocessing\nsteps such as normalisation for classification tasks a F1-Score accuracy of\n63.68\\% was achieved with an internal test dataset. We participated as Team\n'GanbareAM' in the 'SHL recognition challenge'.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:47:25 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Friedrich", "Bj\u00f6rn", ""], ["Cauchy", "Benjamin", ""], ["Hein", "Andreas", ""], ["Fudickar", "Sebastian", ""]]}, {"id": "1910.04742", "submitter": "Jessica Lee", "authors": "Jessica Lee, Deva Ramanan and Rohit Girdhar", "title": "MetaPix: Few-Shot Video Retargeting", "comments": "Short version accepted to NeurIPS'19 MetaLearn Workshop. Full version\n  accepted to ICLR 2020. Webpage: https://imjal.github.io/MetaPix/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of unsupervised retargeting of human actions from one\nvideo to another. We consider the challenging setting where only a few frames\nof the target is available. The core of our approach is a conditional\ngenerative model that can transcode input skeletal poses (automatically\nextracted with an off-the-shelf pose estimator) to output target frames.\nHowever, it is challenging to build a universal transcoder because humans can\nappear wildly different due to clothing and background scene geometry. Instead,\nwe learn to adapt - or personalize - a universal generator to the particular\nhuman and background in the target. To do so, we make use of meta-learning to\ndiscover effective strategies for on-the-fly personalization. One significant\nbenefit of meta-learning is that the personalized transcoder naturally enforces\ntemporal coherence across its generated frames; all frames contain consistent\nclothing and background geometry of the target. We experiment on in-the-wild\ninternet videos and images and show our approach improves over widely-used\nbaselines for the task.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:51:44 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 21:09:45 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Lee", "Jessica", ""], ["Ramanan", "Deva", ""], ["Girdhar", "Rohit", ""]]}, {"id": "1910.04743", "submitter": "Daniel LeJeune", "authors": "Daniel LeJeune, Hamid Javadi, Richard G. Baraniuk", "title": "The Implicit Regularization of Ordinary Least Squares Ensembles", "comments": "18 pages, 4 figures. To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensemble methods that average over a collection of independent predictors\nthat are each limited to a subsampling of both the examples and features of the\ntraining data command a significant presence in machine learning, such as the\never-popular random forest, yet the nature of the subsampling effect,\nparticularly of the features, is not well understood. We study the case of an\nensemble of linear predictors, where each individual predictor is fit using\nordinary least squares on a random submatrix of the data matrix. We show that,\nunder standard Gaussianity assumptions, when the number of features selected\nfor each predictor is optimally tuned, the asymptotic risk of a large ensemble\nis equal to the asymptotic ridge regression risk, which is known to be optimal\namong linear predictors in this setting. In addition to eliciting this implicit\nregularization that results from subsampling, we also connect this ensemble to\nthe dropout technique used in training deep (neural) networks, another strategy\nthat has been shown to have a ridge-like regularizing effect.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:52:07 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 18:46:30 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["LeJeune", "Daniel", ""], ["Javadi", "Hamid", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1910.04749", "submitter": "Ximing Qiao", "authors": "Ximing Qiao, Yukun Yang, Hai Li", "title": "Defending Neural Backdoors via Generative Distribution Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural backdoor attack is emerging as a severe security threat to deep\nlearning, while the capability of existing defense methods is limited,\nespecially for complex backdoor triggers. In the work, we explore the space\nformed by the pixel values of all possible backdoor triggers. An original\ntrigger used by an attacker to build the backdoored model represents only a\npoint in the space. It then will be generalized into a distribution of valid\ntriggers, all of which can influence the backdoored model. Thus, previous\nmethods that model only one point of the trigger distribution is not\nsufficient. Getting the entire trigger distribution, e.g., via generative\nmodeling, is a key to effective defense. However, existing generative modeling\ntechniques for image generation are not applicable to the backdoor scenario as\nthe trigger distribution is completely unknown. In this work, we propose\nmax-entropy staircase approximator (MESA), an algorithm for high-dimensional\nsampling-free generative modeling and use it to recover the trigger\ndistribution. We also develop a defense technique to remove the triggers from\nthe backdoored model. Our experiments on Cifar10/100 dataset demonstrate the\neffectiveness of MESA in modeling the trigger distribution and the robustness\nof the proposed defense method.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:55:49 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 01:38:01 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Qiao", "Ximing", ""], ["Yang", "Yukun", ""], ["Li", "Hai", ""]]}, {"id": "1910.04751", "submitter": "Bowen Cheng", "authors": "Bowen Cheng and Maxwell D. Collins and Yukun Zhu and Ting Liu and\n  Thomas S. Huang and Hartwig Adam and Liang-Chieh Chen", "title": "Panoptic-DeepLab", "comments": "This work is presented at ICCV 2019 Joint COCO and Mapillary\n  Recognition Challenge Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Panoptic-DeepLab, a bottom-up and single-shot approach for\npanoptic segmentation. Our Panoptic-DeepLab is conceptually simple and delivers\nstate-of-the-art results. In particular, we adopt the dual-ASPP and\ndual-decoder structures specific to semantic, and instance segmentation,\nrespectively. The semantic segmentation branch is the same as the typical\ndesign of any semantic segmentation model (e.g., DeepLab), while the instance\nsegmentation branch is class-agnostic, involving a simple instance center\nregression. Our single Panoptic-DeepLab sets the new state-of-art at all three\nCityscapes benchmarks, reaching 84.2% mIoU, 39.0% AP, and 65.5% PQ on test set,\nand advances results on the other challenging Mapillary Vistas.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:57:19 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 15:27:18 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 01:13:12 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Cheng", "Bowen", ""], ["Collins", "Maxwell D.", ""], ["Zhu", "Yukun", ""], ["Liu", "Ting", ""], ["Huang", "Thomas S.", ""], ["Adam", "Hartwig", ""], ["Chen", "Liang-Chieh", ""]]}, {"id": "1910.04753", "submitter": "Andre Nguyen", "authors": "Andre T. Nguyen, Edward Raff, Aaron Sant-Miller", "title": "Would a File by Any Other Name Seem as Malicious?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful malware attacks on information technology systems can cause\nmillions of dollars in damage, the exposure of sensitive and private\ninformation, and the irreversible destruction of data. Anti-virus systems that\nanalyze a file's contents use a combination of static and dynamic analysis to\ndetect and remove/remediate such malware. However, examining a file's entire\ncontents is not always possible in practice, as the volume and velocity of\nincoming data may be too high, or access to the underlying file contents may be\nrestricted or unavailable. If it were possible to obtain estimates of a file's\nrelative likelihood of being malicious without looking at the file contents, we\ncould better prioritize file processing order and aid analysts in situations\nwhere a file is unavailable. In this work, we demonstrate that file names can\ncontain information predictive of the presence of malware in a file. In\nparticular, we show the effectiveness of a character-level convolutional neural\nnetwork at predicting malware status using file names on Endgame's EMBER\nmalware detection benchmark dataset.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 00:02:19 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Nguyen", "Andre T.", ""], ["Raff", "Edward", ""], ["Sant-Miller", "Aaron", ""]]}, {"id": "1910.04756", "submitter": "Yuwei Fan", "authors": "Yuwei Fan, Lexing Ying", "title": "Solving Optical Tomography with Deep Learning", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a neural network approach for solving two-dimensional\noptical tomography (OT) problems based on the radiative transfer equation. The\nmathematical problem of OT is to recover the optical properties of an object\nbased on the albedo operator that is accessible from boundary measurements.\nBoth the forward map from the optical properties to the albedo operator and the\ninverse map are high-dimensional and nonlinear. For the circular tomography\ngeometry, a perturbative analysis shows that the forward map can be\napproximated by a vectorized convolution operator in the angular direction.\nMotivated by this, we propose effective neural network architectures for the\nforward and inverse maps based on convolution layers, with weights learned from\ntraining datasets. Numerical results demonstrate the efficiency of the proposed\nneural networks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 07:44:42 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Fan", "Yuwei", ""], ["Ying", "Lexing", ""]]}, {"id": "1910.04760", "submitter": "Qi Li", "authors": "Qi Li, Long Mai, Michael A. Alcorn, Anh Nguyen", "title": "A cost-effective method for improving and re-purposing large,\n  pre-trained GANs by fine-tuning their class-embeddings", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large, pre-trained generative models have been increasingly popular and\nuseful to both the research and wider communities. Specifically, BigGANs a\nclass-conditional Generative Adversarial Networks trained on\nImageNet---achieved excellent, state-of-the-art capability in generating\nrealistic photos. However, fine-tuning or training BigGANs from scratch is\npractically impossible for most researchers and engineers because (1) GAN\ntraining is often unstable and suffering from mode-collapse; and (2) the\ntraining requires a significant amount of computation, 256 Google TPUs for 2\ndays or 8xV100 GPUs for 15 days. Importantly, many pre-trained generative\nmodels both in NLP and image domains were found to contain biases that are\nharmful to society. Thus, we need computationally-feasible methods for\nmodifying and re-purposing these huge, pre-trained models for downstream tasks.\nIn this paper, we propose a cost-effective optimization method for improving\nand re-purposing BigGANs by fine-tuning only the class-embedding layer. We show\nthe effectiveness of our model-editing approach in three tasks: (1)\nsignificantly improving the realism and diversity of samples of complete\nmode-collapse classes; (2) re-purposing ImageNet BigGANs for generating images\nfor Places365; and (3) de-biasing or improving the sample diversity for\nselected ImageNet classes.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 15:18:28 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 18:34:35 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 06:35:26 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 21:46:34 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Li", "Qi", ""], ["Mai", "Long", ""], ["Alcorn", "Michael A.", ""], ["Nguyen", "Anh", ""]]}, {"id": "1910.04778", "submitter": "Hengrui Luo", "authors": "Hengrui Luo, Justin Strait", "title": "Combining Geometric and Topological Information for Boundary Estimation", "comments": "38 pages with appendices, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in computer vision is boundary estimation, where the\ngoal is to delineate the boundary of objects in an image. In this paper, we\npropose a method which jointly incorporates geometric and topological\ninformation within an image to simultaneously estimate boundaries for objects\nwithin images with more complex topologies. We use a topological\nclustering-based method to assist initialization of the Bayesian active contour\nmodel. This combines pixel clustering, boundary smoothness, and potential prior\nshape information to produce an estimated object boundary. Active contour\nmethods are knownto be extremely sensitive to algorithm initialization, relying\non the user to provide a reasonable starting curve to the algorithm. In the\npresence of images featuring objects with complex topological structures, such\nas objects with holes or multiple objects, the user must initialize separate\ncurves for each boundary of interest. Our proposed topologically-guided method\ncan provide an interpretable, smart initialization in these settings, freeing\nup the user from potential pitfalls associated with objects of complex\ntopological structure. We provide a detailed simulation study comparing our\ninitialization to boundary estimates obtained from standard segmentation\nalgorithms. The method is demonstrated on artificial image datasets from\ncomputer vision, as well as real-world applications to skin lesion and neural\ncellular images, for which multiple topological features can be identified.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 18:00:10 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 15:36:03 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 23:27:16 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Luo", "Hengrui", ""], ["Strait", "Justin", ""]]}, {"id": "1910.04792", "submitter": "Shruti Jadon", "authors": "Shruti Jadon, Mahmood Jasim", "title": "Unsupervised video summarization framework using keyframe extraction and\n  video skimming", "comments": "5 pages, 3 figures. Technical Report", "journal-ref": "2020 IEEE 5th International Conference on Computing Communication\n  and Automation (ICCCA)", "doi": "10.1109/ICCCA49541.2020.9250764", "report-no": "140 - 145", "categories": "cs.IR cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Video is one of the robust sources of information and the consumption of\nonline and offline videos has reached an unprecedented level in the last few\nyears. A fundamental challenge of extracting information from videos is a\nviewer has to go through the complete video to understand the context, as\nopposed to an image where the viewer can extract information from a single\nframe. Apart from context understanding, it almost impossible to create a\nuniversal summarized video for everyone, as everyone has their own bias of\nkeyframe, e.g; In a soccer game, a coach person might consider those frames\nwhich consist of information on player placement, techniques, etc; however, a\nperson with less knowledge about a soccer game, will focus more on frames which\nconsist of goals and score-board. Therefore, if we were to tackle problem video\nsummarization through a supervised learning path, it will require extensive\npersonalized labeling of data. In this paper, we attempt to solve video\nsummarization through unsupervised learning by employing traditional\nvision-based algorithmic methodologies for accurate feature extraction from\nvideo frames. We have also proposed a deep learning-based feature extraction\nfollowed by multiple clustering methods to find an effective way of summarizing\na video by interesting key-frame extraction. We have compared the performance\nof these approaches on the SumMe dataset and showcased that using deep\nlearning-based feature extraction has been proven to perform better in case of\ndynamic viewpoint videos.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 18:14:48 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 18:27:25 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Jadon", "Shruti", ""], ["Jasim", "Mahmood", ""]]}, {"id": "1910.04803", "submitter": "Dong Chen", "authors": "Dong Chen, Longsheng Jiang, Yue Wang, Zhaojian Li", "title": "Autonomous Driving using Safe Reinforcement Learning by Incorporating a\n  Regret-based Human Lane-Changing Decision Model", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is expected that many human drivers will still prefer to drive themselves\neven if the self-driving technologies are ready. Therefore, human-driven\nvehicles and autonomous vehicles (AVs) will coexist in a mixed traffic for a\nlong time. To enable AVs to safely and efficiently maneuver in this mixed\ntraffic, it is critical that the AVs can understand how humans cope with risks\nand make driving-related decisions. On the other hand, the driving environment\nis highly dynamic and ever-changing, and it is thus difficult to enumerate all\nthe scenarios and hard-code the controllers. To face up these challenges, in\nthis work, we incorporate a human decision-making model in reinforcement\nlearning to control AVs for safe and efficient operations. Specifically, we\nadapt regret theory to describe a human driver's lane-changing behavior, and\nfit the personalized models to individual drivers for predicting their\nlane-changing decisions. The predicted decisions are incorporated in the safety\nconstraints for reinforcement learning in training and in implementation. We\nthen use an extended version of double deep Q-network (DDQN) to train our AV\ncontroller within the safety set. By doing so, the amount of collisions in\ntraining is reduced to zero, while the training accuracy is not impinged.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 18:33:42 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Chen", "Dong", ""], ["Jiang", "Longsheng", ""], ["Wang", "Yue", ""], ["Li", "Zhaojian", ""]]}, {"id": "1910.04807", "submitter": "Weiwei Gu", "authors": "Weiwei Gu, Fei Gao, Xiaodan Lou, Jiang Zhang", "title": "Link Prediction via Graph Attention Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction aims to infer missing links or predicting the future ones\nbased on currently observed partial networks, it is a fundamental problem in\nnetwork science with tremendous real-world applications. However, conventional\nlink prediction approaches neither have high prediction accuracy nor being\ncapable of revealing the hidden information behind links. To address this\nproblem, we generalize the latest techniques in deep learning on graphs and\npresent a new link prediction model - DeepLinker. Instead of learning node\nrepresentation with the node label information, DeepLinker uses the links as\nsupervised information. Experiments on five graphs show that DeepLinker can not\nonly achieve the state-of-the-art link prediction accuracy, but also acquire\nthe efficient node representations and node centrality ranking as the\nbyproducts. Although the representations are obtained without any supervised\nnode label information, they still perform well on node ranking and node\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 18:41:54 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 18:57:00 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 15:32:47 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Gu", "Weiwei", ""], ["Gao", "Fei", ""], ["Lou", "Xiaodan", ""], ["Zhang", "Jiang", ""]]}, {"id": "1910.04814", "submitter": "Nima Tajbakhsh", "authors": "Nima Tajbakhsh, Brian Lai, Shilpa Ananth, Xiaowei Ding", "title": "ErrorNet: Learning error representations from limited data to improve\n  vascular segmentation", "comments": "Accepted in ISBI 2019. The supplementary material is only available\n  in the arxiv version of our paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have proved effective in segmenting\nlesions and anatomies in various medical imaging modalities. However, in the\npresence of small sample size and domain shift problems, these models often\nproduce masks with non-intuitive segmentation mistakes. In this paper, we\npropose a segmentation framework called ErrorNet, which learns to correct these\nsegmentation mistakes through the repeated process of injecting systematic\nsegmentation errors to the segmentation result based on a learned shape prior,\nfollowed by attempting to predict the injected error. During inference,\nErrorNet corrects the segmentation mistakes by adding the predicted error map\nto the initial segmentation result. ErrorNet has advantages over alternatives\nbased on domain adaptation or CRF-based post processing, because it requires\nneither domain-specific parameter tuning nor any data from the target domains.\nWe have evaluated ErrorNet using five public datasets for the task of retinal\nvessel segmentation. The selected datasets differ in size and patient\npopulation, allowing us to evaluate the effectiveness of ErrorNet in handling\nsmall sample size and domain shift problems. Our experiments demonstrate that\nErrorNet outperforms a base segmentation model, a CRF-based post processing\nscheme, and a domain adaptation method, with a greater performance gain in the\npresence of the aforementioned dataset limitations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 18:54:15 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 21:24:28 GMT"}, {"version": "v3", "created": "Sat, 18 Jan 2020 19:40:57 GMT"}, {"version": "v4", "created": "Sun, 2 Feb 2020 00:40:05 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Tajbakhsh", "Nima", ""], ["Lai", "Brian", ""], ["Ananth", "Shilpa", ""], ["Ding", "Xiaowei", ""]]}, {"id": "1910.04817", "submitter": "Maggie Makar", "authors": "Maggie Makar, Fredrik D. Johansson, John Guttag, David Sontag", "title": "Estimation of Bounds on Potential Outcomes For Decision Making", "comments": null, "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of individual treatment effects is commonly used as the basis for\ncontextual decision making in fields such as healthcare, education, and\neconomics. However, it is often sufficient for the decision maker to have\nestimates of upper and lower bounds on the potential outcomes of decision\nalternatives to assess risks and benefits. We show that, in such cases, we can\nimprove sample efficiency by estimating simple functions that bound these\noutcomes instead of estimating their conditional expectations, which may be\ncomplex and hard to estimate. Our analysis highlights a trade-off between the\ncomplexity of the learning task and the confidence with which the learned\nbounds hold. Guided by these findings, we develop an algorithm for learning\nupper and lower bounds on potential outcomes which optimize an objective\nfunction defined by the decision maker, subject to the probability that bounds\nare violated being small. Using a clinical dataset and a well-known causality\nbenchmark, we demonstrate that our algorithm outperforms baselines, providing\ntighter, more reliable bounds.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 19:07:08 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 19:40:17 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 21:34:35 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 04:26:34 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Makar", "Maggie", ""], ["Johansson", "Fredrik D.", ""], ["Guttag", "John", ""], ["Sontag", "David", ""]]}, {"id": "1910.04819", "submitter": "Theodoros Tsiligkaridis", "authors": "Theodoros Tsiligkaridis", "title": "Information Aware Max-Norm Dirichlet Networks for Predictive Uncertainty\n  Estimation", "comments": "To appear in Neural Networks.\n  https://doi.org/10.1016/j.neunet.2020.12.011", "journal-ref": "Neural Networks, Volume 135, March 2021, Pages 105-114", "doi": "10.1016/j.neunet.2020.12.011", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise estimation of uncertainty in predictions for AI systems is a critical\nfactor in ensuring trust and safety. Deep neural networks trained with a\nconventional method are prone to over-confident predictions. In contrast to\nBayesian neural networks that learn approximate distributions on weights to\ninfer prediction confidence, we propose a novel method, Information Aware\nDirichlet networks, that learn an explicit Dirichlet prior distribution on\npredictive distributions by minimizing a bound on the expected max norm of the\nprediction error and penalizing information associated with incorrect outcomes.\nProperties of the new cost function are derived to indicate how improved\nuncertainty estimation is achieved. Experiments using real datasets show that\nour technique outperforms, by a large margin, state-of-the-art neural networks\nfor estimating within-distribution and out-of-distribution uncertainty, and\ndetecting adversarial examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 19:10:42 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 18:44:49 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 00:32:23 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 16:13:24 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Tsiligkaridis", "Theodoros", ""]]}, {"id": "1910.04832", "submitter": "Sui Tang", "authors": "Fei Lu, Mauro Maggioni, Sui Tang", "title": "Learning interaction kernels in heterogeneous systems of agents from\n  multiple trajectories", "comments": "63 pages, revised various places", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems of interacting particles or agents have wide applications in many\ndisciplines such as Physics, Chemistry, Biology and Economics. These systems\nare governed by interaction laws, which are often unknown: estimating them from\nobservation data is a fundamental task that can provide meaningful insights and\naccurate predictions of the behaviour of the agents. In this paper, we consider\nthe inverse problem of learning interaction laws given data from multiple\ntrajectories, in a nonparametric fashion, when the interaction kernels depend\non pairwise distances. We establish a condition for learnability of interaction\nkernels, and construct estimators that are guaranteed to converge in a suitable\n$L^2$ space, at the optimal min-max rate for 1-dimensional nonparametric\nregression. We propose an efficient learning algorithm based on least squares,\nwhich can be implemented in parallel for multiple trajectories and is therefore\nwell-suited for the high dimensional, big data regime. Numerical simulations on\na variety examples, including opinion dynamics, predator-swarm dynamics and\nheterogeneous particle dynamics, suggest that the learnability condition is\nsatisfied in models used in practice, and the rate of convergence of our\nestimator is consistent with the theory. These simulations also suggest that\nour estimators are robust to noise in the observations, and produce accurate\npredictions of dynamics in relative large time intervals, even when they are\nlearned from data collected in short time intervals.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 19:54:04 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 20:44:42 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 00:48:14 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Lu", "Fei", ""], ["Maggioni", "Mauro", ""], ["Tang", "Sui", ""]]}, {"id": "1910.04849", "submitter": "Lu Wang", "authors": "Xinyun Chen, Lu Wang, Yizhe Hang, Heng Ge, Hongyuan Zha", "title": "Infinite-horizon Off-Policy Policy Evaluation with Multiple Behavior\n  Policies", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider off-policy policy evaluation when the trajectory data are\ngenerated by multiple behavior policies. Recent work has shown the key role\nplayed by the state or state-action stationary distribution corrections in the\ninfinite horizon context for off-policy policy evaluation. We propose estimated\nmixture policy (EMP), a novel class of partially policy-agnostic methods to\naccurately estimate those quantities. With careful analysis, we show that EMP\ngives rise to estimates with reduced variance for estimating the state\nstationary distribution correction while it also offers a useful induction bias\nfor estimating the state-action stationary distribution correction. In\nextensive experiments with both continuous and discrete environments, we\ndemonstrate that our algorithm offers significantly improved accuracy compared\nto the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 21:01:07 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Chen", "Xinyun", ""], ["Wang", "Lu", ""], ["Hang", "Yizhe", ""], ["Ge", "Heng", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1910.04851", "submitter": "Charles Corbi\\`ere", "authors": "Charles Corbi\\`ere, Nicolas Thome, Avner Bar-Hen, Matthieu Cord,\n  Patrick P\\'erez", "title": "Addressing Failure Prediction by Learning Model Confidence", "comments": "NeurIPS 2019 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing reliably the confidence of a deep neural network and predicting its\nfailures is of primary importance for the practical deployment of these models.\nIn this paper, we propose a new target criterion for model confidence,\ncorresponding to the True Class Probability (TCP). We show how using the TCP is\nmore suited than relying on the classic Maximum Class Probability (MCP). We\nprovide in addition theoretical guarantees for TCP in the context of failure\nprediction. Since the true class is by essence unknown at test time, we propose\nto learn TCP criterion on the training set, introducing a specific learning\nscheme adapted to this context. Extensive experiments are conducted for\nvalidating the relevance of the proposed approach. We study various network\narchitectures, small and large scale datasets for image classification and\nsemantic segmentation. We show that our approach consistently outperforms\nseveral strong methods, from MCP to Bayesian uncertainty, as well as recent\napproaches specifically designed for failure prediction.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 08:23:45 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 15:09:46 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Corbi\u00e8re", "Charles", ""], ["Thome", "Nicolas", ""], ["Bar-Hen", "Avner", ""], ["Cord", "Matthieu", ""], ["P\u00e9rez", "Patrick", ""]]}, {"id": "1910.04855", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias and Stefanos Zafeiriou", "title": "Expression, Affect, Action Unit Recognition: Aff-Wild2, Multi-Task\n  Learning and ArcFace", "comments": "oral presentation in BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affective computing has been largely limited in terms of available data\nresources. The need to collect and annotate diverse in-the-wild datasets has\nbecome apparent with the rise of deep learning models, as the default approach\nto address any computer vision task. Some in-the-wild databases have been\nrecently proposed. However: i) their size is small, ii) they are not\naudiovisual, iii) only a small part is manually annotated, iv) they contain a\nsmall number of subjects, or v) they are not annotated for all main behavior\ntasks (valence-arousal estimation, action unit detection and basic expression\nclassification). To address these, we substantially extend the largest\navailable in-the-wild database (Aff-Wild) to study continuous emotions such as\nvalence and arousal. Furthermore, we annotate parts of the database with basic\nexpressions and action units. As a consequence, for the first time, this allows\nthe joint study of all three types of behavior states. We call this database\nAff-Wild2. We conduct extensive experiments with CNN and CNN-RNN architectures\nthat use visual and audio modalities; these networks are trained on Aff-Wild2\nand their performance is then evaluated on 10 publicly available emotion\ndatabases. We show that the networks achieve state-of-the-art performance for\nthe emotion recognition tasks. Additionally, we adapt the ArcFace loss function\nin the emotion recognition context and use it for training two new networks on\nAff-Wild2 and then re-train them in a variety of diverse expression recognition\ndatabases. The networks are shown to improve the existing state-of-the-art. The\ndatabase, emotion recognition models and source code are available at\nhttp://ibug.doc.ic.ac.uk/resources/aff-wild2.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:45:18 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1910.04856", "submitter": "Giuseppe Lancioni", "authors": "Marco Zamprogno, Marco Passon, Niki Martinel, Giuseppe Serra, Giuseppe\n  Lancioni, Christian Micheloni, Carlo Tasso, Gian Luca Foresti", "title": "Video-Based Convolutional Attention for Person Re-Identification", "comments": "11 pages, 2 figures. Accepted by ICIAP2019, 20th International\n  Conference on IMAGE ANALYSIS AND PROCESSING, Trento, Italy, 9-13 September,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of video-based person\nre-identification, which is the task of associating videos of the same person\ncaptured by different and non-overlapping cameras. We propose a Siamese\nframework in which video frames of the person to re-identify and of the\ncandidate one are processed by two identical networks which produce a\nsimilarity score. We introduce an attention mechanisms to capture the relevant\ninformation both at frame level (spatial information) and at video level\n(temporal information given by the importance of a specific frame within the\nsequence). One of the novelties of our approach is given by a joint concurrent\nprocessing of both frame and video levels, providing in such a way a very\nsimple architecture. Despite this fact, our approach achieves better\nperformance than the state-of-the-art on the challenging iLIDS-VID dataset.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 08:23:43 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Zamprogno", "Marco", ""], ["Passon", "Marco", ""], ["Martinel", "Niki", ""], ["Serra", "Giuseppe", ""], ["Lancioni", "Giuseppe", ""], ["Micheloni", "Christian", ""], ["Tasso", "Carlo", ""], ["Foresti", "Gian Luca", ""]]}, {"id": "1910.04857", "submitter": "Suryabhan Singh Hada", "authors": "Suryabhan Singh Hada and Miguel \\'A. Carreira-Perpi\\~n\\'an", "title": "Sampling the \"Inverse Set\" of a Neuron: An Approach to Understanding\n  Neural Nets", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent success of deep neural networks in computer vision, it is\nimportant to understand the internal working of these networks. What does a\ngiven neuron represent? The concepts captured by a neuron may be hard to\nunderstand or express in simple terms. The approach we propose in this paper is\nto characterize the region of input space that excites a given neuron to a\ncertain level; we call this the inverse set. This inverse set is a complicated\nhigh dimensional object that we explore by an optimization-based sampling\napproach. Inspection of samples of this set by a human can reveal regularities\nthat help to understand the neuron. This goes beyond approaches which were\nlimited to finding an image which maximally activates the neuron or using\nMarkov chain Monte Carlo to sample images, but this is very slow, generates\nsamples with little diversity and lacks control over the activation value of\nthe generated samples. Our approach also allows us to explore the intersection\nof inverse sets of several neurons and other variations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 02:22:43 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 00:49:03 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Hada", "Suryabhan Singh", ""], ["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""]]}, {"id": "1910.04858", "submitter": "Lu Mi", "authors": "Lu Mi, Hao Wang, Yonglong Tian, Nir Shavit", "title": "Training-Free Uncertainty Estimation for Dense Regression: Sensitivity\n  as a Surrogate", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimation is an essential step in the evaluation of the\nrobustness for deep learning models in computer vision, especially when applied\nin risk-sensitive areas. However, most state-of-the-art deep learning models\neither fail to obtain uncertainty estimation or need significant modification\n(e.g., formulating a proper Bayesian treatment) to obtain it. Most previous\nmethods are not able to take an arbitrary model off the shelf and generate\nuncertainty estimation without retraining or redesigning it. To address this\ngap, we perform a systematic exploration into training-free uncertainty\nestimation for dense regression, an unrecognized yet important problem, and\nprovide a theoretical construction justifying such estimations. We propose\nthree simple and scalable methods to analyze the variance of outputs from a\ntrained network under tolerable perturbations: infer-transformation,\ninfer-noise, and infer-dropout. They operate solely during inference, without\nthe need to re-train, re-design, or fine-tune the model, as typically required\nby state-of-the-art uncertainty estimation methods. Surprisingly, even without\ninvolving such perturbations in training, our methods produce comparable or\neven better uncertainty estimation when compared to training-required\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 02:30:02 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 03:11:41 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Mi", "Lu", ""], ["Wang", "Hao", ""], ["Tian", "Yonglong", ""], ["Shavit", "Nir", ""]]}, {"id": "1910.04864", "submitter": "Lichao Chen", "authors": "Lichao Chen, Sudhir Singh, Thomas Kailath, and Vwani Roychowdhury", "title": "Brain-inspired automated visual object discovery and detection", "comments": null, "journal-ref": "PNAS January 2, 2019 116 (1) 96-105", "doi": "10.1073/pnas.1802103115", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant recent progress, machine vision systems lag considerably\nbehind their biological counterparts in performance, scalability, and\nrobustness. A distinctive hallmark of the brain is its ability to automatically\ndiscover and model objects, at multiscale resolutions, from repeated exposures\nto unlabeled contextual data and then to be able to robustly detect the learned\nobjects under various nonideal circumstances, such as partial occlusion and\ndifferent view angles. Replication of such capabilities in a machine would\nrequire three key ingredients: (i) access to large-scale perceptual data of the\nkind that humans experience, (ii) flexible representations of objects, and\n(iii) an efficient unsupervised learning algorithm. The Internet fortunately\nprovides unprecedented access to vast amounts of visual data. This paper\nleverages the availability of such data to develop a scalable framework for\nunsupervised learning of object prototypes--brain-inspired flexible, scale, and\nshift invariant representations of deformable objects (e.g., humans,\nmotorcycles, cars, airplanes) comprised of parts, their different\nconfigurations and views, and their spatial relationships. Computationally, the\nobject prototypes are represented as geometric associative networks using\nprobabilistic constructs such as Markov random fields. We apply our framework\nto various datasets and show that our approach is computationally scalable and\ncan construct accurate and operational part-aware object models much more\nefficiently than in much of the recent computer vision literature. We also\npresent efficient algorithms for detection and localization in new scenes of\nobjects and their partial views.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 01:55:46 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Chen", "Lichao", ""], ["Singh", "Sudhir", ""], ["Kailath", "Thomas", ""], ["Roychowdhury", "Vwani", ""]]}, {"id": "1910.04865", "submitter": "Adewale Akinfaderin", "authors": "Adewale Akinfaderin and Olamilekan Wahab", "title": "NASS-AI: Towards Digitization of Parliamentary Bills using Document\n  Level Embedding and Bidirectional Long Short-Term Memory", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been several reports in the Nigerian and International media about\nthe Senators and House of Representative Members of the Nigerian National\nAssembly (NASS) being the highest paid in the world. Despite this high-level of\nparliamentary compensation and a lack of oversight, most of the legislative\nduties like bills introduced and vote proceedings are shrouded in mystery\nwithout an open and annotated corpus. In this paper, we present results from\nongoing research on the categorization of bills introduced in the Nigerian\nparliament since the fourth republic (1999 - 2018). For this task, we employed\na multi-step approach which involves extracting text from scanned and embedded\npdfs with low to medium quality using Optical Character Recognition (OCR) tools\nand labeling them into eight categories. We investigate the performance of\ndocument level embedding for feature representation of the extracted texts\nbefore using a Bidirectional Long Short-Term Memory (Bi-LSTM) for our\nclassifier. The performance was further compared with other feature\nrepresentation and machine learning techniques. We believe that these results\nare well-positioned to have a substantial impact on the quest to meet the basic\nopen data charter principles.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 00:39:02 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Akinfaderin", "Adewale", ""], ["Wahab", "Olamilekan", ""]]}, {"id": "1910.04867", "submitter": "Neil Houlsby", "authors": "Xiaohua Zhai, Joan Puigcerver, Alexander Kolesnikov, Pierre Ruyssen,\n  Carlos Riquelme, Mario Lucic, Josip Djolonga, Andre Susano Pinto, Maxim\n  Neumann, Alexey Dosovitskiy, Lucas Beyer, Olivier Bachem, Michael Tschannen,\n  Marcin Michalski, Olivier Bousquet, Sylvain Gelly, Neil Houlsby", "title": "A Large-scale Study of Representation Learning with the Visual Task\n  Adaptation Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning promises to unlock deep learning for the long tail of\nvision tasks without expensive labelled datasets. Yet, the absence of a unified\nevaluation for general visual representations hinders progress. Popular\nprotocols are often too constrained (linear classification), limited in\ndiversity (ImageNet, CIFAR, Pascal-VOC), or only weakly related to\nrepresentation quality (ELBO, reconstruction error). We present the Visual Task\nAdaptation Benchmark (VTAB), which defines good representations as those that\nadapt to diverse, unseen tasks with few examples. With VTAB, we conduct a\nlarge-scale study of many popular publicly-available representation learning\nalgorithms. We carefully control confounders such as architecture and tuning\nbudget. We address questions like: How effective are ImageNet representations\nbeyond standard natural datasets? How do representations trained via generative\nand discriminative models compare? To what extent can self-supervision replace\nlabels? And, how close are we to general visual representations?\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:06:29 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 13:36:15 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhai", "Xiaohua", ""], ["Puigcerver", "Joan", ""], ["Kolesnikov", "Alexander", ""], ["Ruyssen", "Pierre", ""], ["Riquelme", "Carlos", ""], ["Lucic", "Mario", ""], ["Djolonga", "Josip", ""], ["Pinto", "Andre Susano", ""], ["Neumann", "Maxim", ""], ["Dosovitskiy", "Alexey", ""], ["Beyer", "Lucas", ""], ["Bachem", "Olivier", ""], ["Tschannen", "Michael", ""], ["Michalski", "Marcin", ""], ["Bousquet", "Olivier", ""], ["Gelly", "Sylvain", ""], ["Houlsby", "Neil", ""]]}, {"id": "1910.04868", "submitter": "Haraldur Hallgr\\'imsson", "authors": "Haraldur T. Hallgrimsson, Richika Sharan, Scott T. Grafton, Ambuj K.\n  Singh", "title": "Estimating localized complexity of white-matter wiring with GANs", "comments": "Three page extended abstract, accepted to Medical Imaging meets\n  NeurIPS 2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-vivo examination of the physical connectivity of axonal projections\nthrough the white matter of the human brain is made possible by diffusion\nweighted magnetic resonance imaging (dMRI) Analysis of dMRI commonly considers\nderived scalar metrics such as fractional anisotrophy as proxies for \"white\nmatter integrity,\" and differences of such measures have been observed as\nsignificantly correlating with various neurological diagnosis and clinical\nmeasures such as executive function, presence of multiple sclerosis, and\ngenetic similarity. The analysis of such voxel measures is confounded in areas\nof more complicated fiber wiring due to crossing, kissing, and dispersing\nfibers. Recently, Volz et al. introduced a simple probabilistic measure of the\ncount of distinct fiber populations within a voxel, which was shown to reduce\nvariance in group comparisons. We propose a complementary measure that\nconsiders the complexity of a voxel in context of its local region, with an aim\nto quantify the localized wiring complexity of every part of white matter. This\nallows, for example, identification of particularly ambiguous regions of the\nbrain for tractographic approaches of modeling global wiring connectivity. Our\nmethod builds on recent advances in image inpainting, in which the task is to\nplausibly fill in a missing region of an image. Our proposed method builds on a\nBayesian estimate of heteroscedastic aleatoric uncertainty of a region of white\nmatter by inpainting it from its context. We define the localized wiring\ncomplexity of white matter as how accurately and confidently a well-trained\nmodel can predict the missing patch. In our results, we observe low aleatoric\nuncertainty along major neuronal pathways which increases at junctions and\ntowards cortex boundaries. This directly quantifies the difficulty of lesion\ninpainting of dMRI images at all parts of white matter.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:45:32 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 02:48:04 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Hallgrimsson", "Haraldur T.", ""], ["Sharan", "Richika", ""], ["Grafton", "Scott T.", ""], ["Singh", "Ambuj K.", ""]]}, {"id": "1910.04870", "submitter": "Rachel Blin", "authors": "Rachel Blin, Samia Ainouz, St\\'ephane Canu and Fabrice Meriaudeau", "title": "Road scenes analysis in adverse weather conditions by\n  polarization-encoded images and adapted deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection in road scenes is necessary to develop both autonomous\nvehicles and driving assistance systems. Even if deep neural networks for\nrecognition task have shown great performances using conventional images, they\nfail to detect objects in road scenes in complex acquisition situations. In\ncontrast, polarization images, characterizing the light wave, can robustly\ndescribe important physical properties of the object even under poor\nillumination or strong reflections. This paper shows how non-conventional\npolarimetric imaging modality overcomes the classical methods for object\ndetection especially in adverse weather conditions. The efficiency of the\nproposed method is mostly due to the high power of the polarimetry to\ndiscriminate any object by its reflective properties and on the use of deep\nneural networks for object detection. Our goal by this work, is to prove that\npolarimetry brings a real added value compared with RGB images for object\ndetection. Experimental results on our own dataset composed of road scene\nimages taken during adverse weather conditions show that polarimetry together\nwith deep learning can improve the state-of-the-art by about 20% to 50% on\ndifferent detection tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 13:47:46 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Blin", "Rachel", ""], ["Ainouz", "Samia", ""], ["Canu", "St\u00e9phane", ""], ["Meriaudeau", "Fabrice", ""]]}, {"id": "1910.04871", "submitter": "Daniele Cattaneo", "authors": "Daniele Cattaneo, Matteo Vaghi, Simone Fontana, Augusto Luis\n  Ballardini, Domenico Giorgio Sorrenti", "title": "Global visual localization in LiDAR-maps through shared 2D-3D embedding\n  space", "comments": "Accepted for presentation at IEEE ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Global localization is an important and widely studied problem for many\nrobotic applications. Place recognition approaches can be exploited to solve\nthis task, e.g., in the autonomous driving field. While most vision-based\napproaches match an image w.r.t. an image database, global visual localization\nwithin LiDAR-maps remains fairly unexplored, even though the path toward high\ndefinition 3D maps, produced mainly from LiDARs, is clear. In this work we\nleverage Deep Neural Network (DNN) approaches to create a shared embedding\nspace between images and LiDAR-maps, allowing for image to 3D-LiDAR place\nrecognition. We trained a 2D and a 3D DNN that create embeddings, respectively\nfrom images and from point clouds, that are close to each other whether they\nrefer to the same place. An extensive experimental activity is presented to\nassess the effectiveness of the approach w.r.t. different learning paradigms,\nnetwork architectures, and loss functions. All the evaluations have been\nperformed using the Oxford Robotcar Dataset, which encompasses a wide range of\nweather and light conditions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 09:59:00 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 12:14:33 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Cattaneo", "Daniele", ""], ["Vaghi", "Matteo", ""], ["Fontana", "Simone", ""], ["Ballardini", "Augusto Luis", ""], ["Sorrenti", "Domenico Giorgio", ""]]}, {"id": "1910.04875", "submitter": "Xiaomeng Dong", "authors": "Xiaomeng Dong, Junpyo Hong, Hsi-Ming Chang, Michael Potter, Aritra\n  Chowdhury, Purujit Bahl, Vivek Soni, Yun-Chan Tsai, Rajesh Tamada, Gaurav\n  Kumar, Caroline Favart, V. Ratna Saripalli, Gopal Avinash", "title": "FastEstimator: A Deep Learning Library for Fast Prototyping and\n  Productization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As the complexity of state-of-the-art deep learning models increases by the\nmonth, implementation, interpretation, and traceability become\never-more-burdensome challenges for AI practitioners around the world. Several\nAI frameworks have risen in an effort to stem this tide, but the steady advance\nof the field has begun to test the bounds of their flexibility, expressiveness,\nand ease of use. To address these concerns, we introduce a radically flexible\nhigh-level open source deep learning framework for both research and industry.\nWe introduce FastEstimator.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 01:01:27 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 19:20:13 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Dong", "Xiaomeng", ""], ["Hong", "Junpyo", ""], ["Chang", "Hsi-Ming", ""], ["Potter", "Michael", ""], ["Chowdhury", "Aritra", ""], ["Bahl", "Purujit", ""], ["Soni", "Vivek", ""], ["Tsai", "Yun-Chan", ""], ["Tamada", "Rajesh", ""], ["Kumar", "Gaurav", ""], ["Favart", "Caroline", ""], ["Saripalli", "V. Ratna", ""], ["Avinash", "Gopal", ""]]}, {"id": "1910.04877", "submitter": "Sek Chai", "authors": "Prateeth Nayak, David Zhang, Sek Chai", "title": "Bit Efficient Quantization for Deep Neural Networks", "comments": "EMC2 - NeurIPS workshop 2019, #latentai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization for deep neural networks have afforded models for edge devices\nthat use less on-board memory and enable efficient low-power inference. In this\npaper, we present a comparison of model-parameter driven quantization\napproaches that can achieve as low as 3-bit precision without affecting\naccuracy. The post-training quantization approaches are data-free, and the\nresulting weight values are closely tied to the dataset distribution on which\nthe model has converged to optimality. We show quantization results for a\nnumber of state-of-art deep neural networks (DNN) using large dataset like\nImageNet. To better analyze quantization results, we describe the overall range\nand local sparsity of values afforded through various quantization schemes. We\nshow the methods to lower bit-precision beyond quantization limits with object\nclass clustering.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 18:43:12 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Nayak", "Prateeth", ""], ["Zhang", "David", ""], ["Chai", "Sek", ""]]}, {"id": "1910.04879", "submitter": "Yan Chi Vinci Chow", "authors": "Vinci Chow", "title": "Predicting Auction Price of Vehicle License Plate with Deep Residual\n  Learning", "comments": null, "journal-ref": "Trends and Applications in Knowledge Discovery and Data Mining.\n  PAKDD 2019. Lecture Notes in Computer Science, vol 11607. Springer, Cham", "doi": "10.1007/978-3-030-26142-9_16", "report-no": null, "categories": "cs.CV cs.LG econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to superstition, license plates with desirable combinations of characters\nare highly sought after in China, fetching prices that can reach into the\nmillions in government-held auctions. Despite the high stakes involved, there\nhas been essentially no attempt to provide price estimates for license plates.\nWe present an end-to-end neural network model that simultaneously predict the\nauction price, gives the distribution of prices and produces latent feature\nvectors. While both types of neural network architectures we consider\noutperform simpler machine learning methods, convolutional networks outperform\nrecurrent networks for comparable training time or model complexity. The\nresulting model powers our online price estimator and search engine.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 16:38:06 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Chow", "Vinci", ""]]}, {"id": "1910.04887", "submitter": "Samuel Sharpe", "authors": "Samuel Sharpe, Jin Yan, Fan Wu, Iddo Drori", "title": "Visual Natural Language Query Auto-Completion for Estimating Instance\n  Probabilities", "comments": null, "journal-ref": "CVPR Language and Vision Workshop, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new task of query auto-completion for estimating instance\nprobabilities. We complete a user query prefix conditioned upon an image. Given\nthe complete query, we fine tune a BERT embedding for estimating probabilities\nof a broad set of instances. The resulting instance probabilities are used for\nselection while being agnostic to the segmentation or attention mechanism. Our\nresults demonstrate that auto-completion using both language and vision\nperforms better than using only language, and that fine tuning a BERT embedding\nallows to efficiently rank instances in the image. In the spirit of\nreproducible research we make our data, models, and code available.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 21:46:26 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Sharpe", "Samuel", ""], ["Yan", "Jin", ""], ["Wu", "Fan", ""], ["Drori", "Iddo", ""]]}, {"id": "1910.04895", "submitter": "Hamda Ajmal", "authors": "Hamda Ajmal, Michael Madden, Catherine Enright", "title": "PROFET: Construction and Inference of DBNs Based on Mathematical Models", "comments": "9 pages. In Proceedings of the 14th UAI Bayesian Modelling\n  Applications Workshop (BMAW 2017), co-located with the 33rd Conference on\n  Uncertainty in Artificial Intelligence (UAI 2017) Sydney, Australia, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents, evaluates, and discusses a new software tool to\nautomatically build Dynamic Bayesian Networks (DBNs) from ordinary differential\nequations (ODEs) entered by the user. The DBNs generated from ODE models can\nhandle both data uncertainty and model uncertainty in a principled manner. The\napplication, named PROFET, can be used for temporal data mining with noisy or\nmissing variables. It enables automatic re-estimation of model parameters using\ntemporal evidence in the form of data streams. For temporal inference, PROFET\nincludes both standard fixed time step particle filtering and its extension,\nadaptive-time particle filtering algorithms. Adaptive-time particle filtering\nenables the DBN to automatically adapt its time step length to match the\ndynamics of the model. We demonstrate PROFET's functionality by using it to\ninfer the model variables by estimating the model parameters of four benchmark\nODE systems. From the generation of the DBN model to temporal inference, the\nentire process is automated and is delivered as an open-source\nplatform-independent software application with a comprehensive user interface.\nPROFET is released under the Apache License 2.0. Its source code, executable\nand documentation are available at http:://profet.it.nuigalway.ie.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 22:17:12 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 08:36:45 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Ajmal", "Hamda", ""], ["Madden", "Michael", ""], ["Enright", "Catherine", ""]]}, {"id": "1910.04903", "submitter": "Arturo Pardo", "authors": "Arturo Pardo, Jos\\'e A. Guti\\'errez-Guti\\'errez, Jos\\'e Miguel\n  L\\'opez-Higuera, Brian W. Pogue, and Olga M. Conde", "title": "Coloring the Black Box: Visualizing neural network behavior with a\n  self-introspective model", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following work presents how autoencoding all the possible hidden\nactivations of a network for a given problem can provide insight about its\nstructure, behavior, and vulnerabilities. The method, termed\nself-introspection, can show that a trained model showcases similar activation\npatterns (albeit randomly distributed due to initialization) when shown data\nbelonging to the same category, and classification errors occur in fringe areas\nwhere the activations are not as clearly defined, suggesting some form of\nrandom, slowly varying, implicit encoding occurring within deep networks, that\ncan be observed with this representation. Additionally, obtaining a\nlow-dimensional representation of all the activations allows for (1) real-time\nmodel evaluation in the context of a multiclass classification problem, (2) the\nrearrangement of all hidden layers by their relevance in obtaining a specific\noutput, and (3) the obtainment of a framework where studying possible\ncounter-measures to noise and adversarial attacks is possible.\nSelf-introspection can show how damaged input data can modify the hidden\nactivations, producing an erroneous response. A few illustrative are\nimplemented for feedforward and convolutional models and the MNIST and CIFAR-10\ndatasets, showcasing its capabilities as a model evaluation framework.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 23:02:12 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 10:41:04 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Pardo", "Arturo", ""], ["Guti\u00e9rrez-Guti\u00e9rrez", "Jos\u00e9 A.", ""], ["L\u00f3pez-Higuera", "Jos\u00e9 Miguel", ""], ["Pogue", "Brian W.", ""], ["Conde", "Olga M.", ""]]}, {"id": "1910.04909", "submitter": "Hamda Ajmal", "authors": "Hamda Ajmal, Michael Madden, Catherine Enright", "title": "Dealing with Stochasticity in Biological ODE Models", "comments": "5 pages. In Workshop on Computational Biology (WCB) 2017, co-located\n  with the 34th International Conference on Machine Learning (ICML). arXiv\n  admin note: text overlap with arXiv:1910.04895", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical modeling with Ordinary Differential Equations (ODEs) has proven\nto be extremely successful in a variety of fields, including biology. However,\nthese models are completely deterministic given a certain set of initial\nconditions. We convert mathematical ODE models of three benchmark biological\nsystems to Dynamic Bayesian Networks (DBNs). The DBN model can handle model\nuncertainty and data uncertainty in a principled manner. They can be used for\ntemporal data mining for noisy and missing variables. We apply Particle\nFiltering algorithm to infer the model variables by re-estimating the models\nparameters of various biological ODE models. The model parameters are\nautomatically re-estimated using temporal evidence in the form of data streams.\nThe results show that DBNs are capable of inferring the model variables of the\nODE model with high accuracy in situations where data is missing, incomplete,\nsparse and irregular and true values of model parameters are not known.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 23:20:19 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 08:57:03 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Ajmal", "Hamda", ""], ["Madden", "Michael", ""], ["Enright", "Catherine", ""]]}, {"id": "1910.04915", "submitter": "Krzysztof Maziarz", "authors": "Krzysztof Maziarz, Efi Kokiopoulou, Andrea Gesmundo, Luciano Sbaiz,\n  Gabor Bartok, Jesse Berent", "title": "Flexible Multi-task Networks by Learning Parameter Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel learning method for multi-task applications.\nMulti-task neural networks can learn to transfer knowledge across different\ntasks by using parameter sharing. However, sharing parameters between unrelated\ntasks can hurt performance. To address this issue, we propose a framework to\nlearn fine-grained patterns of parameter sharing. Assuming that the network is\ncomposed of several components across layers, our framework uses learned binary\nvariables to allocate components to tasks in order to encourage more parameter\nsharing between related tasks, and discourage parameter sharing otherwise. The\nbinary allocation variables are learned jointly with the model parameters by\nstandard back-propagation thanks to the Gumbel-Softmax reparametrization\nmethod. When applied to the Omniglot benchmark, the proposed method achieves a\n17% relative reduction of the error rate compared to state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 23:46:08 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 15:21:56 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Maziarz", "Krzysztof", ""], ["Kokiopoulou", "Efi", ""], ["Gesmundo", "Andrea", ""], ["Sbaiz", "Luciano", ""], ["Bartok", "Gabor", ""], ["Berent", "Jesse", ""]]}, {"id": "1910.04918", "submitter": "Okyaz Eminaga", "authors": "Okyaz Eminaga, Yuri Tolkach, Christian Kunder, Mahmood Abbas, Ryan\n  Han, Rosalie Nolley, Axel Semjonow, Martin Boegemann, Sebastian Huss, Andreas\n  Loening, Robert West, Geoffrey Sonn, Richard Fan, Olaf Bettendorf, James\n  Brook and Daniel Rubin", "title": "Deep Learning for Prostate Pathology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.TO cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current study detects different morphologies related to prostate\npathology using deep learning models; these models were evaluated on 2,121\nhematoxylin and eosin (H&E) stain histology images captured using bright field\nmicroscopy, which spanned a variety of image qualities, origins (whole slide,\ntissue micro array, whole mount, Internet), scanning machines, timestamps, H&E\nstaining protocols, and institutions. For case usage, these models were applied\nfor the annotation tasks in clinician-oriented pathology reports for\nprostatectomy specimens. The true positive rate (TPR) for slides with prostate\ncancer was 99.7% by a false positive rate of 0.785%. The F1-scores of Gleason\npatterns reported in pathology reports ranged from 0.795 to 1.0 at the case\nlevel. TPR was 93.6% for the cribriform morphology and 72.6% for the ductal\nmorphology. The correlation between the ground truth and the prediction for the\nrelative tumor volume was 0.987 n. Our models cover the major components of\nprostate pathology and successfully accomplish the annotation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 00:10:59 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 07:34:27 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 00:14:28 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Eminaga", "Okyaz", ""], ["Tolkach", "Yuri", ""], ["Kunder", "Christian", ""], ["Abbas", "Mahmood", ""], ["Han", "Ryan", ""], ["Nolley", "Rosalie", ""], ["Semjonow", "Axel", ""], ["Boegemann", "Martin", ""], ["Huss", "Sebastian", ""], ["Loening", "Andreas", ""], ["West", "Robert", ""], ["Sonn", "Geoffrey", ""], ["Fan", "Richard", ""], ["Bettendorf", "Olaf", ""], ["Brook", "James", ""], ["Rubin", "Daniel", ""]]}, {"id": "1910.04919", "submitter": "Yongsheng Gao", "authors": "Bin Wang, Yongsheng Gao, Xiaohan Yu, Xiaohui Yuan, Shengwu Xiong,\n  Xianzhong Feng", "title": "From Species to Cultivar: Soybean Cultivar Recognition using Multiscale\n  Sliding Chord Matching of Leaf Images", "comments": "33 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leaf image recognition techniques have been actively researched for plant\nspecies identification. However it remains unclear whether leaf patterns can\nprovide sufficient information for cultivar recognition. This paper reports the\nfirst attempt on soybean cultivar recognition from plant leaves which is not\nonly a challenging research problem but also important for soybean cultivar\nevaluation, selection and production in agriculture. In this paper, we propose\na novel multiscale sliding chord matching (MSCM) approach to extract leaf\npatterns that are distinctive for soybean cultivar identification. A chord is\ndefined to slide along the contour for measuring the synchronised patterns of\nexterior shape and interior appearance of soybean leaf images. A multiscale\nsliding chord strategy is developed to extract features in a coarse-to-fine\nhierarchical order. A joint description that integrates the leaf descriptors\nfrom different parts of a soybean plant is proposed for further enhancing the\ndiscriminative power of cultivar description. We built a cultivar leaf image\ndatabase, SoyCultivar, consisting of 1200 sample leaf images from 200 soybean\ncultivars for performance evaluation. Encouraging experimental results of the\nproposed method in comparison to the state-of-the-art leaf species recognition\nmethods demonstrate the availability of cultivar information in soybean leaves\nand effectiveness of the proposed MSCM for soybean cultivar identification,\nwhich may advance the research in leaf recognition from species to cultivar.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 00:21:43 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Wang", "Bin", ""], ["Gao", "Yongsheng", ""], ["Yu", "Xiaohan", ""], ["Yuan", "Xiaohui", ""], ["Xiong", "Shengwu", ""], ["Feng", "Xianzhong", ""]]}, {"id": "1910.04920", "submitter": "Sharan Vaswani", "authors": "Si Yi Meng, Sharan Vaswani, Issam Laradji, Mark Schmidt, Simon\n  Lacoste-Julien", "title": "Fast and Furious Convergence: Stochastic Second Order Methods under\n  Interpolation", "comments": "AISTATS, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider stochastic second-order methods for minimizing smooth and\nstrongly-convex functions under an interpolation condition satisfied by\nover-parameterized models. Under this condition, we show that the regularized\nsubsampled Newton method (R-SSN) achieves global linear convergence with an\nadaptive step-size and a constant batch-size. By growing the batch size for\nboth the subsampled gradient and Hessian, we show that R-SSN can converge at a\nquadratic rate in a local neighbourhood of the solution. We also show that\nR-SSN attains local linear convergence for the family of self-concordant\nfunctions. Furthermore, we analyze stochastic BFGS algorithms in the\ninterpolation setting and prove their global linear convergence. We empirically\nevaluate stochastic L-BFGS and a \"Hessian-free\" implementation of R-SSN for\nbinary classification on synthetic, linearly-separable datasets and real\ndatasets under a kernel mapping. Our experimental results demonstrate the fast\nconvergence of these methods, both in terms of the number of iterations and\nwall-clock time.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 00:24:19 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 21:47:56 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Meng", "Si Yi", ""], ["Vaswani", "Sharan", ""], ["Laradji", "Issam", ""], ["Schmidt", "Mark", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1910.04928", "submitter": "Sharan Vaswani", "authors": "Sharan Vaswani, Abbas Mehrabian, Audrey Durand, Branislav Kveton", "title": "Old Dog Learns New Tricks: Randomized UCB for Bandit Problems", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose $\\tt RandUCB$, a bandit strategy that builds on theoretically\nderived confidence intervals similar to upper confidence bound (UCB)\nalgorithms, but akin to Thompson sampling (TS), it uses randomization to trade\noff exploration and exploitation. In the $K$-armed bandit setting, we show that\nthere are infinitely many variants of $\\tt RandUCB$, all of which achieve the\nminimax-optimal $\\widetilde{O}(\\sqrt{K T})$ regret after $T$ rounds. Moreover,\nfor a specific multi-armed bandit setting, we show that both UCB and TS can be\nrecovered as special cases of $\\tt RandUCB$. For structured bandits, where each\narm is associated with a $d$-dimensional feature vector and rewards are\ndistributed according to a linear or generalized linear model, we prove that\n$\\tt RandUCB$ achieves the minimax-optimal $\\widetilde{O}(d \\sqrt{T})$ regret\neven in the case of infinitely many arms. Through experiments in both the\nmulti-armed and structured bandit settings, we demonstrate that $\\tt RandUCB$\nmatches or outperforms TS and other randomized exploration strategies. Our\ntheoretical and empirical results together imply that $\\tt RandUCB$ achieves\nthe best of both worlds.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 01:15:07 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 00:11:07 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Vaswani", "Sharan", ""], ["Mehrabian", "Abbas", ""], ["Durand", "Audrey", ""], ["Kveton", "Branislav", ""]]}, {"id": "1910.04930", "submitter": "Qilong Gu", "authors": "Arindam Banerjee, Qilong Gu, Vidyashankar Sivakumar, and Zhiwei Steven\n  Wu", "title": "Random Quadratic Forms with Dependence: Applications to Restricted\n  Isometry and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several important families of computational and statistical results in\nmachine learning and randomized algorithms rely on uniform bounds on quadratic\nforms of random vectors or matrices. Such results include the\nJohnson-Lindenstrauss (J-L) Lemma, the Restricted Isometry Property (RIP),\nrandomized sketching algorithms, and approximate linear algebra. The existing\nresults critically depend on statistical independence, e.g., independent\nentries for random vectors, independent rows for random matrices, etc., which\nprevent their usage in dependent or adaptive modeling settings. In this paper,\nwe show that such independence is in fact not needed for such results which\ncontinue to hold under fairly general dependence structures. In particular, we\npresent uniform bounds on random quadratic forms of stochastic processes which\nare conditionally independent and sub-Gaussian given another (latent) process.\nOur setup allows general dependencies of the stochastic process on the history\nof the latent process and the latent process to be influenced by realizations\nof the stochastic process. The results are thus applicable to adaptive modeling\nsettings and also allows for sequential design of random vectors and matrices.\nWe also discuss stochastic process based forms of J-L, RIP, and sketching, to\nillustrate the generality of the results.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 01:30:46 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 05:32:02 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Banerjee", "Arindam", ""], ["Gu", "Qilong", ""], ["Sivakumar", "Vidyashankar", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1910.04935", "submitter": "Haoran Dou", "authors": "Xin Yang, Wenlong Shi, Haoran Dou, Jikuan Qian, Yi Wang, Wufeng Xue,\n  Shengli Li, Dong Ni, Pheng-Ann Heng", "title": "FetusMap: Fetal Pose Estimation in 3D Ultrasound", "comments": "9 pages, 6 figures, 2 tables. Accepted by MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 3D ultrasound (US) entrance inspires a multitude of automated prenatal\nexaminations. However, studies about the structuralized description of the\nwhole fetus in 3D US are still rare. In this paper, we propose to estimate the\n3D pose of fetus in US volumes to facilitate its quantitative analyses in\nglobal and local scales. Given the great challenges in 3D US, including the\nhigh volume dimension, poor image quality, symmetric ambiguity in anatomical\nstructures and large variations of fetal pose, our contribution is three-fold.\n(i) This is the first work about 3D pose estimation of fetus in the literature.\nWe aim to extract the skeleton of whole fetus and assign different\nsegments/joints with correct torso/limb labels. (ii) We propose a\nself-supervised learning (SSL) framework to finetune the deep network to form\nvisually plausible pose predictions. Specifically, we leverage the\nlandmark-based registration to effectively encode case-adaptive anatomical\npriors and generate evolving label proxy for supervision. (iii) To enable our\n3D network perceive better contextual cues with higher resolution input under\nlimited computing resource, we further adopt the gradient check-pointing (GCP)\nstrategy to save GPU memory and improve the prediction. Extensively validated\non a large 3D US dataset, our method tackles varying fetal poses and achieves\npromising results. 3D pose estimation of fetus has potentials in serving as a\nmap to provide navigation for many advanced studies.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 01:45:09 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Yang", "Xin", ""], ["Shi", "Wenlong", ""], ["Dou", "Haoran", ""], ["Qian", "Jikuan", ""], ["Wang", "Yi", ""], ["Xue", "Wufeng", ""], ["Li", "Shengli", ""], ["Ni", "Dong", ""], ["Heng", "Pheng-Ann", ""]]}, {"id": "1910.04938", "submitter": "Yangyi Lu", "authors": "Yangyi Lu, Amirhossein Meisami, Ambuj Tewari, Zhenyu Yan", "title": "Regret Analysis of Bandit Problems with Causal Background Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to learn optimal interventions sequentially given causal\ninformation represented as a causal graph along with associated conditional\ndistributions. Causal modeling is useful in real world problems like online\nadvertisement where complex causal mechanisms underlie the relationship between\ninterventions and outcomes. We propose two algorithms, causal upper confidence\nbound (C-UCB) and causal Thompson Sampling (C-TS), that enjoy improved\ncumulative regret bounds compared with algorithms that do not use causal\ninformation. We thus resolve an open problem posed by\n\\cite{lattimore2016causal}. Further, we extend C-UCB and C-TS to the linear\nbandit setting and propose causal linear UCB (CL-UCB) and causal linear TS\n(CL-TS) algorithms. These algorithms enjoy a cumulative regret bound that only\nscales with the feature dimension. Our experiments show the benefit of using\ncausal information. For example, we observe that even with a few hundreds of\niterations, the regret of causal algorithms is less than that of standard\nalgorithms by a factor of three. We also show that under certain causal\nstructures, our algorithms scale better than the standard bandit algorithms as\nthe number of interventions increases.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 02:00:32 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 18:28:46 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 18:31:45 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Lu", "Yangyi", ""], ["Meisami", "Amirhossein", ""], ["Tewari", "Ambuj", ""], ["Yan", "Zhenyu", ""]]}, {"id": "1910.04939", "submitter": "Hung Ngo", "authors": "Ryan Curtin, Ben Moseley, Hung Q. Ngo, XuanLong Nguyen, Dan Olteanu,\n  Maximilian Schleich", "title": "Rk-means: Fast Clustering for Relational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional machine learning algorithms cannot be applied until a data\nmatrix is available to process. When the data matrix needs to be obtained from\na relational database via a feature extraction query, the computation cost can\nbe prohibitive, as the data matrix may be (much) larger than the total input\nrelation size. This paper introduces Rk-means, or relational k -means\nalgorithm, for clustering relational data tuples without having to access the\nfull data matrix. As such, we avoid having to run the expensive feature\nextraction query and storing its output. Our algorithm leverages the underlying\nstructures in relational data. It involves construction of a small {\\it grid\ncoreset} of the data matrix for subsequent cluster construction. This gives a\nconstant approximation for the k -means objective, while having asymptotic\nruntime improvements over standard approaches of first running the database\nquery and then clustering. Empirical results show orders-of-magnitude speedup,\nand Rk-means can run faster on the database than even just computing the data\nmatrix.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 02:03:08 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Curtin", "Ryan", ""], ["Moseley", "Ben", ""], ["Ngo", "Hung Q.", ""], ["Nguyen", "XuanLong", ""], ["Olteanu", "Dan", ""], ["Schleich", "Maximilian", ""]]}, {"id": "1910.04940", "submitter": "Guanhua Wang", "authors": "Guanhua Wang, Shivaram Venkataraman, Amar Phanishayee, Jorgen Thelin,\n  Nikhil Devanur, Ion Stoica", "title": "Blink: Fast and Generic Collectives for Distributed ML", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model parameter synchronization across GPUs introduces high overheads for\ndata-parallel training at scale. Existing parameter synchronization protocols\ncannot effectively leverage available network resources in the face of ever\nincreasing hardware heterogeneity. To address this, we propose Blink, a\ncollective communication library that dynamically generates optimal\ncommunication primitives by packing spanning trees. We propose techniques to\nminimize the number of trees generated and extend Blink to leverage\nheterogeneous communication channels for faster data transfers. Evaluations\nshow that compared to the state-of-the-art (NCCL), Blink can achieve up to 8x\nfaster model synchronization, and reduce end-to-end training time for image\nclassification tasks by up to 40%.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 02:13:34 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Wang", "Guanhua", ""], ["Venkataraman", "Shivaram", ""], ["Phanishayee", "Amar", ""], ["Thelin", "Jorgen", ""], ["Devanur", "Nikhil", ""], ["Stoica", "Ion", ""]]}, {"id": "1910.04952", "submitter": "Anastasios Kyrillidis", "authors": "John Chen, Cameron Wolfe, Zhao Li, Anastasios Kyrillidis", "title": "Demon: Improved Neural Network Training with Momentum Decay", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum is a widely used technique for gradient-based optimizers in deep\nlearning. In this paper, we propose a decaying momentum (\\textsc{Demon}) rule.\nWe conduct the first large-scale empirical analysis of momentum decay methods\nfor modern neural network optimization, in addition to the most popular\nlearning rate decay schedules. Across 28 relevant combinations of models,\nepochs, datasets, and optimizers, \\textsc{Demon} achieves the highest number of\nTop-1 and Top-3 finishes at 39\\% and 85\\% respectively, almost doubling the\nsecond-placed learning rate cosine schedule at 17\\% and 60\\%, respectively.\n\\textsc{Demon} also outperforms other widely used schedulers including, but not\nlimited to, the learning rate step schedule, linear schedule, OneCycle\nschedule, and exponential schedule. Compared with the widely used learning rate\nstep schedule, \\textsc{Demon} is observed to be less sensitive to parameter\ntuning, which is critical to training neural networks in practice. Results are\ndemonstrated across a variety of settings and architectures, including image\nclassification, generative models, and language models. \\textsc{Demon} is easy\nto implement, requires no additional tuning, and incurs almost no extra\ncomputational overhead compared to the vanilla counterparts. Code is readily\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 03:12:21 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 15:04:16 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 22:35:49 GMT"}, {"version": "v4", "created": "Thu, 1 Jul 2021 12:50:46 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chen", "John", ""], ["Wolfe", "Cameron", ""], ["Li", "Zhao", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "1910.04956", "submitter": "Chaoyang He", "authors": "Chaoyang He, Conghui Tan, Hanlin Tang, Shuang Qiu, Ji Liu", "title": "Central Server Free Federated Learning over Single-sided Trust Social\n  Networks", "comments": "decentralized federated learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning has become increasingly important for modern machine\nlearning, especially for data privacy-sensitive scenarios. Existing federated\nlearning mostly adopts the central server-based architecture or centralized\narchitecture. However, in many social network scenarios, centralized federated\nlearning is not applicable (e.g., a central agent or server connecting all\nusers may not exist, or the communication cost to the central server is not\naffordable). In this paper, we consider a generic setting: 1) the central\nserver may not exist, and 2) the social network is unidirectional or of\nsingle-sided trust (i.e., user A trusts user B but user B may not trust user\nA). We propose a central server free federated learning algorithm, named Online\nPush-Sum (OPS) method, to handle this challenging but generic scenario. A\nrigorous regret analysis is also provided, which shows very interesting results\non how users can benefit from communication with trusted users in the federated\nlearning scenario. This work builds upon the fundamental algorithm framework\nand theoretical guarantees for federated learning in the generic social network\nscenario.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 03:36:53 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 17:20:53 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["He", "Chaoyang", ""], ["Tan", "Conghui", ""], ["Tang", "Hanlin", ""], ["Qiu", "Shuang", ""], ["Liu", "Ji", ""]]}, {"id": "1910.04958", "submitter": "Cengiz Pehlevan", "authors": "Dina Obeid, Hugo Ramambason and Cengiz Pehlevan", "title": "Structured and Deep Similarity Matching via Structured and Deep Hebbian\n  Networks", "comments": "Accepted for publication in NeurIPS 2019; Minor typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synaptic plasticity is widely accepted to be the mechanism behind learning in\nthe brain's neural networks. A central question is how synapses, with access to\nonly local information about the network, can still organize collectively and\nperform circuit-wide learning in an efficient manner. In single-layered and\nall-to-all connected neural networks, local plasticity has been shown to\nimplement gradient-based learning on a class of cost functions that contain a\nterm that aligns the similarity of outputs to the similarity of inputs. Whether\nsuch cost functions exist for networks with other architectures is not known.\nIn this paper, we introduce structured and deep similarity matching cost\nfunctions, and show how they can be optimized in a gradient-based manner by\nneural networks with local learning rules. These networks extend F\\\"oldiak's\nHebbian/Anti-Hebbian network to deep architectures and structured feedforward,\nlateral and feedback connections. Credit assignment problem is solved elegantly\nby a factorization of the dual learning objective to synapse specific local\nobjectives. Simulations show that our networks learn meaningful features.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 03:44:00 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 22:16:34 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Obeid", "Dina", ""], ["Ramambason", "Hugo", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "1910.04959", "submitter": "Hossein Esfandiari", "authors": "Hossein Esfandiari, Amin Karbasi, Abbas Mehrabian, Vahab Mirrokni", "title": "Regret Bounds for Batched Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present simple and efficient algorithms for the batched stochastic\nmulti-armed bandit and batched stochastic linear bandit problems. We prove\nbounds for their expected regrets that improve over the best-known regret\nbounds for any number of batches. In particular, our algorithms in both\nsettings achieve the optimal expected regrets by using only a logarithmic\nnumber of batches. We also study the batched adversarial multi-armed bandit\nproblem for the first time and find the optimal regret, up to logarithmic\nfactors, of any algorithm with predetermined batch sizes.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 03:53:28 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 16:44:52 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Esfandiari", "Hossein", ""], ["Karbasi", "Amin", ""], ["Mehrabian", "Abbas", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1910.04964", "submitter": "Xin Wang", "authors": "Wenwu Zhu, Xin Wang, Hongzhi Li", "title": "Multi-modal Deep Analysis for Multimedia", "comments": "25 pages, 39 figures, IEEE Transactions on Circuits and Systems for\n  Video Technology", "journal-ref": null, "doi": "10.1109/TCSVT.2019.2940647", "report-no": null, "categories": "cs.MM cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of Internet and multimedia services in the past\ndecade, a huge amount of user-generated and service provider-generated\nmultimedia data become available. These data are heterogeneous and multi-modal\nin nature, imposing great challenges for processing and analyzing them.\nMulti-modal data consist of a mixture of various types of data from different\nmodalities such as texts, images, videos, audios etc. In this article, we\npresent a deep and comprehensive overview for multi-modal analysis in\nmultimedia. We introduce two scientific research problems, data-driven\ncorrelational representation and knowledge-guided fusion for multimedia\nanalysis. To address the two scientific problems, we investigate them from the\nfollowing aspects: 1) multi-modal correlational representation: multi-modal\nfusion of data across different modalities, and 2) multi-modal data and\nknowledge fusion: multi-modal fusion of data with domain knowledge. More\nspecifically, on data-driven correlational representation, we highlight three\nimportant categories of methods, such as multi-modal deep representation,\nmulti-modal transfer learning, and multi-modal hashing. On knowledge-guided\nfusion, we discuss the approaches for fusing knowledge with data and four\nexemplar applications that require various kinds of domain knowledge, including\nmulti-modal visual question answering, multi-modal video summarization,\nmulti-modal visual pattern mining and multi-modal recommendation. Finally, we\nbring forward our insights and future research directions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 04:21:36 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 08:42:13 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zhu", "Wenwu", ""], ["Wang", "Xin", ""], ["Li", "Hongzhi", ""]]}, {"id": "1910.04966", "submitter": "Cheng He", "authors": "Cheng He, Shihua Huang, Ran Cheng, Kay Chen Tan, and Yaochu Jin", "title": "Evolutionary Multiobjective Optimization Driven by Generative\n  Adversarial Networks (GANs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, increasing works have proposed to drive evolutionary algorithms\nusing machine learning models. Usually, the performance of such model based\nevolutionary algorithms is highly dependent on the training qualities of the\nadopted models. Since it usually requires a certain amount of data (i.e. the\ncandidate solutions generated by the algorithms) for model training, the\nperformance deteriorates rapidly with the increase of the problem scales, due\nto the curse of dimensionality. To address this issue, we propose a\nmulti-objective evolutionary algorithm driven by the generative adversarial\nnetworks (GANs). At each generation of the proposed algorithm, the parent\nsolutions are first classified into real and fake samples to train the GANs;\nthen the offspring solutions are sampled by the trained GANs. Thanks to the\npowerful generative ability of the GANs, our proposed algorithm is capable of\ngenerating promising offspring solutions in high-dimensional decision space\nwith limited training data. The proposed algorithm is tested on 10 benchmark\nproblems with up to 200 decision variables. Experimental results on these test\nproblems demonstrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 04:28:41 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 06:19:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["He", "Cheng", ""], ["Huang", "Shihua", ""], ["Cheng", "Ran", ""], ["Tan", "Kay Chen", ""], ["Jin", "Yaochu", ""]]}, {"id": "1910.04969", "submitter": "Hamid Shiri", "authors": "Hamid Shiri, Jihong Park, Mehdi Bennis", "title": "Remote UAV Online Path Planning via Neural Network Based Opportunistic\n  Control", "comments": "5 pages, 2 figures; This work has been submitted to the IEEE for\n  possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter proposes a neural network (NN) aided remote unmanned aerial\nvehicle (UAV) online control algorithm, coined oHJB. By downloading a UAV's\nstate, a base station (BS) trains an HJB NN that solves the\nHamilton-Jacobi-Bellman equation (HJB) in real time, yielding the optimal\ncontrol action. Initially, the BS uploads this control action to the UAV. If\nthe HJB NN is sufficiently trained and the UAV is far away, the BS uploads the\nHJB NN model, enabling to locally carry out control decisions even when the\nconnection is lost. Simulations corroborate the effectiveness of oHJB in\nreducing the UAV's travel time and energy by utilizing the trade-off between\nuploading delays and control robustness in poor channel conditions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 04:40:57 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Shiri", "Hamid", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1910.04970", "submitter": "Gege Zhang", "authors": "Gege Zhang, Gangwei Li, Ningwei Shen and Weidong Zhang", "title": "The Expressivity and Training of Deep Neural Networks: toward the Edge\n  of Chaos?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expressivity is one of the most significant issues in assessing neural\nnetworks. In this paper, we provide a quantitative analysis of the expressivity\nfor the deep neural network (DNN) from its dynamic model, where the Hilbert\nspace is employed to analyze the convergence and criticality. We study the\nfeature mapping of several widely used activation functions obtained by Hermite\npolynomials, and find sharp declines or even saddle points in the feature\nspace, which stagnate the information transfer in DNNs. We then present a new\nactivation function design based on the Hermite polynomials for better\nutilization of spatial representation. Moreover, we analyze the information\ntransfer of DNNs, emphasizing the convergence problem caused by the mismatch\nbetween input and topological structure. We also study the effects of input\nperturbations and regularization operators on critical expressivity. Our\ntheoretical analysis reveals that DNNs use spatial domains for information\nrepresentation and evolve to the edge of chaos as depth increases. In actual\ntraining, whether a particular network can ultimately arrive the edge of chaos\ndepends on its ability to overcome convergence and pass information to the\nrequired network depth. Finally, we demonstrate the empirical performance of\nthe proposed hypothesis via multivariate time series prediction and image\nclassification examples.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 04:44:10 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 13:33:24 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Zhang", "Gege", ""], ["Li", "Gangwei", ""], ["Shen", "Ningwei", ""], ["Zhang", "Weidong", ""]]}, {"id": "1910.04979", "submitter": "Nicholas Andrews", "authors": "Nicholas Andrews and Marcus Bishop", "title": "Learning Invariant Representations of Social Media Users", "comments": "12 pages, 3 figures; to be published in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of social media users' behavior over time complicates\nuser-level comparison tasks such as verification, classification, clustering,\nand ranking. As a result, na\\\"ive approaches may fail to generalize to new\nusers or even to future observations of previously known users. In this paper,\nwe propose a novel procedure to learn a mapping from short episodes of user\nactivity on social media to a vector space in which the distance between points\ncaptures the similarity of the corresponding users' invariant features. We fit\nthe model by optimizing a surrogate metric learning objective over a large\ncorpus of unlabeled social media content. Once learned, the mapping may be\napplied to users not seen at training time and enables efficient comparisons of\nusers in the resulting vector space. We present a comprehensive evaluation to\nvalidate the benefits of the proposed approach using data from Reddit, Twitter,\nand Wikipedia.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 05:37:11 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Andrews", "Nicholas", ""], ["Bishop", "Marcus", ""]]}, {"id": "1910.04988", "submitter": "Rui Fan", "authors": "Rui Fan, Ming Liu", "title": "Road Damage Detection Based on Unsupervised Disparity Map Segmentation", "comments": "6 pages, 9 figures", "journal-ref": null, "doi": "10.1109/TITS.2019.2947206", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel road damage detection algorithm based on\nunsupervised disparity map segmentation. Firstly, a disparity map is\ntransformed by minimizing an energy function with respect to stereo rig roll\nangle and road disparity projection model. Instead of solving this energy\nminimization problem using non-linear optimization techniques, we directly find\nits numerical solution. The transformed disparity map is then segmented using\nOtus's thresholding method, and the damaged road areas can be extracted. The\nproposed algorithm requires no parameters when detecting road damage. The\nexperimental results illustrate that our proposed algorithm performs both\naccurately and efficiently. The pixel-level road damage detection accuracy is\napproximately 97.56%.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 06:31:28 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Fan", "Rui", ""], ["Liu", "Ming", ""]]}, {"id": "1910.04991", "submitter": "Santhilata Kuppili Venkata", "authors": "Santhilata Kuppili Venkata and Katarzyna Musial", "title": "Sub-query Fragmentation for Query Analysis and Data Caching in the\n  Distributed Environment", "comments": "29 pages, 18 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When data stores and users are distributed geographically, it is essential to\norganize distributed data cache points at ideal locations to minimize data\ntransfers. To answer this, we are developing an adaptive distributed data\ncaching framework that can identify suitable data chunks to cache and move\nacross a network of community cache locations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 06:41:09 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Venkata", "Santhilata Kuppili", ""], ["Musial", "Katarzyna", ""]]}, {"id": "1910.04997", "submitter": "Sebastian Zambal", "authors": "Sebastian Zambal, Christoph Heindl, Christian Eitzinger, Josef\n  Scharinger", "title": "End-to-End Defect Detection in Automated Fiber Placement Based on\n  Artificially Generated Data", "comments": "Presented at Quality Control by Artificial Vision (QCAV), 2019", "journal-ref": null, "doi": "10.1117/12.2521739", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated fiber placement (AFP) is an advanced manufacturing technology that\nincreases the rate of production of composite materials. At the same time, the\nneed for adaptable and fast inline control methods of such parts raises.\nExisting inspection systems make use of handcrafted filter chains and feature\ndetectors, tuned for a specific measurement methods by domain experts. These\nmethods hardly scale to new defects or different measurement devices. In this\npaper, we propose to formulate AFP defect detection as an image segmentation\nproblem that can be solved in an end-to-end fashion using artificially\ngenerated training data. We employ a probabilistic graphical model to generate\ntraining images and annotations. We then train a deep neural network based on\nrecent architectures designed for image segmentation. This leads to an\nappealing method that scales well with new defect types and measurement devices\nand requires little real world data for training.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 07:10:24 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Zambal", "Sebastian", ""], ["Heindl", "Christoph", ""], ["Eitzinger", "Christian", ""], ["Scharinger", "Josef", ""]]}, {"id": "1910.04998", "submitter": "No\\'emie Jaquier", "authors": "No\\'emie Jaquier, Leonel Rozo, Sylvain Calinon, Mathias B\\\"urger", "title": "Bayesian Optimization Meets Riemannian Manifolds in Robot Learning", "comments": "Accepted in CoRL'19, 14 pages, 9 figures, 5 tables, 7 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) recently became popular in robotics to optimize\ncontrol parameters and parametric policies in direct reinforcement learning due\nto its data efficiency and gradient-free approach. However, its performance may\nbe seriously compromised when the parameter space is high-dimensional. A way to\ntackle this problem is to introduce domain knowledge into the BO framework. We\npropose to exploit the geometry of non-Euclidean parameter spaces, which often\narise in robotics (e.g. orientation, stiffness matrix). Our approach, built on\nRiemannian manifold theory, allows BO to properly measure similarities in the\nparameter space through geometry-aware kernel functions and to optimize the\nacquisition function on the manifold as an unconstrained problem. We test our\napproach in several benchmark artificial landscapes and using a 7-DOF simulated\nrobot to learn orientation and impedance parameters for manipulation skills.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 07:13:45 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Jaquier", "No\u00e9mie", ""], ["Rozo", "Leonel", ""], ["Calinon", "Sylvain", ""], ["B\u00fcrger", "Mathias", ""]]}, {"id": "1910.05005", "submitter": "No\\'emie Jaquier", "authors": "No\\'emie Jaquier, David Ginsbourger, Sylvain Calinon", "title": "Learning from demonstration with model-based Gaussian process", "comments": "Accepted in CoRL'19, 11 pages, 7 figures, 1 table, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In learning from demonstrations, it is often desirable to adapt the behavior\nof the robot as a function of the variability retrieved from human\ndemonstrations and the (un)certainty encoded in different parts of the task. In\nthis paper, we propose a novel multi-output Gaussian process (MOGP) based on\nGaussian mixture regression (GMR). The proposed approach encapsulates the\nvariability retrieved from the demonstrations in the covariance of the MOGP.\nLeveraging the generative nature of GP models, our approach can efficiently\nmodulate trajectories towards new start-, via- or end-points defined by the\ntask. Our framework allows the robot to precisely track via-points while being\ncompliant in regions of high variability. We illustrate the proposed approach\nin simulated examples and validate it in a real-robot experiment.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 07:39:38 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Jaquier", "No\u00e9mie", ""], ["Ginsbourger", "David", ""], ["Calinon", "Sylvain", ""]]}, {"id": "1910.05006", "submitter": "Zvika Ben-Haim", "authors": "Zvika Ben-Haim, Vladimir Anisimov, Aaron Yonas, Varun Gulshan, Yusef\n  Shafi, Stephan Hoyer, and Sella Nevo", "title": "Inundation Modeling in Data Scarce Regions", "comments": "To appear in the Artificial Intelligence for Humanitarian Assistance\n  and Disaster Response Workshop (AI+HADR) @ NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flood forecasts are crucial for effective individual and governmental\nprotective action. The vast majority of flood-related casualties occur in\ndeveloping countries, where providing spatially accurate forecasts is a\nchallenge due to scarcity of data and lack of funding. This paper describes an\noperational system providing flood extent forecast maps covering several\nflood-prone regions in India, with the goal of being sufficiently scalable and\ncost-efficient to facilitate the establishment of effective flood forecasting\nsystems globally.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 07:40:39 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 10:54:48 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Ben-Haim", "Zvika", ""], ["Anisimov", "Vladimir", ""], ["Yonas", "Aaron", ""], ["Gulshan", "Varun", ""], ["Shafi", "Yusef", ""], ["Hoyer", "Stephan", ""], ["Nevo", "Sella", ""]]}, {"id": "1910.05014", "submitter": "Jean-Claude Houbart M.", "authors": "Jean-Claude Houbart, Solen Quiniou, Marion Berthaut, B\\'eatrice\n  Daille, Claire Salom\\'e", "title": "Automatic segmentation of texts into units of meaning for reading\n  assistance", "comments": "7 pages, 7 figures. Work Presented at International Joint Conferences\n  on Artificial Intelligence (IJCAI ) workshop on AI and the United Nations\n  Sustainable Development Goals", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The emergence of the digital book is a major step forward in providing access\nto reading, and therefore often to the common culture and the labour market. By\nallowing the enrichment of texts with cognitive crutches, EPub 3 compatible\naccessibility formats such as FROG have proven their effectiveness in\nalleviating but also reducing dyslexic disorders. In this paper, we show how\nArtificial Intelligence and particularly Transfer Learning with Google BERT can\nautomate the division into units of meaning, and thus facilitate the creation\nof enriched digital books at a moderate cost.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 07:54:38 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Houbart", "Jean-Claude", ""], ["Quiniou", "Solen", ""], ["Berthaut", "Marion", ""], ["Daille", "B\u00e9atrice", ""], ["Salom\u00e9", "Claire", ""]]}, {"id": "1910.05018", "submitter": "Nathana\\\"el Fijalkow", "authors": "Nathana\\\"el Fijalkow, Mohit Kumar Gupta", "title": "Verification of Neural Networks: Specifying Global Robustness using\n  Generative Models", "comments": "A preliminary version was presented at the VNN Symposium\n  (Verification of Neural Networks) in Stanford, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of neural networks across most machine learning tasks and the\npersistence of adversarial examples have made the verification of such models\nan important quest. Several techniques have been successfully developed to\nverify robustness, and are now able to evaluate neural networks with thousands\nof nodes. The main weakness of this approach is in the specification:\nrobustness is asserted on a validation set consisting of a finite set of\nexamples, i.e. locally.\n  We propose a notion of global robustness based on generative models, which\nasserts the robustness on a very large and representative set of examples. We\nshow how this can be used for verifying neural networks. In this paper we\nexperimentally explore the merits of this approach, and show how it can be used\nto construct realistic adversarial examples.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 08:05:54 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Fijalkow", "Nathana\u00ebl", ""], ["Gupta", "Mohit Kumar", ""]]}, {"id": "1910.05026", "submitter": "Alex Bird", "authors": "Alex Bird, Christopher K. I. Williams", "title": "Customizing Sequence Generation with Multi-Task Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical system models (including RNNs) often lack the ability to adapt the\nsequence generation or prediction to a given context, limiting their real-world\napplication. In this paper we show that hierarchical multi-task dynamical\nsystems (MTDSs) provide direct user control over sequence generation, via use\nof a latent code $\\mathbf{z}$ that specifies the customization to the\nindividual data sequence. This enables style transfer, interpolation and\nmorphing within generated sequences. We show the MTDS can improve predictions\nvia latent code interpolation, and avoid the long-term performance degradation\nof standard RNN approaches.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 08:32:13 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Bird", "Alex", ""], ["Williams", "Christopher K. I.", ""]]}, {"id": "1910.05030", "submitter": "Maximilian Idahl", "authors": "Maximilian Idahl, Megha Khosla and Avishek Anand", "title": "Finding Interpretable Concept Spaces in Node Embeddings using Knowledge\n  Bases", "comments": "Accepted for poster presentation at ECML PKDD AIMLAI-XKDD workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose and study the novel problem of explaining node\nembeddings by finding embedded human interpretable subspaces in already trained\nunsupervised node representation embeddings. We use an external knowledge base\nthat is organized as a taxonomy of human-understandable concepts over entities\nas a guide to identify subspaces in node embeddings learned from an entity\ngraph derived from Wikipedia. We propose a method that given a concept finds a\nlinear transformation to a subspace where the structure of the concept is\nretained. Our initial experiments show that we obtain low error in finding\nfine-grained concepts.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 08:40:50 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Idahl", "Maximilian", ""], ["Khosla", "Megha", ""], ["Anand", "Avishek", ""]]}, {"id": "1910.05054", "submitter": "Weisi Guo", "authors": "Zhiyong Du, Yansha Deng, Weisi Guo, Arumugam Nallanathan, Qihui Wu", "title": "Green Deep Reinforcement Learning for Radio Resource Management:\n  Architecture, Algorithm Compression and Challenge", "comments": "under review in IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI heralds a step-change in the performance and capability of wireless\nnetworks and other critical infrastructures. However, it may also cause\nirreversible environmental damage due to their high energy consumption. Here,\nwe address this challenge in the context of 5G and beyond, where there is a\ncomplexity explosion in radio resource management (RRM). On the one hand, deep\nreinforcement learning (DRL) provides a powerful tool for scalable optimization\nfor high dimensional RRM problems in a dynamic environment. On the other hand,\nDRL algorithms consume a high amount of energy over time and risk compromising\nprogress made in green radio research. This paper reviews and analyzes how to\nachieve green DRL for RRM via both architecture and algorithm innovations.\nArchitecturally, a cloud based training and distributed decision-making DRL\nscheme is proposed, where RRM entities can make lightweight deep local\ndecisions whilst assisted by on-cloud training and updating. On the algorithm\nlevel, compression approaches are introduced for both deep neural networks and\nthe underlying Markov Decision Processes, enabling accurate low-dimensional\nrepresentations of challenges. To scale learning across geographic areas, a\nspatial transfer learning scheme is proposed to further promote the learning\nefficiency of distributed DRL entities by exploiting the traffic demand\ncorrelations. Together, our proposed architecture and algorithms provide a\nvision for green and on-demand DRL capability.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 09:51:15 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Du", "Zhiyong", ""], ["Deng", "Yansha", ""], ["Guo", "Weisi", ""], ["Nallanathan", "Arumugam", ""], ["Wu", "Qihui", ""]]}, {"id": "1910.05057", "submitter": "Elahe Arani", "authors": "Elahe Arani, Fahad Sarfraz, Bahram Zonooz", "title": "Noise as a Resource for Learning in Knowledge Distillation", "comments": "Accepted at IEEE Winter Conference on Applications of Computer Vision\n  (WACV, 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While noise is commonly considered a nuisance in computing systems, a number\nof studies in neuroscience have shown several benefits of noise in the nervous\nsystem from enabling the brain to carry out computations such as probabilistic\ninference as well as carrying additional information about the stimuli.\nSimilarly, noise has been shown to improve the performance of deep neural\nnetworks. In this study, we further investigate the effect of adding noise in\nthe knowledge distillation framework because of its resemblance to\ncollaborative subnetworks in the brain regions. We empirically show that\ninjecting constructive noise at different levels in the collaborative learning\nframework enables us to train the model effectively and distill desirable\ncharacteristics in the student model. In doing so, we propose three different\nmethods that target the common challenges in deep neural networks: minimizing\nthe performance gap between a compact model and large model (Fickle Teacher),\ntraining high performance compact adversarially robust models (Soft\nRandomization), and training models efficiently under label noise (Messy\nCollaboration). Our findings motivate further study in the role of noise as a\nresource for learning in a collaborative learning framework.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 09:58:50 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 11:52:30 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Arani", "Elahe", ""], ["Sarfraz", "Fahad", ""], ["Zonooz", "Bahram", ""]]}, {"id": "1910.05065", "submitter": "Leonidas Doumas", "authors": "Leonidas A. A. Doumas, Guillermo Puebla, Andrea E. Martin, John E.\n  Hummel", "title": "Relation learning in a neurocomputational architecture supports\n  cross-domain transfer", "comments": "Includes supplemental material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  People readily generalise prior knowledge to novel situations and stimuli.\nAdvances in machine learning and artificial intelligence have begun to\napproximate and even surpass human performance in specific domains, but machine\nlearning systems struggle to generalise information to untrained situations. We\npresent and model that demonstrates human-like extrapolatory generalisation by\nlearning and explicitly representing an open-ended set of relations\ncharacterising regularities within the domains it is exposed to. First, when\ntrained to play one video game (e.g., Breakout). the model generalises to a new\ngame (e.g., Pong) with different rules, dimensions, and characteristics in a\nsingle shot. Second, the model can learn representations from a different\ndomain (e.g., 3D shape images) that support learning a video game and\ngeneralising to a new game in one shot. By exploiting well-established\nprinciples from cognitive psychology and neuroscience, the model learns\nstructured representations without feedback, and without requiring knowledge of\nthe relevant relations to be given a priori. We present additional simulations\nshowing that the representations that the model learns support cross-domain\ngeneralisation. The model's ability to generalise between different games\ndemonstrates the flexible generalisation afforded by a capacity to learn not\nonly statistical relations, but also other relations that are useful for\ncharacterising the domain to be learned. In turn, this kind of flexible,\nrelational generalisation is only possible because the model is capable of\nrepresenting relations explicitly, a capacity that is notably absent in extant\nstatistical machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 10:21:06 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Doumas", "Leonidas A. A.", ""], ["Puebla", "Guillermo", ""], ["Martin", "Andrea E.", ""], ["Hummel", "John E.", ""]]}, {"id": "1910.05083", "submitter": "Kohei Yoshikawa", "authors": "Kohei Yoshikawa, Shuichi Kawano", "title": "Sparse Reduced-Rank Regression for Simultaneous Rank and Variable\n  Selection via Manifold Optimization", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constructing a reduced-rank regression model whose\ncoefficient parameter is represented as a singular value decomposition with\nsparse singular vectors. The traditional estimation procedure for the\ncoefficient parameter often fails when the true rank of the parameter is high.\nTo overcome this issue, we develop an estimation algorithm with rank and\nvariable selection via sparse regularization and manifold optimization, which\nenables us to obtain an accurate estimation of the coefficient parameter even\nif the true rank of the coefficient parameter is high. Using sparse\nregularization, we can also select an optimal value of the rank. We conduct\nMonte Carlo experiments and real data analysis to illustrate the effectiveness\nof our proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 11:22:21 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 05:38:11 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Yoshikawa", "Kohei", ""], ["Kawano", "Shuichi", ""]]}, {"id": "1910.05092", "submitter": "B. Mert Albaba", "authors": "Mert Albaba, Yildiray Yildiz", "title": "Modeling Cyber-Physical Human Systems via an Interplay Between\n  Reinforcement Learning and Game Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the outcomes of cyber-physical systems with multiple human\ninteractions is a challenging problem. This article reviews a game theoretical\napproach to address this issue, where reinforcement learning is employed to\npredict the time-extended interaction dynamics. We explain that the most\nattractive feature of the method is proposing a computationally feasible\napproach to simultaneously model multiple humans as decision makers, instead of\ndetermining the decision dynamics of the intelligent agent of interest and\nforcing the others to obey certain kinematic and dynamic constraints imposed by\nthe environment. We present two recent exploitations of the method to model 1)\nunmanned aircraft integration into the National Airspace System and 2) highway\ntraffic. We conclude the article by providing ongoing and future work about\nemploying, improving and validating the method. We also provide related open\nproblems and research opportunities.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 11:41:03 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Albaba", "Mert", ""], ["Yildiz", "Yildiray", ""]]}, {"id": "1910.05093", "submitter": "Tao Sun", "authors": "Tao Sun, Yuejiao Sun, Dongsheng Li, Qing Liao", "title": "General Proximal Incremental Aggregated Gradient Algorithms: Better and\n  Novel Results under General Scheme", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The incremental aggregated gradient algorithm is popular in network\noptimization and machine learning research. However, the current convergence\nresults require the objective function to be strongly convex. And the existing\nconvergence rates are also limited to linear convergence. Due to the\nmathematical techniques, the stepsize in the algorithm is restricted by the\nstrongly convex constant, which may make the stepsize be very small (the\nstrongly convex constant may be small).\n  In this paper, we propose a general proximal incremental aggregated gradient\nalgorithm, which contains various existing algorithms including the basic\nincremental aggregated gradient method. Better and new convergence results are\nproved even with the general scheme. The novel results presented in this paper,\nwhich have not appeared in previous literature, include: a general scheme,\nnonconvex analysis, the sublinear convergence rates of the function values,\nmuch larger stepsizes that guarantee the convergence, the convergence when\nnoise exists, the line search strategy of the proximal incremental aggregated\ngradient algorithm and its convergence.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 11:41:37 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Sun", "Tao", ""], ["Sun", "Yuejiao", ""], ["Li", "Dongsheng", ""], ["Liao", "Qing", ""]]}, {"id": "1910.05098", "submitter": "Elahe Ghalebi", "authors": "Elahe Ghalebi, Hamidreza Mahyar, Radu Grosu, Graham W. Taylor, Sinead\n  A. Williamson", "title": "A Nonparametric Bayesian Model for Sparse Dynamic Multigraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the availability and importance of temporal interaction data--such as\nemail communication--increases, it becomes increasingly important to understand\nthe underlying structure that underpins these interactions. Often these\ninteractions form a multigraph, where we might have multiple interactions\nbetween two entities. Such multigraphs tend to be sparse yet structured, and\ntheir distribution often evolves over time. Existing statistical models with\ninterpretable parameters can capture some, but not all, of these properties. We\npropose a dynamic nonparametric model for interaction multigraphs that combines\nthe sparsity of edge-exchangeable multigraphs with dynamic clustering patterns\nthat tend to reinforce recent behavioral patterns. We show that our method\nyields improved held-out likelihood over stationary variants, and impressive\npredictive performance against a range of state-of-the-art dynamic graph\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 12:07:54 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 23:01:10 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ghalebi", "Elahe", ""], ["Mahyar", "Hamidreza", ""], ["Grosu", "Radu", ""], ["Taylor", "Graham W.", ""], ["Williamson", "Sinead A.", ""]]}, {"id": "1910.05103", "submitter": "Wittawat Jitkrittum", "authors": "Mijung Park, Margarita Vinaroz, Wittawat Jitkrittum", "title": "ABCDP: Approximate Bayesian Computation with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel approximate Bayesian computation (ABC) framework, ABCDP,\nthat produces differentially private (DP) and approximate posterior samples.\nOur framework takes advantage of the Sparse Vector Technique (SVT), widely\nstudied in the differential privacy literature. SVT incurs the privacy cost\nonly when a condition (whether a quantity of interest is above/below a\nthreshold) is met. If the condition is met sparsely during the repeated\nqueries, SVT can drastically reduces the cumulative privacy loss, unlike the\nusual case where every query incurs the privacy loss. In ABC, the quantity of\ninterest is the distance between observed and simulated data, and only when the\ndistance is below a threshold, we take the corresponding prior sample as a\nposterior sample. Hence, applying SVT to ABC is an organic way to transform an\nABC algorithm to a privacy-preserving variant with minimal modification, but\nyields the posterior samples with a high privacy level. We theoretically\nanalyze the interplay between the noise added for privacy and the accuracy of\nthe posterior samples.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 12:14:22 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 09:36:42 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 20:55:53 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Park", "Mijung", ""], ["Vinaroz", "Margarita", ""], ["Jitkrittum", "Wittawat", ""]]}, {"id": "1910.05104", "submitter": "Igor Colin", "authors": "Igor Colin, Ludovic Dos Santos, Kevin Scaman", "title": "Theoretical Limits of Pipeline Parallel Optimization and Application to\n  Distributed Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the theoretical limits of pipeline parallel learning of deep\nlearning architectures, a distributed setup in which the computation is\ndistributed per layer instead of per example. For smooth convex and non-convex\nobjective functions, we provide matching lower and upper complexity bounds and\nshow that a naive pipeline parallelization of Nesterov's accelerated gradient\ndescent is optimal. For non-smooth convex functions, we provide a novel\nalgorithm coined Pipeline Parallel Random Smoothing (PPRS) that is within a\n$d^{1/4}$ multiplicative factor of the optimal convergence rate, where $d$ is\nthe underlying dimension. While the convergence rate still obeys a slow\n$\\varepsilon^{-2}$ convergence rate, the depth-dependent part is accelerated,\nresulting in a near-linear speed-up and convergence time that only slightly\ndepends on the depth of the deep learning architecture. Finally, we perform an\nempirical analysis of the non-smooth non-convex case and show that, for\ndifficult and highly non-smooth problems, PPRS outperforms more traditional\noptimization algorithms such as gradient descent and Nesterov's accelerated\ngradient descent for problems where the sample size is limited, such as\nfew-shot or adversarial learning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 12:18:56 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Colin", "Igor", ""], ["Santos", "Ludovic Dos", ""], ["Scaman", "Kevin", ""]]}, {"id": "1910.05108", "submitter": "Lovedeep Gondara", "authors": "Lovedeep Gondara, Ke Wang", "title": "Differentially Private Survival Function Estimation", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival function estimation is used in many disciplines, but it is most\ncommon in medical analytics in the form of the Kaplan-Meier estimator.\nSensitive data (patient records) is used in the estimation without any explicit\ncontrol on the information leakage, which is a significant privacy concern. We\npropose a first differentially private estimator of the survival function and\nshow that it can be easily extended to provide differentially private\nconfidence intervals and test statistics without spending any extra privacy\nbudget. We further provide extensions for differentially private estimation of\nthe competing risk cumulative incidence function, Nelson-Aalen's estimator for\nthe hazard function, etc. Using eleven real-life clinical datasets, we provide\nempirical evidence that our proposed method provides good utility while\nsimultaneously providing strong privacy guarantees.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:15:40 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 21:02:49 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Gondara", "Lovedeep", ""], ["Wang", "Ke", ""]]}, {"id": "1910.05110", "submitter": "Edgar Liberis", "authors": "Edgar Liberis, Nicholas D. Lane", "title": "Neural networks on microcontrollers: saving memory at inference via\n  operator reordering", "comments": "The tool is available at https://github.com/oxmlsys/tflite-tools", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing deep learning models for highly-constrained hardware would allow\nimbuing many edge devices with intelligence. Microcontrollers (MCUs) are an\nattractive platform for building smart devices due to their low cost, wide\navailability, and modest power usage. However, they lack the computational\nresources to run neural networks as straightforwardly as mobile or server\nplatforms, which necessitates changes to the network architecture and the\ninference software. In this work, we discuss the deployment and memory concerns\nof neural networks on MCUs and present a way of saving memory by changing the\nexecution order of the network's operators, which is orthogonal to other\ncompression methods. We publish a tool for reordering operators of TensorFlow\nLite models and demonstrate its utility by sufficiently reducing the memory\nfootprint of a CNN to deploy it on an MCU with 512KB SRAM.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:17:14 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 17:31:30 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Liberis", "Edgar", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "1910.05112", "submitter": "Krystian Radlak", "authors": "Krystian Radlak, Micha{\\l} Szczepankiewicz, Tim Jones, Piotr Serwa", "title": "Organization of machine learning based product development as per ISO\n  26262 and ISO/PAS 21448", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": "10.1109/PRDC50213.2020.00022", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) algorithms generate a continuous stream of success\nstories from various domains and enable many novel applications in\nsafety-critical systems. With the advent of autonomous driving, ML algorithms\nare being used in the automotive domain, where the applicable functional safety\nstandard is ISO 26262. However, requirements and recommendations provided by\nISO 26262 do not cover specific properties of machine learning algorithms.\nTherefore, specific aspects of ML (e.g., dataset requirements, performance\nevaluation metrics, lack of interpretability) must be addressed within some\nwork products, which collect documentation resulting from one or more\nassociated requirements and recommendations of ISO 26262. In this paper, we\npropose how key technical aspects and supporting processes related to\ndevelopment of ML-based systems can be organized according to ISO 26262 phases,\nsub-phases, and work products. We follow the same approach as in the ISO/PAS\n21448 standard, which complements ISO 26262, in order to account for edge cases\nthat can lead to hazards not directly caused by system failure.%, but resulting\nfrom functional insufficiencies of the intended functionality or by reasonably\nforeseeable misuse by persons.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 11:31:58 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 11:57:57 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Radlak", "Krystian", ""], ["Szczepankiewicz", "Micha\u0142", ""], ["Jones", "Tim", ""], ["Serwa", "Piotr", ""]]}, {"id": "1910.05113", "submitter": "Deepak P", "authors": "Savitha Sam Abraham, Deepak P, Sowmya S Sundaram", "title": "Fairness in Clustering with Multiple Sensitive Attributes", "comments": "Proceedings of the 23rd International Conference on Extending\n  Database Technology (EDBT 2020), 30th March-2nd April, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A clustering may be considered as fair on pre-specified sensitive attributes\nif the proportions of sensitive attribute groups in each cluster reflect that\nin the dataset. In this paper, we consider the task of fair clustering for\nscenarios involving multiple multi-valued or numeric sensitive attributes. We\npropose a fair clustering method, \\textit{FairKM} (Fair K-Means), that is\ninspired by the popular K-Means clustering formulation. We outline a\ncomputational notion of fairness which is used along with a cluster coherence\nobjective, to yield the FairKM clustering method. We empirically evaluate our\napproach, wherein we quantify both the quality and fairness of clusters, over\nreal-world datasets. Our experimental evaluation illustrates that the clusters\ngenerated by FairKM fare significantly better on both clustering quality and\nfair representation of sensitive attribute groups compared to the clusters from\na state-of-the-art baseline fair clustering method.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 12:28:52 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 16:52:25 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Abraham", "Savitha Sam", ""], ["P", "Deepak", ""], ["Sundaram", "Sowmya S", ""]]}, {"id": "1910.05117", "submitter": "Steven Atkinson", "authors": "Steven Atkinson and Waad Subber and Liping Wang and Genghis Khan and\n  Philippe Hawi and Roger Ghanem", "title": "Data-driven discovery of free-form governing differential equations", "comments": "Approved for public release; distribution is unlimited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method of discovering governing differential equations from data\nwithout the need to specify a priori the terms to appear in the equation. The\ninput to our method is a dataset (or ensemble of datasets) corresponding to a\nparticular solution (or ensemble of particular solutions) of a differential\nequation. The output is a human-readable differential equation with parameters\ncalibrated to the individual particular solutions provided. The key to our\nmethod is to learn differentiable models of the data that subsequently serve as\ninputs to a genetic programming algorithm in which graphs specify computation\nover arbitrary compositions of functions, parameters, and (potentially\ndifferential) operators on functions. Differential operators are composed and\nevaluated using recursive application of automatic differentiation, allowing\nour algorithm to explore arbitrary compositions of operators without the need\nfor human intervention. We also demonstrate an active learning process to\nidentify and remedy deficiencies in the proposed governing equations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 02:12:19 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 17:17:48 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Atkinson", "Steven", ""], ["Subber", "Waad", ""], ["Wang", "Liping", ""], ["Khan", "Genghis", ""], ["Hawi", "Philippe", ""], ["Ghanem", "Roger", ""]]}, {"id": "1910.05118", "submitter": "Amir Mosavi Prof", "authors": "Shahaboddin Shamshirband, Masoud Hadipoor, Alireza Baghban, Amir\n  Mosavi, Jozsef Bukor, Annamaria Varkonyi Koczy", "title": "Developing an ANFIS PSO Model to Estimate Mercury Emission in Combustion\n  Flue Gases", "comments": "31 pages, 7 figures", "journal-ref": null, "doi": "10.20944/preprints201905.0124.v3", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate prediction of mercury content emitted from fossil fueled power\nstations is of utmost important for environmental pollution assessment and\nhazard mitigation. In this paper, mercury content in the output gas of power\nstations boilers was predicted using adaptive neuro fuzzy inference system\nmethod integrated with particle swarm optimization. The input parameters of the\nmodel include coal characteristics and the operational parameters of the\nboilers. The dataset has been collected from a number of power plants and\nemployed to educate and examine the proposed model. To evaluate the performance\nof the proposed ANFIS PSO model the statistical meter of MARE was implemented.\nFurthermore, relative errors between acquired data and predicted values\npresented, which confirm the accuracy of the model to deal nonlinearity and\nrepresenting the dependency of flue gas mercury content into the specifications\nof coal and the boiler type.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 16:17:20 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Shamshirband", "Shahaboddin", ""], ["Hadipoor", "Masoud", ""], ["Baghban", "Alireza", ""], ["Mosavi", "Amir", ""], ["Bukor", "Jozsef", ""], ["Koczy", "Annamaria Varkonyi", ""]]}, {"id": "1910.05124", "submitter": "Christopher De Sa", "authors": "Bowen Yang, Jian Zhang, Jonathan Li, Christopher R\\'e, Christopher R.\n  Aberger and Christopher De Sa", "title": "PipeMare: Asynchronous Pipeline Parallel DNN Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pipeline parallelism (PP) when training neural networks enables larger models\nto be partitioned spatially, leading to both lower network communication and\noverall higher hardware utilization. Unfortunately, to preserve the statistical\nefficiency of sequential training, existing PP techniques sacrifice hardware\nefficiency by decreasing pipeline utilization or incurring extra memory costs.\nIn this paper, we investigate to what extent these sacrifices are necessary. We\ndevise PipeMare, a simple yet robust training method that tolerates\nasynchronous updates during PP execution without sacrificing utilization or\nmemory, which allows efficient use of fine-grained pipeline parallelism.\nConcretely, when tested on ResNet and Transformer networks, asynchrony enables\nPipeMare to use up to $2.7\\times$ less memory or get $4.3\\times$ higher\npipeline utilization, with similar model quality, when compared to\nstate-of-the-art synchronous PP training techniques.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 19:20:24 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 01:34:36 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yang", "Bowen", ""], ["Zhang", "Jian", ""], ["Li", "Jonathan", ""], ["R\u00e9", "Christopher", ""], ["Aberger", "Christopher R.", ""], ["De Sa", "Christopher", ""]]}, {"id": "1910.05132", "submitter": "Pramod Kaushik Mudrakarta", "authors": "Pramod Kaushik Mudrakarta, Shubhendu Trivedi, Risi Kondor", "title": "Asymmetric Multiresolution Matrix Factorization", "comments": "preliminary work", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiresolution Matrix Factorization (MMF) was recently introduced as an\nalternative to the dominant low-rank paradigm in order to capture structure in\nmatrices at multiple different scales. Using ideas from multiresolution\nanalysis (MRA), MMF teased out hierarchical structure in symmetric matrices by\nconstructing a sequence of wavelet bases. While effective for such matrices,\nthere is plenty of data that is more naturally represented as nonsymmetric\nmatrices (e.g. directed graphs), but nevertheless has similar hierarchical\nstructure. In this paper, we explore techniques for extending MMF to any square\nmatrix. We validate our approach on numerous matrix compression tasks,\ndemonstrating its efficacy compared to low-rank methods. Moreover, we also show\nthat a combined low-rank and MMF approach, which amounts to removing a small\nglobal-scale component of the matrix and then extracting hierarchical structure\nfrom the residual, is even more effective than each of the two complementary\nmethods for matrix compression.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 16:24:03 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Mudrakarta", "Pramod Kaushik", ""], ["Trivedi", "Shubhendu", ""], ["Kondor", "Risi", ""]]}, {"id": "1910.05148", "submitter": "Mark Boss", "authors": "Mark Boss, Hendrik P.A. Lensch", "title": "Single Image BRDF Parameter Estimation with a Conditional Adversarial\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating plausible surfaces is an essential component in achieving a high\ndegree of realism in rendering. To relieve artists, who create these surfaces\nin a time-consuming, manual process, automated retrieval of the\nspatially-varying Bidirectional Reflectance Distribution Function (SVBRDF) from\na single mobile phone image is desirable. By leveraging a deep neural network,\nthis casual capturing method can be achieved. The trained network can estimate\nper pixel normal, base color, metallic and roughness parameters from the Disney\nBRDF. The input image is taken with a mobile phone lit by the camera flash. The\nnetwork is trained to compensate for environment lighting and thus learned to\nreduce artifacts introduced by other light sources. These losses contain a\nmulti-scale discriminator with an additional perceptual loss, a rendering loss\nusing a differentiable renderer, and a parameter loss. Besides the local\nprecision, this loss formulation generates material texture maps which are\nglobally more consistent. The network is set up as a generator network trained\nin an adversarial fashion to ensure that only plausible maps are produced. The\nestimated parameters not only reproduce the material faithfully in rendering\nbut capture the style of hand-authored materials due to the more global loss\nterms compared to previous works without requiring additional post-processing.\nBoth the resolution and the quality is improved.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 13:00:06 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Boss", "Mark", ""], ["Lensch", "Hendrik P. A.", ""]]}, {"id": "1910.05149", "submitter": "Nicolas Farrugia", "authors": "Yusuf Pilavci (IMT Atlantique - ELEC, POLIMI), Nicolas Farrugia (IMT\n  Atlantique - ELEC)", "title": "Spectral Graph Wavelet Transform as Feature Extractor for Machine\n  Learning in Neuroimaging", "comments": null, "journal-ref": "International Conference on Acoustics, Speech, and Signal\n  Processing, May 2019, Brighton, United Kingdom", "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Signal Processing has become a very useful framework for signal\noperations and representations defined on irregular domains. Exploiting\ntransformations that are defined on graph models can be highly beneficial when\nthe graph encodes relationships between signals. In this work, we present the\nbenefits of using Spectral Graph Wavelet Transform (SGWT) as a feature\nextractor for machine learning on brain graphs. First, we consider a synthetic\nregression problem in which the smooth graph signals are generated as input\nwith additive noise, and the target is derived from the input without noise.\nThis enables us to optimize the spectrum coverage using different wavelet\nshapes. Finally, we present the benefits obtained by SGWT on a functional\nMagnetic Resonance Imaging (fMRI) open dataset on human subjects, with several\ngraphs and wavelet shapes, by demonstrating significant performance\nimprovements compared to the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 13:00:44 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Pilavci", "Yusuf", "", "IMT Atlantique - ELEC, POLIMI"], ["Farrugia", "Nicolas", "", "IMT\n  Atlantique - ELEC"]]}, {"id": "1910.05150", "submitter": "Qichen Li", "authors": "Qichen Li, Jiaxin Pei, Jianding Zhang, Bo Han", "title": "SUM: Suboptimal Unitary Multi-task Learning Framework for Spatiotemporal\n  Data Prediction", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The typical multi-task learning methods for spatio-temporal data prediction\ninvolve low-rank tensor computation. However, such a method have relatively\nweak performance when the task number is small, and we cannot integrate it into\nnon-linear models. In this paper, we propose a two-step suboptimal unitary\nmethod (SUM) to combine a meta-learning strategy into multi-task models. In the\nfirst step, it searches for a global pattern by optimising the general\nparameters with gradient descents under constraints, which is a geological\nregularizer to enable model learning with less training data. In the second\nstep, we derive an optimised model on each specific task from the global\npattern with only a few local training data. Compared with traditional\nmulti-task learning methods, SUM shows advantages of generalisation ability on\ndistant tasks. It can be applied on any multi-task models with the gradient\ndescent as its optimiser regardless if the prediction function is linear or\nnot. Moreover, we can harness the model to enable traditional prediction model\nto make coKriging. The experiments on public datasets have suggested that our\nframework, when combined with current multi-task models, has a conspicuously\nbetter prediction result when the task number is small compared to low-rank\ntensor learning, and our model has a quite satisfying outcome when adjusting\nthe current prediction models for coKriging.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 13:02:30 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Li", "Qichen", ""], ["Pei", "Jiaxin", ""], ["Zhang", "Jianding", ""], ["Han", "Bo", ""]]}, {"id": "1910.05171", "submitter": "Byeonggeun Kim", "authors": "Byeonggeun Kim, Mingu Lee, Jinkyu Lee, Yeonseok Kim, and Kyuwoong\n  Hwang", "title": "Query-by-example on-device keyword spotting", "comments": "IEEE ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A keyword spotting (KWS) system determines the existence of, usually\npredefined, keyword in a continuous speech stream. This paper presents a\nquery-by-example on-device KWS system which is user-specific. The proposed\nsystem consists of two main steps: query enrollment and testing. In query\nenrollment step, phonetic posteriors are output by a small-footprint automatic\nspeech recognition model based on connectionist temporal classification. Using\nthe phonetic-level posteriorgram, hypothesis graph of finite-state transducer\n(FST) is built, thus can enroll any keywords thus avoiding an out-of-vocabulary\nproblem. In testing, a log-likelihood is scored for input audio using the FST.\nWe propose a threshold prediction method while using the user-specific keyword\nhypothesis only. The system generates query-specific negatives by rearranging\neach query utterance in waveform. The threshold is decided based on the\nenrollment queries and generated negatives. We tested two keywords in English,\nand the proposed work shows promising performance while preserving simplicity.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 13:28:03 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 03:37:05 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 01:55:51 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Kim", "Byeonggeun", ""], ["Lee", "Mingu", ""], ["Lee", "Jinkyu", ""], ["Kim", "Yeonseok", ""], ["Hwang", "Kyuwoong", ""]]}, {"id": "1910.05173", "submitter": "Ibai Roman", "authors": "Ibai Roman, Roberto Santana, Alexander Mendiburu, Jose A. Lozano", "title": "Evolving Gaussian Process kernels from elementary mathematical\n  expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Choosing the most adequate kernel is crucial in many Machine Learning\napplications. Gaussian Process is a state-of-the-art technique for regression\nand classification that heavily relies on a kernel function. However, in the\nGaussian Process literature, kernels have usually been either ad hoc designed,\nselected from a predefined set, or searched for in a space of compositions of\nkernels which have been defined a priori. In this paper, we propose a\nGenetic-Programming algorithm that represents a kernel function as a tree of\nelementary mathematical expressions. By means of this representation, a wider\nset of kernels can be modeled, where potentially better solutions can be found,\nalthough new challenges also arise. The proposed algorithm is able to overcome\nthese difficulties and find kernels that accurately model the characteristics\nof the data. This method has been tested in several real-world time-series\nextrapolation problems, improving the state-of-the-art results while reducing\nthe complexity of the kernels.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 13:29:42 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 08:20:38 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Roman", "Ibai", ""], ["Santana", "Roberto", ""], ["Mendiburu", "Alexander", ""], ["Lozano", "Jose A.", ""]]}, {"id": "1910.05177", "submitter": "Michael Pradel", "authors": "Yaza Wainakh and Moiz Rauf and Michael Pradel", "title": "IdBench: Evaluating Semantic Representations of Identifier Names in\n  Source Code", "comments": "Accepted as full research paper at International Conference on\n  Software Engineering (ICSE) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifier names convey useful information about the intended semantics of\ncode. Name-based program analyses use this information, e.g., to detect bugs,\nto predict types, and to improve the readability of code. At the core of\nname-based analyses are semantic representations of identifiers, e.g., in the\nform of learned embeddings. The high-level goal of such a representation is to\nencode whether two identifiers, e.g., len and size, are semantically similar.\nUnfortunately, it is currently unclear to what extent semantic representations\nmatch the semantic relatedness and similarity perceived by developers. This\npaper presents IdBench, the first benchmark for evaluating semantic\nrepresentations against a ground truth created from thousands of ratings by 500\nsoftware developers. We use IdBench to study state-of-the-art embedding\ntechniques proposed for natural language, an embedding technique specifically\ndesigned for source code, and lexical string distance functions. Our results\nshow that the effectiveness of semantic representations varies significantly\nand that the best available embeddings successfully represent semantic\nrelatedness. On the downside, no existing technique provides a satisfactory\nrepresentation of semantic similarities, among other reasons because\nidentifiers with opposing meanings are incorrectly considered to be similar,\nwhich may lead to fatal mistakes, e.g., in a refactoring tool. Studying the\nstrengths and weaknesses of the different techniques shows that they complement\neach other. As a first step toward exploiting this complementarity, we present\nan ensemble model that combines existing techniques and that clearly\noutperforms the best available semantic representation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 13:34:30 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 10:07:16 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Wainakh", "Yaza", ""], ["Rauf", "Moiz", ""], ["Pradel", "Michael", ""]]}, {"id": "1910.05189", "submitter": "Pan Li", "authors": "Pan Li, Alexander Tuzhilin", "title": "DDTCDR: Deep Dual Transfer Cross Domain Recommendation", "comments": "Accepted to WSDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross domain recommender systems have been increasingly valuable for helping\nconsumers identify the most satisfying items from different categories.\nHowever, previously proposed cross-domain models did not take into account\nbidirectional latent relations between users and items. In addition, they do\nnot explicitly model information of user and item features, while utilizing\nonly user ratings information for recommendations. To address these concerns,\nin this paper we propose a novel approach to cross-domain recommendations based\non the mechanism of dual learning that transfers information between two\nrelated domains in an iterative manner until the learning process stabilizes.\nWe develop a novel latent orthogonal mapping to extract user preferences over\nmultiple domains while preserving relations between users across different\nlatent spaces. Combining with autoencoder approach to extract the latent\nessence of feature information, we propose Deep Dual Transfer Cross Domain\nRecommendation (DDTCDR) model to provide recommendations in respective domains.\nWe test the proposed method on a large dataset containing three domains of\nmovies, book and music items and demonstrate that it consistently and\nsignificantly outperforms several state-of-the-art baselines and also classical\ntransfer learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 13:51:20 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Li", "Pan", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "1910.05199", "submitter": "Massimiliano Patacchiola PhD", "authors": "Massimiliano Patacchiola, Jack Turner, Elliot J. Crowley, Michael\n  O'Boyle, Amos Storkey", "title": "Bayesian Meta-Learning for the Few-Shot Setting via Deep Kernels", "comments": "Advances in Neural Information Processing Systems (NeurIPS 2020,\n  Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, different machine learning methods have been introduced to tackle\nthe challenging few-shot learning scenario that is, learning from a small\nlabeled dataset related to a specific task. Common approaches have taken the\nform of meta-learning: learning to learn on the new problem given the old.\nFollowing the recognition that meta-learning is implementing learning in a\nmulti-level model, we present a Bayesian treatment for the meta-learning inner\nloop through the use of deep kernels. As a result we can learn a kernel that\ntransfers to new tasks; we call this Deep Kernel Transfer (DKT). This approach\nhas many advantages: is straightforward to implement as a single optimizer,\nprovides uncertainty quantification, and does not require estimation of\ntask-specific parameters. We empirically demonstrate that DKT outperforms\nseveral state-of-the-art algorithms in few-shot classification, and is the\nstate of the art for cross-domain adaptation and regression. We conclude that\ncomplex meta-learning routines can be replaced by a simpler Bayesian model\nwithout loss of accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 14:06:39 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 14:33:51 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2020 16:03:19 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 14:51:41 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Patacchiola", "Massimiliano", ""], ["Turner", "Jack", ""], ["Crowley", "Elliot J.", ""], ["O'Boyle", "Michael", ""], ["Storkey", "Amos", ""]]}, {"id": "1910.05206", "submitter": "Victor Coscrato", "authors": "Victor Coscrato, Marco Henrique de Almeida In\\'acio, Tiago Botari,\n  Rafael Izbicki", "title": "NLS: an accurate and yet easy-to-interpret regression method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important feature of successful supervised machine learning applications\nis to be able to explain the predictions given by the regression or\nclassification model being used. However, most state-of-the-art models that\nhave good predictive power lead to predictions that are hard to interpret.\nThus, several model-agnostic interpreters have been developed recently as a way\nof explaining black-box classifiers. In practice, using these methods is a slow\nprocess because a novel fitting is required for each new testing instance, and\nseveral non-trivial choices must be made. We develop NLS (neural local\nsmoother), a method that is complex enough to give good predictions, and yet\ngives solutions that are easy to be interpreted without the need of using a\nseparate interpreter. The key idea is to use a neural network that imposes a\nlocal linear shape to the output layer. We show that NLS leads to predictive\npower that is comparable to state-of-the-art machine learning models, and yet\nis easier to interpret.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 14:15:52 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Coscrato", "Victor", ""], ["In\u00e1cio", "Marco Henrique de Almeida", ""], ["Botari", "Tiago", ""], ["Izbicki", "Rafael", ""]]}, {"id": "1910.05231", "submitter": "Aleksandar Stanic", "authors": "Aleksandar Stani\\'c and J\\\"urgen Schmidhuber", "title": "R-SQAIR: Relational Sequential Attend, Infer, Repeat", "comments": "4 page workshop paper accepted at the NeurIPS 2019 Workshop on\n  Perception as Generative Reasoning: Structure, Causality, Probability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional sequential multi-object attention models rely on a recurrent\nmechanism to infer object relations. We propose a relational extension\n(R-SQAIR) of one such attention model (SQAIR) by endowing it with a module with\nstrong relational inductive bias that computes in parallel pairwise\ninteractions between inferred objects. Two recently proposed relational modules\nare studied on tasks of unsupervised learning from videos. We demonstrate gains\nover sequential relational mechanisms, also in terms of combinatorial\ngeneralization.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 15:02:34 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Stani\u0107", "Aleksandar", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1910.05233", "submitter": "Artem Chashchin", "authors": "Artem Chashchin, Mikhail Botchev, Ivan Oseledets, George Ovchinnikov", "title": "Predicting dynamical system evolution with residual neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting time series and time-dependent data is a common problem in many\napplications. One typical example is solving ordinary differential equation\n(ODE) systems $\\dot{x}=F(x)$. Oftentimes the right hand side function $F(x)$ is\nnot known explicitly and the ODE system is described by solution samples taken\nat some time points. Hence, ODE solvers cannot be used. In this paper, a\ndata-driven approach to learning the evolution of dynamical systems is\nconsidered. We show how by training neural networks with ResNet-like\narchitecture on the solution samples, models can be developed to predict the\nODE system solution further in time. By evaluating the proposed approaches on\nthree test ODE systems, we demonstrate that the neural network models are able\nto reproduce the main dynamics of the systems qualitatively well. Moreover, the\npredicted solution remains stable for much longer times than for other\ncurrently known models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 15:03:14 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Chashchin", "Artem", ""], ["Botchev", "Mikhail", ""], ["Oseledets", "Ivan", ""], ["Ovchinnikov", "George", ""]]}, {"id": "1910.05242", "submitter": "Zeman Shao", "authors": "Zeman Shao, Runyu Mao and Fengqing Zhu", "title": "Semi-Automatic Crowdsourcing Tool for Online Food Image Collection and\n  Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing dietary intake accurately remains an open and challenging research\nproblem. In recent years, image-based approaches have been developed to\nautomatically estimate food intake by capturing eat occasions with mobile\ndevices and wearable cameras. To build a reliable machine-learning models that\ncan automatically map pixels to calories, successful image-based systems need\nlarge collections of food images with high quality groundtruth labels to\nimprove the learned models. In this paper, we introduce a semi-automatic system\nfor online food image collection and annotation. Our system consists of a web\ncrawler, an automatic food detection method and a web-based crowdsoucing tool.\nThe web crawler is used to download large sets of online food images based on\nthe given food labels. Since not all retrieved images contain foods, we\nintroduce an automatic food detection method to remove irrelevant images. We\ndesigned a web-based crowdsourcing tool to assist the crowd or human annotators\nto locate and label all the foods in the images. The proposed semi-automatic\nonline food image collection system can be used to build large food image\ndatasets with groundtruth labels efficiently from scratch.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 15:20:48 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 18:22:32 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Shao", "Zeman", ""], ["Mao", "Runyu", ""], ["Zhu", "Fengqing", ""]]}, {"id": "1910.05243", "submitter": "Md. Mirajul Islam", "authors": "Sharmin Akther Purabi, Rayhan Rashed, Md. Mirajul Islam, Md. Nahiyan\n  Uddin, Mahmuda Naznin, and A. B. M. Alim Al Islam", "title": "As You Are, So Shall You Move Your Head: A System-Level Analysis between\n  Head Movements and Corresponding Traits and Emotions", "comments": "9 pages, 7 figures, NSysS 2019", "journal-ref": null, "doi": "10.1145/3362966.3362985", "report-no": null, "categories": "cs.HC cs.IR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying physical traits and emotions based on system-sensed physical\nactivities is a challenging problem in the realm of human-computer interaction.\nOur work contributes in this context by investigating an underlying connection\nbetween head movements and corresponding traits and emotions. To do so, we\nutilize a head movement measuring device called eSense, which gives\nacceleration and rotation of a head. Here, first, we conduct a thorough study\nover head movement data collected from 46 persons using eSense while inducing\nfive different emotional states over them in isolation. Our analysis reveals\nseveral new head movement based findings, which in turn, leads us to a novel\nunified solution for identifying different human traits and emotions through\nexploiting machine learning techniques over head movement data. Our analysis\nconfirms that the proposed solution can result in high accuracy over the\ncollected data. Accordingly, we develop an integrated unified solution for\nreal-time emotion and trait identification using head movement data leveraging\noutcomes of our analysis.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 15:22:37 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Purabi", "Sharmin Akther", ""], ["Rashed", "Rayhan", ""], ["Islam", "Md. Mirajul", ""], ["Uddin", "Md. Nahiyan", ""], ["Naznin", "Mahmuda", ""], ["Islam", "A. B. M. Alim Al", ""]]}, {"id": "1910.05245", "submitter": "Asier Mujika", "authors": "Asier Mujika and Felix Weissenberger and Angelika Steger", "title": "Decoupling Hierarchical Recurrent Neural Networks With Locally\n  Computable Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning long-term dependencies is a key long-standing challenge of recurrent\nneural networks (RNNs). Hierarchical recurrent neural networks (HRNNs) have\nbeen considered a promising approach as long-term dependencies are resolved\nthrough shortcuts up and down the hierarchy. Yet, the memory requirements of\nTruncated Backpropagation Through Time (TBPTT) still prevent training them on\nvery long sequences. In this paper, we empirically show that in (deep) HRNNs,\npropagating gradients back from higher to lower levels can be replaced by\nlocally computable losses, without harming the learning capability of the\nnetwork, over a wide range of tasks. This decoupling by local losses reduces\nthe memory requirements of training by a factor exponential in the depth of the\nhierarchy in comparison to standard TBPTT.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 15:25:28 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Mujika", "Asier", ""], ["Weissenberger", "Felix", ""], ["Steger", "Angelika", ""]]}, {"id": "1910.05250", "submitter": "Changying Du", "authors": "Changying Du, Jia He, Changde Du, Fuzhen Zhuang, Qing He and Guoping\n  Long", "title": "Efficient and Adaptive Kernelization for Nonlinear Max-margin Multi-view\n  Learning", "comments": "Multi-view learning, Adaptive kernel, Maximum margin learning, Linear\n  scalability, Dirichlet process Gaussian mixtures, Bayesian inference, Data\n  augmentation, Hamiltonian Monte Carlo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing multi-view learning methods based on kernel function either require\nthe user to select and tune a single predefined kernel or have to compute and\nstore many Gram matrices to perform multiple kernel learning. Apart from the\nhuge consumption of manpower, computation and memory resources, most of these\nmodels seek point estimation of their parameters, and are prone to overfitting\nto small training data. This paper presents an adaptive kernel nonlinear\nmax-margin multi-view learning model under the Bayesian framework.\nSpecifically, we regularize the posterior of an efficient multi-view latent\nvariable model by explicitly mapping the latent representations extracted from\nmultiple data views to a random Fourier feature space where max-margin\nclassification constraints are imposed. Assuming these random features are\ndrawn from Dirichlet process Gaussian mixtures, we can adaptively learn\nshift-invariant kernels from data according to Bochners theorem. For inference,\nwe employ the data augmentation idea for hinge loss, and design an efficient\ngradient-based MCMC sampler in the augmented space. Having no need to compute\nthe Gram matrix, our algorithm scales linearly with the size of training set.\nExtensive experiments on real-world datasets demonstrate that our method has\nsuperior performance.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 15:32:20 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Du", "Changying", ""], ["He", "Jia", ""], ["Du", "Changde", ""], ["Zhuang", "Fuzhen", ""], ["He", "Qing", ""], ["Long", "Guoping", ""]]}, {"id": "1910.05253", "submitter": "Chien-Hsun Lai", "authors": "Tsai-Ho Sun, Chien-Hsun Lai, Sai-Keung Wong, and Yu-Shuen Wang", "title": "Adversarial Colorization Of Icons Based On Structure And Color\n  Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system to help designers create icons that are widely used in\nbanners, signboards, billboards, homepages, and mobile apps. Designers are\ntasked with drawing contours, whereas our system colorizes contours in\ndifferent styles. This goal is achieved by training a dual conditional\ngenerative adversarial network (GAN) on our collected icon dataset. One\ncondition requires the generated image and the drawn contour to possess a\nsimilar contour, while the other anticipates the image and the referenced icon\nto be similar in color style. Accordingly, the generator takes a contour image\nand a man-made icon image to colorize the contour, and then the discriminators\ndetermine whether the result fulfills the two conditions. The trained network\nis able to colorize icons demanded by designers and greatly reduces their\nworkload. For the evaluation, we compared our dual conditional GAN to several\nstate-of-the-art techniques. Experiment results demonstrate that our network is\nover the previous networks. Finally, we will provide the source code, icon\ndataset, and trained network for public use.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 22:48:46 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Sun", "Tsai-Ho", ""], ["Lai", "Chien-Hsun", ""], ["Wong", "Sai-Keung", ""], ["Wang", "Yu-Shuen", ""]]}, {"id": "1910.05262", "submitter": "Hadi Abdullah", "authors": "Hadi Abdullah, Muhammad Sajidur Rahman, Washington Garcia, Logan Blue,\n  Kevin Warren, Anurag Swarnim Yadav, Tom Shrimpton and Patrick Traynor", "title": "Hear \"No Evil\", See \"Kenansville\": Efficient and Transferable Black-Box\n  Attacks on Speech Recognition and Voice Identification Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition and voice identification systems are being\ndeployed in a wide array of applications, from providing control mechanisms to\ndevices lacking traditional interfaces, to the automatic transcription of\nconversations and authentication of users. Many of these applications have\nsignificant security and privacy considerations. We develop attacks that force\nmistranscription and misidentification in state of the art systems, with\nminimal impact on human comprehension. Processing pipelines for modern systems\nare comprised of signal preprocessing and feature extraction steps, whose\noutput is fed to a machine-learned model. Prior work has focused on the models,\nusing white-box knowledge to tailor model-specific attacks. We focus on the\npipeline stages before the models, which (unlike the models) are quite similar\nacross systems. As such, our attacks are black-box and transferable, and\ndemonstrably achieve mistranscription and misidentification rates as high as\n100% by modifying only a few frames of audio. We perform a study via Amazon\nMechanical Turk demonstrating that there is no statistically significant\ndifference between human perception of regular and perturbed audio. Our\nfindings suggest that models may learn aspects of speech that are generally not\nperceived by human subjects, but that are crucial for model accuracy. We also\nfind that certain English language phonemes (in particular, vowels) are\nsignificantly more susceptible to our attack. We show that the attacks are\neffective when mounted over cellular networks, where signals are subject to\ndegradation due to transcoding, jitter, and packet loss.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 15:54:40 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Abdullah", "Hadi", ""], ["Rahman", "Muhammad Sajidur", ""], ["Garcia", "Washington", ""], ["Blue", "Logan", ""], ["Warren", "Kevin", ""], ["Yadav", "Anurag Swarnim", ""], ["Shrimpton", "Tom", ""], ["Traynor", "Patrick", ""]]}, {"id": "1910.05265", "submitter": "Chris Norval", "authors": "Chris Norval, Tristan Henderson", "title": "Automating dynamic consent decisions for the processing of social media\n  data in health research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media have become a rich source of data, particularly in health\nresearch. Yet, the use of such data raises significant ethical questions about\nthe need for the informed consent of those being studied. Consent mechanisms,\nif even obtained, are typically broad and inflexible, or place a significant\nburden on the participant. Machine learning algorithms show much promise for\nfacilitating a 'middle ground' approach: using trained models to predict and\nautomate granular consent decisions. Such techniques, however, raise a myriad\nof follow-on ethical and technical considerations. In this paper, we present an\nexploratory user study (n = 67) in which we find that we can predict the\nappropriate flow of health-related social media data with reasonable accuracy,\nwhile minimising undesired data leaks. We then attempt to deconstruct the\nfindings of this study, identifying and discussing a number of real-world\nimplications if such a technique were put into practice.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 15:57:00 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Norval", "Chris", ""], ["Henderson", "Tristan", ""]]}, {"id": "1910.05266", "submitter": "Pantelis Vlachas", "authors": "Pantelis R. Vlachas, Jaideep Pathak, Brian R. Hunt, Themistoklis P.\n  Sapsis, Michelle Girvan, Edward Ott, Petros Koumoutsakos", "title": "Backpropagation Algorithms and Reservoir Computing in Recurrent Neural\n  Networks for the Forecasting of Complex Spatiotemporal Dynamics", "comments": "41 pages, submitted to Elsevier Journal of Neural Networks (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the efficiency of Recurrent Neural Networks in forecasting the\nspatiotemporal dynamics of high dimensional and reduced order complex systems\nusing Reservoir Computing (RC) and Backpropagation through time (BPTT) for\ngated network architectures. We highlight advantages and limitations of each\nmethod and discuss their implementation for parallel computing architectures.\nWe quantify the relative prediction accuracy of these algorithms for the\nlongterm forecasting of chaotic systems using as benchmarks the Lorenz-96 and\nthe Kuramoto-Sivashinsky (KS) equations. We find that, when the full state\ndynamics are available for training, RC outperforms BPTT approaches in terms of\npredictive performance and in capturing of the long-term statistics, while at\nthe same time requiring much less training time. However, in the case of\nreduced order data, large scale RC models can be unstable and more likely than\nthe BPTT algorithms to diverge. In contrast, RNNs trained via BPTT show\nsuperior forecasting abilities and capture well the dynamics of reduced order\nsystems. Furthermore, the present study quantifies for the first time the\nLyapunov Spectrum of the KS equation with BPTT, achieving similar accuracy as\nRC. This study establishes that RNNs are a potent computational framework for\nthe learning and forecasting of complex spatiotemporal systems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 23:15:32 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 18:21:46 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Vlachas", "Pantelis R.", ""], ["Pathak", "Jaideep", ""], ["Hunt", "Brian R.", ""], ["Sapsis", "Themistoklis P.", ""], ["Girvan", "Michelle", ""], ["Ott", "Edward", ""], ["Koumoutsakos", "Petros", ""]]}, {"id": "1910.05268", "submitter": "Asier Mujika", "authors": "Florian Meier and Asier Mujika and Marcelo Matheus Gauy and Angelika\n  Steger", "title": "Improving Gradient Estimation in Evolutionary Strategies With Past\n  Descent Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary Strategies (ES) are known to be an effective black-box\noptimization technique for deep neural networks when the true gradients cannot\nbe computed, such as in Reinforcement Learning. We continue a recent line of\nresearch that uses surrogate gradients to improve the gradient estimation of\nES. We propose a novel method to optimally incorporate surrogate gradient\ninformation. Our approach, unlike previous work, needs no information about the\nquality of the surrogate gradients and is always guaranteed to find a descent\ndirection that is better than the surrogate gradient. This allows to\niteratively use the previous gradient estimate as surrogate gradient for the\ncurrent search point. We theoretically prove that this yields fast convergence\nto the true gradient for linear functions and show under simplifying\nassumptions that it significantly improves gradient estimates for general\nfunctions. Finally, we evaluate our approach empirically on MNIST and\nreinforcement learning tasks and show that it considerably improves the\ngradient estimation of ES at no extra computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 16:00:39 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Meier", "Florian", ""], ["Mujika", "Asier", ""], ["Gauy", "Marcelo Matheus", ""], ["Steger", "Angelika", ""]]}, {"id": "1910.05270", "submitter": "Aryeh Kontorovich", "authors": "Klim Efremenko, Aryeh Kontorovich, Moshe Noivirt", "title": "Fast and Bayes-consistent nearest neighbors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on nearest-neighbor methods tends to focus somewhat dichotomously\neither on the statistical or the computational aspects -- either on, say, Bayes\nconsistency and rates of convergence or on techniques for speeding up the\nproximity search. This paper aims at bridging these realms: to reap the\nadvantages of fast evaluation time while maintaining Bayes consistency, and\nfurther without sacrificing too much in the risk decay rate. We combine the\nlocality-sensitive hashing (LSH) technique with a novel missing-mass argument\nto obtain a fast and Bayes-consistent classifier. Our algorithm's prediction\nruntime compares favorably against state of the art approximate NN methods,\nwhile maintaining Bayes-consistency and attaining rates comparable to minimax.\nOn samples of size $n$ in $\\R^d$, our pre-processing phase has runtime $O(d n\n\\log n)$, while the evaluation phase has runtime $O(d\\log n)$ per query point.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 19:46:37 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 21:15:47 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 21:46:51 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Efremenko", "Klim", ""], ["Kontorovich", "Aryeh", ""], ["Noivirt", "Moshe", ""]]}, {"id": "1910.05271", "submitter": "Elena Kalinina", "authors": "Elena Kalinina, Fabian Pedregosa, Vittorio Iacovella, Emanuele\n  Olivetti, Paolo Avesani", "title": "A Test for Shared Patterns in Cross-modal Brain Activation Analysis", "comments": "5 figures, tables after References (as required by SciRep template)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the extent to which different cognitive modalities (understood\nhere as the set of cognitive processes underlying the elaboration of a stimulus\nby the brain) rely on overlapping neural representations is a fundamental issue\nin cognitive neuroscience. In the last decade, the identification of shared\nactivity patterns has been mostly framed as a supervised learning problem. For\ninstance, a classifier is trained to discriminate categories (e.g. faces vs.\nhouses) in modality I (e.g. perception) and tested on the same categories in\nmodality II (e.g. imagery). This type of analysis is often referred to as\ncross-modal decoding. In this paper we take a different approach and instead\nformulate the problem of assessing shared patterns across modalities within the\nframework of statistical hypothesis testing. We propose both an appropriate\ntest statistic and a scheme based on permutation testing to compute the\nsignificance of this test while making only minimal distributional assumption.\nWe denote this test cross-modal permutation test (CMPT). We also provide\nempirical evidence on synthetic datasets that our approach has greater\nstatistical power than the cross-modal decoding method while maintaining low\nType I errors (rejecting a true null hypothesis). We compare both approaches on\nan fMRI dataset with three different cognitive modalities (perception, imagery,\nvisual search). Finally, we show how CMPT can be combined with Searchlight\nanalysis to explore spatial distribution of shared activity patterns.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 19:33:49 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Kalinina", "Elena", ""], ["Pedregosa", "Fabian", ""], ["Iacovella", "Vittorio", ""], ["Olivetti", "Emanuele", ""], ["Avesani", "Paolo", ""]]}, {"id": "1910.05276", "submitter": "Sebastian Gehrmann", "authors": "Benjamin Hoover, Hendrik Strobelt, Sebastian Gehrmann", "title": "exBERT: A Visual Analysis Tool to Explore Learned Representations in\n  Transformers Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large language models can produce powerful contextual representations that\nlead to improvements across many NLP tasks. Since these models are typically\nguided by a sequence of learned self attention mechanisms and may comprise\nundesired inductive biases, it is paramount to be able to explore what the\nattention has learned. While static analyses of these models lead to targeted\ninsights, interactive tools are more dynamic and can help humans better gain an\nintuition for the model-internal reasoning process. We present exBERT, an\ninteractive tool named after the popular BERT language model, that provides\ninsights into the meaning of the contextual representations by matching a\nhuman-specified input to similar contexts in a large annotated dataset. By\naggregating the annotations of the matching similar contexts, exBERT helps\nintuitively explain what each attention-head has learned.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 16:10:55 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Hoover", "Benjamin", ""], ["Strobelt", "Hendrik", ""], ["Gehrmann", "Sebastian", ""]]}, {"id": "1910.05280", "submitter": "Masato Tamura", "authors": "Masato Tamura, Tomokazu Murakami", "title": "Augmented Hard Example Mining for Generalizable Person Re-Identification", "comments": "Submit to WACV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the performance of person re-identification (Re-ID) has been much\nimproved by using sophisticated training methods and large-scale labelled\ndatasets, many existing methods make the impractical assumption that\ninformation of a target domain can be utilized during training. In practice, a\nRe-ID system often starts running as soon as it is deployed, hence training\nwith data from a target domain is unrealistic. To make Re-ID systems more\npractical, methods have been proposed that achieve high performance without\ninformation of a target domain. However, they need cumbersome tuning for\ntraining and unusual operations for testing. In this paper, we propose\naugmented hard example mining, which can be easily integrated to a common Re-ID\ntraining process and can utilize sophisticated models without any network\nmodification. The method discovers hard examples on the basis of classification\nprobabilities, and to make the examples harder, various types of augmentation\nare applied to the examples. Among those examples, excessively augmented ones\nare eliminated by a classification based selection process. Extensive analysis\nshows that our method successfully selects effective examples and achieves\nstate-of-the-art performance on publicly available benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 16:19:53 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Tamura", "Masato", ""], ["Murakami", "Tomokazu", ""]]}, {"id": "1910.05291", "submitter": "Serhii Havrylov", "authors": "Shangmin Guo, Yi Ren, Serhii Havrylov, Stella Frank, Ivan Titov, Kenny\n  Smith", "title": "The Emergence of Compositional Languages for Numeric Concepts Through\n  Iterated Learning in Neural Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since first introduced, computer simulation has been an increasingly\nimportant tool in evolutionary linguistics. Recently, with the development of\ndeep learning techniques, research in grounded language learning has also\nstarted to focus on facilitating the emergence of compositional languages\nwithout pre-defined elementary linguistic knowledge. In this work, we explore\nthe emergence of compositional languages for numeric concepts in multi-agent\ncommunication systems. We demonstrate that compositional language for encoding\nnumeric concepts can emerge through iterated learning in populations of deep\nneural network agents. However, language properties greatly depend on the input\nrepresentations given to agents. We found that compositional languages only\nemerge if they require less iterations to be fully learnt than other\nnon-degenerate languages for agents on a given input representation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 16:34:01 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Guo", "Shangmin", ""], ["Ren", "Yi", ""], ["Havrylov", "Serhii", ""], ["Frank", "Stella", ""], ["Titov", "Ivan", ""], ["Smith", "Kenny", ""]]}, {"id": "1910.05299", "submitter": "Awni Hannun", "authors": "Awni Hannun, Brian Knott, Shubho Sengupta, Laurens van der Maaten", "title": "Privacy-Preserving Multi-Party Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits are online learners that, given an input, select an arm\nand receive a reward for that arm. They use the reward as a learning signal and\naim to maximize the total reward over the inputs. Contextual bandits are\ncommonly used to solve recommendation or ranking problems. This paper considers\na learning setting in which multiple parties aim to train a contextual bandit\ntogether in a private way: the parties aim to maximize the total reward but do\nnot want to share any of the relevant information they possess with the other\nparties. Specifically, multiple parties have access to (different) features\nthat may benefit the learner but that cannot be shared with other parties. One\nof the parties pulls the arm but other parties may not learn which arm was\npulled. One party receives the reward but the other parties may not learn the\nreward value. This paper develops a privacy-preserving multi-party contextual\nbandit for this learning setting by combining secure multi-party computation\nwith a differentially private mechanism based on epsilon-greedy exploration.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 16:48:17 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 09:59:47 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 15:30:00 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Hannun", "Awni", ""], ["Knott", "Brian", ""], ["Sengupta", "Shubho", ""], ["van der Maaten", "Laurens", ""]]}, {"id": "1910.05303", "submitter": "Yulun Jiang", "authors": "Yulun Jiang, Lei Yu, Haijian Zhang, Zhou Liu", "title": "Learning Cluster Structured Sparsity by Reweighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the paradigm of unfolding iterative algorithms into finite-length\nfeed-forward neural networks has achieved a great success in the area of sparse\nrecovery. Benefit from available training data, the learned networks have\nachieved state-of-the-art performance in respect of both speed and accuracy.\nHowever, the structure behind sparsity, imposing constraint on the support of\nsparse signals, is often an essential prior knowledge but seldom considered in\nthe existing networks. In this paper, we aim at bridging this gap.\nSpecifically, exploiting the iterative reweighted $\\ell_1$ minimization (IRL1)\nalgorithm, we propose to learn the cluster structured sparsity (CSS) by\nrewegihting adaptively. In particular, we first unfold the Reweighted Iterative\nShrinkage Algorithm (RwISTA) into an end-to-end trainable deep architecture\ntermed as RW-LISTA. Then instead of the element-wise reweighting, the global\nand local reweighting manner are proposed for the cluster structured sparse\nlearning. Numerical experiments further show the superiority of our algorithm\nagainst both classical algorithms and learning-based networks on different\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 16:56:36 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Jiang", "Yulun", ""], ["Yu", "Lei", ""], ["Zhang", "Haijian", ""], ["Liu", "Zhou", ""]]}, {"id": "1910.05305", "submitter": "Faris B Mismar", "authors": "Faris B. Mismar, Ahmad AlAmmouri, Ahmed Alkhateeb, Jeffrey G. Andrews,\n  Brian L. Evans", "title": "Deep Learning Predictive Band Switching in Wireless Networks", "comments": "31 pages, 15 figures, revised and resubmitted to IEEE Transactions on\n  Wireless Communications on October 2, 2019, March 9, 2020, July 2, 2020, and\n  September 1, 2020", "journal-ref": "2020 IEEE Transactions on Wireless Communications", "doi": "10.1109/TWC.2020.3023397", "report-no": null, "categories": "cs.NI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cellular systems, the user equipment (UE) can request a change in the\nfrequency band when its rate drops below a threshold on the current band. The\nUE is then instructed by the base station (BS) to measure the quality of\ncandidate bands, which requires a measurement gap in the data transmission,\nthus lowering the data rate. We propose an online-learning based band switching\napproach that does not require any measurement gap. Our proposed\nclassifier-based band switching policy instead exploits spatial and spectral\ncorrelation between radio frequency signals in different bands based on\nknowledge of the UE location. We focus on switching between a lower (e.g., 3.5\nGHz) band and a millimeter wave band (e.g., 28 GHz), and design and evaluate\ntwo classification models that are trained on a ray-tracing dataset. A key\ninsight is that measurement gaps are overkill, in that only the relative order\nof the bands is necessary for band selection, rather than a full channel\nestimate. Our proposed machine learning based policies achieve roughly 30%\nimprovement in mean effective rates over those of the industry standard policy,\nwhile achieving misclassification errors well below 0.5% and maintaining\nresilience against blockage uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:44:50 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 16:47:07 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 19:08:43 GMT"}, {"version": "v4", "created": "Tue, 1 Sep 2020 14:48:19 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mismar", "Faris B.", ""], ["AlAmmouri", "Ahmad", ""], ["Alkhateeb", "Ahmed", ""], ["Andrews", "Jeffrey G.", ""], ["Evans", "Brian L.", ""]]}, {"id": "1910.05308", "submitter": "Mahadesh Panju", "authors": "Ramkumar Raghu, Pratheek Upadhyaya, Mahadesh Panju, Vaneet Aggarwal,\n  Vinod Sharma", "title": "Deep Reinforcement Learning Based Power control for Wireless Multicast\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multicast scheme recently proposed for a wireless downlink in\n[1]. It was shown earlier that power control can significantly improve its\nperformance. However for this system, obtaining optimal power control is\nintractable because of a very large state space. Therefore in this paper we use\ndeep reinforcement learning where we use function approximation of the\nQ-function via a deep neural network. We show that optimal power control can be\nlearnt for reasonably large systems via this approach. The average power\nconstraint is ensured via a Lagrange multiplier, which is also learnt. Finally,\nwe demonstrate that a slight modification of the learning algorithm allows the\noptimal control to track the time varying system statistics.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:08:09 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 01:12:09 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Raghu", "Ramkumar", ""], ["Upadhyaya", "Pratheek", ""], ["Panju", "Mahadesh", ""], ["Aggarwal", "Vaneet", ""], ["Sharma", "Vinod", ""]]}, {"id": "1910.05309", "submitter": "Chuan-Chi Lai", "authors": "Li-Chun Wang, Chuan-Chi Lai, Hong-Han Shuai, Hsin-Piao Lin, Chi-Yu Li,\n  Teng-Hu Cheng, Chiun-Hsun Chen", "title": "Communications and Networking Technologies for Intelligent Drone\n  Cruisers", "comments": "6 pages, 11 figures, accepted by 2019 IEEE Globecom Workshops (GC\n  Wkshps): IEEE GLOBECOM 2019 Workshop on Space-Ground Integrated Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future mobile communication networks require an Aerial Base Station (ABS)\nwith fast mobility and long-term hovering capabilities. At present, unmanned\naerial vehicles (UAV) or drones do not have long flight times and are mainly\nused for monitoring, surveillance, and image post-processing. On the other\nhand, the traditional airship is too large and not easy to take off and land.\nTherefore, we propose to develop an \"Artificial Intelligence (AI)\nDrone-Cruiser\" base station that can help 5G mobile communication systems and\nbeyond quickly recover the network after a disaster and handle the instant\ncommunications by the flash crowd. The drone-cruiser base station can overcome\nthe communications problem for three types of flash crowds, such as in\nstadiums, parades, and large plaza so that an appropriate number of aerial base\nstations can be accurately deployed to meet large and dynamic traffic demands.\nArtificial intelligence can solve these problems by analyzing the collected\ndata, and then adjust the system parameters in the framework of Self-Organizing\nNetwork (SON) to achieve the goals of self-configuration, self-optimization,\nand self-healing. With the help of AI technologies, 5G networks can become more\nintelligent. This paper aims to provide a new type of service, On-Demand Aerial\nBase Station as a Service. This work needs to overcome the following five\ntechnical challenges: innovative design of drone-cruisers for the long-time\nhovering, crowd estimation and prediction, rapid 3D wireless channel learning\nand modeling, 3D placement of aerial base stations and the integration of WiFi\nfront-haul and millimeter wave/WiGig back-haul networks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:22:29 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Wang", "Li-Chun", ""], ["Lai", "Chuan-Chi", ""], ["Shuai", "Hong-Han", ""], ["Lin", "Hsin-Piao", ""], ["Li", "Chi-Yu", ""], ["Cheng", "Teng-Hu", ""], ["Chen", "Chiun-Hsun", ""]]}, {"id": "1910.05315", "submitter": "Aissatou Diallo", "authors": "Aissatou Diallo, Markus Zopf, Johannes F\\\"urnkranz", "title": "Learning Analogy-Preserving Sentence Embeddings for Answer Selection", "comments": "To appear in CoNLL19", "journal-ref": "Proc. CoNLL 2019: 910-919", "doi": "10.18653/v1/K19-1085", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer selection aims at identifying the correct answer for a given question\nfrom a set of potentially correct answers. Contrary to previous works, which\ntypically focus on the semantic similarity between a question and its answer,\nour hypothesis is that question-answer pairs are often in analogical relation\nto each other. Using analogical inference as our use case, we propose a\nframework and a neural network architecture for learning dedicated sentence\nembeddings that preserve analogical properties in the semantic space. We\nevaluate the proposed method on benchmark datasets for answer selection and\ndemonstrate that our sentence embeddings indeed capture analogical properties\nbetter than conventional embeddings, and that analogy-based question answering\noutperforms a comparable similarity-based technique.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 17:22:19 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Diallo", "Aissatou", ""], ["Zopf", "Markus", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1910.05316", "submitter": "Xu Chen", "authors": "En Li and Liekang Zeng and Zhi Zhou and Xu Chen", "title": "Edge AI: On-Demand Accelerating Deep Neural Network Inference via Edge\n  Computing", "comments": "Accepted by IEEE Transactions on Wireless Communications, Sept 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a key technology of enabling Artificial Intelligence (AI) applications in\n5G era, Deep Neural Networks (DNNs) have quickly attracted widespread\nattention. However, it is challenging to run computation-intensive DNN-based\ntasks on mobile devices due to the limited computation resources. What's worse,\ntraditional cloud-assisted DNN inference is heavily hindered by the significant\nwide-area network latency, leading to poor real-time performance as well as low\nquality of user experience. To address these challenges, in this paper, we\npropose Edgent, a framework that leverages edge computing for DNN collaborative\ninference through device-edge synergy. Edgent exploits two design knobs: (1)\nDNN partitioning that adaptively partitions computation between device and edge\nfor purpose of coordinating the powerful cloud resource and the proximal edge\nresource for real-time DNN inference; (2) DNN right-sizing that further reduces\ncomputing latency via early exiting inference at an appropriate intermediate\nDNN layer. In addition, considering the potential network fluctuation in\nreal-world deployment, Edgentis properly design to specialize for both static\nand dynamic network environment. Specifically, in a static environment where\nthe bandwidth changes slowly, Edgent derives the best configurations with the\nassist of regression-based prediction models, while in a dynamic environment\nwhere the bandwidth varies dramatically, Edgent generates the best execution\nplan through the online change point detection algorithm that maps the current\nbandwidth state to the optimal configuration. We implement Edgent prototype\nbased on the Raspberry Pi and the desktop PC and the extensive experimental\nevaluations demonstrate Edgent's effectiveness in enabling on-demand\nlow-latency edge intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 00:53:44 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Li", "En", ""], ["Zeng", "Liekang", ""], ["Zhou", "Zhi", ""], ["Chen", "Xu", ""]]}, {"id": "1910.05318", "submitter": "Dimitrios Kollias", "authors": "Mengyao Liu and Dimitrios Kollias", "title": "Aff-Wild Database and AffWildNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of HCI, building an automatic system to recognize affect of\nhuman facial expression in real-world condition is very crucial to make machine\ninteract naturallisticaly with a man. However, existing facial emotion\ndatabases usually contain expression in the limited scenario under\nwell-controlled condition. Aff-Wild is currently the largest database\nconsisting of spontaneous facial expression in the wild annotated with valence\nand arousal. The first contribution of this project is the completion of\nextending Aff-Wild database which is fulfilled by collecting videos from\nYouTube on which the videos have spontaneous facial expressions in the wild,\nannotating videos with valence and arousal ranging in [-1,1], detecting faces\nin frames using FFLD2 detector and partitioning the whole data set into train,\nvalidate and test set, with 527056, 94223 and 135145 frames. The diversity is\nguaranteed regarding age, ethnicity and values of valence and arousal. The\nratio of male to female is close to 1. Regarding the techniques used to build\nthe automatic system, deep learning is outstanding since almost all winning\nmethods in emotion challenges adopt DNN techniques. The second contribution of\nthis project is that an end-to-end DNN is constructed to have joint CNN and RNN\nblock and gives the estimation on valence and arousal for each frame in\nsequential data. VGGFace, ResNet, DenseNet with the corresponding pre-trained\nmodel for CNN block and LSTM, GRU, IndRNN, Attention mechanism for RNN block\nare experimented aiming to find the best combination. Fine tuning and transfer\nlearning techniques are also tried out. By comparing the CCC evaluation value\non test data, the best model is found to be pre-trained VGGFace connected with\n2 layers GRU with attention mechanism. The models test performance is 0.555 CCC\nfor valence with sequence length 80 and 0.499 CCC for arousal with sequence\nlength 70.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 17:24:45 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 22:42:52 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Liu", "Mengyao", ""], ["Kollias", "Dimitrios", ""]]}, {"id": "1910.05321", "submitter": "Jack Goetz", "authors": "Jack Goetz, Ambuj Tewari", "title": "Not All are Made Equal: Consistency of Weighted Averaging Estimators\n  Under Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning seeks to build the best possible model with a budget of\nlabelled data by sequentially selecting the next point to label. However the\ntraining set is no longer \\textit{iid}, violating the conditions required by\nexisting consistency results. Inspired by the success of Stone's Theorem we aim\nto regain consistency for weighted averaging estimators under active learning.\nBased on ideas in \\citet{dasgupta2012consistency}, our approach is to enforce a\nsmall amount of random sampling by running an augmented version of the\nunderlying active learning algorithm. We generalize Stone's Theorem in the\nnoise free setting, proving consistency for well known classifiers such as\n$k$-NN, histogram and kernel estimators under conditions which mirror classical\nresults. However in the presence of noise we can no longer deal with these\nestimators in a unified manner; for some satisfying this condition also\nguarantees sufficiency in the noisy case, while for others we can achieve near\nperfect inconsistency while this condition holds. Finally we provide conditions\nfor consistency in the presence of noise, which give insight into why these\nestimators can behave so differently under the combination of noise and active\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 17:38:00 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Goetz", "Jack", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1910.05338", "submitter": "Minh Vu", "authors": "Minh H. Vu, Tufve Nyholm, Tommy L\\\"ofstedt", "title": "TuNet: End-to-end Hierarchical Brain Tumor Segmentation using Cascaded\n  Networks", "comments": "Accepted at MICCAI BrainLes 2019", "journal-ref": null, "doi": "10.1007/978-3-030-46640-4_17", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Glioma is one of the most common types of brain tumors; it arises in the\nglial cells in the human brain and in the spinal cord. In addition to having a\nhigh mortality rate, glioma treatment is also very expensive. Hence, automatic\nand accurate segmentation and measurement from the early stages are critical in\norder to prolong the survival rates of the patients and to reduce the costs of\nthe treatment. In the present work, we propose a novel end-to-end cascaded\nnetwork for semantic segmentation that utilizes the hierarchical structure of\nthe tumor sub-regions with ResNet-like blocks and Squeeze-and-Excitation\nmodules after each convolution and concatenation block. By utilizing\ncross-validation, an average ensemble technique, and a simple post-processing\ntechnique, we obtained dice scores of 88.06, 80.84, and 80.29, and Hausdorff\nDistances (95th percentile) of 6.10, 5.17, and 2.21 for the whole tumor, tumor\ncore, and enhancing tumor, respectively, on the online test set.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 19:02:58 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 10:52:11 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 06:43:53 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Vu", "Minh H.", ""], ["Nyholm", "Tufve", ""], ["L\u00f6fstedt", "Tommy", ""]]}, {"id": "1910.05340", "submitter": "Skanda Koppula", "authors": "Skanda Koppula, Lois Orosa, Abdullah Giray Ya\\u{g}l{\\i}k\\c{c}{\\i},\n  Roknoddin Azizi, Taha Shahroodi, Konstantinos Kanellopoulos, Onur Mutlu", "title": "EDEN: Enabling Energy-Efficient, High-Performance Deep Neural Network\n  Inference Using Approximate DRAM", "comments": "This work is to appear at MICRO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of deep neural networks (DNN) in vision, speech, and\nlanguage processing has prompted a tremendous demand for energy-efficient\nhigh-performance DNN inference systems. Due to the increasing memory intensity\nof most DNN workloads, main memory can dominate the system's energy consumption\nand stall time. One effective way to reduce the energy consumption and increase\nthe performance of DNN inference systems is by using approximate memory, which\noperates with reduced supply voltage and reduced access latency parameters that\nviolate standard specifications. Using approximate memory reduces reliability,\nleading to higher bit error rates. Fortunately, neural networks have an\nintrinsic capacity to tolerate increased bit errors. This can enable\nenergy-efficient and high-performance neural network inference using\napproximate DRAM devices.\n  Based on this observation, we propose EDEN, a general framework that reduces\nDNN energy consumption and DNN evaluation latency by using approximate DRAM\ndevices, while strictly meeting a user-specified target DNN accuracy. EDEN\nrelies on two key ideas: 1) retraining the DNN for a target approximate DRAM\ndevice to increase the DNN's error tolerance, and 2) efficient mapping of the\nerror tolerance of each individual DNN data type to a corresponding approximate\nDRAM partition in a way that meets the user-specified DNN accuracy\nrequirements.\n  We evaluate EDEN on multi-core CPUs, GPUs, and DNN accelerators with error\nmodels obtained from real approximate DRAM devices. For a target accuracy\nwithin 1% of the original DNN, our results show that EDEN enables 1) an average\nDRAM energy reduction of 21%, 37%, 31%, and 32% in CPU, GPU, and two DNN\naccelerator architectures, respectively, across a variety of DNNs, and 2) an\naverage (maximum) speedup of 8% (17%) and 2.7% (5.5%) in CPU and GPU\narchitectures, respectively, when evaluating latency-bound DNNs.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 00:56:59 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Koppula", "Skanda", ""], ["Orosa", "Lois", ""], ["Ya\u011fl\u0131k\u00e7\u0131", "Abdullah Giray", ""], ["Azizi", "Roknoddin", ""], ["Shahroodi", "Taha", ""], ["Kanellopoulos", "Konstantinos", ""], ["Mutlu", "Onur", ""]]}, {"id": "1910.05366", "submitter": "Tonghan Wang", "authors": "Tonghan Wang, Jianhao Wang, Chongyi Zheng, Chongjie Zhang", "title": "Learning Nearly Decomposable Value Functions Via Communication\n  Minimization", "comments": "8th International Conference on Learning Representations (ICLR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning encounters major challenges in multi-agent settings,\nsuch as scalability and non-stationarity. Recently, value function\nfactorization learning emerges as a promising way to address these challenges\nin collaborative multi-agent systems. However, existing methods have been\nfocusing on learning fully decentralized value functions, which are not\nefficient for tasks requiring communication. To address this limitation, this\npaper presents a novel framework for learning nearly decomposable Q-functions\n(NDQ) via communication minimization, with which agents act on their own most\nof the time but occasionally send messages to other agents in order for\neffective coordination. This framework hybridizes value function factorization\nlearning and communication learning by introducing two information-theoretic\nregularizers. These regularizers are maximizing mutual information between\nagents' action selection and communication messages while minimizing the\nentropy of messages between agents. We show how to optimize these regularizers\nin a way that is easily integrated with existing value function factorization\nmethods such as QMIX. Finally, we demonstrate that, on the StarCraft unit\nmicromanagement benchmark, our framework significantly outperforms baseline\nmethods and allows us to cut off more than $80\\%$ of communication without\nsacrificing the performance. The videos of our experiments are available at\nhttps://sites.google.com/view/ndq.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 18:31:15 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 01:30:56 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Wang", "Tonghan", ""], ["Wang", "Jianhao", ""], ["Zheng", "Chongyi", ""], ["Zhang", "Chongjie", ""]]}, {"id": "1910.05369", "submitter": "Shailesh Chaudhari", "authors": "Shailesh Chaudhari, HyukJoon Kwon, Kee-Bong Song", "title": "Reliable and Low-Complexity MIMO Detector Selection using Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to dynamically select a MIMO detector using neural\nnetwork for each resource element (RE) in the transport block of 5G NR/LTE\ncommunication system. The objective is to minimize the computational complexity\nof MIMO detection while keeping the transport block error rate (BLER) close to\nthe BLER when dimension-reduced maximum-likelihood (DR-ML) detection is used. A\ndetector selection problem is formulated to achieve this objective. However,\nsince the problem is high dimensional and NP-hard, we first decompose the\nproblem into smaller problems and train a multi-layer perceptron (MLP) network\nto obtain the solution. The MLP network is trained to select a low-complexity,\nyet reliable, detector using instantaneous channel condition in the RE. We\nfirst propose a method to generate a labeled dataset to select a low-complexity\ndetector. Then, the MLP is trained twice using quasi-Newton method to select a\nreliable detector for each RE. The performance of online detector selection is\nevaluated in 5G NR link level simulator in terms of BLER and the complexity is\nquantified in terms of the number of Euclidean distance (ED) computations and\nthe number of real additions and multiplication. Results show that the\ncomputational complexity in the MIMO detector can be reduced by ~10X using the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 18:34:57 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Chaudhari", "Shailesh", ""], ["Kwon", "HyukJoon", ""], ["Song", "Kee-Bong", ""]]}, {"id": "1910.05370", "submitter": "Ilkay Oksuz", "authors": "Ilkay Oksuz, James R. Clough, Bram Ruijsink, Esther Puyol Anton,\n  Aurelien Bustin, Gastao Cruz, Claudia Prieto, Andrew P. King, Julia A.\n  Schnabel", "title": "Deep Learning Based Detection and Correction of Cardiac MR Motion\n  Artefacts During Reconstruction for High-Quality Segmentation", "comments": "Accepted for publication in IEEE TMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmenting anatomical structures in medical images has been successfully\naddressed with deep learning methods for a range of applications. However, this\nsuccess is heavily dependent on the quality of the image that is being\nsegmented. A commonly neglected point in the medical image analysis community\nis the vast amount of clinical images that have severe image artefacts due to\norgan motion, movement of the patient and/or image acquisition related issues.\nIn this paper, we discuss the implications of image motion artefacts on cardiac\nMR segmentation and compare a variety of approaches for jointly correcting for\nartefacts and segmenting the cardiac cavity. The method is based on our\nrecently developed joint artefact detection and reconstruction method, which\nreconstructs high quality MR images from k-space using a joint loss function\nand essentially converts the artefact correction task to an under-sampled image\nreconstruction task by enforcing a data consistency term. In this paper, we\npropose to use a segmentation network coupled with this in an end-to-end\nframework. Our training optimises three different tasks: 1) image artefact\ndetection, 2) artefact correction and 3) image segmentation. We train the\nreconstruction network to automatically correct for motion-related artefacts\nusing synthetically corrupted cardiac MR k-space data and uncorrected\nreconstructed images. Using a test set of 500 2D+time cine MR acquisitions from\nthe UK Biobank data set, we achieve demonstrably good image quality and high\nsegmentation accuracy in the presence of synthetic motion artefacts. We\nshowcase better performance compared to various image correction architectures.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 18:36:17 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 11:24:03 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2019 09:35:21 GMT"}, {"version": "v4", "created": "Fri, 3 Jul 2020 13:59:14 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Oksuz", "Ilkay", ""], ["Clough", "James R.", ""], ["Ruijsink", "Bram", ""], ["Anton", "Esther Puyol", ""], ["Bustin", "Aurelien", ""], ["Cruz", "Gastao", ""], ["Prieto", "Claudia", ""], ["King", "Andrew P.", ""], ["Schnabel", "Julia A.", ""]]}, {"id": "1910.05375", "submitter": "Hyojin Kim", "authors": "Hyojin Kim, Rushil Anirudh, K. Aditya Mohan, Kyle Champley", "title": "Extreme Few-view CT Reconstruction using Deep Inference", "comments": "Deep Inverse NeurIPS 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of few-view x-ray Computed Tomography (CT) data is a highly\nill-posed problem. It is often used in applications that require low radiation\ndose in clinical CT, rapid industrial scanning, or fixed-gantry CT. Existing\nanalytic or iterative algorithms generally produce poorly reconstructed images,\nseverely deteriorated by artifacts and noise, especially when the number of\nx-ray projections is considerably low. This paper presents a deep\nnetwork-driven approach to address extreme few-view CT by incorporating\nconvolutional neural network-based inference into state-of-the-art iterative\nreconstruction. The proposed method interprets few-view sinogram data using\nattention-based deep networks to infer the reconstructed image. The predicted\nimage is then used as prior knowledge in the iterative algorithm for final\nreconstruction. We demonstrate effectiveness of the proposed approach by\nperforming reconstruction experiments on a chest CT dataset.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 18:55:44 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Kim", "Hyojin", ""], ["Anirudh", "Rushil", ""], ["Mohan", "K. Aditya", ""], ["Champley", "Kyle", ""]]}, {"id": "1910.05376", "submitter": "Dimitrios Kollias", "authors": "Alvertos Benroumpi and Dimitrios Kollias", "title": "AffWild Net and Aff-Wild Database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotions recognition is the task of recognizing people's emotions. Usually it\nis achieved by analyzing expression of peoples faces. There are two ways for\nrepresenting emotions: The categorical approach and the dimensional approach by\nusing valence and arousal values. Valence shows how negative or positive an\nemotion is and arousal shows how much it is activated. Recent deep learning\nmodels, that have to do with emotions recognition, are using the second\napproach, valence and arousal. Moreover, a more interesting concept, which is\nuseful in real life is the \"in the wild\" emotions recognition. \"In the wild\"\nmeans that the images analyzed for the recognition task, come from from real\nlife sources(online videos, online photos, etc.) and not from staged\nexperiments. So, they introduce unpredictable situations in the images, that\nhave to be modeled. The purpose of this project is to study the previous work\nthat was done for the \"in the wild\" emotions recognition concept, design a new\ndataset which has as a standard the \"Aff-wild\" database, implement new deep\nlearning models and evaluate the results. First, already existing databases and\ndeep learning models are presented. Then, inspired by them a new database is\ncreated which includes 507.208 frames in total from 106 videos, which were\ngathered from online sources. Then, the data are tested in a CNN model based on\nCNN-M architecture, in order to be sure about their usability. Next, the main\nmodel of this project is implemented. That is a Regression GAN which can\nexecute unsupervised and supervised learning at the same time. More\nspecifically, it keeps the main functionality of GANs, which is to produce fake\nimages that look as good as the real ones, while it can also predict valence\nand arousal values for both real and fake images. Finally, the database created\nearlier is applied to this model and the results are presented and evaluated.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 18:57:18 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 22:58:20 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Benroumpi", "Alvertos", ""], ["Kollias", "Dimitrios", ""]]}, {"id": "1910.05384", "submitter": "Yinsong Wang", "authors": "Yinsong Wang and Shahin Shahrampour", "title": "A General Scoring Rule for Randomized Kernel Approximation with\n  Application to Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random features has been widely used for kernel approximation in large-scale\nmachine learning. A number of recent studies have explored data-dependent\nsampling of features, modifying the stochastic oracle from which random\nfeatures are sampled. While proposed techniques in this realm improve the\napproximation, their application is limited to a specific learning task. In\nthis paper, we propose a general scoring rule for sampling random features,\nwhich can be employed for various applications with some adjustments. We first\nobserve that our method can recover a number of data-dependent sampling methods\n(e.g., leverage scores and energy-based sampling). Then, we restrict our\nattention to a ubiquitous problem in statistics and machine learning, namely\nCanonical Correlation Analysis (CCA). We provide a principled guide for finding\nthe distribution maximizing the canonical correlations, resulting in a novel\ndata-dependent method for sampling features. Numerical experiments verify that\nour algorithm consistently outperforms other sampling techniques in the CCA\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 19:50:00 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 05:24:58 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Wang", "Yinsong", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "1910.05387", "submitter": "Amanda Gentzel", "authors": "Amanda Gentzel, Dan Garant, and David Jensen", "title": "The Case for Evaluating Causal Models Using Interventional Measures and\n  Empirical Data", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference is central to many areas of artificial intelligence,\nincluding complex reasoning, planning, knowledge-base construction, robotics,\nexplanation, and fairness. An active community of researchers develops and\nenhances algorithms that learn causal models from data, and this work has\nproduced a series of impressive technical advances. However, evaluation\ntechniques for causal modeling algorithms have remained somewhat primitive,\nlimiting what we can learn from experimental studies of algorithm performance,\nconstraining the types of algorithms and model representations that researchers\nconsider, and creating a gap between theory and practice. We argue for more\nfrequent use of evaluation techniques that examine interventional measures\nrather than structural or observational measures, and that evaluate those\nmeasures on empirical data rather than synthetic data. We survey the current\npractice in evaluation and show that the techniques we recommend are rarely\nused in practice. We show that such techniques are feasible and that data sets\nare available to conduct such evaluations. We also show that these techniques\nproduce substantially different results than using structural measures and\nsynthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 19:54:30 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 21:22:15 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Gentzel", "Amanda", ""], ["Garant", "Dan", ""], ["Jensen", "David", ""]]}, {"id": "1910.05396", "submitter": "Kimin Lee", "authors": "Kimin Lee, Kibok Lee, Jinwoo Shin, Honglak Lee", "title": "Network Randomization: A Simple Technique for Generalization in Deep\n  Reinforcement Learning", "comments": "Accepted in ICLR 2020 and NeurIPS Workshop on Deep RL 2019 / First\n  two authors are equally contributed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) agents often fail to generalize to unseen\nenvironments (yet semantically similar to trained agents), particularly when\nthey are trained on high-dimensional state spaces, such as images. In this\npaper, we propose a simple technique to improve a generalization ability of\ndeep RL agents by introducing a randomized (convolutional) neural network that\nrandomly perturbs input observations. It enables trained agents to adapt to new\ndomains by learning robust features invariant across varied and randomized\nenvironments. Furthermore, we consider an inference method based on the Monte\nCarlo approximation to reduce the variance induced by this randomization. We\ndemonstrate the superiority of our method across 2D CoinRun, 3D DeepMind Lab\nexploration and 3D robotics control tasks: it significantly outperforms various\nregularization and data augmentation methods for the same purpose.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 20:12:52 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 07:44:13 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 08:29:25 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lee", "Kimin", ""], ["Lee", "Kibok", ""], ["Shin", "Jinwoo", ""], ["Lee", "Honglak", ""]]}, {"id": "1910.05399", "submitter": "Konstantinos Slavakis", "authors": "Konstantinos Slavakis and Sinjini Banerjee", "title": "Robust Hierarchical-Optimization RLS Against Sparse Outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper fortifies the recently introduced hierarchical-optimization\nrecursive least squares (HO-RLS) against outliers which contaminate\ninfrequently linear-regression models. Outliers are modeled as nuisance\nvariables and are estimated together with the linear filter/system variables\nvia a sparsity-inducing (non-)convexly regularized least-squares task. The\nproposed outlier-robust HO-RLS builds on steepest-descent directions with a\nconstant step size (learning rate), needs no matrix inversion (lemma),\naccommodates colored nominal noise of known correlation matrix, exhibits small\ncomputational footprint, and offers theoretical guarantees, in a probabilistic\nsense, for the convergence of the system estimates to the solutions of a\nhierarchical-optimization problem: Minimize a convex loss, which models\na-priori knowledge about the unknown system, over the minimizers of the\nclassical ensemble LS loss. Extensive numerical tests on synthetically\ngenerated data in both stationary and non-stationary scenarios showcase notable\nimprovements of the proposed scheme over state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 20:27:07 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Slavakis", "Konstantinos", ""], ["Banerjee", "Sinjini", ""]]}, {"id": "1910.05401", "submitter": "Leonardo De Laurentiis", "authors": "Leonardo De Laurentiis, Andrea Pomente, Fabio Del Frate, and Giovanni\n  Schiavon", "title": "Capsule and convolutional neural network-based SAR ship classification\n  in Sentinel-1 data", "comments": "Please check out the original SPIE paper for a complete list of\n  figures, tables, references and general content", "journal-ref": "SPIE Remote Sensing 2019: Proceedings Volume 11154, Active and\n  Passive Microwave Remote Sensing for Environmental Monitoring III; 1115405\n  (2019)", "doi": "10.1117/12.2532551", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic Aperture Radar (SAR) constitutes a fundamental asset for wide-areas\nmonitoring with high-resolution requirements. The first SAR sensors have given\nrise to coarse coastal and maritime monitoring applications, including oil\nspill, ship and ice floes detection. With the upgrade to very high-resolution\nsensors in the recent years, with relatively new SAR missions such as\nSentinel-1, a great deal of data providing a stronger information content has\nbeen released, enabling more refined studies on general targets features and\nthus permitting complex classifications, as for ship classification, which has\nbecome increasingly relevant given the growing need for coastal surveillance in\ncommercial and military segments. In the last decade, several works focused on\nthis topic have been presented, generally based on radiometric features\nprocessing; furthermore, in the very recent years a significant amount of\nresearch works have focused on emerging deep learning techniques, in particular\non Convolutional Neural Networks (CNN). Recently Capsule Neural Networks\n(CapsNets) have been presented, demonstrating a notable improvement in\ncapturing the properties of given entities, improving the use of spatial\ninformations, in particular of spatial dependence between features, a severely\nlacking feature in CNNs. In fact, CNNs pooling operations have been criticized\nfor losing spatial relations, thus special capsules, along with a new iterative\nrouting-by-agreement mechanism, have been proposed. In this work a comparison\nbetween Capsule and CNNs potential in the ship classification application\ndomain is shown, by leveraging the OpenSARShip, a SAR Sentinel-1 ship chips\ndataset; in particular, a performance comparison between capsule and various\nconvolutional architectures is built, demonstrating better performances of\nCapsNet in classifying ships within a small dataset.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 20:32:02 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["De Laurentiis", "Leonardo", ""], ["Pomente", "Andrea", ""], ["Del Frate", "Fabio", ""], ["Schiavon", "Giovanni", ""]]}, {"id": "1910.05404", "submitter": "Manuel Camargo", "authors": "Manuel Camargo, Marlon Dumas, Oscar Gonz\\'alez-Rojas", "title": "Automated Discovery of Business Process Simulation Models from Event\n  Logs", "comments": "34 pages, 5 figures, Research paper", "journal-ref": null, "doi": "10.1016/j.dss.2020.113284", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business process simulation is a versatile technique to estimate the\nperformance of a process under multiple scenarios. This, in turn, allows\nanalysts to compare alternative options to improve a business process. A common\nroadblock for business process simulation is that constructing accurate\nsimulation models is cumbersome and error-prone. Modern information systems\nstore detailed execution logs of the business processes they support. Previous\nwork has shown that these logs can be used to discover simulation models.\nHowever, existing methods for log-based discovery of simulation models do not\nseek to optimize the accuracy of the resulting models. Instead they leave it to\nthe user to manually tune the simulation model to achieve the desired level of\naccuracy. This article presents an accuracy-optimized method to discover\nbusiness process simulation models from execution logs. The method decomposes\nthe problem into a series of steps with associated configuration parameters. A\nhyper-parameter optimization method is used to search through the space of\npossible configurations so as to maximize the similarity between the behavior\nof the simulation model and the behavior observed in the log. The method has\nbeen implemented as a tool and evaluated using logs from different domains.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 20:47:26 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 08:26:46 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 22:58:16 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Camargo", "Manuel", ""], ["Dumas", "Marlon", ""], ["Gonz\u00e1lez-Rojas", "Oscar", ""]]}, {"id": "1910.05405", "submitter": "Shuhang Chen", "authors": "Shuhang Chen, Adithya M. Devraj, Fan Lu, Ana Bu\\v{s}i\\'c, Sean P. Meyn", "title": "Zap Q-Learning With Nonlinear Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zap Q-learning is a recent class of reinforcement learning algorithms,\nmotivated primarily as a means to accelerate convergence. Stability theory has\nbeen absent outside of two restrictive classes: the tabular setting, and\noptimal stopping. This paper introduces a new framework for analysis of a more\ngeneral class of recursive algorithms known as stochastic approximation. Based\non this general theory, it is shown that Zap Q-learning is consistent under a\nnon-degeneracy assumption, even when the function approximation architecture is\nnonlinear. Zap Q-learning with neural network function approximation emerges as\na special case, and is tested on examples from OpenAI Gym. Based on multiple\nexperiments with a range of neural network sizes, it is found that the new\nalgorithms converge quickly and are robust to choice of function approximation\narchitecture.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 20:48:09 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 20:02:18 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Chen", "Shuhang", ""], ["Devraj", "Adithya M.", ""], ["Lu", "Fan", ""], ["Bu\u0161i\u0107", "Ana", ""], ["Meyn", "Sean P.", ""]]}, {"id": "1910.05411", "submitter": "Filippo Maria Bianchi", "authors": "Filippo Maria Bianchi, Jakob Grahn, Markus Eckerstorfer, Eirik Malnes,\n  Hannah Vickers", "title": "Snow avalanche segmentation in SAR images with Fully Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge about frequency and location of snow avalanche activity is\nessential for forecasting and mapping of snow avalanche hazard. Traditional\nfield monitoring of avalanche activity has limitations, especially when\nsurveying large and remote areas. In recent years, avalanche detection in\nSentinel-1 radar satellite imagery has been developed to improve monitoring.\nHowever, the current state-of-the-art detection algorithms, based on radar\nsignal processing techniques, are still much less accurate than human experts.\nTo reduce this gap, we propose a deep learning architecture for detecting\navalanches in Sentinel-1 radar images. We trained a neural network on 6,345\nmanually labelled avalanches from 117 Sentinel-1 images, each one consisting of\nsix channels that include backscatter and topographical information. Then, we\ntested our trained model on a new SAR image. Comparing to the manual labelling\n(the gold standard), we achieved an F1 score above 66\\%, while the\nstate-of-the-art detection algorithm sits at an F1 score of only 38\\%. A visual\ninspection of the results generated by our deep learning model shows that only\nsmall avalanches are undetected, while some avalanches that were originally not\nlabelled by the human expert are discovered.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 21:02:57 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 13:00:56 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Grahn", "Jakob", ""], ["Eckerstorfer", "Markus", ""], ["Malnes", "Eirik", ""], ["Vickers", "Hannah", ""]]}, {"id": "1910.05421", "submitter": "Amine Remita", "authors": "Amine M. Remita and Abdoulaye Banir\\'e Diallo", "title": "Statistical Linear Models in Virus Genomic Alignment-free\n  Classification: Application to Hepatitis C Viruses", "comments": "Accepted as a regular paper for publication in IEEE BIBM 2019\n  (Camera-ready version + Supplemental material)", "journal-ref": "2019 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM), San Diego, CA, USA, 2019, pp. 474-481", "doi": "10.1109/BIBM47256.2019.8983375", "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Viral sequence classification is an important task in pathogen detection,\nepidemiological surveys and evolutionary studies. Statistical learning methods\nare widely used to classify and identify viral sequences in samples from\nenvironments. These methods face several challenges associated with the nature\nand properties of viral genomes such as recombination, mutation rate and\ndiversity. Also, new generations of sequencing technologies rise other\ndifficulties by generating massive amounts of fragmented sequences. While\nlinear classifiers are often used to classify viruses, there is a lack of\nexploration of the accuracy space of existing models in the context of\nalignment free approaches. In this study, we present an exhaustive assessment\nprocedure exploring the power of linear classifiers in genotyping and subtyping\npartial and complete genomes. It is applied to the Hepatitis C viruses (HCV).\nSeveral variables are considered in this investigation such as classifier types\n(generative and discriminative) and their hyper-parameters (smoothing value and\nregularization penalty function), the classification task (genotyping and\nsubtyping), the length of the tested sequences (partial and complete) and the\nlength of k-mer words. Overall, several classifiers perform well given a set of\nprecise combination of the experimental variables mentioned above. Finally, we\nprovide the procedure and benchmark data to allow for more robust assessment of\nclassification from virus genomes.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 21:40:24 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 18:23:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Remita", "Amine M.", ""], ["Diallo", "Abdoulaye Banir\u00e9", ""]]}, {"id": "1910.05422", "submitter": "Cenk Baykal", "authors": "Cenk Baykal, Lucas Liebenwein, Igor Gilitschenski, Dan Feldman,\n  Daniela Rus", "title": "SiPPing Neural Networks: Sensitivity-informed Provable Pruning of Neural\n  Networks", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a pruning algorithm that provably sparsifies the parameters of a\ntrained model in a way that approximately preserves the model's predictive\naccuracy. Our algorithm uses a small batch of input points to construct a\ndata-informed importance sampling distribution over the network's parameters,\nand adaptively mixes a sampling-based and deterministic pruning procedure to\ndiscard redundant weights. Our pruning method is simultaneously computationally\nefficient, provably accurate, and broadly applicable to various network\narchitectures and data distributions. Our empirical comparisons show that our\nalgorithm reliably generates highly compressed networks that incur minimal loss\nin performance relative to that of the original network. We present\nexperimental results that demonstrate our algorithm's potential to unearth\nessential network connections that can be trained successfully in isolation,\nwhich may be of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 21:40:59 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 01:03:33 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Baykal", "Cenk", ""], ["Liebenwein", "Lucas", ""], ["Gilitschenski", "Igor", ""], ["Feldman", "Dan", ""], ["Rus", "Daniela", ""]]}, {"id": "1910.05425", "submitter": "Mostafa Karimi", "authors": "Mostafa Karimi, Gopalkrishna Veni, Yen-Yun Yu", "title": "Illegible Text to Readable Text: An Image-to-Image Transformation using\n  Conditional Sliced Wasserstein Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text recognition from ancient handwritten record images is an\nimportant problem in the genealogy domain. However, critical challenges such as\nvarying noise conditions, vanishing texts, and variations in handwriting make\nthe recognition task difficult. We tackle this problem by developing a\nhandwritten-to-machine-print conditional Generative Adversarial network\n(HW2MP-GAN) model that formulates handwritten recognition as a\ntext-Image-to-text-Image translation problem where a given image, typically in\nan illegible form, is converted into another image, close to its machine-print\nform. The proposed model consists of three-components including a generator,\nand word-level and character-level discriminators. The model incorporates\nSliced Wasserstein distance (SWD) and U-Net architectures in HW2MP-GAN for\nbetter quality image-to-image transformation. Our experiments reveal that\nHW2MP-GAN outperforms state-of-the-art baseline cGAN models by almost 30 in\nFrechet Handwritten Distance (FHD), 0.6 on average Levenshtein distance and 39%\nin word accuracy for image-to-image translation on IAM database. Further,\nHW2MP-GAN improves handwritten recognition word accuracy by 1.3% compared to\nbaseline handwritten recognition models on the IAM database.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 22:01:24 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Karimi", "Mostafa", ""], ["Veni", "Gopalkrishna", ""], ["Yu", "Yen-Yun", ""]]}, {"id": "1910.05429", "submitter": "Buse Gul Atli", "authors": "Buse Gul Atli, Sebastian Szyller, Mika Juuti, Samuel Marchal, N.\n  Asokan", "title": "Extraction of Complex DNN Models: Real Threat or Boogeyman?", "comments": "16 pages, 1 figure, Accepted for publication in AAAI-20 Workshop on\n  Engineering Dependable and Secure Machine Learning Systems (AAAI-EDSMLS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, machine learning (ML) has introduced advanced solutions to many\ndomains. Since ML models provide business advantage to model owners, protecting\nintellectual property of ML models has emerged as an important consideration.\nConfidentiality of ML models can be protected by exposing them to clients only\nvia prediction APIs. However, model extraction attacks can steal the\nfunctionality of ML models using the information leaked to clients through the\nresults returned via the API. In this work, we question whether model\nextraction is a serious threat to complex, real-life ML models. We evaluate the\ncurrent state-of-the-art model extraction attack (Knockoff nets) against\ncomplex models. We reproduce and confirm the results in the original paper. But\nwe also show that the performance of this attack can be limited by several\nfactors, including ML model architecture and the granularity of API response.\nFurthermore, we introduce a defense based on distinguishing queries used for\nKnockoff nets from benign queries. Despite the limitations of the Knockoff\nnets, we show that a more realistic adversary can effectively steal complex ML\nmodels and evade known defenses.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 22:25:11 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 21:53:39 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 09:19:08 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Atli", "Buse Gul", ""], ["Szyller", "Sebastian", ""], ["Juuti", "Mika", ""], ["Marchal", "Samuel", ""], ["Asokan", "N.", ""]]}, {"id": "1910.05433", "submitter": "Jie Su", "authors": "Bin Qian, Jie Su, Zhenyu Wen, Devki Nandan Jha, Yinhao Li, Yu Guan,\n  Deepak Puthal, Philip James, Renyu Yang, Albert Y. Zomaya, Omer Rana, Lizhe\n  Wang, Maciej Koutny, Rajiv Ranjan", "title": "Orchestrating the Development Lifecycle of Machine Learning-Based IoT\n  Applications: A Taxonomy and Survey", "comments": "50 pages, Accepted by ACM Computing Surveys (CSUR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) and Internet of Things (IoT) are complementary\nadvances: ML techniques unlock complete potentials of IoT with intelligence,\nand IoT applications increasingly feed data collected by sensors into ML\nmodels, thereby employing results to improve their business processes and\nservices. Hence, orchestrating ML pipelines that encompasses model training and\nimplication involved in holistic development lifecycle of an IoT application\noften leads to complex system integration. This paper provides a comprehensive\nand systematic survey on the development lifecycle of ML-based IoT application.\nWe outline core roadmap and taxonomy, and subsequently assess and compare\nexisting standard techniques used in individual stage.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 23:04:22 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 10:44:31 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 11:54:30 GMT"}, {"version": "v4", "created": "Sat, 9 May 2020 13:36:49 GMT"}, {"version": "v5", "created": "Fri, 29 May 2020 21:59:18 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Qian", "Bin", ""], ["Su", "Jie", ""], ["Wen", "Zhenyu", ""], ["Jha", "Devki Nandan", ""], ["Li", "Yinhao", ""], ["Guan", "Yu", ""], ["Puthal", "Deepak", ""], ["James", "Philip", ""], ["Yang", "Renyu", ""], ["Zomaya", "Albert Y.", ""], ["Rana", "Omer", ""], ["Wang", "Lizhe", ""], ["Koutny", "Maciej", ""], ["Ranjan", "Rajiv", ""]]}, {"id": "1910.05437", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Roweis Discriminant Analysis: A Generalized Subspace Learning Method", "comments": "This is the paper for the methods Roweis Discriminant Analysis (RDA),\n  dual RDA, kernel RDA, and Roweisfaces. This is in memory of Sam Roweis (rest\n  in peace) to whom subspace and manifold learning owes significantly", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method which generalizes subspace learning based on\neigenvalue and generalized eigenvalue problems. This method, Roweis\nDiscriminant Analysis (RDA), is named after Sam Roweis to whom the field of\nsubspace learning owes significantly. RDA is a family of infinite number of\nalgorithms where Principal Component Analysis (PCA), Supervised PCA (SPCA), and\nFisher Discriminant Analysis (FDA) are special cases. One of the extreme\nspecial cases, which we name Double Supervised Discriminant Analysis (DSDA),\nuses the labels twice; it is novel and has not appeared elsewhere. We propose a\ndual for RDA for some special cases. We also propose kernel RDA, generalizing\nkernel PCA, kernel SPCA, and kernel FDA, using both dual RDA and representation\ntheory. Our theoretical analysis explains previously known facts such as why\nSPCA can use regression but FDA cannot, why PCA and SPCA have duals but FDA\ndoes not, why kernel PCA and kernel SPCA use kernel trick but kernel FDA does\nnot, and why PCA is the best linear method for reconstruction. Roweisfaces and\nkernel Roweisfaces are also proposed generalizing eigenfaces, Fisherfaces,\nsupervised eigenfaces, and their kernel variants. We also report experiments\nshowing the effectiveness of RDA and kernel RDA on some benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 23:14:09 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1910.05441", "submitter": "Morteza Karimzadeh", "authors": "Morteza Karimzadeh, Luke S. Snyder, David S. Ebert", "title": "Geovisual Analytics and Interactive Machine Learning for Situational\n  Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": "2019 US National Report, International Cartographic Association", "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first responder community has traditionally relied on calls from the\npublic, officially-provided geographic information and maps for coordinating\nactions on the ground. The ubiquity of social media platforms created an\nopportunity for near real-time sensing of the situation (e.g. unfolding weather\nevents or crises) through volunteered geographic information. In this article,\nwe provide an overview of the design process and features of the Social Media\nAnalytics Reporting Toolkit (SMART), a visual analytics platform developed at\nPurdue University for providing first responders with real-time situational\nawareness. We attribute its successful adoption by many first responders to its\nuser-centered design, interactive (geo)visualizations and interactive machine\nlearning, giving users control over analysis.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 23:33:55 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Karimzadeh", "Morteza", ""], ["Snyder", "Luke S.", ""], ["Ebert", "David S.", ""]]}, {"id": "1910.05446", "submitter": "Dami Choi", "authors": "Dami Choi, Christopher J. Shallue, Zachary Nado, Jaehoon Lee, Chris J.\n  Maddison, George E. Dahl", "title": "On Empirical Comparisons of Optimizers for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting an optimizer is a central step in the contemporary deep learning\npipeline. In this paper, we demonstrate the sensitivity of optimizer\ncomparisons to the hyperparameter tuning protocol. Our findings suggest that\nthe hyperparameter search space may be the single most important factor\nexplaining the rankings obtained by recent empirical comparisons in the\nliterature. In fact, we show that these results can be contradicted when\nhyperparameter search spaces are changed. As tuning effort grows without bound,\nmore general optimizers should never underperform the ones they can approximate\n(i.e., Adam should never perform worse than momentum), but recent attempts to\ncompare optimizers either assume these inclusion relationships are not\npractically relevant or restrict the hyperparameters in ways that break the\ninclusions. In our experiments, we find that inclusion relationships between\noptimizers matter in practice and always predict optimizer comparisons. In\nparticular, we find that the popular adaptive gradient methods never\nunderperform momentum or gradient descent. We also report practical tips around\ntuning often ignored hyperparameters of adaptive gradient methods and raise\nconcerns about fairly benchmarking optimizers for neural network training.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 23:51:09 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 05:28:34 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 00:58:12 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Choi", "Dami", ""], ["Shallue", "Christopher J.", ""], ["Nado", "Zachary", ""], ["Lee", "Jaehoon", ""], ["Maddison", "Chris J.", ""], ["Dahl", "George E.", ""]]}, {"id": "1910.05448", "submitter": "Tharindu Fernando", "authors": "Tharindu Fernando, Simon Denman, David Ahmedt-Aristizabal, Sridha\n  Sridharan, Kristin Laurens, Patrick Johnston, and Clinton Fookes", "title": "Neural Memory Plasticity for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of machine learning, Neural Memory Networks (NMNs) have\nrecently achieved impressive results in a variety of application areas\nincluding visual question answering, trajectory prediction, object tracking,\nand language modelling. However, we observe that the attention based knowledge\nretrieval mechanisms used in current NMNs restricts them from achieving their\nfull potential as the attention process retrieves information based on a set of\nstatic connection weights. This is suboptimal in a setting where there are vast\ndifferences among samples in the data domain; such as anomaly detection where\nthere is no consistent criteria for what constitutes an anomaly. In this paper,\nwe propose a plastic neural memory access mechanism which exploits both static\nand dynamic connection weights in the memory read, write and output generation\nprocedures. We demonstrate the effectiveness and flexibility of the proposed\nmemory model in three challenging anomaly detection tasks in the medical\ndomain: abnormal EEG identification, MRI tumour type classification and\nschizophrenia risk detection in children. In all settings, the proposed\napproach outperforms the current state-of-the-art. Furthermore, we perform an\nin-depth analysis demonstrating the utility of neural plasticity for the\nknowledge retrieval process and provide evidence on how the proposed memory\nmodel generates sparse yet informative memory outputs.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 00:32:56 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Fernando", "Tharindu", ""], ["Denman", "Simon", ""], ["Ahmedt-Aristizabal", "David", ""], ["Sridharan", "Sridha", ""], ["Laurens", "Kristin", ""], ["Johnston", "Patrick", ""], ["Fookes", "Clinton", ""]]}, {"id": "1910.05449", "submitter": "Yuning Chai", "authors": "Yuning Chai and Benjamin Sapp and Mayank Bansal and Dragomir Anguelov", "title": "MultiPath: Multiple Probabilistic Anchor Trajectory Hypotheses for\n  Behavior Prediction", "comments": "Appears in CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting human behavior is a difficult and crucial task required for motion\nplanning. It is challenging in large part due to the highly uncertain and\nmulti-modal set of possible outcomes in real-world domains such as autonomous\ndriving. Beyond single MAP trajectory prediction, obtaining an accurate\nprobability distribution of the future is an area of active interest. We\npresent MultiPath, which leverages a fixed set of future state-sequence anchors\nthat correspond to modes of the trajectory distribution. At inference, our\nmodel predicts a discrete distribution over the anchors and, for each anchor,\nregresses offsets from anchor waypoints along with uncertainties, yielding a\nGaussian mixture at each time step. Our model is efficient, requiring only one\nforward inference pass to obtain multi-modal future distributions, and the\noutput is parametric, allowing compact communication and analytical\nprobabilistic queries. We show on several datasets that our model achieves more\naccurate predictions, and compared to sampling baselines, does so with an order\nof magnitude fewer trajectories.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 00:34:37 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Chai", "Yuning", ""], ["Sapp", "Benjamin", ""], ["Bansal", "Mayank", ""], ["Anguelov", "Dragomir", ""]]}, {"id": "1910.05453", "submitter": "Alexei Baevski", "authors": "Alexei Baevski, Steffen Schneider, Michael Auli", "title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose vq-wav2vec to learn discrete representations of audio segments\nthrough a wav2vec-style self-supervised context prediction task. The algorithm\nuses either a gumbel softmax or online k-means clustering to quantize the dense\nrepresentations. Discretization enables the direct application of algorithms\nfrom the NLP community which require discrete inputs. Experiments show that\nBERT pre-training achieves a new state of the art on TIMIT phoneme\nclassification and WSJ speech recognition.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 00:55:06 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 21:28:15 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 18:35:27 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Baevski", "Alexei", ""], ["Schneider", "Steffen", ""], ["Auli", "Michael", ""]]}, {"id": "1910.05455", "submitter": "Kritaphat Songsri-in", "authors": "Kritaphat Songsri-in and Stefanos Zafeiriou", "title": "Complement Face Forensic Detection and Localization with FacialLandmarks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Generative Adversarial Networks (GANs) and image manipulating\nmethods are becoming more powerful and can produce highly realistic face images\nbeyond human recognition which have raised significant concerns regarding the\nauthenticity of digital media. Although there have been some prior works that\ntackle face forensic classification problem, it is not trivial to estimate\nedited locations from classification predictions. In this paper, we propose, to\nthe best of our knowledge, the first rigorous face forensic localization\ndataset, which consists of genuine, generated, and manipulated face images. In\nparticular, the pristine parts contain face images from CelebA and FFHQ\ndatasets. The fake images are generated from various GANs methods, namely\nDCGANs, LSGANs, BEGANs, WGAN-GP, ProGANs, and StyleGANs. Lastly, the edited\nsubset is generated from StarGAN and SEFCGAN based on free-form masks. In\ntotal, the dataset contains about 1.3 million facial images labelled with\ncorresponding binary masks.\n  Based on the proposed dataset, we demonstrated that explicit adding facial\nlandmarks information in addition to input images improves the performance. In\naddition, our proposed method consists of two branches and can coherently\npredict face forensic detection and localization to outperform the previous\nstate-of-the-art techniques on the newly proposed dataset as well as the\nfaceforecsic++ dataset especially on low-quality videos.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 01:09:15 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Songsri-in", "Kritaphat", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1910.05471", "submitter": "Yi Zhu", "authors": "YI Zhu, Jing Dong, Henry Lam", "title": "Efficient Inference and Exploration for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite an ever growing literature on reinforcement learning algorithms and\napplications, much less is known about their statistical inference. In this\npaper, we investigate the large sample behaviors of the Q-value estimates with\nclosed-form characterizations of the asymptotic variances. This allows us to\nefficiently construct confidence regions for Q-value and optimal value\nfunctions, and to develop policies to minimize their estimation errors. This\nalso leads to a policy exploration strategy that relies on estimating the\nrelative discrepancies among the Q estimates. Numerical experiments show\nsuperior performances of our exploration strategy than other benchmark\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 03:02:14 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 20:25:09 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Zhu", "YI", ""], ["Dong", "Jing", ""], ["Lam", "Henry", ""]]}, {"id": "1910.05482", "submitter": "Yuqing Zhu", "authors": "Yuqing Zhu and Jianxun Liu", "title": "ClassyTune: A Performance Auto-Tuner for Systems in the Cloud", "comments": "12 pages, Journal paper", "journal-ref": "ClassyTune: A Performance Auto-Tuner for Systems in the Cloud.\n  IEEE Transactions on Cloud Computing, 2019. doi: 10.1109/TCC.2019.2936567", "doi": "10.1109/TCC.2019.2936567", "report-no": null, "categories": "cs.PF cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance tuning can improve the system performance and thus enable the\nreduction of cloud computing resources needed to support an application. Due to\nthe ever increasing number of parameters and complexity of systems, there is a\nnecessity to automate performance tuning for the complicated systems in the\ncloud. The state-of-the-art tuning methods are adopting either the\nexperience-driven tuning approach or the data-driven one. Data-driven tuning is\nattracting increasing attentions, as it has wider applicability. But existing\ndata-driven methods cannot fully address the challenges of sample scarcity and\nhigh dimensionality simultaneously. We present ClassyTune, a data-driven\nautomatic configuration tuning tool for cloud systems. ClassyTune exploits the\nmachine learning model of classification for auto-tuning. This exploitation\nenables the induction of more training samples without increasing the input\ndimension. Experiments on seven popular systems in the cloud show that\nClassyTune can effectively tune system performance to seven times higher for\nhigh-dimensional configuration space, outperforming expert tuning and the\nstate-of-the-art auto-tuning solutions. We also describe a use case in which\nperformance tuning enables the reduction of 33% computing resources needed to\nrun an online stateless service.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 04:05:24 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Zhu", "Yuqing", ""], ["Liu", "Jianxun", ""]]}, {"id": "1910.05484", "submitter": "Chao Qian", "authors": "Chao Qian and Hang Xiong and Ke Xue", "title": "Bayesian Optimization using Pseudo-Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a popular approach for expensive black-box\noptimization, with applications including parameter tuning, experimental\ndesign, robotics. BO usually models the objective function by a Gaussian\nprocess (GP), and iteratively samples the next data point by maximizing an\nacquisition function. In this paper, we propose a new general framework for BO\nby generating pseudo-points (i.e., data points whose objective values are not\nevaluated) to improve the GP model. With the classic acquisition function,\ni.e., upper confidence bound (UCB), we prove that the cumulative regret can be\ngenerally upper bounded. Experiments using UCB and other acquisition functions,\ni.e., probability of improvement (PI) and expectation of improvement (EI), on\nsynthetic as well as real-world problems clearly show the advantage of\ngenerating pseudo-points.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 04:17:26 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 06:41:37 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Qian", "Chao", ""], ["Xiong", "Hang", ""], ["Xue", "Ke", ""]]}, {"id": "1910.05485", "submitter": "Jiapeng Liu", "authors": "Jiapeng Liu, Milosz Kadzinski, Xiuwu Liao, Xiaoxin Mao, Yao Wang", "title": "A preference learning framework for multiple criteria sorting with\n  diverse additive value models and valued assignment examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a preference learning framework for multiple criteria sorting. We\nconsider sorting procedures applying an additive value model with diverse types\nof marginal value functions (including linear, piecewise-linear, splined, and\ngeneral monotone ones) under a unified analytical framework. Differently from\nthe existing sorting methods that infer a preference model from crisp decision\nexamples, where each reference alternative is assigned to a unique class, our\nframework allows to consider valued assignment examples in which a reference\nalternative can be classified into multiple classes with respective credibility\ndegrees. We propose an optimization model for constructing a preference model\nfrom such valued examples by maximizing the credible consistency among\nreference alternatives. To improve the predictive ability of the constructed\nmodel on new instances, we employ the regularization techniques. Moreover, to\nenhance the capability of addressing large-scale datasets, we introduce a\nstate-of-the-art algorithm that is widely used in the machine learning\ncommunity to solve the proposed optimization model in a computationally\nefficient way. Using the constructed additive value model, we determine both\ncrisp and valued assignments for non-reference alternatives. Moreover, we allow\nthe Decision Maker to prioritize importance of classes and give the method a\nflexibility to adjust classification performance across classes according to\nthe specified priorities. The practical usefulness of the analytical framework\nis demonstrated on a real-world dataset by comparing it to several existing\nsorting methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 04:18:46 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Liu", "Jiapeng", ""], ["Kadzinski", "Milosz", ""], ["Liao", "Xiuwu", ""], ["Mao", "Xiaoxin", ""], ["Wang", "Yao", ""]]}, {"id": "1910.05493", "submitter": "Yasir Hussain", "authors": "Yasir Hussain, Zhiqiu Huang, Yu Zhou and Senzhang Wang", "title": "Deep Transfer Learning for Source Code Modeling", "comments": null, "journal-ref": "International Journal of Software Engineering and Knowledge\n  Engineering. Vol. 30, No. 05, pp. 649-668 (2020)", "doi": "10.1142/S0218194020500230", "report-no": null, "categories": "cs.LG cs.NE cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning models have shown great potential in source\ncode modeling and analysis. Generally, deep learning-based approaches are\nproblem-specific and data-hungry. A challenging issue of these approaches is\nthat they require training from starch for a different related problem. In this\nwork, we propose a transfer learning-based approach that significantly improves\nthe performance of deep learning-based source code models. In contrast to\ntraditional learning paradigms, transfer learning can transfer the knowledge\nlearned in solving one problem into another related problem. First, we present\ntwo recurrent neural network-based models RNN and GRU for the purpose of\ntransfer learning in the domain of source code modeling. Next, via transfer\nlearning, these pre-trained (RNN and GRU) models are used as feature\nextractors. Then, these extracted features are combined into attention learner\nfor different downstream tasks. The attention learner leverages from the\nlearned knowledge of pre-trained models and fine-tunes them for a specific\ndownstream task. We evaluate the performance of the proposed approach with\nextensive experiments with the source code suggestion task. The results\nindicate that the proposed approach outperforms the state-of-the-art models in\nterms of accuracy, precision, recall, and F-measure without training the models\nfrom scratch.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 04:59:17 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 12:08:39 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Hussain", "Yasir", ""], ["Huang", "Zhiqiu", ""], ["Zhou", "Yu", ""], ["Wang", "Senzhang", ""]]}, {"id": "1910.05495", "submitter": "Jason Ren", "authors": "Jason Ren, Russell Kunes, Finale Doshi-Velez", "title": "Prediction Focused Topic Models via Feature Selection", "comments": "AISTATS 2020. arXiv admin note: substantial text overlap with\n  arXiv:1911.08551", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised topic models are often sought to balance prediction quality and\ninterpretability. However, when models are (inevitably) misspecified, standard\napproaches rarely deliver on both. We introduce a novel approach, the\nprediction-focused topic model, that uses the supervisory signal to retain only\nvocabulary terms that improve, or at least do not hinder, prediction\nperformance. By removing terms with irrelevant signal, the topic model is able\nto learn task-relevant, coherent topics. We demonstrate on several data sets\nthat compared to existing approaches, prediction-focused topic models learn\nmuch more coherent topics while maintaining competitive predictions.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 05:08:43 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 06:20:26 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Ren", "Jason", ""], ["Kunes", "Russell", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1910.05505", "submitter": "Holger Rauhut", "authors": "Bubacarr Bah, Holger Rauhut, Ulrich Terstiege, Michael Westdickenberg", "title": "Learning deep linear neural networks: Riemannian gradient flows and\n  convergence to global minimizers", "comments": "Minor changes; version accepted for publication in Information and\n  Inference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence of gradient flows related to learning deep linear\nneural networks (where the activation function is the identity map) from data.\nIn this case, the composition of the network layers amounts to simply\nmultiplying the weight matrices of all layers together, resulting in an\noverparameterized problem. The gradient flow with respect to these factors can\nbe re-interpreted as a Riemannian gradient flow on the manifold of rank-$r$\nmatrices endowed with a suitable Riemannian metric. We show that the flow\nalways converges to a critical point of the underlying functional. Moreover, we\nestablish that, for almost all initializations, the flow converges to a global\nminimum on the manifold of rank $k$ matrices for some $k\\leq r$.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 06:51:27 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 07:57:23 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 09:52:45 GMT"}, {"version": "v4", "created": "Mon, 24 Aug 2020 14:21:49 GMT"}, {"version": "v5", "created": "Thu, 15 Oct 2020 15:27:31 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Bah", "Bubacarr", ""], ["Rauhut", "Holger", ""], ["Terstiege", "Ulrich", ""], ["Westdickenberg", "Michael", ""]]}, {"id": "1910.05510", "submitter": "Ahmed Ahmed", "authors": "Ahmed B.Zaky, Joshua Zhexue Huang, KaishunWu and Basem M.ElHalawany", "title": "Generative Neural Network based Spectrum Sharing using Linear Sum\n  Assignment Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectrum management and resource allocation (RA) problems are challenging and\ncritical in a vast number of research areas such as wireless communications and\ncomputer networks. The traditional approaches for solving such problems usually\nconsume time and memory, especially for large size problems. Recently different\nmachine learning approaches have been considered as potential promising\ntechniques for combinatorial optimization problems, especially the generative\nmodel of the deep neural networks. In this work, we propose a resource\nallocation deep autoencoder network, as one of the promising generative models,\nfor enabling spectrum sharing in underlay device-to-device (D2D) communication\nby solving linear sum assignment problems (LSAPs). Specifically, we investigate\nthe performance of three different architectures for the conditional\nvariational autoencoders (CVAE). The three proposed architecture are the\nconvolutional neural network (CVAE-CNN) autoencoder, the feed-forward neural\nnetwork (CVAE-FNN) autoencoder, and the hybrid (H-CVAE) autoencoder. The\nsimulation results show that the proposed approach could be used as a\nreplacement of the conventional RA techniques, such as the Hungarian algorithm,\ndue to its ability to find solutions of LASPs of different sizes with high\naccuracy and very fast execution time. Moreover, the simulation results reveal\nthat the accuracy of the proposed hybrid autoencoder architecture outperforms\nthe other proposed architectures and the state-of-the-art DNN techniques.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 07:05:07 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Zaky", "Ahmed B.", ""], ["Huang", "Joshua Zhexue", ""], ["KaishunWu", "", ""], ["ElHalawany", "Basem M.", ""]]}, {"id": "1910.05512", "submitter": "Tonghan Wang", "authors": "Tonghan Wang, Jianhao Wang, Yi Wu, Chongjie Zhang", "title": "Influence-Based Multi-Agent Exploration", "comments": null, "journal-ref": "International Conference on Learning Representations, 2020,\n  spotlight", "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsically motivated reinforcement learning aims to address the\nexploration challenge for sparse-reward tasks. However, the study of\nexploration methods in transition-dependent multi-agent settings is largely\nabsent from the literature. We aim to take a step towards solving this problem.\nWe present two exploration methods: exploration via information-theoretic\ninfluence (EITI) and exploration via decision-theoretic influence (EDTI), by\nexploiting the role of interaction in coordinated behaviors of agents. EITI\nuses mutual information to capture influence transition dynamics. EDTI uses a\nnovel intrinsic reward, called Value of Interaction (VoI), to characterize and\nquantify the influence of one agent's behavior on expected returns of other\nagents. By optimizing EITI or EDTI objective as a regularizer, agents are\nencouraged to coordinate their exploration and learn policies to optimize team\nperformance. We show how to optimize these regularizers so that they can be\neasily integrated with policy gradient reinforcement learning. The resulting\nupdate rule draws a connection between coordinated exploration and intrinsic\nreward distribution. Finally, we empirically demonstrate the significant\nstrength of our method in a variety of multi-agent scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 07:14:33 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Wang", "Tonghan", ""], ["Wang", "Jianhao", ""], ["Wu", "Yi", ""], ["Zhang", "Chongjie", ""]]}, {"id": "1910.05513", "submitter": "Hanshu Yan", "authors": "Hanshu Yan, Jiawei Du, Vincent Y. F. Tan, Jiashi Feng", "title": "On Robustness of Neural Ordinary Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural ordinary differential equations (ODEs) have been attracting increasing\nattention in various research domains recently. There have been some works\nstudying optimization issues and approximation capabilities of neural ODEs, but\ntheir robustness is still yet unclear. In this work, we fill this important gap\nby exploring robustness properties of neural ODEs both empirically and\ntheoretically. We first present an empirical study on the robustness of the\nneural ODE-based networks (ODENets) by exposing them to inputs with various\ntypes of perturbations and subsequently investigating the changes of the\ncorresponding outputs. In contrast to conventional convolutional neural\nnetworks (CNNs), we find that the ODENets are more robust against both random\nGaussian perturbations and adversarial attack examples. We then provide an\ninsightful understanding of this phenomenon by exploiting a certain desirable\nproperty of the flow of a continuous-time ODE, namely that integral curves are\nnon-intersecting. Our work suggests that, due to their intrinsic robustness, it\nis promising to use neural ODEs as a basic block for building robust deep\nnetwork models. To further enhance the robustness of vanilla neural ODEs, we\npropose the time-invariant steady neural ODE (TisODE), which regularizes the\nflow on perturbed data via the time-invariant property and the imposition of a\nsteady-state constraint. We show that the TisODE method outperforms vanilla\nneural ODEs and also can work in conjunction with other state-of-the-art\narchitectural methods to build more robust deep networks.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 07:15:44 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 03:33:56 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Yan", "Hanshu", ""], ["Du", "Jiawei", ""], ["Tan", "Vincent Y. F.", ""], ["Feng", "Jiashi", ""]]}, {"id": "1910.05527", "submitter": "Rinu Boney", "authors": "Rinu Boney, Juho Kannala, Alexander Ilin", "title": "Regularizing Model-Based Planning with Energy-Based Models", "comments": "Conference on Robot Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning could enable sample-efficient learning by\nquickly acquiring rich knowledge about the world and using it to improve\nbehaviour without additional data. Learned dynamics models can be directly used\nfor planning actions but this has been challenging because of inaccuracies in\nthe learned models. In this paper, we focus on planning with learned dynamics\nmodels and propose to regularize it using energy estimates of state transitions\nin the environment. We visually demonstrate the effectiveness of the proposed\nmethod and show that off-policy training of an energy estimator can be\neffectively used to regularize planning with pre-trained dynamics models.\nFurther, we demonstrate that the proposed method enables sample-efficient\nlearning to achieve competitive performance in challenging continuous control\ntasks such as Half-cheetah and Ant in just a few minutes of experience.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 08:29:24 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Boney", "Rinu", ""], ["Kannala", "Juho", ""], ["Ilin", "Alexander", ""]]}, {"id": "1910.05528", "submitter": "Hironori Washizaki", "authors": "Yasuhiro Watanabe, Hironori Washizaki, Kazunori Sakamoto, Daisuke\n  Saito, Kiyoshi Honda, Naohiko Tsuda, Yoshiaki Fukazawa, Nobukazu Yoshioka", "title": "Preliminary Systematic Literature Review of Machine Learning System\n  Development Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous machine learning (ML) system development research suggests that\nemerging software quality attributes are a concern due to the probabilistic\nbehavior of ML systems. Assuming that detailed development processes depend on\nindividual developers and are not discussed in detail. To help developers to\nstandardize their ML system development processes, we conduct a preliminary\nsystematic literature review on ML system development processes. A search query\nof 2358 papers identified 7 papers as well as two other papers determined in an\nad-hoc review. Our findings include emphasized phases in ML system\ndevelopments, frequently described practices and tailored traditional software\ndevelopment practices.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 08:32:00 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Watanabe", "Yasuhiro", ""], ["Washizaki", "Hironori", ""], ["Sakamoto", "Kazunori", ""], ["Saito", "Daisuke", ""], ["Honda", "Kiyoshi", ""], ["Tsuda", "Naohiko", ""], ["Fukazawa", "Yoshiaki", ""], ["Yoshioka", "Nobukazu", ""]]}, {"id": "1910.05534", "submitter": "Ian Gallagher", "authors": "Ian Gallagher, Andrew Jones, Anna Bertiger, Carey Priebe, and Patrick\n  Rubin-Delanchy", "title": "Spectral embedding of weighted graphs", "comments": "29 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the statistical analysis of a weighted graph through\nspectral embedding. Under a latent position model in which the expected\nadjacency matrix has low rank, we prove uniform consistency and a central limit\ntheorem for the embedded nodes, treated as latent position estimates. In the\nspecial case of a weighted stochastic block model, this result implies that the\nembedding follows a Gaussian mixture model with each component representing a\ncommunity. We exploit this to formally evaluate different weight\nrepresentations of the graph using Chernoff information. For example, in a\nnetwork anomaly detection problem where we observe a p-value on each edge, we\nrecommend against directly embedding the matrix of p-values, and instead using\nthreshold or log p-values, depending on network sparsity and signal strength.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 09:13:26 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 20:12:22 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 12:56:48 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Gallagher", "Ian", ""], ["Jones", "Andrew", ""], ["Bertiger", "Anna", ""], ["Priebe", "Carey", ""], ["Rubin-Delanchy", "Patrick", ""]]}, {"id": "1910.05547", "submitter": "Malik Aqeel Anwar", "authors": "Aqeel Anwar, Arijit Raychowdhury", "title": "Autonomous Navigation via Deep Reinforcement Learning for Resource\n  Constraint Edge Nodes using Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart and agile drones are fast becoming ubiquitous at the edge of the cloud.\nThe usage of these drones are constrained by their limited power and compute\ncapability. In this paper, we present a Transfer Learning (TL) based approach\nto reduce on-board computation required to train a deep neural network for\nautonomous navigation via Deep Reinforcement Learning for a target algorithmic\nperformance. A library of 3D realistic meta-environments is manually designed\nusing Unreal Gaming Engine and the network is trained end-to-end. These trained\nmeta-weights are then used as initializers to the network in a test environment\nand fine-tuned for the last few fully connected layers. Variation in drone\ndynamics and environmental characteristics is carried out to show robustness of\nthe approach. Using NVIDIA GPU profiler it was shown that the energy\nconsumption and training latency is reduced by 3.7x and 1.8x respectively\nwithout significant degradation in the performance in terms of average distance\ntraveled before crash i.e. Mean Safe Flight (MSF). The approach is also tested\non a real environment using DJI Tello drone and similar results were reported.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 10:14:11 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Anwar", "Aqeel", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "1910.05552", "submitter": "Zekun Li", "authors": "Zekun Li, Zeyu Cui, Shu Wu, Xiaoyu Zhang, Liang Wang", "title": "Fi-GNN: Modeling Feature Interactions via Graph Neural Networks for CTR\n  Prediction", "comments": "10 pages, accepted by the 2019 Conference on Information and\n  Knowledge Management (CIKM-2019)", "journal-ref": null, "doi": "10.1145/3357384.3357951", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is an essential task in web applications\nsuch as online advertising and recommender systems, whose features are usually\nin multi-field form. The key of this task is to model feature interactions\namong different feature fields. Recently proposed deep learning based models\nfollow a general paradigm: raw sparse input multi-filed features are first\nmapped into dense field embedding vectors, and then simply concatenated\ntogether to feed into deep neural networks (DNN) or other specifically designed\nnetworks to learn high-order feature interactions. However, the simple\n\\emph{unstructured combination} of feature fields will inevitably limit the\ncapability to model sophisticated interactions among different fields in a\nsufficiently flexible and explicit fashion.\n  In this work, we propose to represent the multi-field features in a graph\nstructure intuitively, where each node corresponds to a feature field and\ndifferent fields can interact through edges. The task of modeling feature\ninteractions can be thus converted to modeling node interactions on the\ncorresponding graph. To this end, we design a novel model Feature Interaction\nGraph Neural Networks (Fi-GNN). Taking advantage of the strong representative\npower of graphs, our proposed model can not only model sophisticated feature\ninteractions in a flexible and explicit fashion, but also provide good model\nexplanations for CTR prediction. Experimental results on two real-world\ndatasets show its superiority over the state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 11:33:05 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 05:51:11 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Li", "Zekun", ""], ["Cui", "Zeyu", ""], ["Wu", "Shu", ""], ["Zhang", "Xiaoyu", ""], ["Wang", "Liang", ""]]}, {"id": "1910.05563", "submitter": "Arnu Pretorius", "authors": "Arnu Pretorius, Herman Kamper, Steve Kroon", "title": "On the expected behaviour of noise regularised deep neural networks as\n  Gaussian processes", "comments": "8 pages, 6 figures, preliminary work", "journal-ref": "Pattern Recognition Letters 138 (2020) 75-81", "doi": "10.1016/j.patrec.2020.06.027", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has established the equivalence between deep neural networks and\nGaussian processes (GPs), resulting in so-called neural network Gaussian\nprocesses (NNGPs). The behaviour of these models depends on the initialisation\nof the corresponding network. In this work, we consider the impact of noise\nregularisation (e.g. dropout) on NNGPs, and relate their behaviour to signal\npropagation theory in noise regularised deep neural networks. For ReLU\nactivations, we find that the best performing NNGPs have kernel parameters that\ncorrespond to a recently proposed initialisation scheme for noise regularised\nReLU networks. In addition, we show how the noise influences the covariance\nmatrix of the NNGP, producing a stronger prior towards simple functions away\nfrom the training points. We verify our theoretical findings with experiments\non MNIST and CIFAR-10 as well as on synthetic data.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 13:23:58 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Pretorius", "Arnu", ""], ["Kamper", "Herman", ""], ["Kroon", "Steve", ""]]}, {"id": "1910.05565", "submitter": "Melanie Weber", "authors": "Melanie Weber", "title": "Neighborhood Growth Determines Geometric Priors for Relational\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of identifying geometric structure in heterogeneous,\nhigh-dimensional data is a cornerstone of representation learning. While there\nexists a large body of literature on the embeddability of canonical graphs,\nsuch as lattices or trees, the heterogeneity of the relational data typically\nencountered in practice limits the applicability of these classical methods. In\nthis paper, we propose a combinatorial approach to evaluating embeddability,\ni.e., to decide whether a data set is best represented in Euclidean, Hyperbolic\nor Spherical space. Our method analyzes nearest-neighbor structures and local\nneighborhood growth rates to identify the geometric priors of suitable\nembedding spaces. For canonical graphs, the algorithm's prediction provably\nmatches classical results. As for large, heterogeneous graphs, we introduce an\nefficiently computable statistic that approximates the algorithm's decision\nrule. We validate our method over a range of benchmark data sets and compare\nwith recently published optimization-based embeddability methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 14:04:25 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Weber", "Melanie", ""]]}, {"id": "1910.05569", "submitter": "Shuai Yang", "authors": "Shuai Yang, Wenqi Zhu, Yuesheng Zhu", "title": "Residual Encoder-Decoder Network for Deep Subspace Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering aims to cluster unlabeled data that lies in a union of\nlow-dimensional linear subspaces. Deep subspace clustering approaches based on\nauto-encoders have become very popular to solve subspace clustering problems.\nHowever, the training of current deep methods converges slowly, which is much\nless efficient than traditional approaches. We propose a Residual\nEncoder-Decoder network for deep Subspace Clustering (RED-SC), which\nsymmetrically links convolutional and deconvolutional layers with skip-layer\nconnections, with which the training converges much faster. We use a\nself-expressive layer to generate more accurate linear representation\ncoefficients through different latent representations from multiple latent\nspaces. Experiments show the superiority of RED-SC in training efficiency and\nclustering accuracy. Moreover, we are the first one to apply residual\nencoder-decoder on unsupervised learning tasks.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 14:35:54 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Yang", "Shuai", ""], ["Zhu", "Wenqi", ""], ["Zhu", "Yuesheng", ""]]}, {"id": "1910.05570", "submitter": "Yuan Jin", "authors": "Yuan Jin, Ming Liu, Yunfeng Li, Ruohua Xu, Lan Du, Longxiang Gao, Yong\n  Xiang", "title": "Variational Auto-encoder Based Bayesian Poisson Tensor Factorization for\n  Sparse and Imbalanced Count Data", "comments": null, "journal-ref": null, "doi": "10.1007/s10618-020-00723-7", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-negative tensor factorization models enable predictive analysis on count\ndata. Among them, Bayesian Poisson-Gamma models can derive full posterior\ndistributions of latent factors and are less sensitive to sparse count data.\nHowever, current inference methods for these Bayesian models adopt restricted\nupdate rules for the posterior parameters. They also fail to share the update\ninformation to better cope with the data sparsity. Moreover, these models are\nnot endowed with a component that handles the imbalance in count data values.\nIn this paper, we propose a novel variational auto-encoder framework called\nVAE-BPTF which addresses the above issues. It uses multi-layer perceptron\nnetworks to encode and share complex update information. The encoded\ninformation is then reweighted per data instance to penalize common data values\nbefore aggregated to compute the posterior parameters for the latent factors.\nUnder synthetic data evaluation, VAE-BPTF tended to recover the right number of\nlatent factors and posterior parameter values. It also outperformed current\nmodels in both reconstruction errors and latent factor (semantic) coherence\nacross five real-world datasets. Furthermore, the latent factors inferred by\nVAE-BPTF are perceived to be meaningful and coherent under a qualitative\nanalysis.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 14:36:45 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 14:16:45 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Jin", "Yuan", ""], ["Liu", "Ming", ""], ["Li", "Yunfeng", ""], ["Xu", "Ruohua", ""], ["Du", "Lan", ""], ["Gao", "Longxiang", ""], ["Xiang", "Yong", ""]]}, {"id": "1910.05571", "submitter": "Lester James Miranda", "authors": "Lester James V. Miranda, Mark Steve Samson, Alfiero K. Orden II,\n  Bianca S. Silmaro, Ram K. De Guzman III, Stephanie S. Sy", "title": "Geomancer: An Open-Source Framework for Geospatial Feature Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Geomancer, an open-source framework for geospatial\nfeature engineering. It simplifies the acquisition of geospatial attributes for\ndownstream, large-scale machine learning tasks. Geomancer leverages any\ngeospatial dataset stored in a data warehouse, users need only to define the\nfeatures (Spells) they want to create, and cast them on any spatial dataset. In\naddition, these features can be exported into a JSON file (SpellBook) for\nsharing and reproducibility. Geomancer has been useful to some of our\nproduction use-cases such as property value estimation, area valuation, and\nmore. It is available on Github, and can be installed from PyPI.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 14:47:26 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Miranda", "Lester James V.", ""], ["Samson", "Mark Steve", ""], ["Orden", "Alfiero K.", "II"], ["Silmaro", "Bianca S.", ""], ["Guzman", "Ram K. De", "III"], ["Sy", "Stephanie S.", ""]]}, {"id": "1910.05575", "submitter": "Rafael Izbicki", "authors": "Rafael Izbicki, Gilson T. Shimizu, Rafael B. Stern", "title": "Flexible distribution-free conditional predictive bands using density\n  estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conformal methods create prediction bands that control average coverage under\nno assumptions besides i.i.d. data. Besides average coverage, one might also\ndesire to control conditional coverage, that is, coverage for every new testing\npoint. However, without strong assumptions, conditional coverage is\nunachievable. Given this limitation, the literature has focused on methods with\nasymptotical conditional coverage. In order to obtain this property, these\nmethods require strong conditions on the dependence between the target variable\nand the features. We introduce two conformal methods based on conditional\ndensity estimators that do not depend on this type of assumption to obtain\nasymptotic conditional coverage: Dist-split and CD-split. While Dist-split\nasymptotically obtains optimal intervals, which are easier to interpret than\ngeneral regions, CD-split obtains optimal size regions, which are smaller than\nintervals. CD-split also obtains local coverage by creating a data-driven\npartition of the feature space that scales to high-dimensional settings and by\ngenerating prediction bands locally on the partition elements. In a wide\nvariety of simulated scenarios, our methods have a better control of\nconditional coverage and have smaller length than previously proposed methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 15:23:13 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 15:28:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Izbicki", "Rafael", ""], ["Shimizu", "Gilson T.", ""], ["Stern", "Rafael B.", ""]]}, {"id": "1910.05587", "submitter": "Anna Sepliarskaia", "authors": "Anna Sepliarskaia, Julia Kiseleva and Maarten de Rijke", "title": "How to Not Measure Disentanglement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To evaluate disentangled representations several metrics have been proposed.\nHowever, theoretical guarantees for conventional metrics of disentanglement are\nmissing. Moreover, conventional metrics do not have a consistent correlation\nwith the outcomes of qualitative studies. In this paper we analyze metrics of\ndisentanglement and their properties. We conclude that existing metrics of\ndisentanglement were created to reflect different characteristics of\ndisentanglement and do not satisfy two basic desirable properties: (1) assign a\nhigh score to representations that are disentangled according to the\ndefinition; and (2) assign a low score to representations that are entangled\naccording to the definition. In addition, we propose a new metric of\ndisentanglement and prove that it satisfies both of the properties.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 16:09:16 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 10:13:06 GMT"}, {"version": "v3", "created": "Wed, 24 Mar 2021 10:43:28 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Sepliarskaia", "Anna", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1910.05591", "submitter": "Juliana Cesaro", "authors": "Juliana Cesaro and Fabio G. Cozman", "title": "Measuring Unfairness through Game-Theoretic Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One often finds in the literature connections between measures of fairness\nand measures of feature importance employed to interpret trained classifiers.\nHowever, there seems to be no study that compares fairness measures and feature\nimportance measures. In this paper we propose ways to evaluate and compare such\nmeasures. We focus in particular on SHAP, a game-theoretic measure of feature\nimportance; we present results for a number of unfairness-prone datasets.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 16:23:04 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Cesaro", "Juliana", ""], ["Cozman", "Fabio G.", ""]]}, {"id": "1910.05594", "submitter": "Ayman Wagdy", "authors": "Ayman Wagdy, Veronica Garcia-Hansen, Mohammed Elhenawy, Gillian\n  Isoardi, Robin Drogemuller, Fatma Fathy", "title": "Open-plan Glare Evaluator (OGE): A Demonstration of a New Glare\n  Prediction Approach Using Machine Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Predicting discomfort glare in open-plan offices is a challenging problem.\nAlthough glare research has existed for more than 50 years, all current glare\nmetrics have accuracy limitations, especially in open-plan offices with low\nlighting levels. Thus, it is crucial to develop a new method to predict glare\nmore accurately. This paper is the first to adopt Machine Learning (ML)\napproaches in the prediction of glare. This research aims to demonstrate the\nvalidity of this approach by comparing the accuracy of the new ML model for\nopen-plan offices (OGE) to the accuracy of the existing glare metrics using\nlocal dataset. To utilize and test this approach, Post-Occupancy Evaluation\n(POE) and High Dynamic Range (HDR) images were collected from 80 occupants\n(n=80) in four different open-plan offices in Brisbane, Australia.\nConsequently, various multi-region luminance values, luminance, and glare\nindices were calculated and examined as input features to train ML models. The\naccuracy of the ML model was compared to the accuracy of 24 indices which were\nalso evaluated using a Receiver Operating Characteristic (ROC) analysis to\nidentify the best cutoff values (thresholds) for each index in open-plan\nconfigurations. Results showed that the ML approach could predict glare with an\naccuracy of 83.8% (0.80 true positive rate and 0.86 true negative rate), which\noutperformed the accuracy of the previously developed glare metrics. OGE is\napplicable for open-plan office situations with low vertical illuminance (200\nto 600 lux). However, ML models can be trained with more substantial datasets\nto achieve global model.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 16:33:02 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 14:13:22 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Wagdy", "Ayman", ""], ["Garcia-Hansen", "Veronica", ""], ["Elhenawy", "Mohammed", ""], ["Isoardi", "Gillian", ""], ["Drogemuller", "Robin", ""], ["Fathy", "Fatma", ""]]}, {"id": "1910.05611", "submitter": "Yijie Xu", "authors": "Yijie Xu and Arushi Goel", "title": "Cross-Domain Image Classification through Neural-Style Transfer Data\n  Augmentation", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In particular, the lack of sufficient amounts of domain-specific data can\nreduce the accuracy of a classifier. In this paper, we explore the effects of\nstyle transfer-based data transformation on the accuracy of a convolutional\nneural network classifiers in the context of automobile detection under adverse\nwinter weather conditions. The detection of automobiles under highly adverse\nweather conditions is a difficult task as such conditions present large amounts\nof noise in each image. The InceptionV2 architecture is trained on a composite\ndataset, consisting of either normal car image dataset , a mixture of normal\nand style transferred car images, or a mixture of normal car images and those\ntaken at blizzard conditions, at a ratio of 80:20. All three classifiers are\nthen tested on a dataset of car images taken at blizzard conditions and on\nvehicle-free snow landscape images. We evaluate and contrast the effectiveness\nof each classifier upon each dataset, and discuss the strengths and weaknesses\nof style-transfer based approaches to data augmentation.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 18:00:33 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xu", "Yijie", ""], ["Goel", "Arushi", ""]]}, {"id": "1910.05625", "submitter": "Laura Niss", "authors": "Laura Niss and Ambuj Tewari", "title": "What You See May Not Be What You Get: UCB Bandit Algorithms Robust to\n  {\\epsilon}-Contamination", "comments": "Changes to reflect UAI2020 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications of bandit algorithms in education, we consider a\nstochastic multi-armed bandit problem with $\\varepsilon$-contaminated rewards.\nWe allow an adversary to give arbitrary unbounded contaminated rewards with\nfull knowledge of the past and future. We impose the constraint that for each\ntime $t$ the proportion of contaminated rewards for any action is less than or\nequal to $\\varepsilon$. We derive concentration inequalities for two robust\nmean estimators for sub-Gaussian distributions in the\n$\\varepsilon$-contamination context. We define the $\\varepsilon$-contaminated\nstochastic bandit problem and use our robust mean estimators to give two\nvariants of a robust Upper Confidence Bound (UCB) algorithm, crUCB. Using\nregret derived from only the underlying stochastic rewards, both variants of\ncrUCB achieve $\\mathcal{O} (\\sqrt{KT\\log T})$ regret for small enough\ncontamination proportions. Our simulations assume small horizons, reflecting\nthe newly explored setting of bandits in education. We show that in certain\nadversarial regimes crUCB not only outperforms algorithms designed for\nstochastic (UCB1) and adversarial (EXP3) bandits but also those that have \"best\nof both worlds\" guarantees (EXP3++ and TsallisInf) even when our constraint on\nthe proportion of contaminated rewards is broken.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 19:00:17 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 17:27:49 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 18:16:13 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Niss", "Laura", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1910.05626", "submitter": "Daniel Jung", "authors": "Daniel Jung", "title": "Isolation and Localization of Unknown Faults Using Neural Network-Based\n  Residuals", "comments": "8 pages, 7 figures, If citing this paper please use: In: Proceedings\n  of the Annual Conference of the PHM Society, Scottsdale, Arizona, USA (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization of unknown faults in industrial systems is a difficult task for\ndata-driven diagnosis methods. The classification performance of many machine\nlearning methods relies on the quality of training data. Unknown faults, for\nexample faults not represented in training data, can be detected using, for\nexample, anomaly classifiers. However, mapping these unknown faults to an\nactual location in the real system is a non-trivial problem. In model-based\ndiagnosis, physical-based models are used to create residuals that isolate\nfaults by mapping model equations to faulty system components. Developing\nsufficiently accurate physical-based models can be a time-consuming process.\nHybrid modeling methods combining physical-based methods and machine learning\nis one solution to design data-driven residuals for fault isolation. In this\nwork, a set of neural network-based residuals are designed by incorporating\nphysical insights about the system behavior in the residual model structure.\nThe residuals are trained using only fault-free data and a simulation case\nstudy shows that they can be used to perform fault isolation and localization\nof unknown faults in the system.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 19:00:21 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Jung", "Daniel", ""]]}, {"id": "1910.05639", "submitter": "Niklas Stoehr", "authors": "Niklas Stoehr, Emine Yilmaz, Marc Brockschmidt, Jan Stuehmer", "title": "Disentangling Interpretable Generative Parameters of Random and\n  Real-World Graphs", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Workshop on Graph Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While a wide range of interpretable generative procedures for graphs exist,\nmatching observed graph topologies with such procedures and choices for its\nparameters remains an open problem. Devising generative models that closely\nreproduce real-world graphs requires domain knowledge and time-consuming\nsimulation. While existing deep learning approaches rely on less manual\nmodelling, they offer little interpretability. This work approaches graph\ngeneration (decoding) as the inverse of graph compression (encoding). We show\nthat in a disentanglement-focused deep autoencoding framework, specifically\nBeta-Variational Autoencoders (Beta-VAE), choices of generative procedures and\ntheir parameters arise naturally in the latent space. Our model is capable of\nlearning disentangled, interpretable latent variables that represent the\ngenerative parameters of procedurally generated random graphs and real-world\ngraphs. The degree of disentanglement is quantitatively measured using the\nMutual Information Gap (MIG). When training our Beta-VAE model on ER random\ngraphs, its latent variables have a near one-to-one mapping to the ER random\ngraph parameters n and p. We deploy the model to analyse the correlation\nbetween graph topology and node attributes measuring their mutual dependence\nwithout handpicking topological properties.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 19:57:55 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 19:40:41 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Stoehr", "Niklas", ""], ["Yilmaz", "Emine", ""], ["Brockschmidt", "Marc", ""], ["Stuehmer", "Jan", ""]]}, {"id": "1910.05640", "submitter": "Xujiang Zhao", "authors": "Xujiang Zhao, Feng Chen, Jin-Hee Cho", "title": "Deep Learning for Predicting Dynamic Uncertain Opinions in Network Data", "comments": "IEEE Bigdata 2018", "journal-ref": "2018 IEEE International Conference on Big Data (Big Data)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subjective Logic (SL) is one of well-known belief models that can explicitly\ndeal with uncertain opinions and infer unknown opinions based on a rich set of\noperators of fusing multiple opinions. Due to high simplicity and\napplicability, SL has been substantially applied in a variety of decision\nmaking in the area of cybersecurity, opinion models, trust models, and/or\nsocial network analysis. However, SL and its variants have exposed limitations\nin predicting uncertain opinions in real-world dynamic network data mainly in\nthree-fold: (1) a lack of scalability to deal with a large-scale network; (2)\nlimited capability to handle heterogeneous topological and temporal\ndependencies among node-level opinions; and (3) a high sensitivity with\nconflicting evidence that may generate counterintuitive opinions derived from\nthe evidence. In this work, we proposed a novel deep learning (DL)-based\ndynamic opinion inference model while node-level opinions are still formalized\nbased on SL meaning that an opinion has a dimension of uncertainty in addition\nto belief and disbelief in a binomial opinion (i.e., agree or disagree). The\nproposed DL-based dynamic opinion inference model overcomes the above three\nlimitations by integrating the following techniques: (1) state-of-the-art DL\ntechniques, such as the Graph Convolutional Network (GCN) and the Gated\nRecurrent Units (GRU) for modeling the topological and temporal heterogeneous\ndependency information of a given dynamic network; (2) modeling conflicting\nopinions based on robust statistics; and (3) a highly scalable inference\nalgorithm to predict dynamic, uncertain opinions in a linear computation time.\nWe validated the outperformance of our proposed DL-based algorithm (i.e.,\nGCN-GRU-opinion model) via extensive comparative performance analysis based on\nfour real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 20:10:59 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Zhao", "Xujiang", ""], ["Chen", "Feng", ""], ["Cho", "Jin-Hee", ""]]}, {"id": "1910.05646", "submitter": "Samson Zhou", "authors": "Dmitrii Avdiukhin, Grigory Yaroslavtsev, Samson Zhou", "title": "\"Bring Your Own Greedy\"+Max: Near-Optimal $1/2$-Approximations for\n  Submodular Knapsack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of selecting a small-size representative summary of a large\ndataset is a cornerstone of machine learning, optimization and data science.\nMotivated by applications to recommendation systems and other scenarios with\nquery-limited access to vast amounts of data, we propose a new rigorous\nalgorithmic framework for a standard formulation of this problem as a\nsubmodular maximization subject to a linear (knapsack) constraint. Our\nframework is based on augmenting all partial Greedy solutions with the best\nadditional item. It can be instantiated with negligible overhead in any model\nof computation, which allows the classic \\greedy algorithm and its variants to\nbe implemented. We give such instantiations in the offline (Greedy+Max),\nmulti-pass streaming (Sieve+Max) and distributed (Distributed+Max) settings.\nOur algorithms give ($1/2-\\epsilon$)-approximation with most other key\nparameters of interest being near-optimal. Our analysis is based on a new set\nof first-order linear differential inequalities and their robust approximate\nversions. Experiments on typical datasets (movie recommendations, influence\nmaximization) confirm scalability and high quality of solutions obtained via\nour framework. Instance-specific approximations are typically in the 0.6-0.7\nrange and frequently beat even the $(1-1/e) \\approx 0.63$ worst-case barrier\nfor polynomial-time algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 21:20:10 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Avdiukhin", "Dmitrii", ""], ["Yaroslavtsev", "Grigory", ""], ["Zhou", "Samson", ""]]}, {"id": "1910.05651", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash", "title": "Interventional Experiment Design for Causal Structure Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that from purely observational data, a causal DAG is identifiable\nonly up to its Markov equivalence class, and for many ground truth DAGs, the\ndirection of a large portion of the edges will be remained unidentified. The\ngolden standard for learning the causal DAG beyond Markov equivalence is to\nperform a sequence of interventions in the system and use the data gathered\nfrom the interventional distributions. We consider a setup in which given a\nbudget $k$, we design $k$ interventions non-adaptively. We cast the problem of\nfinding the best intervention target set as an optimization problem which aims\nto maximize the number of edges whose directions are identified due to the\nperformed interventions. First, we consider the case that the underlying causal\nstructure is a tree. For this case, we propose an efficient exact algorithm for\nthe worst-case gain setup, as well as an approximate algorithm for the average\ngain setup. We then show that the proposed approach for the average gain setup\ncan be extended to the case of general causal structures. In this case, besides\nthe design of interventions, calculating the objective function is also\nchallenging. We propose an efficient exact calculator as well as two estimators\nfor this task. We evaluate the proposed methods using synthetic as well as real\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 21:48:22 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Salehkaleybar", "Saber", ""], ["Kiyavash", "Negar", ""]]}, {"id": "1910.05653", "submitter": "Sidak Pal Singh", "authors": "Sidak Pal Singh and Martin Jaggi", "title": "Model Fusion via Optimal Transport", "comments": "NeurIPS 2020 conference proceedings (early version featured in the\n  Optimal Transport & Machine Learning workshop, NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combining different models is a widely used paradigm in machine learning\napplications. While the most common approach is to form an ensemble of models\nand average their individual predictions, this approach is often rendered\ninfeasible by given resource constraints in terms of memory and computation,\nwhich grow linearly with the number of models. We present a layer-wise model\nfusion algorithm for neural networks that utilizes optimal transport to (soft-)\nalign neurons across the models before averaging their associated parameters.\n  We show that this can successfully yield \"one-shot\" knowledge transfer (i.e,\nwithout requiring any retraining) between neural networks trained on\nheterogeneous non-i.i.d. data. In both i.i.d. and non-i.i.d. settings , we\nillustrate that our approach significantly outperforms vanilla averaging, as\nwell as how it can serve as an efficient replacement for the ensemble with\nmoderate fine-tuning, for standard convolutional networks (like VGG11),\nresidual networks (like ResNet18), and multi-layer perceptrons on CIFAR10,\nCIFAR100, and MNIST. Finally, our approach also provides a principled way to\ncombine the parameters of neural networks with different widths, and we explore\nits application for model compression. The code is available at the following\nlink, https://github.com/sidak/otfusion.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 22:07:15 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 13:05:55 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 15:16:06 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2020 16:42:43 GMT"}, {"version": "v5", "created": "Sun, 14 Feb 2021 21:50:57 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Singh", "Sidak Pal", ""], ["Jaggi", "Martin", ""]]}, {"id": "1910.05654", "submitter": "Young Hun Jung", "authors": "Young Hun Jung, Marc Abeille, Ambuj Tewari", "title": "Thompson Sampling in Non-Episodic Restless Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restless bandit problems assume time-varying reward distributions of the\narms, which adds flexibility to the model but makes the analysis more\nchallenging. We study learning algorithms over the unknown reward distributions\nand prove a sub-linear, $O(\\sqrt{T}\\log T)$, regret bound for a variant of\nThompson sampling. Our analysis applies in the infinite time horizon setting,\nresolving the open question raised by Jung and Tewari (2019) whose analysis is\nlimited to the episodic case. We adopt their policy mapping framework, which\nallows our algorithm to be efficient and simultaneously keeps the regret\nmeaningful. Our algorithm adapts the TSDE algorithm of Ouyang et al. (2017) in\na non-trivial manner to account for the special structure of restless bandits.\nWe test our algorithm on a simulated dynamic channel access problem with\nseveral policy mappings, and the empirical regrets agree with the theoretical\nbound regardless of the choice of the policy mapping.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 22:30:24 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Jung", "Young Hun", ""], ["Abeille", "Marc", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1910.05664", "submitter": "Yonadav Shavit", "authors": "Yonadav Shavit, William S. Moses", "title": "Extracting Incentives from Black-Box Decisions", "comments": "Accepted to the NeurIPS 2019 Workshop on Robust AI in Financial\n  Services: Data, Fairness, Explainability, Trustworthiness, and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithmic decision-maker incentivizes people to act in certain ways to\nreceive better decisions. These incentives can dramatically influence subjects'\nbehaviors and lives, and it is important that both decision-makers and\ndecision-recipients have clarity on which actions are incentivized by the\nchosen model. While for linear functions, the changes a subject is incentivized\nto make may be clear, we prove that for many non-linear functions (e.g. neural\nnetworks, random forests), classical methods for interpreting the behavior of\nmodels (e.g. input gradients) provide poor advice to individuals on which\nactions they should take. In this work, we propose a mathematical framework for\nunderstanding algorithmic incentives as the challenge of solving a Markov\nDecision Process, where the state includes the set of input features, and the\nreward is a function of the model's output. We can then leverage the many\ntoolkits for solving MDPs (e.g. tree-based planning, reinforcement learning) to\nidentify the optimal actions each individual is incentivized to take to improve\ntheir decision under a given model. We demonstrate the utility of our method by\nestimating the maximally-incentivized actions in two real-world settings: a\nrecidivism risk predictor we train using ProPublica's COMPAS dataset, and an\nonline credit scoring tool published by the Fair Isaac Corporation (FICO).\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 01:17:29 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Shavit", "Yonadav", ""], ["Moses", "William S.", ""]]}, {"id": "1910.05680", "submitter": "Chao-Tsung Huang", "authors": "Chao-Tsung Huang, Yu-Chun Ding, Huan-Ching Wang, Chi-Wen Weng,\n  Kai-Ping Lin, Li-Wei Wang, Li-De Chen", "title": "eCNN: A Block-Based and Highly-Parallel CNN Accelerator for Edge\n  Inference", "comments": "14 pages; appearing in IEEE/ACM International Symposium on\n  Microarchitecture (MICRO), 2019", "journal-ref": null, "doi": "10.1145/3352460.3358263", "report-no": null, "categories": "cs.DC cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have recently demonstrated superior\nquality for computational imaging applications. Therefore, they have great\npotential to revolutionize the image pipelines on cameras and displays.\nHowever, it is difficult for conventional CNN accelerators to support\nultra-high-resolution videos at the edge due to their considerable DRAM\nbandwidth and power consumption. Therefore, finding a further memory- and\ncomputation-efficient microarchitecture is crucial to speed up this coming\nrevolution.\n  In this paper, we approach this goal by considering the inference flow,\nnetwork model, instruction set, and processor design jointly to optimize\nhardware performance and image quality. We apply a block-based inference flow\nwhich can eliminate all the DRAM bandwidth for feature maps and accordingly\npropose a hardware-oriented network model, ERNet, to optimize image quality\nbased on hardware constraints. Then we devise a coarse-grained instruction set\narchitecture, FBISA, to support power-hungry convolution by massive\nparallelism. Finally,we implement an embedded processor---eCNN---which\naccommodates to ERNet and FBISA with a flexible processing architecture. Layout\nresults show that it can support high-quality ERNets for super-resolution and\ndenoising at up to 4K Ultra-HD 30 fps while using only DDR-400 and consuming\n6.94W on average. By comparison, the state-of-the-art Diffy uses dual-channel\nDDR3-2133 and consumes 54.3W to support lower-quality VDSR at Full HD 30 fps.\nLastly, we will also present application examples of high-performance style\ntransfer and object recognition to demonstrate the flexibility of eCNN.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 03:54:25 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Huang", "Chao-Tsung", ""], ["Ding", "Yu-Chun", ""], ["Wang", "Huan-Ching", ""], ["Weng", "Chi-Wen", ""], ["Lin", "Kai-Ping", ""], ["Wang", "Li-Wei", ""], ["Chen", "Li-De", ""]]}, {"id": "1910.05683", "submitter": "Brosnan Yuen", "authors": "Brosnan Yuen", "title": "Hardware/Software Codesign for Training/Testing Multiple Neural Networks\n  on Multiple FPGAs", "comments": "It was submitted without proper permission granted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most neural network designs for FPGAs are inflexible. In this paper, we\npropose a flexible VHDL structure that would allow any neural network to be\nimplemented on multiple FPGAs. Moreover, the VHDL structure allows for testing\nas well as training multiple neural networks. The VHDL design consists of\nmultiple processor groups. There are two types of processor groups: Mini Vector\nMachine Processor Group and Activation Processor Group. Each processor group\nconsists of individual Mini Vector Machines and Activation Processor. The Mini\nVector Machines apply vector operations to the data, while the Activation\nProcessors apply activation functions to the data. A ring buffer was\nimplemented to connect the various processor groups.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 04:12:32 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 22:26:16 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Yuen", "Brosnan", ""]]}, {"id": "1910.05691", "submitter": "Dhrubasish Sarkar", "authors": "Dhrubasish Sarkar and Premananda Jana", "title": "Analyzing User Activities Using Vector Space Model in Online Social\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popularity of internet, wireless technologies and mobile\ndevices has led to the birth of mass connectivity and online interaction\nthrough Online Social Networks (OSNs) and similar environments. OSN reflects a\nsocial structure consist of a set of individuals and different types of ties\nlike connections, relationships, interactions etc among them and helps its\nusers to connect with their friends and common interest groups, share views and\nto pass information. Now days the users choose OSN sites as a most preferred\nplace for sharing their updates, different views, posting photographs and would\nlike to make it available for others for viewing, rating and making comments.\nThe current paper aims to explore and analyze the association between the\nobjects (like photographs, posts etc) and its viewers (friends, acquaintances\netc) for a given user and to find activity relationship among them by using the\nTF-IDF scheme of Vector Space Model. After vectorization the vector data has\nbeen presented through a weighted graph with various properties.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 05:57:16 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Sarkar", "Dhrubasish", ""], ["Jana", "Premananda", ""]]}, {"id": "1910.05695", "submitter": "Babak Shahbaba", "authors": "Tian Chen, Lingge Li, Gabriel Elias, Norbert Fortin, and Babak\n  Shahbaba", "title": "Bayesian Neural Decoding Using A Diversity-Encouraging Latent\n  Representation Learning Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well established that temporal organization is critical to memory, and\nthat the ability to temporally organize information is fundamental to many\nperceptual, cognitive, and motor processes. While our understanding of how the\nbrain processes the spatial context of memories has advanced considerably, our\nunderstanding of their temporal organization lags far behind. In this paper, we\npropose a new approach for elucidating the neural basis of complex behaviors\nand temporal organization of memories. More specifically, we focus on neural\ndecoding - the prediction of behavioral or experimental conditions based on\nobserved neural data. In general, this is a challenging classification problem,\nwhich is of immense interest in neuroscience. Our goal is to develop a new\nframework that not only improves the overall accuracy of decoding, but also\nprovides a clear latent representation of the decoding process. To accomplish\nthis, our approach uses a Variational Auto-encoder (VAE) model with a\ndiversity-encouraging prior based on determinantal point processes (DPP) to\nimprove latent representation learning by avoiding redundancy in the latent\nspace. We apply our method to data collected from a novel rat experiment that\ninvolves presenting repeated sequences of odors at a single port and testing\nthe rats' ability to identify each odor. We show that our method leads to\nsubstantially higher accuracy rate for neural decoding and allows to discover\nnovel biological phenomena by providing a clear latent representation of the\ndecoding process.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 06:03:39 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Chen", "Tian", ""], ["Li", "Lingge", ""], ["Elias", "Gabriel", ""], ["Fortin", "Norbert", ""], ["Shahbaba", "Babak", ""]]}, {"id": "1910.05697", "submitter": "Amit Daniely", "authors": "Amit Daniely and Elad Granot", "title": "Generalization Bounds for Neural Networks via Approximate Description\n  Length", "comments": "To appear in NeurIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the sample complexity of networks with bounds on the magnitude\nof its weights. In particular, we consider the class \\[\nH=\\left\\{W_t\\circ\\rho\\circ \\ldots\\circ\\rho\\circ W_{1} :W_1,\\ldots,W_{t-1}\\in\nM_{d, d}, W_t\\in M_{1,d}\\right\\} \\] where the spectral norm of each $W_i$ is\nbounded by $O(1)$, the Frobenius norm is bounded by $R$, and $\\rho$ is the\nsigmoid function $\\frac{e^x}{1+e^x}$ or the smoothened ReLU function $ \\ln\n(1+e^x)$. We show that for any depth $t$, if the inputs are in $[-1,1]^d$, the\nsample complexity of $H$ is $\\tilde O\\left(\\frac{dR^2}{\\epsilon^2}\\right)$.\nThis bound is optimal up to log-factors, and substantially improves over the\nprevious state of the art of $\\tilde O\\left(\\frac{d^2R^2}{\\epsilon^2}\\right)$.\n  We furthermore show that this bound remains valid if instead of considering\nthe magnitude of the $W_i$'s, we consider the magnitude of $W_i - W_i^0$, where\n$W_i^0$ are some reference matrices, with spectral norm of $O(1)$. By taking\nthe $W_i^0$ to be the matrices at the onset of the training process, we get\nsample complexity bounds that are sub-linear in the number of parameters, in\nmany typical regimes of parameters.\n  To establish our results we develop a new technique to analyze the sample\ncomplexity of families $H$ of predictors. We start by defining a new notion of\na randomized approximate description of functions $f:X\\to\\mathbb{R}^d$. We then\nshow that if there is a way to approximately describe functions in a class $H$\nusing $d$ bits, then $d/\\epsilon^2$ examples suffices to guarantee uniform\nconvergence. Namely, that the empirical loss of all the functions in the class\nis $\\epsilon$-close to the true loss. Finally, we develop a set of tools for\ncalculating the approximate description length of classes of functions that can\nbe presented as a composition of linear function classes and non-linear\nfunctions.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 06:21:55 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Daniely", "Amit", ""], ["Granot", "Elad", ""]]}, {"id": "1910.05704", "submitter": "Zhenzhou Wang", "authors": "Zhenzhou Wang", "title": "Contour Sparse Representation with SDD Features for Object Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slope difference distribution (SDD) is computed for the one-dimensional\ncurve. It is not only robust to calculate the partitioning point to separate\nthe curve logically, but also robust to calculate the clustering center of each\npart of the separated curve. SDD has been proposed for image segmentation and\nit outperforms all existing image segmentation methods. For verification\npurpose, we have made the Matlab codes of comparing SDD method with existing\nimage segmentation methods freely available at Matlab Central. The contour of\nthe object is similar to the histogram of the image. Thus, feature detection by\nSDD from the contour of the object is also feasible. In this letter, SDD\nfeatures are defined and they form the sparse representation of the object\ncontour. The reference model of each object is built based on the SDD features\nand then model matching is used for on line object recognition. The\nexperimental results are very encouraging. For the gesture recognition, SDD\nachieved 100% accuracy for two public datasets: the NUS dataset and the\nnear-infrared dataset. For the object recognition, SDD achieved 100% accuracy\nfor the Kimia 99 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 07:13:19 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 07:23:13 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Wang", "Zhenzhou", ""]]}, {"id": "1910.05705", "submitter": "Vishnu Raj", "authors": "Navaneet Athreya, Vishnu Raj and Sheetal Kalyani", "title": "Beyond 5G: Leveraging Cell Free TDD Massive MIMO using Cascaded Deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the calibration of Time Division Duplexing (TDD)\nreciprocity in an Orthogonal Frequency Division Multiplexing (OFDM) based Cell\nFree Massive MIMO system where the responses of the (Radio Frequency) RF chains\nrender the end to end channel non-reciprocal, even though the physical wireless\nchannel is reciprocal. We further address the non-availability of the uplink\nchannel estimates at locations other than pilot subcarriers and propose a\nsingle-shot solution to estimate the downlink channel at all subcarriers from\nthe uplink channel at selected pilot subcarriers. We propose a cascade of two\nDeep Neural Networks (DNN) to achieve the objective. The proposed method is\neasily scalable and removes the need for relative reciprocity calibration based\non the cooperation of antennas, which usually introduces dependency in Cell\nFree Massive MIMO systems.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 07:24:16 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 00:49:23 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Athreya", "Navaneet", ""], ["Raj", "Vishnu", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1910.05725", "submitter": "Herman Kamper", "authors": "Arnu Pretorius, Elan van Biljon, Benjamin van Niekerk, Ryan Eloff,\n  Matthew Reynard, Steve James, Benjamin Rosman, Herman Kamper, Steve Kroon", "title": "If dropout limits trainable depth, does critical initialisation still\n  matter? A large-scale statistical analysis on ReLU networks", "comments": "8 pages, 6 figures, under consideration at Pattern Recognition\n  Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in signal propagation theory has shown that dropout limits the\ndepth to which information can propagate through a neural network. In this\npaper, we investigate the effect of initialisation on training speed and\ngeneralisation for ReLU networks within this depth limit. We ask the following\nresearch question: given that critical initialisation is crucial for training\nat large depth, if dropout limits the depth at which networks are trainable,\ndoes initialising critically still matter? We conduct a large-scale controlled\nexperiment, and perform a statistical analysis of over $12000$ trained\nnetworks. We find that (1) trainable networks show no statistically significant\ndifference in performance over a wide range of non-critical initialisations;\n(2) for initialisations that show a statistically significant difference, the\nnet effect on performance is small; (3) only extreme initialisations (very\nsmall or very large) perform worse than criticality. These findings also apply\nto standard ReLU networks of moderate depth as a special case of zero dropout.\nOur results therefore suggest that, in the shallow-to-moderate depth setting,\ncritical initialisation provides zero performance gains when compared to\noff-critical initialisations and that searching for off-critical\ninitialisations that might improve training speed or generalisation, is likely\nto be a fruitless endeavour.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 10:39:32 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 10:34:44 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Pretorius", "Arnu", ""], ["van Biljon", "Elan", ""], ["van Niekerk", "Benjamin", ""], ["Eloff", "Ryan", ""], ["Reynard", "Matthew", ""], ["James", "Steve", ""], ["Rosman", "Benjamin", ""], ["Kamper", "Herman", ""], ["Kroon", "Steve", ""]]}, {"id": "1910.05728", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Shivansh Patel and Vinay P. Namboodiri", "title": "Granular Multimodal Attention Networks for Visual Dialog", "comments": "ICCV Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vision and language tasks have benefited from attention. There have been a\nnumber of different attention models proposed. However, the scale at which\nattention needs to be applied has not been well examined. Particularly, in this\nwork, we propose a new method Granular Multi-modal Attention, where we aim to\nparticularly address the question of the right granularity at which one needs\nto attend while solving the Visual Dialog task. The proposed method shows\nimprovement in both image and text attention networks. We then propose a\ngranular Multi-modal Attention network that jointly attends on the image and\ntext granules and shows the best performance. With this work, we observe that\nobtaining granular attention and doing exhaustive Multi-modal Attention appears\nto be the best way to attend while solving visual dialog.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 10:49:41 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Patro", "Badri N.", ""], ["Patel", "Shivansh", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1910.05744", "submitter": "Dong Liu", "authors": "Dong Liu and Antoine Honor\\'e and Saikat Chatterjee and Lars K.\n  Rasmussen", "title": "Powering Hidden Markov Model by Neural Network based Generative Models", "comments": null, "journal-ref": "ECAI 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov model (HMM) has been successfully used for sequential data\nmodeling problems. In this work, we propose to power the modeling capacity of\nHMM by bringing in neural network based generative models. The proposed model\nis termed as GenHMM. In the proposed GenHMM, each HMM hidden state is\nassociated with a neural network based generative model that has tractability\nof exact likelihood and provides efficient likelihood computation. A generative\nmodel in GenHMM consists of mixture of generators that are realized by flow\nmodels. A learning algorithm for GenHMM is proposed in expectation-maximization\nframework. The convergence of the learning GenHMM is analyzed. We demonstrate\nthe efficiency of GenHMM by classification tasks on practical sequential data.\nCode available at https://github.com/FirstHandScientist/genhmm.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 13:06:43 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 15:41:27 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 20:07:01 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Liu", "Dong", ""], ["Honor\u00e9", "Antoine", ""], ["Chatterjee", "Saikat", ""], ["Rasmussen", "Lars K.", ""]]}, {"id": "1910.05751", "submitter": "Jia Liu", "authors": "Wenhua Zhang, Licheng Jiao, Jia Liu", "title": "Hierarchical Feature-Aware Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a hierarchical feature-aware tracking framework for\nefficient visual tracking. Recent years, ensembled trackers which combine\nmultiple component trackers have achieved impressive performance. In ensembled\ntrackers, the decision of results is usually a post-event process, i.e.,\ntracking result for each tracker is first obtained and then the suitable one is\nselected according to result ensemble. In this paper, we propose a pre-event\nmethod. We construct an expert pool with each expert being one set of features.\nFor each frame, several experts are first selected in the pool according to\ntheir past performance and then they are used to predict the object. The\nselection rate of each expert in the pool is then updated and tracking result\nis obtained according to result ensemble. We propose a novel pre-known\nexpert-adaptive selection strategy. Since the process is more efficient, more\nexperts can be constructed by fusing more types of features which leads to more\nrobustness. Moreover, with the novel expert selection strategy, overfitting\ncaused by fixed experts for each frame can be mitigated. Experiments on several\npublic available datasets demonstrate the superiority of the proposed method\nand its state-of-the-art performance among ensembled trackers.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 13:51:44 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 14:09:12 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Zhang", "Wenhua", ""], ["Jiao", "Licheng", ""], ["Liu", "Jia", ""]]}, {"id": "1910.05765", "submitter": "Tugba Erpek", "authors": "Sohraab Soltani, Yalin E. Sagduyu, Raqibul Hasan, Kemal Davaslioglu,\n  Hongmei Deng, Tugba Erpek", "title": "Real-Time and Embedded Deep Learning on FPGA for RF Signal\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We designed and implemented a deep learning based RF signal classifier on the\nField Programmable Gate Array (FPGA) of an embedded software-defined radio\nplatform, DeepRadio, that classifies the signals received through the RF front\nend to different modulation types in real time and with low power. This\nclassifier implementation successfully captures complex characteristics of\nwireless signals to serve critical applications in wireless security and\ncommunications systems such as identifying spoofing signals in signal\nauthentication systems, detecting target emitters and jammers in electronic\nwarfare (EW) applications, discriminating primary and secondary users in\ncognitive radio networks, interference hunting, and adaptive modulation.\nEmpowered by low-power and low-latency embedded computing, the deep neural\nnetwork runs directly on the FPGA fabric of DeepRadio, while maintaining\nclassifier accuracy close to the software performance. We evaluated the\nperformance when another SDR (USRP) transmits signals with different modulation\ntypes at different power levels and DeepRadio receives the signals and\nclassifies them in real time on its FPGA. A smartphone with a mobile app is\nconnected to DeepRadio to initiate the experiment and visualize the\nclassification results. With real radio transmissions over the air, we show\nthat the classifier implemented on DeepRadio achieves high accuracy with low\nlatency (microsecond per sample) and low energy consumption (microJoule per\nsample), and this performance is not matched by other embedded platforms such\nas embedded graphics processing unit (GPU).\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 15:01:56 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Soltani", "Sohraab", ""], ["Sagduyu", "Yalin E.", ""], ["Hasan", "Raqibul", ""], ["Davaslioglu", "Kemal", ""], ["Deng", "Hongmei", ""], ["Erpek", "Tugba", ""]]}, {"id": "1910.05766", "submitter": "Tugba Erpek", "authors": "Nof Abuzainab, Tugba Erpek, Kemal Davaslioglu, Yalin E. Sagduyu, Yi\n  Shi, Sharon J. Mackey, Mitesh Patel, Frank Panettieri, Muhammad A. Qureshi,\n  Volkan Isler, Aylin Yener", "title": "QoS and Jamming-Aware Wireless Networking Using Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of quality of service (QoS) and jamming-aware communications is\nconsidered in an adversarial wireless network subject to external eavesdropping\nand jamming attacks. To ensure robust communication against jamming, an\ninterference-aware routing protocol is developed that allows nodes to avoid\ncommunication holes created by jamming attacks. Then, a distributed cooperation\nframework, based on deep reinforcement learning, is proposed that allows nodes\nto assess network conditions and make deep learning-driven, distributed, and\nreal-time decisions on whether to participate in data communications, defend\nthe network against jamming and eavesdropping attacks, or jam other\ntransmissions. The objective is to maximize the network performance that\nincorporates throughput, energy efficiency, delay, and security metrics.\nSimulation results show that the proposed jamming-aware routing approach is\nrobust against jamming and when throughput is prioritized, the proposed deep\nreinforcement learning approach can achieve significant (measured as\nthree-fold) increase in throughput, compared to a benchmark policy with fixed\nroles assigned to nodes.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 15:10:53 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Abuzainab", "Nof", ""], ["Erpek", "Tugba", ""], ["Davaslioglu", "Kemal", ""], ["Sagduyu", "Yalin E.", ""], ["Shi", "Yi", ""], ["Mackey", "Sharon J.", ""], ["Patel", "Mitesh", ""], ["Panettieri", "Frank", ""], ["Qureshi", "Muhammad A.", ""], ["Isler", "Volkan", ""], ["Yener", "Aylin", ""]]}, {"id": "1910.05769", "submitter": "Bo Li", "authors": "Bo Li and David Saad", "title": "Large Deviation Analysis of Function Sensitivity in Random Deep Neural\n  Networks", "comments": null, "journal-ref": "J. Phys. A: Math. Theor. 53. 104002 (2020)", "doi": "10.1088/1751-8121/ab6a6f", "report-no": null, "categories": "cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean field theory has been successfully used to analyze deep neural networks\n(DNN) in the infinite size limit. Given the finite size of realistic DNN, we\nutilize the large deviation theory and path integral analysis to study the\ndeviation of functions represented by DNN from their typical mean field\nsolutions. The parameter perturbations investigated include weight\nsparsification (dilution) and binarization, which are commonly used in model\nsimplification, for both ReLU and sign activation functions. We find that\nrandom networks with ReLU activation are more robust to parameter perturbations\nwith respect to their counterparts with sign activation, which arguably is\nreflected in the simplicity of the functions they generate.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 15:20:18 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 17:24:45 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Li", "Bo", ""], ["Saad", "David", ""]]}, {"id": "1910.05770", "submitter": "Lamberto Ballan", "authors": "Tobia Tesan, Pasquale Coscia, Lamberto Ballan", "title": "A CNN-RNN Framework for Image Annotation from Visual Cues and Social\n  Network Metadata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images represent a commonly used form of visual communication among people.\nNevertheless, image classification may be a challenging task when dealing with\nunclear or non-common images needing more context to be correctly annotated.\nMetadata accompanying images on social-media represent an ideal source of\nadditional information for retrieving proper neighborhoods easing image\nannotation task. To this end, we blend visual features extracted from neighbors\nand their metadata to jointly leverage context and visual cues. Our models use\nmultiple semantic embeddings to achieve the dual objective of being robust to\nvocabulary changes between train and test sets and decoupling the architecture\nfrom the low-level metadata representation. Convolutional and recurrent neural\nnetworks (CNNs-RNNs) are jointly adopted to infer similarity among neighbors\nand query images. We perform comprehensive experiments on the NUS-WIDE dataset\nshowing that our models outperform state-of-the-art architectures based on\nimages and metadata, and decrease both sensory and semantic gaps to better\nannotate images.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 15:24:48 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 17:19:26 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Tesan", "Tobia", ""], ["Coscia", "Pasquale", ""], ["Ballan", "Lamberto", ""]]}, {"id": "1910.05774", "submitter": "Dimitrios Kollias", "authors": "Hanne Carlsson and Dimitrios Kollias", "title": "Image Generation and Recognition (Emotions)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) were proposed in 2014 by Goodfellow et\nal., and have since been extended into multiple computer vision applications.\nThis report provides a thorough survey of recent GAN research, outlining the\nvarious architectures and applications, as well as methods for training GANs\nand dealing with latent space. This is followed by a discussion of potential\nareas for future GAN research, including: evaluating GANs, better understanding\nGANs, and techniques for training GANs. The second part of this report outlines\nthe compilation of a dataset of images `in the wild' representing each of the 7\nbasic human emotions, and analyses experiments done when training a StarGAN on\nthis dataset combined with the FER2013 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 16:00:06 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 23:10:05 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Carlsson", "Hanne", ""], ["Kollias", "Dimitrios", ""]]}, {"id": "1910.05784", "submitter": "Dimitrios Kollias", "authors": "Xia Yicheng and Dimitrios Kollias", "title": "Interpretable Deep Neural Networks for Dimensional and Categorical\n  Emotion Recognition in-the-wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotions play an important role in people's life. Understanding and\nrecognising is not only important for interpersonal communication, but also has\npromising applications in Human-Computer Interaction, automobile safety and\nmedical research. This project focuses on extending the emotion recognition\ndatabase, and training the CNN + RNN emotion recognition neural networks with\nemotion category representation and valence \\& arousal representation. The\ncombined models are constructed by training the two representations\nsimultaneously. The comparison and analysis between the three types of model\nare discussed. The inner-relationship between two emotion representations and\nthe interpretability of the neural networks are investigated. The findings\nsuggest that categorical emotion recognition performance can benefit from\ntraining with a combined model. And the mapping of emotion category and valence\n\\& arousal values can explain this phenomenon.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 16:33:18 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 23:25:57 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Yicheng", "Xia", ""], ["Kollias", "Dimitrios", ""]]}, {"id": "1910.05787", "submitter": "Chao-Tsung Huang", "authors": "Chao-Tsung Huang", "title": "ERNet Family: Hardware-Oriented CNN Models for Computational Imaging\n  Using Block-Based Inference", "comments": "5 pages; appearing in IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) demand huge DRAM bandwidth for\ncomputational imaging tasks, and block-based processing has recently been\napplied to greatly reduce the bandwidth. However, the induced additional\ncomputation for feature recomputing or the large SRAM for feature reusing will\ndegrade the performance or even forbid the usage of state-of-the-art models. In\nthis paper, we address these issues by considering the overheads and hardware\nconstraints in advance when constructing CNNs. We investigate a novel model\nfamily---ERNet---which includes temporary layer expansion as another means for\nincreasing model capacity. We analyze three ERNet variants in terms of hardware\nrequirement and introduce a hardware-aware model optimization procedure.\nEvaluations on Full HD and 4K UHD applications will be given to show the\neffectiveness in terms of image quality, pixel throughput, and SRAM usage. The\nresults also show that, for block-based inference, ERNet can outperform the\nstate-of-the-art FFDNet and EDSR-baseline models for image denoising and\nsuper-resolution respectively.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 17:02:41 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 08:13:33 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Huang", "Chao-Tsung", ""]]}, {"id": "1910.05789", "submitter": "Micah Carroll", "authors": "Micah Carroll, Rohin Shah, Mark K. Ho, Thomas L. Griffiths, Sanjit A.\n  Seshia, Pieter Abbeel, Anca Dragan", "title": "On the Utility of Learning about Humans for Human-AI Coordination", "comments": "Published at NeurIPS 2019\n  (http://papers.nips.cc/paper/8760-on-the-utility-of-learning-about-humans-for-human-ai-coordination)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While we would like agents that can coordinate with humans, current\nalgorithms such as self-play and population-based training create agents that\ncan coordinate with themselves. Agents that assume their partner to be optimal\nor similar to them can converge to coordination protocols that fail to\nunderstand and be understood by humans. To demonstrate this, we introduce a\nsimple environment that requires challenging coordination, based on the popular\ngame Overcooked, and learn a simple model that mimics human play. We evaluate\nthe performance of agents trained via self-play and population-based training.\nThese agents perform very well when paired with themselves, but when paired\nwith our human model, they are significantly worse than agents designed to play\nwith the human model. An experiment with a planning algorithm yields the same\nconclusion, though only when the human-aware planner is given the exact human\nmodel that it is playing with. A user study with real humans shows this pattern\nas well, though less strongly. Qualitatively, we find that the gains come from\nhaving the agent adapt to the human's gameplay. Given this result, we suggest\nseveral approaches for designing agents that learn about humans in order to\nbetter coordinate with them. Code is available at\nhttps://github.com/HumanCompatibleAI/overcooked_ai.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 17:17:52 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 00:51:44 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Carroll", "Micah", ""], ["Shah", "Rohin", ""], ["Ho", "Mark K.", ""], ["Griffiths", "Thomas L.", ""], ["Seshia", "Sanjit A.", ""], ["Abbeel", "Pieter", ""], ["Dragan", "Anca", ""]]}, {"id": "1910.05804", "submitter": "Ching-Yao Chuang", "authors": "Ching-Yao Chuang, Antonio Torralba, Stefanie Jegelka", "title": "The Role of Embedding Complexity in Domain-invariant Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation aims to generalize the hypothesis trained in a\nsource domain to an unlabeled target domain. One popular approach to this\nproblem is to learn domain-invariant embeddings for both domains. In this work,\nwe study, theoretically and empirically, the effect of the embedding complexity\non generalization to the target domain. In particular, this complexity affects\nan upper bound on the target risk; this is reflected in experiments, too. Next,\nwe specify our theoretical framework to multilayer neural networks. As a\nresult, we develop a strategy that mitigates sensitivity to the embedding\ncomplexity, and empirically achieves performance on par with or better than the\nbest layer-dependent complexity tradeoff.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 18:20:25 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Chuang", "Ching-Yao", ""], ["Torralba", "Antonio", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1910.05811", "submitter": "Fan Ding", "authors": "Fan Ding, Hanjing Wang, Ashish Sabharwal, Yexiang Xue", "title": "Towards Efficient Discrete Integration via Adaptive Quantile Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete integration in a high dimensional space of n variables poses\nfundamental challenges. The WISH algorithm reduces the intractable discrete\nintegration problem into n optimization queries subject to randomized\nconstraints, obtaining a constant approximation guarantee. The optimization\nqueries are expensive, which limits the applicability of WISH. We propose\nAdaWISH, which is able to obtain the same guarantee but accesses only a small\nsubset of queries of WISH. For example, when the number of function values is\nbounded by a constant, AdaWISH issues only O(log n) queries. The key idea is to\nquery adaptively, taking advantage of the shape of the weight function being\nintegrated. In general, we prove that AdaWISH has a regret of only O(log n)\nrelative to an idealistic oracle that issues queries at data-dependent optimal\npoints. Experimentally, AdaWISH gives precise estimates for discrete\nintegration problems, of the same quality as that of WISH and better than\nseveral competing approaches, on a variety of probabilistic inference\nbenchmarks. At the same time, it saves substantially on the number of\noptimization queries compared to WISH. On a suite of UAI inference challenge\nbenchmarks, it saves 81.5% of WISH queries while retaining the quality of\nresults.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 18:45:10 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 23:24:40 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Ding", "Fan", ""], ["Wang", "Hanjing", ""], ["Sabharwal", "Ashish", ""], ["Xue", "Yexiang", ""]]}, {"id": "1910.05814", "submitter": "Samuel Melton", "authors": "Samuel Melton, Sharad Ramanathan", "title": "Discovering a sparse set of pairwise discriminating features in high\n  dimensional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting an understanding of the underlying system from high dimensional\ndata is a growing problem in science. Discovering informative and meaningful\nfeatures is crucial for clustering, classification, and low dimensional data\nembedding. Here we propose to construct features based on their ability to\ndiscriminate between clusters of the data points. We define a class of problems\nin which linear separability of clusters is hidden in a low dimensional space.\nWe propose an unsupervised method to identify the subset of features that\ndefine a low dimensional subspace in which clustering can be conducted. This is\nachieved by averaging over discriminators trained on an ensemble of proposed\ncluster configurations. We then apply our method to single cell RNA-seq data\nfrom mouse gastrulation, and identify 27 key transcription factors (out of 409\ntotal), 18 of which are known to define cell states through their expression\nlevels. In this inferred subspace, we find clear signatures of known cell types\nthat eluded classification prior to discovery of the correct low dimensional\nsubspace.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 19:19:32 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 16:47:06 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Melton", "Samuel", ""], ["Ramanathan", "Sharad", ""]]}, {"id": "1910.05821", "submitter": "Yuzhe Ma", "authors": "Yuzhe Ma, Xuezhou Zhang, Wen Sun, Xiaojin Zhu", "title": "Policy Poisoning in Batch Reinforcement Learning and Control", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a security threat to batch reinforcement learning and control where\nthe attacker aims to poison the learned policy. The victim is a reinforcement\nlearner / controller which first estimates the dynamics and the rewards from a\nbatch data set, and then solves for the optimal policy with respect to the\nestimates. The attacker can modify the data set slightly before learning\nhappens, and wants to force the learner into learning a target policy chosen by\nthe attacker. We present a unified framework for solving batch policy poisoning\nattacks, and instantiate the attack on two standard victims: tabular certainty\nequivalence learner in reinforcement learning and linear quadratic regulator in\ncontrol. We show that both instantiation result in a convex optimization\nproblem on which global optimality is guaranteed, and provide analysis on\nattack feasibility and attack cost. Experiments show the effectiveness of\npolicy poisoning attacks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 19:53:31 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 01:58:12 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Ma", "Yuzhe", ""], ["Zhang", "Xuezhou", ""], ["Sun", "Wen", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1910.05835", "submitter": "Christopher Choquette Choo", "authors": "Christopher A. Choquette-Choo, David Sheldon, Jonny Proppe, John\n  Alphonso-Gibbs, Harsha Gupta", "title": "A multi-label, dual-output deep neural network for automated bug\n  triaging", "comments": "8 pages, 2 figures, 9 tables", "journal-ref": "2019 18th IEEE International Conference On Machine Learning And\n  Applications (ICMLA) 937-944", "doi": "10.1109/ICMLA.2019.00161", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bug tracking enables the monitoring and resolution of issues and bugs within\norganizations. Bug triaging, or assigning bugs to the owner(s) who will resolve\nthem, is a critical component of this process because there are many incorrect\nassignments that waste developer time and reduce bug resolution throughput. In\nthis work, we explore the use of a novel two-output deep neural network\narchitecture (Dual DNN) for triaging a bug to both an individual team and\ndeveloper, simultaneously. Dual DNN leverages this simultaneous prediction by\nexploiting its own guess of the team classes to aid in developer assignment. A\nmulti-label classification approach is used for each of the two outputs to\nlearn from all interim owners, not just the last one who closed the bug. We\nmake use of a heuristic combination of the interim owners\n(owner-importance-weighted labeling) which is converted into a probability mass\nfunction (pmf). We employ a two-stage learning scheme, whereby the team portion\nof the model is trained first and then held static to train the team--developer\nand bug--developer relationships. The scheme employed to encode the\nteam--developer relationships is based on an organizational chart (org chart),\nwhich renders the model robust to organizational changes as it can adapt to\nrole changes within an organization. There is an observed average lift (with\nrespect to both team and developer assignment) of 13%-points in 11-fold\nincremental-learning cross-validation (IL-CV) accuracy for Dual DNN utilizing\nowner-weighted labels compared with the traditional multi-class classification\napproach. Furthermore, Dual DNN with owner-weighted labels achieves average\n11-fold IL-CV accuracies of 76% (team assignment) and 55% (developer\nassignment), outperforming reference models by 14%- and 25%-points,\nrespectively, on a proprietary dataset with 236,865 entries.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 21:14:53 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Choquette-Choo", "Christopher A.", ""], ["Sheldon", "David", ""], ["Proppe", "Jonny", ""], ["Alphonso-Gibbs", "John", ""], ["Gupta", "Harsha", ""]]}, {"id": "1910.05843", "submitter": "Rui Meng", "authors": "Rui Meng, Herbert Lee, Soper Braden, Priyadip Ray", "title": "Regularized Sparse Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are a flexible Bayesian nonparametric modelling approach\nthat has been widely applied but poses computational challenges. To address the\npoor scaling of exact inference methods, approximation methods based on sparse\nGaussian processes (SGP) are attractive. An issue faced by SGP, especially in\nlatent variable models, is the inefficient learning of the inducing inputs,\nwhich leads to poor model prediction. We propose a regularization approach by\nbalancing the reconstruction performance of data and the approximation\nperformance of the model itself. This regularization improves both inference\nand prediction performance. We extend this regularization approach into latent\nvariable models with SGPs and show that performing variational inference (VI)\non those models is equivalent to performing VI on a related empirical Bayes\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 21:53:44 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 03:09:40 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Meng", "Rui", ""], ["Lee", "Herbert", ""], ["Braden", "Soper", ""], ["Ray", "Priyadip", ""]]}, {"id": "1910.05852", "submitter": "Florian Sch\\\"afer", "authors": "Florian Sch\\\"afer, Hongkai Zheng, Anima Anandkumar", "title": "Implicit competitive regularization in GANs", "comments": "The code used to produce the numerical experiments can be found under\n  http://github.com/devzhk/ICR . A high-level overview of this work can be\n  found under https://f-t-s.github.io/projects/icr/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the stability of GAN training we need to understand why they can\nproduce realistic samples. Presently, this is attributed to properties of the\ndivergence obtained under an optimal discriminator. This argument has a\nfundamental flaw: If we do not impose regularity of the discriminator, it can\nexploit visually imperceptible errors of the generator to always achieve the\nmaximal generator loss. In practice, gradient penalties are used to regularize\nthe discriminator. However, this needs a metric on the space of images that\ncaptures visual similarity. Such a metric is not known, which explains the\nlimited success of gradient penalties in stabilizing GANs. We argue that the\nperformance of GANs is instead due to the implicit competitive regularization\n(ICR) arising from the simultaneous optimization of generator and\ndiscriminator. ICR promotes solutions that look real to the discriminator and\nthus leverages its inductive biases to generate realistic images. We show that\nopponent-aware modelling of generator and discriminator, as present in\ncompetitive gradient descent (CGD), can significantly strengthen ICR and thus\nstabilize GAN training without explicit regularization. In our experiments, we\nuse an existing implementation of WGAN-GP and show that by training it with CGD\nwe can improve the inception score (IS) on CIFAR10 for a wide range of\nscenarios, without any hyperparameter tuning. The highest IS is obtained by\ncombining CGD with the WGAN-loss, without any explicit regularization.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 22:39:23 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 17:57:42 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 22:25:31 GMT"}, {"version": "v4", "created": "Fri, 30 Oct 2020 19:08:22 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Sch\u00e4fer", "Florian", ""], ["Zheng", "Hongkai", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1910.05857", "submitter": "Haoran Sun", "authors": "Haoran Sun, Songtao Lu, Mingyi Hong", "title": "Improving the Sample and Communication Complexity for Decentralized\n  Non-Convex Optimization: A Joint Gradient Estimation and Tracking Approach", "comments": null, "journal-ref": "Published at the International Conference on Machine Learning\n  (ICML 2020)", "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern large-scale machine learning problems benefit from decentralized\nand stochastic optimization. Recent works have shown that utilizing both\ndecentralized computing and local stochastic gradient estimates can outperform\nstate-of-the-art centralized algorithms, in applications involving highly\nnon-convex problems, such as training deep neural networks.\n  In this work, we propose a decentralized stochastic algorithm to deal with\ncertain smooth non-convex problems where there are $m$ nodes in the system, and\neach node has a large number of samples (denoted as $n$). Differently from the\nmajority of the existing decentralized learning algorithms for either\nstochastic or finite-sum problems, our focus is given to both reducing the\ntotal communication rounds among the nodes, while accessing the minimum number\nof local data samples. In particular, we propose an algorithm named D-GET\n(decentralized gradient estimation and tracking), which jointly performs\ndecentralized gradient estimation (which estimates the local gradient using a\nsubset of local samples) and gradient tracking (which tracks the global full\ngradient using local estimates). We show that, to achieve certain $\\epsilon$\nstationary solution of the deterministic finite sum problem, the proposed\nalgorithm achieves an $\\mathcal{O}(mn^{1/2}\\epsilon^{-1})$ sample complexity\nand an $\\mathcal{O}(\\epsilon^{-1})$ communication complexity. These bounds\nsignificantly improve upon the best existing bounds of\n$\\mathcal{O}(mn\\epsilon^{-1})$ and $\\mathcal{O}(\\epsilon^{-1})$, respectively.\nSimilarly, for online problems, the proposed method achieves an $\\mathcal{O}(m\n\\epsilon^{-3/2})$ sample complexity and an $\\mathcal{O}(\\epsilon^{-1})$\ncommunication complexity, while the best existing bounds are\n$\\mathcal{O}(m\\epsilon^{-2})$ and $\\mathcal{O}(\\epsilon^{-2})$, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 22:57:33 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Sun", "Haoran", ""], ["Lu", "Songtao", ""], ["Hong", "Mingyi", ""]]}, {"id": "1910.05858", "submitter": "Ankur Mallick", "authors": "Ankur Mallick, Chaitanya Dwivedi, Bhavya Kailkhura, Gauri Joshi, T.\n  Yong-Jin Han", "title": "Deep Probabilistic Kernels for Sample-Efficient Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Processes (GPs) with an appropriate kernel are known to provide\naccurate predictions and uncertainty estimates even with very small amounts of\nlabeled data. However, GPs are generally unable to learn a good representation\nthat can encode intricate structures in high dimensional data. The\nrepresentation power of GPs depends heavily on kernel functions used to\nquantify the similarity between data points. Traditional GP kernels are not\nvery effective at capturing similarity between high dimensional data points,\nwhile methods that use deep neural networks to learn a kernel are not\nsample-efficient. To overcome these drawbacks, we propose deep probabilistic\nkernels which use a probabilistic neural network to map high-dimensional data\nto a probability distribution in a low dimensional subspace, and leverage the\nrich work on kernels between distributions to capture the similarity between\nthese distributions. Experiments on a variety of datasets show that building a\nGP using this covariance kernel solves the conflicting problems of\nrepresentation learning and sample efficiency. Our model can be extended beyond\nGPs to other small-data paradigms such as few-shot classification where we show\ncompetitive performance with state-of-the-art models on the mini-Imagenet\ndataset.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 23:10:33 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Mallick", "Ankur", ""], ["Dwivedi", "Chaitanya", ""], ["Kailkhura", "Bhavya", ""], ["Joshi", "Gauri", ""], ["Han", "T. Yong-Jin", ""]]}, {"id": "1910.05859", "submitter": "HanQin Cai", "authors": "HanQin Cai, Jian-Feng Cai, Tianming Wang, and Guojian Yin", "title": "Accelerated Structured Alternating Projections for Robust Spectrally\n  Sparse Signal Recovery", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, 69 (2021): 809-821", "doi": "10.1109/TSP.2021.3049618", "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a spectrally sparse signal $\\boldsymbol{x}$ that consists of $r$\ncomplex sinusoids with or without damping. We study the robust recovery problem\nfor the spectrally sparse signal under the fully observed setting, which is\nabout recovering $\\boldsymbol{x}$ and a sparse corruption vector\n$\\boldsymbol{s}$ from their sum $\\boldsymbol{z}=\\boldsymbol{x}+\\boldsymbol{s}$.\nIn this paper, we exploit the low-rank property of the Hankel matrix formed by\n$\\boldsymbol{x}$, and formulate the problem as the robust recovery of a\ncorrupted low-rank Hankel matrix. We develop a highly efficient non-convex\nalgorithm, coined Accelerated Structured Alternating Projections (ASAP). The\nhigh computational efficiency and low space complexity of ASAP are achieved by\nfast computations involving structured matrices, and a subspace projection\nmethod for accelerated low-rank approximation. Theoretical recovery guarantee\nwith a linear convergence rate has been established for ASAP, under some mild\nassumptions on $\\boldsymbol{x}$ and $\\boldsymbol{s}$. Empirical performance\ncomparisons on both synthetic and real-world data confirm the advantages of\nASAP, in terms of computational efficiency and robustness aspects.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 23:12:59 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 03:44:17 GMT"}, {"version": "v3", "created": "Sat, 16 Jan 2021 16:46:03 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Cai", "HanQin", ""], ["Cai", "Jian-Feng", ""], ["Wang", "Tianming", ""], ["Yin", "Guojian", ""]]}, {"id": "1910.05861", "submitter": "Haizhao Yang", "authors": "John Harlim and Shixiao W. Jiang and Senwei Liang and Haizhao Yang", "title": "Machine Learning for Prediction with Missing Dynamics", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109922", "report-no": null, "categories": "math.NA cs.LG cs.NA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a general framework for recovering missing dynamical\nsystems using available data and machine learning techniques. The proposed\nframework reformulates the prediction problem as a supervised learning problem\nto approximate a map that takes the memories of the resolved and identifiable\nunresolved variables to the missing components in the resolved dynamics. We\ndemonstrate the effectiveness of the proposed framework with a theoretical\nguarantee of a path-wise convergence of the resolved variables up to finite\ntime and numerical tests on prototypical models in various scientific domains.\nThese include the 57-mode barotropic stress models with multiscale interactions\nthat mimic the blocked and unblocked patterns observed in the atmosphere, the\nnonlinear Schr\\\"{o}dinger equation which found many applications in physics\nsuch as optics and Bose-Einstein-Condense, the Kuramoto-Sivashinsky equation\nwhich spatiotemporal chaotic pattern formation models trapped ion mode in\nplasma and phase dynamics in reaction-diffusion systems. While many machine\nlearning techniques can be used to validate the proposed framework, we found\nthat recurrent neural networks outperform kernel regression methods in terms of\nrecovering the trajectory of the resolved components and the equilibrium\none-point and two-point statistics. This superb performance suggests that\nrecurrent neural networks are an effective tool for recovering the missing\ndynamics that involves approximation of high-dimensional functions.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 23:19:08 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 20:09:27 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 18:01:24 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Harlim", "John", ""], ["Jiang", "Shixiao W.", ""], ["Liang", "Senwei", ""], ["Yang", "Haizhao", ""]]}, {"id": "1910.05862", "submitter": "Yuwei Wang", "authors": "Yuwei Wang, Yan Zheng, Yanqing Peng, Wei Zhang, Feifei Li", "title": "Feature Detection and Attenuation in Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding is one of the fundamental building blocks for data analysis tasks.\nAlthough most embedding schemes are designed to be domain-specific, they have\nbeen recently extended to represent various other research domains. However,\nthere are relatively few discussions on analyzing these generated embeddings,\nand removing undesired features from the embedding. In this paper, we first\npropose an innovative embedding analyzing method that quantitatively measures\nthe features in the embedding data. We then propose an unsupervised method to\nremove or alleviate undesired features in the embedding by applying Domain\nAdversarial Network (DAN). Our empirical results demonstrate that the proposed\nalgorithm has good performance on both industry and natural language processing\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 23:19:18 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Wang", "Yuwei", ""], ["Zheng", "Yan", ""], ["Peng", "Yanqing", ""], ["Zhang", "Wei", ""], ["Li", "Feifei", ""]]}, {"id": "1910.05863", "submitter": "Wei Xie", "authors": "Wei Xie, Yuan Yi, Hua Zheng", "title": "Global-Local Metamodel Assisted Two-Stage Optimization via Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To integrate strategic, tactical and operational decisions, the two-stage\noptimization has been widely used to guide dynamic decision making. In this\npaper, we study the two-stage stochastic programming for complex systems with\nunknown response estimated by simulation. We introduce the global-local\nmetamodel assisted two-stage optimization via simulation that can efficiently\nemploy the simulation resource to iteratively solve for the optimal first- and\nsecond-stage decisions. Specifically, at each visited first-stage decision, we\ndevelop a local metamodel to simultaneously solve a set of scenario-based\nsecond-stage optimization problems, which also allows us to estimate the\noptimality gap. Then, we construct a global metamodel accounting for the errors\ninduced by: (1) using a finite number of scenarios to approximate the expected\nfuture cost occurring in the planning horizon, (2) second-stage optimality gap,\nand (3) finite visited first-stage decisions. Assisted by the global-local\nmetamodel, we propose a new simulation optimization approach that can\nefficiently and iteratively search for the optimal first- and second-stage\ndecisions. Our framework can guarantee the convergence of optimal solution for\nthe discrete two-stage optimization with unknown objective, and the empirical\nstudy indicates that it achieves substantial efficiency and accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 23:29:09 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xie", "Wei", ""], ["Yi", "Yuan", ""], ["Zheng", "Hua", ""]]}, {"id": "1910.05865", "submitter": "Yifan Xu", "authors": "Yifan Xu, Lu Dai, Udaikaran Singh, Kening Zhang, Zhuowen Tu", "title": "Neural Program Synthesis By Self-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural inductive program synthesis is a task generating instructions that can\nproduce desired outputs from given inputs. In this paper, we focus on the\ngeneration of a chunk of assembly code that can be executed to match a state\nchange inside the CPU and RAM. We develop a neural program synthesis algorithm,\nAutoAssemblet, learned via self-learning reinforcement learning that explores\nthe large code space efficiently. Policy networks and value networks are\nlearned to reduce the breadth and depth of the Monte Carlo Tree Search,\nresulting in better synthesis performance. We also propose an effective\nmulti-entropy policy sampling technique to alleviate online update\ncorrelations. We apply AutoAssemblet to basic programming tasks and show\nsignificant higher success rates compared to several competing baselines.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 23:44:37 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xu", "Yifan", ""], ["Dai", "Lu", ""], ["Singh", "Udaikaran", ""], ["Zhang", "Kening", ""], ["Tu", "Zhuowen", ""]]}, {"id": "1910.05872", "submitter": "Hankook Lee", "authors": "Hankook Lee, Sung Ju Hwang, Jinwoo Shin", "title": "Self-supervised Label Augmentation via Input Transformations", "comments": "Accepted to ICML 2020. Code available at\n  https://github.com/hankook/SLA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning, which learns by constructing artificial labels\ngiven only the input signals, has recently gained considerable attention for\nlearning representations with unlabeled datasets, i.e., learning without any\nhuman-annotated supervision. In this paper, we show that such a technique can\nbe used to significantly improve the model accuracy even under fully-labeled\ndatasets. Our scheme trains the model to learn both original and\nself-supervised tasks, but is different from conventional multi-task learning\nframeworks that optimize the summation of their corresponding losses. Our main\nidea is to learn a single unified task with respect to the joint distribution\nof the original and self-supervised labels, i.e., we augment original labels\nvia self-supervision of input transformation. This simple, yet effective\napproach allows to train models easier by relaxing a certain invariant\nconstraint during learning the original and self-supervised tasks\nsimultaneously. It also enables an aggregated inference which combines the\npredictions from different augmentations to improve the prediction accuracy.\nFurthermore, we propose a novel knowledge transfer technique, which we refer to\nas self-distillation, that has the effect of the aggregated inference in a\nsingle (faster) inference. We demonstrate the large accuracy improvement and\nwide applicability of our framework on various fully-supervised settings, e.g.,\nthe few-shot and imbalanced classification scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 00:37:33 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 12:10:28 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Lee", "Hankook", ""], ["Hwang", "Sung Ju", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1910.05874", "submitter": "Yeonjong Shin", "authors": "Yeonjong Shin", "title": "Effects of Depth, Width, and Initialization: A Convergence Analysis of\n  Layer-wise Training for Deep Linear Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks have been used in various machine learning applications\nand achieved tremendous empirical successes. However, training deep neural\nnetworks is a challenging task. Many alternatives have been proposed in place\nof end-to-end back-propagation. Layer-wise training is one of them, which\ntrains a single layer at a time, rather than trains the whole layers\nsimultaneously. In this paper, we study a layer-wise training using a block\ncoordinate gradient descent (BCGD) for deep linear networks. We establish a\ngeneral convergence analysis of BCGD and found the optimal learning rate, which\nresults in the fastest decrease in the loss. More importantly, the optimal\nlearning rate can directly be applied in practice, as it does not require any\nprior knowledge. Thus, tuning the learning rate is not needed at all. Also, we\nidentify the effects of depth, width, and initialization in the training\nprocess. We show that when the orthogonal-like initialization is employed, the\nwidth of intermediate layers plays no role in gradient-based training, as long\nas the width is greater than or equal to both the input and output dimensions.\nWe show that under some conditions, the deeper the network is, the faster the\nconvergence is guaranteed. This implies that in an extreme case, the global\noptimum is achieved after updating each weight matrix only once. Besides, we\nfound that the use of deep networks could drastically accelerate convergence\nwhen it is compared to those of a depth 1 network, even when the computational\ncost is considered. Numerical examples are provided to justify our theoretical\nfindings and demonstrate the performance of layer-wise training by BCGD.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 00:50:55 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 21:21:37 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Shin", "Yeonjong", ""]]}, {"id": "1910.05876", "submitter": "Jonathan Lebensold", "authors": "Jonathan Lebensold, William Hamilton, Borja Balle, Doina Precup", "title": "Actor Critic with Differentially Private Critic", "comments": "6 Pages, Presented at the Privacy in Machine Learning Workshop,\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning algorithms are known to be sample inefficient, and\noften performance on one task can be substantially improved by leveraging\ninformation (e.g., via pre-training) on other related tasks. In this work, we\npropose a technique to achieve such knowledge transfer in cases where agent\ntrajectories contain sensitive or private information, such as in the\nhealthcare domain. Our approach leverages a differentially private policy\nevaluation algorithm to initialize an actor-critic model and improve the\neffectiveness of learning in downstream tasks. We empirically show this\ntechnique increases sample efficiency in resource-constrained control problems\nwhile preserving the privacy of trajectories collected in an upstream task.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 01:19:55 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Lebensold", "Jonathan", ""], ["Hamilton", "William", ""], ["Balle", "Borja", ""], ["Precup", "Doina", ""]]}, {"id": "1910.05877", "submitter": "Dimitrios Kollias", "authors": "Valentin Richer and Dimitrios Kollias", "title": "Interpretable Deep Neural Networks for Facial Expression and Dimensional\n  Emotion Recognition in-the-wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project, we created a database with two types of annotations used in\nthe emotion recognition domain : Action Units and Valence Arousal to try to\nachieve better results than with only one model. The originality of the\napproach is also based on the type of architecture used to perform the\nprediction of the emotions : a categorical Generative Adversarial Network. This\nkind of dual network can generate images based on the pictures from the new\ndataset thanks to its generative network and decide if an image is fake or real\nthanks to its discriminative network as well as help to predict the annotations\nfor Action Units and Valence Arousal due to its categorical nature. GANs were\ntrained on the Action Units model only, then the Valence Arousal model only and\nthen on both the Action Units model and Valence Arousal model in order to test\ndifferent parameters and understand their influence. The generative and\ndiscriminative aspects of the GANs have performed interesting results.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 01:33:06 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 23:17:07 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Richer", "Valentin", ""], ["Kollias", "Dimitrios", ""]]}, {"id": "1910.05878", "submitter": "Dongrui Wu", "authors": "Wen Zhang and Dongrui Wu", "title": "Manifold Embedded Knowledge Transfer for Brain-Computer Interfaces", "comments": null, "journal-ref": "IEEE Trans. on Neural Systems and Rehabilitation Engineering,\n  28(5), pp. 1117-1127, 2020", "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning makes use of data or knowledge in one problem to help solve\na different, yet related, problem. It is particularly useful in brain-computer\ninterfaces (BCIs), for coping with variations among different subjects and/or\ntasks. This paper considers offline unsupervised cross-subject\nelectroencephalogram (EEG) classification, i.e., we have labeled EEG trials\nfrom one or more source subjects, but only unlabeled EEG trials from the target\nsubject. We propose a novel manifold embedded knowledge transfer (MEKT)\napproach, which first aligns the covariance matrices of the EEG trials in the\nRiemannian manifold, extracts features in the tangent space, and then performs\ndomain adaptation by minimizing the joint probability distribution shift\nbetween the source and the target domains, while preserving their geometric\nstructures. MEKT can cope with one or multiple source domains, and can be\ncomputed efficiently. We also propose a domain transferability estimation (DTE)\napproach to identify the most beneficial source domains, in case there are a\nlarge number of source domains. Experiments on four EEG datasets from two\ndifferent BCI paradigms demonstrated that MEKT outperformed several\nstate-of-the-art transfer learning approaches, and DTE can reduce more than\nhalf of the computational cost when the number of source subjects is large,\nwith little sacrifice of classification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 01:33:33 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 19:38:50 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhang", "Wen", ""], ["Wu", "Dongrui", ""]]}, {"id": "1910.05885", "submitter": "Lucas A. Wilson", "authors": "Pei Yang, Srinivas Varadharajan, Lucas A. Wilson, Don D. Smith II,\n  John A Lockman III, Vineet Gundecha, Quy Ta", "title": "Parallelized Training of Restricted Boltzmann Machines using\n  Markov-Chain Monte Carlo Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machine (RBM) is a generative stochastic neural network\nthat can be applied to collaborative filtering technique used by recommendation\nsystems. Prediction accuracy of the RBM model is usually better than that of\nother models for recommendation systems. However, training the RBM model\ninvolves Markov-Chain Monte Carlo (MCMC) method, which is computationally\nexpensive. In this paper, we have successfully applied distributed parallel\ntraining using Horovod framework to improve the training time of the RBM model.\nOur tests show that the distributed training approach of the RBM model has a\ngood scaling efficiency. We also show that this approach effectively reduces\nthe training time to little over 12 minutes on 64 CPU nodes compared to 5 hours\non a single CPU node. This will make RBM models more practically applicable in\nrecommendation systems.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 01:50:57 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Yang", "Pei", ""], ["Varadharajan", "Srinivas", ""], ["Wilson", "Lucas A.", ""], ["Smith", "Don D.", "II"], ["Lockman", "John A", "III"], ["Gundecha", "Vineet", ""], ["Ta", "Quy", ""]]}, {"id": "1910.05895", "submitter": "Julian Salazar", "authors": "Toan Q. Nguyen and Julian Salazar", "title": "Transformers without Tears: Improving the Normalization of\n  Self-Attention", "comments": "Accepted to IWSLT 2019 (oral); code is available at\n  https://github.com/tnq177/transformers_without_tears", "journal-ref": null, "doi": "10.5281/zenodo.3525484", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate three simple, normalization-centric changes to improve\nTransformer training. First, we show that pre-norm residual connections\n(PreNorm) and smaller initializations enable warmup-free, validation-based\ntraining with large learning rates. Second, we propose $\\ell_2$ normalization\nwith a single scale parameter (ScaleNorm) for faster training and better\nperformance. Finally, we reaffirm the effectiveness of normalizing word\nembeddings to a fixed length (FixNorm). On five low-resource translation pairs\nfrom TED Talks-based corpora, these changes always converge, giving an average\n+1.1 BLEU over state-of-the-art bilingual baselines and a new 32.8 BLEU on\nIWSLT'15 English-Vietnamese. We observe sharper performance curves, more\nconsistent gradient norms, and a linear relationship between activation scaling\nand decoder depth. Surprisingly, in the high-resource setting (WMT'14\nEnglish-German), ScaleNorm and FixNorm remain competitive but PreNorm degrades\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 02:23:43 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 03:53:04 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Nguyen", "Toan Q.", ""], ["Salazar", "Julian", ""]]}, {"id": "1910.05897", "submitter": "Haichuan Yang", "authors": "Haichuan Yang, Shupeng Gui, Yuhao Zhu, Ji Liu", "title": "Automatic Neural Network Compression by Sparsity-Quantization Joint\n  Learning: A Constrained Optimization-based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are applied in a wide range of usecases. There is\nan increased demand for deploying DNNs on devices that do not have abundant\nresources such as memory and computation units. Recently, network compression\nthrough a variety of techniques such as pruning and quantization have been\nproposed to reduce the resource requirement. A key parameter that all existing\ncompression techniques are sensitive to is the compression ratio (e.g., pruning\nsparsity, quantization bitwidth) of each layer. Traditional solutions treat the\ncompression ratios of each layer as hyper-parameters, and tune them using human\nheuristic. Recent researchers start using black-box hyper-parameter\noptimizations, but they will introduce new hyper-parameters and have efficiency\nissue. In this paper, we propose a framework to jointly prune and quantize the\nDNNs automatically according to a target model size without using any\nhyper-parameters to manually set the compression ratio for each layer. In the\nexperiments, we show that our framework can compress the weights data of\nResNet-50 to be 836$\\times$ smaller without accuracy loss on CIFAR-10, and\ncompress AlexNet to be 205$\\times$ smaller without accuracy loss on ImageNet\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 03:00:58 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 15:29:24 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 17:14:44 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 07:07:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Yang", "Haichuan", ""], ["Gui", "Shupeng", ""], ["Zhu", "Yuhao", ""], ["Liu", "Ji", ""]]}, {"id": "1910.05898", "submitter": "Junxiang Chen", "authors": "Junxiang Chen, Kayhan Batmanghelich", "title": "Robust Ordinal VAE: Employing Noisy Pairwise Comparisons for\n  Disentanglement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work by Locatello et al. (2018) has shown that an inductive bias is\nrequired to disentangle factors of interest in Variational Autoencoder (VAE).\nMotivated by a real-world problem, we propose a setting where such bias is\nintroduced by providing pairwise ordinal comparisons between instances, based\non the desired factor to be disentangled. For example, a doctor compares pairs\nof patients based on the level of severity of their illnesses, and the desired\nfactor is a quantitive level of the disease severity. In a real-world\napplication, the pairwise comparisons are usually noisy. Our method, Robust\nOrdinal VAE (ROVAE), incorporates the noisy pairwise ordinal comparisons in the\ndisentanglement task. We introduce non-negative random variables in ROVAE, such\nthat it can automatically determine whether each pairwise ordinal comparison is\ntrustworthy and ignore the noisy comparisons. Experimental results demonstrate\nthat ROVAE outperforms existing methods and is more robust to noisy pairwise\ncomparisons in both benchmark datasets and a real-world application.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 03:01:46 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Chen", "Junxiang", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "1910.05905", "submitter": "Qianqian Xu", "authors": "Qianqian Xu, Xinwei Sun, Zhiyong Yang, Xiaochun Cao, Qingming Huang,\n  Yuan Yao", "title": "iSplit LBI: Individualized Partial Ranking with Ties via Split LBI", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the inherent uncertainty of data, the problem of predicting partial\nranking from pairwise comparison data with ties has attracted increasing\ninterest in recent years. However, in real-world scenarios, different\nindividuals often hold distinct preferences. It might be misleading to merely\nlook at a global partial ranking while ignoring personal diversity. In this\npaper, instead of learning a global ranking which is agreed with the consensus,\nwe pursue the tie-aware partial ranking from an individualized perspective.\nParticularly, we formulate a unified framework which not only can be used for\nindividualized partial ranking prediction, but also be helpful for abnormal\nuser selection. This is realized by a variable splitting-based algorithm called\n\\ilbi. Specifically, our algorithm generates a sequence of estimations with a\nregularization path, where both the hyperparameters and model parameters are\nupdated. At each step of the path, the parameters can be decomposed into three\northogonal parts, namely, abnormal signals, personalized signals and random\nnoise. The abnormal signals can serve the purpose of abnormal user selection,\nwhile the abnormal signals and personalized signals together are mainly\nresponsible for individual partial ranking prediction. Extensive experiments on\nsimulated and real-world datasets demonstrate that our new approach\nsignificantly outperforms state-of-the-art alternatives. The code is now\navailiable at https://github.com/qianqianxu010/NeurIPS2019-iSplitLBI.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 03:25:51 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xu", "Qianqian", ""], ["Sun", "Xinwei", ""], ["Yang", "Zhiyong", ""], ["Cao", "Xiaochun", ""], ["Huang", "Qingming", ""], ["Yao", "Yuan", ""]]}, {"id": "1910.05907", "submitter": "Changfu Li", "authors": "Changfu Li, Chenrui Jin, Ratnesh Sharma", "title": "Coordination of PV Smart Inverters Using Deep Reinforcement Learning for\n  Grid Voltage Regulation", "comments": "18th IEEE International Conference on Machine Learning and\n  Applications - ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing adoption of solar photovoltaic (PV) presents new challenges to\nmodern power grid due to its variable and intermittent nature. Fluctuating\noutputs from PV generation can cause the grid violating voltage operation\nlimits. PV smart inverters (SIs) provide a fast-response method to regulate\nvoltage by modulating real and/or reactive power at the connection point. Yet\nexisting local autonomous control scheme of SIs is based on local information\nwithout coordination, which can lead to suboptimal performance. In this paper,\na deep reinforcement learning (DRL) based algorithm is developed and\nimplemented for coordinating multiple SIs. The reward scheme of the DRL is\ncarefully designed to ensure voltage operation limits of the grid are met with\nmore effective utilization of SI reactive power. The proposed DRL agent for\nvoltage control can learn its policy through interaction with massive offline\nsimulations, and adapts to load and solar variations. The performance of the\nDRL agent is compared against the local autonomous control on the IEEE 37 node\nsystem with thousands of scenarios. The results show a properly trained DRL\nagent can intelligently coordinate different SIs for maintaining grid voltage\nwithin allowable ranges, achieving reduction of PV production curtailment, and\ndecreasing system losses.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 03:50:58 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Li", "Changfu", ""], ["Jin", "Chenrui", ""], ["Sharma", "Ratnesh", ""]]}, {"id": "1910.05917", "submitter": "Chase Kew", "authors": "J. Chase Kew, Brian Ichter, Maryam Bandari, Tsang-Wei Edward Lee,\n  Aleksandra Faust", "title": "Neural Collision Clearance Estimator for Batched Motion Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural network collision checking heuristic, ClearanceNet, and a\nplanning algorithm, CN-RRT. ClearanceNet learns to predict separation distance\n(minimum distance between robot and workspace) with respect to a workspace.\nCN-RRT then efficiently computes a motion plan by leveraging three key features\nof ClearanceNet. First, CN-RRT explores the space by expanding multiple nodes\nat the same time, processing batches of thousands of collision checks. Second,\nCN-RRT adaptively relaxes its clearance requirements for more difficult\nproblems. Third, to repair errors, CN-RRT shifts its nodes in the direction of\nClearanceNet's gradient and repairs any residual errors with a traditional RRT,\nthus maintaining theoretical probabilistic completeness guarantees. In\nconfiguration spaces with up to 30 degrees of freedom, ClearanceNet achieves\n845x speedup over traditional collision detection methods, while CN-RRT\naccelerates motion planning by up to 42% over a baseline and finds paths up to\n36% more efficient. Experiments on an 11 degree of freedom robot in a cluttered\nenvironment confirm the method's feasibility on real robots.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 05:36:51 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 02:36:49 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Kew", "J. Chase", ""], ["Ichter", "Brian", ""], ["Bandari", "Maryam", ""], ["Lee", "Tsang-Wei Edward", ""], ["Faust", "Aleksandra", ""]]}, {"id": "1910.05923", "submitter": "Bolin Wei", "authors": "Bolin Wei, Ge Li, Xin Xia, Zhiyi Fu, Zhi Jin", "title": "Code Generation as a Dual Task of Code Summarization", "comments": "To appear at the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code summarization (CS) and code generation (CG) are two crucial tasks in the\nfield of automatic software development. Various neural network-based\napproaches are proposed to solve these two tasks separately. However, there\nexists a specific intuitive correlation between CS and CG, which have not been\nexploited in previous work. In this paper, we apply the relations between two\ntasks to improve the performance of both tasks. In other words, exploiting the\nduality between the two tasks, we propose a dual training framework to train\nthe two tasks simultaneously. In this framework, we consider the dualities on\nprobability and attention weights, and design corresponding regularization\nterms to constrain the duality. We evaluate our approach on two datasets\ncollected from GitHub, and experimental results show that our dual framework\ncan improve the performance of CS and CG tasks over baselines.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 05:54:00 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Wei", "Bolin", ""], ["Li", "Ge", ""], ["Xia", "Xin", ""], ["Fu", "Zhiyi", ""], ["Jin", "Zhi", ""]]}, {"id": "1910.05927", "submitter": "Yuping Luo", "authors": "Kefan Dong, Yuping Luo, Tengyu Ma", "title": "On the Expressivity of Neural Networks for Deep Reinforcement Learning", "comments": "Accepted in ICML 2020. Title of previous version was \"Bootstrapping\n  the Expressivity with Model-based Planning\". Code is available at\n  https://github.com/roosephu/boots", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the model-free reinforcement learning with the model-based\napproaches through the lens of the expressive power of neural networks for\npolicies, $Q$-functions, and dynamics. We show, theoretically and empirically,\nthat even for one-dimensional continuous state space, there are many MDPs whose\noptimal $Q$-functions and policies are much more complex than the dynamics. We\nhypothesize many real-world MDPs also have a similar property. For these MDPs,\nmodel-based planning is a favorable algorithm, because the resulting policies\ncan approximate the optimal policy significantly better than a neural network\nparameterization can, and model-free or model-based policy optimization rely on\npolicy parameterization. Motivated by the theory, we apply a simple multi-step\nmodel-based bootstrapping planner (BOOTS) to bootstrap a weak $Q$-function into\na stronger policy. Empirical results show that applying BOOTS on top of\nmodel-based or model-free policy optimization algorithms at the test time\nimproves the performance on MuJoCo benchmark tasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 06:17:49 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 01:07:35 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 12:15:54 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Dong", "Kefan", ""], ["Luo", "Yuping", ""], ["Ma", "Tengyu", ""]]}, {"id": "1910.05929", "submitter": "Stanislav Fort", "authors": "Stanislav Fort, Surya Ganguli", "title": "Emergent properties of the local geometry of neural loss landscapes", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The local geometry of high dimensional neural network loss landscapes can\nboth challenge our cherished theoretical intuitions as well as dramatically\nimpact the practical success of neural network training. Indeed recent works\nhave observed 4 striking local properties of neural loss landscapes on\nclassification tasks: (1) the landscape exhibits exactly $C$ directions of high\npositive curvature, where $C$ is the number of classes; (2) gradient directions\nare largely confined to this extremely low dimensional subspace of positive\nHessian curvature, leaving the vast majority of directions in weight space\nunexplored; (3) gradient descent transiently explores intermediate regions of\nhigher positive curvature before eventually finding flatter minima; (4)\ntraining can be successful even when confined to low dimensional {\\it random}\naffine hyperplanes, as long as these hyperplanes intersect a Goldilocks zone of\nhigher than average curvature. We develop a simple theoretical model of\ngradients and Hessians, justified by numerical experiments on architectures and\ndatasets used in practice, that {\\it simultaneously} accounts for all $4$ of\nthese surprising and seemingly unrelated properties. Our unified model provides\nconceptual insights into the emergence of these properties and makes\nconnections with diverse topics in neural networks, random matrix theory, and\nspin glasses, including the neural tangent kernel, BBP phase transitions, and\nDerrida's random energy model.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 06:23:38 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Fort", "Stanislav", ""], ["Ganguli", "Surya", ""]]}, {"id": "1910.05930", "submitter": "Guoping Long", "authors": "Mengdi Wang, Chen Meng, Guoping Long, Chuan Wu, Jun Yang, Wei Lin,\n  Yangqing Jia", "title": "Characterizing Deep Learning Training Workloads on Alibaba-PAI", "comments": "Accepted by IISWC2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning models have been exploited in various domains, including\ncomputer vision (CV), natural language processing (NLP), search and\nrecommendation. In practical AI clusters, workloads training these models are\nrun using software frameworks such as TensorFlow, Caffe, PyTorch and CNTK. One\ncritical issue for efficiently operating practical AI clouds, is to\ncharacterize the computing and data transfer demands of these workloads, and\nmore importantly, the training performance given the underlying software\nframework and hardware configurations. In this paper, we characterize deep\nlearning training workloads from Platform of Artificial Intelligence (PAI) in\nAlibaba. We establish an analytical framework to investigate detailed execution\ntime breakdown of various workloads using different training architectures, to\nidentify performance bottleneck. Results show that weight/gradient\ncommunication during training takes almost 62% of the total execution time\namong all our workloads on average. The computation part, involving both GPU\ncomputing and memory access, are not the biggest bottleneck based on collective\nbehavior of the workloads. We further evaluate attainable performance of the\nworkloads on various potential software/hardware mappings, and explore\nimplications on software architecture selection and hardware configurations. We\nidentify that 60% of PS/Worker workloads can be potentially sped up when ported\nto the AllReduce architecture exploiting the high-speed NVLink for GPU\ninterconnect, and on average 1.7X speedup can be achieved when Ethernet\nbandwidth is upgraded from 25 Gbps to 100 Gbps.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 06:26:01 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Wang", "Mengdi", ""], ["Meng", "Chen", ""], ["Long", "Guoping", ""], ["Wu", "Chuan", ""], ["Yang", "Jun", ""], ["Lin", "Wei", ""], ["Jia", "Yangqing", ""]]}, {"id": "1910.05933", "submitter": "Ali Hassani", "authors": "Ali Hassani, Amir Iranmanesh, Mahdi Eftekhari, Abbas Salemi", "title": "DISCERN: Diversity-based Selection of Centroids for k-Estimation and\n  Rapid Non-stochastic Clustering", "comments": "Int. J. Mach. Learn. & Cyber. (2020)", "journal-ref": null, "doi": "10.1007/s13042-020-01193-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the applications of center-based clustering algorithms such as K-Means\nis partitioning data points into K clusters. In some examples, the feature\nspace relates to the underlying problem we are trying to solve, and sometimes\nwe can obtain a suitable feature space. Nevertheless, while K-Means is one of\nthe most efficient offline clustering algorithms, it is not equipped to\nestimate the number of clusters, which is useful in some practical cases. Other\npractical methods which do are simply too complex, as they require at least one\nrun of K-Means for each possible K. In order to address this issue, we propose\na K-Means initialization similar to K-Means++, which would be able to estimate\nK based on the feature space while finding suitable initial centroids for\nK-Means in a deterministic manner. Then we compare the proposed method,\nDISCERN, with a few of the most practical K estimation methods, while also\ncomparing clustering results of K-Means when initialized randomly, using\nK-Means++ and using DISCERN. The results show improvement in both the\nestimation and final clustering performance.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 06:45:41 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 19:58:57 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 07:13:15 GMT"}, {"version": "v4", "created": "Thu, 13 Aug 2020 04:41:16 GMT"}, {"version": "v5", "created": "Tue, 22 Sep 2020 06:32:51 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Hassani", "Ali", ""], ["Iranmanesh", "Amir", ""], ["Eftekhari", "Mahdi", ""], ["Salemi", "Abbas", ""]]}, {"id": "1910.05954", "submitter": "Quentin M\\'erigot", "authors": "Quentin M\\'erigot, Alex Delalande, Fr\\'ed\\'eric Chazal", "title": "Quantitative stability of optimal transport maps and linearization of\n  the 2-Wasserstein space", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.MG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies an explicit embedding of the set of probability measures\ninto a Hilbert space, defined using optimal transport maps from a reference\nprobability density. This embedding linearizes to some extent the 2-Wasserstein\nspace, and enables the direct use of generic supervised and unsupervised\nlearning algorithms on measure data. Our main result is that the embedding is\n(bi-)H\\\"older continuous, when the reference density is uniform over a convex\nset, and can be equivalently phrased as a dimension-independent\nH\\\"older-stability results for optimal transport maps.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 07:24:37 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["M\u00e9rigot", "Quentin", ""], ["Delalande", "Alex", ""], ["Chazal", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1910.05964", "submitter": "Riikka Huusari", "authors": "Riikka Huusari, C\\'ecile Capponi, Paul Villoutreix, Hachem Kadri", "title": "Kernel transfer over multiple views for missing data completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the kernel completion problem with the presence of multiple views\nin the data. In this context the data samples can be fully missing in some\nviews, creating missing columns and rows to the kernel matrices that are\ncalculated individually for each view. We propose to solve the problem of\ncompleting the kernel matrices by transferring the features of the other views\nto represent the view under consideration. We align the known part of the\nkernel matrix with a new kernel built from the features of the other views. We\nare thus able to find generalizable structures in the kernel under completion,\nand represent it accurately. Its missing values can be predicted with the data\navailable in other views. We illustrate the benefits of our approach with\nsimulated data and multivariate digits dataset, as well as with real biological\ndatasets from studies of pattern formation in early \\textit{Drosophila\nmelanogaster} embryogenesis.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 07:45:12 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Huusari", "Riikka", ""], ["Capponi", "C\u00e9cile", ""], ["Villoutreix", "Paul", ""], ["Kadri", "Hachem", ""]]}, {"id": "1910.05983", "submitter": "Mohammed Sabry", "authors": "Mohammed Sabry and Amr M. A. Khalifa", "title": "On the Reduction of Variance and Overestimation of Deep Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The breakthrough of deep Q-Learning on different types of environments\nrevolutionized the algorithmic design of Reinforcement Learning to introduce\nmore stable and robust algorithms, to that end many extensions to deep\nQ-Learning algorithm have been proposed to reduce the variance of the target\nvalues and the overestimation phenomena. In this paper, we examine new\nmethodology to solve these issues, we propose using Dropout techniques on deep\nQ-Learning algorithm as a way to reduce variance and overestimation. We further\npresent experiments on some of the benchmark environments that demonstrate\nsignificant improvement of the stability of the performance and a reduction in\nvariance and overestimation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 08:43:06 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Sabry", "Mohammed", ""], ["Khalifa", "Amr M. A.", ""]]}, {"id": "1910.05992", "submitter": "Ryo Karakida", "authors": "Ryo Karakida, Shotaro Akaho, Shun-ichi Amari", "title": "Pathological spectra of the Fisher information metric and its variants\n  in deep neural networks", "comments": "23 pages, 7 figures; v2: minor improvements, Section 3.4 added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fisher information matrix (FIM) plays an essential role in statistics and\nmachine learning as a Riemannian metric tensor or a component of the Hessian\nmatrix of loss functions. Focusing on the FIM and its variants in deep neural\nnetworks (DNNs), we reveal their characteristic scale dependence on the network\nwidth, depth and sample size when the network has random weights and is\nsufficiently wide. This study covers two widely-used FIMs for regression with\nlinear output and for classification with softmax output. Both FIMs\nasymptotically show pathological eigenvalue spectra in the sense that a small\nnumber of eigenvalues become large outliers depending the width or sample size\nwhile the others are much smaller. It implies that the local shape of the\nparameter space or loss landscape is very sharp in a few specific directions\nwhile almost flat in the other directions. In particular, the softmax output\ndisperses the outliers and makes a tail of the eigenvalue density spread from\nthe bulk. We also show that pathological spectra appear in other variants of\nFIMs: one is the neural tangent kernel; another is a metric for the input\nsignal and feature space that arises from feedforward signal propagation. Thus,\nwe provide a unified perspective on the FIM and its variants that will lead to\nmore quantitative understanding of learning in large-scale DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 08:54:56 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 08:31:59 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Karakida", "Ryo", ""], ["Akaho", "Shotaro", ""], ["Amari", "Shun-ichi", ""]]}, {"id": "1910.06000", "submitter": "Lifu Wang", "authors": "Lifu Wang, Bo Shen, Ning Zhao", "title": "Second-Order Convergence of Asynchronous Parallel Stochastic Gradient\n  Descent: When Is the Linear Speedup Achieved?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, asynchronous parallel stochastic gradient descent\n(APSGD) is broadly used to speed up the training process through multi-workers.\nMeanwhile, the time delay of stale gradients in asynchronous algorithms is\ngenerally proportional to the total number of workers, which brings additional\ndeviation from the accurate gradient due to using delayed gradients. This may\nhave a negative influence on the convergence of the algorithm. One may ask: How\nmany workers can we use at most to achieve a good convergence and the linear\nspeedup?\n  In this paper, we consider the second-order convergence of asynchronous\nalgorithms in non-convex optimization. We investigate the behaviors of APSGD\nwith consistent read near strictly saddle points and provide a theoretical\nguarantee that if the total number of workers is bounded by\n$\\widetilde{O}(K^{1/3}M^{-1/3})$ ($K$ is the total steps and $M$ is the\nmini-batch size), APSGD will converge to good stationary points ($||\\nabla\nf(x)||\\leq \\epsilon, \\nabla^2 f(x)\\succeq -\\sqrt{\\epsilon}\\bm{I},\n\\epsilon^2\\leq O(\\sqrt{\\frac{1}{MK}}) $) and the linear speedup is achieved.\nOur works give the first theoretical guarantee on the second-order convergence\nfor asynchronous algorithms. The technique we provide can be generalized to\nanalyze other types of asynchronous algorithms to understand the behaviors of\nasynchronous algorithms in distributed asynchronous parallel training.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 09:14:55 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 07:52:21 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2019 13:42:14 GMT"}, {"version": "v4", "created": "Thu, 28 May 2020 06:15:42 GMT"}, {"version": "v5", "created": "Sun, 31 May 2020 12:37:39 GMT"}, {"version": "v6", "created": "Sun, 7 Jun 2020 17:23:20 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Wang", "Lifu", ""], ["Shen", "Bo", ""], ["Zhao", "Ning", ""]]}, {"id": "1910.06001", "submitter": "Xinle Liang", "authors": "Xinle Liang, Yang Liu, Tianjian Chen, Ming Liu and Qiang Yang", "title": "Federated Transfer Reinforcement Learning for Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is widely used in autonomous driving tasks and\ntraining RL models typically involves in a multi-step process: pre-training RL\nmodels on simulators, uploading the pre-trained model to real-life robots, and\nfine-tuning the weight parameters on robot vehicles. This sequential process is\nextremely time-consuming and more importantly, knowledge from the fine-tuned\nmodel stays local and can not be re-used or leveraged collaboratively. To\ntackle this problem, we present an online federated RL transfer process for\nreal-time knowledge extraction where all the participant agents make\ncorresponding actions with the knowledge learned by others, even when they are\nacting in very different environments. To validate the effectiveness of the\nproposed approach, we constructed a real-life collision avoidance system with\nMicrosoft Airsim simulator and NVIDIA JetsonTX2 car agents, which cooperatively\nlearn from scratch to avoid collisions in indoor environment with obstacle\nobjects. We demonstrate that with the proposed framework, the simulator car\nagents can transfer knowledge to the RC cars in real-time, with 27% increase in\nthe average distance with obstacles and 42% decrease in the collision counts.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 09:15:31 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Liang", "Xinle", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""], ["Liu", "Ming", ""], ["Yang", "Qiang", ""]]}, {"id": "1910.06002", "submitter": "Kaito Ariu", "authors": "Kaito Ariu, Jungseul Ok, Alexandre Proutiere, Se-Young Yun", "title": "Optimal Clustering from Noisy Binary Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of solving large-scale labeling tasks with minimal\neffort put on the users. Examples of such tasks include those in some of the\nrecent CAPTCHA systems, where users clicks (binary answers) constitute the only\ndata available to label images. Specifically, we study the generic problem of\nclustering a set of items from binary user feedback. Items are grouped into\ninitially unknown non-overlapping clusters. To recover these clusters, the\nlearner sequentially presents to users a finite list of items together with a\nquestion with a binary answer selected from a fixed finite set. For each of\nthese items, the user provides a noisy answer whose expectation is determined\nby the item cluster and the question and by an item-specific parameter\ncharacterizing the {\\it hardness} of classifying the item. The objective is to\ndevise an algorithm with a minimal cluster recovery error rate. We derive\nproblem-specific information-theoretical lower bounds on the error rate\nsatisfied by any algorithm, for both uniform and adaptive (list, question)\nselection strategies. For uniform selection, we present a simple algorithm\nbuilt upon the K-means algorithm and whose performance almost matches the\nfundamental limits. For adaptive selection, we develop an adaptive algorithm\nthat is inspired by the derivation of the information-theoretical error lower\nbounds, and in turn allocates the budget in an efficient way. The algorithm\nlearns to select items hard to cluster and relevant questions more often. We\ncompare the performance of our algorithms with or without the adaptive\nselection strategy numerically and illustrate the gain achieved by being\nadaptive.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 09:18:26 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 03:01:01 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ariu", "Kaito", ""], ["Ok", "Jungseul", ""], ["Proutiere", "Alexandre", ""], ["Yun", "Se-Young", ""]]}, {"id": "1910.06031", "submitter": "Ali Ghadirzadeh", "authors": "Judith B\\\"utepage, Ali Ghadirzadeh, \\\"Ozge \\\"Oztimur Karada\\~g,\n  M{\\aa}rten Bj\\\"orkman and Danica Kragic", "title": "Imitating by generating: deep generative models for imitation of\n  interactive tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To coordinate actions with an interaction partner requires a constant\nexchange of sensorimotor signals. Humans acquire these skills in infancy and\nearly childhood mostly by imitation learning and active engagement with a\nskilled partner. They require the ability to predict and adapt to one's partner\nduring an interaction. In this work we want to explore these ideas in a\nhuman-robot interaction setting in which a robot is required to learn\ninteractive tasks from a combination of observational and kinesthetic learning.\nTo this end, we propose a deep learning framework consisting of a number of\ncomponents for (1) human and robot motion embedding, (2) motion prediction of\nthe human partner and (3) generation of robot joint trajectories matching the\nhuman motion. To test these ideas, we collect human-human interaction data and\nhuman-robot interaction data of four interactive tasks \"hand-shake\",\n\"hand-wave\", \"parachute fist-bump\" and \"rocket fist-bump\". We demonstrate\nexperimentally the importance of predictive and adaptive components as well as\nlow-level abstractions to successfully learn to imitate human behavior in\ninteractive social tasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 10:42:50 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["B\u00fctepage", "Judith", ""], ["Ghadirzadeh", "Ali", ""], ["Karadag", "\u00d6zge \u00d6ztimur", ""], ["Bj\u00f6rkman", "M\u00e5rten", ""], ["Kragic", "Danica", ""]]}, {"id": "1910.06036", "submitter": "Yifan Gao", "authors": "Jingjing Li, Yifan Gao, Lidong Bing, Irwin King, Michael R. Lyu", "title": "Improving Question Generation With to the Point Context", "comments": "EMNLP19, fix wordings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question generation (QG) is the task of generating a question from a\nreference sentence and a specified answer within the sentence. A major\nchallenge in QG is to identify answer-relevant context words to finish the\ndeclarative-to-interrogative sentence transformation. Existing\nsequence-to-sequence neural models achieve this goal by proximity-based answer\nposition encoding under the intuition that neighboring words of answers are of\nhigh possibility to be answer-relevant. However, such intuition may not apply\nto all cases especially for sentences with complex answer-relevant relations.\nConsequently, the performance of these models drops sharply when the relative\ndistance between the answer fragment and other non-stop sentence words that\nalso appear in the ground truth question increases. To address this issue, we\npropose a method to jointly model the unstructured sentence and the structured\nanswer-relevant relation (extracted from the sentence in advance) for question\ngeneration. Specifically, the structured answer-relevant relation acts as the\nto the point context and it thus naturally helps keep the generated question to\nthe point, while the unstructured sentence provides the full information.\nExtensive experiments show that to the point context helps our question\ngeneration model achieve significant improvements on several automatic\nevaluation metrics. Furthermore, our model is capable of generating diverse\nquestions for a sentence which conveys multiple relations of its answer\nfragment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 11:03:55 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 09:51:33 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Li", "Jingjing", ""], ["Gao", "Yifan", ""], ["Bing", "Lidong", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "1910.06044", "submitter": "Lixu Wang", "authors": "Lixu Wang, Shichao Xu, Xiao Wang, Qi Zhu", "title": "Eavesdrop the Composition Proportion of Training Labels in Federated\n  Learning", "comments": "15 pages, 10 figures, security conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) has recently emerged as a new form of collaborative\nmachine learning, where a common model can be learned while keeping all the\ntraining data on local devices. Although it is designed for enhancing the data\nprivacy, we demonstrated in this paper a new direction in inference attacks in\nthe context of FL, where valuable information about training data can be\nobtained by adversaries with very limited power. In particular, we proposed\nthree new types of attacks to exploit this vulnerability. The first type of\nattack, Class Sniffing, can detect whether a certain label appears in training.\nThe other two types of attacks can determine the quantity of each label, i.e.,\nQuantity Inference attack determines the composition proportion of the training\nlabel owned by the selected clients in a single round, while Whole\nDetermination attack determines that of the whole training process. We\nevaluated our attacks on a variety of tasks and datasets with different\nsettings, and the corresponding results showed that our attacks work well\ngenerally. Finally, we analyzed the impact of major hyper-parameters to our\nattacks and discussed possible defenses.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 11:26:10 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 03:21:25 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wang", "Lixu", ""], ["Xu", "Shichao", ""], ["Wang", "Xiao", ""], ["Zhu", "Qi", ""]]}, {"id": "1910.06048", "submitter": "Kashyap Popat", "authors": "Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, Gerhard Weikum", "title": "STANCY: Stance Classification Based on Consistency Cues", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controversial claims are abundant in online media and discussion forums. A\nbetter understanding of such claims requires analyzing them from different\nperspectives. Stance classification is a necessary step for inferring these\nperspectives in terms of supporting or opposing the claim. In this work, we\npresent a neural network model for stance classification leveraging BERT\nrepresentations and augmenting them with a novel consistency constraint.\nExperiments on the Perspectrum dataset, consisting of claims and users'\nperspectives from various debate websites, demonstrate the effectiveness of our\napproach over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 11:39:45 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Popat", "Kashyap", ""], ["Mukherjee", "Subhabrata", ""], ["Yates", "Andrew", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1910.06054", "submitter": "Julian Zimmert", "authors": "Julian Zimmert and Yevgeny Seldin", "title": "An Optimal Algorithm for Adversarial Bandits with Arbitrary Delays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm for adversarial multi-armed bandits with\nunrestricted delays. The algorithm is based on a novel hybrid regularizer\napplied in the Follow the Regularized Leader (FTRL) framework. It achieves\n$\\mathcal{O}(\\sqrt{kn}+\\sqrt{D\\log(k)})$ regret guarantee, where $k$ is the\nnumber of arms, $n$ is the number of rounds, and $D$ is the total delay. The\nresult matches the lower bound within constants and requires no prior knowledge\nof $n$ or $D$. Additionally, we propose a refined tuning of the algorithm,\nwhich achieves $\\mathcal{O}(\\sqrt{kn}+\\min_{S}|S|+\\sqrt{D_{\\bar S}\\log(k)})$\nregret guarantee, where $S$ is a set of rounds excluded from delay counting,\n$\\bar S = [n]\\setminus S$ are the counted rounds, and $D_{\\bar S}$ is the total\ndelay in the counted rounds. If the delays are highly unbalanced, the latter\nregret guarantee can be significantly tighter than the former. The result\nrequires no advance knowledge of the delays and resolves an open problem of\nThune et al. (2019). The new FTRL algorithm and its refined tuning are anytime\nand require no doubling, which resolves another open problem of Thune et al.\n(2019).\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 11:48:21 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 09:20:20 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Zimmert", "Julian", ""], ["Seldin", "Yevgeny", ""]]}, {"id": "1910.06061", "submitter": "Lukas Lange", "authors": "Lukas Lange, Michael A. Hedderich, Dietrich Klakow", "title": "Feature-Dependent Confusion Matrices for Low-Resource NER Labeling with\n  Noisy Labels", "comments": "Published at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In low-resource settings, the performance of supervised labeling models can\nbe improved with automatically annotated or distantly supervised data, which is\ncheap to create but often noisy. Previous works have shown that significant\nimprovements can be reached by injecting information about the confusion\nbetween clean and noisy labels in this additional training data into the\nclassifier training. However, for noise estimation, these approaches either do\nnot take the input features (in our case word embeddings) into account, or they\nneed to learn the noise modeling from scratch which can be difficult in a\nlow-resource setting. We propose to cluster the training data using the input\nfeatures and then compute different confusion matrices for each cluster. To the\nbest of our knowledge, our approach is the first to leverage feature-dependent\nnoise modeling with pre-initialized confusion matrices. We evaluate on\nlow-resource named entity recognition settings in several languages, showing\nthat our methods improve upon other confusion-matrix based methods by up to 9%.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 12:03:07 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 23:20:44 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Lange", "Lukas", ""], ["Hedderich", "Michael A.", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1910.06067", "submitter": "Puneesh Deora", "authors": "Puneesh Deora, Bhavya Vasudeva, Saumik Bhattacharya, Pyari Mohan\n  Pradhan", "title": "Structure Preserving Compressive Sensing MRI Reconstruction using\n  Generative Adversarial Networks", "comments": "Accepted in IEEE CVPR Workshop on NTIRE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive sensing magnetic resonance imaging (CS-MRI) accelerates the\nacquisition of MR images by breaking the Nyquist sampling limit. In this work,\na novel generative adversarial network (GAN) based framework for CS-MRI\nreconstruction is proposed. Leveraging a combination of patch-based\ndiscriminator and structural similarity index based loss, our model focuses on\npreserving high frequency content as well as fine textural details in the\nreconstructed image. Dense and residual connections have been incorporated in a\nU-net based generator architecture to allow easier transfer of information as\nwell as variable network length. We show that our algorithm outperforms\nstate-of-the-art methods in terms of quality of reconstruction and robustness\nto noise. Also, the reconstruction time, which is of the order of milliseconds,\nmakes it highly suitable for real-time clinical use.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 12:08:48 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 09:50:15 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Deora", "Puneesh", ""], ["Vasudeva", "Bhavya", ""], ["Bhattacharya", "Saumik", ""], ["Pradhan", "Pyari Mohan", ""]]}, {"id": "1910.06070", "submitter": "Hao Zhou", "authors": "Hao Zhou, Jorge Laval, Anye Zhou, Yu Wang, Wenchao Wu, Zhu Qing and\n  Srinivas Peeta", "title": "Review of Learning-based Longitudinal Motion Planning for Autonomous\n  Vehicles: Research Gaps between Self-driving and Traffic Congestion", "comments": "submitted to presentation at TRB 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-driving technology companies and the research community are accelerating\ntheir pace to use machine learning longitudinal motion planning (mMP) for\nautonomous vehicles (AVs). This paper reviews the current state of the art in\nmMP, with an exclusive focus on its impact on traffic congestion. We identify\nthe availability of congestion scenarios in current datasets, and summarize the\nrequired features for training mMP. For learning methods, we survey the major\nmethods in both imitation learning and non-imitation learning. We also\nhighlight the emerging technologies adopted by some leading AV companies, e.g.\nTesla, Waymo, and Comma.ai. We find that: i) the AV industry has been mostly\nfocusing on the long tail problem related to safety and overlooked the impact\non traffic congestion, ii) the current public self-driving datasets have not\nincluded enough congestion scenarios, and mostly lack the necessary input\nfeatures/output labels to train mMP, and iii) albeit reinforcement learning\n(RL) approach can integrate congestion mitigation into the learning goal, the\nmajor mMP method adopted by industry is still behavior cloning (BC), whose\ncapability to learn a congestion-mitigating mMP remains to be seen. Based on\nthe review, the study identifies the research gaps in current mMP development.\nSome suggestions towards congestion mitigation for future mMP studies are\nproposed: i) enrich data collection to facilitate the congestion learning, ii)\nincorporate non-imitation learning methods to combine traffic efficiency into a\nsafety-oriented technical route, and iii) integrate domain knowledge from the\ntraditional car following (CF) theory to improve the string stability of mMP.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 19:19:48 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 15:37:49 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Zhou", "Hao", ""], ["Laval", "Jorge", ""], ["Zhou", "Anye", ""], ["Wang", "Yu", ""], ["Wu", "Wenchao", ""], ["Qing", "Zhu", ""], ["Peeta", "Srinivas", ""]]}, {"id": "1910.06079", "submitter": "Tomek Korbak", "authors": "Tomasz Korbak and Julian Zubek and {\\L}ukasz Kuci\\'nski and Piotr\n  Mi{\\l}o\\'s and Joanna R\\k{a}czaszek-Leonardi", "title": "Developmentally motivated emergence of compositional communication via\n  template transfer", "comments": "Accepted for NeurIPS 2019 workshop Emergent Communication: Towards\n  Natural Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a novel approach to achieving emergent compositional\ncommunication in multi-agent systems. We propose a training regime implementing\ntemplate transfer, the idea of carrying over learned biases across contexts. In\nour method, a sender-receiver pair is first trained with disentangled loss\nfunctions and then the receiver is transferred to train a new sender with a\nstandard loss. Unlike other methods (e.g. the obverter algorithm), our approach\ndoes not require imposing inductive biases on the architecture of the agents.\nWe experimentally show the emergence of compositional communication using\ntopographical similarity, zero-shot generalization and context independence as\nevaluation metrics. The presented approach is connected to an important line of\nwork in semiotics and developmental psycholinguistics: it supports a conjecture\nthat compositional communication is scaffolded on simpler communication\nprotocols.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:04:53 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Korbak", "Tomasz", ""], ["Zubek", "Julian", ""], ["Kuci\u0144ski", "\u0141ukasz", ""], ["Mi\u0142o\u015b", "Piotr", ""], ["R\u0105czaszek-Leonardi", "Joanna", ""]]}, {"id": "1910.06093", "submitter": "Jy-yong Sohn", "authors": "Jy-yong Sohn, Dong-Jun Han, Beongjun Choi and Jaekyun Moon", "title": "Election Coding for Distributed Learning: Protecting SignSGD against\n  Byzantine Attacks", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in large-scale distributed learning algorithms have enabled\ncommunication-efficient training via SignSGD. Unfortunately, a major issue\ncontinues to plague distributed learning: namely, Byzantine failures may incur\nserious degradation in learning accuracy. This paper proposes Election Coding,\na coding-theoretic framework to guarantee Byzantine-robustness for SignSGD with\nMajority Vote, which uses minimum worker-master communication in both\ndirections. The suggested framework explores new information-theoretic limits\nof finding the majority opinion when some workers could be malicious, and paves\nthe road to implement robust and efficient distributed learning algorithms.\nUnder this framework, we construct two types of explicit codes, random\nBernoulli codes and deterministic algebraic codes, that can tolerate Byzantine\nattacks with a controlled amount of computational redundancy. For the Bernoulli\ncodes, we provide upper bounds on the error probability in estimating the\nmajority opinion, which give useful insights into code design for tolerating\nByzantine attacks. As for deterministic codes, we construct an explicit code\nwhich perfectly tolerates Byzantines, and provide tight upper/lower bounds on\nthe minimum required computational redundancy. Finally, the Byzantine-tolerance\nof the suggested coding schemes is confirmed by deep learning experiments on\nAmazon EC2 using Python with MPI4py package.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 12:27:20 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 14:19:31 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 01:35:37 GMT"}, {"version": "v4", "created": "Sat, 24 Oct 2020 05:54:53 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Sohn", "Jy-yong", ""], ["Han", "Dong-Jun", ""], ["Choi", "Beongjun", ""], ["Moon", "Jaekyun", ""]]}, {"id": "1910.06100", "submitter": "Irfan Al-Hussaini", "authors": "Irfan Al-Hussaini, Cao Xiao, M. Brandon Westover, Jimeng Sun", "title": "SLEEPER: interpretable Sleep staging via Prototypes from Expert Rules", "comments": "Machine Learning for Healthcare Conference (MLHC) 2019. Proceedings\n  of Machine Learning Research 106", "journal-ref": "PMLR 106:721-739, 2019", "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep staging is a crucial task for diagnosing sleep disorders. It is tedious\nand complex as it can take a trained expert several hours to annotate just one\npatient's polysomnogram (PSG) from a single night. Although deep learning\nmodels have demonstrated state-of-the-art performance in automating sleep\nstaging, interpretability which defines other desiderata, has largely remained\nunexplored. In this study, we propose Sleep staging via Prototypes from Expert\nRules (SLEEPER), which combines deep learning models with expert defined rules\nusing a prototype learning framework to generate simple interpretable models.\nIn particular, SLEEPER utilizes sleep scoring rules and expert defined features\nto derive prototypes which are embeddings of PSG data fragments via\nconvolutional neural networks. The final models are simple interpretable models\nlike a shallow decision tree defined over those phenotypes. We evaluated\nSLEEPER using two PSG datasets collected from sleep studies and demonstrated\nthat SLEEPER could provide accurate sleep stage classification comparable to\nhuman experts and deep neural networks with about 85% ROC-AUC and .7 kappa.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 12:37:38 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Al-Hussaini", "Irfan", ""], ["Xiao", "Cao", ""], ["Westover", "M. Brandon", ""], ["Sun", "Jimeng", ""]]}, {"id": "1910.06109", "submitter": "Asif Imran", "authors": "Asif Imran, Tevfik Kosar", "title": "Software Sustainability: A Systematic Literature Review and\n  Comprehensive Analysis", "comments": "none", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software Engineering is a constantly evolving subject area that faces new\nchallenges every day as it tries to automate newer business processes. One of\nthe key challenges to the success of a software solution is attaining\nsustainability. The inability of numerous software to sustain for the desired\ntime-length is caused by limited consideration given towards sustainability\nduring the stages of software development. This review aims to present a\ndetailed and inclusive study covering both the technical and non-technical\nchallenges and approaches of software sustainability. A systematic and\ncomprehensive literature review was conducted based on 107 relevant studies\nthat were selected using the Evidence-Based Software Engineering (EBSE)\ntechnique. The study showed that sustainability can be achieved by conducting\nspecific activities at the technical and non-technical levels. The technical\nlevel consists of software design, coding, and user experience attributes. The\nnon-technical level consists of documentation, sustainability manifestos,\ntraining of software engineers, funding software projects, and leadership\nskills of project managers to achieve sustainability. This paper groups the\nexisting research efforts based on the above aspects. Next, how those aspects\naffect open and closed source software is tabulated. Based on the findings of\nthis review, it is seen that both technical and non-technical sustainability\naspects are equally important, taking one into contention and ignoring the\nother will threaten the sustenance of software products.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 00:54:13 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Imran", "Asif", ""], ["Kosar", "Tevfik", ""]]}, {"id": "1910.06121", "submitter": "Marko J\\\"arvenp\\\"a\\\"a", "authors": "Marko J\\\"arvenp\\\"a\\\"a, Aki Vehtari, Pekka Marttinen", "title": "Batch simulations and uncertainty quantification in Gaussian process\n  surrogate approximate Bayesian computation", "comments": "Minor improvements and clarifications to the text over the previous\n  version. 20 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational efficiency of approximate Bayesian computation (ABC) has\nbeen improved by using surrogate models such as Gaussian processes (GP). In one\nsuch promising framework the discrepancy between the simulated and observed\ndata is modelled with a GP which is further used to form a model-based\nestimator for the intractable posterior. In this article we improve this\napproach in several ways. We develop batch-sequential Bayesian experimental\ndesign strategies to parallellise the expensive simulations. In earlier work\nonly sequential strategies have been used. Current surrogate-based ABC methods\nalso do not fully account the uncertainty due to the limited budget of\nsimulations as they output only a point estimate of the ABC posterior. We\npropose a numerical method to fully quantify the uncertainty in, for example,\nABC posterior moments. We also provide some new analysis on the GP modelling\nassumptions in the resulting improved framework called Bayesian ABC and discuss\nits connection to Bayesian quadrature (BQ) and Bayesian optimisation (BO).\nExperiments with toy and real-world simulation models demonstrate advantages of\nthe proposed techniques.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 13:01:32 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 12:35:02 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 12:46:52 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["J\u00e4rvenp\u00e4\u00e4", "Marko", ""], ["Vehtari", "Aki", ""], ["Marttinen", "Pekka", ""]]}, {"id": "1910.06134", "submitter": "Jen Ning Lim", "authors": "Jen Ning Lim, Makoto Yamada, Wittawat Jitkrittum, Yoshikazu Terada,\n  Shigeyuki Matsui, Hidetoshi Shimodaira", "title": "More Powerful Selective Kernel Tests for Feature Selection", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Refining one's hypotheses in the light of data is a common scientific\npractice; however, the dependency on the data introduces selection bias and can\nlead to specious statistical analysis. An approach for addressing this is via\nconditioning on the selection procedure to account for how we have used the\ndata to generate our hypotheses, and prevent information to be used again after\nselection. Many selective inference (a.k.a. post-selection inference)\nalgorithms typically take this approach but will \"over-condition\" for sake of\ntractability. While this practice yields well calibrated statistic tests with\ncontrolled false positive rates (FPR), it can incur a major loss in power. In\nour work, we extend two recent proposals for selecting features using the\nMaximum Mean Discrepancy and Hilbert Schmidt Independence Criterion to\ncondition on the minimal conditioning event. We show how recent advances in\nmultiscale bootstrap makes conditioning on the minimal selection event possible\nand demonstrate our proposal over a range of synthetic and real world\nexperiments. Our results show that our proposed test is indeed more powerful in\nmost scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 13:28:22 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 12:05:58 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lim", "Jen Ning", ""], ["Yamada", "Makoto", ""], ["Jitkrittum", "Wittawat", ""], ["Terada", "Yoshikazu", ""], ["Matsui", "Shigeyuki", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "1910.06136", "submitter": "Grace Lewis", "authors": "Grace A. Lewis, Stephany Bellomo, and April Galyardt", "title": "Component Mismatches Are a Critical Bottleneck to Fielding AI-Enabled\n  Systems in the Public Sector", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The use of machine learning or artificial intelligence (ML/AI) holds\nsubstantial potential toward improving many functions and needs of the public\nsector. In practice however, integrating ML/AI components into public sector\napplications is severely limited not only by the fragility of these components\nand their algorithms, but also because of mismatches between components of\nML-enabled systems. For example, if an ML model is trained on data that is\ndifferent from data in the operational environment, field performance of the ML\ncomponent will be dramatically reduced. Separate from software engineering\nconsiderations, the expertise needed to field an ML/AI component within a\nsystem frequently comes from outside software engineering. As a result,\nassumptions and even descriptive language used by practitioners from these\ndifferent disciplines can exacerbate other challenges to integrating ML/AI\ncomponents into larger systems. We are investigating classes of mismatches in\nML/AI systems integration, to identify the implicit assumptions made by\npractitioners in different fields (data scientists, software engineers,\noperations staff) and find ways to communicate the appropriate information\nexplicitly. We will discuss a few categories of mismatch, and provide examples\nfrom each class. To enable ML/AI components to be fielded in a meaningful way,\nwe will need to understand the mismatches that exist and develop practices to\nmitigate the impacts of these mismatches.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 13:35:24 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Lewis", "Grace A.", ""], ["Bellomo", "Stephany", ""], ["Galyardt", "April", ""]]}, {"id": "1910.06149", "submitter": "Yujia Ding", "authors": "Yujia Ding and Weiqing Gu", "title": "Accelerometer-Based Gait Segmentation: Simultaneously User and Adversary\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new gait segmentation method based on\naccelerometer data and develop a new distance function between two time series,\nshowing novel and effectiveness in simultaneously identifying user and\nadversary. Comparing with the normally used Neural Network methods, our\napproaches use geometric features to extract walking cycles more precisely and\nemploy a new similarity metric to conduct user-adversary identification. This\nnew technology for simultaneously identify user and adversary contributes to\ncybersecurity beyond user-only identification. In particular, the new\ntechnology is being applied to cell phone recorded walking data and performs an\naccuracy of $98.79\\%$ for 6 classes classification (user-adversary\nidentification) and $99.06\\%$ for binary classification (user only\nidentification). In addition to walking signal, our approach works on walking\nup, walking down and mixed walking signals. This technology is feasible for\nboth large and small data set, overcoming the current challenges facing to\nNeural Networks such as tuning large number of hyper-parameters for large data\nsets and lacking of training data for small data sets. In addition, the new\ndistance function developed here can be applied in any signal analysis.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 06:45:30 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Ding", "Yujia", ""], ["Gu", "Weiqing", ""]]}, {"id": "1910.06151", "submitter": "Ewin Tang", "authors": "Nai-Hui Chia, Andr\\'as Gily\\'en, Tongyang Li, Han-Hsuan Lin, Ewin\n  Tang, Chunhao Wang", "title": "Sampling-based sublinear low-rank matrix arithmetic framework for\n  dequantizing quantum machine learning", "comments": "79 pages, 1 figure. revised to add more connection to QSVT, improve\n  existing results, and clarify exposition", "journal-ref": null, "doi": "10.1145/3357713.3384314", "report-no": null, "categories": "cs.DS cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithmic framework for quantum-inspired classical algorithms\non close-to-low-rank matrices, generalizing the series of results started by\nTang's breakthrough quantum-inspired algorithm for recommendation systems\n[STOC'19]. Motivated by quantum linear algebra algorithms and the quantum\nsingular value transformation (SVT) framework of Gily\\'en et al. [STOC'19], we\ndevelop classical algorithms for SVT that run in time independent of input\ndimension, under suitable quantum-inspired sampling assumptions. Our results\ngive compelling evidence that in the corresponding QRAM data structure input\nmodel, quantum SVT does not yield exponential quantum speedups. Since the\nquantum SVT framework generalizes essentially all known techniques for quantum\nlinear algebra, our results, combined with sampling lemmas from previous work,\nsuffice to generalize all recent results about dequantizing quantum machine\nlearning algorithms. In particular, our classical SVT framework recovers and\noften improves the dequantization results on recommendation systems, principal\ncomponent analysis, supervised clustering, support vector machines, low-rank\nregression, and semidefinite program solving. We also give additional\ndequantization results on low-rank Hamiltonian simulation and discriminant\nanalysis. Our improvements come from identifying the key feature of the\nquantum-inspired input model that is at the core of all prior quantum-inspired\nresults: $\\ell^2$-norm sampling can approximate matrix products in time\nindependent of their dimension. We reduce all our main results to this fact,\nmaking our exposition concise, self-contained, and intuitive.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 14:04:30 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 16:54:14 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Chia", "Nai-Hui", ""], ["Gily\u00e9n", "Andr\u00e1s", ""], ["Li", "Tongyang", ""], ["Lin", "Han-Hsuan", ""], ["Tang", "Ewin", ""], ["Wang", "Chunhao", ""]]}, {"id": "1910.06153", "submitter": "Ravinath Kausik", "authors": "Augustin Prado, Ravinath Kausik, Lalitha Venkataramanan", "title": "Dual Neural Network Architecture for Determining Epistemic and Aleatoric\n  Uncertainties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have been shown to be extremely effective for\nvarious classification and regression problems, but quantifying the uncertainty\nof their predictions and separating them into the epistemic and aleatoric\nfractions is still considered challenging. In oil and gas exploration projects,\ntools consisting of seismic, sonic, magnetic resonance, resistivity, dielectric\nand/or nuclear sensors are sent downhole through boreholes to probe the earth's\nrock and fluid properties. The measurements from these tools are used to build\nreservoir models that are subsequently used for estimation and optimization of\nhydrocarbon production. Machine learning algorithms are often used to estimate\nthe rock and fluid properties from the measured downhole data. Quantifying\nuncertainties of these properties is crucial for rock and fluid evaluation and\nsubsequent reservoir optimization and production decisions. These machine\nlearning algorithms are often trained on a \"ground-truth\" or core database.\nDuring the inference phase which involves application of these algorithms to\nfield data, it is critical that the machine learning algorithm flag data as out\nof distribution from new geologies that the model was not trained upon. It is\nalso highly important to be sensitive to heteroscedastic aleatoric noise in the\nfeature space arising from the combination of tool and geological conditions.\nUnderstanding the source of the uncertainty and reducing them is key to\ndesigning intelligent tools and applications such as automated log\ninterpretation answer products for exploration and field development. In this\npaper we describe a methodology consisting of a system of dual networks\ncomprising of the combination of a Bayesian Neural Network (BNN) and an\nArtificial Neural Network (ANN) addressing this challenge for geophysical\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 23:00:29 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Prado", "Augustin", ""], ["Kausik", "Ravinath", ""], ["Venkataramanan", "Lalitha", ""]]}, {"id": "1910.06156", "submitter": "Alessio Netti", "authors": "Alessio Netti, Micha Mueller, Carla Guillen, Michael Ott, Daniele\n  Tafani, Gence Ozer and Martin Schulz", "title": "DCDB Wintermute: Enabling Online and Holistic Operational Data Analytics\n  on HPC Systems", "comments": "Accepted for publication at the 29th ACM International Symposium on\n  High-Performance Parallel and Distributed Computing (HPDC 2020)", "journal-ref": null, "doi": "10.1145/3369583.3392674", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we approach the exascale era, the size and complexity of HPC systems\ncontinues to increase, raising concerns about their manageability and\nsustainability. For this reason, more and more HPC centers are experimenting\nwith fine-grained monitoring coupled with Operational Data Analytics (ODA) to\noptimize efficiency and effectiveness of system operations. However, while\nmonitoring is a common reality in HPC, there is no well-stated and\ncomprehensive list of requirements, nor matching frameworks, to support\nholistic and online ODA. This leads to insular ad-hoc solutions, each\naddressing only specific aspects of the problem.\n  In this paper we propose Wintermute, a novel generic framework to enable\nonline ODA on large-scale HPC installations. Its design is based on the results\nof a literature survey of common operational requirements. We implement\nWintermute on top of the holistic DCDB monitoring system, offering a large\nvariety of configuration options to accommodate the varying requirements of ODA\napplications. Moreover, Wintermute is based on a set of logical abstractions to\nease the configuration of models at a large scale and maximize code re-use. We\nhighlight Wintermute's flexibility through a series of practical case studies,\neach targeting a different aspect of the management of HPC systems, and then\ndemonstrate the small resource footprint of our implementation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 14:05:52 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 18:04:48 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Netti", "Alessio", ""], ["Mueller", "Micha", ""], ["Guillen", "Carla", ""], ["Ott", "Michael", ""], ["Tafani", "Daniele", ""], ["Ozer", "Gence", ""], ["Schulz", "Martin", ""]]}, {"id": "1910.06169", "submitter": "Giorgio Vinciguerra", "authors": "Paolo Ferragina and Giorgio Vinciguerra", "title": "The PGM-index: a multicriteria, compressed and learned approach to data\n  indexing", "comments": "We remark to the reader that this paper is an extended and improved\n  version of our previous paper titled \"Superseding traditional indexes by\n  orchestrating learning and geometry\" (arXiv:1903.00507)", "journal-ref": "PVLDB, 13(8): 1162-1175, 2020", "doi": "10.14778/3389133.3389135", "report-no": null, "categories": "cs.DS cs.DB cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent introduction of learned indexes has shaken the foundations of the\ndecades-old field of indexing data structures. Combining, or even replacing,\nclassic design elements such as B-tree nodes with machine learning models has\nproven to give outstanding improvements in the space footprint and time\nefficiency of data systems. However, these novel approaches are based on\nheuristics, thus they lack any guarantees both in their time and space\nrequirements. We propose the Piecewise Geometric Model index (shortly,\nPGM-index), which achieves guaranteed I/O-optimality in query operations,\nlearns an optimal number of linear models, and its peculiar recursive\nconstruction makes it a purely learned data structure, rather than a hybrid of\ntraditional and learned indexes (such as RMI and FITing-tree). We show that the\nPGM-index improves the space of the FITing-tree by 63.3% and of the B-tree by\nmore than four orders of magnitude, while achieving their same or even better\nquery time efficiency. We complement this result by proposing three variants of\nthe PGM-index. First, we design a compressed PGM-index that further reduces its\nspace footprint by exploiting the repetitiveness at the level of the learned\nlinear models it is composed of. Second, we design a PGM-index that adapts\nitself to the distribution of the queries, thus resulting in the first known\ndistribution-aware learned index to date. Finally, given its flexibility in the\noffered space-time trade-offs, we propose the multicriteria PGM-index that\nefficiently auto-tune itself in a few seconds over hundreds of millions of keys\nto the possibly evolving space-time constraints imposed by the application of\nuse.\n  We remark to the reader that this paper is an extended and improved version\nof our previous paper titled \"Superseding traditional indexes by orchestrating\nlearning and geometry\" (arXiv:1903.00507).\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 14:25:25 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Ferragina", "Paolo", ""], ["Vinciguerra", "Giorgio", ""]]}, {"id": "1910.06188", "submitter": "Ofir Zafrir", "authors": "Ofir Zafrir, Guy Boudoukh, Peter Izsak, Moshe Wasserblat", "title": "Q8BERT: Quantized 8Bit BERT", "comments": "5 Pages, Accepted at the 5th Workshop on Energy Efficient Machine\n  Learning and Cognitive Computing - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, pre-trained Transformer based language models such as BERT and GPT,\nhave shown great improvement in many Natural Language Processing (NLP) tasks.\nHowever, these models contain a large amount of parameters. The emergence of\neven larger and more accurate models such as GPT2 and Megatron, suggest a trend\nof large pre-trained Transformer models. However, using these large models in\nproduction environments is a complex task requiring a large amount of compute,\nmemory and power resources. In this work we show how to perform\nquantization-aware training during the fine-tuning phase of BERT in order to\ncompress BERT by $4\\times$ with minimal accuracy loss. Furthermore, the\nproduced quantized model can accelerate inference speed if it is optimized for\n8bit Integer supporting hardware.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 14:55:19 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 17:15:24 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Zafrir", "Ofir", ""], ["Boudoukh", "Guy", ""], ["Izsak", "Peter", ""], ["Wasserblat", "Moshe", ""]]}, {"id": "1910.06192", "submitter": "Alireza Mohammadinodooshan", "authors": "Alireza Mohammadinodooshan, Ulf Karg\\'en, Nahid Shahmehri", "title": "Comment on \"AndrODet: An adaptive Android obfuscation detector\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have identified a methodological problem in the empirical evaluation of\nthe string encryption detection capabilities of the AndrODet system described\nby Mirzaei et al. in the recent paper \"AndrODet: An adaptive Android\nobfuscation detector\". The accuracy of string encryption detection is evaluated\nusing samples from the AMD and PraGuard malware datasets. However, the authors\nfailed to account for the fact that many of the AMD samples are highly similar\ndue to the fact that they come from the same malware family. This introduces a\nrisk that a machine learning system trained on these samples could fail to\nlearn a generalizable model for string encryption detection, and might instead\nlearn to classify samples based on characteristics of each malware family. Our\nown evaluation strongly indicates that the reported high accuracy of AndrODet's\nstring encryption detection is indeed due to this phenomenon. When we evaluated\nAndrODet, we found that when we ensured that samples from the same family never\nappeared in both training and testing data, the accuracy dropped to around 50%.\nMoreover, the PraGuard dataset is not suitable for evaluating a static string\nencryption detector such as AndrODet, since the particular obfuscation tool\nused to produce the dataset effectively makes it impossible to extract\nmeaningful features of static strings in Android apps.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 15:06:53 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 18:50:40 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mohammadinodooshan", "Alireza", ""], ["Karg\u00e9n", "Ulf", ""], ["Shahmehri", "Nahid", ""]]}, {"id": "1910.06205", "submitter": "Maximilian Soelch", "authors": "Adnan Akhundov, Maximilian Soelch, Justin Bayer, Patrick van der Smagt", "title": "Variational Tracking and Prediction with Generative Disentangled\n  State-Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address tracking and prediction of multiple moving objects in visual data\nstreams as inference and sampling in a disentangled latent state-space model.\nBy encoding objects separately and including explicit position information in\nthe latent state space, we perform tracking via amortized variational Bayesian\ninference of the respective latent positions. Inference is implemented in a\nmodular neural framework tailored towards our disentangled latent space.\nGenerative and inference model are jointly learned from observations only.\nComparing to related prior work, we empirically show that our Markovian\nstate-space assumption enables faithful and much improved long-term prediction\nwell beyond the training horizon. Further, our inference model correctly\ndecomposes frames into objects, even in the presence of occlusions. Tracking\nperformance is increased significantly over prior art.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 15:20:30 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Akhundov", "Adnan", ""], ["Soelch", "Maximilian", ""], ["Bayer", "Justin", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1910.06222", "submitter": "Jiaming Song", "authors": "Jiaming Song and Stefano Ermon", "title": "Understanding the Limitations of Variational Mutual Information\n  Estimators", "comments": "Fixed some typos, credit to Yilun Xu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational approaches based on neural networks are showing promise for\nestimating mutual information (MI) between high dimensional variables. However,\nthey can be difficult to use in practice due to poorly understood bias/variance\ntradeoffs. We theoretically show that, under some conditions, estimators such\nas MINE exhibit variance that could grow exponentially with the true amount of\nunderlying MI. We also empirically demonstrate that existing estimators fail to\nsatisfy basic self-consistency properties of MI, such as data processing and\nadditivity under independence. Based on a unified perspective of variational\napproaches, we develop a new estimator that focuses on variance reduction.\nEmpirical results on standard benchmark tasks demonstrate that our proposed\nestimator exhibits improved bias-variance trade-offs on standard benchmark\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 15:45:21 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 04:40:12 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "1910.06234", "submitter": "No\\'e Tits", "authors": "No\\'e Tits, Kevin El Haddad, Thierry Dutoit", "title": "The Theory behind Controllable Expressive Speech Synthesis: a\n  Cross-disciplinary Approach", "comments": "19 pages, 6 figures. To be published in the book \"Human Computer\n  Interaction\" edited by Prof. Yves Rybarczyk, published by IntechOpen", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.HC cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of the Human-Computer Interaction field, Expressive speech synthesis\nis a very rich domain as it requires knowledge in areas such as machine\nlearning, signal processing, sociology, psychology. In this Chapter, we will\nfocus mostly on the technical side. From the recording of expressive speech to\nits modeling, the reader will have an overview of the main paradigms used in\nthis field, through some of the most prominent systems and methods. We explain\nhow speech can be represented and encoded with audio features. We present a\nhistory of the main methods of Text-to-Speech synthesis: concatenative,\nparametric and statistical parametric speech synthesis. Finally, we focus on\nthe last one, with the last techniques modeling Text-to-Speech synthesis as a\nsequence-to-sequence problem. This enables the use of Deep Learning blocks such\nas Convolutional and Recurrent Neural Networks as well as Attention Mechanism.\nThe last part of the Chapter intends to assemble the different aspects of the\ntheory and summarize the concepts.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:08:33 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Tits", "No\u00e9", ""], ["Haddad", "Kevin El", ""], ["Dutoit", "Thierry", ""]]}, {"id": "1910.06239", "submitter": "Matthias Kirchler", "authors": "Matthias Kirchler, Shahryar Khorasani, Marius Kloft, Christoph Lippert", "title": "Two-sample Testing Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a two-sample testing procedure based on learned deep neural\nnetwork representations. To this end, we define two test statistics that\nperform an asymptotic location test on data samples mapped onto a hidden layer.\nThe tests are consistent and asymptotically control the type-1 error rate.\nTheir test statistics can be evaluated in linear time (in the sample size).\nSuitable data representations are obtained in a data-driven way, by solving a\nsupervised or unsupervised transfer-learning task on an auxiliary (potentially\ndistinct) data set. If no auxiliary data is available, we split the data into\ntwo chunks: one for learning representations and one for computing the test\nstatistic. In experiments on audio samples, natural images and\nthree-dimensional neuroimaging data our tests yield significant decreases in\ntype-2 error rate (up to 35 percentage points) compared to state-of-the-art\ntwo-sample tests such as kernel-methods and classifier two-sample tests.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:16:58 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 16:01:53 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Kirchler", "Matthias", ""], ["Khorasani", "Shahryar", ""], ["Kloft", "Marius", ""], ["Lippert", "Christoph", ""]]}, {"id": "1910.06243", "submitter": "Adam Derek Cobb", "authors": "Adam D. Cobb, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Andrew Markham, Stephen\n  J. Roberts", "title": "Introducing an Explicit Symplectic Integration Scheme for Riemannian\n  Manifold Hamiltonian Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a recent symplectic integration scheme derived for solving\nphysically motivated systems with non-separable Hamiltonians. We show its\nrelevance to Riemannian manifold Hamiltonian Monte Carlo (RMHMC) and provide an\nalternative to the currently used generalised leapfrog symplectic integrator,\nwhich relies on solving multiple fixed point iterations to convergence. Via\nthis approach, we are able to reduce the number of higher-order derivative\ncalculations per leapfrog step. We explore the implications of this integrator\nand demonstrate its efficacy in reducing the computational burden of RMHMC. Our\ncode is provided in a new open-source Python package, hamiltorch.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:20:06 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Cobb", "Adam D.", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Markham", "Andrew", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1910.06251", "submitter": "Shuai Li", "authors": "Shuai Li, Wanqing Li, Chris Cook, Yanbo Gao", "title": "Deep Independently Recurrent Neural Network (IndRNN)", "comments": "Extension of the CVPR2018 paper \"Independently Recurrent Neural\n  Network (IndRNN): Building A Longer and Deeper RNN\", with significant\n  improvements as described in the end of Section I. arXiv admin note: text\n  overlap with arXiv:1803.04831", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are known to be difficult to train due to\nthe gradient vanishing and exploding problems and thus difficult to learn\nlong-term patterns and construct deep networks. To address these problems, this\npaper proposes a new type of RNNs with the recurrent connection formulated as\nHadamard product, referred to as independently recurrent neural network\n(IndRNN), where neurons in the same layer are independent of each other and\nconnected across layers. Due to the better behaved gradient backpropagation,\nIndRNN with regulated recurrent weights effectively addresses the gradient\nvanishing and exploding problems and thus long-term dependencies can be\nlearned. Moreover, an IndRNN can work with non-saturated activation functions\nsuch as ReLU (rectified linear unit) and be still trained robustly. Different\ndeeper IndRNN architectures, including the basic stacked IndRNN, residual\nIndRNN and densely connected IndRNN, have been investigated, all of which can\nbe much deeper than the existing RNNs. Furthermore, IndRNN reduces the\ncomputation at each time step and can be over 10 times faster than the commonly\nused Long short-term memory (LSTM). Experimental results have shown that the\nproposed IndRNN is able to process very long sequences and construct very deep\nnetworks. Better performance has been achieved on various tasks with IndRNNs\ncompared with the traditional RNN, LSTM and the popular Transformer.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 09:43:49 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 12:51:05 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 09:19:00 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Li", "Shuai", ""], ["Li", "Wanqing", ""], ["Cook", "Chris", ""], ["Gao", "Yanbo", ""]]}, {"id": "1910.06259", "submitter": "David Stutz", "authors": "David Stutz, Matthias Hein, Bernt Schiele", "title": "Confidence-Calibrated Adversarial Training: Generalizing to Unseen\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training yields robust models against a specific threat model,\ne.g., $L_\\infty$ adversarial examples. Typically robustness does not generalize\nto previously unseen threat models, e.g., other $L_p$ norms, or larger\nperturbations. Our confidence-calibrated adversarial training (CCAT) tackles\nthis problem by biasing the model towards low confidence predictions on\nadversarial examples. By allowing to reject examples with low confidence,\nrobustness generalizes beyond the threat model employed during training. CCAT,\ntrained only on $L_\\infty$ adversarial examples, increases robustness against\nlarger $L_\\infty$, $L_2$, $L_1$ and $L_0$ attacks, adversarial frames, distal\nadversarial examples and corrupted examples and yields better clean accuracy\ncompared to adversarial training. For thorough evaluation we developed novel\nwhite- and black-box attacks directly attacking CCAT by maximizing confidence.\nFor each threat model, we use $7$ attacks with up to $50$ restarts and $5000$\niterations and report worst-case robust test error, extended to our\nconfidence-thresholded setting, across all attacks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:38:03 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 16:34:42 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 16:15:44 GMT"}, {"version": "v4", "created": "Tue, 30 Jun 2020 12:03:44 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Stutz", "David", ""], ["Hein", "Matthias", ""], ["Schiele", "Bernt", ""]]}, {"id": "1910.06261", "submitter": "Edgar Kaziakhmedov", "authors": "Edgar Kaziakhmedov, Klim Kireev, Grigorii Melnikov, Mikhail Pautov,\n  Aleksandr Petiushko", "title": "Real-world adversarial attack on MTCNN face detection system", "comments": null, "journal-ref": "2019 International Multi-Conference on Engineering, Computer and\n  Information Sciences (SIBIRCON)", "doi": "10.1109/SIBIRCON48586.2019.8958122", "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies proved that deep learning approaches achieve remarkable\nresults on face detection task. On the other hand, the advances gave rise to a\nnew problem associated with the security of the deep convolutional neural\nnetwork models unveiling potential risks of DCNNs based applications. Even\nminor input changes in the digital domain can result in the network being\nfooled. It was shown then that some deep learning-based face detectors are\nprone to adversarial attacks not only in a digital domain but also in the real\nworld. In the paper, we investigate the security of the well-known cascade CNN\nface detection system - MTCNN and introduce an easily reproducible and a robust\nway to attack it. We propose different face attributes printed on an ordinary\nwhite and black printer and attached either to the medical face mask or to the\nface directly. Our approach is capable of breaking the MTCNN detector in a\nreal-world scenario.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:42:09 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 22:29:44 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kaziakhmedov", "Edgar", ""], ["Kireev", "Klim", ""], ["Melnikov", "Grigorii", ""], ["Pautov", "Mikhail", ""], ["Petiushko", "Aleksandr", ""]]}, {"id": "1910.06271", "submitter": "Karim Armanious", "authors": "Karim Armanious, Sherif Abdulatif, Anish Rao Bhaktharaguttu, Thomas\n  K\\\"ustner, Tobias Hepp, Sergios Gatidis, Bin Yang", "title": "Organ-based Chronological Age Estimation based on 3D MRI Scans", "comments": "Submitted to IEEE EUSIPCO 2020", "journal-ref": null, "doi": "10.23919/Eusipco47968.2020.9287398", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individuals age differently depending on a multitude of different factors\nsuch as lifestyle, medical history and genetics. Often, the global\nchronological age is not indicative of the true ageing process. An organ-based\nage estimation would yield a more accurate health state assessment. In this\nwork, we propose a new deep learning architecture for organ-based age\nestimation based on magnetic resonance images (MRI). The proposed network is a\n3D convolutional neural network (CNN) with increased depth and width made\npossible by the hybrid utilization of inception and fire modules. We apply the\nproposed framework for the tasks of brain and knee age estimation. Quantitative\ncomparisons against concurrent MR-based regression networks and different 2D\nand 3D data feeding strategies illustrated the superior performance of the\nproposed work.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:55:10 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 11:39:16 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Armanious", "Karim", ""], ["Abdulatif", "Sherif", ""], ["Bhaktharaguttu", "Anish Rao", ""], ["K\u00fcstner", "Thomas", ""], ["Hepp", "Tobias", ""], ["Gatidis", "Sergios", ""], ["Yang", "Bin", ""]]}, {"id": "1910.06294", "submitter": "Peter Izsak", "authors": "Peter Izsak, Shira Guskin, Moshe Wasserblat", "title": "Training Compact Models for Low Resource Entity Tagging using\n  Pre-trained Language Models", "comments": "Accepted to the 5th Workshop on Energy Efficient Machine Learning and\n  Cognitive Computing - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training models on low-resource named entity recognition tasks has been shown\nto be a challenge, especially in industrial applications where deploying\nupdated models is a continuous effort and crucial for business operations. In\nsuch cases there is often an abundance of unlabeled data, while labeled data is\nscarce or unavailable. Pre-trained language models trained to extract\ncontextual features from text were shown to improve many natural language\nprocessing (NLP) tasks, including scarcely labeled tasks, by leveraging\ntransfer learning. However, such models impose a heavy memory and computational\nburden, making it a challenge to train and deploy such models for inference\nuse. In this work-in-progress we combined the effectiveness of transfer\nlearning provided by pre-trained masked language models with a semi-supervised\napproach to train a fast and compact model using labeled and unlabeled\nexamples. Preliminary evaluations show that the compact models can achieve\ncompetitive accuracy with 36x compression rate when compared with a\nstate-of-the-art pre-trained language model, and run significantly faster in\ninference, allowing deployment of such models in production environments or on\nedge devices.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 17:22:37 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 08:07:19 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Izsak", "Peter", ""], ["Guskin", "Shira", ""], ["Wasserblat", "Moshe", ""]]}, {"id": "1910.06296", "submitter": "Fuyuan Zhang", "authors": "Fuyuan Zhang, Sankalan Pal Chowdhury, Maria Christakis", "title": "DeepSearch: A Simple and Effective Blackbox Attack for Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural networks have been very successful in\nimage-classification tasks, they are prone to adversarial attacks. To generate\nadversarial inputs, there has emerged a wide variety of techniques, such as\nblack- and whitebox attacks for neural networks. In this paper, we present\nDeepSearch, a novel fuzzing-based, query-efficient, blackbox attack for image\nclassifiers. Despite its simplicity, DeepSearch is shown to be more effective\nin finding adversarial inputs than state-of-the-art blackbox approaches.\nDeepSearch is additionally able to generate the most subtle adversarial inputs\nin comparison to these approaches.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 17:25:21 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 10:40:18 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zhang", "Fuyuan", ""], ["Chowdhury", "Sankalan Pal", ""], ["Christakis", "Maria", ""]]}, {"id": "1910.06302", "submitter": "Erfan Noury", "authors": "Erfan Noury, Suria S. Mannil, Robert T. Chang, An Ran Ran, Carol Y.\n  Cheung, Suman S. Thapa, Harsha L. Rao, Srilakshmi Dasari, Mohammed\n  Riyazuddin, Dolly Chang, Sriharsha Nagaraj, Clement C. Tham, Reza Zadeh", "title": "Finding New Diagnostic Information for Detecting Glaucoma using Neural\n  Networks", "comments": "28 pages, 12 figures, 15 tables, title changed, new authors added", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new approach to automated Glaucoma detection in 3D Spectral\nDomain Optical Coherence Tomography (OCT) optic nerve scans. First, we gathered\na unique and diverse multi-ethnic dataset of OCT scans consisting of glaucoma\nand non-glaucomatous cases obtained from four tertiary care eye hospitals\nlocated in four different countries. Using this longitudinal data, we achieved\nstate-of-the-art results for automatically detecting Glaucoma from a single raw\nOCT using a 3D Deep Learning system. These results are close to human doctors\nin a variety of settings across heterogeneous datasets and scanning\nenvironments. To verify correctness and interpretability of the automated\ncategorization, we used saliency maps to find areas of focus for the model.\nMatching human doctor behavior, the model predictions indeed correlated with\nthe conventional diagnostic parameters in the OCT printouts, such as the\nretinal nerve fiber layer. We further used our model to find new areas in the\n3D data that are presently not being identified as a diagnostic parameter to\ndetect glaucoma by human doctors. Namely, we found that the Lamina Cribrosa\n(LC) region can be a valuable source of helpful diagnostic information\npreviously unavailable to doctors during routine clinical care because it lacks\na quantitative printout. Our model provides such volumetric quantification of\nthis region. We found that even when a majority of the RNFL is removed, the LC\nregion can distinguish glaucoma. This is clinically relevant in high myopes,\nwhen the RNFL is already reduced, and thus the LC region may help differentiate\nglaucoma in this confounding situation. We further generalize this approach to\ncreate a new algorithm called DiagFind that provides a recipe for finding new\ndiagnostic information in medical imagery that may have been previously\nunusable by doctors.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 17:29:17 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 02:36:09 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Noury", "Erfan", ""], ["Mannil", "Suria S.", ""], ["Chang", "Robert T.", ""], ["Ran", "An Ran", ""], ["Cheung", "Carol Y.", ""], ["Thapa", "Suman S.", ""], ["Rao", "Harsha L.", ""], ["Dasari", "Srilakshmi", ""], ["Riyazuddin", "Mohammed", ""], ["Chang", "Dolly", ""], ["Nagaraj", "Sriharsha", ""], ["Tham", "Clement C.", ""], ["Zadeh", "Reza", ""]]}, {"id": "1910.06310", "submitter": "Yu-Hang Tang", "authors": "Yu-Hang Tang, Oguz Selvitopi, Doru Popovici, Ayd{\\i}n Bulu\\c{c}", "title": "A High-Throughput Solver for Marginalized Graph Kernels on GPU", "comments": null, "journal-ref": null, "doi": "10.1109/IPDPS47924.2020.00080", "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design and optimization of a linear solver on General Purpose\nGPUs for the efficient and high-throughput evaluation of the marginalized graph\nkernel between pairs of labeled graphs. The solver implements a preconditioned\nconjugate gradient (PCG) method to compute the solution to a generalized\nLaplacian equation associated with the tensor product of two graphs. To cope\nwith the gap between the instruction throughput and the memory bandwidth of\ncurrent generation GPUs, our solver forms the tensor product linear system\non-the-fly without storing it in memory when performing matrix-vector dot\nproduct operations in PCG. Such on-the-fly computation is accomplished by using\nthreads in a warp to cooperatively stream the adjacency and edge label matrices\nof individual graphs by small square matrix blocks called tiles, which are then\nstaged in registers and the shared memory for later reuse. Warps across a\nthread block can further share tiles via the shared memory to increase data\nreuse. We exploit the sparsity of the graphs hierarchically by storing only\nnon-empty tiles using a coordinate format and nonzero elements within each tile\nusing bitmaps. Besides, we propose a new partition-based reordering algorithm\nfor aggregating nonzero elements of the graphs into fewer but denser tiles to\nimprove the efficiency of the sparse format.\n  We carry out extensive theoretical analyses on the graph tensor product\nprimitives for tiles of various density and evaluate their performance on\nsynthetic and real-world datasets. Our solver delivers three to four orders of\nmagnitude speedup over existing CPU-based solvers such as GraKeL and\nGraphKernels. The capability of the solver enables kernel-based learning tasks\nat unprecedented scales.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 17:46:47 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 08:58:01 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 08:09:42 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2020 23:28:34 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Tang", "Yu-Hang", ""], ["Selvitopi", "Oguz", ""], ["Popovici", "Doru", ""], ["Bulu\u00e7", "Ayd\u0131n", ""]]}, {"id": "1910.06315", "submitter": "Badri Narayana Patro", "authors": "Soumik Dasgupta, Badri N. Patro, and Vinay P. Namboodiri", "title": "Dynamic Attention Networks for Task Oriented Grounding", "comments": "Accepted ICCV 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In order to successfully perform tasks specified by natural language\ninstructions, an artificial agent operating in a visual world needs to map\nwords, concepts, and actions from the instruction to visual elements in its\nenvironment. This association is termed as Task-Oriented Grounding. In this\nwork, we propose a novel Dynamic Attention Network architecture for the\nefficient multi-modal fusion of text and visual representations which can\ngenerate a robust definition of state for the policy learner. Our model assumes\nno prior knowledge from visual and textual domains and is an end to end\ntrainable. For a 3D visual world where the observation changes continuously,\nthe attention on the visual elements tends to be highly co-related from a\none-time step to the next. We term this as \"Dynamic Attention\". In this work,\nwe show that Dynamic Attention helps in achieving grounding and also aids in\nthe policy learning objective. Since most practical robotic applications take\nplace in the real world where the observation space is continuous, our\nframework can be used as a generalized multi-modal fusion unit for robotic\ncontrol through natural language. We show the effectiveness of using 1D\nconvolution over Gated Attention Hadamard product on the rate of convergence of\nthe network. We demonstrate that the cell-state of a Long Short Term Memory\n(LSTM) is a natural choice for modeling Dynamic Attention and shows through\nvisualization that the generated attention is very close to how humans tend to\nfocus on the environment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 17:57:21 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Dasgupta", "Soumik", ""], ["Patro", "Badri N.", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1910.06324", "submitter": "Fengpei Li", "authors": "Henry Lam, Fengpei Li, Siddharth Prusty", "title": "Robust Importance Weighting for Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many learning problems, the training and testing data follow different\ndistributions and a particularly common situation is the \\textit{covariate\nshift}. To correct for sampling biases, most approaches, including the popular\nkernel mean matching (KMM), focus on estimating the importance weights between\nthe two distributions. Reweighting-based methods, however, are exposed to high\nvariance when the distributional discrepancy is large and the weights are\npoorly estimated. On the other hand, the alternate approach of using\nnonparametric regression (NR) incurs high bias when the training size is\nlimited. In this paper, we propose and analyze a new estimator that\nsystematically integrates the residuals of NR with KMM reweighting, based on a\ncontrol-variate perspective. The proposed estimator can be shown to either\nstrictly outperform or match the best-known existing rates for both KMM and NR,\nand thus is a robust combination of both estimators. The experiments shows the\nestimator works well in practice.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 15:20:04 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 22:23:46 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Lam", "Henry", ""], ["Li", "Fengpei", ""], ["Prusty", "Siddharth", ""]]}, {"id": "1910.06358", "submitter": "Christopher Frye", "authors": "Christopher Frye, Colin Rowat, Ilya Feige", "title": "Asymmetric Shapley values: incorporating causal knowledge into\n  model-agnostic explainability", "comments": "To appear in NeurIPS 2020; 9 pages, 2 figures, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining AI systems is fundamental both to the development of high\nperforming models and to the trust placed in them by their users. The Shapley\nframework for explainability has strength in its general applicability combined\nwith its precise, rigorous foundation: it provides a common, model-agnostic\nlanguage for AI explainability and uniquely satisfies a set of intuitive\nmathematical axioms. However, Shapley values are too restrictive in one\nsignificant regard: they ignore all causal structure in the data. We introduce\na less restrictive framework, Asymmetric Shapley values (ASVs), which are\nrigorously founded on a set of axioms, applicable to any AI system, and\nflexible enough to incorporate any causal structure known to be respected by\nthe data. We demonstrate that ASVs can (i) improve model explanations by\nincorporating causal information, (ii) provide an unambiguous test for unfair\ndiscrimination in model predictions, (iii) enable sequentially incremental\nexplanations in time-series models, and (iv) support feature-selection studies\nwithout the need for model retraining.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 18:08:32 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 19:15:21 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Frye", "Christopher", ""], ["Rowat", "Colin", ""], ["Feige", "Ilya", ""]]}, {"id": "1910.06360", "submitter": "Jeffrey McCarley", "authors": "J.S. McCarley, Rishav Chakravarti, and Avirup Sil", "title": "Structured Pruning of a BERT-based Question Answering Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent trend in industry-setting Natural Language Processing (NLP)\nresearch has been to operate large %scale pretrained language models like BERT\nunder strict computational limits. While most model compression work has\nfocused on \"distilling\" a general-purpose language representation using\nexpensive pretraining distillation, less attention has been paid to creating\nsmaller task-specific language representations which, arguably, are more useful\nin an industry setting. In this paper, we investigate compressing BERT- and\nRoBERTa-based question answering systems by structured pruning of parameters\nfrom the underlying transformer model. We find that an inexpensive combination\nof task-specific structured pruning and task-specific distillation, without the\nexpense of pretraining distillation, yields highly-performing models across a\nrange of speed/accuracy tradeoff operating points. We start from existing\nfull-size models trained for SQuAD 2.0 or Natural Questions and introduce gates\nthat allow selected parts of transformers to be individually eliminated.\nSpecifically, we investigate (1) structured pruning to reduce the number of\nparameters in each transformer layer, (2) applicability to both BERT- and\nRoBERTa-based models, (3) applicability to both SQuAD 2.0 and Natural\nQuestions, and (4) combining structured pruning with distillation. We achieve a\nnear-doubling of inference speed with less than a 0.5 F1-point loss in short\nanswer accuracy on Natural Questions.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 18:12:30 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 23:23:14 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 18:53:43 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["McCarley", "J. S.", ""], ["Chakravarti", "Rishav", ""], ["Sil", "Avirup", ""]]}, {"id": "1910.06366", "submitter": "Lijun Sun Mr", "authors": "Xinyu Chen and Lijun Sun", "title": "Bayesian Temporal Factorization for Multidimensional Time Series\n  Prediction", "comments": "15 pages, 9 figures, 3 tables", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3066551", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale and multidimensional spatiotemporal data sets are becoming\nubiquitous in many real-world applications such as monitoring urban traffic and\nair quality. Making predictions on these time series has become a critical\nchallenge due to not only the large-scale and high-dimensional nature but also\nthe considerable amount of missing data. In this paper, we propose a Bayesian\ntemporal factorization (BTF) framework for modeling multidimensional time\nseries -- in particular spatiotemporal data -- in the presence of missing\nvalues. By integrating low-rank matrix/tensor factorization and vector\nautoregressive (VAR) process into a single probabilistic graphical model, this\nframework can characterize both global and local consistencies in large-scale\ntime series data. The graphical model allows us to effectively perform\nprobabilistic predictions and produce uncertainty estimates without imputing\nthose missing values. We develop efficient Gibbs sampling algorithms for model\ninference and model updating for real-time prediction and test the proposed BTF\nframework on several real-world spatiotemporal data sets for both missing data\nimputation and multi-step rolling prediction tasks. The numerical experiments\ndemonstrate the superiority of the proposed BTF approaches over existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 18:21:33 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 14:24:39 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Chen", "Xinyu", ""], ["Sun", "Lijun", ""]]}, {"id": "1910.06368", "submitter": "Yichong Xu", "authors": "Yichong Xu, Xi Chen, Aarti Singh and Artur Dubrawski", "title": "Thresholding Bandit Problem with Both Duels and Pulls", "comments": "15 pages, 8 figures; The 23rd International Conference on Artificial\n  Intelligence and Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Thresholding Bandit Problem (TBP) aims to find the set of arms with mean\nrewards greater than a given threshold. We consider a new setting of TBP, where\nin addition to pulling arms, one can also \\emph{duel} two arms and get the arm\nwith a greater mean. In our motivating application from crowdsourcing, dueling\ntwo arms can be more cost-effective and time-efficient than direct pulls. We\nrefer to this problem as TBP with Dueling Choices (TBP-DC). This paper provides\nan algorithm called Rank-Search (RS) for solving TBP-DC by alternating between\nranking and binary search. We prove theoretical guarantees for RS, and also\ngive lower bounds to show the optimality of it. Experiments show that RS\noutperforms previous baseline algorithms that only use pulls or duels.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 18:24:21 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 21:25:04 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Xu", "Yichong", ""], ["Chen", "Xi", ""], ["Singh", "Aarti", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1910.06378", "submitter": "Sai Praneeth Karimireddy", "authors": "Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank J.\n  Reddi, Sebastian U. Stich, Ananda Theertha Suresh", "title": "SCAFFOLD: Stochastic Controlled Averaging for Federated Learning", "comments": "v2 contains analysis of FedAvg, non-convex rates of Scaffold, and\n  experimental evaluation. v3 fixes typos, ICML version. v4 slightly improves\n  rate of SCAFFOLD for general convex functions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Averaging (FedAvg) has emerged as the algorithm of choice for\nfederated learning due to its simplicity and low communication cost. However,\nin spite of recent research efforts, its performance is not fully understood.\nWe obtain tight convergence rates for FedAvg and prove that it suffers from\n`client-drift' when the data is heterogeneous (non-iid), resulting in unstable\nand slow convergence.\n  As a solution, we propose a new algorithm (SCAFFOLD) which uses control\nvariates (variance reduction) to correct for the `client-drift' in its local\nupdates. We prove that SCAFFOLD requires significantly fewer communication\nrounds and is not affected by data heterogeneity or client sampling. Further,\nwe show that (for quadratics) SCAFFOLD can take advantage of similarity in the\nclient's data yielding even faster convergence. The latter is the first result\nto quantify the usefulness of local-steps in distributed optimization.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 18:49:20 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 15:57:57 GMT"}, {"version": "v3", "created": "Sun, 9 Aug 2020 23:37:28 GMT"}, {"version": "v4", "created": "Fri, 9 Apr 2021 16:21:59 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Karimireddy", "Sai Praneeth", ""], ["Kale", "Satyen", ""], ["Mohri", "Mehryar", ""], ["Reddi", "Sashank J.", ""], ["Stich", "Sebastian U.", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "1910.06379", "submitter": "Yi Luo", "authors": "Yi Luo, Zhuo Chen, Takuya Yoshioka", "title": "Dual-path RNN: efficient long sequence modeling for time-domain\n  single-channel speech separation", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent studies in deep learning-based speech separation have proven the\nsuperiority of time-domain approaches to conventional time-frequency-based\nmethods. Unlike the time-frequency domain approaches, the time-domain\nseparation systems often receive input sequences consisting of a huge number of\ntime steps, which introduces challenges for modeling extremely long sequences.\nConventional recurrent neural networks (RNNs) are not effective for modeling\nsuch long sequences due to optimization difficulties, while one-dimensional\nconvolutional neural networks (1-D CNNs) cannot perform utterance-level\nsequence modeling when its receptive field is smaller than the sequence length.\nIn this paper, we propose dual-path recurrent neural network (DPRNN), a simple\nyet effective method for organizing RNN layers in a deep structure to model\nextremely long sequences. DPRNN splits the long sequential input into smaller\nchunks and applies intra- and inter-chunk operations iteratively, where the\ninput length can be made proportional to the square root of the original\nsequence length in each operation. Experiments show that by replacing 1-D CNN\nwith DPRNN and apply sample-level modeling in the time-domain audio separation\nnetwork (TasNet), a new state-of-the-art performance on WSJ0-2mix is achieved\nwith a 20 times smaller model than the previous best system.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 18:52:49 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 10:15:38 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Luo", "Yi", ""], ["Chen", "Zhuo", ""], ["Yoshioka", "Takuya", ""]]}, {"id": "1910.06391", "submitter": "Chaofeng Wang", "authors": "Qian Yu, Chaofeng Wang, Barbaros Cetiner, Stella X. Yu, Frank Mckenna,\n  Ertugrul Taciroglu, Kincho H. Law", "title": "Building Information Modeling and Classification by Visual Learning At A\n  City Scale", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": "10.5281/zenodo.3996808", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide two case studies to demonstrate how artificial\nintelligence can empower civil engineering. In the first case, a machine\nlearning-assisted framework, BRAILS, is proposed for city-scale building\ninformation modeling. Building information modeling (BIM) is an efficient way\nof describing buildings, which is essential to architecture, engineering, and\nconstruction. Our proposed framework employs deep learning technique to extract\nvisual information of buildings from satellite/street view images. Further, a\nnovel machine learning (ML)-based statistical tool, SURF, is proposed to\ndiscover the spatial patterns in building metadata.\n  The second case focuses on the task of soft-story building classification.\nSoft-story buildings are a type of buildings prone to collapse during a\nmoderate or severe earthquake. Hence, identifying and retrofitting such\nbuildings is vital in the current earthquake preparedness efforts. For this\ntask, we propose an automated deep learning-based procedure for identifying\nsoft-story buildings from street view images at a regional scale. We also\ncreate a large-scale building image database and a semi-automated image\nlabeling approach that effectively annotates new database entries. Through\nextensive computational experiments, we demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 19:44:25 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 00:59:50 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Yu", "Qian", ""], ["Wang", "Chaofeng", ""], ["Cetiner", "Barbaros", ""], ["Yu", "Stella X.", ""], ["Mckenna", "Frank", ""], ["Taciroglu", "Ertugrul", ""], ["Law", "Kincho H.", ""]]}, {"id": "1910.06392", "submitter": "Muhammad Usman", "authors": "Muhammad Usman and Jeong A Lee", "title": "AFP-CKSAAP: Prediction of Antifreeze Proteins Using Composition of\n  k-Spaced Amino Acid Pairs with Deep Neural Network", "comments": "Accepted for oral presentation at 19th 2019 IEEE International\n  Conference on Bioinformatics and Bioengineering (IC-BIBE 2019) Copyright (c)\n  2019 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Antifreeze proteins (AFPs) are the sub-set of ice binding proteins\nindispensable for the species living in extreme cold weather. These proteins\nbind to the ice crystals, hindering their growth into large ice lattice that\ncould cause physical damage. There are variety of AFPs found in numerous\norganisms and due to the heterogeneous sequence characteristics, AFPs are found\nto demonstrate a high degree of diversity, which makes their prediction a\nchallenging task. Herein, we propose a machine learning framework to deal with\nthis vigorous and diverse prediction problem using the manifolding learning\nthrough composition of k-spaced amino acid pairs. We propose to use the deep\nneural network with skipped connection and ReLU non-linearity to learn the\nnon-linear mapping of protein sequence descriptor and class label. The proposed\nantifreeze protein prediction method called AFP-CKSAAP has shown to outperform\nthe contemporary methods, achieving excellent prediction scores on standard\ndataset. The main evaluater for the performance of the proposed method in this\nstudy is Youden's index whose high value is dependent on both sensitivity and\nspecificity. In particular, AFP-CKSAAP yields a Youden's index value of 0.82 on\nthe independent dataset, which is better than previous methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 03:13:14 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Usman", "Muhammad", ""], ["Lee", "Jeong A", ""]]}, {"id": "1910.06393", "submitter": "Zachary Kaden", "authors": "Zachary Kaden, Teven Le Scao, Raphael Olivier", "title": "In-training Matrix Factorization for Parameter-frugal Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the use of in-training matrix factorization to\nreduce the model size for neural machine translation. Using in-training matrix\nfactorization, parameter matrices may be decomposed into the products of\nsmaller matrices, which can compress large machine translation architectures by\nvastly reducing the number of learnable parameters. We apply in-training matrix\nfactorization to different layers of standard neural architectures and show\nthat in-training factorization is capable of reducing nearly 50% of learnable\nparameters without any associated loss in BLEU score. Further, we find that\nin-training matrix factorization is especially powerful on embedding layers,\nproviding a simple and effective method to curtail the number of parameters\nwith minimal impact on model performance, and, at times, an increase in\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:58:55 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 18:17:20 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Kaden", "Zachary", ""], ["Scao", "Teven Le", ""], ["Olivier", "Raphael", ""]]}, {"id": "1910.06401", "submitter": "Konstantin Berestizshevsky", "authors": "Jonatan Ostrometzky, Konstantin Berestizshevsky, Andrey Bernstein, Gil\n  Zussman", "title": "Physics-Informed Deep Neural Network Method for Limited Observability\n  State Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The precise knowledge regarding the state of the power grid is important in\norder to ensure optimal and reliable grid operation. Specifically, knowing the\nstate of the distribution grid becomes increasingly important as more renewable\nenergy sources are connected directly into the distribution network, increasing\nthe fluctuations of the injected power. In this paper, we consider the case\nwhen the distribution grid becomes partially observable, and the state\nestimation problem is under-determined. We present a new methodology that\nleverages a deep neural network (DNN) to estimate the grid state. The standard\nDNN training method is modified to explicitly incorporate the physical\ninformation of the grid topology and line/shunt admittance. We show that our\nmethod leads to a superior accuracy of the estimation when compared to the case\nwhen no physical information is provided. Finally, we compare the performance\nof our method to the standard state estimation approach, which is based on the\nweighted least squares with pseudo-measurements, and show that our method\nperforms significantly better with respect to the estimation accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 20:09:50 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 18:58:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ostrometzky", "Jonatan", ""], ["Berestizshevsky", "Konstantin", ""], ["Bernstein", "Andrey", ""], ["Zussman", "Gil", ""]]}, {"id": "1910.06403", "submitter": "Maximilian Balandat", "authors": "Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton,\n  Benjamin Letham, Andrew Gordon Wilson, Eytan Bakshy", "title": "BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization provides sample-efficient global optimization for a\nbroad range of applications, including automatic machine learning, engineering,\nphysics, and experimental design. We introduce BoTorch, a modern programming\nframework for Bayesian optimization that combines Monte-Carlo (MC) acquisition\nfunctions, a novel sample average approximation optimization approach,\nauto-differentiation, and variance reduction techniques. BoTorch's modular\ndesign facilitates flexible specification and optimization of probabilistic\nmodels written in PyTorch, simplifying implementation of new acquisition\nfunctions. Our approach is backed by novel theoretical convergence results and\nmade practical by a distinctive algorithmic foundation that leverages fast\npredictive distributions, hardware acceleration, and deterministic\noptimization. We also propose a novel \"one-shot\" formulation of the Knowledge\nGradient, enabled by a combination of our theoretical and software\ncontributions. In experiments, we demonstrate the improved sample efficiency of\nBoTorch relative to other popular libraries.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 20:11:30 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 17:28:05 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 19:31:38 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Balandat", "Maximilian", ""], ["Karrer", "Brian", ""], ["Jiang", "Daniel R.", ""], ["Daulton", "Samuel", ""], ["Letham", "Benjamin", ""], ["Wilson", "Andrew Gordon", ""], ["Bakshy", "Eytan", ""]]}, {"id": "1910.06407", "submitter": "Jigar Doshi", "authors": "Jigar Doshi, Dominic Garcia, Cliff Massey, Pablo Llueca, Nicolas\n  Borensztein, Michael Baird, Matthew Cook, Devaki Raj", "title": "FireNet: Real-time Segmentation of Fire Perimeter from Aerial Video", "comments": "Published at NeurIPS 2019; Workshop on Artificial Intelligence for\n  Humanitarian Assistance and Disaster Response(AI+HADR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we share our approach to real-time segmentation of fire\nperimeter from aerial full-motion infrared video. We start by describing the\nproblem from a humanitarian aid and disaster response perspective.\nSpecifically, we explain the importance of the problem, how it is currently\nresolved, and how our machine learning approach improves it. To test our models\nwe annotate a large-scale dataset of 400,000 frames with guidance from domain\nexperts. Finally, we share our approach currently deployed in production with\ninference speed of 20 frames per second and an accuracy of 92 (F1 Score).\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 20:19:15 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Doshi", "Jigar", ""], ["Garcia", "Dominic", ""], ["Massey", "Cliff", ""], ["Llueca", "Pablo", ""], ["Borensztein", "Nicolas", ""], ["Baird", "Michael", ""], ["Cook", "Matthew", ""], ["Raj", "Devaki", ""]]}, {"id": "1910.06419", "submitter": "Paavo Parmas", "authors": "Paavo Parmas and Masashi Sugiyama", "title": "A unified view of likelihood ratio and reparameterization gradients and\n  an optimal importance sampling scheme", "comments": "8 pages + 19 pages appendix. Preliminary work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reparameterization (RP) and likelihood ratio (LR) gradient estimators are\nused throughout machine and reinforcement learning; however, they are usually\nexplained as simple mathematical tricks without providing any insight into\ntheir nature. We use a first principles approach to explain LR and RP, and show\na connection between the two via the divergence theorem. The theory motivated\nus to derive optimal importance sampling schemes to reduce LR gradient\nvariance. Our newly derived distributions have analytic probability densities\nand can be directly sampled from. The improvement for Gaussian target\ndistributions was modest, but for other distributions such as a Beta\ndistribution, our method could lead to arbitrarily large improvements, and was\ncrucial to obtain competitive performance in evolution strategies experiments.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 20:59:13 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Parmas", "Paavo", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1910.06428", "submitter": "Soheil Ghafurian", "authors": "Bairavi Venkatesh, Tosha Shah, Antong Chen, Soheil Ghafurian", "title": "Restoration of marker occluded hematoxylin and eosin stained whole slide\n  histology images using generative adversarial networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common for pathologists to annotate specific regions of the tissue,\nsuch as tumor, directly on the glass slide with markers. Although this practice\nwas helpful prior to the advent of histology whole slide digitization, it often\noccludes important details which are increasingly relevant to immuno-oncology\ndue to recent advancements in digital pathology imaging techniques. The current\nwork uses a generative adversarial network with cycle loss to remove these\nannotations while still maintaining the underlying structure of the tissue by\nsolving an image-to-image translation problem. We train our network on up to\n300 whole slide images with marker inks and show that 70% of the corrected\nimage patches are indistinguishable from originally uncontaminated image tissue\nto a human expert. This portion increases 97% when we replace the human expert\nwith a deep residual network. We demonstrated the fidelity of the method to the\noriginal image by calculating the correlation between image gradient\nmagnitudes. We observed a revival of up to 94,000 nuclei per slide in our\ndataset, the majority of which were located on tissue border.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 21:22:54 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Venkatesh", "Bairavi", ""], ["Shah", "Tosha", ""], ["Chen", "Antong", ""], ["Ghafurian", "Soheil", ""]]}, {"id": "1910.06444", "submitter": "Joseph Xu", "authors": "Joseph Z. Xu, Wenhan Lu, Zebo Li, Pranav Khaitan, Valeriya Zaytseva", "title": "Building Damage Detection in Satellite Imagery Using Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In all types of disasters, from earthquakes to armed conflicts, aid workers\nneed accurate and timely data such as damage to buildings and population\ndisplacement to mount an effective response. Remote sensing provides this data\nat an unprecedented scale, but extracting operationalizable information from\nsatellite images is slow and labor-intensive. In this work, we use machine\nlearning to automate the detection of building damage in satellite imagery. We\ncompare the performance of four different convolutional neural network models\nin detecting damaged buildings in the 2010 Haiti earthquake. We also quantify\nhow well the models will generalize to future disasters by training and testing\nmodels on different disaster events.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 22:03:49 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Xu", "Joseph Z.", ""], ["Lu", "Wenhan", ""], ["Li", "Zebo", ""], ["Khaitan", "Pranav", ""], ["Zaytseva", "Valeriya", ""]]}, {"id": "1910.06456", "submitter": "Shaika Chowdhury", "authors": "Shaika Chowdhury, Chenwei Zhang, Philip S.Yu and Yuan Luo", "title": "Mixed Pooling Multi-View Attention Autoencoder for Representation\n  Learning in Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representations have been used to support downstream tasks in\nhealthcare recently. Healthcare data (e.g., electronic health records) contain\nmultiple modalities of data from heterogeneous sources that can provide\ncomplementary information, alongside an added dimension to learning\npersonalized patient representations. To this end, in this paper we propose a\nnovel unsupervised encoder-decoder model, namely Mixed Pooling Multi-View\nAttention Autoencoder (MPVAA), that generates patient representations\nencapsulating a holistic view of their medical profile. Specifically, by first\nlearning personalized graph embeddings pertaining to each patient's\nheterogeneous healthcare data, it then integrates the non-linear relationships\namong them into a unified representation through multi-view attention\nmechanism. Additionally, a mixed pooling strategy is incorporated in the\nencoding step to learn diverse information specific to each data modality.\nExperiments conducted for multiple tasks demonstrate the effectiveness of the\nproposed model over the state-of-the-art representation learning methods in\nhealthcare.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 22:59:51 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Chowdhury", "Shaika", ""], ["Zhang", "Chenwei", ""], ["Yu", "Philip S.", ""], ["Luo", "Yuan", ""]]}, {"id": "1910.06458", "submitter": "Ali Mirzaeian", "authors": "Ali Mirzaeian, Houman Homayoun, Avesta Sasan", "title": "TCD-NPE: A Re-configurable and Efficient Neural Processing Engine,\n  Powered by Novel Temporal-Carry-deferring MACs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we first propose the design of Temporal-Carry-deferring MAC\n(TCD-MAC) and illustrate how our proposed solution can gain significant energy\nand performance benefit when utilized to process a stream of input data. We\nthen propose using the TCD-MAC to build a reconfigurable, high speed, and low\npower Neural Processing Engine (TCD-NPE). We, further, propose a novel\nscheduler that lists the sequence of needed processing events to process an MLP\nmodel in the least number of computational rounds in our proposed TCD-NPE. We\nillustrate that our proposed TCD-NPE significantly outperform similar neural\nprocessing solutions that use conventional MACs in terms of both energy\nconsumption and execution time.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 23:05:34 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Mirzaeian", "Ali", ""], ["Homayoun", "Houman", ""], ["Sasan", "Avesta", ""]]}, {"id": "1910.06464", "submitter": "Cristina Garbacea", "authors": "Cristina G\\^arbacea, A\\\"aron van den Oord, Yazhe Li, Felicia S C Lim,\n  Alejandro Luebs, Oriol Vinyals, Thomas C Walters", "title": "Low Bit-Rate Speech Coding with VQ-VAE and a WaveNet Decoder", "comments": "ICASSP 2019", "journal-ref": "ICASSP 2019-2019 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), pp. 735-739. IEEE, 2019", "doi": "10.1109/ICASSP.2019.8683277", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to efficiently transmit and store speech signals, speech codecs\ncreate a minimally redundant representation of the input signal which is then\ndecoded at the receiver with the best possible perceptual quality. In this work\nwe demonstrate that a neural network architecture based on VQ-VAE with a\nWaveNet decoder can be used to perform very low bit-rate speech coding with\nhigh reconstruction quality. A prosody-transparent and speaker-independent\nmodel trained on the LibriSpeech corpus coding audio at 1.6 kbps exhibits\nperceptual quality which is around halfway between the MELP codec at 2.4 kbps\nand AMR-WB codec at 23.05 kbps. In addition, when training on high-quality\nrecorded speech with the test speaker included in the training set, a model\ncoding speech at 1.6 kbps produces output of similar perceptual quality to that\ngenerated by AMR-WB at 23.05 kbps.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 23:54:08 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["G\u00e2rbacea", "Cristina", ""], ["Oord", "A\u00e4ron van den", ""], ["Li", "Yazhe", ""], ["Lim", "Felicia S C", ""], ["Luebs", "Alejandro", ""], ["Vinyals", "Oriol", ""], ["Walters", "Thomas C", ""]]}, {"id": "1910.06466", "submitter": "Alexander Wong", "authors": "Mohammad Javad Shafiee, Andrew Hryniowski, Francis Li, Zhong Qiu Lin,\n  and Alexander Wong", "title": "State of Compact Architecture Search For Deep Neural Networks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of compact deep neural networks is a crucial task to enable\nwidespread adoption of deep neural networks in the real-world, particularly for\nedge and mobile scenarios. Due to the time-consuming and challenging nature of\nmanually designing compact deep neural networks, there has been significant\nrecent research interest into algorithms that automatically search for compact\nnetwork architectures. A particularly interesting class of compact architecture\nsearch algorithms are those that are guided by baseline network architectures.\nSuch algorithms have been shown to be significantly more computationally\nefficient than unguided methods. In this study, we explore the current state of\ncompact architecture search for deep neural networks through both theoretical\nand empirical analysis of four different state-of-the-art compact architecture\nsearch algorithms: i) group lasso regularization, ii) variational dropout, iii)\nMorphNet, and iv) Generative Synthesis. We examine these methods in detail\nbased on a number of different factors such as efficiency, effectiveness, and\nscalability. Furthermore, empirical evaluations are conducted to compare the\nefficacy of these compact architecture search algorithms across three\nwell-known benchmark datasets. While by no means an exhaustive exploration, we\nhope that this study helps provide insights into the interesting state of this\nrelatively new area of research in terms of diversity and real, tangible gains\nalready achieved in architecture design improvements. Furthermore, the hope is\nthat this study would help in pushing the conversation forward towards a deeper\ntheoretical and empirical understanding where the research community currently\nstands in the landscape of compact architecture search for deep neural\nnetworks, and the practical challenges and considerations in leveraging such\napproaches for operational usage.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 00:16:52 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Shafiee", "Mohammad Javad", ""], ["Hryniowski", "Andrew", ""], ["Li", "Francis", ""], ["Lin", "Zhong Qiu", ""], ["Wong", "Alexander", ""]]}, {"id": "1910.06489", "submitter": "Sneha Aenugu", "authors": "Sneha Aenugu, Abhishek Sharma, Sasikiran Yelamarthi, Hananel Hazan,\n  Philip S. Thomas, Robert Kozma", "title": "Reinforcement learning with a network of spiking agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscientific theory suggests that dopaminergic neurons broadcast global\nreward prediction errors to large areas of the brain influencing the synaptic\nplasticity of the neurons in those regions. We build on this theory to propose\na multi-agent learning framework with spiking neurons in the generalized linear\nmodel (GLM) formulation as agents, to solve reinforcement learning (RL) tasks.\nWe show that a network of GLM spiking agents connected in a hierarchical\nfashion, where each spiking agent modulates its firing policy based on local\ninformation and a global prediction error, can learn complex action\nrepresentations to solve RL tasks. We further show how leveraging principles of\nmodularity and population coding inspired from the brain can help reduce\nvariance in the learning updates making it a viable optimization technique.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 02:27:18 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 15:12:39 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 22:19:56 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Aenugu", "Sneha", ""], ["Sharma", "Abhishek", ""], ["Yelamarthi", "Sasikiran", ""], ["Hazan", "Hananel", ""], ["Thomas", "Philip S.", ""], ["Kozma", "Robert", ""]]}, {"id": "1910.06492", "submitter": "Shaika Chowdhury", "authors": "Shaika Chowdhury, Chenwei Zhang, Philip S.Yu and Yuan Luo", "title": "Hierarchical Semantic Correspondence Learning for Post-Discharge Patient\n  Mortality Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting patient mortality is an important and challenging problem in the\nhealthcare domain, especially for intensive care unit (ICU) patients.\nElectronic health notes serve as a rich source for learning patient\nrepresentations, that can facilitate effective risk assessment. However, a\nlarge portion of clinical notes are unstructured and also contain domain\nspecific terminologies, from which we need to extract structured information.\nIn this paper, we introduce an embedding framework to learn\nsemantically-plausible distributed representations of clinical notes that\nexploits the semantic correspondence between the unstructured texts and their\ncorresponding structured knowledge, known as semantic frame, in a hierarchical\nfashion. Our approach integrates text modeling and semantic correspondence\nlearning into a single model that comprises 1) an unstructured embedding module\nthat makes use of self-similarity matrix representations in order to inject\nstructural regularities of different segments inherent in clinical texts to\npromote local coherence, 2) a structured embedding module to embed the semantic\nframes (e.g., UMLS semantic types) with deep ConvNet and 3) a hierarchical\nsemantic correspondence module that embeds by enhancing the interactions\nbetween text-semantic frame embedding pairs at multiple levels (i.e., words,\nsentence, note). Evaluations on multiple embedding benchmarks on post discharge\nintensive care patient mortality prediction tasks demonstrate its effectiveness\ncompared to approaches that do not exploit the semantic interactions between\nstructured and unstructured information present in clinical notes.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 02:40:29 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Chowdhury", "Shaika", ""], ["Zhang", "Chenwei", ""], ["Yu", "Philip S.", ""], ["Luo", "Yuan", ""]]}, {"id": "1910.06508", "submitter": "Yao Liu", "authors": "Yao Liu, Pierre-Luc Bacon, Emma Brunskill", "title": "Understanding the Curse of Horizon in Off-Policy Evaluation via\n  Conditional Importance Sampling", "comments": "Accepted by ICML 2020, 21 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy policy estimators that use importance sampling (IS) can suffer\nfrom high variance in long-horizon domains, and there has been particular\nexcitement over new IS methods that leverage the structure of Markov decision\nprocesses. We analyze the variance of the most popular approaches through the\nviewpoint of conditional Monte Carlo. Surprisingly, we find that in finite\nhorizon MDPs there is no strict variance reduction of per-decision importance\nsampling or stationary importance sampling, comparing with vanilla importance\nsampling. We then provide sufficient conditions under which the per-decision or\nstationary estimators will provably reduce the variance over importance\nsampling with finite horizons. For the asymptotic (in terms of horizon $T$)\ncase, we develop upper and lower bounds on the variance of those estimators\nwhich yields sufficient conditions under which there exists an exponential v.s.\npolynomial gap between the variance of importance sampling and that of the\nper-decision or stationary estimators. These results help advance our\nunderstanding of if and when new types of IS estimators will improve the\naccuracy of off-policy estimation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 03:35:30 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 01:09:35 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Liu", "Yao", ""], ["Bacon", "Pierre-Luc", ""], ["Brunskill", "Emma", ""]]}, {"id": "1910.06509", "submitter": "Kaixuan Zhang", "authors": "Kaixuan Zhang, Qinglong Wang, Xue Liu, C. Lee Giles", "title": "Shapley Homology: Topological Analysis of Sample Influence for Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data samples collected for training machine learning models are typically\nassumed to be independent and identically distributed (iid). Recent research\nhas demonstrated that this assumption can be problematic as it simplifies the\nmanifold of structured data. This has motivated different research areas such\nas data poisoning, model improvement, and explanation of machine learning\nmodels. In this work, we study the influence of a sample on determining the\nintrinsic topological features of its underlying manifold. We propose the\nShapley Homology framework, which provides a quantitative metric for the\ninfluence of a sample of the homology of a simplicial complex. By interpreting\nthe influence as a probability measure, we further define an entropy which\nreflects the complexity of the data manifold. Our empirical studies show that\nwhen using the 0-dimensional homology, on neighboring graphs, samples with\nhigher influence scores have more impact on the accuracy of neural networks for\ndetermining the graph connectivity and on several regular grammars whose higher\nentropy values imply more difficulty in being learned.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 03:40:45 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Zhang", "Kaixuan", ""], ["Wang", "Qinglong", ""], ["Liu", "Xue", ""], ["Giles", "C. Lee", ""]]}, {"id": "1910.06511", "submitter": "Ling-Xiao Zhang", "authors": "Lin Gao, Ling-Xiao Zhang, Hsien-Yu Meng, Yi-Hui Ren, Yu-Kun Lai, Leif\n  Kobbelt", "title": "PRS-Net: Planar Reflective Symmetry Detection Net for 3D Models", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In geometry processing, symmetry is a universal type of high-level structural\ninformation of 3D models and benefits many geometry processing tasks including\nshape segmentation, alignment, matching, and completion. Thus it is an\nimportant problem to analyze various symmetry forms of 3D shapes. Planar\nreflective symmetry is the most fundamental one. Traditional methods based on\nspatial sampling can be time-consuming and may not be able to identify all the\nsymmetry planes. In this paper, we present a novel learning framework to\nautomatically discover global planar reflective symmetry of a 3D shape. Our\nframework trains an unsupervised 3D convolutional neural network to extract\nglobal model features and then outputs possible global symmetry parameters,\nwhere input shapes are represented using voxels. We introduce a dedicated\nsymmetry distance loss along with a regularization loss to avoid generating\nduplicated symmetry planes. Our network can also identify generalized cylinders\nby predicting their rotation axes. We further provide a method to remove\ninvalid and duplicated planes and axes. We demonstrate that our method is able\nto produce reliable and accurate results. Our neural network based method is\nhundreds of times faster than the state-of-the-art methods, which are based on\nsampling. Our method is also robust even with noisy or incomplete input\nsurfaces.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 03:46:58 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 04:05:15 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 06:55:05 GMT"}, {"version": "v4", "created": "Sat, 16 May 2020 02:21:17 GMT"}, {"version": "v5", "created": "Mon, 1 Jun 2020 11:54:32 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Gao", "Lin", ""], ["Zhang", "Ling-Xiao", ""], ["Meng", "Hsien-Yu", ""], ["Ren", "Yi-Hui", ""], ["Lai", "Yu-Kun", ""], ["Kobbelt", "Leif", ""]]}, {"id": "1910.06513", "submitter": "Xiangyi Chen", "authors": "Xiangyi Chen, Sijia Liu, Kaidi Xu, Xingguo Li, Xue Lin, Mingyi Hong,\n  David Cox", "title": "ZO-AdaMM: Zeroth-Order Adaptive Momentum Method for Black-Box\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adaptive momentum method (AdaMM), which uses past gradients to update\ndescent directions and learning rates simultaneously, has become one of the\nmost popular first-order optimization methods for solving machine learning\nproblems. However, AdaMM is not suited for solving black-box optimization\nproblems, where explicit gradient forms are difficult or infeasible to obtain.\nIn this paper, we propose a zeroth-order AdaMM (ZO-AdaMM) algorithm, that\ngeneralizes AdaMM to the gradient-free regime. We show that the convergence\nrate of ZO-AdaMM for both convex and nonconvex optimization is roughly a factor\nof $O(\\sqrt{d})$ worse than that of the first-order AdaMM algorithm, where $d$\nis problem size. In particular, we provide a deep understanding on why\nMahalanobis distance matters in convergence of ZO-AdaMM and other AdaMM-type\nmethods. As a byproduct, our analysis makes the first step toward understanding\nadaptive learning rate methods for nonconvex constrained optimization.\nFurthermore, we demonstrate two applications, designing per-image and universal\nadversarial attacks from black-box neural networks, respectively. We perform\nextensive experiments on ImageNet and empirically show that ZO-AdaMM converges\nmuch faster to a solution of high accuracy compared with $6$ state-of-the-art\nZO optimization methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 03:54:11 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 02:27:28 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Chen", "Xiangyi", ""], ["Liu", "Sijia", ""], ["Xu", "Kaidi", ""], ["Li", "Xingguo", ""], ["Lin", "Xue", ""], ["Hong", "Mingyi", ""], ["Cox", "David", ""]]}, {"id": "1910.06517", "submitter": "Yujia Jin", "authors": "Yujia Jin, Aaron Sidford", "title": "Principal Component Projection and Regression in Nearly Linear Time\n  through Asymmetric SVRG", "comments": "37 pages, 3 figures; to appear in NeurIPS '19 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a data matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$, principal\ncomponent projection (PCP) and principal component regression (PCR), i.e.\nprojection and regression restricted to the top-eigenspace of $\\mathbf{A}$, are\nfundamental problems in machine learning, optimization, and numerical analysis.\nIn this paper we provide the first algorithms that solve these problems in\nnearly linear time for fixed eigenvalue distribution and large n. This improves\nupon previous methods which have superlinear running times when both the number\nof top eigenvalues and inverse gap between eigenspaces is large. We achieve our\nresults by applying rational approximations to reduce PCP and PCR to solving\nasymmetric linear systems which we solve by a variant of SVRG. We corroborate\nthese findings with preliminary empirical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 04:02:53 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Jin", "Yujia", ""], ["Sidford", "Aaron", ""]]}, {"id": "1910.06521", "submitter": "Chelsea Sidrane", "authors": "Chelsea Sidrane, Dylan J Fitzpatrick, Andrew Annex, Diane O'Donoghue,\n  Yarin Gal, Piotr Bili\\'nski", "title": "Machine Learning for Generalizable Prediction of Flood Susceptibility", "comments": "Will be presented at hadri.ai 2019, a workshop at NeurIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flooding is a destructive and dangerous hazard and climate change appears to\nbe increasing the frequency of catastrophic flooding events around the world.\nPhysics-based flood models are costly to calibrate and are rarely generalizable\nacross different river basins, as model outputs are sensitive to site-specific\nparameters and human-regulated infrastructure. In contrast, statistical models\nimplicitly account for such factors through the data on which they are trained.\nSuch models trained primarily from remotely-sensed Earth observation data could\nreduce the need for extensive in-situ measurements. In this work, we develop\ngeneralizable, multi-basin models of river flooding susceptibility using\ngeographically-distributed data from the USGS stream gauge network. Machine\nlearning models are trained in a supervised framework to predict two measures\nof flood susceptibility from a mix of river basin attributes, impervious\nsurface cover information derived from satellite imagery, and historical\nrecords of rainfall and stream height. We report prediction performance of\nmultiple models using precision-recall curves, and compare with performance of\nnaive baselines. This work on multi-basin flood prediction represents a step in\nthe direction of making flood prediction accessible to all at-risk communities.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 04:31:39 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Sidrane", "Chelsea", ""], ["Fitzpatrick", "Dylan J", ""], ["Annex", "Andrew", ""], ["O'Donoghue", "Diane", ""], ["Gal", "Yarin", ""], ["Bili\u0144ski", "Piotr", ""]]}, {"id": "1910.06532", "submitter": "Bingcong Li", "authors": "Bingcong Li, Georgios B. Giannakis", "title": "Adaptive Step Sizes in Variance Reduction via Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this work is equipping convex and nonconvex problems with\nBarzilai-Borwein (BB) step size. With the adaptivity of BB step sizes granted,\nthey can fail when the objective function is not strongly convex. To overcome\nthis challenge, the key idea here is to bridge (non)convex problems and\nstrongly convex ones via regularization. The proposed regularization schemes\nare \\textit{simple} yet effective. Wedding the BB step size with a variance\nreduction method, known as SARAH, offers a free lunch compared with vanilla\nSARAH in convex problems. The convergence of BB step sizes in nonconvex\nproblems is also established and its complexity is no worse than other adaptive\nstep sizes such as AdaGrad. As a byproduct, our regularized SARAH methods for\nconvex functions ensure that the complexity to find $\\mathbb{E}[\\| \\nabla\nf(\\mathbf{x}) \\|^2]\\leq \\epsilon$ is ${\\cal O}\\big(\n(n+\\frac{1}{\\sqrt{\\epsilon}})\\ln{\\frac{1}{\\epsilon}}\\big)$, improving\n$\\epsilon$ dependence over existing results. Numerical tests further validate\nthe merits of proposed approaches.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 05:24:32 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Li", "Bingcong", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1910.06535", "submitter": "Tianyu Li", "authors": "Tianyu Li, Chien-Chih Wang, Yukun Ma, Patricia Ortal, Qifang Zhao,\n  Bjorn Stenger, Yu Hirate", "title": "Learning Classifiers on Positive and Unlabeled Data with Policy Gradient", "comments": "Proceedings of the IEEE International Conference on Data Mining, pp.\n  309-408, Beijing, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing algorithms aiming to learn a binary classifier from positive (P) and\nunlabeled (U) data generally require estimating the class prior or label noises\nahead of building a classification model. However, the estimation and\nclassifier learning are normally conducted in a pipeline instead of being\njointly optimized. In this paper, we propose to alternatively train the two\nsteps using reinforcement learning. Our proposal adopts a policy network to\nadaptively make assumptions on the labels of unlabeled data, while a classifier\nis built upon the output of the policy network and provides rewards to learn a\nbetter strategy. The dynamic and interactive training between the policy maker\nand the classifier can exploit the unlabeled data in a more effective manner\nand yield a significant improvement on the classification performance.\nFurthermore, we present two different approaches to represent the actions\nsampled from the policy. The first approach considers continuous actions as\nsoft labels, while the other uses discrete actions as hard assignment of labels\nfor unlabeled examples.We validate the effectiveness of the proposed method on\ntwo benchmark datasets as well as one e-commerce dataset. The result shows the\nproposed method is able to consistently outperform state-of-the-art methods in\nvarious settings.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 05:34:23 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 11:04:14 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Tianyu", ""], ["Wang", "Chien-Chih", ""], ["Ma", "Yukun", ""], ["Ortal", "Patricia", ""], ["Zhao", "Qifang", ""], ["Stenger", "Bjorn", ""], ["Hirate", "Yu", ""]]}, {"id": "1910.06539", "submitter": "Theodore Papamarkou", "authors": "Theodore Papamarkou and Jacob Hinkle and M. Todd Young and David\n  Womble", "title": "Challenges in Markov chain Monte Carlo for Bayesian neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo (MCMC) methods have not been broadly adopted in\nBayesian neural networks (BNNs). This paper initially reviews the main\nchallenges in sampling from the parameter posterior of a neural network via\nMCMC. Such challenges culminate to lack of convergence to the parameter\nposterior. Nevertheless, this paper shows that a non-converged Markov chain,\ngenerated via MCMC sampling from the parameter space of a neural network, can\nyield via Bayesian marginalization a valuable predictive posterior of the\noutput of the neural network. Classification examples based on multilayer\nperceptrons showcase highly accurate predictive posteriors. The postulate of\nlimited scope for MCMC developments in BNNs is partially valid; an\nasymptotically exact parameter posterior seems less plausible, yet an accurate\npredictive posterior is a tenable research avenue.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 05:43:45 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 18:02:21 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 03:37:55 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 10:39:02 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Papamarkou", "Theodore", ""], ["Hinkle", "Jacob", ""], ["Young", "M. Todd", ""], ["Womble", "David", ""]]}, {"id": "1910.06541", "submitter": "Xuewei Ma", "authors": "Xuewei Ma, Geng Qin, Zhiyang Qiu, Mingxin Zheng, Zhe Wang", "title": "RiWalk: Fast Structural Node Embedding via Role Identification", "comments": "Accepted as a regular paper at IEEE ICDM 2019. 10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nodes performing different functions in a network have different roles, and\nthese roles can be gleaned from the structure of the network. Learning latent\nrepresentations for the roles of nodes helps to understand the network and to\ntransfer knowledge across networks. However, most existing structural embedding\napproaches suffer from high computation and space cost or rely on heuristic\nfeature engineering. Here we propose RiWalk, a flexible paradigm for learning\nstructural node representations. It decouples the structural embedding problem\ninto a role identification procedure and a network embedding procedure. Through\nrole identification, rooted kernels with structural dependencies kept are built\nto better integrate network embedding methods. To demonstrate the effectiveness\nof RiWalk, we develop two different role identification methods named RiWalk-SP\nand RiWalk-WL respectively and employ random walk based network embedding\nmethods. Experiments on within-network classification tasks show that our\nproposed algorithms achieve comparable performance with other baselines while\nbeing an order of magnitude more efficient. Besides, we also conduct\nacross-network role classification tasks. The results show potential of\nstructural embeddings in transfer learning. RiWalk is also scalable, making it\ncapable of capturing structural roles in massive networks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 05:47:24 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Ma", "Xuewei", ""], ["Qin", "Geng", ""], ["Qiu", "Zhiyang", ""], ["Zheng", "Mingxin", ""], ["Wang", "Zhe", ""]]}, {"id": "1910.06548", "submitter": "Zissis Poulos", "authors": "Zissis Poulos, Ali Nouri, Andreas Moshovos", "title": "Training CNNs faster with Dynamic Input and Kernel Downsampling", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reduce training time in convolutional networks (CNNs) with a method that,\nfor some of the mini-batches: a) scales down the resolution of input images via\ndownsampling, and b) reduces the forward pass operations via pooling on the\nconvolution filters. Training is performed in an interleaved fashion; some\nbatches undergo the regular forward and backpropagation passes with original\nnetwork parameters, whereas others undergo a forward pass with pooled filters\nand downsampled inputs. Since pooling is differentiable, the gradients of the\npooled filters propagate to the original network parameters for a standard\nparameter update. The latter phase requires fewer floating point operations and\nless storage due to the reduced spatial dimensions in feature maps and filters.\nThe key idea is that this phase leads to smaller and approximate updates and\nthus slower learning, but at significantly reduced cost, followed by passes\nthat use the original network parameters as a refinement stage. Deciding how\noften and for which batches the downsmapling occurs can be done either\nstochastically or deterministically, and can be defined as a training\nhyperparameter itself. Experiments on residual architectures show that we can\nachieve up to 23% reduction in training time with minimal loss in validation\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 06:18:29 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Poulos", "Zissis", ""], ["Nouri", "Ali", ""], ["Moshovos", "Andreas", ""]]}, {"id": "1910.06552", "submitter": "Masaaki Imaizumi", "authors": "Akiyoshi Sannai, Masaaki Imaizumi, Makoto Kawano", "title": "Improved Generalization Bounds of Group Invariant / Equivariant Deep\n  Networks via Quotient Feature Spaces", "comments": "Old title: \"Improved Generalization Bound of Permutation Invariant\n  Deep Neural Networks\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous invariant (or equivariant) neural networks have succeeded in\nhandling invariant data such as point clouds and graphs. However, a\ngeneralization theory for the neural networks has not been well developed,\nbecause several essential factors for the theory, such as network size and\nmargin distribution, are not deeply connected to the invariance and\nequivariance. In this study, we develop a novel generalization error bound for\ninvariant and equivariant deep neural networks. To describe the effect of\ninvariance and equivariance on generalization, we develop a notion of a\n\\textit{quotient feature space}, which measures the effect of group actions for\nthe properties. Our main result proves that the volume of quotient feature\nspaces can describe the generalization error. Furthermore, the bound shows that\nthe invariance and equivariance significantly improve the leading term of the\nbound. We apply our result to specific invariant and equivariant networks, such\nas DeepSets (Zaheer et al. (2017)), and show that their generalization bound is\nconsiderably improved by $\\sqrt{n!}$, where $n!$ is the number of permutations.\nWe also discuss the expressive power of invariant DNNs and show that they can\nachieve an optimal approximation rate. Our experimental result supports our\ntheoretical claims.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 06:24:53 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 12:56:51 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 15:53:54 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Sannai", "Akiyoshi", ""], ["Imaizumi", "Masaaki", ""], ["Kawano", "Makoto", ""]]}, {"id": "1910.06560", "submitter": "Francesco Zola", "authors": "Francesco Zola, Maria Eguimendia, Jan Lukas Bruse and Raul Orduna\n  Urrutia", "title": "Cascading Machine Learning to Attack Bitcoin Anonymity", "comments": "15 pages,7 figures, 4 tables, presented in 2019 IEEE International\n  Conference on Blockchain (Blockchain)", "journal-ref": null, "doi": "10.1109/Blockchain.2019.00011", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is a decentralized, pseudonymous cryptocurrency that is one of the\nmost used digital assets to date. Its unregulated nature and inherent anonymity\nof users have led to a dramatic increase in its use for illicit activities.\nThis calls for the development of novel methods capable of characterizing\ndifferent entities in the Bitcoin network. In this paper, a method to attack\nBitcoin anonymity is presented, leveraging a novel cascading machine learning\napproach that requires only a few features directly extracted from Bitcoin\nblockchain data. Cascading, used to enrich entities information with data from\nprevious classifications, led to considerably improved multi-class\nclassification performance with excellent values of Precision close to 1.0 for\neach considered class. Final models were implemented and compared using\ndifferent machine learning models and showed significantly higher accuracy\ncompared to their baseline implementation. Our approach can contribute to the\ndevelopment of effective tools for Bitcoin entity characterization, which may\nassist in uncovering illegal activities.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 06:55:31 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Zola", "Francesco", ""], ["Eguimendia", "Maria", ""], ["Bruse", "Jan Lukas", ""], ["Urrutia", "Raul Orduna", ""]]}, {"id": "1910.06562", "submitter": "Cheng-En Wu", "authors": "Steven C.Y. Hung, Cheng-Hao Tu, Cheng-En Wu, Chien-Hung Chen, Yi-Ming\n  Chan, Chu-Song Chen", "title": "Compacting, Picking and Growing for Unforgetting Continual Learning", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual lifelong learning is essential to many applications. In this paper,\nwe propose a simple but effective approach to continual deep learning. Our\napproach leverages the principles of deep model compression, critical weights\nselection, and progressive networks expansion. By enforcing their integration\nin an iterative manner, we introduce an incremental learning method that is\nscalable to the number of sequential tasks in a continual learning process. Our\napproach is easy to implement and owns several favorable characteristics.\nFirst, it can avoid forgetting (i.e., learn new tasks while remembering all\nprevious tasks). Second, it allows model expansion but can maintain the model\ncompactness when handling sequential tasks. Besides, through our compaction and\nselection/expansion mechanism, we show that the knowledge accumulated through\nlearning previous tasks is helpful to build a better model for the new tasks\ncompared to training the models independently with tasks. Experimental results\nshow that our approach can incrementally learn a deep model tackling multiple\ntasks without forgetting, while the model compactness is maintained with the\nperformance more satisfiable than individual task training.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 07:02:01 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 03:44:22 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 06:29:48 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Hung", "Steven C. Y.", ""], ["Tu", "Cheng-Hao", ""], ["Wu", "Cheng-En", ""], ["Chen", "Chien-Hung", ""], ["Chan", "Yi-Ming", ""], ["Chen", "Chu-Song", ""]]}, {"id": "1910.06569", "submitter": "Pablo Martinez Olmos", "authors": "Fernando Perez-Cruz, Pablo M. Olmos, Michael Minyi Zhang, and Howard\n  Huang", "title": "Probabilistic Time of Arrival Localization", "comments": "IEEE Signal Processing Letters, 2019", "journal-ref": null, "doi": "10.1109/LSP.2019.2944005", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we take a new approach for time of arrival geo-localization.\nWe show that the main sources of error in metropolitan areas are due to\nenvironmental imperfections that bias our solutions, and that we can rely on a\nprobabilistic model to learn and compensate for them. The resulting\nlocalization error is validated using measurements from a live LTE cellular\nnetwork to be less than 10 meters, representing an order-of-magnitude\nimprovement.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 07:43:53 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Perez-Cruz", "Fernando", ""], ["Olmos", "Pablo M.", ""], ["Zhang", "Michael Minyi", ""], ["Huang", "Howard", ""]]}, {"id": "1910.06588", "submitter": "Yuanyuan Wei", "authors": "Yuanyuan Wei, Julian Jang-Jaccard, Fariza Sabrina, Timothy McIntosh", "title": "MSD-Kmeans: A Novel Algorithm for Efficient Detection of Global and\n  Local Outliers", "comments": "12 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is a technique in data mining that aims to detect unusual\nor unexpected records in the dataset. Existing outlier detection algorithms\nhave different pros and cons and exhibit different sensitivity to noisy data\nsuch as extreme values. In this paper, we propose a novel cluster-based outlier\ndetection algorithm named MSD-Kmeans that combines the statistical method of\nMean and Standard Deviation (MSD) and the machine learning clustering algorithm\nK-means to detect outliers more accurately with the better control of extreme\nvalues. There are two phases in this combination method of MSD-Kmeans: (1)\napplying MSD algorithm to eliminate as many noisy data to minimize the\ninterference on clusters, and (2) applying K-means algorithm to obtain local\noptimal clusters. We evaluate our algorithm and demonstrate its effectiveness\nin the context of detecting possible overcharging of taxi fares, as greedy\ndishonest drivers may attempt to charge high fares by detouring. We compare the\nperformance indicators of MSD-Kmeans with those of other outlier detection\nalgorithms, such as MSD, K-means, Z-score, MIQR and LOF, and prove that the\nproposed MSD-Kmeans algorithm achieves the highest measure of precision,\naccuracy, and F-measure. We conclude that MSD-Kmeans can be used for effective\nand efficient outlier detection on data of varying quality on IoT devices.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 08:24:16 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Wei", "Yuanyuan", ""], ["Jang-Jaccard", "Julian", ""], ["Sabrina", "Fariza", ""], ["McIntosh", "Timothy", ""]]}, {"id": "1910.06591", "submitter": "Rapha\\\"el Marinier", "authors": "Lasse Espeholt, Rapha\\\"el Marinier, Piotr Stanczyk, Ke Wang, Marcin\n  Michalski", "title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central\n  Inference", "comments": "New version that includes changes made during the ICLR 2020 review\n  process (https://openreview.net/forum?id=rkgvXlrKwH)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a modern scalable reinforcement learning agent called SEED\n(Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we\nshow that it is not only possible to train on millions of frames per second but\nalso to lower the cost of experiments compared to current methods. We achieve\nthis with a simple architecture that features centralized inference and an\noptimized communication layer. SEED adopts two state of the art distributed\nalgorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is\nevaluated on Atari-57, DeepMind Lab and Google Research Football. We improve\nthe state of the art on Football and are able to reach state of the art on\nAtari-57 three times faster in wall-time. For the scenarios we consider, a 40%\nto 80% cost reduction for running experiments is achieved. The implementation\nalong with experiments is open-sourced so results can be reproduced and novel\nideas tried out.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 08:32:45 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 16:08:46 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Espeholt", "Lasse", ""], ["Marinier", "Rapha\u00ebl", ""], ["Stanczyk", "Piotr", ""], ["Wang", "Ke", ""], ["Michalski", "Marcin", ""]]}, {"id": "1910.06611", "submitter": "Imanol Schlag", "authors": "Imanol Schlag, Paul Smolensky, Roland Fernandez, Nebojsa Jojic,\n  J\\\"urgen Schmidhuber, Jianfeng Gao", "title": "Enhancing the Transformer with Explicit Relational Encoding for Math\n  Problem Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We incorporate Tensor-Product Representations within the Transformer in order\nto better support the explicit representation of relation structure. Our\nTensor-Product Transformer (TP-Transformer) sets a new state of the art on the\nrecently-introduced Mathematics Dataset containing 56 categories of free-form\nmath word-problems. The essential component of the model is a novel attention\nmechanism, called TP-Attention, which explicitly encodes the relations between\neach Transformer cell and the other cells from which values have been retrieved\nby attention. TP-Attention goes beyond linear combination of retrieved values,\nstrengthening representation-building and resolving ambiguities introduced by\nmultiple layers of standard attention. The TP-Transformer's attention maps give\nbetter insights into how it is capable of solving the Mathematics Dataset's\nchallenging problems. Pretrained models and code will be made available after\npublication.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 09:19:55 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 15:28:24 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Schlag", "Imanol", ""], ["Smolensky", "Paul", ""], ["Fernandez", "Roland", ""], ["Jojic", "Nebojsa", ""], ["Schmidhuber", "J\u00fcrgen", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1910.06640", "submitter": "Carlos Ruiz", "authors": "Andr\\'es M. Alonso, F. Javier Nogales and Carlos Ruiz", "title": "A Single Scalable LSTM Model for Short-Term Forecasting of Disaggregated\n  Electricity Loads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most electricity systems worldwide are deploying advanced metering\ninfrastructures to collect relevant operational data. In particular, smart\nmeters allow tracking electricity load consumption at a very disaggregated\nlevel and at high frequency rates. This data opens the possibility of\ndeveloping new forecasting models with a potential positive impact in\nelectricity systems. We present a general methodology that is able to process\nand forecast a large number of smart meter time series. Instead of using\ntraditional and univariate approaches, we develop a single but complex\nrecurrent neural-network model with long short-term memory that can capture\nindividual consumption patterns and also consumptions from different\nhouseholds. The resulting model can accurately predict future loads\n(short-term) of individual consumers, even if these were not included in the\noriginal training set. This entails a great potential for large scale\napplications as once the single network is trained, accurate individual\nforecast for new consumers can be obtained at almost no computational cost. The\nproposed model is tested under a large set of numerical experiments by using a\nreal-world dataset with thousands of disaggregated electricity consumption time\nseries. Furthermore, we explore how geo-demographic segmentation of consumers\nmay impact the forecasting accuracy of the model.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 10:33:34 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 10:42:47 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Alonso", "Andr\u00e9s M.", ""], ["Nogales", "F. Javier", ""], ["Ruiz", "Carlos", ""]]}, {"id": "1910.06663", "submitter": "Andrey Ignatov", "authors": "Andrey Ignatov, Radu Timofte, Andrei Kulik, Seungsoo Yang, Ke Wang,\n  Felix Baum, Max Wu, Lirong Xu, Luc Van Gool", "title": "AI Benchmark: All About Deep Learning on Smartphones in 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of mobile AI accelerators has been evolving rapidly in the\npast two years, nearly doubling with each new generation of SoCs. The current\n4th generation of mobile NPUs is already approaching the results of\nCUDA-compatible Nvidia graphics cards presented not long ago, which together\nwith the increased capabilities of mobile deep learning frameworks makes it\npossible to run complex and deep AI models on mobile devices. In this paper, we\nevaluate the performance and compare the results of all chipsets from Qualcomm,\nHiSilicon, Samsung, MediaTek and Unisoc that are providing hardware\nacceleration for AI inference. We also discuss the recent changes in the\nAndroid ML pipeline and provide an overview of the deployment of deep learning\nmodels on mobile devices. All numerical results provided in this paper can be\nfound and are regularly updated on the official project website:\nhttp://ai-benchmark.com.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 11:31:36 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Ignatov", "Andrey", ""], ["Timofte", "Radu", ""], ["Kulik", "Andrei", ""], ["Yang", "Seungsoo", ""], ["Wang", "Ke", ""], ["Baum", "Felix", ""], ["Wu", "Max", ""], ["Xu", "Lirong", ""], ["Van Gool", "Luc", ""]]}, {"id": "1910.06673", "submitter": "Tessa Van Der Heiden", "authors": "Tessa van der Heiden, Naveen Shankar Nagaraja, Christian Weiss,\n  Efstratios Gavves", "title": "SafeCritic: Collision-Aware Trajectory Prediction", "comments": "To Appear as workshop paper for the British Machine Vision Conference\n  (BMVC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Navigating complex urban environments safely is a key to realize fully\nautonomous systems. Predicting future locations of vulnerable road users, such\nas pedestrians and cyclists, thus, has received a lot of attention in the\nrecent years. While previous works have addressed modeling interactions with\nthe static (obstacles) and dynamic (humans) environment agents, we address an\nimportant gap in trajectory prediction. We propose SafeCritic, a model that\nsynergizes generative adversarial networks for generating multiple \"real\"\ntrajectories with reinforcement learning to generate \"safe\" trajectories. The\nDiscriminator evaluates the generated candidates on whether they are consistent\nwith the observed inputs. The Critic network is environmentally aware to prune\ntrajectories that are in collision or are in violation with the environment.\nThe auto-encoding loss stabilizes training and prevents mode-collapse. We\ndemonstrate results on two large scale data sets with a considerable\nimprovement over state-of-the-art. We also show that the Critic is able to\nclassify the safety of trajectories.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 12:15:19 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["van der Heiden", "Tessa", ""], ["Nagaraja", "Naveen Shankar", ""], ["Weiss", "Christian", ""], ["Gavves", "Efstratios", ""]]}, {"id": "1910.06693", "submitter": "Alejandro Cartas", "authors": "Alejandro Cartas and Jordi Luque and Petia Radeva and Carlos Segura\n  and Mariella Dimiccoli", "title": "Seeing and Hearing Egocentric Actions: How Much Can We Learn?", "comments": "Accepted for the Fifth International Workshop on Egocentric\n  Perception, Interaction and Computing (EPIC) at the International Conference\n  on Computer Vision (ICCV) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our interaction with the world is an inherently multimodal experience.\nHowever, the understanding of human-to-object interactions has historically\nbeen addressed focusing on a single modality. In particular, a limited number\nof works have considered to integrate the visual and audio modalities for this\npurpose. In this work, we propose a multimodal approach for egocentric action\nrecognition in a kitchen environment that relies on audio and visual\ninformation. Our model combines a sparse temporal sampling strategy with a late\nfusion of audio, spatial, and temporal streams. Experimental results on the\nEPIC-Kitchens dataset show that multimodal integration leads to better\nperformance than unimodal approaches. In particular, we achieved a 5.18%\nimprovement over the state of the art on verb classification.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 12:55:49 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Cartas", "Alejandro", ""], ["Luque", "Jordi", ""], ["Radeva", "Petia", ""], ["Segura", "Carlos", ""], ["Dimiccoli", "Mariella", ""]]}, {"id": "1910.06697", "submitter": "Anirban Panda", "authors": "Asad Ahmed, Pratham Tangri, Anirban Panda, Dhruv Ramani, Samarjit\n  Karmakar", "title": "VFNet: A Convolutional Architecture for Accent Classification", "comments": "Accepted at IEEE INDICON 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding accent is an issue which can derail any human-machine\ninteraction. Accent classification makes this task easier by identifying the\naccent being spoken by a person so that the correct words being spoken can be\nidentified by further processing, since same noises can mean entirely different\nwords in different accents of the same language. In this paper, we present\nVFNet (Variable Filter Net), a convolutional neural network (CNN) based\narchitecture which captures a hierarchy of features to beat the previous\nbenchmarks of accent classification, through a novel and elegant technique of\napplying variable filter sizes along the frequency band of the audio\nutterances.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 13:04:45 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Ahmed", "Asad", ""], ["Tangri", "Pratham", ""], ["Panda", "Anirban", ""], ["Ramani", "Dhruv", ""], ["Karmakar", "Samarjit", ""]]}, {"id": "1910.06699", "submitter": "Cesar Roberto De Souza", "authors": "C\\'esar Roberto de Souza, Adrien Gaidon, Yohann Cabon, Naila Murray,\n  Antonio Manuel L\\'opez", "title": "Generating Human Action Videos by Coupling 3D Game Engines and\n  Probabilistic Graphical Models", "comments": "Pre-print of the article accepted for publication in the Special\n  Issue on Generating Realistic Visual Data of Human Behavior of the\n  International Journal of Computer Vision (IJCV). arXiv admin note:\n  substantial text overlap with arXiv:1612.00881", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep video action recognition models have been highly successful in recent\nyears but require large quantities of manually annotated data, which are\nexpensive and laborious to obtain. In this work, we investigate the generation\nof synthetic training data for video action recognition, as synthetic data have\nbeen successfully used to supervise models for a variety of other computer\nvision tasks. We propose an interpretable parametric generative model of human\naction videos that relies on procedural generation, physics models and other\ncomponents of modern game engines. With this model we generate a diverse,\nrealistic, and physically plausible dataset of human action videos, called PHAV\nfor \"Procedural Human Action Videos\". PHAV contains a total of 39,982 videos,\nwith more than 1,000 examples for each of 35 action categories. Our video\ngeneration approach is not limited to existing motion capture sequences: 14 of\nthese 35 categories are procedurally defined synthetic actions. In addition,\neach video is represented with 6 different data modalities, including RGB,\noptical flow and pixel-level semantic labels. These modalities are generated\nalmost simultaneously using the Multiple Render Targets feature of modern GPUs.\nIn order to leverage PHAV, we introduce a deep multi-task (i.e. that considers\naction classes from multiple datasets) representation learning architecture\nthat is able to simultaneously learn from synthetic and real video datasets,\neven when their action categories differ. Our experiments on the UCF-101 and\nHMDB-51 benchmarks suggest that combining our large set of synthetic videos\nwith small real-world datasets can boost recognition performance. Our approach\nalso significantly outperforms video representations produced by fine-tuning\nstate-of-the-art unsupervised generative models of videos.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 11:51:24 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["de Souza", "C\u00e9sar Roberto", ""], ["Gaidon", "Adrien", ""], ["Cabon", "Yohann", ""], ["Murray", "Naila", ""], ["L\u00f3pez", "Antonio Manuel", ""]]}, {"id": "1910.06705", "submitter": "YoungJoon Yoo", "authors": "YoungJoon Yoo, Sanghyuk Chun, Sangdoo Yun, Jung-Woo Ha, Jaejun Yoo", "title": "Neural Approximation of an Auto-Regressive Process through Confidence\n  Guided Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generic confidence-based approximation that can be plugged in\nand simplify the auto-regressive generation process with a proved convergence.\nWe first assume that the priors of future samples can be generated in an\nindependently and identically distributed (i.i.d.) manner using an efficient\npredictor. Given the past samples and future priors, the mother AR model can\npost-process the priors while the accompanied confidence predictor decides\nwhether the current sample needs a resampling or not. Thanks to the i.i.d.\nassumption, the post-processing can update each sample in a parallel way, which\nremarkably accelerates the mother model. Our experiments on different data\ndomains including sequences and images show that the proposed method can\nsuccessfully capture the complex structures of the data and generate the\nmeaningful future samples with lower computational cost while preserving the\nsequential relationship of the data.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 13:11:24 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Yoo", "YoungJoon", ""], ["Chun", "Sanghyuk", ""], ["Yun", "Sangdoo", ""], ["Ha", "Jung-Woo", ""], ["Yoo", "Jaejun", ""]]}, {"id": "1910.06707", "submitter": "Junjie Yin", "authors": "Junjie Yin, Zixun Chen, Kelai Zhou, Chongyuan Yu", "title": "A Deep Learning Based Chatbot for Campus Psychological Therapy", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Evebot, an innovative, sequence to sequence\n(Seq2seq) based, fully generative conversational system for the diagnosis of\nnegative emotions and prevention of depression through positively suggestive\nresponses. The system consists of an assembly of deep-learning based models,\nincluding Bi-LSTM based model for detecting negative emotions of users and\nobtaining psychological counselling related corpus for training the chatbot,\nanti-language sequence to sequence neural network, and maximum mutual\ninformation (MMI) model. As adolescents are reluctant to show their negative\nemotions in physical interaction, traditional methods of emotion analysis and\ncomforting methods may not work. Therefore, this system puts emphasis on using\nvirtual platform to detect signs of depression or anxiety, channel adolescents'\nstress and mood, and thus prevent the emergence of mental illness. We launched\nthe integrated chatbot system onto an online platform for real-world campus\napplications. Through a one-month user study, we observe better results in the\nincrease in positivity than other public chatbots in the control group.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:34:28 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Yin", "Junjie", ""], ["Chen", "Zixun", ""], ["Zhou", "Kelai", ""], ["Yu", "Chongyuan", ""]]}, {"id": "1910.06711", "submitter": "Rithesh Kumar", "authors": "Kundan Kumar, Rithesh Kumar, Thibault de Boissiere, Lucas Gestin, Wei\n  Zhen Teoh, Jose Sotelo, Alexandre de Brebisson, Yoshua Bengio, Aaron\n  Courville", "title": "MelGAN: Generative Adversarial Networks for Conditional Waveform\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous works (Donahue et al., 2018a; Engel et al., 2019a) have found that\ngenerating coherent raw audio waveforms with GANs is challenging. In this\npaper, we show that it is possible to train GANs reliably to generate high\nquality coherent waveforms by introducing a set of architectural changes and\nsimple training techniques. Subjective evaluation metric (Mean Opinion Score,\nor MOS) shows the effectiveness of the proposed approach for high quality\nmel-spectrogram inversion. To establish the generality of the proposed\ntechniques, we show qualitative results of our model in speech synthesis, music\ndomain translation and unconditional music synthesis. We evaluate the various\ncomponents of the model through ablation studies and suggest a set of\nguidelines to design general purpose discriminators and generators for\nconditional sequence synthesis tasks. Our model is non-autoregressive, fully\nconvolutional, with significantly fewer parameters than competing models and\ngeneralizes to unseen speakers for mel-spectrogram inversion. Our pytorch\nimplementation runs at more than 100x faster than realtime on GTX 1080Ti GPU\nand more than 2x faster than real-time on CPU, without any hardware specific\noptimization tricks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:03:08 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 12:00:53 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 01:17:32 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Kumar", "Kundan", ""], ["Kumar", "Rithesh", ""], ["de Boissiere", "Thibault", ""], ["Gestin", "Lucas", ""], ["Teoh", "Wei Zhen", ""], ["Sotelo", "Jose", ""], ["de Brebisson", "Alexandre", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""]]}, {"id": "1910.06715", "submitter": "Jin Zhang", "authors": "Jin Zhang, Jingyue Li", "title": "Testing and verification of neural-network-based safety-critical control\n  software: A systematic literature review", "comments": "This paper had been submitted to Journal of Information and Software\n  Technology on April 20, 2019,Revised 5 December 2019, Accepted 6 March 2020,\n  Available online 7 March 2020", "journal-ref": null, "doi": "10.1016/j.infsof.2020.106296", "report-no": null, "categories": "cs.LG cs.SE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Neural Network (NN) algorithms have been successfully adopted in a\nnumber of Safety-Critical Cyber-Physical Systems (SCCPSs). Testing and\nVerification (T&V) of NN-based control software in safety-critical domains are\ngaining interest and attention from both software engineering and safety\nengineering researchers and practitioners. Objective: With the increase in\nstudies on the T&V of NN-based control software in safety-critical domains, it\nis important to systematically review the state-of-the-art T&V methodologies,\nto classify approaches and tools that are invented, and to identify challenges\nand gaps for future studies. Method: We retrieved 950 papers on the T&V of\nNN-based Safety-Critical Control Software (SCCS). To reach our result, we\nfiltered 83 primary papers published between 2001 and 2018, applied the\nthematic analysis approach for analyzing the data extracted from the selected\npapers, presented the classification of approaches, and identified challenges.\nConclusion: The approaches were categorized into five high-order themes:\nassuring robustness of NNs, assuring safety properties of NN-based control\nsoftware, improving the failure resilience of NNs, measuring and ensuring test\ncompleteness, and improving the interpretability of NNs. From the industry\nperspective, improving the interpretability of NNs is a crucial need in\nsafety-critical applications. We also investigated nine safety integrity\nproperties within four major safety lifecycle phases to investigate the\nachievement level of T&V goals in IEC 61508-3. Results show that correctness,\ncompleteness, freedom from intrinsic faults, and fault tolerance have drawn\nmost attention from the research community. However, little effort has been\ninvested in achieving repeatability; no reviewed study focused on precisely\ndefined testing configuration or on defense against common cause failure.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 03:54:05 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 05:17:59 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Zhang", "Jin", ""], ["Li", "Jingyue", ""]]}, {"id": "1910.06717", "submitter": "Kenton Murray", "authors": "Kenton Murray, Jeffery Kinnison, Toan Q. Nguyen, Walter Scheirer,\n  David Chiang", "title": "Auto-Sizing the Transformer Network: Improving Speed, Efficiency, and\n  Performance for Low-Resource Machine Translation", "comments": "The 3rd Workshop on Neural Generation and Translation (WNGT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence-to-sequence models, particularly the Transformer, are the\nstate of the art in machine translation. Yet these neural networks are very\nsensitive to architecture and hyperparameter settings. Optimizing these\nsettings by grid or random search is computationally expensive because it\nrequires many training runs. In this paper, we incorporate architecture search\ninto a single training run through auto-sizing, which uses regularization to\ndelete neurons in a network over the course of training. On very low-resource\nlanguage pairs, we show that auto-sizing can improve BLEU scores by up to 3.9\npoints while removing one-third of the parameters from the model.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 19:21:26 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Murray", "Kenton", ""], ["Kinnison", "Jeffery", ""], ["Nguyen", "Toan Q.", ""], ["Scheirer", "Walter", ""], ["Chiang", "David", ""]]}, {"id": "1910.06719", "submitter": "Bo-Hsiang (Andy) Tseng", "authors": "Bo-Hsiang Tseng, Pawe{\\l} Budzianowski, Yen-Chen Wu, Milica\n  Ga\\v{s}i\\'c", "title": "Tree-Structured Semantic Encoder with Knowledge Sharing for Domain\n  Adaptation in Natural Language Generation", "comments": "Published in SIGDIAL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation in natural language generation (NLG) remains challenging\nbecause of the high complexity of input semantics across domains and limited\ndata of a target domain. This is particularly the case for dialogue systems,\nwhere we want to be able to seamlessly include new domains into the\nconversation. Therefore, it is crucial for generation models to share knowledge\nacross domains for the effective adaptation from one domain to another. In this\nstudy, we exploit a tree-structured semantic encoder to capture the internal\nstructure of complex semantic representations required for multi-domain\ndialogues in order to facilitate knowledge sharing across domains. In addition,\na layer-wise attention mechanism between the tree encoder and the decoder is\nadopted to further improve the model's capability. The automatic evaluation\nresults show that our model outperforms previous methods in terms of the BLEU\nscore and the slot error rate, in particular when the adaptation data is\nlimited. In subjective evaluation, human judges tend to prefer the sentences\ngenerated by our model, rating them more highly on informativeness and\nnaturalness than other systems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:27:11 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Tseng", "Bo-Hsiang", ""], ["Budzianowski", "Pawe\u0142", ""], ["Wu", "Yen-Chen", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1910.06720", "submitter": "Ahmad Rashid", "authors": "Vasileios Lioutas, Ahmad Rashid, Krtin Kumar, Md Akmal Haidar and\n  Mehdi Rezagholizadeh", "title": "Improving Word Embedding Factorization for Compression Using Distilled\n  Nonlinear Neural Decomposition", "comments": "Accepted at Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word-embeddings are vital components of Natural Language Processing (NLP)\nmodels and have been extensively explored. However, they consume a lot of\nmemory which poses a challenge for edge deployment. Embedding matrices,\ntypically, contain most of the parameters for language models and about a third\nfor machine translation systems. In this paper, we propose Distilled Embedding,\nan (input/output) embedding compression method based on low-rank matrix\ndecomposition and knowledge distillation. First, we initialize the weights of\nour decomposed matrices by learning to reconstruct the full pre-trained\nword-embedding and then fine-tune end-to-end, employing knowledge distillation\non the factorized embedding. We conduct extensive experiments with various\ncompression rates on machine translation and language modeling, using different\ndata-sets with a shared word-embedding matrix for both embedding and vocabulary\nprojection matrices. We show that the proposed technique is simple to\nreplicate, with one fixed parameter controlling compression size, has higher\nBLEU score on translation and lower perplexity on language modeling compared to\ncomplex, difficult to tune state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:40:03 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 22:59:44 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Lioutas", "Vasileios", ""], ["Rashid", "Ahmad", ""], ["Kumar", "Krtin", ""], ["Haidar", "Md Akmal", ""], ["Rezagholizadeh", "Mehdi", ""]]}, {"id": "1910.06724", "submitter": "H{\\aa}vard Kvamme", "authors": "H{\\aa}vard Kvamme and {\\O}rnulf Borgan", "title": "Continuous and Discrete-Time Survival Prediction with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Application of discrete-time survival methods for continuous-time survival\nprediction is considered. For this purpose, a scheme for discretization of\ncontinuous-time data is proposed by considering the quantiles of the estimated\nevent-time distribution, and, for smaller data sets, it is found to be\npreferable over the commonly used equidistant scheme. Furthermore, two\ninterpolation schemes for continuous-time survival estimates are explored, both\nof which are shown to yield improved performance compared to the discrete-time\nestimates. The survival methods considered are based on the likelihood for\nright-censored survival data, and parameterize either the probability mass\nfunction (PMF) or the discrete-time hazard rate, both with neural networks.\nThrough simulations and study of real-world data, the hazard rate\nparametrization is found to perform slightly better than the parametrization of\nthe PMF. Inspired by these investigations, a continuous-time method is proposed\nby assuming that the continuous-time hazard rate is piecewise constant. The\nmethod, named PC-Hazard, is found to be highly competitive with the\naforementioned methods in addition to other methods for survival prediction\nfound in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 13:23:19 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Kvamme", "H\u00e5vard", ""], ["Borgan", "\u00d8rnulf", ""]]}, {"id": "1910.06737", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Yida Zhao, Yuqing Song, Qin Jin, Qi Wu", "title": "Integrating Temporal and Spatial Attentions for VATEX Video Captioning\n  Challenge 2019", "comments": "ICCV 2019 VATEX challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This notebook paper presents our model in the VATEX video captioning\nchallenge. In order to capture multi-level aspects in the video, we propose to\nintegrate both temporal and spatial attentions for video captioning. The\ntemporal attentive module focuses on global action movements while spatial\nattentive module enables to describe more fine-grained objects. Considering\nthese two types of attentive modules are complementary, we thus fuse them via a\nlate fusion strategy. The proposed model significantly outperforms baselines\nand achieves 73.4 CIDEr score on the testing set which ranks the second place\nat the VATEX video captioning challenge leaderboard 2019.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 13:45:30 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Chen", "Shizhe", ""], ["Zhao", "Yida", ""], ["Song", "Yuqing", ""], ["Jin", "Qin", ""], ["Wu", "Qi", ""]]}, {"id": "1910.06741", "submitter": "Luis Polanco", "authors": "Luis Polanco and Jose A. Perea", "title": "Adaptive template systems: Data-driven feature selection for learning\n  with persistence diagrams", "comments": "To appear in proceedings of IEEE ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG eess.IV math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction from persistence diagrams, as a tool to enrich machine\nlearning techniques, has received increasing attention in recent years. In this\npaper we explore an adaptive methodology to localize features in persistent\ndiagrams, which are then used in learning tasks. Specifically, we investigate\nthree algorithms, CDER, GMM and HDBSCAN, to obtain adaptive template\nfunctions/features. Said features are evaluated in three classification\nexperiments with persistence diagrams. Namely, manifold, human shapes and\nprotein classification. The main conclusion of our analysis is that adaptive\ntemplate systems, as a feature extraction technique, yield competitive and\noften superior results in the studied examples. Moreover, from the adaptive\nalgorithms here studied, CDER consistently provides the most reliable and\nrobust adaptive featurization.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 04:15:31 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Polanco", "Luis", ""], ["Perea", "Jose A.", ""]]}, {"id": "1910.06742", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Generic Bounds on the Maximum Deviations in Sequential Prediction: An\n  Information-Theoretic Analysis", "comments": "arXiv admin note: text overlap with arXiv:1904.04765. text overlap\n  with arXiv:2001.03813", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive generic bounds on the maximum deviations in\nprediction errors for sequential prediction via an information-theoretic\napproach. The fundamental bounds are shown to depend only on the conditional\nentropy of the data point to be predicted given the previous data points. In\nthe asymptotic case, the bounds are achieved if and only if the prediction\nerror is white and uniformly distributed.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 23:31:17 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 18:54:54 GMT"}, {"version": "v3", "created": "Tue, 11 May 2021 15:01:04 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1910.06745", "submitter": "Yundong Zhang", "authors": "Yundong Zhang, Hang Wu, Huiye Liu, Li Tong and May D Wang", "title": "Improve Model Generalization and Robustness to Dataset Bias with\n  Bias-regularized Learning and Domain-guided Augmentation", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has thrived on the emergence of biomedical big data. However,\nmedical datasets acquired at different institutions have inherent bias caused\nby various confounding factors such as operation policies, machine protocols,\ntreatment preference and etc. As the result, models trained on one dataset,\nregardless of volume, cannot be confidently utilized for the others. In this\nstudy, we investigated model robustness to dataset bias using three large-scale\nChest X-ray datasets: first, we assessed the dataset bias using vanilla\ntraining baseline; second, we proposed a novel multi-source domain\ngeneralization model by (a) designing a new bias-regularized loss function; and\n(b) synthesizing new data for domain augmentation. We showed that our model\nsignificantly outperformed the baseline and other approaches on data from\nunseen domain in terms of accuracy and various bias measures, without\nretraining or finetuning. Our method is generally applicable to other\nbiomedical data, providing new algorithms for training models robust to bias\nfor big data analysis and applications. Demo training code is publicly\navailable.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 18:15:20 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 02:13:57 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 20:04:08 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Zhang", "Yundong", ""], ["Wu", "Hang", ""], ["Liu", "Huiye", ""], ["Tong", "Li", ""], ["Wang", "May D", ""]]}, {"id": "1910.06749", "submitter": "Shanshan Wang", "authors": "Yu Gong, Hongming Shan, Yueyang Teng, Ning Tu, Ming Li, Guodong Liang,\n  Ge Wang and Shanshan Wang", "title": "Parameter-Transferred Wasserstein Generative Adversarial Network\n  (PT-WGAN) for Low-Dose PET Image Denoising", "comments": "10 pages and 12 figures", "journal-ref": "IEEE Transactions on Radiation and Plasma Medical Sciences, 2021", "doi": "10.1109/TRPMS.2020.3025071", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the widespread use of positron emission tomography (PET) in clinical\npractice, the potential risk of PET-associated radiation dose to patients needs\nto be minimized. However, with the reduction in the radiation dose, the\nresultant images may suffer from noise and artifacts that compromise diagnostic\nperformance. In this paper, we propose a parameter-transferred Wasserstein\ngenerative adversarial network (PT-WGAN) for low-dose PET image denoising. The\ncontributions of this paper are twofold: i) a PT-WGAN framework is designed to\ndenoise low-dose PET images without compromising structural details, and ii) a\ntask-specific initialization based on transfer learning is developed to train\nPT-WGAN using trainable parameters transferred from a pretrained model, which\nsignificantly improves the training efficiency of PT-WGAN. The experimental\nresults on clinical data show that the proposed network can suppress image\nnoise more effectively while preserving better image fidelity than recently\npublished state-of-the-art methods. We make our code available at\nhttps://github.com/90n9-yu/PT-WGAN.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 02:41:04 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 08:49:23 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 06:09:12 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Gong", "Yu", ""], ["Shan", "Hongming", ""], ["Teng", "Yueyang", ""], ["Tu", "Ning", ""], ["Li", "Ming", ""], ["Liang", "Guodong", ""], ["Wang", "Ge", ""], ["Wang", "Shanshan", ""]]}, {"id": "1910.06750", "submitter": "Marija Jegorova", "authors": "Marija Jegorova, Antti Ilari Karjalainen, Jose Vazquez, Timothy\n  Hospedales", "title": "Full-Scale Continuous Synthetic Sonar Data Generation with Markov\n  Conditional Generative Adversarial Networks", "comments": "6 pages, 6 figures. Accepted to ICRA2020. 2020 IEEE International\n  Conference on Robotics and Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment and operation of autonomous underwater vehicles is expensive and\ntime-consuming. High-quality realistic sonar data simulation could be of\nbenefit to multiple applications, including training of human operators for\npost-mission analysis, as well as tuning and validation of autonomous target\nrecognition (ATR) systems for underwater vehicles. Producing realistic\nsynthetic sonar imagery is a challenging problem as the model has to account\nfor specific artefacts of real acoustic sensors, vehicle altitude, and a\nvariety of environmental factors. We propose a novel method for generating\nrealistic-looking sonar side-scans of full-length missions, called Markov\nConditional pix2pix (MC-pix2pix). Quantitative assessment results confirm that\nthe quality of the produced data is almost indistinguishable from real.\nFurthermore, we show that bootstrapping ATR systems with MC-pix2pix data can\nimprove the performance. Synthetic data is generated 18 times faster than real\nacquisition speed, with full user control over the topography of the generated\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 13:53:03 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 16:58:24 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Jegorova", "Marija", ""], ["Karjalainen", "Antti Ilari", ""], ["Vazquez", "Jose", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1910.06761", "submitter": "Boyan Xu", "authors": "Zijian Li, Ruichu Cai, Kok Soon Chai, Hong Wei Ng, Hoang Dung Vu,\n  Marianne Winslett, Tom Z. J. Fu, Boyan Xu, Xiaoyan Yang, Zhenjie Zhang", "title": "Causal Mechanism Transfer Network for Time Series Domain Adaptation in\n  Mechanical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven models are becoming essential parts in modern mechanical systems,\ncommonly used to capture the behavior of various equipment and varying\nenvironmental characteristics. Despite the advantages of these data-driven\nmodels on excellent adaptivity to high dynamics and aging equipment, they are\nusually hungry to massive labels over historical data, mostly contributed by\nhuman engineers at an extremely high cost. The label demand is now the major\nlimiting factor to modeling accuracy, hindering the fulfillment of visions for\napplications. Fortunately, domain adaptation enhances the model generalization\nby utilizing the labelled source data as well as the unlabelled target data and\nthen we can reuse the model on different domains. However, the mainstream\ndomain adaptation methods cannot achieve ideal performance on time series data,\nbecause most of them focus on static samples and even the existing time series\ndomain adaptation methods ignore the properties of time series data, such as\ntemporal causal mechanism. In this paper, we assume that causal mechanism is\ninvariant and present our Causal Mechanism Transfer Network(CMTN) for time\nseries domain adaptation. By capturing and transferring the dynamic and\ntemporal causal mechanism of multivariate time series data and alleviating the\ntime lags and different value ranges among different machines, CMTN allows the\ndata-driven models to exploit existing data and labels from similar systems,\nsuch that the resulting model on a new system is highly reliable even with very\nlimited data. We report our empirical results and lessons learned from two\nreal-world case studies, on chiller plant energy optimization and boiler fault\ndetection, which outperforms the existing state-of-the-art method.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 08:30:31 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Li", "Zijian", ""], ["Cai", "Ruichu", ""], ["Chai", "Kok Soon", ""], ["Ng", "Hong Wei", ""], ["Vu", "Hoang Dung", ""], ["Winslett", "Marianne", ""], ["Fu", "Tom Z. J.", ""], ["Xu", "Boyan", ""], ["Yang", "Xiaoyan", ""], ["Zhang", "Zhenjie", ""]]}, {"id": "1910.06764", "submitter": "Emilio Parisotto", "authors": "Emilio Parisotto, H. Francis Song, Jack W. Rae, Razvan Pascanu, Caglar\n  Gulcehre, Siddhant M. Jayakumar, Max Jaderberg, Raphael Lopez Kaufman, Aidan\n  Clark, Seb Noury, Matthew M. Botvinick, Nicolas Heess, Raia Hadsell", "title": "Stabilizing Transformers for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to their ability to both effectively integrate information over long\ntime horizons and scale to massive amounts of data, self-attention\narchitectures have recently shown breakthrough success in natural language\nprocessing (NLP), achieving state-of-the-art results in domains such as\nlanguage modeling and machine translation. Harnessing the transformer's ability\nto process long time horizons of information could provide a similar\nperformance boost in partially observable reinforcement learning (RL) domains,\nbut the large-scale transformers used in NLP have yet to be successfully\napplied to the RL setting. In this work we demonstrate that the standard\ntransformer architecture is difficult to optimize, which was previously\nobserved in the supervised learning setting but becomes especially pronounced\nwith RL objectives. We propose architectural modifications that substantially\nimprove the stability and learning speed of the original Transformer and XL\nvariant. The proposed architecture, the Gated Transformer-XL (GTrXL), surpasses\nLSTMs on challenging memory environments and achieves state-of-the-art results\non the multi-task DMLab-30 benchmark suite, exceeding the performance of an\nexternal memory architecture. We show that the GTrXL, trained using the same\nlosses, has stability and performance that consistently matches or exceeds a\ncompetitive LSTM baseline, including on more reactive tasks where memory is\nless critical. GTrXL offers an easy-to-train, simple-to-implement but\nsubstantially more expressive architectural alternative to the standard\nmulti-layer LSTM ubiquitously used for RL agents in partially observable\nenvironments.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 20:02:15 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Parisotto", "Emilio", ""], ["Song", "H. Francis", ""], ["Rae", "Jack W.", ""], ["Pascanu", "Razvan", ""], ["Gulcehre", "Caglar", ""], ["Jayakumar", "Siddhant M.", ""], ["Jaderberg", "Max", ""], ["Kaufman", "Raphael Lopez", ""], ["Clark", "Aidan", ""], ["Noury", "Seb", ""], ["Botvinick", "Matthew M.", ""], ["Heess", "Nicolas", ""], ["Hadsell", "Raia", ""]]}, {"id": "1910.06772", "submitter": "Jonathan Richens", "authors": "Jonathan G. Richens, Ciaran M. Lee, Saurabh Johri", "title": "Counterfactual diagnosis", "comments": "Restructured and new subsections. Improved figures. Introduction\n  rewritten", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning promises to revolutionize clinical decision making and\ndiagnosis. In medical diagnosis a doctor aims to explain a patient's symptoms\nby determining the diseases \\emph{causing} them. However, existing diagnostic\nalgorithms are purely associative, identifying diseases that are strongly\ncorrelated with a patients symptoms and medical history. We show that this\ninability to disentangle correlation from causation can result in sub-optimal\nor dangerous diagnoses. To overcome this, we reformulate diagnosis as a\ncounterfactual inference task and derive new counterfactual diagnostic\nalgorithms. We show that this approach is closer to the diagnostic reasoning of\nclinicians and significantly improves the accuracy and safety of the resulting\ndiagnoses. We compare our counterfactual algorithm to the standard Bayesian\ndiagnostic algorithm and a cohort of 44 doctors using a test set of clinical\nvignettes. While the Bayesian algorithm achieves an accuracy comparable to the\naverage doctor, placing in the top 48% of doctors in our cohort, our\ncounterfactual algorithm places in the top 25% of doctors, achieving expert\nclinical accuracy. This improvement is achieved simply by changing how we query\nour model, without requiring any additional model improvements. Our results\nshow that counterfactual reasoning is a vital missing ingredient for applying\nmachine learning to medical diagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 14:07:43 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 23:55:42 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 18:14:43 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Richens", "Jonathan G.", ""], ["Lee", "Ciaran M.", ""], ["Johri", "Saurabh", ""]]}, {"id": "1910.06784", "submitter": "Hyoungwoo Park", "authors": "Janghoon Cho, Sungrack Yun, Hyoungwoo Park, Jungyun Eum and Kyuwoong\n  Hwang", "title": "Acoustic Scene Classification Based on a Large-margin Factorized CNN", "comments": "5 pages, DCASE 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an acoustic scene classification framework based on\na large-margin factorized convolutional neural network (CNN). We adopt the\nfactorized CNN to learn the patterns in the time-frequency domain by\nfactorizing the 2D kernel into two separate 1D kernels. The factorized kernel\nleads to learn the main component of two patterns: the long-term ambient and\nshort-term event sounds which are the key patterns of the audio scene\nclassification. In training our model, we consider the loss function based on\nthe triplet sampling such that the same audio scene samples from different\nenvironments are minimized, and simultaneously the different audio scene\nsamples are maximized. With this loss function, the samples from the same audio\nscene are clustered independently of the environment, and thus we can get the\nclassifier with better generalization ability in an unseen environment. We\nevaluated our audio scene classification framework using the dataset of the\nDCASE challenge 2019 task1A. Experimental results show that the proposed\nalgorithm improves the performance of the baseline network and reduces the\nnumber of parameters to one third. Furthermore, the performance gain is higher\non unseen data, and it shows that the proposed algorithm has better\ngeneralization ability.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 07:47:15 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Cho", "Janghoon", ""], ["Yun", "Sungrack", ""], ["Park", "Hyoungwoo", ""], ["Eum", "Jungyun", ""], ["Hwang", "Kyuwoong", ""]]}, {"id": "1910.06788", "submitter": "Udesh Gunarathna", "authors": "Udesh Gunarathna, Hairuo Xie, Egemen Tanin, Shanika Karunasekara,\n  Renata Borovica-Gajic", "title": "Dynamic Graph Configuration with Reinforcement Learning for Connected\n  Autonomous Vehicle Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.DB cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional traffic optimization solutions assume that the graph structure of\nroad networks is static, missing opportunities for further traffic flow\noptimization. We are interested in optimizing traffic flows as a new type of\ngraph-based problem, where the graph structure of a road network can adapt to\ntraffic conditions in real time. In particular, we focus on the dynamic\nconfiguration of traffic-lane directions, which can help balance the usage of\ntraffic lanes in opposite directions. The rise of connected autonomous vehicles\noffers an opportunity to apply this type of dynamic traffic optimization at a\nlarge scale. The existing techniques for optimizing lane-directions are however\nnot suitable for dynamic traffic environments due to their high computational\ncomplexity and the static nature.\n  In this paper, we propose an efficient traffic optimization solution, called\nCoordinated Learning-based Lane Allocation (CLLA), which is suitable for\ndynamic configuration of lane-directions. CLLA consists of a two-layer\nmulti-agent architecture, where the bottom-layer agents use a machine learning\ntechnique to find a suitable configuration of lane-directions around individual\nroad intersections. The lane-direction changes proposed by the learning agents\nare then coordinated at a higher level to reduce the negative impact of the\nchanges on other parts of the road network. Our experimental results show that\nCLLA can reduce the average travel time significantly in congested road\nnetworks. We believe our method is general enough to be applied to other types\nof networks as well.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 14:22:01 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Gunarathna", "Udesh", ""], ["Xie", "Hairuo", ""], ["Tanin", "Egemen", ""], ["Karunasekara", "Shanika", ""], ["Borovica-Gajic", "Renata", ""]]}, {"id": "1910.06789", "submitter": "Surya Karthik Mukkavilli", "authors": "Caleb Hoyne, S. Karthik Mukkavilli and David Meger", "title": "Deep learning for Aerosol Forecasting", "comments": "Machine Learning and the Physical Sciences Workshop at the 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV physics.ao-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reanalysis datasets combining numerical physics models and limited\nobservations to generate a synthesised estimate of variables in an Earth\nsystem, are prone to biases against ground truth. Biases identified with the\nNASA Modern-Era Retrospective Analysis for Research and Applications, Version 2\n(MERRA-2) aerosol optical depth (AOD) dataset, against the Aerosol Robotic\nNetwork (AERONET) ground measurements in previous studies, motivated the\ndevelopment of a deep learning based AOD prediction model globally. This study\ncombines a convolutional neural network (CNN) with MERRA-2, tested against all\nAERONET sites. The new hybrid CNN-based model provides better estimates\nvalidated versus AERONET ground truth, than only using MERRA-2 reanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 17:35:08 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Hoyne", "Caleb", ""], ["Mukkavilli", "S. Karthik", ""], ["Meger", "David", ""]]}, {"id": "1910.06790", "submitter": "Hyoungwoo Park", "authors": "Hyoungwoo Park, Sungrack Yun, Jungyun Eum, Janghoon Cho and Kyuwoong\n  Hwang", "title": "Weakly Labeled Sound Event Detection Using Tri-training and Adversarial\n  Learning", "comments": "5 pages, DCASE 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a semi-supervised learning framework for weakly labeled\npolyphonic sound event detection problems for the DCASE 2019 challenge's task4\nby combining both the tri-training and adversarial learning. The goal of the\ntask4 is to detect onsets and offsets of multiple sound events in a single\naudio clip. The entire dataset consists of the synthetic data with a strong\nlabel (sound event labels with boundaries) and real data with weakly labeled\n(sound event labels) and unlabeled dataset. Given this dataset, we apply the\ntri-training where two different classifiers are used to obtain pseudo labels\non the weakly labeled and unlabeled dataset, and the final classifier is\ntrained using the strongly labeled dataset and weakly/unlabeled dataset with\npseudo labels. Also, we apply the adversarial learning to reduce the domain gap\nbetween the real and synthetic dataset. We evaluated our learning framework\nusing the validation set of the task4 dataset, and in the experiments, our\nlearning framework shows a considerable performance improvement over the\nbaseline model.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 07:47:55 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Park", "Hyoungwoo", ""], ["Yun", "Sungrack", ""], ["Eum", "Jungyun", ""], ["Cho", "Janghoon", ""], ["Hwang", "Kyuwoong", ""]]}, {"id": "1910.06792", "submitter": "Luchen Liu", "authors": "Luchen Liu, Haoxian Wu, Zichang Wang, Zequn Liu, Ming Zhang", "title": "Early Prediction of Sepsis From Clinical Datavia Heterogeneous Event\n  Aggregation", "comments": "4 pages, 2 figures, Accept by CINC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is a life-threatening condition that seriously endangers millions of\npeople over the world. Hopefully, with the widespread availability of\nelectronic health records (EHR), predictive models that can effectively deal\nwith clinical sequential data increase the possibility to predict sepsis and\ntake early preventive treatment. However, the early prediction is challenging\nbecause patients' sequential data in EHR contains temporal interactions of\nmultiple clinical events. And capturing temporal interactions in the long event\nsequence is hard for traditional LSTM. Rather than directly applying the LSTM\nmodel to the event sequences, our proposed model firstly aggregates\nheterogeneous clinical events in a short period and then captures temporal\ninteractions of the aggregated representations with LSTM. Our proposed\nHeterogeneous Event Aggregation can not only shorten the length of clinical\nevent sequence but also help to retain temporal interactions of both\ncategorical and numerical features of clinical events in the multiple heads of\nthe aggregation representations. In the PhysioNet/Computing in Cardiology\nChallenge 2019, with the team named PKU_DLIB, our proposed model, in high\nefficiency, achieved utility score (0.321) in the full test set.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 03:05:48 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Liu", "Luchen", ""], ["Wu", "Haoxian", ""], ["Wang", "Zichang", ""], ["Liu", "Zequn", ""], ["Zhang", "Ming", ""]]}, {"id": "1910.06799", "submitter": "Dinesh Verma", "authors": "D. Verma, S. Calo, S. Witherspoon, E. Bertino, A. Abu Jabal, A. Swami,\n  G. Cirincione, S. Julier, G. White, G. de Mel, G. Pearson", "title": "Federated Learning for Coalition Operations", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning in coalition settings requires combining insights available\nfrom data assets and knowledge repositories distributed across multiple\ncoalition partners. In tactical environments, this requires sharing the assets,\nknowledge and models in a bandwidth-constrained environment, while staying in\nconformance with the privacy, security and other applicable policies for each\ncoalition member. Federated Machine Learning provides an approach for such\nsharing. In its simplest version, federated machine learning could exchange\ntraining data available among the different coalition members, with each\npartner deciding which part of the training data from other partners to accept\nbased on the quality and value of the offered data. In a more sophisticated\nversion, coalition partners may exchange models learnt locally, which need to\nbe transformed, accepted in entirety or in part based on the quality and value\noffered by each model, and fused together into an integrated model. In this\npaper, we examine the challenges present in creating federated learning\nsolutions in coalition settings, and present the different flavors of federated\nlearning that we have created as part of our research in the DAIS ITA. The\nchallenges addressed include dealing with varying quality of data and models,\ndetermining the value offered by the data/model of each coalition partner,\naddressing the heterogeneity in data representation, labeling and AI model\narchitecture selected by different coalition members, and handling the varying\nlevels of trust present among members of the coalition. We also identify some\nopen problems that remain to be addressed to create a viable solution for\nfederated learning in coalition environments.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:40:10 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Verma", "D.", ""], ["Calo", "S.", ""], ["Witherspoon", "S.", ""], ["Bertino", "E.", ""], ["Jabal", "A. Abu", ""], ["Swami", "A.", ""], ["Cirincione", "G.", ""], ["Julier", "S.", ""], ["White", "G.", ""], ["de Mel", "G.", ""], ["Pearson", "G.", ""]]}, {"id": "1910.06809", "submitter": "Xihui Liu", "authors": "Xihui Liu, Guojun Yin, Jing Shao, Xiaogang Wang, Hongsheng Li", "title": "Learning to Predict Layout-to-image Conditional Convolutions for\n  Semantic Image Synthesis", "comments": "Accepted by NeurIPS 2019. Code is available soon at\n  https://github.com/xh-liu/CC-FPSE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic image synthesis aims at generating photorealistic images from\nsemantic layouts. Previous approaches with conditional generative adversarial\nnetworks (GAN) show state-of-the-art performance on this task, which either\nfeed the semantic label maps as inputs to the generator, or use them to\nmodulate the activations in normalization layers via affine transformations. We\nargue that convolutional kernels in the generator should be aware of the\ndistinct semantic labels at different locations when generating images. In\norder to better exploit the semantic layout for the image generator, we propose\nto predict convolutional kernels conditioned on the semantic label map to\ngenerate the intermediate feature maps from the noise maps and eventually\ngenerate the images. Moreover, we propose a feature pyramid semantics-embedding\ndiscriminator, which is more effective in enhancing fine details and semantic\nalignments between the generated images and the input semantic layouts than\nprevious multi-scale discriminators. We achieve state-of-the-art results on\nboth quantitative metrics and subjective evaluation on various semantic\nsegmentation datasets, demonstrating the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 14:33:07 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 08:09:58 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 15:29:28 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Liu", "Xihui", ""], ["Yin", "Guojun", ""], ["Shao", "Jing", ""], ["Wang", "Xiaogang", ""], ["Li", "Hongsheng", ""]]}, {"id": "1910.06813", "submitter": "Anindya Sarkar", "authors": "Anindya Sarkar, Anirudh Sunder Raj, Raghu Sesha Iyengar", "title": "ODE guided Neural Data Augmentation Techniques for Time Series Data and\n  its Benefits on Robustness", "comments": "8 pages, 5 figures, International Conference on Machine Learning and\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploring adversarial attack vectors and studying their effects on machine\nlearning algorithms has been of interest to researchers. Deep neural networks\nworking with time series data have received lesser interest compared to their\nimage counterparts in this context. In a recent finding, it has been revealed\nthat current state-of-the-art deep learning time series classifiers are\nvulnerable to adversarial attacks. In this paper, we introduce two local\ngradient based and one spectral density based time series data augmentation\ntechniques. We show that a model trained with data obtained using our\ntechniques obtains state-of-the-art classification accuracy on various time\nseries benchmarks. In addition, it improves the robustness of the model against\nsome of the most common corruption techniques,such as Fast Gradient Sign Method\n(FGSM) and Basic Iterative Method (BIM).\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 14:37:18 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 10:31:48 GMT"}, {"version": "v3", "created": "Sun, 27 Sep 2020 17:53:53 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Sarkar", "Anindya", ""], ["Raj", "Anirudh Sunder", ""], ["Iyengar", "Raghu Sesha", ""]]}, {"id": "1910.06816", "submitter": "Antoine Saporta", "authors": "Antoine Saporta, Yifu Chen, Michael Blot, Matthieu Cord", "title": "REVE: Regularizing Deep Learning with Variational Entropy Bound", "comments": "Published in 2019 IEEE International Conference on Image Processing\n  (ICIP)", "journal-ref": null, "doi": "10.1109/ICIP.2019.8804396", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on generalization performance of machine learning algorithms under\nthe scope of information theory suggest that compressed representations can\nguarantee good generalization, inspiring many compression-based regularization\nmethods. In this paper, we introduce REVE, a new regularization scheme. Noting\nthat compressing the representation can be sub-optimal, our first contribution\nis to identify a variable that is directly responsible for the final\nprediction. Our method aims at compressing the class conditioned entropy of\nthis latter variable. Second, we introduce a variational upper bound on this\nconditional entropy term. Finally, we propose a scheme to instantiate a\ntractable loss that is integrated within the training procedure of the neural\nnetwork and demonstrate its efficiency on different neural networks and\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 14:38:30 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Saporta", "Antoine", ""], ["Chen", "Yifu", ""], ["Blot", "Michael", ""], ["Cord", "Matthieu", ""]]}, {"id": "1910.06820", "submitter": "Vladimir Pestov", "authors": "Vladimir G. Pestov", "title": "Elementos da teoria de aprendizagem de m\\'aquina supervisionada", "comments": "390 pp. + vii, in Portuguese, a preliminary version, to be published\n  by IMPA as a book of lectures of the 23nd Brazilian Math Colloquium (July 28\n  - Aug 2, 2019), submitted to arXiv upon IMPA permission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a set of lecture notes for an introductory course (advanced\nundergaduates or the 1st graduate course) on foundations of supervised machine\nlearning (in Portuguese). The topics include: the geometry of the Hamming cube,\nconcentration of measure, shattering and VC dimension, Glivenko-Cantelli\nclasses, PAC learnability, universal consistency and the k-NN classifier in\nmetric spaces, dimensionality reduction, universal approximation, sample\ncompression. There are appendices on metric and normed spaces, measure theory,\netc., making the notes self-contained.\n  Este \\'e um conjunto de notas de aula para um curso introdut\\'orio (curso de\ngradua\\c{c}\\~ao avan\\c{c}ado ou o 1o curso de p\\'os) sobre fundamentos da\naprendizagem de m\\'aquina supervisionada (em Portugu\\^es). Os t\\'opicos\nincluem: a geometria do cubo de Hamming, concentra\\c{c}\\~ao de medida,\nfragmenta\\c{c}\\~ao e dimens\\~ao de Vapnik-Chervonenkis, classes de\nGlivenko-Cantelli, aprendizabilidade PAC, consist\\^encia universal e o\nclassificador k-NN em espa\\c{c}os m\\'etricos, redu\\c{c}\\~ao de\ndimensionalidade, aproxima\\c{c}\\~ao universal, compress\\~ao amostral. H\\'a\nap\\^endices sobre espa\\c{c}os m\\'etricos e normados, teoria de medida, etc.,\ntornando as notas autosuficientes.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 02:03:42 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Pestov", "Vladimir G.", ""]]}, {"id": "1910.06832", "submitter": "Akinori Tanaka", "authors": "Akinori Tanaka", "title": "Discriminator optimal transport", "comments": "github link added, NeurIPS2019", "journal-ref": null, "doi": null, "report-no": "RIKEN-iTHEMS-Report-19", "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within a broad class of generative adversarial networks, we show that\ndiscriminator optimization process increases a lower bound of the dual cost\nfunction for the Wasserstein distance between the target distribution $p$ and\nthe generator distribution $p_G$. It implies that the trained discriminator can\napproximate optimal transport (OT) from $p_G$ to $p$.Based on some experiments\nand a bit of OT theory, we propose a discriminator optimal transport (DOT)\nscheme to improve generated images. We show that it improves inception score\nand FID calculated by un-conditional GAN trained by CIFAR-10, STL-10 and a\npublic pre-trained model of conditional GAN by ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 14:47:37 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 17:18:07 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Tanaka", "Akinori", ""]]}, {"id": "1910.06838", "submitter": "Derui Derek Wang", "authors": "Derui (Derek) Wang, Chaoran Li, Sheng Wen, Surya Nepal, Yang Xiang", "title": "Man-in-the-Middle Attacks against Machine Learning Classifiers via\n  Malicious Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks (DNNs) are vulnerable to deliberately crafted\nadversarial examples. In the past few years, many efforts have been spent on\nexploring query-optimisation attacks to find adversarial examples of either\nblack-box or white-box DNN models, as well as the defending countermeasures\nagainst those attacks. In this work, we explore vulnerabilities of DNN models\nunder the umbrella of Man-in-the-Middle (MitM) attacks, which has not been\ninvestigated before. From the perspective of an MitM adversary, the\naforementioned adversarial example attacks are not viable anymore. First, such\nattacks must acquire the outputs from the models by multiple times before\nactually launching attacks, which is difficult for the MitM adversary in\npractice. Second, such attacks are one-off and cannot be directly generalised\nonto new data examples, which decreases the rate of return for the attacker. In\ncontrast, using generative models to craft adversarial examples on the fly can\nmitigate the drawbacks. However, the adversarial capability of the generative\nmodels, such as Variational Auto-Encoder (VAE), has not been extensively\nstudied. Therefore, given a classifier, we investigate using a VAE decoder to\neither transform benign inputs to their adversarial counterparts or decode\noutputs from benign VAE encoders to be adversarial examples. The proposed\nmethod can endue more capability to MitM attackers. Based on our evaluation,\nthe proposed attack can achieve above 95% success rate on both MNIST and\nCIFAR10 datasets, which is better or comparable with state-of-the-art\nquery-optimisation attacks. At the meantime, the attack is 104 times faster\nthan the query-optimisation attacks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 05:04:37 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Derui", "", "", "Derek"], ["Wang", "", ""], ["Li", "Chaoran", ""], ["Wen", "Sheng", ""], ["Nepal", "Surya", ""], ["Xiang", "Yang", ""]]}, {"id": "1910.06840", "submitter": "Marvin Chanc\\'an", "authors": "Marvin Chanc\\'an, Luis Hernandez-Nunez, Ajay Narendra, Andrew B.\n  Barron, Michael Milford", "title": "A Hybrid Compact Neural Architecture for Visual Place Recognition", "comments": "Preprint version of article published in IEEE Robotics and Automation\n  Letters", "journal-ref": "IEEE Robotics and Automation Letters, vol. 5, no. 2, pp. 993-1000,\n  April 2020", "doi": "10.1109/LRA.2020.2967324", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  State-of-the-art algorithms for visual place recognition, and related visual\nnavigation systems, can be broadly split into two categories:\ncomputer-science-oriented models including deep learning or image\nretrieval-based techniques with minimal biological plausibility, and\nneuroscience-oriented dynamical networks that model temporal properties\nunderlying spatial navigation in the brain. In this letter, we propose a new\ncompact and high-performing place recognition model that bridges this divide\nfor the first time. Our approach comprises two key neural models of these\ncategories: (1) FlyNet, a compact, sparse two-layer neural network inspired by\nbrain architectures of fruit flies, Drosophila melanogaster, and (2) a\none-dimensional continuous attractor neural network (CANN). The resulting\nFlyNet+CANN network incorporates the compact pattern recognition capabilities\nof our FlyNet model with the powerful temporal filtering capabilities of an\nequally compact CANN, replicating entirely in a hybrid neural implementation\nthe functionality that yields high performance in algorithmic localization\napproaches like SeqSLAM. We evaluate our model, and compare it to three\nstate-of-the-art methods, on two benchmark real-world datasets with small\nviewpoint variations and extreme environmental changes - achieving 87% AUC\nresults under day to night transitions compared to 60% for Multi-Process\nFusion, 46% for LoST-X and 1% for SeqSLAM, while being 6.5, 310, and 1.5 times\nfaster, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 14:58:54 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 10:21:22 GMT"}, {"version": "v3", "created": "Sun, 19 Jan 2020 09:18:47 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Chanc\u00e1n", "Marvin", ""], ["Hernandez-Nunez", "Luis", ""], ["Narendra", "Ajay", ""], ["Barron", "Andrew B.", ""], ["Milford", "Michael", ""]]}, {"id": "1910.06846", "submitter": "Dan Vilenchik", "authors": "Guy Holtzman, Adam Soffer and Dan Vilenchik", "title": "A greedy anytime algorithm for sparse PCA", "comments": "improving results", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The taxing computational effort that is involved in solving some\nhigh-dimensional statistical problems, in particular problems involving\nnon-convex optimization, has popularized the development and analysis of\nalgorithms that run efficiently (polynomial-time) but with no general guarantee\non statistical consistency. In light of the ever-increasing compute power and\ndecreasing costs, a more useful characterization of algorithms is by their\nability to calibrate the invested computational effort with various\ncharacteristics of the input at hand and with the available computational\nresources. For example, design an algorithm that always guarantees statistical\nconsistency of its output by increasing the running time as the SNR weakens. We\npropose a new greedy algorithm for the $\\ell_0$-sparse PCA problem which\nsupports the calibration principle. We provide both a rigorous analysis of our\nalgorithm in the spiked covariance model, as well as simulation results and\ncomparison with other existing methods. Our findings show that our algorithm\nrecovers the spike in SNR regimes where all polynomial-time algorithms fail\nwhile running in a reasonable parallel-time on a cluster.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:09:13 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 19:47:25 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 16:07:42 GMT"}, {"version": "v4", "created": "Wed, 5 Feb 2020 13:44:58 GMT"}, {"version": "v5", "created": "Wed, 12 Feb 2020 12:32:58 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Holtzman", "Guy", ""], ["Soffer", "Adam", ""], ["Vilenchik", "Dan", ""]]}, {"id": "1910.06849", "submitter": "Guohao Li", "authors": "Guohao Li, Matthias M\\\"uller, Guocheng Qian, Itzel C. Delgadillo,\n  Abdulellah Abualshour, Ali Thabet, Bernard Ghanem", "title": "DeepGCNs: Making GCNs Go as Deep as CNNs", "comments": "Accepted at TPAMI. This work is a journal extension of our ICCV'19\n  paper arXiv:1904.03751. The first three authors contributed equally", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3074057", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have been very successful at solving a\nvariety of computer vision tasks such as object classification and detection,\nsemantic segmentation, activity understanding, to name just a few. One key\nenabling factor for their great performance has been the ability to train very\ndeep networks. Despite their huge success in many tasks, CNNs do not work well\nwith non-Euclidean data, which is prevalent in many real-world applications.\nGraph Convolutional Networks (GCNs) offer an alternative that allows for\nnon-Eucledian data input to a neural network. While GCNs already achieve\nencouraging results, they are currently limited to architectures with a\nrelatively small number of layers, primarily due to vanishing gradients during\ntraining. This work transfers concepts such as residual/dense connections and\ndilated convolutions from CNNs to GCNs in order to successfully train very deep\nGCNs. We show the benefit of using deep GCNs (with as many as 112 layers)\nexperimentally across various datasets and tasks. Specifically, we achieve very\npromising performance in part segmentation and semantic segmentation on point\nclouds and in node classification of protein functions across biological\nprotein-protein interaction (PPI) graphs. We believe that the insights in this\nwork will open avenues for future research on GCNs and their application to\nfurther tasks not explored in this paper. The source code for this work is\navailable at https://github.com/lightaime/deep_gcns_torch and\nhttps://github.com/lightaime/deep_gcns for PyTorch and TensorFlow\nimplementation respectively.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:10:34 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 19:38:05 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 21:35:58 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Li", "Guohao", ""], ["M\u00fcller", "Matthias", ""], ["Qian", "Guocheng", ""], ["Delgadillo", "Itzel C.", ""], ["Abualshour", "Abdulellah", ""], ["Thabet", "Ali", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1910.06853", "submitter": "Nikolas Ioannou", "authors": "Andreea Anghel, Nikolas Ioannou, Thomas Parnell, Nikolaos Papandreou,\n  Celestine Mendler-D\\\"unner, Haris Pozidis", "title": "Breadth-first, Depth-next Training of Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze, evaluate, and improve the performance of training\nRandom Forest (RF) models on modern CPU architectures. An exact,\nstate-of-the-art binary decision tree building algorithm is used as the basis\nof this study. Firstly, we investigate the trade-offs between using different\ntree building algorithms, namely breadth-first-search (BFS) and\ndepth-search-first (DFS). We design a novel, dynamic, hybrid BFS-DFS algorithm\nand demonstrate that it performs better than both BFS and DFS, and is more\nrobust in the presence of workloads with different characteristics. Secondly,\nwe identify CPU performance bottlenecks when generating trees using this\napproach, and propose optimizations to alleviate them. The proposed hybrid tree\nbuilding algorithm for RF is implemented in the Snap Machine Learning\nframework, and speeds up the training of RFs by 7.8x on average when compared\nto state-of-the-art RF solvers (sklearn, H2O, and xgboost) on a range of\ndatasets, RF configurations, and multi-core CPU architectures.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:14:35 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Anghel", "Andreea", ""], ["Ioannou", "Nikolas", ""], ["Parnell", "Thomas", ""], ["Papandreou", "Nikolaos", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Pozidis", "Haris", ""]]}, {"id": "1910.06859", "submitter": "Hrishikesh Kulkarni", "authors": "Hrishikesh Kulkarni, P Joshi, P Chande", "title": "Computational Psychology to Embed Emotions into News or Advertisements\n  to Increase Reader Affinity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Readers take decisions about going through the complete news based on many\nfactors. The emotional impact of the news title on reader is one of the most\nimportant factors. Cognitive ergonomics tries to strike the balance between\nwork, product and environment with human needs and capabilities. The utmost\nneed to integrate emotions in the news as well as advertisements cannot be\ndenied. The idea is that news or advertisement should be able to engage the\nreader on emotional and behavioral platform. While achieving this objective\nthere is need to learn about reader behavior and use computational psychology\nwhile presenting as well as writing news or advertisements. This paper based on\nMachine Learning, tries to map behavior of the reader with the\nnews/advertisements and also provide inputs for affective value for building\npersonalized news or advertisements presentations. The affective value of the\nnews is determined and news artifacts are mapped to reader. The algorithm\nsuggests the most suitable news for readers while understanding emotional\ntraits required for personalization. This work can be used to improve reader\nsatisfaction through embedding emotions in the reading material and\nprioritizing news presentations. It can be used to map personal reading\nmaterial range, personalized programs and ranking programs, advertisements with\nreference to individuals.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:12:21 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Kulkarni", "Hrishikesh", ""], ["Joshi", "P", ""], ["Chande", "P", ""]]}, {"id": "1910.06862", "submitter": "Lars Buesing", "authors": "Lars Buesing, Nicolas Heess, Theophane Weber", "title": "Approximate Inference in Discrete Distributions with Monte Carlo Tree\n  Search and Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of problems in AI, engineering and the sciences are naturally\nformalized as inference in discrete probabilistic models. Exact inference is\noften prohibitively expensive, as it may require evaluating the (unnormalized)\ntarget density on its entire domain. Here we consider the setting where only a\nlimited budget of calls to the unnormalized density oracle is available,\nraising the challenge of where in the domain to allocate these function calls\nin order to construct a good approximate solution. We formulate this problem as\nan instance of sequential decision-making under uncertainty and leverage\nmethods from reinforcement learning for probabilistic inference with budget\nconstraints. In particular, we propose the TreeSample algorithm, an adaptation\nof Monte Carlo Tree Search to approximate inference. This algorithm caches all\nprevious queries to the density oracle in an explicit search tree, and\ndynamically allocates new queries based on a \"best-first\" heuristic for\nexploration, using existing upper confidence bound methods. Our non-parametric\ninference method can be effectively combined with neural networks that compile\napproximate conditionals of the target, which are then used to guide the\ninference search and enable generalization across multiple target\ndistributions. We show empirically that TreeSample outperforms standard\napproximate inference methods on synthetic factor graphs.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:24:41 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Buesing", "Lars", ""], ["Heess", "Nicolas", ""], ["Weber", "Theophane", ""]]}, {"id": "1910.06864", "submitter": "Yuzhe Ou", "authors": "Xujiang Zhao, Yuzhe Ou, Lance Kaplan, Feng Chen, Jin-Hee Cho", "title": "Quantifying Classification Uncertainty using Regularized Evidential\n  Neural Networks", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional deep neural nets (NNs) have shown the state-of-the-art\nperformance in the task of classification in various applications. However, NNs\nhave not considered any types of uncertainty associated with the class\nprobabilities to minimize risk due to misclassification under uncertainty in\nreal life. Unlike Bayesian neural nets indirectly infering uncertainty through\nweight uncertainties, evidential neural networks (ENNs) have been recently\nproposed to support explicit modeling of the uncertainty of class\nprobabilities. It treats predictions of an NN as subjective opinions and learns\nthe function by collecting the evidence leading to these opinions by a\ndeterministic NN from data. However, an ENN is trained as a black box without\nexplicitly considering different types of inherent data uncertainty, such as\nvacuity (uncertainty due to a lack of evidence) or dissonance (uncertainty due\nto conflicting evidence). This paper presents a new approach, called a {\\em\nregularized ENN}, that learns an ENN based on regularizations related to\ndifferent characteristics of inherent data uncertainty. Via the experiments\nwith both synthetic and real-world datasets, we demonstrate that the proposed\nregularized ENN can better learn of an ENN modeling different types of\nuncertainty in the class probabilities for classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:26:20 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Zhao", "Xujiang", ""], ["Ou", "Yuzhe", ""], ["Kaplan", "Lance", ""], ["Chen", "Feng", ""], ["Cho", "Jin-Hee", ""]]}, {"id": "1910.06878", "submitter": "Sin Yong Tan", "authors": "Zhanhong Jiang, Aditya Balu, Sin Yong Tan, Young M Lee, Chinmay Hegde,\n  Soumik Sarkar", "title": "On Higher-order Moments in Adam", "comments": "Accepted in Beyond First Order Methods in Machine Learning workshop\n  in 33rd Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the popular deep learning optimization routine,\nAdam, from the perspective of statistical moments. While Adam is an adaptive\nlower-order moment based (of the stochastic gradient) method, we propose an\nextension namely, HAdam, which uses higher order moments of the stochastic\ngradient. Our analysis and experiments reveal that certain higher-order moments\nof the stochastic gradient are able to achieve better performance compared to\nthe vanilla Adam algorithm. We also provide some analysis of HAdam related to\nodd and even moments to explain some intriguing and seemingly non-intuitive\nempirical results.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:45:38 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Jiang", "Zhanhong", ""], ["Balu", "Aditya", ""], ["Tan", "Sin Yong", ""], ["Lee", "Young M", ""], ["Hegde", "Chinmay", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1910.06893", "submitter": "Ankit Pensia", "authors": "Ankit Pensia, Varun Jog, Po-Ling Loh", "title": "Extracting robust and accurate features via a robust information\n  bottleneck", "comments": "A version of this paper was submitted to IEEE Journal on Selected\n  Areas in Information Theory (JSAIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel strategy for extracting features in supervised learning\nthat can be used to construct a classifier which is more robust to small\nperturbations in the input space. Our method builds upon the idea of the\ninformation bottleneck by introducing an additional penalty term that\nencourages the Fisher information of the extracted features to be small, when\nparametrized by the inputs. By tuning the regularization parameter, we can\nexplicitly trade off the opposing desiderata of robustness and accuracy when\nconstructing a classifier. We derive the optimal solution to the robust\ninformation bottleneck when the inputs and outputs are jointly Gaussian,\nproving that the optimally robust features are also jointly Gaussian in that\nsetting. Furthermore, we propose a method for optimizing a variational bound on\nthe robust information bottleneck objective in general settings using\nstochastic gradient descent, which may be implemented efficiently in neural\nnetworks. Our experimental results for synthetic and real data sets show that\nthe proposed feature extraction method indeed produces classifiers with\nincreased robustness to perturbations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 16:07:34 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Pensia", "Ankit", ""], ["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1910.06899", "submitter": "Maxim Vaysburd", "authors": "Maxim Vaysburd", "title": "Identifying Epigenetic Signature of Breast Cancer with Machine Learning", "comments": "8 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research reported in this paper identifies the epigenetic biomarker\n(methylation beta pattern) of breast cancer. Many cancers are triggered by\nabnormal gene expression levels caused by aberrant methylation of CpG sites in\nthe DNA. In order to develop early diagnostics of cancer-causing methylations\nand to develop a treatment, it is necessary to identify a few dozen key\ncancer-related CpG methylation sites out of the millions of locations in the\nDNA. This research used public TCGA dataset to train a TensorFlow machine\nlearning model to classify breast cancer versus non-breast-cancer tissue\nsamples, based on over 300,000 methylation beta values in each sample. L1\nregularization was applied to identify the CpG methylation sites most important\nfor accurate classification. It was hypothesized that CpG sites with the\nhighest learned model weights correspond to DNA locations most relevant to\nbreast cancer. A reduced model trained on methylation betas of just the 25 CpG\nsites having the highest weights in the full model (trained on methylation\nbetas at over 300,000 CpG sites) has achieved over 94% accuracy on evaluation\ndata, confirming that the identified 25 CpG sites are indeed a biomarker of\nbreast cancer.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 19:46:17 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Vaysburd", "Maxim", ""]]}, {"id": "1910.06907", "submitter": "Utku Kose", "authors": "Utku Kose", "title": "Techniques for Adversarial Examples Threatening the Safety of Artificial\n  Intelligence Based Systems", "comments": "International Science and Innovation Congress 2019, pp. 643-655, 13\n  pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Artificial intelligence is known as the most effective technological field\nfor rapid developments shaping the future of the world. Even today, it is\npossible to see intense use of intelligence systems in all fields of the life.\nAlthough advantages of the Artificial Intelligence are widely observed, there\nis also a dark side employing efforts to design hacking oriented techniques\nagainst Artificial Intelligence. Thanks to such techniques, it is possible to\ntrick intelligent systems causing directed results for unsuccessful outputs.\nThat is critical for also cyber wars of the future as it is predicted that the\nwars will be done unmanned, autonomous intelligent systems. Moving from the\nexplanations, objective of this study is to provide information regarding\nadversarial examples threatening the Artificial Intelligence and focus on\ndetails of some techniques, which are used for creating adversarial examples.\nAdversarial examples are known as training data, which can trick a Machine\nLearning technique to learn incorrectly about the target problem and cause an\nunsuccessful or maliciously directed intelligent system at the end. The study\nenables the readers to learn enough about details of recent techniques for\ncreating adversarial examples.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:56:59 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Kose", "Utku", ""]]}, {"id": "1910.06908", "submitter": "Hosny Abbas H. A. Abbas", "authors": "Hosny Abbas", "title": "Machine Learning for Paper Grammage Prediction Based on Sensor\n  Measurements in Paper Mills", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automation is at the core of modern industry. It aims to increase production\nrates, decrease production costs, and reduce human intervention in order to\navoid human mistakes and time delays during manufacturing. On the other hand,\nhuman assistance is usually required to customize products and reconfigure\ncontrol systems through a special process interface called Human Machine\nInterface (HMI). Machine Learning (ML) algorithms can effectively be used to\nresolve this tradeoff between full automation and human assistance.This paper\nprovides an example of the industrial application of ML algorithms to help\nhuman operators save their mental effort and avoid time delays and unintended\nmistakes for the sake of high production rates. Based on real-time sensor\nmeasurements, several ML algorithms have been tried to classify paper rolls\naccording to paper grammage in a white paper mill. The performance evaluation\nshows that the AdaBoost algorithm is the best ML algorithm for this application\nwith classification accuracy (CA), precision, and recall of 97.1%. The\ngeneralization of the proposed approach for achieving cost-effective mills\nconstruction will be the subject of our future research.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:35:03 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Abbas", "Hosny", ""]]}, {"id": "1910.06909", "submitter": "Jordan Dotzel", "authors": "Ritchie Zhao, Jordan Dotzel, Zhanqiu Hu, Preslav Ivanov, Christopher\n  De Sa, Zhiru Zhang", "title": "OverQ: Opportunistic Outlier Quantization for Neural Network\n  Accelerators", "comments": "Preprint, work in progress. 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outliers in weights and activations pose a key challenge for fixed-point\nquantization of neural networks. While they can be addressed by fine-tuning,\nthis is not practical for ML service providers (e.g., Google or Microsoft) who\noften receive customer models without training data. Specialized hardware for\nhandling activation outliers can enable low-precision neural networks, but at\nthe cost of nontrivial area overhead. We instead propose overwrite quantization\n(OverQ), a lightweight hardware technique that opportunistically increases\nbitwidth for activation outliers by overwriting nearby zeros. It has two major\nmodes of operation: range overwrite and precision overwrite. Range overwrite\nreallocates bits to increase the range of outliers, while precision overwrite\nreuses zeros to increase the precision of non-outlier values. Combining range\noverwrite with a simple cascading logic, we handle the vast majority of\noutliers to significantly improve model accuracy at low bitwidth. Our\nexperiments show that with modest cascading, we can consistently handle over\n90% of outliers and achieve +5% ImageNet Top-1 accuracy on a quantized\nResNet-50 at 4 bits. Our ASIC prototype shows OverQ can be implemented\nefficiently on top of existing weight-stationary systolic arrays with small\narea increases per processing element. We imagine this technique can complement\nmodern DNN accelerator designs to provide small increases in accuracy with\ninsignificant area overhead.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 23:21:59 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 07:01:47 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Zhao", "Ritchie", ""], ["Dotzel", "Jordan", ""], ["Hu", "Zhanqiu", ""], ["Ivanov", "Preslav", ""], ["De Sa", "Christopher", ""], ["Zhang", "Zhiru", ""]]}, {"id": "1910.06922", "submitter": "Alexia Jolicoeur-Martineau", "authors": "Alexia Jolicoeur-Martineau, Ioannis Mitliagkas", "title": "Gradient penalty from a maximum margin perspective", "comments": "Code at https://github.com/AlexiaJM/MaximumMarginGANs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular heuristic for improved performance in Generative adversarial\nnetworks (GANs) is to use some form of gradient penalty on the discriminator.\nThis gradient penalty was originally motivated by a Wasserstein distance\nformulation. However, the use of gradient penalty in other GAN formulations is\nnot well motivated. We present a unifying framework of expected margin\nmaximization and show that a wide range of gradient-penalized GANs (e.g.,\nWasserstein, Standard, Least-Squares, and Hinge GANs) can be derived from this\nframework. Our results imply that employing gradient penalties induces a\nlarge-margin classifier (thus, a large-margin discriminator in GANs). We\ndescribe how expected margin maximization helps reduce vanishing gradients at\nfake (generated) samples, a known problem in GANs. From this framework, we\nderive a new $L^\\infty$ gradient norm penalty with Hinge loss which generally\nproduces equally good (or better) generated output in GANs than $L^2$-norm\npenalties (based on the Fr\\'echet Inception Distance).\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 16:48:43 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 15:41:01 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Jolicoeur-Martineau", "Alexia", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "1910.06924", "submitter": "Frederik Harder", "authors": "Frederik Harder, Jonas K\\\"ohler, Max Welling, Mijung Park", "title": "DP-MAC: The Differentially Private Method of Auxiliary Coordinates for\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing a differentially private deep learning algorithm is challenging,\ndue to the difficulty in analyzing the sensitivity of objective functions that\nare typically used to train deep neural networks. Many existing methods resort\nto the stochastic gradient descent algorithm and apply a pre-defined\nsensitivity to the gradients for privatizing weights. However, their slow\nconvergence typically yields a high cumulative privacy loss. Here, we take a\ndifferent route by employing the method of auxiliary coordinates, which allows\nus to independently update the weights per layer by optimizing a per-layer\nobjective function. This objective function can be well approximated by a\nlow-order Taylor's expansion, in which sensitivity analysis becomes tractable.\nWe perturb the coefficients of the expansion for privacy, which we optimize\nusing more advanced optimization routines than SGD for faster convergence. We\nempirically show that our algorithm provides a decent trained model quality\nunder a modest privacy budget.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 16:51:36 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Harder", "Frederik", ""], ["K\u00f6hler", "Jonas", ""], ["Welling", "Max", ""], ["Park", "Mijung", ""]]}, {"id": "1910.06939", "submitter": "Benjamin Lengerich", "authors": "Benjamin Lengerich, Bryon Aragam, Eric P. Xing", "title": "Learning Sample-Specific Models with Low-Rank Personalized Regression", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern applications of machine learning (ML) deal with increasingly\nheterogeneous datasets comprised of data collected from overlapping latent\nsubpopulations. As a result, traditional models trained over large datasets may\nfail to recognize highly predictive localized effects in favour of weakly\npredictive global patterns. This is a problem because localized effects are\ncritical to developing individualized policies and treatment plans in\napplications ranging from precision medicine to advertising. To address this\nchallenge, we propose to estimate sample-specific models that tailor inference\nand prediction at the individual level. In contrast to classical ML models that\nestimate a single, complex model (or only a few complex models), our approach\nproduces a model personalized to each sample. These sample-specific models can\nbe studied to understand subgroup dynamics that go beyond coarse-grained class\nlabels. Crucially, our approach does not assume that relationships between\nsamples (e.g. a similarity network) are known a priori. Instead, we use\nunmodeled covariates to learn a latent distance metric over the samples. We\napply this approach to financial, biomedical, and electoral data as well as\nsimulated data and show that sample-specific models provide fine-grained\ninterpretations of complicated phenomena without sacrificing predictive\naccuracy compared to state-of-the-art models such as deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:24:25 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Lengerich", "Benjamin", ""], ["Aragam", "Bryon", ""], ["Xing", "Eric P.", ""]]}, {"id": "1910.06943", "submitter": "Weijie J. Su", "authors": "Hangfeng He and Weijie J. Su", "title": "The Local Elasticity of Neural Networks", "comments": "To appear in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a phenomenon in neural networks that we refer to as\n\\textit{local elasticity}. Roughly speaking, a classifier is said to be locally\nelastic if its prediction at a feature vector $\\bx'$ is \\textit{not}\nsignificantly perturbed, after the classifier is updated via stochastic\ngradient descent at a (labeled) feature vector $\\bx$ that is\n\\textit{dissimilar} to $\\bx'$ in a certain sense. This phenomenon is shown to\npersist for neural networks with nonlinear activation functions through\nextensive simulations on real-life and synthetic datasets, whereas this is not\nobserved in linear classifiers. In addition, we offer a geometric\ninterpretation of local elasticity using the neural tangent kernel\n\\citep{jacot2018neural}. Building on top of local elasticity, we obtain\npairwise similarity measures between feature vectors, which can be used for\nclustering in conjunction with $K$-means. The effectiveness of the clustering\nalgorithm on the MNIST and CIFAR-10 datasets in turn corroborates the\nhypothesis of local elasticity of neural networks on real-life data. Finally,\nwe discuss some implications of local elasticity to shed light on several\nintriguing aspects of deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:35:30 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 02:04:50 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["He", "Hangfeng", ""], ["Su", "Weijie J.", ""]]}, {"id": "1910.06948", "submitter": "Kailiang Wu", "authors": "Kailiang Wu, Dongbin Xiu", "title": "Data-Driven Deep Learning of Partial Differential Equations in Modal\n  Space", "comments": "Minor notational changes", "journal-ref": "Journal of Computational Physics, 408: 109307, 2020", "doi": "10.1016/j.jcp.2020.109307", "report-no": null, "categories": "math.NA cs.LG cs.NA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for recovering/approximating unknown time-dependent\npartial differential equation (PDE) using its solution data. Instead of\nidentifying the terms in the underlying PDE, we seek to approximate the\nevolution operator of the underlying PDE numerically. The evolution operator of\nthe PDE, defined in infinite-dimensional space, maps the solution from a\ncurrent time to a future time and completely characterizes the solution\nevolution of the underlying unknown PDE. Our recovery strategy relies on\napproximation of the evolution operator in a properly defined modal space,\ni.e., generalized Fourier space, in order to reduce the problem to finite\ndimensions. The finite dimensional approximation is then accomplished by\ntraining a deep neural network structure, which is based on residual network\n(ResNet), using the given data. Error analysis is provided to illustrate the\npredictive accuracy of the proposed method. A set of examples of different\ntypes of PDEs, including inviscid Burgers' equation that develops discontinuity\nin its solution, are presented to demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:43:32 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 23:59:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wu", "Kailiang", ""], ["Xiu", "Dongbin", ""]]}, {"id": "1910.06949", "submitter": "Yue Yang", "authors": "Qiong Tian, Yue Yang, Jiaqi Wen, Fan Ding and Jing He", "title": "How to Eliminate Detour Behaviors in E-hailing? Real-time Detecting and\n  Time-dependent Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of information and communication technology (ICT),\ntaxi business becomes a typical electronic commerce mode. However, one\ntraditional problem still exists in taxi service, that greedy taxi drivers may\ndeliberately take unnecessary detours to overcharge passengers. The detection\nof these fraudulent behaviors is essential to ensure high-quality taxi service.\nIn this paper, we propose a novel framework for detecting and analyzing the\ndetour behaviors both in off-line database and among on-line trips. Applying\nour framework to real-world taxi data-set, a remarkable performance (AUC\nsurpasses 0.98) has been achieved in off-line classification. Meanwhile, we\nfurther extend the off-line methods to on-line detection, a warning mechanism\nis introduced to remind drivers and an excellent precision (AUC surpasses 0.90)\nalso has arrived in this phases. After conducting extensive experiments to\nverify the relationships between pricing regulations and detour behaviors, some\nquantitative pricing suggestions, including rising base fare and reducing\ndistance-based fare rate, are provided to eliminate detour behaviors from the\nlong term.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:43:32 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 01:50:51 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 17:22:17 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Tian", "Qiong", ""], ["Yang", "Yue", ""], ["Wen", "Jiaqi", ""], ["Ding", "Fan", ""], ["He", "Jing", ""]]}, {"id": "1910.06950", "submitter": "Nicha Dvornek", "authors": "Nicha C. Dvornek, Xiaoxiao Li, Juntang Zhuang, James S. Duncan", "title": "Jointly Discriminative and Generative Recurrent Neural Networks for\n  Learning from fMRI", "comments": "10th International Workshop on Machine Learning in Medical Imaging\n  (MLMI 2019)", "journal-ref": null, "doi": "10.1007/978-3-030-32692-0_44", "report-no": null, "categories": "eess.IV cs.LG q-bio.NC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) were designed for dealing with time-series\ndata and have recently been used for creating predictive models from functional\nmagnetic resonance imaging (fMRI) data. However, gathering large fMRI datasets\nfor learning is a difficult task. Furthermore, network interpretability is\nunclear. To address these issues, we utilize multitask learning and design a\nnovel RNN-based model that learns to discriminate between classes while\nsimultaneously learning to generate the fMRI time-series data. Employing the\nlong short-term memory (LSTM) structure, we develop a discriminative model\nbased on the hidden state and a generative model based on the cell state. The\naddition of the generative model constrains the network to learn functional\ncommunities represented by the LSTM nodes that are both consistent with the\ndata generation as well as useful for the classification task. We apply our\napproach to the classification of subjects with autism vs. healthy controls\nusing several datasets from the Autism Brain Imaging Data Exchange. Experiments\nshow that our jointly discriminative and generative model improves\nclassification learning while also producing robust and meaningful functional\ncommunities for better model understanding.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:43:45 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Dvornek", "Nicha C.", ""], ["Li", "Xiaoxiao", ""], ["Zhuang", "Juntang", ""], ["Duncan", "James S.", ""]]}, {"id": "1910.06953", "submitter": "Shiqi Yu", "authors": "Shiqi Yu", "title": "Electron Neutrino Energy Reconstruction in NOvA Using CNN Particle IDs", "comments": "Talk presented at the 2019 Meeting of the Division of Particles and\n  Fields of the American Physical Society (DPF2019), July 29 - August 2, 2019,\n  Northeastern University, Boston, C1907293", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ins-det cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NOvA is a long-baseline neutrino oscillation experiment. It is optimized to\nmeasure $\\nu_e$ appearance and $\\nu_{\\mu}$ disappearance at the Far Detector in\nthe $\\nu_{\\mu}$ beam produced by the NuMI facility at Fermilab. NOvA uses a\nconvolutional neural network (CNN) to identify neutrino events in two\nfunctionally identical liquid scintillator detectors. A different network,\ncalled prong-CNN, has been used to classify reconstructed particles in each\nevent as either lepton or hadron. Within each event, hits are clustered into\nprongs to reconstruct final-state particles and these prongs form the input to\nthis prong-CNN classifier. Classified particle energies are then used as input\nto an electron neutrino energy estimator. Improving the resolution and\nsystematic robustness of NOvA's energy estimator will improve the sensitivity\nof the oscillation parameters measurement. This paper describes the methods to\nidentify particles with prong-CNN and the following approach to estimate\n$\\nu_e$ energy for signal events.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:48:28 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 16:24:31 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Yu", "Shiqi", ""]]}, {"id": "1910.06954", "submitter": "Marius C\\u{a}t\\u{a}lin Iordan", "authors": "Marius C\\u{a}t\\u{a}lin Iordan, Tyler Giallanza, Cameron T. Ellis,\n  Nicole M. Beckage, Jonathan D. Cohen", "title": "Context Matters: Recovering Human Semantic Structure from Machine\n  Learning Analysis of Large-Scale Text Corpora", "comments": "Main Text: 35 pages, 5 figures; Supplemental: 21 pages, 11 figures, 6\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying machine learning algorithms to large-scale, text-based corpora\n(embeddings) presents a unique opportunity to investigate at scale how human\nsemantic knowledge is organized and how people use it to judge fundamental\nrelationships, such as similarity between concepts. However, efforts to date\nhave shown a substantial discrepancy between algorithm predictions and\nempirical judgments. Here, we introduce a novel approach of generating\nembeddings motivated by the psychological theory that semantic context plays a\ncritical role in human judgments. Specifically, we train state-of-the-art\nmachine learning algorithms using contextually-constrained text corpora and\nshow that this greatly improves predictions of similarity judgments and feature\nratings. By improving the correspondence between representations derived using\nembeddings generated by machine learning methods and empirical measurements of\nhuman judgments, the approach we describe helps advance the use of large-scale\ntext corpora to understand the structure of human semantic representations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:51:01 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 23:49:12 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 20:41:41 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Iordan", "Marius C\u0103t\u0103lin", ""], ["Giallanza", "Tyler", ""], ["Ellis", "Cameron T.", ""], ["Beckage", "Nicole M.", ""], ["Cohen", "Jonathan D.", ""]]}, {"id": "1910.06956", "submitter": "Matus Telgarsky", "authors": "Ziwei Ji and Matus Telgarsky and Ruicheng Xian", "title": "Neural tangent kernels, transportation mappings, and universal\n  approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes rates of universal approximation for the shallow\nneural tangent kernel (NTK): network weights are only allowed microscopic\nchanges from random initialization, which entails that activations are mostly\nunchanged, and the network is nearly equivalent to its linearization.\nConcretely, the paper has two main contributions: a generic scheme to\napproximate functions with the NTK by sampling from transport mappings between\nthe initial weights and their desired values, and the construction of transport\nmappings via Fourier transforms. Regarding the first contribution, the proof\nscheme provides another perspective on how the NTK regime arises from\nrescaling: redundancy in the weights due to resampling allows individual\nweights to be scaled down. Regarding the second contribution, the most notable\ntransport mapping asserts that roughly $1 / \\delta^{10d}$ nodes are sufficient\nto approximate continuous functions, where $\\delta$ depends on the continuity\nproperties of the target function. By contrast, nearly the same proof yields a\nbound of $1 / \\delta^{2d}$ for shallow ReLU networks; this gap suggests a\ntantalizing direction for future work, separating shallow ReLU networks and\ntheir linearization.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:52:49 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 00:45:24 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ji", "Ziwei", ""], ["Telgarsky", "Matus", ""], ["Xian", "Ruicheng", ""]]}, {"id": "1910.06962", "submitter": "Jyh-Jing Hwang", "authors": "Jyh-Jing Hwang, Stella X. Yu, Jianbo Shi, Maxwell D. Collins, Tien-Ju\n  Yang, Xiao Zhang, Liang-Chieh Chen", "title": "SegSort: Segmentation by Discriminative Sorting of Segments", "comments": "In ICCV 2019. Webpage & Code:\n  https://jyhjinghwang.github.io/projects/segsort.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all existing deep learning approaches for semantic segmentation tackle\nthis task as a pixel-wise classification problem. Yet humans understand a scene\nnot in terms of pixels, but by decomposing it into perceptual groups and\nstructures that are the basic building blocks of recognition. This motivates us\nto propose an end-to-end pixel-wise metric learning approach that mimics this\nprocess. In our approach, the optimal visual representation determines the\nright segmentation within individual images and associates segments with the\nsame semantic classes across images. The core visual learning problem is\ntherefore to maximize the similarity within segments and minimize the\nsimilarity between segments. Given a model trained this way, inference is\nperformed consistently by extracting pixel-wise embeddings and clustering, with\nthe semantic label determined by the majority vote of its nearest neighbors\nfrom an annotated set.\n  As a result, we present the SegSort, as a first attempt using deep learning\nfor unsupervised semantic segmentation, achieving $76\\%$ performance of its\nsupervised counterpart. When supervision is available, SegSort shows consistent\nimprovements over conventional approaches based on pixel-wise softmax training.\nAdditionally, our approach produces more precise boundaries and consistent\nregion predictions. The proposed SegSort further produces an interpretable\nresult, as each choice of label can be easily understood from the retrieved\nnearest segments.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:58:20 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 17:43:04 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Hwang", "Jyh-Jing", ""], ["Yu", "Stella X.", ""], ["Shi", "Jianbo", ""], ["Collins", "Maxwell D.", ""], ["Yang", "Tien-Ju", ""], ["Zhang", "Xiao", ""], ["Chen", "Liang-Chieh", ""]]}, {"id": "1910.06985", "submitter": "Katja Ried", "authors": "Katja Ried and Benjamin Eva and Thomas M\\\"uller and Hans J. Briegel", "title": "How a minimal learning agent can infer the existence of unobserved\n  variables in a complex environment", "comments": "28 pages plus references, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to a mainstream position in contemporary cognitive science and\nphilosophy, the use of abstract compositional concepts is both a necessary and\na sufficient condition for the presence of genuine thought. In this article, we\nshow how the ability to develop and utilise abstract conceptual structures can\nbe achieved by a particular kind of learning agents. More specifically, we\nprovide and motivate a concrete operational definition of what it means for\nthese agents to be in possession of abstract concepts, before presenting an\nexplicit example of a minimal architecture that supports this capability. We\nthen proceed to demonstrate how the existence of abstract conceptual structures\ncan be operationally useful in the process of employing previously acquired\nknowledge in the face of new experiences, thereby vindicating the natural\nconjecture that the cognitive functions of abstraction and generalisation are\nclosely related.\n  Keywords: concept formation, projective simulation, reinforcement learning,\ntransparent artificial intelligence, theory formation, explainable artificial\nintelligence (XAI)\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 18:08:08 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Ried", "Katja", ""], ["Eva", "Benjamin", ""], ["M\u00fcller", "Thomas", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1910.06988", "submitter": "Rogerio Bonatti", "authors": "Rogerio Bonatti and Wenshan Wang and Cherie Ho and Aayush Ahuja and\n  Mirko Gschwindt and Efe Camci and Erdal Kayacan and Sanjiban Choudhury and\n  Sebastian Scherer", "title": "Autonomous Aerial Cinematography In Unstructured Environments With\n  Learned Artistic Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aerial cinematography is revolutionizing industries that require live and\ndynamic camera viewpoints such as entertainment, sports, and security. However,\nsafely piloting a drone while filming a moving target in the presence of\nobstacles is immensely taxing, often requiring multiple expert human operators.\nHence, there is demand for an autonomous cinematographer that can reason about\nboth geometry and scene context in real-time. Existing approaches do not\naddress all aspects of this problem; they either require high-precision\nmotion-capture systems or GPS tags to localize targets, rely on prior maps of\nthe environment, plan for short time horizons, or only follow artistic\nguidelines specified before flight.\n  In this work, we address the problem in its entirety and propose a complete\nsystem for real-time aerial cinematography that for the first time combines:\n(1) vision-based target estimation; (2) 3D signed-distance mapping for\nocclusion estimation; (3) efficient trajectory optimization for long\ntime-horizon camera motion; and (4) learning-based artistic shot selection. We\nextensively evaluate our system both in simulation and in field experiments by\nfilming dynamic targets moving through unstructured environments. Our results\nindicate that our system can operate reliably in the real world without\nrestrictive assumptions. We also provide in-depth analysis and discussions for\neach module, with the hope that our design tradeoffs can generalize to other\nrelated applications. Videos of the complete system can be found at:\nhttps://youtu.be/ookhHnqmlaU.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 18:17:58 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Bonatti", "Rogerio", ""], ["Wang", "Wenshan", ""], ["Ho", "Cherie", ""], ["Ahuja", "Aayush", ""], ["Gschwindt", "Mirko", ""], ["Camci", "Efe", ""], ["Kayacan", "Erdal", ""], ["Choudhury", "Sanjiban", ""], ["Scherer", "Sebastian", ""]]}, {"id": "1910.06990", "submitter": "Raed Al Kontar", "authors": "Xubo Yue, Raed Kontar", "title": "The Renyi Gaussian Process: Towards Improved Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an alternative closed form lower bound on the Gaussian process\n($\\mathcal{GP}$) likelihood based on the R\\'enyi $\\alpha$-divergence. This new\nlower bound can be viewed as a convex combination of the Nystr\\\"om\napproximation and the exact $\\mathcal{GP}$. The key advantage of this bound, is\nits capability to control and tune the enforced regularization on the model and\nthus is a generalization of the traditional variational $\\mathcal{GP}$\nregression. From a theoretical perspective, we provide the convergence rate and\nrisk bound for inference using our proposed approach. Experiments on real data\nshow that the proposed algorithm may be able to deliver improvement over\nseveral $\\mathcal{GP}$ inference methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 18:21:06 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 01:25:20 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 16:32:45 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Yue", "Xubo", ""], ["Kontar", "Raed", ""]]}, {"id": "1910.06995", "submitter": "Talgat Daulbaev", "authors": "Julia Gusak, Talgat Daulbaev, Evgeny Ponomarev, Andrzej Cichocki, Ivan\n  Oseledets", "title": "Reduced-Order Modeling of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for speeding up the inference of deep neural\nnetworks. It is somewhat inspired by the reduced-order modeling techniques for\ndynamical systems.The cornerstone of the proposed method is the maximum volume\nalgorithm. We demonstrate efficiency on neural networks pre-trained on\ndifferent datasets. We show that in many practical cases it is possible to\nreplace convolutional layers with much smaller fully-connected layers with a\nrelatively small drop in accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 18:25:26 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 08:03:10 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 14:09:00 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 08:55:41 GMT"}, {"version": "v5", "created": "Wed, 25 Nov 2020 09:45:47 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Gusak", "Julia", ""], ["Daulbaev", "Talgat", ""], ["Ponomarev", "Evgeny", ""], ["Cichocki", "Andrzej", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1910.06996", "submitter": "Botao Hao", "authors": "Botao Hao, Tor Lattimore, Csaba Szepesvari", "title": "Adaptive Exploration in Linear Contextual Bandit", "comments": "Accepted at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits serve as a fundamental model for many sequential decision\nmaking tasks. The most popular theoretically justified approaches are based on\nthe optimism principle. While these algorithms can be practical, they are known\nto be suboptimal asymptotically. On the other hand, existing asymptotically\noptimal algorithms for this problem do not exploit the linear structure in an\noptimal way and suffer from lower-order terms that dominate the regret in all\npractically interesting regimes. We start to bridge the gap by designing an\nalgorithm that is asymptotically optimal and has good finite-time empirical\nperformance. At the same time, we make connections to the recent literature on\nwhen exploration-free methods are effective. Indeed, if the distribution of\ncontexts is well behaved, then our algorithm acts mostly greedily and enjoys\nsub-logarithmic regret. Furthermore, our approach is adaptive in the sense that\nit automatically detects the nice case. Numerical results demonstrate\nsignificant regret reductions by our method relative to several baselines.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 18:26:52 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 01:01:50 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Hao", "Botao", ""], ["Lattimore", "Tor", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1910.07003", "submitter": "Valerio Perrone", "authors": "Valerio Perrone, Iaroslav Shcherbatyi, Rodolphe Jenatton, Cedric\n  Archambeau, Matthias Seeger", "title": "Constrained Bayesian Optimization with Max-Value Entropy Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a model-based approach to sequentially optimize\nexpensive black-box functions, such as the validation error of a deep neural\nnetwork with respect to its hyperparameters. In many real-world scenarios, the\noptimization is further subject to a priori unknown constraints. For example,\ntraining a deep network configuration may fail with an out-of-memory error when\nthe model is too large. In this work, we focus on a general formulation of\nGaussian process-based BO with continuous or binary constraints. We propose\nconstrained Max-value Entropy Search (cMES), a novel information\ntheoretic-based acquisition function implementing this formulation. We also\nrevisit the validity of the factorized approximation adopted for rapid\ncomputation of the MES acquisition function, showing empirically that this\nleads to inaccurate results. On an extensive set of real-world constrained\nhyperparameter optimization problems we show that cMES compares favourably to\nprior work, while being simpler to implement and faster than other constrained\nextensions of Entropy Search.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 18:56:04 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Perrone", "Valerio", ""], ["Shcherbatyi", "Iaroslav", ""], ["Jenatton", "Rodolphe", ""], ["Archambeau", "Cedric", ""], ["Seeger", "Matthias", ""]]}, {"id": "1910.07012", "submitter": "Gean Pereira", "authors": "Gean Trindade Pereira, Mois\\'es dos Santos, Edesio Alcoba\\c{c}a,\n  Rafael Mantovani and Andr\\'e Carvalho", "title": "Transfer Learning for Algorithm Recommendation", "comments": "Short-paper accepted in LXAI Research Workshop co-located with\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-Learning is a subarea of Machine Learning that aims to take advantage of\nprior knowledge to learn faster and with fewer data [1]. There are different\nscenarios where meta-learning can be applied, and one of the most common is\nalgorithm recommendation, where previous experience on applying machine\nlearning algorithms for several datasets can be used to learn which algorithm,\nfrom a set of options, would be more suitable for a new dataset [2]. Perhaps\nthe most popular form of meta-learning is transfer learning, which consists of\ntransferring knowledge acquired by a machine learning algorithm in a previous\nlearning task to increase its performance faster in another and similar task\n[3]. Transfer Learning has been widely applied in a variety of complex tasks\nsuch as image classification, machine translation and, speech recognition,\nachieving remarkable results [4,5,6,7,8]. Although transfer learning is very\nused in traditional or base-learning, it is still unknown if it is useful in a\nmeta-learning setup. For that purpose, in this paper, we investigate the\neffects of transferring knowledge in the meta-level instead of base-level.\nThus, we train a neural network on meta-datasets related to algorithm\nrecommendation, and then using transfer learning, we reuse the knowledge\nlearned by the neural network in other similar datasets from the same domain,\nto verify how transferable is the acquired meta-knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 19:26:31 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Pereira", "Gean Trindade", ""], ["Santos", "Mois\u00e9s dos", ""], ["Alcoba\u00e7a", "Edesio", ""], ["Mantovani", "Rafael", ""], ["Carvalho", "Andr\u00e9", ""]]}, {"id": "1910.07022", "submitter": "Annie Liang", "authors": "Drew Fudenberg, Jon Kleinberg, Annie Liang, Sendhil Mullainathan", "title": "Measuring the Completeness of Theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use machine learning to provide a tractable measure of the amount of\npredictable variation in the data that a theory captures, which we call its\n\"completeness.\" We apply this measure to three problems: assigning certain\nequivalents to lotteries, initial play in games, and human generation of random\nsequences. We discover considerable variation in the completeness of existing\nmodels, which sheds light on whether to focus on developing better models with\nthe same features or instead to look for new features that will improve\npredictions. We also illustrate how and why completeness varies with the\nexperiments considered, which highlights the role played in choosing which\nexperiments to run.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 19:46:54 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Fudenberg", "Drew", ""], ["Kleinberg", "Jon", ""], ["Liang", "Annie", ""], ["Mullainathan", "Sendhil", ""]]}, {"id": "1910.07030", "submitter": "Qi Lei", "authors": "Qi Lei, Jason D. Lee, Alexandros G. Dimakis, Constantinos Daskalakis", "title": "SGD Learns One-Layer Networks in WGANs", "comments": "24 pages, 4 figures, ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a widely used framework for\nlearning generative models. Wasserstein GANs (WGANs), one of the most\nsuccessful variants of GANs, require solving a minmax optimization problem to\nglobal optimality, but are in practice successfully trained using stochastic\ngradient descent-ascent. In this paper, we show that, when the generator is a\none-layer network, stochastic gradient descent-ascent converges to a global\nsolution with polynomial time and sample complexity.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 20:01:27 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 02:35:27 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Lei", "Qi", ""], ["Lee", "Jason D.", ""], ["Dimakis", "Alexandros G.", ""], ["Daskalakis", "Constantinos", ""]]}, {"id": "1910.07038", "submitter": "Avi Ben-Cohen", "authors": "Hussam Lawen, Avi Ben-Cohen, Matan Protter, Itamar Friedman, Lihi\n  Zelnik-Manor", "title": "Compact Network Training for Person ReID", "comments": null, "journal-ref": null, "doi": "10.1145/3372278.3390686", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of person re-identification (ReID) has attracted growing attention\nin recent years leading to improved performance, albeit with little focus on\nreal-world applications. Most SotA methods are based on heavy pre-trained\nmodels, e.g. ResNet50 (~25M parameters), which makes them less practical and\nmore tedious to explore architecture modifications. In this study, we focus on\na small-sized randomly initialized model that enables us to easily introduce\narchitecture and training modifications suitable for person ReID. The outcomes\nof our study are a compact network and a fitting training regime. We show the\nrobustness of the network by outperforming the SotA on both Market1501 and\nDukeMTMC. Furthermore, we show the representation power of our ReID network via\nSotA results on a different task of multi-object tracking.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 20:16:55 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 15:08:35 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 08:17:01 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Lawen", "Hussam", ""], ["Ben-Cohen", "Avi", ""], ["Protter", "Matan", ""], ["Friedman", "Itamar", ""], ["Zelnik-Manor", "Lihi", ""]]}, {"id": "1910.07042", "submitter": "Mayoore Jaiswal", "authors": "Mayoore S. Jaiswal, Bumsoo Kang, Jinho Lee, Minsik Cho", "title": "MUTE: Data-Similarity Driven Multi-hot Target Encoding for Neural\n  Network Design", "comments": "NeurIPS Workshop 2019 - Learning with Rich Experience: Integration of\n  Learning Paradigms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Target encoding is an effective technique to deliver better performance for\nconventional machine learning methods, and recently, for deep neural networks\nas well. However, the existing target encoding approaches require significant\nincrease in the learning capacity, thus demand higher computation power and\nmore training data. In this paper, we present a novel and efficient target\nencoding scheme, MUTE to improve both generalizability and robustness of a\ntarget model by understanding the inter-class characteristics of a target\ndataset. By extracting the confusion level between the target classes in a\ndataset, MUTE strategically optimizes the Hamming distances among target\nencoding. Such optimized target encoding offers higher classification strength\nfor neural network models with negligible computation overhead and without\nincreasing the model size. When MUTE is applied to the popular image\nclassification networks and datasets, our experimental results show that MUTE\noffers better generalization and defense against the noises and adversarial\nattacks over the existing solutions.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 20:23:06 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jaiswal", "Mayoore S.", ""], ["Kang", "Bumsoo", ""], ["Lee", "Jinho", ""], ["Cho", "Minsik", ""]]}, {"id": "1910.07047", "submitter": "Salar Jafarlou", "authors": "Salar Jafarlou, Soheil Khorram, Vinay Kothapally, John H.L. Hansen", "title": "Analyzing Large Receptive Field Convolutional Networks for Distant\n  Speech Recognition", "comments": "ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant efforts over the last few years to build a robust\nautomatic speech recognition (ASR) system for different acoustic settings, the\nperformance of the current state-of-the-art technologies significantly degrades\nin noisy reverberant environments.\n  Convolutional Neural Networks (CNNs) have been successfully used to achieve\nsubstantial improvements in many speech processing applications including\ndistant speech recognition (DSR). However, standard CNN architectures were not\nefficient in capturing long-term speech dynamics, which are essential in the\ndesign of a robust DSR system. In the present study, we address this issue by\ninvestigating variants of large receptive field CNNs (LRF-CNNs) which include\ndeeply recursive networks, dilated convolutional neural networks, and stacked\nhourglass networks. To compare the efficacy of the aforementioned architectures\nwith the standard CNN for Wall Street Journal (WSJ) corpus, we use a hybrid\nDNN-HMM based speech recognition system. We extend the study to evaluate the\nsystem performances for distant speech simulated using realistic room impulse\nresponses (RIRs). Our experiments show that with fixed number of parameters\nacross all architectures, the large receptive field networks show consistent\nimprovements over the standard CNNs for distant speech. Amongst the explored\nLRF-CNNs, stacked hourglass network has shown improvements with a 8.9% relative\nreduction in word error rate (WER) and 10.7% relative improvement in frame\naccuracy compared to the standard CNNs for distant simulated speech signals.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 20:47:29 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Jafarlou", "Salar", ""], ["Khorram", "Soheil", ""], ["Kothapally", "Vinay", ""], ["Hansen", "John H. L.", ""]]}, {"id": "1910.07056", "submitter": "Youngsuk Park", "authors": "Youngsuk Park, Sauptik Dhar, Stephen Boyd, Mohak Shah", "title": "Variable Metric Proximal Gradient Method with Diagonal Barzilai-Borwein\n  Stepsize", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable metric proximal gradient (VM-PG) is a widely used class of convex\noptimization method. Lately, there has been a lot of research on the\ntheoretical guarantees of VM-PG with different metric selections. However, most\nsuch metric selections are dependent on (an expensive) Hessian, or limited to\nscalar stepsizes like the Barzilai-Borwein (BB) stepsize with lots of\nsafeguarding. Instead, in this paper we propose an adaptive metric selection\nstrategy called the diagonal Barzilai-Borwein (BB) stepsize. The proposed\ndiagonal selection better captures the local geometry of the problem while\nkeeping per-step computation cost similar to the scalar BB stepsize i.e.\n$O(n)$. Under this metric selection for VM-PG, the theoretical convergence is\nanalyzed. Our empirical studies illustrate the improved convergence results\nunder the proposed diagonal BB stepsize, specifically for ill-conditioned\nmachine learning problems for both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 21:04:11 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Park", "Youngsuk", ""], ["Dhar", "Sauptik", ""], ["Boyd", "Stephen", ""], ["Shah", "Mohak", ""]]}, {"id": "1910.07067", "submitter": "Mikhail Pautov", "authors": "Mikhail Pautov, Grigorii Melnikov, Edgar Kaziakhmedov, Klim Kireev,\n  Aleksandr Petiushko", "title": "On adversarial patches: real-world attack on ArcFace-100 face\n  recognition system", "comments": null, "journal-ref": "2019 International Multi-Conference on Engineering, Computer and\n  Information Sciences (SIBIRCON)", "doi": "10.1109/SIBIRCON48586.2019.8958134", "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works showed the vulnerability of image classifiers to adversarial\nattacks in the digital domain. However, the majority of attacks involve adding\nsmall perturbation to an image to fool the classifier. Unfortunately, such\nprocedures can not be used to conduct a real-world attack, where adding an\nadversarial attribute to the photo is a more practical approach. In this paper,\nwe study the problem of real-world attacks on face recognition systems. We\nexamine security of one of the best public face recognition systems,\nLResNet100E-IR with ArcFace loss, and propose a simple method to attack it in\nthe physical world. The method suggests creating an adversarial patch that can\nbe printed, added as a face attribute and photographed; the photo of a person\nwith such attribute is then passed to the classifier such that the classifier's\nrecognized class changes from correct to the desired one. Proposed generating\nprocedure allows projecting adversarial patches not only on different areas of\nthe face, such as nose or forehead but also on some wearable accessory, such as\neyeglasses.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 21:49:56 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 12:35:59 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 23:14:52 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Pautov", "Mikhail", ""], ["Melnikov", "Grigorii", ""], ["Kaziakhmedov", "Edgar", ""], ["Kireev", "Klim", ""], ["Petiushko", "Aleksandr", ""]]}, {"id": "1910.07070", "submitter": "Wenqian Ronny Huang", "authors": "W. Ronny Huang, Yike Qi, Qianqian Li, Jonathan Degange", "title": "DeepErase: Weakly Supervised Ink Artifact Removal in Document Text\n  Images", "comments": "Conference paper at WACV 2020. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paper-intensive industries like insurance, law, and government have long\nleveraged optical character recognition (OCR) to automatically transcribe\nhordes of scanned documents into text strings for downstream processing. Even\nin 2019, there are still many scanned documents and mail that come into\nbusinesses in non-digital format. Text to be extracted from real world\ndocuments is often nestled inside rich formatting, such as tabular structures\nor forms with fill-in-the-blank boxes or underlines whose ink often touches or\neven strikes through the ink of the text itself. Further, the text region could\nhave random ink smudges or spurious strokes. Such ink artifacts can severely\ninterfere with the performance of recognition algorithms or other downstream\nprocessing tasks. In this work, we propose DeepErase, a neural-based\npreprocessor to erase ink artifacts from text images. We devise a method to\nprogrammatically assemble real text images and real artifacts into\nrealistic-looking \"dirty\" text images, and use them to train an artifact\nsegmentation network in a weakly supervised manner, since pixel-level\nannotations are automatically obtained during the assembly process. In addition\nto high segmentation accuracy, we show that our cleansed images achieve a\nsignificant boost in recognition accuracy by popular OCR software such as\nTesseract 4.0. Finally, we test DeepErase on out-of-distribution datasets (NIST\nSDB) of scanned IRS tax return forms and achieve double-digit improvements in\naccuracy. All experiments are performed on both printed and handwritten text.\nCode for all experiments is available at https://github.com/yikeqicn/DeepErase\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 21:57:04 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 00:50:27 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 05:35:49 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Huang", "W. Ronny", ""], ["Qi", "Yike", ""], ["Li", "Qianqian", ""], ["Degange", "Jonathan", ""]]}, {"id": "1910.07072", "submitter": "Chen-Yu Wei", "authors": "Chen-Yu Wei, Mehdi Jafarnia-Jahromi, Haipeng Luo, Hiteshi Sharma,\n  Rahul Jain", "title": "Model-free Reinforcement Learning in Infinite-horizon Average-reward\n  Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning is known to be memory and computation\nefficient and more amendable to large scale problems. In this paper, two\nmodel-free algorithms are introduced for learning infinite-horizon\naverage-reward Markov Decision Processes (MDPs). The first algorithm reduces\nthe problem to the discounted-reward version and achieves\n$\\mathcal{O}(T^{2/3})$ regret after $T$ steps, under the minimal assumption of\nweakly communicating MDPs. To our knowledge, this is the first model-free\nalgorithm for general MDPs in this setting. The second algorithm makes use of\nrecent advances in adaptive algorithms for adversarial multi-armed bandits and\nimproves the regret to $\\mathcal{O}(\\sqrt{T})$, albeit with a stronger ergodic\nassumption. This result significantly improves over the $\\mathcal{O}(T^{3/4})$\nregret achieved by the only existing model-free algorithm by Abbasi-Yadkori et\nal. (2019a) for ergodic MDPs in the infinite-horizon average-reward setting.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 22:01:31 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 15:23:05 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Wei", "Chen-Yu", ""], ["Jafarnia-Jahromi", "Mehdi", ""], ["Luo", "Haipeng", ""], ["Sharma", "Hiteshi", ""], ["Jain", "Rahul", ""]]}, {"id": "1910.07089", "submitter": "Subbarao Kambhampati", "authors": "Subbarao Kambhampati", "title": "Challenges of Human-Aware AI Systems", "comments": "To appear in AI Magazine (Written version of AAAI 2018 Presidential\n  Address. Video and slides at http://bit.ly/2tHyzAh )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From its inception, AI has had a rather ambivalent relationship to\nhumans---swinging between their augmentation and replacement. Now, as AI\ntechnologies enter our everyday lives at an ever increasing pace, there is a\ngreater need for AI systems to work synergistically with humans. To do this\neffectively, AI systems must pay more attention to aspects of intelligence that\nhelped humans work with each other---including social intelligence. I will\ndiscuss the research challenges in designing such human-aware AI systems,\nincluding modeling the mental states of humans in the loop, recognizing their\ndesires and intentions, providing proactive support, exhibiting explicable\nbehavior, giving cogent explanations on demand, and engendering trust. I will\nsurvey the progress made so far on these challenges, and highlight some\npromising directions. I will also touch on the additional ethical quandaries\nthat such systems pose. I will end by arguing that the quest for human-aware AI\nsystems broadens the scope of AI enterprise, necessitates and facilitates true\ninter-disciplinary collaborations, and can go a long way towards increasing\npublic acceptance of AI technologies.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 22:34:50 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Kambhampati", "Subbarao", ""]]}, {"id": "1910.07093", "submitter": "Jean Oh", "authors": "Jean Oh, Martial Hebert, Hae-Gon Jeon, Xavier Perez, Chia Dai, Yeeho\n  Song", "title": "Explainable Semantic Mapping for First Responders", "comments": "Artificial Intelligence for Humanitarian Assistance and Disaster\n  Response Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges in the semantic mapping problem in postdisaster\nenvironments is how to analyze a large amount of data efficiently with minimal\nsupervision. To address this challenge, we propose a deep learning-based\nsemantic mapping tool consisting of three main ideas. First, we develop a\nfrugal semantic segmentation algorithm that uses only a small amount of labeled\ndata. Next, we investigate on the problem of learning to detect a new class of\nobject using just a few training examples. Finally, we develop an explainable\ncost map learning algorithm that can be quickly trained to generate\ntraversability cost maps using only raw sensor data such as aerial-view\nimagery. This paper presents an overview of the proposed idea and the lessons\nlearned.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 22:58:19 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Oh", "Jean", ""], ["Hebert", "Martial", ""], ["Jeon", "Hae-Gon", ""], ["Perez", "Xavier", ""], ["Dai", "Chia", ""], ["Song", "Yeeho", ""]]}, {"id": "1910.07099", "submitter": "Jing Zhang", "authors": "Hong Wen and Jing Zhang and Yuan Wang and Fuyu Lv and Wentian Bao and\n  Quan Lin and Keping Yang", "title": "Entire Space Multi-Task Modeling via Post-Click Behavior Decomposition\n  for Conversion Rate Prediction", "comments": "10page, 7 figures. Accepted by SIGIR 2020. The source code will be\n  released at https://github.com/chaimi2013/ESM2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender system, as an essential part of modern e-commerce, consists of\ntwo fundamental modules, namely Click-Through Rate (CTR) and Conversion Rate\n(CVR) prediction. While CVR has a direct impact on the purchasing volume, its\nprediction is well-known challenging due to the Sample Selection Bias (SSB) and\nData Sparsity (DS) issues. Although existing methods, typically built on the\nuser sequential behavior path ``impression$\\to$click$\\to$purchase'', is\neffective for dealing with SSB issue, they still struggle to address the DS\nissue due to rare purchase training samples. Observing that users always take\nseveral purchase-related actions after clicking, we propose a novel idea of\npost-click behavior decomposition. Specifically, disjoint purchase-related\nDeterministic Action (DAction) and Other Action (OAction) are inserted between\nclick and purchase in parallel, forming a novel user sequential behavior graph\n``impression$\\to$click$\\to$D(O)Action$\\to$purchase''. Defining model on this\ngraph enables to leverage all the impression samples over the entire space and\nextra abundant supervised signals from D(O)Action, which will effectively\naddress the SSB and DS issues together. To this end, we devise a novel deep\nrecommendation model named Elaborated Entire Space Supervised Multi-task Model\n($ESM^{2}$). According to the conditional probability rule defined on the\ngraph, it employs multi-task learning to predict some decomposed sub-targets in\nparallel and compose them sequentially to formulate the final CVR. Extensive\nexperiments on both offline and online environments demonstrate the superiority\nof $ESM^{2}$ over state-of-the-art models. The source code and dataset will be\nreleased.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 23:15:42 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 00:44:54 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Wen", "Hong", ""], ["Zhang", "Jing", ""], ["Wang", "Yuan", ""], ["Lv", "Fuyu", ""], ["Bao", "Wentian", ""], ["Lin", "Quan", ""], ["Yang", "Keping", ""]]}, {"id": "1910.07104", "submitter": "Mehrdad Farajtabar", "authors": "Mehrdad Farajtabar, Navid Azizan, Alex Mott, Ang Li", "title": "Orthogonal Gradient Descent for Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are achieving state of the art and sometimes super-human\nperformance on learning tasks across a variety of domains. Whenever these\nproblems require learning in a continual or sequential manner, however, neural\nnetworks suffer from the problem of catastrophic forgetting; they forget how to\nsolve previous tasks after being trained on a new task, despite having the\nessential capacity to solve both tasks if they were trained on both\nsimultaneously. In this paper, we propose to address this issue from a\nparameter space perspective and study an approach to restrict the direction of\nthe gradient updates to avoid forgetting previously-learned data. We present\nthe Orthogonal Gradient Descent (OGD) method, which accomplishes this goal by\nprojecting the gradients from new tasks onto a subspace in which the neural\nnetwork output on previous task does not change and the projected gradient is\nstill in a useful direction for learning the new task. Our approach utilizes\nthe high capacity of a neural network more efficiently and does not require\nstoring the previously learned data that might raise privacy concerns.\nExperiments on common benchmarks reveal the effectiveness of the proposed OGD\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 23:31:26 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Farajtabar", "Mehrdad", ""], ["Azizan", "Navid", ""], ["Mott", "Alex", ""], ["Li", "Ang", ""]]}, {"id": "1910.07113", "submitter": "Matthias Plappert", "authors": "OpenAI, Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz\n  Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn\n  Powell, Raphael Ribas, Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter\n  Welinder, Lilian Weng, Qiming Yuan, Wojciech Zaremba, Lei Zhang", "title": "Solving Rubik's Cube with a Robot Hand", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that models trained only in simulation can be used to solve a\nmanipulation problem of unprecedented complexity on a real robot. This is made\npossible by two key components: a novel algorithm, which we call automatic\ndomain randomization (ADR) and a robot platform built for machine learning. ADR\nautomatically generates a distribution over randomized environments of\never-increasing difficulty. Control policies and vision state estimators\ntrained with ADR exhibit vastly improved sim2real transfer. For control\npolicies, memory-augmented models trained on an ADR-generated distribution of\nenvironments show clear signs of emergent meta-learning at test time. The\ncombination of ADR with our custom robot platform allows us to solve a Rubik's\ncube with a humanoid robot hand, which involves both control and state\nestimation problems. Videos summarizing our results are available:\nhttps://openai.com/blog/solving-rubiks-cube/\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 00:59:05 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["OpenAI", "", ""], ["Akkaya", "Ilge", ""], ["Andrychowicz", "Marcin", ""], ["Chociej", "Maciek", ""], ["Litwin", "Mateusz", ""], ["McGrew", "Bob", ""], ["Petron", "Arthur", ""], ["Paino", "Alex", ""], ["Plappert", "Matthias", ""], ["Powell", "Glenn", ""], ["Ribas", "Raphael", ""], ["Schneider", "Jonas", ""], ["Tezak", "Nikolas", ""], ["Tworek", "Jerry", ""], ["Welinder", "Peter", ""], ["Weng", "Lilian", ""], ["Yuan", "Qiming", ""], ["Zaremba", "Wojciech", ""], ["Zhang", "Lei", ""]]}, {"id": "1910.07115", "submitter": "Yu Zhang", "authors": "Yu Zhang, Frank F. Xu, Sha Li, Yu Meng, Xuan Wang, Qi Li, Jiawei Han", "title": "HiGitClass: Keyword-Driven Hierarchical Classification of GitHub\n  Repositories", "comments": "10 pages; Accepted to ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GitHub has become an important platform for code sharing and scientific\nexchange. With the massive number of repositories available, there is a\npressing need for topic-based search. Even though the topic label functionality\nhas been introduced, the majority of GitHub repositories do not have any\nlabels, impeding the utility of search and topic-based analysis. This work\ntargets the automatic repository classification problem as\n\\textit{keyword-driven hierarchical classification}. Specifically, users only\nneed to provide a label hierarchy with keywords to supply as supervision. This\nsetting is flexible, adaptive to the users' needs, accounts for the different\ngranularity of topic labels and requires minimal human effort. We identify\nthree key challenges of this problem, namely (1) the presence of multi-modal\nsignals; (2) supervision scarcity and bias; (3) supervision format mismatch. In\nrecognition of these challenges, we propose the \\textsc{HiGitClass} framework,\ncomprising of three modules: heterogeneous information network embedding;\nkeyword enrichment; topic modeling and pseudo document generation. Experimental\nresults on two GitHub repository collections confirm that \\textsc{HiGitClass}\nis superior to existing weakly-supervised and dataless hierarchical\nclassification methods, especially in its ability to integrate both structured\nand unstructured data for repository classification.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 01:05:26 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Zhang", "Yu", ""], ["Xu", "Frank F.", ""], ["Li", "Sha", ""], ["Meng", "Yu", ""], ["Wang", "Xuan", ""], ["Li", "Qi", ""], ["Han", "Jiawei", ""]]}, {"id": "1910.07117", "submitter": "Tianxing He", "authors": "Tianxing He and Jun Liu and Kyunghyun Cho and Myle Ott and Bing Liu\n  and James Glass and Fuchun Peng", "title": "Analyzing the Forgetting Problem in the Pretrain-Finetuning of Dialogue\n  Response Models", "comments": null, "journal-ref": "EACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study how the finetuning stage in the pretrain-finetune\nframework changes the behavior of a pretrained neural language generator. We\nfocus on the transformer encoder-decoder model for the open-domain dialogue\nresponse generation task. Our major finding is that after standard finetuning,\nthe model forgets some of the important language generation skills acquired\nduring large-scale pretraining. We demonstrate the forgetting phenomenon\nthrough a set of detailed behavior analysis from the perspectives of knowledge\ntransfer, context sensitivity, and function space projection. As a preliminary\nattempt to alleviate the forgetting problem, we propose an intuitive finetuning\nstrategy named \"mix-review\". We find that mix-review effectively regularizes\nthe finetuning process, and the forgetting problem is alleviated to some\nextent. Finally, we discuss interesting behavior of the resulting dialogue\nmodel and its implications.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 01:10:10 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 23:38:37 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 19:43:05 GMT"}, {"version": "v4", "created": "Thu, 23 Apr 2020 17:56:28 GMT"}, {"version": "v5", "created": "Sat, 16 Jan 2021 19:14:41 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["He", "Tianxing", ""], ["Liu", "Jun", ""], ["Cho", "Kyunghyun", ""], ["Ott", "Myle", ""], ["Liu", "Bing", ""], ["Glass", "James", ""], ["Peng", "Fuchun", ""]]}, {"id": "1910.07123", "submitter": "Martin Jankowiak", "authors": "Martin Jankowiak, Geoff Pleiss, Jacob R. Gardner", "title": "Parametric Gaussian Process Regressors", "comments": "17 pages, 10 figures; as appeared in ICML 2020", "journal-ref": "International Conference on Machine Learning, pp. 4702-4712. PMLR,\n  2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of inducing point methods with stochastic variational\ninference has enabled approximate Gaussian Process (GP) inference on large\ndatasets. Unfortunately, the resulting predictive distributions often exhibit\nsubstantially underestimated uncertainties. Notably, in the regression case the\npredictive variance is typically dominated by observation noise, yielding\nuncertainty estimates that make little use of the input-dependent function\nuncertainty that makes GP priors attractive. In this work we propose two simple\nmethods for scalable GP regression that address this issue and thus yield\nsubstantially improved predictive uncertainties. The first applies variational\ninference to FITC (Fully Independent Training Conditional; Snelson\net.~al.~2006). The second bypasses posterior approximations and instead\ndirectly targets the posterior predictive distribution. In an extensive\nempirical comparison with a number of alternative methods for scalable GP\nregression, we find that the resulting predictive distributions exhibit\nsignificantly better calibrated uncertainties and higher log likelihoods--often\nby as much as half a nat per datapoint.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 01:27:15 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 16:36:01 GMT"}, {"version": "v3", "created": "Sat, 26 Dec 2020 17:16:16 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jankowiak", "Martin", ""], ["Pleiss", "Geoff", ""], ["Gardner", "Jacob R.", ""]]}, {"id": "1910.07150", "submitter": "Jiewen Wu", "authors": "Jiewen Wu, Luis Fernando D'Haro, Nancy F. Chen, Pavitra Krishnaswamy,\n  Rafael E. Banchs", "title": "Joint Learning of Word and Label Embeddings for Sequence Labelling in\n  Spoken Language Understanding", "comments": "Accepted for publication at ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an architecture to jointly learn word and label embeddings for\nslot filling in spoken language understanding. The proposed approach encodes\nlabels using a combination of word embeddings and straightforward word-label\nassociation from the training data. Compared to the state-of-the-art methods,\nour approach does not require label embeddings as part of the input and\ntherefore lends itself nicely to a wide range of model architectures. In\naddition, our architecture computes contextual distances between words and\nlabels to avoid adding contextual windows, thus reducing memory footprint. We\nvalidate the approach on established spoken dialogue datasets and show that it\ncan achieve state-of-the-art performance with much fewer trainable parameters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 03:28:14 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Wu", "Jiewen", ""], ["D'Haro", "Luis Fernando", ""], ["Chen", "Nancy F.", ""], ["Krishnaswamy", "Pavitra", ""], ["Banchs", "Rafael E.", ""]]}, {"id": "1910.07151", "submitter": "Peng Yang", "authors": "Peng Yang and Qi Yang and Ke Tang and Xin Yao", "title": "Parallel Exploration via Negatively Correlated Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective exploration is a key to successful search. The recently proposed\nNegatively Correlated Search (NCS) tries to achieve this by parallel\nexploration, where a set of search processes are driven to be negatively\ncorrelated so that different promising areas of the search space can be visited\nsimultaneously. Various applications have verified the advantages of such novel\nsearch behaviors. Nevertheless, the mathematical understandings are still\nlacking as the previous NCS was mostly devised by intuition. In this paper, a\nmore principled NCS is presented, explaining that the parallel exploration is\nequivalent to the explicit maximization of both the population diversity and\nthe population solution qualities, and can be optimally obtained by partially\ngradient descending both models with respect to each search process. For\nempirical assessments, the reinforcement learning tasks that largely demand\nexploration ability is considered. The new NCS is applied to the popular\nreinforcement learning problems, i.e., playing Atari games, to directly train a\ndeep convolution network with 1.7 million connection weights in the\nenvironments with uncertain and delayed rewards. Empirical results show that\nthe significant advantages of NCS over the compared state-of-the-art methods\ncan be highly owed to the effective parallel exploration ability.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 03:30:29 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 07:44:06 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Yang", "Peng", ""], ["Yang", "Qi", ""], ["Tang", "Ke", ""], ["Yao", "Xin", ""]]}, {"id": "1910.07153", "submitter": "Mingfei Gao", "authors": "Mingfei Gao, Zizhao Zhang, Guo Yu, Sercan O. Arik, Larry S. Davis,\n  Tomas Pfister", "title": "Consistency-based Semi-supervised Active Learning: Towards Minimizing\n  Labeling Cost", "comments": "Accepted by ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) combines data labeling and model training to minimize\nthe labeling cost by prioritizing the selection of high value data that can\nbest improve model performance. In pool-based active learning, accessible\nunlabeled data are not used for model training in most conventional methods.\nHere, we propose to unify unlabeled sample selection and model training towards\nminimizing labeling cost, and make two contributions towards that end. First,\nwe exploit both labeled and unlabeled data using semi-supervised learning (SSL)\nto distill information from unlabeled data during the training stage. Second,\nwe propose a consistency-based sample selection metric that is coherent with\nthe training objective such that the selected samples are effective at\nimproving model performance. We conduct extensive experiments on image\nclassification tasks. The experimental results on CIFAR-10, CIFAR-100 and\nImageNet demonstrate the superior performance of our proposed method with\nlimited labeled data, compared to the existing methods and the alternative AL\nand SSL combinations. Additionally, we study an important yet under-explored\nproblem -- \"When can we start learning-based AL selection?\". We propose a\nmeasure that is empirically correlated with the AL target loss and is\npotentially useful for determining the proper starting point of learning-based\nAL methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 03:31:53 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 04:21:15 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Gao", "Mingfei", ""], ["Zhang", "Zizhao", ""], ["Yu", "Guo", ""], ["Arik", "Sercan O.", ""], ["Davis", "Larry S.", ""], ["Pfister", "Tomas", ""]]}, {"id": "1910.07162", "submitter": "Han Zhao", "authors": "Han Zhao, Amanda Coston, Tameem Adel, Geoffrey J. Gordon", "title": "Conditional Learning of Fair Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithm for learning fair representations that can\nsimultaneously mitigate two notions of disparity among different demographic\nsubgroups in the classification setting. Two key components underpinning the\ndesign of our algorithm are balanced error rate and conditional alignment of\nrepresentations. We show how these two components contribute to ensuring\naccuracy parity and equalized false-positive and false-negative rates across\ngroups without impacting demographic parity. Furthermore, we also demonstrate\nboth in theory and on two real-world experiments that the proposed algorithm\nleads to a better utility-fairness trade-off on balanced datasets compared with\nexisting algorithms on learning fair representations for classification.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 04:12:50 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 18:10:34 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 00:10:35 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhao", "Han", ""], ["Coston", "Amanda", ""], ["Adel", "Tameem", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1910.07169", "submitter": "Lanlan Liu", "authors": "Lanlan Liu, Michael Muelly, Jia Deng, Tomas Pfister, Li-Jia Li", "title": "Generative Modeling for Small-Data Object Detection", "comments": "Published in ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores object detection in the small data regime, where only a\nlimited number of annotated bounding boxes are available due to data rarity and\nannotation expense. This is a common challenge today with machine learning\nbeing applied to many new tasks where obtaining training data is more\nchallenging, e.g. in medical images with rare diseases that doctors sometimes\nonly see once in their life-time. In this work we explore this problem from a\ngenerative modeling perspective by learning to generate new images with\nassociated bounding boxes, and using these for training an object detector. We\nshow that simply training previously proposed generative models does not yield\nsatisfactory performance due to them optimizing for image realism rather than\nobject detection accuracy. To this end we develop a new model with a novel\nunrolling mechanism that jointly optimizes the generative model and a detector\nsuch that the generated images improve the performance of the detector. We show\nthis method outperforms the state of the art on two challenging datasets,\ndisease detection and small data pedestrian detection, improving the average\nprecision on NIH Chest X-ray by a relative 20% and localization accuracy by a\nrelative 50%.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 04:57:25 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Liu", "Lanlan", ""], ["Muelly", "Michael", ""], ["Deng", "Jia", ""], ["Pfister", "Tomas", ""], ["Li", "Li-Jia", ""]]}, {"id": "1910.07172", "submitter": "Davit Buniatyan", "authors": "Davit Buniatyan", "title": "Hyper: Distributed Cloud Processing for Large-Scale Deep Learning Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training and deploying deep learning models in real-world applications\nrequire processing large amounts of data. This is a challenging task when the\namount of data grows to a hundred terabytes, or even, petabyte-scale. We\nintroduce a hybrid distributed cloud framework with a unified view to multiple\nclouds and an on-premise infrastructure for processing tasks using both CPU and\nGPU compute instances at scale. The system implements a distributed file system\nand failure-tolerant task processing scheduler, independent of the language and\nDeep Learning framework used. It allows to utilize unstable cheap resources on\nthe cloud to significantly reduce costs. We demonstrate the scalability of the\nframework on running pre-processing, distributed training, hyperparameter\nsearch and large-scale inference tasks utilizing 10,000 CPU cores and 300 GPU\ninstances with the overall processing power of 30 petaflops.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 05:23:11 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Buniatyan", "Davit", ""]]}, {"id": "1910.07174", "submitter": "Momo Matsuda", "authors": "Momo Matsuda, Keiichi Morikuni, Akira Imakura, Xiucai Ye, Tetsuya\n  Sakurai", "title": "Multiclass spectral feature scaling method for dimensionality reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irregular features disrupt the desired classification. In this paper, we\nconsider aggressively modifying scales of features in the original space\naccording to the label information to form well-separated clusters in\nlow-dimensional space. The proposed method exploits spectral clustering to\nderive scaling factors that are used to modify the features. Specifically, we\nreformulate the Laplacian eigenproblem of the spectral clustering as an\neigenproblem of a linear matrix pencil whose eigenvector has the scaling\nfactors. Numerical experiments show that the proposed method outperforms\nwell-established supervised dimensionality reduction methods for toy problems\nwith more samples than features and real-world problems with more features than\nsamples.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 05:33:12 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Matsuda", "Momo", ""], ["Morikuni", "Keiichi", ""], ["Imakura", "Akira", ""], ["Ye", "Xiucai", ""], ["Sakurai", "Tetsuya", ""]]}, {"id": "1910.07178", "submitter": "Chirag Modi", "authors": "Chirag Modi, Uros Seljak", "title": "Generative Learning of Counterfactual for Synthetic Control Applications\n  in Econometrics", "comments": "6 pages, 3 figures. Accepted at NeurIPS 2019 Workshop on Causal\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common statistical problem in econometrics is to estimate the impact of a\ntreatment on a treated unit given a control sample with untreated outcomes.\nHere we develop a generative learning approach to this problem, learning the\nprobability distribution of the data, which can be used for downstream tasks\nsuch as post-treatment counterfactual prediction and hypothesis testing. We use\ncontrol samples to transform the data to a Gaussian and homoschedastic form and\nthen perform Gaussian process analysis in Fourier space, evaluating the optimal\nGaussian kernel via non-parametric power spectrum estimation. We combine this\nGaussian prior with the data likelihood given by the pre-treatment data of the\nsingle unit, to obtain the synthetic prediction of the unit post-treatment,\nwhich minimizes the error variance of synthetic prediction. Given the\ngenerative model the minimum variance counterfactual is unique, and comes with\nan associated error covariance matrix. We extend this basic formalism to\ninclude correlations of primary variable with other covariates of interest.\nGiven the probabilistic description of generative model we can compare\nsynthetic data prediction with real data to address the question of whether the\ntreatment had a statistically significant impact. For this purpose we develop a\nhypothesis testing approach and evaluate the Bayes factor. We apply the method\nto the well studied example of California (CA) tobacco sales tax of 1988. We\nalso perform a placebo analysis using control states to validate our\nmethodology. Our hypothesis testing method suggests 5.8:1 odds in favor of CA\ntobacco sales tax having an impact on the tobacco sales, a value that is at\nleast three times higher than any of the 38 control states.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 05:50:14 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Modi", "Chirag", ""], ["Seljak", "Uros", ""]]}, {"id": "1910.07186", "submitter": "Yihao Feng", "authors": "Ziyang Tang, Yihao Feng, Lihong Li, Dengyong Zhou, Qiang Liu", "title": "Doubly Robust Bias Reduction in Infinite Horizon Off-Policy Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infinite horizon off-policy policy evaluation is a highly challenging task\ndue to the excessively large variance of typical importance sampling (IS)\nestimators. Recently, Liu et al. (2018a) proposed an approach that\nsignificantly reduces the variance of infinite-horizon off-policy evaluation by\nestimating the stationary density ratio, but at the cost of introducing\npotentially high biases due to the error in density ratio estimation. In this\npaper, we develop a bias-reduced augmentation of their method, which can take\nadvantage of a learned value function to obtain higher accuracy. Our method is\ndoubly robust in that the bias vanishes when either the density ratio or the\nvalue function estimation is perfect. In general, when either of them is\naccurate, the bias can also be reduced. Both theoretical and empirical results\nshow that our method yields significant advantages over previous methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 06:33:17 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Tang", "Ziyang", ""], ["Feng", "Yihao", ""], ["Li", "Lihong", ""], ["Zhou", "Dengyong", ""], ["Liu", "Qiang", ""]]}, {"id": "1910.07201", "submitter": "Florian Lemarchand", "authors": "Florian Lemarchand, Cyril Marlin, Florent Montreuil, Erwan Nogues and\n  Maxime Pelcat", "title": "Electro-Magnetic Side-Channel Attack Through Learned Denoising and\n  Classification", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053913", "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an upgraded electro-magnetic side-channel attack that\nautomatically reconstructs the intercepted data. A novel system is introduced,\nrunning in parallel with leakage signal interception and catching compromising\ndata in real-time. Based on deep learning and character recognition the\nproposed system retrieves more than 57% of characters present in intercepted\nsignals regardless of signal type: analog or digital. The approach is also\nextended to a protection system that triggers an alarm if the system is\ncompromised, demonstrating a success rate over 95%. Based on software-defined\nradio and graphics processing unit architectures, this solution can be easily\ndeployed onto existing information systems where information shall be kept\nsecret.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 07:56:54 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Lemarchand", "Florian", ""], ["Marlin", "Cyril", ""], ["Montreuil", "Florent", ""], ["Nogues", "Erwan", ""], ["Pelcat", "Maxime", ""]]}, {"id": "1910.07207", "submitter": "Petros Christodoulou Mr", "authors": "Petros Christodoulou", "title": "Soft Actor-Critic for Discrete Action Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soft Actor-Critic is a state-of-the-art reinforcement learning algorithm for\ncontinuous action settings that is not applicable to discrete action settings.\nMany important settings involve discrete actions, however, and so here we\nderive an alternative version of the Soft Actor-Critic algorithm that is\napplicable to discrete action settings. We then show that, even without any\nhyperparameter tuning, it is competitive with the tuned model-free\nstate-of-the-art on a selection of games from the Atari suite.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 08:11:08 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 09:17:44 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Christodoulou", "Petros", ""]]}, {"id": "1910.07210", "submitter": "Chaitanya K. Joshi", "authors": "Chaitanya K. Joshi, Thomas Laurent, Xavier Bresson", "title": "On Learning Paradigms for the Travelling Salesman Problem", "comments": "Presented at the NeurIPS 2019 Graph Representation Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the impact of learning paradigms on training deep neural networks\nfor the Travelling Salesman Problem. We design controlled experiments to train\nsupervised learning (SL) and reinforcement learning (RL) models on fixed graph\nsizes up to 100 nodes, and evaluate them on variable sized graphs up to 500\nnodes. Beyond not needing labelled data, our results reveal favorable\nproperties of RL over SL: RL training leads to better emergent generalization\nto variable graph sizes and is a key component for learning scale-invariant\nsolvers for novel combinatorial problems.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 08:17:37 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 08:53:08 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Joshi", "Chaitanya K.", ""], ["Laurent", "Thomas", ""], ["Bresson", "Xavier", ""]]}, {"id": "1910.07212", "submitter": "Boaz Shmueli", "authors": "Boaz Shmueli", "title": "Tutorial on NLP-Inspired Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial covers a few recent papers in the field of network embedding.\nNetwork embedding is a collective term for techniques for mapping graph nodes\nto vectors of real numbers in a multidimensional space. To be useful, a good\nembedding should preserve the structure of the graph. The vectors can then be\nused as input to various network and graph analysis tasks, such as link\nprediction. The papers discussed develop methods for the online learning of\nsuch embeddings, and include DeepWalk, LINE, node2vec, struc2vec and\nmegapath2vec. These new methods and developments in online learning of network\nembeddings have major applications for the analysis of graphs and networks,\nincluding online social networks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 08:25:07 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Shmueli", "Boaz", ""]]}, {"id": "1910.07224", "submitter": "R\\'emy Portelas", "authors": "R\\'emy Portelas, C\\'edric Colas, Katja Hofmann, Pierre-Yves Oudeyer", "title": "Teacher algorithms for curriculum learning of Deep RL in continuously\n  parameterized environments", "comments": "Accepted at CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of how a teacher algorithm can enable an unknown Deep\nReinforcement Learning (DRL) student to become good at a skill over a wide\nrange of diverse environments. To do so, we study how a teacher algorithm can\nlearn to generate a learning curriculum, whereby it sequentially samples\nparameters controlling a stochastic procedural generation of environments.\nBecause it does not initially know the capacities of its student, a key\nchallenge for the teacher is to discover which environments are easy, difficult\nor unlearnable, and in what order to propose them to maximize the efficiency of\nlearning over the learnable ones. To achieve this, this problem is transformed\ninto a surrogate continuous bandit problem where the teacher samples\nenvironments in order to maximize absolute learning progress of its student. We\npresent a new algorithm modeling absolute learning progress with Gaussian\nmixture models (ALP-GMM). We also adapt existing algorithms and provide a\ncomplete study in the context of DRL. Using parameterized variants of the\nBipedalWalker environment, we study their efficiency to personalize a learning\ncurriculum for different learners (embodiments), their robustness to the ratio\nof learnable/unlearnable environments, and their scalability to non-linear and\nhigh-dimensional parameter spaces. Videos and code are available at\nhttps://github.com/flowersteam/teachDeepRL.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 09:07:43 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Portelas", "R\u00e9my", ""], ["Colas", "C\u00e9dric", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1910.07225", "submitter": "Julian Stier", "authors": "Julian Stier and Michael Granitzer", "title": "Structural Analysis of Sparse Neural Networks", "comments": "23rd International Conference on Knowledge-Based and Intelligent\n  Information & Engineering Systems", "journal-ref": null, "doi": "10.1016/j.procs.2019.09.165", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Neural Networks regained attention due to their potential for\nmathematical and computational advantages. We give motivation to study\nArtificial Neural Networks (ANNs) from a network science perspective, provide a\ntechnique to embed arbitrary Directed Acyclic Graphs into ANNs and report study\nresults on predicting the performance of image classifiers based on the\nstructural properties of the networks' underlying graph. Results could further\nprogress neuroevolution and add explanations for the success of distinct\narchitectures from a structural perspective.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 09:08:42 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Stier", "Julian", ""], ["Granitzer", "Michael", ""]]}, {"id": "1910.07234", "submitter": "Anis Koubaa", "authors": "Adel Ammar, Anis Koubaa, Mohanned Ahmed, Abdulrahman Saad", "title": "Aerial Images Processing for Car Detection using Convolutional Neural\n  Networks: Comparison between Faster R-CNN and YoloV3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we address the problem of car detection from aerial images\nusing Convolutional Neural Networks (CNN). This problem presents additional\nchallenges as compared to car (or any object) detection from ground images\nbecause features of vehicles from aerial images are more difficult to discern.\nTo investigate this issue, we assess the performance of two state-of-the-art\nCNN algorithms, namely Faster R-CNN, which is the most popular region-based\nalgorithm, and YOLOv3, which is known to be the fastest detection algorithm. We\nanalyze two datasets with different characteristics to check the impact of\nvarious factors, such as UAV's altitude, camera resolution, and object size. A\ntotal of 39 training experiments were conducted to account for the effect of\ndifferent hyperparameter values. The objective of this work is to conduct the\nmost robust and exhaustive comparison between these two cutting-edge algorithms\non the specific domain of aerial images. By using a variety of metrics, we show\nthat YOLOv3 yields better performance in most configurations, except that it\nexhibits a lower recall and less confident detections when object sizes and\nscales in the testing dataset differ largely from those in the training\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 09:25:35 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 20:11:47 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Ammar", "Adel", ""], ["Koubaa", "Anis", ""], ["Ahmed", "Mohanned", ""], ["Saad", "Abdulrahman", ""]]}, {"id": "1910.07236", "submitter": "Nikolay Jetchev", "authors": "Nikolay Jetchev, Urs Bergmann, G\\\"okhan Yildirim", "title": "Transform the Set: Memory Attentive Generation of Guided and Unguided\n  Image Collages", "comments": "To be presented at the NeurIPS 2019 workshop on Creativity and AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cutting and pasting image segments feels intuitive: the choice of source\ntemplates gives artists flexibility in recombining existing source material.\nFormally, this process takes an image set as input and outputs a collage of the\nset elements. Such selection from sets of source templates does not fit easily\nin classical convolutional neural models requiring inputs of fixed size.\nInspired by advances in attention and set-input machine learning, we present a\nnovel architecture that can generate in one forward pass image collages of\nsource templates using set-structured representations. This paper has the\nfollowing contributions: (i) a novel framework for image generation called\nMemory Attentive Generation of Image Collages (MAGIC) which gives artists new\nways to create digital collages; (ii) from the machine-learning perspective, we\nshow a novel Generative Adversarial Networks (GAN) architecture that uses\nSet-Transformer layers and set-pooling to blend sets of random image samples -\na hybrid non-parametric approach.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 09:28:40 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 10:57:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Jetchev", "Nikolay", ""], ["Bergmann", "Urs", ""], ["Yildirim", "G\u00f6khan", ""]]}, {"id": "1910.07247", "submitter": "Gard Spreemann", "authors": "Stefania Ebli, Gard Spreemann", "title": "A Notion of Harmonic Clustering in Simplicial Complexes", "comments": null, "journal-ref": "2019 18th IEEE International Conference On Machine Learning And\n  Applications (ICMLA)", "doi": "10.1109/ICMLA.2019.00182", "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline a novel clustering scheme for simplicial complexes that produces\nclusters of simplices in a way that is sensitive to the homology of the\ncomplex. The method is inspired by, and can be seen as a higher-dimensional\nversion of, graph spectral clustering. The algorithm involves only sparse\neigenproblems, and is therefore computationally efficient. We believe that it\nhas broad application as a way to extract features from simplicial complexes\nthat often arise in topological data analysis.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 09:40:20 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Ebli", "Stefania", ""], ["Spreemann", "Gard", ""]]}, {"id": "1910.07254", "submitter": "Florian Henkel", "authors": "Florian Henkel, Rainer Kelz, Gerhard Widmer", "title": "Audio-Conditioned U-Net for Position Estimation in Full Sheet Images", "comments": "Accepted at International Workshop on Reading Music Systems 2019\n  (WoRMS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of score following is to track a musical performance, usually in the\nform of audio, in a corresponding score representation. Established methods\nmainly rely on computer-readable scores in the form of MIDI or MusicXML and\nachieve robust and reliable tracking results. Recently, multimodal deep\nlearning methods have been used to follow along musical performances in raw\nsheet images. Among the current limits of these systems is that they require a\nnon trivial amount of preprocessing steps that unravel the raw sheet image into\na single long system of staves. The current work is an attempt at removing this\nparticular limitation. We propose an architecture capable of estimating\nmatching score positions directly within entire unprocessed sheet images. We\nargue that this is a necessary first step towards a fully integrated score\nfollowing system that does not rely on any preprocessing steps such as optical\nmusic recognition.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 09:58:27 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Henkel", "Florian", ""], ["Kelz", "Rainer", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1910.07265", "submitter": "Jeroen Berrevoets", "authors": "Jeroen Berrevoets, Sam Verboven, Wouter Verbeke", "title": "Optimising Individual-Treatment-Effect Using Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying causal inference models in areas such as economics, healthcare and\nmarketing receives great interest from the machine learning community. In\nparticular, estimating the individual-treatment-effect (ITE) in settings such\nas precision medicine and targeted advertising has peaked in application.\nOptimising this ITE under the strong-ignorability-assumption -- meaning all\nconfounders expressing influence on the outcome of a treatment are registered\nin the data -- is often referred to as uplift modeling (UM). While these\ntechniques have proven useful in many settings, they suffer vividly in a\ndynamic environment due to concept drift. Take for example the negative\ninfluence on a marketing campaign when a competitor product is released. To\ncounter this, we propose the uplifted contextual multi-armed bandit (U-CMAB), a\nnovel approach to optimise the ITE by drawing upon bandit literature.\nExperiments on real and simulated data indicate that our proposed approach\ncompares favourably against the state-of-the-art. All our code can be found\nonline at https://github.com/vub-dl/u-cmab.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 10:33:31 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Berrevoets", "Jeroen", ""], ["Verboven", "Sam", ""], ["Verbeke", "Wouter", ""]]}, {"id": "1910.07283", "submitter": "Matteo Dell'Amico Ph.D.", "authors": "Matteo Dell'Amico", "title": "FISHDBC: Flexible, Incremental, Scalable, Hierarchical Density-Based\n  Clustering for Arbitrary Data and Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FISHDBC is a flexible, incremental, scalable, and hierarchical density-based\nclustering algorithm. It is flexible because it empowers users to work on\narbitrary data, skipping the feature extraction step that usually transforms\nraw data in numeric arrays letting users define an arbitrary distance function\ninstead. It is incremental and scalable: it avoids the $\\mathcal O(n^2)$\nperformance of other approaches in non-metric spaces and requires only\nlightweight computation to update the clustering when few items are added. It\nis hierarchical: it produces a \"flat\" clustering which can be expanded to a\ntree structure, so that users can group and/or divide clusters in sub- or\nsuper-clusters when data exploration requires so. It is density-based and\napproximates HDBSCAN*, an evolution of DBSCAN.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 11:06:23 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Dell'Amico", "Matteo", ""]]}, {"id": "1910.07291", "submitter": "Christopher Foley Dr", "authors": "Philip G. Breen, Christopher N. Foley, Tjarda Boekholt, Simon\n  Portegies Zwart", "title": "Newton vs the machine: solving the chaotic three-body problem using deep\n  neural networks", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": "10.1093/mnras/staa713", "report-no": null, "categories": "astro-ph.GA astro-ph.SR cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its formulation by Sir Isaac Newton, the problem of solving the\nequations of motion for three bodies under their own gravitational force has\nremained practically unsolved. Currently, the solution for a given\ninitialization can only be found by performing laborious iterative calculations\nthat have unpredictable and potentially infinite computational cost, due to the\nsystem's chaotic nature. We show that an ensemble of solutions obtained using\nan arbitrarily precise numerical integrator can be used to train a deep\nartificial neural network (ANN) that, over a bounded time interval, provides\naccurate solutions at fixed computational cost and up to 100 million times\nfaster than a state-of-the-art solver. Our results provide evidence that, for\ncomputationally challenging regions of phase-space, a trained ANN can replace\nexisting numerical solvers, enabling fast and scalable simulations of many-body\nsystems to shed light on outstanding phenomena such as the formation of\nblack-hole binary systems or the origin of the core collapse in dense star\nclusters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 11:31:18 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Breen", "Philip G.", ""], ["Foley", "Christopher N.", ""], ["Boekholt", "Tjarda", ""], ["Zwart", "Simon Portegies", ""]]}, {"id": "1910.07294", "submitter": "Ozsel Kilinc", "authors": "Ozsel Kilinc, Yang Hu, Giovanni Montana", "title": "Reinforcement Learning for Robotic Manipulation using Simulated\n  Locomotion Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robotic manipulation through reinforcement learning (RL) using only\nsparse reward signals is still considered a largely unsolved problem.\nLeveraging human demonstrations can make the learning process more sample\nefficient, but obtaining high-quality demonstrations can be costly or\nunfeasible. In this paper we propose a novel approach that introduces\nobject-level demonstrations, i.e. examples of where the objects should be at\nany state. These demonstrations are generated automatically through RL hence\nrequire no expert knowledge. We observe that, during a manipulation task, an\nobject is moved from an initial to a final position. When seen from the point\nof view of the object being manipulated, this induces a locomotion task that\ncan be decoupled from the manipulation task and learnt through a\nphysically-realistic simulator. The resulting object-level trajectories, called\nsimulated locomotion demonstrations (SLDs), are then leveraged to define\nauxiliary rewards that are used to learn the manipulation policy. The proposed\napproach has been evaluated on 13 tasks of increasing complexity, and has been\ndemonstrated to achieve higher success rate and faster learning rates compared\nto alternative algorithms. SLDs are especially beneficial for tasks like\nmulti-object stacking and non-rigid object manipulation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 11:38:43 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 10:19:13 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 21:58:30 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kilinc", "Ozsel", ""], ["Hu", "Yang", ""], ["Montana", "Giovanni", ""]]}, {"id": "1910.07295", "submitter": "Yuta Saito", "authors": "Yuta Saito", "title": "Offline Recommender Learning Meets Unsupervised Domain Adaptation", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the offline recommender learning problem in the presence of\nselection bias in rating feedback. A current promising solution to address the\nbias is to use the propensity score. However, the performance of the existing\npropensity-based methods can significantly suffer from propensity estimation\nbias. To solve the problem, we formulate the recommendation with selection bias\nas unsupervised domain adaptation and derive a propensity-independent\ngeneralization error bound. We further propose a novel algorithm that minimizes\nthe bound via adversarial learning. Our theory and algorithm do not depend on\npropensity scores, and thus can result in a well-performing rating predictor\nwithout requiring the true propensity information. Empirical evaluation\ndemonstrates the effectiveness and real-world applicability of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 11:41:17 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 16:36:09 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 21:04:32 GMT"}, {"version": "v4", "created": "Wed, 29 Jan 2020 13:07:20 GMT"}, {"version": "v5", "created": "Thu, 18 Jun 2020 07:56:23 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Saito", "Yuta", ""]]}, {"id": "1910.07320", "submitter": "David Blei", "authors": "Yixin Wang and David M. Blei", "title": "The Blessings of Multiple Causes: A Reply to Ogburn et al. (2019)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ogburn et al. (2019, arXiv:1910.05438) discuss \"The Blessings of Multiple\nCauses\" (Wang and Blei, 2018, arXiv:1805.06826). Many of their remarks are\ninteresting. But they also claim that the paper has \"foundational errors\" and\nthat its \"premise is...incorrect.\" These claims are not substantiated. There\nare no foundational errors; the premise is correct.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 16:43:53 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:20:25 GMT"}, {"version": "v3", "created": "Fri, 20 Dec 2019 19:34:28 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Wang", "Yixin", ""], ["Blei", "David M.", ""]]}, {"id": "1910.07323", "submitter": "Adrien Dufraux", "authors": "Adrien Dufraux, Emmanuel Vincent, Awni Hannun, Armelle Brun, Matthijs\n  Douze", "title": "Lead2Gold: Towards exploiting the full potential of noisy transcriptions\n  for speech recognition", "comments": "8 pages, 4 tables, Accepted for publication in ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transcriptions used to train an Automatic Speech Recognition (ASR) system\nmay contain errors. Usually, either a quality control stage discards\ntranscriptions with too many errors, or the noisy transcriptions are used as\nis. We introduce Lead2Gold, a method to train an ASR system that exploits the\nfull potential of noisy transcriptions. Based on a noise model of transcription\nerrors, Lead2Gold searches for better transcriptions of the training data with\na beam search that takes this noise model into account. The beam search is\ndifferentiable and does not require a forced alignment step, thus the whole\nsystem is trained end-to-end. Lead2Gold can be viewed as a new loss function\nthat can be used on top of any sequence-to-sequence deep neural network. We\nconduct proof-of-concept experiments on noisy transcriptions generated from\nletter corruptions with different noise levels. We show that Lead2Gold obtains\na better ASR accuracy than a competitive baseline which does not account for\nthe (artificially-introduced) transcription noise.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 12:55:34 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Dufraux", "Adrien", ""], ["Vincent", "Emmanuel", ""], ["Hannun", "Awni", ""], ["Brun", "Armelle", ""], ["Douze", "Matthijs", ""]]}, {"id": "1910.07333", "submitter": "Lahari Poddar", "authors": "Lahari Poddar, Gyorgy Szarvas, Lea Frermann", "title": "A Probabilistic Framework for Learning Domain Specific Hierarchical Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The meaning of a word often varies depending on its usage in different\ndomains. The standard word embedding models struggle to represent this\nvariation, as they learn a single global representation for a word. We propose\na method to learn domain-specific word embeddings, from text organized into\nhierarchical domains, such as reviews in an e-commerce website, where products\nfollow a taxonomy. Our structured probabilistic model allows vector\nrepresentations for the same word to drift away from each other for distant\ndomains in the taxonomy, to accommodate its domain-specific meanings. By\nlearning sets of domain-specific word representations jointly, our model can\nleverage domain relationships, and it scales well with the number of domains.\nUsing large real-world review datasets, we demonstrate the effectiveness of our\nmodel compared to state-of-the-art approaches, in learning domain-specific word\nembeddings that are both intuitive to humans and benefit downstream NLP tasks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 13:24:54 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 17:11:39 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Poddar", "Lahari", ""], ["Szarvas", "Gyorgy", ""], ["Frermann", "Lea", ""]]}, {"id": "1910.07344", "submitter": "Micha{\\l} Stypu{\\l}kowski", "authors": "Micha{\\l} Stypu{\\l}kowski, Maciej Zamorski, Maciej Zi\\k{e}ba, Jan\n  Chorowski", "title": "Conditional Invertible Flow for Point Cloud Generation", "comments": "Published in Sets & Partitions Workshop at NeurIPS 2019\n  (https://www.sets.parts/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a novel generative approach for 3D point clouds that\nmakes use of invertible flow-based models. The main idea of the method is to\ntreat a point cloud as a probability density in 3D space that is modeled using\na cloud-specific neural network. To capture the similarity between point clouds\nwe rely on parameter sharing among networks, with each cloud having only a\nsmall embedding vector that defines it. We use invertible flows networks to\ngenerate the individual point clouds, and to regularize the embedding vectors.\nWe evaluate the generative capabilities of the model both in qualitative and\nquantitative manner.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 13:47:05 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Stypu\u0142kowski", "Micha\u0142", ""], ["Zamorski", "Maciej", ""], ["Zi\u0119ba", "Maciej", ""], ["Chorowski", "Jan", ""]]}, {"id": "1910.07364", "submitter": "Sarthak Yadav", "authors": "Sarthak Yadav and Atul Rai", "title": "Frequency and temporal convolutional attention for text-independent\n  speaker recognition", "comments": "5 pages, 1 figure, 3 tables, submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Majority of the recent approaches for text-independent speaker recognition\napply attention or similar techniques for aggregation of frame-level feature\ndescriptors generated by a deep neural network (DNN) front-end. In this paper,\nwe propose methods of convolutional attention for independently modelling\ntemporal and frequency information in a convolutional neural network (CNN)\nbased front-end. Our system utilizes convolutional block attention modules\n(CBAMs) [1] appropriately modified to accommodate spectrogram inputs. The\nproposed CNN front-end fitted with the proposed convolutional attention modules\noutperform the no-attention and spatial-CBAM baselines by a significant margin\non the VoxCeleb [2, 3] speaker verification benchmark, and our best model\nachieves an equal error rate of 2:031% on the VoxCeleb1 test set, improving the\nexisting state of the art result by a significant margin. For a more thorough\nassessment of the effects of frequency and temporal attention in real-world\nconditions, we conduct ablation experiments by randomly dropping frequency bins\nand temporal frames from the input spectrograms, concluding that instead of\nmodelling either of the entities, simultaneously modelling temporal and\nfrequency attention translates to better real-world performance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 14:14:53 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 20:05:30 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Yadav", "Sarthak", ""], ["Rai", "Atul", ""]]}, {"id": "1910.07368", "submitter": "Jiwoong Im", "authors": "Daniel Jiwoong Im, Yibo Jiang, Nakul Verma", "title": "Model-Agnostic Meta-Learning using Runge-Kutta Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning has emerged as an important framework for learning new tasks\nfrom just a few examples. The success of any meta-learning model depends on (i)\nits fast adaptation to new tasks, as well as (ii) having a shared\nrepresentation across similar tasks. Here we extend the model-agnostic\nmeta-learning (MAML) framework introduced by Finn et al. (2017) to achieve\nimproved performance by analyzing the temporal dynamics of the optimization\nprocedure via the Runge-Kutta method. This method enables us to gain\nfine-grained control over the optimization and helps us achieve both the\nadaptation and representation goals across tasks. By leveraging this refined\ncontrol, we demonstrate that there are multiple principled ways to update MAML\nand show that the classic MAML optimization is simply a special case of\nsecond-order Runge-Kutta method that mainly focuses on fast-adaptation.\nExperiments on benchmark classification, regression and reinforcement learning\ntasks show that this refined control helps attain improved results.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 14:22:35 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 21:28:07 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Im", "Daniel Jiwoong", ""], ["Jiang", "Yibo", ""], ["Verma", "Nakul", ""]]}, {"id": "1910.07387", "submitter": "Alexander Wong", "authors": "Zhong Qiu Lin, Mohammad Javad Shafiee, Stanislav Bochkarev, Michael\n  St. Jules, Xiao Yu Wang, and Alexander Wong", "title": "Do Explanations Reflect Decisions? A Machine-centric Strategy to\n  Quantify the Performance of Explainability Algorithms", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a significant surge of interest recently around the concept of\nexplainable artificial intelligence (XAI), where the goal is to produce an\ninterpretation for a decision made by a machine learning algorithm. Of\nparticular interest is the interpretation of how deep neural networks make\ndecisions, given the complexity and `black box' nature of such networks. Given\nthe infancy of the field, there has been very limited exploration into the\nassessment of the performance of explainability methods, with most evaluations\ncentered around subjective visual interpretation of the produced\ninterpretations. In this study, we explore a more machine-centric strategy for\nquantifying the performance of explainability methods on deep neural networks\nvia the notion of decision-making impact analysis. We introduce two\nquantitative performance metrics: i) Impact Score, which assesses the\npercentage of critical factors with either strong confidence reduction impact\nor decision changing impact, and ii) Impact Coverage, which assesses the\npercentage coverage of adversarially impacted factors in the input. A\ncomprehensive analysis using this approach was conducted on several\nstate-of-the-art explainability methods (LIME, SHAP, Expected Gradients,\nGSInquire) on a ResNet-50 deep convolutional neural network using a subset of\nImageNet for the task of image classification. Experimental results show that\nthe critical regions identified by LIME within the tested images had the lowest\nimpact on the decision-making process of the network (~38%), with progressive\nincrease in decision-making impact for SHAP (~44%), Expected Gradients (~51%),\nand GSInquire (~76%). While by no means perfect, the hope is that the proposed\nmachine-centric strategy helps push the conversation forward towards better\nmetrics for evaluating explainability methods and improve trust in deep neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 14:52:51 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 21:14:22 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lin", "Zhong Qiu", ""], ["Shafiee", "Mohammad Javad", ""], ["Bochkarev", "Stanislav", ""], ["Jules", "Michael St.", ""], ["Wang", "Xiao Yu", ""], ["Wong", "Alexander", ""]]}, {"id": "1910.07392", "submitter": "Jun Shi", "authors": "Jun Shi and Zhibo Chen", "title": "Reinforced Bit Allocation under Task-Driven Semantic Distortion Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid growing intelligent applications require optimized bit allocation in\nimage/video coding to support specific task-driven scenarios such as detection,\nclassification, segmentation, etc. Some learning-based frameworks have been\nproposed for this purpose due to their inherent end-to-end optimization\nmechanisms. However, it is still quite challenging to integrate these\ntask-driven metrics seamlessly into traditional hybrid coding framework. To the\nbest of our knowledge, this paper is the first work trying to solve this\nchallenge based on reinforcement learning (RL) approach. Specifically, we\nformulate the bit allocation problem as a Markovian Decision Process (MDP) and\ntrain RL agents to automatically decide the quantization parameter (QP) of each\ncoding tree unit (CTU) for HEVC intra coding, according to the task-driven\nsemantic distortion metrics. This bit allocation scheme can maximize the\nsemantic level fidelity of the task, such as classification accuracy, while\nminimizing the bit-rate. We also employ gradient class activation map\n(Grad-CAM) and Mask R-CNN tools to extract task-related importance maps to help\nthe agents make decisions. Extensive experimental results demonstrate the\nsuperior performance of our approach by achieving 43.1% to 73.2% bit-rate\nsaving over the anchor of HEVC under the equivalent task-related distortions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 14:59:44 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 13:17:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Shi", "Jun", ""], ["Chen", "Zhibo", ""]]}, {"id": "1910.07402", "submitter": "Jos\\'e \\'Angel Morell Mart\\'inez", "authors": "Jos\\'e \\'A. Morell, Andr\\'es Camero and Enrique Alba", "title": "JSDoop and TensorFlow.js: Volunteer Distributed Web Browser-Based Neural\n  Network Training", "comments": null, "journal-ref": "IEEE Access 7 (2019): 158671-158684", "doi": "10.1109/ACCESS.2019.2950287", "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2019, around 57\\% of the population of the world has broadband access to\nthe Internet. Moreover, there are 5.9 billion mobile broadband subscriptions,\ni.e., 1.3 subscriptions per user. So there is an enormous interconnected\ncomputational power held by users all around the world. Also, it is estimated\nthat Internet users spend more than six and a half hours online every day. But\nin spite of being a great amount of time, those resources are idle most of the\nday. Therefore, taking advantage of them presents an interesting opportunity.\nIn this study, we introduce JSDoop, a prototype implementation to profit from\nthis opportunity. In particular, we propose a volunteer web browser-based\nhigh-performance computing library. JSdoop divides a problem into tasks and\nuses different queues to distribute the computation. Then, volunteers access\nthe web page of the problem and start processing the tasks in their web\nbrowsers. We conducted a proof-of-concept using our proposal and TensorFlow.js\nto train a recurrent neural network that predicts text. We tested it in a\ncomputer cluster and with up to 32 volunteers. The experimental results show\nthat training a neural network in distributed web browsers is feasible and\naccurate, has a high scalability, and it is an interesting area for research.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 19:39:01 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Morell", "Jos\u00e9 \u00c1.", ""], ["Camero", "Andr\u00e9s", ""], ["Alba", "Enrique", ""]]}, {"id": "1910.07407", "submitter": "Benjamin Cramer", "authors": "Benjamin Cramer, Yannik Stradmann, Johannes Schemmel and Friedemann\n  Zenke", "title": "The Heidelberg spiking datasets for the systematic evaluation of spiking\n  neural networks", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.3044364", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking neural networks are the basis of versatile and power-efficient\ninformation processing in the brain. Although we currently lack a detailed\nunderstanding of how these networks compute, recently developed optimization\ntechniques allow us to instantiate increasingly complex functional spiking\nneural networks in-silico. These methods hold the promise to build more\nefficient non-von-Neumann computing hardware and will offer new vistas in the\nquest of unraveling brain circuit function. To accelerate the development of\nsuch methods, objective ways to compare their performance are indispensable.\nPresently, however, there are no widely accepted means for comparing the\ncomputational performance of spiking neural networks. To address this issue, we\nintroduce two spike-based classification datasets, broadly applicable to\nbenchmark both software and neuromorphic hardware implementations of spiking\nneural networks. To accomplish this, we developed a general audio-to-spiking\nconversion procedure inspired by neurophysiology. Further, we applied this\nconversion to an existing and a novel speech dataset. The latter is the free,\nhigh-fidelity, and word-level aligned Heidelberg digit dataset that we created\nspecifically for this study. By training a range of conventional and spiking\nclassifiers, we show that leveraging spike timing information within these\ndatasets is essential for good classification accuracy. These results serve as\nthe first reference for future performance comparisons of spiking neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:22:01 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 10:23:34 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 13:30:24 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Cramer", "Benjamin", ""], ["Stradmann", "Yannik", ""], ["Schemmel", "Johannes", ""], ["Zenke", "Friedemann", ""]]}, {"id": "1910.07410", "submitter": "Jennifer Hobbs", "authors": "Matthew Holbrook, Jennifer Hobbs, Patrick Lucey", "title": "Rugby-Bot: Utilizing Multi-Task Learning & Fine-Grained Features for\n  Rugby League Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sporting events are extremely complex and require a multitude of metrics to\naccurate describe the event. When making multiple predictions, one should make\nthem from a single source to keep consistency across the predictions. We\npresent a multi-task learning method of generating multiple predictions for\nanalysis via a single prediction source. To enable this approach, we utilize a\nfine-grain representation using fine-grain spatial data using a wide-and-deep\nlearning approach. Additionally, our approach can predict distributions rather\nthan single point values. We highlighted the utility of our approach on the\nsport of Rugby League and call our prediction engine \"Rugby-Bot\".\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:29:33 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Holbrook", "Matthew", ""], ["Hobbs", "Jennifer", ""], ["Lucey", "Patrick", ""]]}, {"id": "1910.07421", "submitter": "Paul Almasan", "authors": "Paul Almasan, Jos\\'e Su\\'arez-Varela, Arnau Badia-Sampera, Krzysztof\n  Rusek, Pere Barlet-Ros, Albert Cabellos-Aparicio", "title": "Deep Reinforcement Learning meets Graph Neural Networks: exploring a\n  routing optimization use case", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Deep Reinforcement Learning (DRL) have shown a significant\nimprovement in decision-making problems. The networking community has started\nto investigate how DRL can provide a new breed of solutions to relevant\noptimization problems, such as routing. However, most of the state-of-the-art\nDRL-based networking techniques fail to generalize, this means that they can\nonly operate over network topologies seen during training, but not over new\ntopologies. The reason behind this important limitation is that existing DRL\nnetworking solutions use standard neural networks (e.g., fully connected),\nwhich are unable to learn graph-structured information. In this paper we\npropose to use Graph Neural Networks (GNN) in combination with DRL. GNN have\nbeen recently proposed to model graphs, and our novel DRL+GNN architecture is\nable to learn, operate and generalize over arbitrary network topologies. To\nshowcase its generalization capabilities, we evaluate it on an Optical\nTransport Network (OTN) scenario, where the agent needs to allocate traffic\ndemands efficiently. Our results show that our DRL+GNN agent is able to achieve\noutstanding performance in topologies unseen during training.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:36:08 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 14:04:46 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Almasan", "Paul", ""], ["Su\u00e1rez-Varela", "Jos\u00e9", ""], ["Badia-Sampera", "Arnau", ""], ["Rusek", "Krzysztof", ""], ["Barlet-Ros", "Pere", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "1910.07423", "submitter": "Vishnu Naresh Boddeti", "authors": "Bashir Sadeghi, Runyi Yu, Vishnu Naresh Boddeti", "title": "On the Global Optima of Kernelized Adversarial Representation Learning", "comments": "Accepted for publication at ICCV 2019. This version includes\n  additional theoretical and experimental analysis. Minor update to the GMM\n  experiment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial representation learning is a promising paradigm for obtaining\ndata representations that are invariant to certain sensitive attributes while\nretaining the information necessary for predicting target attributes. Existing\napproaches solve this problem through iterative adversarial minimax\noptimization and lack theoretical guarantees. In this paper, we first study the\n\"linear\" form of this problem i.e., the setting where all the players are\nlinear functions. We show that the resulting optimization problem is both\nnon-convex and non-differentiable. We obtain an exact closed-form expression\nfor its global optima through spectral learning and provide performance\nguarantees in terms of analytical bounds on the achievable utility and\ninvariance. We then extend this solution and analysis to non-linear functions\nthrough kernel representation. Numerical experiments on UCI, Extended Yale B\nand CIFAR-100 datasets indicate that, (a) practically, our solution is ideal\nfor \"imparting\" provable invariance to any biased pre-trained data\nrepresentation, and (b) empirically, the trade-off between utility and\ninvariance provided by our solution is comparable to iterative minimax\noptimization of existing deep neural network based approaches. Code is\navailable at https://github.com/human-analysis/Kernel-ARL\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:37:14 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 16:41:09 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Sadeghi", "Bashir", ""], ["Yu", "Runyi", ""], ["Boddeti", "Vishnu Naresh", ""]]}, {"id": "1910.07425", "submitter": "Tai-Danae Bradley", "authors": "Tai-Danae Bradley, E. Miles Stoudenmire, John Terilla", "title": "Modeling Sequences with Quantum States: A Look Under the Hood", "comments": "27 pages", "journal-ref": "2020 Mach. Learn.: Sci. Technol. 1 035008", "doi": "10.1088/2632-2153/ab8731", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical probability distributions on sets of sequences can be modeled using\nquantum states. Here, we do so with a quantum state that is pure and entangled.\nBecause it is entangled, the reduced densities that describe subsystems also\ncarry information about the complementary subsystem. This is in contrast to the\nclassical marginal distributions on a subsystem in which information about the\ncomplementary system has been integrated out and lost. A training algorithm\nbased on the density matrix renormalization group (DMRG) procedure uses the\nextra information contained in the reduced densities and organizes it into a\ntensor network model. An understanding of the extra information contained in\nthe reduced densities allow us to examine the mechanics of this DMRG algorithm\nand study the generalization error of the resulting model. As an illustration,\nwe work with the even-parity dataset and produce an estimate for the\ngeneralization error as a function of the fraction of the dataset used in\ntraining.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:39:55 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Bradley", "Tai-Danae", ""], ["Stoudenmire", "E. Miles", ""], ["Terilla", "John", ""]]}, {"id": "1910.07440", "submitter": "Thomas Booth", "authors": "Thomas Booth, Matthew Williams, Aysha Luis, Jorge Cardoso, Ashkan\n  Keyoumars, Haris Shuaib", "title": "Machine learning and glioma imaging biomarkers", "comments": null, "journal-ref": null, "doi": "10.1016/j.crad.2019.07.001", "report-no": null, "categories": "q-bio.QM cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aim: To review how machine learning (ML) is applied to imaging biomarkers in\nneuro-oncology, in particular for diagnosis, prognosis, and treatment response\nmonitoring.\n  Materials and Methods: The PubMed and MEDLINE databases were searched for\narticles published before September 2018 using relevant search terms. The\nsearch strategy focused on articles applying ML to high-grade glioma biomarkers\nfor treatment response monitoring, prognosis, and prediction.\n  Results: Magnetic resonance imaging (MRI) is typically used throughout the\npatient pathway because routine structural imaging provides detailed anatomical\nand pathological information and advanced techniques provide additional\nphysiological detail. Using carefully chosen image features, ML is frequently\nused to allow accurate classification in a variety of scenarios. Rather than\nbeing chosen by human selection, ML also enables image features to be\nidentified by an algorithm. Much research is applied to determining molecular\nprofiles, histological tumour grade, and prognosis using MRI images acquired at\nthe time that patients first present with a brain tumour. Differentiating a\ntreatment response from a post-treatment-related effect using imaging is\nclinically important and also an area of active study (described here in one of\ntwo Special Issue publications dedicated to the application of ML in glioma\nimaging).\n  Conclusion: Although pioneering, most of the evidence is of a low level,\nhaving been obtained retrospectively and in single centres. Studies applying ML\nto build neuro-oncology monitoring biomarker models have yet to show an overall\nadvantage over those using traditional statistical methods. Development and\nvalidation of ML models applied to neuro-oncology require large, well-annotated\ndatasets, and therefore multidisciplinary and multi-centre collaborations are\nnecessary.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 12:44:30 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Booth", "Thomas", ""], ["Williams", "Matthew", ""], ["Luis", "Aysha", ""], ["Cardoso", "Jorge", ""], ["Keyoumars", "Ashkan", ""], ["Shuaib", "Haris", ""]]}, {"id": "1910.07454", "submitter": "Zhiyuan Li", "authors": "Zhiyuan Li, Sanjeev Arora", "title": "An Exponential Learning Rate Schedule for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intriguing empirical evidence exists that deep learning can work well with\nexoticschedules for varying the learning rate. This paper suggests that the\nphenomenon may be due to Batch Normalization or BN, which is ubiquitous and\nprovides benefits in optimization and generalization across all standard\narchitectures. The following new results are shown about BN with weight decay\nand momentum (in other words, the typical use case which was not considered in\nearlier theoretical analyses of stand-alone BN.\n  1. Training can be done using SGD with momentum and an exponentially\nincreasing learning rate schedule, i.e., learning rate increases by some $(1\n+\\alpha)$ factor in every epoch for some $\\alpha >0$. (Precise statement in the\npaper.) To the best of our knowledge this is the first time such a rate\nschedule has been successfully used, let alone for highly successful\narchitectures. As expected, such training rapidly blows up network weights, but\nthe net stays well-behaved due to normalization.\n  2. Mathematical explanation of the success of the above rate schedule: a\nrigorous proof that it is equivalent to the standard setting of BN + SGD +\nStandardRate Tuning + Weight Decay + Momentum. This equivalence holds for other\nnormalization layers as well, Group Normalization, LayerNormalization, Instance\nNorm, etc.\n  3. A worked-out toy example illustrating the above linkage of\nhyper-parameters. Using either weight decay or BN alone reaches global minimum,\nbut convergence fails when both are used.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 16:22:58 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 17:56:03 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 11:01:34 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Li", "Zhiyuan", ""], ["Arora", "Sanjeev", ""]]}, {"id": "1910.07459", "submitter": "Malhar Bhoite", "authors": "Juan Carlos Vargas, Malhar Bhoite, Amir Barati Farimani", "title": "Creativity in Robot Manipulation with Deep Reinforcement Learning", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has emerged as a powerful control technique\nin robotic science. In contrast to control theory, DRL is more robust in the\nthorough exploration of the environment. This capability of DRL generates more\nhuman-like behaviour and intelligence when applied to the robots. To explore\nthis capability, we designed challenging manipulation tasks to observe robots\nstrategy to handle complex scenarios. We observed that robots not only perform\ntasks successfully, but also transpire a creative and non intuitive solution.\nWe also observed robot's persistence in tasks that are close to success and its\nstriking ability in discerning to continue or give up.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 16:33:52 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Vargas", "Juan Carlos", ""], ["Bhoite", "Malhar", ""], ["Farimani", "Amir Barati", ""]]}, {"id": "1910.07467", "submitter": "Biao Zhang", "authors": "Biao Zhang, Rico Sennrich", "title": "Root Mean Square Layer Normalization", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layer normalization (LayerNorm) has been successfully applied to various deep\nneural networks to help stabilize training and boost model convergence because\nof its capability in handling re-centering and re-scaling of both inputs and\nweight matrix. However, the computational overhead introduced by LayerNorm\nmakes these improvements expensive and significantly slows the underlying\nnetwork, e.g. RNN in particular. In this paper, we hypothesize that\nre-centering invariance in LayerNorm is dispensable and propose root mean\nsquare layer normalization, or RMSNorm. RMSNorm regularizes the summed inputs\nto a neuron in one layer according to root mean square (RMS), giving the model\nre-scaling invariance property and implicit learning rate adaptation ability.\nRMSNorm is computationally simpler and thus more efficient than LayerNorm. We\nalso present partial RMSNorm, or pRMSNorm where the RMS is estimated from p% of\nthe summed inputs without breaking the above properties. Extensive experiments\non several tasks using diverse network architectures show that RMSNorm achieves\ncomparable performance against LayerNorm but reduces the running time by 7%~64%\non different models. Source code is available at\nhttps://github.com/bzhangGo/rmsnorm.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 16:44:22 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Zhang", "Biao", ""], ["Sennrich", "Rico", ""]]}, {"id": "1910.07474", "submitter": "Robert Walecki Mr", "authors": "Robert Walecki, Kostis Gourgoulias, Adam Baker, Chris Hart, Chris\n  Lucas, Max Zwiessele, Albert Buchard, Maria Lomeli, Yura Perov, Saurabh Johri", "title": "Universal Marginaliser for Deep Amortised Inference for Probabilistic\n  Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming languages (PPLs) are powerful modelling tools which\nallow to formalise our knowledge about the world and reason about its inherent\nuncertainty. Inference methods used in PPL can be computationally costly due to\nsignificant time burden and/or storage requirements; or they can lack\ntheoretical guarantees of convergence and accuracy when applied to large scale\ngraphical models. To this end, we present the Universal Marginaliser (UM), a\nnovel method for amortised inference, in PPL. We show how combining samples\ndrawn from the original probabilistic program prior with an appropriate\naugmentation method allows us to train one neural network to approximate any of\nthe corresponding conditional marginal distributions, with any separation into\nlatent and observed variables, and thus amortise the cost of inference.\nFinally, we benchmark the method on multiple probabilistic programs, in Pyro,\nwith different model structure.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:01:02 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Walecki", "Robert", ""], ["Gourgoulias", "Kostis", ""], ["Baker", "Adam", ""], ["Hart", "Chris", ""], ["Lucas", "Chris", ""], ["Zwiessele", "Max", ""], ["Buchard", "Albert", ""], ["Lomeli", "Maria", ""], ["Perov", "Yura", ""], ["Johri", "Saurabh", ""]]}, {"id": "1910.07475", "submitter": "Patrick Lewis", "authors": "Patrick Lewis, Barlas O\\u{g}uz, Ruty Rinott, Sebastian Riedel, Holger\n  Schwenk", "title": "MLQA: Evaluating Cross-lingual Extractive Question Answering", "comments": "To appear in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) models have shown rapid progress enabled by the\navailability of large, high-quality benchmark datasets. Such annotated datasets\nare difficult and costly to collect, and rarely exist in languages other than\nEnglish, making training QA systems in other languages challenging. An\nalternative to building large monolingual training datasets is to develop\ncross-lingual systems which can transfer to a target language without requiring\ntraining data in that language. In order to develop such systems, it is crucial\nto invest in high quality multilingual evaluation benchmarks to measure\nprogress. We present MLQA, a multi-way aligned extractive QA evaluation\nbenchmark intended to spur research in this area. MLQA contains QA instances in\n7 languages, namely English, Arabic, German, Spanish, Hindi, Vietnamese and\nSimplified Chinese. It consists of over 12K QA instances in English and 5K in\neach other language, with each QA instance being parallel between 4 languages\non average. MLQA is built using a novel alignment context strategy on Wikipedia\narticles, and serves as a cross-lingual extension to existing extractive QA\ndatasets. We evaluate current state-of-the-art cross-lingual representations on\nMLQA, and also provide machine-translation-based baselines. In all cases,\ntransfer results are shown to be significantly behind training-language\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:05:21 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 05:46:56 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 10:13:02 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lewis", "Patrick", ""], ["O\u011fuz", "Barlas", ""], ["Rinott", "Ruty", ""], ["Riedel", "Sebastian", ""], ["Schwenk", "Holger", ""]]}, {"id": "1910.07476", "submitter": "Michael Biehl", "authors": "Elisa Oostwal and Michiel Straat and Michael Biehl", "title": "Hidden Unit Specialization in Layered Neural Networks: ReLU vs.\n  Sigmoidal Activation", "comments": "Main changes compared to first version: Added a section on supporting\n  Monte Carlo simulations, results and additional figures are presented and\n  discussed. Some references added. Layout changed to single column layout for\n  better readability. Minor textual changes and typos corrected", "journal-ref": "Physica A: Statistical Mechanics and its Applications 564: 125517,\n  2020", "doi": "10.1016/j.physa.2020.125517", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study layered neural networks of rectified linear units (ReLU) in a\nmodelling framework for stochastic training processes. The comparison with\nsigmoidal activation functions is in the center of interest. We compute typical\nlearning curves for shallow networks with K hidden units in matching student\nteacher scenarios. The systems exhibit sudden changes of the generalization\nperformance via the process of hidden unit specialization at critical sizes of\nthe training set. Surprisingly, our results show that the training behavior of\nReLU networks is qualitatively different from that of networks with sigmoidal\nactivations. In networks with K >= 3 sigmoidal hidden units, the transition is\ndiscontinuous: Specialized network configurations co-exist and compete with\nstates of poor performance even for very large training sets. On the contrary,\nthe use of ReLU activations results in continuous transitions for all K: For\nlarge enough training sets, two competing, differently specialized states\ndisplay similar generalization abilities, which coincide exactly for large\nnetworks in the limit K to infinity.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:06:00 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 05:19:14 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Oostwal", "Elisa", ""], ["Straat", "Michiel", ""], ["Biehl", "Michael", ""]]}, {"id": "1910.07478", "submitter": "Mark Rowland", "authors": "Mark Rowland, Will Dabney, R\\'emi Munos", "title": "Adaptive Trade-Offs in Off-Policy Learning", "comments": "AISTATS 2020 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A great variety of off-policy learning algorithms exist in the literature,\nand new breakthroughs in this area continue to be made, improving theoretical\nunderstanding and yielding state-of-the-art reinforcement learning algorithms.\nIn this paper, we take a unifying view of this space of algorithms, and\nconsider their trade-offs of three fundamental quantities: update variance,\nfixed-point bias, and contraction rate. This leads to new perspectives of\nexisting methods, and also naturally yields novel algorithms for off-policy\nevaluation and control. We develop one such algorithm, C-trace, demonstrating\nthat it is able to more efficiently make these trade-offs than existing methods\nin use, and that it can be scaled to yield state-of-the-art performance in\nlarge-scale environments.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:09:19 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 11:24:06 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Rowland", "Mark", ""], ["Dabney", "Will", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "1910.07479", "submitter": "Mark Rowland", "authors": "Mark Rowland, Anna Harutyunyan, Hado van Hasselt, Diana Borsa, Tom\n  Schaul, R\\'emi Munos, Will Dabney", "title": "Conditional Importance Sampling for Off-Policy Learning", "comments": "AISTATS 2020 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principal contribution of this paper is a conceptual framework for\noff-policy reinforcement learning, based on conditional expectations of\nimportance sampling ratios. This framework yields new perspectives and\nunderstanding of existing off-policy algorithms, and reveals a broad space of\nunexplored algorithms. We theoretically analyse this space, and concretely\ninvestigate several algorithms that arise from this framework.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:09:33 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 10:24:45 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Rowland", "Mark", ""], ["Harutyunyan", "Anna", ""], ["van Hasselt", "Hado", ""], ["Borsa", "Diana", ""], ["Schaul", "Tom", ""], ["Munos", "R\u00e9mi", ""], ["Dabney", "Will", ""]]}, {"id": "1910.07483", "submitter": "Anuj Mahajan", "authors": "Anuj Mahajan, Tabish Rashid, Mikayel Samvelyan, Shimon Whiteson", "title": "MAVEN: Multi-Agent Variational Exploration", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, 32, 2019,\n  7611-7622", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Centralised training with decentralised execution is an important setting for\ncooperative deep multi-agent reinforcement learning due to communication\nconstraints during execution and computational tractability in training. In\nthis paper, we analyse value-based methods that are known to have superior\nperformance in complex environments [43]. We specifically focus on QMIX [40],\nthe current state-of-the-art in this domain. We show that the representational\nconstraints on the joint action-values introduced by QMIX and similar methods\nlead to provably poor exploration and suboptimality. Furthermore, we propose a\nnovel approach called MAVEN that hybridises value and policy-based methods by\nintroducing a latent space for hierarchical control. The value-based agents\ncondition their behaviour on the shared latent variable controlled by a\nhierarchical policy. This allows MAVEN to achieve committed, temporally\nextended exploration, which is key to solving complex multi-agent tasks. Our\nexperimental results show that MAVEN achieves significant performance\nimprovements on the challenging SMAC domain [43].\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:29:25 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 18:25:11 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mahajan", "Anuj", ""], ["Rashid", "Tabish", ""], ["Samvelyan", "Mikayel", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1910.07485", "submitter": "Stanislav Minsker", "authors": "Stanislav Minsker and Timoth\\'ee Mathieu", "title": "Excess risk bounds in robust empirical risk minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates robust versions of the general empirical risk\nminimization algorithm, one of the core techniques underlying modern\nstatistical methods. Success of the empirical risk minimization is based on the\nfact that for a \"well-behaved\" stochastic process $\\left\\{ f(X), \\ f\\in\n\\mathcal F\\right\\}$ indexed by a class of functions $f\\in \\mathcal F$, averages\n$\\frac{1}{N}\\sum_{j=1}^N f(X_j)$ evaluated over a sample $X_1,\\ldots,X_N$ of\ni.i.d. copies of $X$ provide good approximation to the expectations $\\mathbb E\nf(X)$ uniformly over large classes $f\\in \\mathcal F$. However, this might no\nlonger be true if the marginal distributions of the process are heavy-tailed or\nif the sample contains outliers. We propose a version of empirical risk\nminimization based on the idea of replacing sample averages by robust proxies\nof the expectation, and obtain high-confidence bounds for the excess risk of\nresulting estimators. In particular, we show that the excess risk of robust\nestimators can converge to $0$ at fast rates with respect to the sample size.\nWe discuss implications of the main results to the linear and logistic\nregression problems, and evaluate the numerical performance of proposed methods\non simulated and real data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:33:14 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Minsker", "Stanislav", ""], ["Mathieu", "Timoth\u00e9e", ""]]}, {"id": "1910.07487", "submitter": "Joshua Powers", "authors": "Joshua Powers, Ryan Grindle, Sam Kriegman, Lapo Frati, Nick Cheney,\n  Josh Bongard", "title": "Embodiment dictates learnability in neural controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting continues to severely restrict the learnability of\ncontrollers suitable for multiple task environments. Efforts to combat\ncatastrophic forgetting reported in the literature to date have focused on how\ncontrol systems can be updated more rapidly, hastening their adjustment from\ngood initial settings to new environments, or more circumspectly, suppressing\ntheir ability to overfit to any one environment. When using robots, the\nenvironment includes the robot's own body, its shape and material properties,\nand how its actuators and sensors are distributed along its mechanical\nstructure. Here we demonstrate for the first time how one such design decision\n(sensor placement) can alter the landscape of the loss function itself, either\nexpanding or shrinking the weight manifolds containing suitable controllers for\neach individual task, thus increasing or decreasing their probability of\noverlap across tasks, and thus reducing or inducing the potential for\ncatastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:38:20 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 15:06:25 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Powers", "Joshua", ""], ["Grindle", "Ryan", ""], ["Kriegman", "Sam", ""], ["Frati", "Lapo", ""], ["Cheney", "Nick", ""], ["Bongard", "Josh", ""]]}, {"id": "1910.07497", "submitter": "Pritam Sarkar", "authors": "Pritam Sarkar, Ali Etemad", "title": "Self-supervised Learning for ECG-based Emotion Recognition", "comments": "Accepted, 45th IEEE International Conference on Acoustics, Speech,\n  and Signal Processing", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053985", "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an electrocardiogram (ECG) -based emotion recognition system using\nself-supervised learning. Our proposed architecture consists of two main\nnetworks, a signal transformation recognition network and an emotion\nrecognition network. First, unlabelled data are used to successfully train the\nformer network to detect specific pre-determined signal transformations in the\nself-supervised learning step. Next, the weights of the convolutional layers of\nthis network are transferred to the emotion recognition network, and two dense\nlayers are trained in order to classify arousal and valence scores. We show\nthat our self-supervised approach helps the model learn the ECG feature\nmanifold required for emotion recognition, performing equal or better than the\nfully-supervised version of the model. Our proposed method outperforms the\nstate-of-the-art in ECG-based emotion recognition with two publicly available\ndatasets, SWELL and AMIGOS. Further analysis highlights the advantage of our\nself-supervised approach in requiring significantly less data to achieve\nacceptable results.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 15:19:08 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 02:50:53 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 03:30:45 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Sarkar", "Pritam", ""], ["Etemad", "Ali", ""]]}, {"id": "1910.07498", "submitter": "Zuyue Fu", "authors": "Zuyue Fu, Zhuoran Yang, Yongxin Chen, Zhaoran Wang", "title": "Actor-Critic Provably Finds Nash Equilibria of Linear-Quadratic\n  Mean-Field Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study discrete-time mean-field Markov games with infinite numbers of\nagents where each agent aims to minimize its ergodic cost. We consider the\nsetting where the agents have identical linear state transitions and quadratic\ncost functions, while the aggregated effect of the agents is captured by the\npopulation mean of their states, namely, the mean-field state. For such a game,\nbased on the Nash certainty equivalence principle, we provide sufficient\nconditions for the existence and uniqueness of its Nash equilibrium. Moreover,\nto find the Nash equilibrium, we propose a mean-field actor-critic algorithm\nwith linear function approximation, which does not require knowing the model of\ndynamics. Specifically, at each iteration of our algorithm, we use the\nsingle-agent actor-critic algorithm to approximately obtain the optimal policy\nof the each agent given the current mean-field state, and then update the\nmean-field state. In particular, we prove that our algorithm converges to the\nNash equilibrium at a linear rate. To the best of our knowledge, this is the\nfirst success of applying model-free reinforcement learning with function\napproximation to discrete-time mean-field Markov games with provable\nnon-asymptotic global convergence guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:59:20 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Fu", "Zuyue", ""], ["Yang", "Zhuoran", ""], ["Chen", "Yongxin", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1910.07512", "submitter": "Guodong Zhang", "authors": "Yuanhao Wang, Guodong Zhang, Jimmy Ba", "title": "On Solving Minimax Optimization Locally: A Follow-the-Ridge Approach", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in modern machine learning can be formulated as finding equilibria\nin \\emph{sequential} games. In particular, two-player zero-sum sequential\ngames, also known as minimax optimization, have received growing interest. It\nis tempting to apply gradient descent to solve minimax optimization given its\npopularity and success in supervised learning. However, it has been noted that\nnaive application of gradient descent fails to find some local minimax and can\nconverge to non-local-minimax points. In this paper, we propose\n\\emph{Follow-the-Ridge} (FR), a novel algorithm that provably converges to and\nonly converges to local minimax. We show theoretically that the algorithm\naddresses the notorious rotational behaviour of gradient dynamics, and is\ncompatible with preconditioning and \\emph{positive} momentum. Empirically, FR\nsolves toy minimax problems and improves the convergence of GAN training\ncompared to the recent minimax optimization algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:57:08 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 15:54:54 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Wang", "Yuanhao", ""], ["Zhang", "Guodong", ""], ["Ba", "Jimmy", ""]]}, {"id": "1910.07514", "submitter": "Deepali Aneja", "authors": "Deepali Aneja, Rens Hoegen, Daniel McDuff, and Mary Czerwinski", "title": "Designing Style Matching Conversational Agents", "comments": "Conversational Agents: Acting on the Wave of Research and\n  Development, CHI 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in machine intelligence have enabled conversational interfaces that\nhave the potential to radically change the way humans interact with machines.\nHowever, even with the progress in the abilities of these agents, there remain\ncritical gaps in their capacity for natural interactions. One limitation is\nthat the agents are often monotonic in behavior and do not adapt to their\npartner. We built two end-to-end conversational agents: a voice-based agent\nthat can engage in naturalistic, multi-turn dialogue and align with the\ninterlocutor's conversational style, and a 2nd, expressive, embodied\nconversational agent (ECA) that can recognize human behavior during open-ended\nconversations and automatically align its responses to the visual and\nconversational style of the other party. The embodied conversational agent\nleverages multimodal inputs to produce rich and perceptually valid vocal and\nfacial responses (e.g., lip syncing and expressions) during the conversation.\nBased on empirical results from a set of user studies, we highlight several\nsignificant challenges in building such systems and provide design guidelines\nfor multi-turn dialogue interactions using style adaptation for future\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:58:36 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Aneja", "Deepali", ""], ["Hoegen", "Rens", ""], ["McDuff", "Daniel", ""], ["Czerwinski", "Mary", ""]]}, {"id": "1910.07517", "submitter": "Uri Alon", "authors": "Noam Yefet, Uri Alon, Eran Yahav", "title": "Adversarial Examples for Models of Code", "comments": "Accepted to OOPSLA'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models of code have shown impressive results when performing tasks\nsuch as predicting method names and identifying certain kinds of bugs. We show\nthat these models are vulnerable to adversarial examples, and introduce a novel\napproach for attacking trained models of code using adversarial examples. The\nmain idea of our approach is to force a given trained model to make an\nincorrect prediction, as specified by the adversary, by introducing small\nperturbations that do not change the program's semantics, thereby creating an\nadversarial example. To find such perturbations, we present a new technique for\nDiscrete Adversarial Manipulation of Programs (DAMP). DAMP works by deriving\nthe desired prediction with respect to the model's inputs, while holding the\nmodel weights constant, and following the gradients to slightly modify the\ninput code. We show that our DAMP attack is effective across three neural\narchitectures: code2vec, GGNN, and GNN-FiLM, in both Java and C#. Our\nevaluations demonstrate that DAMP has up to 89% success rate in changing a\nprediction to the adversary's choice (a targeted attack) and a success rate of\nup to 94% in changing a given prediction to any incorrect prediction (a\nnon-targeted attack). To defend a model against such attacks, we empirically\nexamine a variety of possible defenses and discuss their trade-offs. We show\nthat some of these defenses can dramatically drop the success rate of the\nattacker, with a minor penalty of 2% relative degradation in accuracy when they\nare not performing under attack. Our code, data, and trained models are\navailable at https://github.com/tech-srl/adversarial-examples .\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 19:56:42 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 10:31:10 GMT"}, {"version": "v3", "created": "Sun, 8 Dec 2019 07:26:44 GMT"}, {"version": "v4", "created": "Wed, 27 May 2020 07:54:30 GMT"}, {"version": "v5", "created": "Mon, 12 Oct 2020 18:36:43 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Yefet", "Noam", ""], ["Alon", "Uri", ""], ["Yahav", "Eran", ""]]}, {"id": "1910.07521", "submitter": "Minh Vu", "authors": "Minh H. Vu and Guus Grimbergen and Attila Simk\\'o and Tufve Nyholm and\n  Tommy L\\\"ofstedt", "title": "End-to-End Cascaded U-Nets with a Localization Network for Kidney Tumor\n  Segmentation", "comments": "2019 Kidney Tumor Segmentation Challenge", "journal-ref": null, "doi": "10.24926/548719.073", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kidney tumor segmentation emerges as a new frontier of computer vision in\nmedical imaging. This is partly due to its challenging manual annotation and\ngreat medical impact. Within the scope of the Kidney Tumor Segmentation\nChallenge 2019, that is aiming at combined kidney and tumor segmentation, this\nwork proposes a novel combination of 3D U-Nets---collectively denoted\nTuNet---utilizing the resulting kidney masks for the consecutive tumor\nsegmentation. The proposed method achieves a S{\\o}rensen-Dice coefficient score\nof 0.902 for the kidney, and 0.408 for the tumor segmentation, computed from a\nfive-fold cross-validation on the 210 patients available in the data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 11:25:23 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Vu", "Minh H.", ""], ["Grimbergen", "Guus", ""], ["Simk\u00f3", "Attila", ""], ["Nyholm", "Tufve", ""], ["L\u00f6fstedt", "Tommy", ""]]}, {"id": "1910.07561", "submitter": "Xiaorui Liu", "authors": "Xiaorui Liu, Yao Li, Jiliang Tang and Ming Yan", "title": "A Double Residual Compression Algorithm for Efficient Distributed\n  Learning", "comments": null, "journal-ref": "PMLR 108:133-143, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale machine learning models are often trained by parallel stochastic\ngradient descent algorithms. However, the communication cost of gradient\naggregation and model synchronization between the master and worker nodes\nbecomes the major obstacle for efficient learning as the number of workers and\nthe dimension of the model increase. In this paper, we propose DORE, a DOuble\nREsidual compression stochastic gradient descent algorithm, to reduce over\n$95\\%$ of the overall communication such that the obstacle can be immensely\nmitigated. Our theoretical analyses demonstrate that the proposed strategy has\nsuperior convergence properties for both strongly convex and nonconvex\nobjective functions. The experimental results validate that DORE achieves the\nbest communication efficiency while maintaining similar model accuracy and\nconvergence speed in comparison with start-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 18:19:19 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Liu", "Xiaorui", ""], ["Li", "Yao", ""], ["Tang", "Jiliang", ""], ["Yan", "Ming", ""]]}, {"id": "1910.07567", "submitter": "Yichong Xu", "authors": "Yuexin Wu, Yichong Xu, Aarti Singh, Yiming Yang, Artur Dubrawski", "title": "Active Learning for Graph Neural Networks via Node Feature Propagation", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) for prediction tasks like node classification or\nedge prediction have received increasing attention in recent machine learning\nfrom graphically structured data. However, a large quantity of labeled graphs\nis difficult to obtain, which significantly limits the true success of GNNs.\nAlthough active learning has been widely studied for addressing label-sparse\nissues with other data types like text, images, etc., how to make it effective\nover graphs is an open question for research. In this paper, we present an\ninvestigation on active learning with GNNs for node classification tasks.\nSpecifically, we propose a new method, which uses node feature propagation\nfollowed by K-Medoids clustering of the nodes for instance selection in active\nlearning. With a theoretical bound analysis we justify the design choice of our\napproach. In our experiments on four benchmark datasets, the proposed method\noutperforms other representative baseline methods consistently and\nsignificantly.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 18:44:30 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Wu", "Yuexin", ""], ["Xu", "Yichong", ""], ["Singh", "Aarti", ""], ["Yang", "Yiming", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1910.07581", "submitter": "Mayank Agrawal", "authors": "Mayank Agrawal, Joshua C. Peterson, Thomas L. Griffiths", "title": "Scaling up Psychology via Scientific Regret Minimization: A Case Study\n  in Moral Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do large datasets provide value to psychologists? Without a systematic\nmethodology for working with such datasets, there is a valid concern that\nanalyses will produce noise artifacts rather than true effects. In this paper,\nwe offer a way to enable researchers to systematically build models and\nidentify novel phenomena in large datasets. One traditional approach is to\nanalyze the residuals of models---the biggest errors they make in predicting\nthe data---to discover what might be missing from those models. However, once a\ndataset is sufficiently large, machine learning algorithms approximate the true\nunderlying function better than the data, suggesting instead that the\npredictions of these data-driven models should be used to guide model-building.\nWe call this approach \"Scientific Regret Minimization\" (SRM) as it focuses on\nminimizing errors for cases that we know should have been predictable. We\ndemonstrate this methodology on a subset of the Moral Machine dataset, a public\ncollection of roughly forty million moral decisions. Using SRM, we found that\nincorporating a set of deontological principles that capture dimensions along\nwhich groups of agents can vary (e.g. sex and age) improves a computational\nmodel of human moral judgment. Furthermore, we were able to identify and\nindependently validate three interesting moral phenomena: criminal\ndehumanization, age of responsibility, and asymmetric notions of\nresponsibility.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 19:25:06 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 00:13:23 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Agrawal", "Mayank", ""], ["Peterson", "Joshua C.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1910.07600", "submitter": "Defeng Liu", "authors": "Defeng Liu, Andrea Lodi, Mathieu Tanneau", "title": "Learning chordal extensions", "comments": "Submitted to Journal of Global Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A highly influential ingredient of many techniques designed to exploit\nsparsity in numerical optimization is the so-called chordal extension of a\ngraph representation of the optimization problem. The definitive relation\nbetween chordal extension and the performance of the optimization algorithm\nthat uses the extension is not a mathematically understood task. For this\nreason, we follow the current research trend of looking at Combinatorial\nOptimization tasks by using a Machine Learning lens, and we devise a framework\nfor learning elimination rules yielding high-quality chordal extensions. As a\nfirst building block of the learning framework, we propose an on-policy\nimitation learning scheme that mimics the elimination ordering provided by the\n(classical) minimum degree rule. The results show that our on-policy imitation\nlearning approach is effective in learning the minimum degree policy and,\nconsequently, produces graphs with desirable fill-in characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 20:25:45 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Liu", "Defeng", ""], ["Lodi", "Andrea", ""], ["Tanneau", "Mathieu", ""]]}, {"id": "1910.07601", "submitter": "Yanpei Shi", "authors": "Yanpei Shi, Thomas Hain", "title": "Contextual Joint Factor Acoustic Embeddings", "comments": "Published at SLT2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding acoustic information into fixed length representations is of\ninterest for a whole range of applications in speech and audio technology. Two\nnovel unsupervised approaches to generate acoustic embeddings by modelling of\nacoustic context are proposed. The first approach is a contextual joint factor\nsynthesis encoder, where the encoder in an encoder/decoder framework is trained\nto extract joint factors from surrounding audio frames to best generate the\ntarget output. The second approach is a contextual joint factor analysis\nencoder, where the encoder is trained to analyse joint factors from the source\nsignal that correlates best with the neighbouring audio. To evaluate the\neffectiveness of our approaches compared to prior work, two tasks are conducted\n-- phone classification and speaker recognition -- and test on different TIMIT\ndata sets. Experimental results show that one of the proposed approaches\noutperforms phone classification baselines, yielding a classification accuracy\nof 74.1%. When using additional out-of-domain data for training, an additional\n3% improvements can be obtained, for both for phone classification and speaker\nrecognition tasks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 20:36:41 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 15:40:15 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Shi", "Yanpei", ""], ["Hain", "Thomas", ""]]}, {"id": "1910.07604", "submitter": "Jacob Pfau", "authors": "Jacob Pfau, Albert T. Young, Maria L. Wei, Michael J. Keiser", "title": "Global Saliency: Aggregating Saliency Maps to Assess Dataset Artefact\n  Bias", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high-stakes applications of machine learning models, interpretability\nmethods provide guarantees that models are right for the right reasons. In\nmedical imaging, saliency maps have become the standard tool for determining\nwhether a neural model has learned relevant robust features, rather than\nartefactual noise. However, saliency maps are limited to local model\nexplanation because they interpret predictions on an image-by-image basis. We\npropose aggregating saliency globally, using semantic segmentation masks, to\nprovide quantitative measures of model bias across a dataset. To evaluate\nglobal saliency methods, we propose two metrics for quantifying the validity of\nsaliency explanations. We apply the global saliency method to skin lesion\ndiagnosis to determine the effect of artefacts, such as ink, on model bias.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 20:45:19 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 00:14:28 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Pfau", "Jacob", ""], ["Young", "Albert T.", ""], ["Wei", "Maria L.", ""], ["Keiser", "Michael J.", ""]]}, {"id": "1910.07617", "submitter": "Samir Chowdhury", "authors": "Samir Chowdhury, Thomas Gebhart, Steve Huntsman, Matvey Yutin", "title": "Path homologies of deep feedforward networks", "comments": "To appear in the proceedings of IEEE ICMLA 2019", "journal-ref": null, "doi": "10.1109/ICMLA.2019.00181", "report-no": null, "categories": "math.AT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a characterization of two types of directed homology for\nfully-connected, feedforward neural network architectures. These exact\ncharacterizations of the directed homology structure of a neural network\narchitecture are the first of their kind. We show that the directed flag\nhomology of deep networks reduces to computing the simplicial homology of the\nunderlying undirected graph, which is explicitly given by Euler characteristic\ncomputations. We also show that the path homology of these networks is\nnon-trivial in higher dimensions and depends on the number and size of the\nlayers within the network. These results provide a foundation for investigating\nhomological differences between neural network architectures and their realized\nstructure as implied by their parameters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 21:14:55 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chowdhury", "Samir", ""], ["Gebhart", "Thomas", ""], ["Huntsman", "Steve", ""], ["Yutin", "Matvey", ""]]}, {"id": "1910.07623", "submitter": "Azade Nazi", "authors": "Azade Nazi, Will Hang, Anna Goldie, Sujith Ravi, Azalia Mirhoseini", "title": "Generalized Clustering by Learning to Optimize Expected Normalized Cuts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel end-to-end approach for learning to cluster in the\nabsence of labeled examples. Our clustering objective is based on optimizing\nnormalized cuts, a criterion which measures both intra-cluster similarity as\nwell as inter-cluster dissimilarity. We define a differentiable loss function\nequivalent to the expected normalized cuts. Unlike much of the work in\nunsupervised deep learning, our trained model directly outputs final cluster\nassignments, rather than embeddings that need further processing to be usable.\nOur approach generalizes to unseen datasets across a wide variety of domains,\nincluding text, and image. Specifically, we achieve state-of-the-art results on\npopular unsupervised clustering benchmarks (e.g., MNIST, Reuters, CIFAR-10, and\nCIFAR-100), outperforming the strongest baselines by up to 10.9%. Our\ngeneralization results are superior (by up to 21.9%) to the recent\ntop-performing clustering approach with the ability to generalize.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 21:28:51 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Nazi", "Azade", ""], ["Hang", "Will", ""], ["Goldie", "Anna", ""], ["Ravi", "Sujith", ""], ["Mirhoseini", "Azalia", ""]]}, {"id": "1910.07629", "submitter": "Tao Yu", "authors": "Tao Yu, Shengyuan Hu, Chuan Guo, Wei-Lun Chao, Kilian Q. Weinberger", "title": "A New Defense Against Adversarial Images: Turning a Weakness into a\n  Strength", "comments": "NeurIPS 2019, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural images are virtually surrounded by low-density misclassified regions\nthat can be efficiently discovered by gradient-guided search --- enabling the\ngeneration of adversarial images. While many techniques for detecting these\nattacks have been proposed, they are easily bypassed when the adversary has\nfull knowledge of the detection mechanism and adapts the attack strategy\naccordingly. In this paper, we adopt a novel perspective and regard the\nomnipresence of adversarial perturbations as a strength rather than a weakness.\nWe postulate that if an image has been tampered with, these adversarial\ndirections either become harder to find with gradient methods or have\nsubstantially higher density than for natural images. We develop a practical\ntest for this signature characteristic to successfully detect adversarial\nattacks, achieving unprecedented accuracy under the white-box setting where the\nadversary is given full knowledge of our detection mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 21:48:59 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 04:01:23 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Yu", "Tao", ""], ["Hu", "Shengyuan", ""], ["Guo", "Chuan", ""], ["Chao", "Wei-Lun", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "1910.07631", "submitter": "Jeyan Thiyagalingam", "authors": "Tony Hey, Keith Butler, Sam Jackson and Jeyarajan Thiyagalingam", "title": "Machine Learning and Big Scientific Data", "comments": "42 Pages with full colour images", "journal-ref": null, "doi": "10.1098/rsta.2019.0054", "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews some of the challenges posed by the huge growth of\nexperimental data generated by the new generation of large-scale experiments at\nUK national facilities at the Rutherford Appleton Laboratory site at Harwell\nnear Oxford. Such \"Big Scientific Data\" comes from the Diamond Light Source and\nElectron Microscopy Facilities, the ISIS Neutron and Muon Facility, and the\nUK's Central Laser Facility. Increasingly, scientists are now needing to use\nadvanced machine learning and other AI technologies both to automate parts of\nthe data pipeline and also to help find new scientific discoveries in the\nanalysis of their data. For commercially important applications, such as object\nrecognition, natural language processing and automatic translation, deep\nlearning has made dramatic breakthroughs. Google's DeepMind has now also used\ndeep learning technology to develop their AlphaFold tool to make predictions\nfor protein folding. Remarkably, they have been able to achieve some\nspectacular results for this specific scientific problem. Can deep learning be\nsimilarly transformative for other scientific problems? After a brief review of\nsome initial applications of machine learning at the Rutherford Appleton\nLaboratory, we focus on challenges and opportunities for AI in advancing\nmaterials science. Finally, we discuss the importance of developing some\nrealistic machine learning benchmarks using Big Scientific Data coming from a\nnumber of different scientific domains. We conclude with some initial examples\nof our \"SciML\" benchmark suite and of the research challenges these benchmarks\nwill enable.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 15:02:13 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Hey", "Tony", ""], ["Butler", "Keith", ""], ["Jackson", "Sam", ""], ["Thiyagalingam", "Jeyarajan", ""]]}, {"id": "1910.07632", "submitter": "Donglin Zhan", "authors": "Donglin Zhan, Shiyu Yi, Dongli Xu, Xiao Yu, Denglin Jiang, Siqi Yu,\n  Haoting Zhang, Wenfang Shangguan and Weihua Zhang", "title": "Adaptive Transfer Learning of Multi-View Time Series Classification", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time Series Classification (TSC) has been an important and challenging task\nin data mining, especially on multivariate time series and multi-view time\nseries data sets. Meanwhile, transfer learning has been widely applied in\ncomputer vision and natural language processing applications to improve deep\nneural network's generalization capabilities. However, very few previous works\napplied transfer learning framework to time series mining problems.\nParticularly, the technique of measuring similarities between source domain and\ntarget domain based on dynamic representation such as density estimation with\nimportance sampling has never been combined with transfer learning framework.\nIn this paper, we first proposed a general adaptive transfer learning framework\nfor multi-view time series data, which shows strong ability in storing\ninter-view importance value in the process of knowledge transfer. Next, we\nrepresented inter-view importance through some time series similarity\nmeasurements and approximated the posterior distribution in latent space for\nthe importance sampling via density estimation techniques. We then computed the\nmatrix norm of sampled importance value, which controls the degree of knowledge\ntransfer in pre-training process. We further evaluated our work, applied it to\nmany other time series classification tasks, and observed that our architecture\nmaintained desirable generalization ability. Finally, we concluded that our\nframework could be adapted with deep learning techniques to receive significant\nmodel performance improvements.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 21:46:03 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Zhan", "Donglin", ""], ["Yi", "Shiyu", ""], ["Xu", "Dongli", ""], ["Yu", "Xiao", ""], ["Jiang", "Denglin", ""], ["Yu", "Siqi", ""], ["Zhang", "Haoting", ""], ["Shangguan", "Wenfang", ""], ["Zhang", "Weihua", ""]]}, {"id": "1910.07633", "submitter": "Xiaoyang Xu", "authors": "Xiaoyang Xu, Yiqun Liu, Hanqing Chao, Youcheng Luo, Hai Chu, Lei Chen,\n  Junping Zhang, Leiming Ma", "title": "Towards a Precipitation Bias Corrector against Noise and Maldistribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With broad applications in various public services like aviation management\nand urban disaster warning, numerical precipitation prediction plays a crucial\nrole in weather forecast. However, constrained by the limitation of observation\nand conventional meteorological models, the numerical precipitation predictions\nare often highly biased. To correct this bias, classical correction methods\nheavily depend on profound experts who have knowledge in aerodynamics,\nthermodynamics and meteorology. As precipitation can be influenced by countless\nfactors, however, the performances of these expert-driven methods can drop\ndrastically when some un-modeled factors change. To address this issue, this\npaper presents a data-driven deep learning model which mainly includes two\nblocks, i.e. a Denoising Autoencoder Block and an Ordinal Regression Block. To\nthe best of our knowledge, it is the first expert-free models for bias\ncorrection. The proposed model can effectively correct the numerical\nprecipitation prediction based on 37 basic meteorological data from European\nCentre for Medium-Range Weather Forecasts (ECMWF). Experiments indicate that\ncompared with several classical machine learning algorithms and deep learning\nmodels, our method achieves the best correcting performance and meteorological\nindex, namely the threat scores (TS), obtaining satisfactory visualization\neffect.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 12:25:58 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Xu", "Xiaoyang", ""], ["Liu", "Yiqun", ""], ["Chao", "Hanqing", ""], ["Luo", "Youcheng", ""], ["Chu", "Hai", ""], ["Chen", "Lei", ""], ["Zhang", "Junping", ""], ["Ma", "Leiming", ""]]}, {"id": "1910.07636", "submitter": "Ruei-Sung Lin", "authors": "Oliver Zhang, Ruei-Sung Lin, Yuchuan Gou", "title": "Optimal Transport Based Generative Autoencoders", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of deep generative modeling is dominated by generative adversarial\nnetworks (GANs). However, the training of GANs often lacks stability, fails to\nconverge, and suffers from model collapse. It takes an assortment of tricks to\nsolve these problems, which may be difficult to understand for those seeking to\napply generative modeling. Instead, we propose two novel generative\nautoencoders, AE-OTtrans and AE-OTgen, which rely on optimal transport instead\nof adversarial training. AE-OTtrans and AEOTgen, unlike VAE and WAE, preserve\nthe manifold of the data; they do not force the latent distribution to match a\nnormal distribution, resulting in greater quality images. AEOTtrans and\nAE-OTgen also produce images of higher diversity compared to their predecessor,\nAE-OT. We show that AE-OTtrans and AE-OTgen surpass GANs in the MNIST and\nFashionMNIST datasets. Furthermore, We show that AE-OTtrans and AE-OTgen do\nstate of the art on the MNIST, FashionMNIST, and CelebA image sets comapred to\nother non-adversarial generative models.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 22:01:51 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Zhang", "Oliver", ""], ["Lin", "Ruei-Sung", ""], ["Gou", "Yuchuan", ""]]}, {"id": "1910.07638", "submitter": "Peng Liu", "authors": "Peng Liu, Bin Kong, Zhongyu Li, Shaoting Zhang, Ruogu Fang", "title": "CFEA: Collaborative Feature Ensembling Adaptation for Domain Adaptation\n  in Unsupervised Optic Disc and Cup Segmentation", "comments": null, "journal-ref": "the 22nd International Conference on Medical Image Computing and\n  Computer Assisted Intervention (MICCAI 2019)", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks have demonstrated comparable and even better\nperformance with board-certified ophthalmologists in well-annotated datasets.\nHowever, the diversity of retinal imaging devices poses a significant\nchallenge: domain shift, which leads to performance degradation when applying\nthe deep learning models to new testing domains. In this paper, we propose a\nnovel unsupervised domain adaptation framework, called Collaborative Feature\nEnsembling Adaptation (CFEA), to effectively overcome this challenge. Our\nproposed CFEA is an interactive paradigm which presents an exquisite of\ncollaborative adaptation through both adversarial learning and ensembling\nweights. In particular, we simultaneously achieve domain-invariance and\nmaintain an exponential moving average of the historical predictions, which\nachieves a better prediction for the unlabeled data, via ensembling weights\nduring training. Without annotating any sample from the target domain, multiple\nadversarial losses in encoder and decoder layers guide the extraction of\ndomain-invariant features to confuse the domain classifier and meanwhile\nbenefit the ensembling of smoothing weights. Comprehensive experimental results\ndemonstrate that our CFEA model can overcome performance degradation and\noutperform the state-of-the-art methods in segmenting retinal optic disc and\ncup from fundus images. \\textit{Code is available at\n\\url{https://github.com/cswin/AWC}}.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 22:11:16 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Liu", "Peng", ""], ["Kong", "Bin", ""], ["Li", "Zhongyu", ""], ["Zhang", "Shaoting", ""], ["Fang", "Ruogu", ""]]}, {"id": "1910.07643", "submitter": "Osman Asif Malik", "authors": "Osman Asif Malik, Shashanka Ubaru, Lior Horesh, Misha E. Kilmer, Haim\n  Avron", "title": "Dynamic Graph Convolutional Networks Using the Tensor M-Product", "comments": "Accepted to SIAM International Conference on Data Mining (SDM) 2021", "journal-ref": null, "doi": "10.1137/1.9781611976700.82", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many irregular domains such as social networks, financial transactions,\nneuron connections, and natural language constructs are represented using graph\nstructures. In recent years, a variety of graph neural networks (GNNs) have\nbeen successfully applied for representation learning and prediction on such\ngraphs. In many of the real-world applications, the underlying graph changes\nover time, however, most of the existing GNNs are inadequate for handling such\ndynamic graphs. In this paper we propose a novel technique for learning\nembeddings of dynamic graphs using a tensor algebra framework. Our method\nextends the popular graph convolutional network (GCN) for learning\nrepresentations of dynamic graphs using the recently proposed tensor M-product\ntechnique. Theoretical results presented establish a connection between the\nproposed tensor approach and spectral convolution of tensors. The proposed\nmethod TM-GCN is consistent with the Message Passing Neural Network (MPNN)\nframework, accounting for both spatial and temporal message passing. Numerical\nexperiments on real-world datasets demonstrate the performance of the proposed\nmethod for edge classification and link prediction tasks on dynamic graphs. We\nalso consider an application related to the COVID-19 pandemic, and show how our\nmethod can be used for early detection of infected individuals from contact\ntracing data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 23:06:34 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 02:28:32 GMT"}, {"version": "v3", "created": "Sat, 23 Jan 2021 02:46:40 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Malik", "Osman Asif", ""], ["Ubaru", "Shashanka", ""], ["Horesh", "Lior", ""], ["Kilmer", "Misha E.", ""], ["Avron", "Haim", ""]]}, {"id": "1910.07655", "submitter": "Kumar Abhishek", "authors": "Saeid Asgari Taghanaki, Kumar Abhishek, Joseph Paul Cohen, Julien\n  Cohen-Adad, Ghassan Hamarneh", "title": "Deep Semantic Segmentation of Natural and Medical Images: A Review", "comments": "45 pages, 16 figures. Accepted for publication in Springer Artificial\n  Intelligence Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The semantic image segmentation task consists of classifying each pixel of an\nimage into an instance, where each instance corresponds to a class. This task\nis a part of the concept of scene understanding or better explaining the global\ncontext of an image. In the medical image analysis domain, image segmentation\ncan be used for image-guided interventions, radiotherapy, or improved\nradiological diagnostics. In this review, we categorize the leading deep\nlearning-based medical and non-medical image segmentation solutions into six\nmain groups of deep architectural, data synthesis-based, loss function-based,\nsequenced models, weakly supervised, and multi-task methods and provide a\ncomprehensive review of the contributions in each of these groups. Further, for\neach group, we analyze each variant of these groups and discuss the limitations\nof the current approaches and present potential future research directions for\nsemantic image segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 06:35:50 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 18:18:01 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 22:20:36 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Taghanaki", "Saeid Asgari", ""], ["Abhishek", "Kumar", ""], ["Cohen", "Joseph Paul", ""], ["Cohen-Adad", "Julien", ""], ["Hamarneh", "Ghassan", ""]]}, {"id": "1910.07663", "submitter": "James P. Crutchfield", "authors": "S. E. Marzen and J. P. Crutchfield", "title": "Probabilistic Deterministic Finite Automata and Recurrent Networks,\n  Revisited", "comments": "15 pages, 4 figures;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/pdfarnr.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech cs.IT math.IT nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computers (RCs) and recurrent neural networks (RNNs) can mimic any\nfinite-state automaton in theory, and some workers demonstrated that this can\nhold in practice. We test the capability of generalized linear models, RCs, and\nLong Short-Term Memory (LSTM) RNN architectures to predict the stochastic\nprocesses generated by a large suite of probabilistic deterministic\nfinite-state automata (PDFA). PDFAs provide an excellent performance benchmark\nin that they can be systematically enumerated, the randomness and correlation\nstructure of their generated processes are exactly known, and their optimal\nmemory-limited predictors are easily computed. Unsurprisingly, LSTMs outperform\nRCs, which outperform generalized linear models. Surprisingly, each of these\nmethods can fall short of the maximal predictive accuracy by as much as 50%\nafter training and, when optimized, tend to fall short of the maximal\npredictive accuracy by ~5%, even though previously available methods achieve\nmaximal predictive accuracy with orders-of-magnitude less data. Thus, despite\nthe representational universality of RCs and RNNs, using them can engender a\nsurprising predictive gap for simple stimuli. One concludes that there is an\nimportant and underappreciated role for methods that infer \"causal states\" or\n\"predictive state representations\".\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 00:32:12 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Marzen", "S. E.", ""], ["Crutchfield", "J. P.", ""]]}, {"id": "1910.07676", "submitter": "Jie Su", "authors": "Jie Su", "title": "Wasserstein Distance Guided Cross-Domain Learning", "comments": "47 pages, Master Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation aims to generalise a high-performance learner on target\ndomain (non-labelled data) by leveraging the knowledge from source domain (rich\nlabelled data) which comes from a different but related distribution. Assuming\nthe source and target domains data(e.g. images) come from a joint distribution\nbut follow on different marginal distributions, the domain adaptation work aims\nto infer the joint distribution from the source and target domain to learn the\ndomain invariant features. Therefore, in this study, I extend the existing\nstate-of-the-art approach to solve the domain adaptation problem. In\nparticular, I propose a new approach to infer the joint distribution of images\nfrom different distributions, namely Wasserstein Distance Guided Cross-Domain\nLearning (WDGCDL). WDGCDL applies the Wasserstein distance to estimate the\ndivergence between the source and target distribution which provides good\ngradient property and promising generalisation bound. Moreover, to tackle the\ntraining difficulty of the proposed framework, I propose two different training\nschemes for stable training. Qualitative results show that this new approach is\nsuperior to the existing state-of-the-art methods in the standard domain\nadaptation benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:37:09 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Su", "Jie", ""]]}, {"id": "1910.07703", "submitter": "Jiacheng Zhuo", "authors": "Jiacheng Zhuo, Qi Lei, Alexandros G. Dimakis, Constantine Caramanis", "title": "Communication-Efficient Asynchronous Stochastic Frank-Wolfe over\n  Nuclear-norm Balls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale machine learning training suffers from two prior challenges,\nspecifically for nuclear-norm constrained problems with distributed systems:\nthe synchronization slowdown due to the straggling workers, and high\ncommunication costs. In this work, we propose an asynchronous Stochastic Frank\nWolfe (SFW-asyn) method, which, for the first time, solves the two problems\nsimultaneously, while successfully maintaining the same convergence rate as the\nvanilla SFW. We implement our algorithm in python (with MPI) to run on Amazon\nEC2, and demonstrate that SFW-asyn yields speed-ups almost linear to the number\nof machines compared to the vanilla SFW.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 04:22:21 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Zhuo", "Jiacheng", ""], ["Lei", "Qi", ""], ["Dimakis", "Alexandros G.", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1910.07719", "submitter": "Jiachen Yang", "authors": "Jiachen Yang, Brenden Petersen, Hongyuan Zha, Daniel Faissol", "title": "Single Episode Policy Transfer in Reinforcement Learning", "comments": "Published at International Conference on Learning Representations\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer and adaptation to new unknown environmental dynamics is a key\nchallenge for reinforcement learning (RL). An even greater challenge is\nperforming near-optimally in a single attempt at test time, possibly without\naccess to dense rewards, which is not addressed by current methods that require\nmultiple experience rollouts for adaptation. To achieve single episode transfer\nin a family of environments with related dynamics, we propose a general\nalgorithm that optimizes a probe and an inference model to rapidly estimate\nunderlying latent variables of test dynamics, which are then immediately used\nas input to a universal control policy. This modular approach enables\nintegration of state-of-the-art algorithms for variational inference or RL.\nMoreover, our approach does not require access to rewards at test time,\nallowing it to perform in settings where existing adaptive approaches cannot.\nIn diverse experimental domains with a single episode test constraint, our\nmethod significantly outperforms existing adaptive approaches and shows\nfavorable performance against baselines for robust transfer.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 05:37:50 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 17:24:49 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 19:54:41 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Yang", "Jiachen", ""], ["Petersen", "Brenden", ""], ["Zha", "Hongyuan", ""], ["Faissol", "Daniel", ""]]}, {"id": "1910.07724", "submitter": "Sagar Verma", "authors": "Sagar Verma and Prince Patel and Angshul Majumdar", "title": "Collaborative Filtering with Label Consistent Restricted Boltzmann\n  Machine", "comments": "6 pages, ICAPR 2017, Code: https://github.com/sagarverma/LC-CFRBM", "journal-ref": null, "doi": "10.1109/ICAPR.2017.8593079", "report-no": null, "categories": "cs.LG cs.IR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The possibility of employing restricted Boltzmann machine (RBM) for\ncollaborative filtering has been known for about a decade. However, there has\nbeen hardly any work on this topic since 2007. This work revisits the\napplication of RBM in recommender systems. RBM based collaborative filtering\nonly used the rating information; this is an unsupervised architecture. This\nwork adds supervision by exploiting user demographic information and item\nmetadata. A network is learned from the representation layer to the labels\n(metadata). The proposed label consistent RBM formulation improves\nsignificantly on the existing RBM based approach and yield results at par with\nthe state-of-the-art latent factor based models.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 05:58:56 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Verma", "Sagar", ""], ["Patel", "Prince", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1910.07737", "submitter": "Alexander Li", "authors": "Murtaza Dalal, Alexander C. Li, Rohan Taori", "title": "Autoregressive Models: What Are They Good For?", "comments": "Accepted for the Information Theory and Machine Learning workshop at\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive (AR) models have become a popular tool for unsupervised\nlearning, achieving state-of-the-art log likelihood estimates. We investigate\nthe use of AR models as density estimators in two settings -- as a learning\nsignal for image translation, and as an outlier detector -- and find that these\ndensity estimates are much less reliable than previously thought. We examine\nthe underlying optimization issues from both an empirical and theoretical\nperspective, and provide a toy example that illustrates the problem.\nOverwhelmingly, we find that density estimates do not correlate with perceptual\nquality and are unhelpful for downstream tasks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 07:04:13 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Dalal", "Murtaza", ""], ["Li", "Alexander C.", ""], ["Taori", "Rohan", ""]]}, {"id": "1910.07738", "submitter": "Bogdan Trasnea", "authors": "Sorin Grigorescu and Bogdan Trasnea and Tiberiu Cocias and Gigel\n  Macesanu", "title": "A Survey of Deep Learning Techniques for Autonomous Driving", "comments": "28 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:1709.02435, arXiv:1610.01256 by other authors", "journal-ref": "Journal of Field Robotics, Online ISSN:1556-4967, 2019", "doi": "10.1002/rob.21918", "report-no": "Article ID: ROB21918", "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade witnessed increasingly rapid progress in self-driving vehicle\ntechnology, mainly backed up by advances in the area of deep learning and\nartificial intelligence. The objective of this paper is to survey the current\nstate-of-the-art on deep learning technologies used in autonomous driving. We\nstart by presenting AI-based self-driving architectures, convolutional and\nrecurrent neural networks, as well as the deep reinforcement learning paradigm.\nThese methodologies form a base for the surveyed driving scene perception, path\nplanning, behavior arbitration and motion control algorithms. We investigate\nboth the modular perception-planning-action pipeline, where each module is\nbuilt using deep learning methods, as well as End2End systems, which directly\nmap sensory information to steering commands. Additionally, we tackle current\nchallenges encountered in designing AI architectures for autonomous driving,\nsuch as their safety, training data sources and computational hardware. The\ncomparison presented in this survey helps to gain insight into the strengths\nand limitations of deep learning and AI approaches for autonomous driving and\nassist with design choices\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 07:05:28 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 07:47:39 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Grigorescu", "Sorin", ""], ["Trasnea", "Bogdan", ""], ["Cocias", "Tiberiu", ""], ["Macesanu", "Gigel", ""]]}, {"id": "1910.07747", "submitter": "Eunjin Jeon", "authors": "Eunjin Jeon, Wonjun Ko, Jee Seok Yoon, Heung-Il Suk", "title": "Mutual Information-driven Subject-invariant and Class-relevant Deep\n  Representation Learning in BCI", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning-based feature representation methods have\nshown a promising impact in electroencephalography (EEG)-based brain-computer\ninterface (BCI). Nonetheless, owing to high intra- and inter-subject\nvariabilities, many studies on decoding EEG were designed in a subject-specific\nmanner by using calibration samples, with no concern of its practical use,\nhampered by time-consuming steps and a large data requirement. To this end,\nrecent studies adopted a transfer learning strategy, especially domain\nadaptation techniques. Among those, to our knowledge, an adversarial learning\nhas shown its potential in BCIs. In the meantime, it is known that adversarial\nlearning-based domain adaptation methods are prone to negative transfer that\ndisrupts learning generalized feature representations, applicable to diverse\ndomains, e.g., subjects or sessions in BCIs. In this paper, we propose a novel\nframework that learns class-relevant and subject-invariant feature\nrepresentations in an information-theoretic manner, without using adversarial\nlearning. To be specific, we devise two operational components in a deep\nnetwork that explicitly estimate mutual information between feature\nrepresentations; (1) to decompose features in an intermediate layer into\nclass-relevant and class-irrelevant ones, (2) to enrich class-discriminative\nfeature representation. On two large EEG datasets, we validated the\neffectiveness of our proposed framework by comparing with several comparative\nmethods in performance. Further, we conducted rigorous analyses by performing\nan ablation study in regard to the components in our network, explaining our\nmodel's decision on input EEG signals via layer-wise relevance propagation, and\nvisualizing the distribution of learned features via t-SNE.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 07:32:40 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 09:24:45 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 01:27:47 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 06:32:26 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Jeon", "Eunjin", ""], ["Ko", "Wonjun", ""], ["Yoon", "Jee Seok", ""], ["Suk", "Heung-Il", ""]]}, {"id": "1910.07755", "submitter": "Hufei Zhu", "authors": "Hufei Zhu, Chenghao Wei", "title": "Reducing the Computational Complexity of Pseudoinverse for the\n  Incremental Broad Learning System on Added Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this brief, we improve the Broad Learning System (BLS) [7] by reducing the\ncomputational complexity of the incremental learning for added inputs. We\nutilize the inverse of a sum of matrices in [8] to improve a step in the\npseudoinverse of a row-partitioned matrix. Accordingly we propose two fast\nalgorithms for the cases of q > k and q < k, respectively, where q and k denote\nthe number of additional training samples and the total number of nodes,\nrespectively. Specifically, when q > k, the proposed algorithm computes only a\nk * k matrix inverse, instead of a q * q matrix inverse in the existing\nalgorithm. Accordingly it can reduce the complexity dramatically. Our\nsimulations, which follow those for Table V in [7], show that the proposed\nalgorithm and the existing algorithm achieve the same testing accuracy, while\nthe speedups in BLS training time of the proposed algorithm over the existing\nalgorithm are 1.24 - 1.30.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 07:58:15 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Zhu", "Hufei", ""], ["Wei", "Chenghao", ""]]}, {"id": "1910.07762", "submitter": "Zengyi Li", "authors": "Zengyi Li, Yubei Chen, Friedrich T. Sommer", "title": "Learning Energy-Based Models in High-Dimensional Spaces with Multi-scale\n  Denoising Score Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-Based Models (EBMs) assign unnormalized log-probability to data\nsamples. This functionality has a variety of applications, such as sample\nsynthesis, data denoising, sample restoration, outlier detection, Bayesian\nreasoning, and many more. But training of EBMs using standard maximum\nlikelihood is extremely slow because it requires sampling from the model\ndistribution. Score matching potentially alleviates this problem. In\nparticular, denoising score matching \\citep{vincent2011connection} has been\nsuccessfully used to train EBMs. Using noisy data samples with one fixed noise\nlevel, these models learn fast and yield good results in data denoising\n\\citep{saremi2019neural}. However, demonstrations of such models in high\nquality sample synthesis of high dimensional data were lacking. Recently,\n\\citet{song2019generative} have shown that a generative model trained by\ndenoising score matching accomplishes excellent sample synthesis, when trained\nwith data samples corrupted with multiple levels of noise. Here we provide\nanalysis and empirical evidence showing that training with multiple noise\nlevels is necessary when the data dimension is high. Leveraging this insight,\nwe propose a novel EBM trained with multi-scale denoising score matching. Our\nmodel exhibits data generation performance comparable to state-of-the-art\ntechniques such as GANs, and sets a new baseline for EBMs. The proposed model\nalso provides density information and performs well in an image inpainting\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 08:21:17 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 04:58:04 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Li", "Zengyi", ""], ["Chen", "Yubei", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "1910.07763", "submitter": "Andreas Kopf", "authors": "Andreas Kopf, Vincent Fortuin, Vignesh Ram Somnath, Manfred Claassen", "title": "Mixture-of-Experts Variational Autoencoder for Clustering and Generating\n  from Similarity-Based Representations on Single Cell Data", "comments": "Submitted to PLOS Computational Biology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering high-dimensional data, such as images or biological measurements,\nis a long-standingproblem and has been studied extensively. Recently, Deep\nClustering has gained popularity due toits flexibility in fitting the specific\npeculiarities of complex data. Here we introduce the Mixture-of-Experts\nSimilarity Variational Autoencoder (MoE-Sim-VAE), a novel generative clustering\nmodel.The model can learn multi-modal distributions of high-dimensional data\nand use these to generaterealistic data with high efficacy and efficiency.\nMoE-Sim-VAE is based on a Variational Autoencoder(VAE), where the decoder\nconsists of a Mixture-of-Experts (MoE) architecture. This specific architecture\nallows for various modes of the data to be automatically learned by means of\nthe experts.Additionally, we encourage the lower dimensional latent\nrepresentation of our model to follow aGaussian mixture distribution and to\naccurately represent the similarities between the data points. Weassess the\nperformance of our model on the MNIST benchmark data set and challenging\nreal-worldtasks of clustering mouse organs from single-cell RNA-sequencing\nmeasurements and defining cellsubpopulations from mass cytometry (CyTOF)\nmeasurements on hundreds of different datasets.MoE-Sim-VAE exhibits superior\nclustering performance on all these tasks in comparison to thebaselines as well\nas competitor methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 08:21:28 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 10:05:05 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 14:23:42 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Kopf", "Andreas", ""], ["Fortuin", "Vincent", ""], ["Somnath", "Vignesh Ram", ""], ["Claassen", "Manfred", ""]]}, {"id": "1910.07772", "submitter": "Florian Wirthm\\\"uller", "authors": "Florian Wirthm\\\"uller, Julian Schlechtriemen, Jochen Hipp and Manfred\n  Reichert", "title": "Teaching Vehicles to Anticipate: A Systematic Study on Probabilistic\n  Behavior Prediction Using Large Data Sets", "comments": "the paper has been accepted for publication in IEEE Transcations on\n  Intelligent Transportation Systems (T-ITS) 16 pages 13 figures 12 tables", "journal-ref": null, "doi": "10.1109/TITS.2020.3002070", "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By observing their environment as well as other traffic participants, humans\nare enabled to drive road vehicles safely. Vehicle passengers, however,\nperceive a notable difference between non-experienced and experienced drivers.\nIn particular, they may get the impression that the latter ones anticipate what\nwill happen in the next few moments and consider these foresights in their\ndriving behavior. To make the driving style of automated vehicles comparable to\nthe one of human drivers with respect to comfort and perceived safety, the\naforementioned anticipation skills need to become a built-in feature of\nself-driving vehicles. This article provides a systematic comparison of methods\nand strategies to generate this intention for self-driving cars using machine\nlearning techniques. To implement and test these algorithms we use a large data\nset collected over more than 30000 km of highway driving and containing\napproximately 40000 real-world driving situations. We further show that it is\npossible to classify driving maneuvers upcoming within the next 5 s with an\nArea Under the ROC Curve (AUC) above 0.92 for all defined maneuver classes.\nThis enables us to predict the lateral position with a prediction horizon of 5\ns with a median lateral error of less than 0.21 m.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 08:42:40 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 13:46:33 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 15:14:48 GMT"}, {"version": "v4", "created": "Wed, 10 Jun 2020 15:43:01 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Wirthm\u00fcller", "Florian", ""], ["Schlechtriemen", "Julian", ""], ["Hipp", "Jochen", ""], ["Reichert", "Manfred", ""]]}, {"id": "1910.07779", "submitter": "Ryan-Rhys Griffiths", "authors": "Ryan-Rhys Griffiths, Alexander A. Aldrick, Miguel Garcia-Ortegon,\n  Vidhi R. Lalchand, Alpha A. Lee", "title": "Achieving Robustness to Aleatoric Uncertainty with Heteroscedastic\n  Bayesian Optimisation", "comments": "Accepted to the 2019 NeurIPS Workshop on Safety and Robustness in\n  Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a sample-efficient search methodology that holds\ngreat promise for accelerating drug and materials discovery programs. A\nfrequently-overlooked modelling consideration in Bayesian optimisation\nstrategies however, is the representation of heteroscedastic aleatoric\nuncertainty. In many practical applications it is desirable to identify inputs\nwith low aleatoric noise, an example of which might be a material composition\nwhich consistently displays robust properties in response to a noisy\nfabrication process. In this paper, we propose a heteroscedastic Bayesian\noptimisation scheme capable of representing and minimising aleatoric noise\nacross the input space. Our scheme employs a heteroscedastic Gaussian process\n(GP) surrogate model in conjunction with two straightforward adaptations of\nexisting acquisition functions. First, we extend the augmented expected\nimprovement (AEI) heuristic to the heteroscedastic setting and second, we\nintroduce the aleatoric noise-penalised expected improvement (ANPEI) heuristic.\nBoth methodologies are capable of penalising aleatoric noise in the suggestions\nand yield improved performance relative to homoscedastic Bayesian optimisation\nand random sampling on toy problems as well as on two real-world scientific\ndatasets. Code is available at:\n\\url{https://github.com/Ryan-Rhys/Heteroscedastic-BO}\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 09:15:46 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 22:28:47 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Griffiths", "Ryan-Rhys", ""], ["Aldrick", "Alexander A.", ""], ["Garcia-Ortegon", "Miguel", ""], ["Lalchand", "Vidhi R.", ""], ["Lee", "Alpha A.", ""]]}, {"id": "1910.07796", "submitter": "Neta Shoham", "authors": "Neta Shoham (Edgify), Tomer Avidor (Edgify), Aviv Keren (Edgify),\n  Nadav Israel (Edgify), Daniel Benditkis (Edgify), Liron Mor-Yosef (Edgify),\n  Itai Zeitak (Edgify)", "title": "Overcoming Forgetting in Federated Learning on Non-IID Data", "comments": "Accepted to NeurIPS 2019 Workshop on Federated Learning for Data\n  Privacy and Confidentiality", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of Federated Learning in the non i.i.d. case, in which\nlocal models drift apart, inhibiting learning. Building on an analogy with\nLifelong Learning, we adapt a solution for catastrophic forgetting to Federated\nLearning. We add a penalty term to the loss function, compelling all local\nmodels to converge to a shared optimum. We show that this can be done\nefficiently for communication (adding no further privacy risks), scaling with\nthe number of nodes in the distributed setting. Our experiments show that this\nmethod is superior to competing ones for image recognition on the MNIST\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 09:53:16 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Shoham", "Neta", "", "Edgify"], ["Avidor", "Tomer", "", "Edgify"], ["Keren", "Aviv", "", "Edgify"], ["Israel", "Nadav", "", "Edgify"], ["Benditkis", "Daniel", "", "Edgify"], ["Mor-Yosef", "Liron", "", "Edgify"], ["Zeitak", "Itai", "", "Edgify"]]}, {"id": "1910.07813", "submitter": "Jacky H. T. Yip", "authors": "Jacky H. T. Yip, Xinyue Zhang, Yanfang Wang, Wei Zhang, Yueqiu Sun,\n  Gabriella Contardo, Francisco Villaescusa-Navarro, Siyu He, Shy Genel,\n  Shirley Ho", "title": "From Dark Matter to Galaxies with Convolutional Neural Networks", "comments": "5 pages, 2 figures. Accepted to the Second Workshop on Machine\n  Learning and the Physical Sciences (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cosmological simulations play an important role in the interpretation of\nastronomical data, in particular in comparing observed data to our theoretical\nexpectations. However, to compare data with these simulations, the simulations\nin principle need to include gravity, magneto-hydrodyanmics, radiative\ntransfer, etc. These ideal large-volume simulations\n(gravo-magneto-hydrodynamical) are incredibly computationally expensive which\ncan cost tens of millions of CPU hours to run. In this paper, we propose a deep\nlearning approach to map from the dark-matter-only simulation (computationally\ncheaper) to the galaxy distribution (from the much costlier cosmological\nsimulation). The main challenge of this task is the high sparsity in the target\ngalaxy distribution: space is mainly empty. We propose a cascade architecture\ncomposed of a classification filter followed by a regression procedure. We show\nthat our result outperforms a state-of-the-art model used in the astronomical\ncommunity, and provides a good trade-off between computational cost and\nprediction accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 10:30:24 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Yip", "Jacky H. T.", ""], ["Zhang", "Xinyue", ""], ["Wang", "Yanfang", ""], ["Zhang", "Wei", ""], ["Sun", "Yueqiu", ""], ["Contardo", "Gabriella", ""], ["Villaescusa-Navarro", "Francisco", ""], ["He", "Siyu", ""], ["Genel", "Shy", ""], ["Ho", "Shirley", ""]]}, {"id": "1910.07817", "submitter": "Soroosh Shafieezadeh-Abadeh", "authors": "Viet Anh Nguyen, Soroosh Shafieezadeh-Abadeh, Man-Chung Yue, Daniel\n  Kuhn, Wolfram Wiesemann", "title": "Calculating Optimistic Likelihoods Using (Geodesically) Convex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem arising in many areas of machine learning is the\nevaluation of the likelihood of a given observation under different nominal\ndistributions. Frequently, these nominal distributions are themselves estimated\nfrom data, which makes them susceptible to estimation errors. We thus propose\nto replace each nominal distribution with an ambiguity set containing all\ndistributions in its vicinity and to evaluate an \\emph{optimistic likelihood},\nthat is, the maximum of the likelihood over all distributions in the ambiguity\nset. When the proximity of distributions is quantified by the Fisher-Rao\ndistance or the Kullback-Leibler divergence, the emerging optimistic\nlikelihoods can be computed efficiently using either geodesic or standard\nconvex optimization techniques. We showcase the advantages of working with\noptimistic likelihoods on a classification problem using synthetic as well as\nempirical data.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 10:40:02 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Nguyen", "Viet Anh", ""], ["Shafieezadeh-Abadeh", "Soroosh", ""], ["Yue", "Man-Chung", ""], ["Kuhn", "Daniel", ""], ["Wiesemann", "Wolfram", ""]]}, {"id": "1910.07833", "submitter": "Nikita Zhivotovskiy", "authors": "Olivier Bousquet, Yegor Klochkov, Nikita Zhivotovskiy", "title": "Sharper bounds for uniformly stable algorithms", "comments": "17 pages, minor improvements, to appear in COLT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deriving generalization bounds for stable algorithms is a classical question\nin learning theory taking its roots in the early works by Vapnik and\nChervonenkis (1974) and Rogers and Wagner (1978). In a series of recent\nbreakthrough papers by Feldman and Vondrak (2018, 2019), it was shown that the\nbest known high probability upper bounds for uniformly stable learning\nalgorithms due to Bousquet and Elisseef (2002) are sub-optimal in some natural\nregimes. To do so, they proved two generalization bounds that significantly\noutperform the simple generalization bound of Bousquet and Elisseef (2002).\nFeldman and Vondrak also asked if it is possible to provide sharper bounds and\nprove corresponding high probability lower bounds. This paper is devoted to\nthese questions: firstly, inspired by the original arguments of Feldman and\nVondrak (2019), we provide a short proof of the moment bound that implies the\ngeneralization bound stronger than both recent results (Feldman and Vondrak,\n2018, 2019). Secondly, we prove general lower bounds, showing that our moment\nbound is sharp (up to a logarithmic factor) unless some additional properties\nof the corresponding random variables are used. Our main probabilistic result\nis a general concentration inequality for weakly correlated random variables,\nwhich may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 11:42:37 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 08:08:48 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Bousquet", "Olivier", ""], ["Klochkov", "Yegor", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "1910.07842", "submitter": "Firuz Kamalov", "authors": "Firuz Kamalov", "title": "Kernel density estimation based sampling for imbalanced class\n  distribution", "comments": "This is the version of the article that was accepted in Information\n  Sciences", "journal-ref": null, "doi": "10.1016/j.ins.2019.10.017", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced response variable distribution is a common occurrence in data\nscience. In fields such as fraud detection, medical diagnostics, system\nintrusion detection and many others where abnormal behavior is rarely observed\nthe data under study often features disproportionate target class distribution.\nOne common way to combat class imbalance is through resampling the minority\nclass to achieve a more balanced distribution. In this paper, we investigate\nthe performance of the sampling method based on kernel density estimation\n(KDE). We believe that KDE offers a more natural way of generating new\ninstances of minority class that is less prone to overfitting than other\nstandard sampling techniques. It is based on a well established theory of\nnonparametric statistical estimation. Numerical experiments show that KDE can\noutperform other sampling techniques on a range of real life datasets as\nmeasured by F1-score and G-mean. The results remain consistent across a number\nof classification algorithms used in the experiments. Furthermore, the proposed\nmethod outperforms the benchmark methods irregardless of the class distribution\nratio. We conclude, based on the solid theoretical foundation and strong\nexperimental results, that the proposed method would be a valuable tool in\nproblems involving imbalanced class distribution.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 11:52:30 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 09:51:06 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Kamalov", "Firuz", ""]]}, {"id": "1910.07856", "submitter": "Johannes Rabold", "authors": "Ludwig Schallner, Johannes Rabold, Oliver Scholz, Ute Schmid", "title": "Effect of Superpixel Aggregation on Explanations in LIME -- A Case Study\n  with Biological Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end learning with deep neural networks, such as convolutional neural\nnetworks (CNNs), has been demonstrated to be very successful for different\ntasks of image classification. To make decisions of black-box approaches\ntransparent, different solutions have been proposed. LIME is an approach to\nexplainable AI relying on segmenting images into superpixels based on the\nQuick-Shift algorithm. In this paper, we present an explorative study of how\ndifferent superpixel methods, namely Felzenszwalb, SLIC and Compact-Watershed,\nimpact the generated visual explanations. We compare the resulting relevance\nareas with the image parts marked by a human reference. Results show that image\nparts selected as relevant strongly vary depending on the applied method.\nQuick-Shift resulted in the least and Compact-Watershed in the highest\ncorrespondence with the reference relevance areas.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 12:30:05 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Schallner", "Ludwig", ""], ["Rabold", "Johannes", ""], ["Scholz", "Oliver", ""], ["Schmid", "Ute", ""]]}, {"id": "1910.07860", "submitter": "Raghav Brahmadesam Venkataramaiyer", "authors": "Raghav Brahmadesam Venkataramaiyer, Subham Kumar, Vinay P. Namboodiri", "title": "Can I teach a robot to replicate a line art", "comments": "9 pages, Accepted for the 2020 Winter Conference on Applications of\n  Computer Vision (WACV '20); Supplementary Video: https://youtu.be/nMt5Dw04XhY", "journal-ref": null, "doi": "10.1109/WACV45572.2020.9093434", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Line art is arguably one of the fundamental and versatile modes of\nexpression. We propose a pipeline for a robot to look at a grayscale line art\nand redraw it. The key novel elements of our pipeline are: a) we propose a\nnovel task of mimicking line drawings, b) to solve the pipeline we modify the\nQuick-draw dataset to obtain supervised training for converting a line drawing\ninto a series of strokes c) we propose a multi-stage segmentation and graph\ninterpretation pipeline for solving the problem. The resultant method has also\nbeen deployed on a CNC plotter as well as a robotic arm. We have trained\nseveral variations of the proposed methods and evaluate these on a dataset\nobtained from Quick-draw. Through the best methods we observe an accuracy of\naround 98% for this task, which is a significant improvement over the baseline\narchitecture we adapted from. This therefore allows for deployment of the\nmethod on robots for replicating line art in a reliable manner. We also show\nthat while the rule-based vectorization methods do suffice for simple drawings,\nit fails for more complicated sketches, unlike our method which generalizes\nwell to more complicated distributions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 12:40:15 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Venkataramaiyer", "Raghav Brahmadesam", ""], ["Kumar", "Subham", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1910.07870", "submitter": "Kush Varshney", "authors": "Sanghamitra Dutta, Dennis Wei, Hazar Yueksel, Pin-Yu Chen, Sijia Liu,\n  Kush R. Varshney", "title": "Is There a Trade-Off Between Fairness and Accuracy? A Perspective Using\n  Mismatched Hypothesis Testing", "comments": "This paper appears in the Proceedings of the 37th International\n  Conference on Machine Learning, pp. 2803--2813, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A trade-off between accuracy and fairness is almost taken as a given in the\nexisting literature on fairness in machine learning. Yet, it is not preordained\nthat accuracy should decrease with increased fairness. Novel to this work, we\nexamine fair classification through the lens of mismatched hypothesis testing:\ntrying to find a classifier that distinguishes between two ideal distributions\nwhen given two mismatched distributions that are biased. Using Chernoff\ninformation, a tool in information theory, we theoretically demonstrate that,\ncontrary to popular belief, there always exist ideal distributions such that\noptimal fairness and accuracy (with respect to the ideal distributions) are\nachieved simultaneously: there is no trade-off. Moreover, the same classifier\nyields the lack of a trade-off with respect to ideal distributions while\nyielding a trade-off when accuracy is measured with respect to the given\n(possibly biased) dataset. To complement our main result, we formulate an\noptimization to find ideal distributions and derive fundamental limits to\nexplain why a trade-off exists on the given biased dataset. We also derive\nconditions under which active data collection can alleviate the\nfairness-accuracy trade-off in the real world. Our results lead us to contend\nthat it is problematic to measure accuracy with respect to data that reflects\nbias, and instead, we should be considering accuracy with respect to ideal,\nunbiased data.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 12:59:25 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 20:03:48 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Dutta", "Sanghamitra", ""], ["Wei", "Dennis", ""], ["Yueksel", "Hazar", ""], ["Chen", "Pin-Yu", ""], ["Liu", "Sijia", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1910.07882", "submitter": "Boyuan Chen", "authors": "Boyuan Chen, Shuran Song, Hod Lipson, Carl Vondrick", "title": "Visual Hide and Seek", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train embodied agents to play Visual Hide and Seek where a prey must\nnavigate in a simulated environment in order to avoid capture from a predator.\nWe place a variety of obstacles in the environment for the prey to hide behind,\nand we only give the agents partial observations of their environment using an\negocentric perspective. Although we train the model to play this game from\nscratch, experiments and visualizations suggest that the agent learns to\npredict its own visibility in the environment. Furthermore, we quantitatively\nanalyze how agent weaknesses, such as slower speed, effect the learned policy.\nOur results suggest that, although agent weaknesses make the learning problem\nmore challenging, they also cause more useful features to be learned. Our\nproject website is available at: http://www.cs.columbia.edu/\n~bchen/visualhideseek/.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 01:27:09 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Chen", "Boyuan", ""], ["Song", "Shuran", ""], ["Lipson", "Hod", ""], ["Vondrick", "Carl", ""]]}, {"id": "1910.07892", "submitter": "Wenhao Zhang", "authors": "Wenhao Zhang, Ramin Ramezani, Arash Naeim", "title": "WOTBoost: Weighted Oversampling Technique in Boosting for imbalanced\n  learning", "comments": "10 pages, 5 figures, 3 tables; Accepted by 5th Special Session on\n  Intelligent Data Mining in IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning classifiers often stumble over imbalanced datasets where\nclasses are not equally represented. This inherent bias towards the majority\nclass may result in low accuracy in labeling minority class. Imbalanced\nlearning is prevalent in many real-world applications, such as medical\nresearch, network intrusion detection, and fraud detection in credit card\ntransactions, etc. A good number of research works have been reported to tackle\nthis challenging problem. For example, Synthetic Minority Over-sampling\nTEchnique (SMOTE) and ADAptive SYNthetic sampling approach (ADASYN) use\noversampling techniques to balance the skewed datasets. In this paper, we\npropose a novel method that combines a Weighted Oversampling Technique and\nensemble Boosting method (WOTBoost) to improve the classification accuracy of\nminority data without sacrificing the accuracy of the majority class. WOTBoost\nadjusts its oversampling strategy at each round of boosting to synthesize more\ntargeted minority data samples. The adjustment is enforced using a weighted\ndistribution. We compare WOTBoost with other four classification models (i.e.,\ndecision tree, SMOTE + decision tree, ADASYN + decision tree, SMOTEBoost)\nextensively on 18 public accessible imbalanced datasets. WOTBoost achieves the\nbest G mean on 6 datasets and highest AUC score on 7 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 13:27:04 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 20:10:50 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 19:36:59 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Zhang", "Wenhao", ""], ["Ramezani", "Ramin", ""], ["Naeim", "Arash", ""]]}, {"id": "1910.07897", "submitter": "Jishnu Ray Chowdhury", "authors": "Jishnu Ray Chowdhury, Cornelia Caragea, Doina Caragea", "title": "Keyphrase Extraction from Disaster-related Tweets", "comments": "12 pages, 7 figures", "journal-ref": "In The World Wide Web Conference (WWW '19), Ling Liu and Ryen\n  White (Eds.). ACM, New York, NY, USA, 1555-1566 (2019)", "doi": "10.1145/3308558.3313696", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While keyphrase extraction has received considerable attention in recent\nyears, relatively few studies exist on extracting keyphrases from social media\nplatforms such as Twitter, and even fewer for extracting disaster-related\nkeyphrases from such sources. During a disaster, keyphrases can be extremely\nuseful for filtering relevant tweets that can enhance situational awareness.\nPreviously, joint training of two different layers of a stacked Recurrent\nNeural Network for keyword discovery and keyphrase extraction had been shown to\nbe effective in extracting keyphrases from general Twitter data. We improve the\nmodel's performance on both general Twitter data and disaster-related Twitter\ndata by incorporating contextual word embeddings, POS-tags, phonetics, and\nphonological features. Moreover, we discuss the shortcomings of the often used\nF1-measure for evaluating the quality of predicted keyphrases with respect to\nthe ground truth annotations. Instead of the F1-measure, we propose the use of\nembedding-based metrics to better capture the correctness of the predicted\nkeyphrases. In addition, we also present a novel extension of an\nembedding-based metric. The extension allows one to better control the penalty\nfor the difference in the number of ground-truth and predicted keyphrases\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 13:31:45 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Chowdhury", "Jishnu Ray", ""], ["Caragea", "Cornelia", ""], ["Caragea", "Doina", ""]]}, {"id": "1910.07899", "submitter": "Hari Prasanna Das", "authors": "Ioannis C. Konstantakopoulos, Hari Prasanna Das, Andrew R. Barkan,\n  Shiying He, Tanya Veeravalli, Huihan Liu, Aummul Baneen Manasawala, Yu-Wen\n  Lin and Costas J. Spanos", "title": "Design, Benchmarking and Explainability Analysis of a Game-Theoretic\n  Framework towards Energy Efficiency in Smart Infrastructure", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.05142,\n  arXiv:1810.10533", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a gamification approach as a novel framework for\nsmart building infrastructure with the goal of motivating human occupants to\nreconsider personal energy usage and to have positive effects on their\nenvironment. Human interaction in the context of cyber-physical systems is a\ncore component and consideration in the implementation of any smart building\ntechnology. Research has shown that the adoption of human-centric building\nservices and amenities leads to improvements in the operational efficiency of\nthese cyber-physical systems directed towards controlling building energy\nusage. We introduce a strategy in form of a game-theoretic framework that\nincorporates humans-in-the-loop modeling by creating an interface to allow\nbuilding managers to interact with occupants and potentially incentivize energy\nefficient behavior. Prior works on game theoretic analysis typically rely on\nthe assumption that the utility function of each individual agent is known a\npriori. Instead, we propose novel utility learning framework for benchmarking\nthat employs robust estimations of occupant actions towards energy efficiency.\nTo improve forecasting performance, we extend the utility learning scheme by\nleveraging deep bi-directional recurrent neural networks. Using the proposed\nmethods on data gathered from occupant actions for resources such as room\nlighting, we forecast patterns of energy resource usage to demonstrate the\nprediction performance of the methods. The results of our study show that we\ncan achieve a highly accurate representation of the ground truth for occupant\nenergy resource usage. We also demonstrate the explainable nature on human\ndecision making towards energy usage inherent in the dataset using graphical\nlasso and granger causality algorithms. Finally, we open source the\nde-identified, high-dimensional data pertaining to the energy game-theoretic\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 07:36:26 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Konstantakopoulos", "Ioannis C.", ""], ["Das", "Hari Prasanna", ""], ["Barkan", "Andrew R.", ""], ["He", "Shiying", ""], ["Veeravalli", "Tanya", ""], ["Liu", "Huihan", ""], ["Manasawala", "Aummul Baneen", ""], ["Lin", "Yu-Wen", ""], ["Spanos", "Costas J.", ""]]}, {"id": "1910.07900", "submitter": "Yanpei Shi", "authors": "Yanpei Shi, Qiang Huang, Thomas Hain", "title": "H-VECTORS: Utterance-level Speaker Embedding Using A Hierarchical\n  Attention Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a hierarchical attention network to generate utterance-level\nembeddings (H-vectors) for speaker identification is proposed. Since different\nparts of an utterance may have different contributions to speaker identities,\nthe use of hierarchical structure aims to learn speaker related information\nlocally and globally. In the proposed approach, frame-level encoder and\nattention are applied on segments of an input utterance and generate individual\nsegment vectors. Then, segment level attention is applied on the segment\nvectors to construct an utterance representation. To evaluate the effectiveness\nof the proposed approach, NIST SRE 2008 Part1 dataset is used for training, and\ntwo datasets, Switchboard Cellular part1 and CallHome American English Speech,\nare used to evaluate the quality of extracted utterance embeddings on speaker\nidentification and verification tasks. In comparison with two baselines,\nX-vector, X-vector+Attention, the obtained results show that H-vectors can\nachieve a significantly better performance. Furthermore, the extracted\nutterance-level embeddings are more discriminative than the two baselines when\nmapped into a 2D space using t-SNE.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 13:33:41 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 19:21:26 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Shi", "Yanpei", ""], ["Huang", "Qiang", ""], ["Hain", "Thomas", ""]]}, {"id": "1910.07918", "submitter": "Jun Sun", "authors": "Jun Sun, Steffen Staab, J\\'er\\^ome Kunegis", "title": "Understanding Social Networks using Transfer Learning", "comments": "11 pages, 4 figures, IEEE Computer. arXiv admin note: text overlap\n  with arXiv:1611.02941", "journal-ref": "IEEE Computer (Volume: 51, Issue: 6, June 2018)", "doi": "10.1109/MC.2018.2701640", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A detailed understanding of users contributes to the understanding of the\nWeb's evolution, and to the development of Web applications. Although for new\nWeb platforms such a study is especially important, it is often jeopardized by\nthe lack of knowledge about novel phenomena due to the sparsity of data. Akin\nto human transfer of experiences from one domain to the next, transfer learning\nas a subfield of machine learning adapts knowledge acquired in one domain to a\nnew domain. We systematically investigate how the concept of transfer learning\nmay be applied to the study of users on newly created (emerging) Web platforms,\nand propose our transfer learning-based approach, TraNet. We show two use cases\nwhere TraNet is applied to tasks involving the identification of user trust and\nroles on different Web platforms. We compare the performance of TraNet with\nother approaches and find that our approach can best transfer knowledge on\nusers across platforms in the given tasks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 09:51:13 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Sun", "Jun", ""], ["Staab", "Steffen", ""], ["Kunegis", "J\u00e9r\u00f4me", ""]]}, {"id": "1910.07927", "submitter": "Sergul Aydore", "authors": "Sergul Aydore, Tianhao Zhu, Dean Foster", "title": "Dynamic Local Regret for Non-convex Online Forecasting", "comments": "NeurIPS2019. arXiv admin note: substantial text overlap with\n  arXiv:1905.08850", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online forecasting problems for non-convex machine learning\nmodels. Forecasting introduces several challenges such as (i) frequent updates\nare necessary to deal with concept drift issues since the dynamics of the\nenvironment change over time, and (ii) the state of the art models are\nnon-convex models. We address these challenges with a novel regret framework.\nStandard regret measures commonly do not consider both dynamic environment and\nnon-convex models. We introduce a local regret for non-convex models in a\ndynamic environment. We present an update rule incurring a cost, according to\nour proposed local regret, which is sublinear in time T. Our update uses\ntime-smoothed gradients. Using a real-world dataset we show that our\ntime-smoothed approach yields several benefits when compared with\nstate-of-the-art competitors: results are more stable against new data;\ntraining is more robust to hyperparameter selection; and our approach is more\ncomputationally efficient than the alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:01:08 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 14:34:31 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Aydore", "Sergul", ""], ["Zhu", "Tianhao", ""], ["Foster", "Dean", ""]]}, {"id": "1910.07939", "submitter": "S Indrapriyadarsini", "authors": "Sota Yasuda, Shahrzad Mahboubi, S. Indrapriyadarsini, Hiroshi Ninomiya\n  and Hideki Asai", "title": "A Stochastic Variance Reduced Nesterov's Accelerated Quasi-Newton Method", "comments": "Accepted in ICMLA 2019", "journal-ref": null, "doi": "10.1109/ICMLA.2019.00301", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently algorithms incorporating second order curvature information have\nbecome popular in training neural networks. The Nesterov's Accelerated\nQuasi-Newton (NAQ) method has shown to effectively accelerate the BFGS\nquasi-Newton method by incorporating the momentum term and Nesterov's\naccelerated gradient vector. A stochastic version of NAQ method was proposed\nfor training of large-scale problems. However, this method incurs high\nstochastic variance noise. This paper proposes a stochastic variance reduced\nNesterov's Accelerated Quasi-Newton method in full (SVR-NAQ) and limited\n(SVRLNAQ) memory forms. The performance of the proposed method is evaluated in\nTensorflow on four benchmark problems - two regression and two classification\nproblems respectively. The results show improved performance compared to\nconventional methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 14:31:37 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Yasuda", "Sota", ""], ["Mahboubi", "Shahrzad", ""], ["Indrapriyadarsini", "S.", ""], ["Ninomiya", "Hiroshi", ""], ["Asai", "Hideki", ""]]}, {"id": "1910.07948", "submitter": "Oier Mees", "authors": "Oier Mees, Maxim Tatarchenko, Thomas Brox, Wolfram Burgard", "title": "Self-supervised 3D Shape and Viewpoint Estimation from Single Images for\n  Robotics", "comments": "Accepted at the 2019 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS). Video at\n  https://www.youtube.com/watch?v=oQgHG9JdMP4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a convolutional neural network for joint 3D shape prediction and\nviewpoint estimation from a single input image. During training, our network\ngets the learning signal from a silhouette of an object in the input image - a\nform of self-supervision. It does not require ground truth data for 3D shapes\nand the viewpoints. Because it relies on such a weak form of supervision, our\napproach can easily be applied to real-world data. We demonstrate that our\nmethod produces reasonable qualitative and quantitative results on natural\nimages for both shape estimation and viewpoint prediction. Unlike previous\napproaches, our method does not require multiple views of the same object\ninstance in the dataset, which significantly expands the applicability in\npractical robotics scenarios. We showcase it by using the hallucinated shapes\nto improve the performance on the task of grasping real-world objects both in\nsimulation and with a PR2 robot.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 14:55:21 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Mees", "Oier", ""], ["Tatarchenko", "Maxim", ""], ["Brox", "Thomas", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1910.07969", "submitter": "Chih-Kuan Yeh", "authors": "Chih-Kuan Yeh, Been Kim, Sercan O. Arik, Chun-Liang Li, Tomas Pfister,\n  and Pradeep Ravikumar", "title": "On Completeness-aware Concept-Based Explanations in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human explanations of high-level decisions are often expressed in terms of\nkey concepts the decisions are based on. In this paper, we study such\nconcept-based explainability for Deep Neural Networks (DNNs). First, we define\nthe notion of completeness, which quantifies how sufficient a particular set of\nconcepts is in explaining a model's prediction behavior based on the assumption\nthat complete concept scores are sufficient statistics of the model prediction.\nNext, we propose a concept discovery method that aims to infer a complete set\nof concepts that are additionally encouraged to be interpretable, which\naddresses the limitations of existing methods on concept explanations. To\ndefine an importance score for each discovered concept, we adapt game-theoretic\nnotions to aggregate over sets and propose ConceptSHAP. Via proposed metrics\nand user studies, on a synthetic dataset with apriori-known concept\nexplanations, as well as on real-world image and language datasets, we validate\nthe effectiveness of our method in finding concepts that are both complete in\nexplaining the decisions and interpretable. (The code is released at\nhttps://github.com/chihkuanyeh/concept_exp)\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 15:27:37 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 04:15:19 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 18:38:56 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 10:57:12 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 00:57:19 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Yeh", "Chih-Kuan", ""], ["Kim", "Been", ""], ["Arik", "Sercan O.", ""], ["Li", "Chun-Liang", ""], ["Pfister", "Tomas", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1910.07972", "submitter": "Max Argus", "authors": "Lukas Hermann, Max Argus, Andreas Eitel, Artemij Amiranashvili,\n  Wolfram Burgard, Thomas Brox", "title": "Adaptive Curriculum Generation from Demonstrations for Sim-to-Real\n  Visuomotor Control", "comments": "Accepted at the 2020 IEEE International Conference on Robotics and\n  Automation (ICRA). Project page see\n  https://lmb.informatik.uni-freiburg.de/projects/curriculum/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Adaptive Curriculum Generation from Demonstrations (ACGD) for\nreinforcement learning in the presence of sparse rewards. Rather than designing\nshaped reward functions, ACGD adaptively sets the appropriate task difficulty\nfor the learner by controlling where to sample from the demonstration\ntrajectories and which set of simulation parameters to use. We show that\ntraining vision-based control policies in simulation while gradually increasing\nthe difficulty of the task via ACGD improves the policy transfer to the real\nworld. The degree of domain randomization is also gradually increased through\nthe task difficulty. We demonstrate zero-shot transfer for two real-world\nmanipulation tasks: pick-and-stow and block stacking. A video showing the\nresults can be found at\nhttps://lmb.informatik.uni-freiburg.de/projects/curriculum/\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 15:33:03 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 10:49:36 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 15:44:10 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Hermann", "Lukas", ""], ["Argus", "Max", ""], ["Eitel", "Andreas", ""], ["Amiranashvili", "Artemij", ""], ["Burgard", "Wolfram", ""], ["Brox", "Thomas", ""]]}, {"id": "1910.07973", "submitter": "Xiaofei Ma", "authors": "Xiaofei Ma, Zhiguo Wang, Patrick Ng, Ramesh Nallapati, Bing Xiang", "title": "Universal Text Representation from BERT: An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a systematic investigation of layer-wise BERT activations for\ngeneral-purpose text representations to understand what linguistic information\nthey capture and how transferable they are across different tasks.\nSentence-level embeddings are evaluated against two state-of-the-art models on\ndownstream and probing tasks from SentEval, while passage-level embeddings are\nevaluated on four question-answering (QA) datasets under a learning-to-rank\nproblem setting. Embeddings from the pre-trained BERT model perform poorly in\nsemantic similarity and sentence surface information probing tasks. Fine-tuning\nBERT on natural language inference data greatly improves the quality of the\nembeddings. Combining embeddings from different BERT layers can further boost\nperformance. BERT embeddings outperform BM25 baseline significantly on factoid\nQA datasets at the passage level, but fail to perform better than BM25 on\nnon-factoid datasets. For all QA datasets, there is a gap between\nembedding-based method and in-domain fine-tuned BERT (we report new\nstate-of-the-art results on two datasets), which suggests deep interactions\nbetween question and answer pairs are critical for those hard tasks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 15:33:26 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 23:56:32 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Ma", "Xiaofei", ""], ["Wang", "Zhiguo", ""], ["Ng", "Patrick", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1910.07988", "submitter": "Yue Zhao", "authors": "Yue Zhao, Xuejian Wang, Cheng Cheng, Xueying Ding", "title": "Combining Machine Learning Models using combo Library", "comments": "In Proceedings of Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI 2020)", "journal-ref": null, "doi": "10.1609/aaai.v34i09.7111", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model combination, often regarded as a key sub-field of ensemble learning,\nhas been widely used in both academic research and industry applications. To\nfacilitate this process, we propose and implement an easy-to-use Python\ntoolkit, combo, to aggregate models and scores under various scenarios,\nincluding classification, clustering, and anomaly detection. In a nutshell,\ncombo provides a unified and consistent way to combine both raw and pretrained\nmodels from popular machine learning libraries, e.g., scikit-learn, XGBoost,\nand LightGBM. With accessibility and robustness in mind, combo is designed with\ndetailed documentation, interactive examples, continuous integration, code\ncoverage, and maintainability check; it can be installed easily through Python\nPackage Index (PyPI) or https://github.com/yzhao062/combo.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 15:00:13 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 21:00:53 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhao", "Yue", ""], ["Wang", "Xuejian", ""], ["Cheng", "Cheng", ""], ["Ding", "Xueying", ""]]}, {"id": "1910.07999", "submitter": "Ramya Akula", "authors": "Ramya Akula, Niloofar Yousefi and Ivan Garibay", "title": "DeepFork: Supervised Prediction of Information Diffusion in GitHub", "comments": "12 Pages, 7 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information spreads on complex social networks extremely fast, in other\nwords, a piece of information can go viral within no time. Often it is hard to\nbarricade this diffusion prior to the significant occurrence of chaos, be it a\nsocial media or an online coding platform. GitHub is one such trending online\nfocal point for any business to reach their potential contributors and\ncustomers, simultaneously. By exploiting such software development paradigm,\nmillions of free software emerged lately in diverse communities. To understand\nhuman influence, information spread and evolution of transmitted information\namong assorted users in GitHub, we developed a deep neural network model:\nDeepFork, a supervised machine learning based approach that aims to predict\ninformation diffusion in complex social networks; considering node as well as\ntopological features. In our empirical studies, we observed that information\ndiffusion can be detected by link prediction using supervised learning.\nDeepFork outperforms other machine learning models as it better learns the\ndiscriminative patterns from the input features. DeepFork aids in understanding\ninformation spread and evolution through a bipartite network of users and\nrepositories i.e., information flow from a user to repository to user.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 16:18:45 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Akula", "Ramya", ""], ["Yousefi", "Niloofar", ""], ["Garibay", "Ivan", ""]]}, {"id": "1910.08007", "submitter": "Thu Nguyen Ms.", "authors": "Thu Nguyen", "title": "Faster feature selection with a Dropping Forward-Backward algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this era of big data, feature selection techniques, which have long been\nproven to simplify the model, makes the model more comprehensible, speed up the\nprocess of learning, have become more and more important. Among many developed\nmethods, forward and stepwise feature selection regression remained widely used\ndue to their simplicity and efficiency. However, they all involving rescanning\nall the un-selected features again and again. Moreover, many times, the\nbackward steps in stepwise deem unnecessary, as we will illustrate in our\nexample. These remarks motivate us to introduce a novel algorithm that may\nboost the speed up to 65.77% compared to the stepwise procedure while\nmaintaining good performance in terms of the number of selected features and\nerror rates. Also, our experiments illustrate that feature selection procedures\nmay be a better choice for high-dimensional problems where the number of\nfeatures highly exceeds the number of samples.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 16:25:47 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 02:47:55 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 17:50:26 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Nguyen", "Thu", ""]]}, {"id": "1910.08013", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison", "title": "Why bigger is not always better: on finite and infinite neural networks", "comments": null, "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has argued that neural networks can be understood theoretically\nby taking the number of channels to infinity, at which point the outputs become\nGaussian process (GP) distributed. However, we note that infinite Bayesian\nneural networks lack a key facet of the behaviour of real neural networks: the\nfixed kernel, determined only by network hyperparameters, implies that they\ncannot do any form of representation learning. The lack of representation or\nequivalently kernel learning leads to less flexibility and hence worse\nperformance, giving a potential explanation for the inferior performance of\ninfinite networks observed in the literature (e.g. Novak et al. 2019). We give\nanalytic results characterising the prior over representations and\nrepresentation learning in finite deep linear networks. We show empirically\nthat the representations in SOTA architectures such as ResNets trained with SGD\nare much closer to those suggested by our deep linear results than by the\ncorresponding infinite network. This motivates the introduction of a new class\nof network: infinite networks with bottlenecks, which inherit the theoretical\ntractability of infinite networks while at the same time allowing\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 16:33:34 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 11:51:36 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 08:53:07 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Aitchison", "Laurence", ""]]}, {"id": "1910.08018", "submitter": "Xinjie Fan", "authors": "Xinjie Fan, Yuguang Yue, Purnamrita Sarkar, Y. X. Rachel Wang", "title": "A Unified Framework for Tuning Hyperparameters in Clustering Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting hyperparameters for unsupervised learning problems is challenging\nin general due to the lack of ground truth for validation. Despite the\nprevalence of this issue in statistics and machine learning, especially in\nclustering problems, there are not many methods for tuning these\nhyperparameters with theoretical guarantees. In this paper, we provide a\nframework with provable guarantees for selecting hyperparameters in a number of\ndistinct models. We consider both the subgaussian mixture model and network\nmodels to serve as examples of i.i.d. and non-i.i.d. data. We demonstrate that\nthe same framework can be used to choose the Lagrange multipliers of penalty\nterms in semi-definite programming (SDP) relaxations for community detection,\nand the bandwidth parameter for constructing kernel similarity matrices for\nspectral clustering. By incorporating a cross-validation procedure, we show the\nframework can also do consistent model selection for network models. Using a\nvariety of simulated and real data examples, we show that our framework\noutperforms other widely used tuning procedures in a broad range of parameter\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 16:40:42 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 02:12:38 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Fan", "Xinjie", ""], ["Yue", "Yuguang", ""], ["Sarkar", "Purnamrita", ""], ["Wang", "Y. X. Rachel", ""]]}, {"id": "1910.08031", "submitter": "Boyan Gao", "authors": "Boyan Gao, Yongxin Yang, Henry Gouk, Timothy M. Hospedales", "title": "Deep clustering with concrete k-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of simultaneously learning a k-means clustering and\ndeep feature representation from unlabelled data, which is of interest due to\nthe potential of deep k-means to outperform traditional two-step feature\nextraction and shallow-clustering strategies. We achieve this by developing a\ngradient-estimator for the non-differentiable k-means objective via the\nGumbel-Softmax reparameterisation trick. In contrast to previous attempts at\ndeep clustering, our concrete k-means model can be optimised with respect to\nthe canonical k-means objective and is easily trained end-to-end without\nresorting to alternating optimisation. We demonstrate the efficacy of our\nmethod on standard clustering benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 16:57:15 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Gao", "Boyan", ""], ["Yang", "Yongxin", ""], ["Gouk", "Henry", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1910.08032", "submitter": "George Kesidis", "authors": "George Kesidis and David J. Miller and Zhen Xiang", "title": "Notes on Margin Training and Margin p-Values for Deep Neural Network\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new local class-purity theorem for Lipschitz continuous DNN\nclassifiers. In addition, we discuss how to achieve classification margin for\ntraining samples. Finally, we describe how to compute margin p-values for test\nsamples.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 03:26:32 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 16:31:08 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Kesidis", "George", ""], ["Miller", "David J.", ""], ["Xiang", "Zhen", ""]]}, {"id": "1910.08036", "submitter": "Philippe Schwaller", "authors": "Philippe Schwaller, Riccardo Petraglia, Valerio Zullo, Vishnu H Nair,\n  Rico Andreas Haeuselmann, Riccardo Pisoni, Costas Bekas, Anna Iuliano, and\n  Teodoro Laino", "title": "Predicting retrosynthetic pathways using a combined linguistic model and\n  hyper-graph exploration strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension of our Molecular Transformer architecture combined\nwith a hyper-graph exploration strategy for automatic retrosynthesis route\nplanning without human intervention. The single-step retrosynthetic model sets\na new state of the art for predicting reactants as well as reagents, solvents\nand catalysts for each retrosynthetic step. We introduce new metrics (coverage,\nclass diversity, round-trip accuracy and Jensen-Shannon divergence) to evaluate\nthe single-step retrosynthetic models, using the forward prediction and a\nreaction classification model always based on the transformer architecture. The\nhypergraph is constructed on the fly, and the nodes are filtered and further\nexpanded based on a Bayesian-like probability. We critically assessed the\nend-to-end framework with several retrosynthesis examples from literature and\nacademic exams. Overall, the frameworks has a very good performance with few\nweaknesses due to the bias induced during the training process. The use of the\nnewly introduced metrics opens up the possibility to optimize entire\nretrosynthetic frameworks through focusing on the performance of the\nsingle-step model only.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 17:02:41 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Schwaller", "Philippe", ""], ["Petraglia", "Riccardo", ""], ["Zullo", "Valerio", ""], ["Nair", "Vishnu H", ""], ["Haeuselmann", "Rico Andreas", ""], ["Pisoni", "Riccardo", ""], ["Bekas", "Costas", ""], ["Iuliano", "Anna", ""], ["Laino", "Teodoro", ""]]}, {"id": "1910.08037", "submitter": "Han Bao", "authors": "Han Bao, Jinyong Feng, Nam Dinh, Hongbin Zhang", "title": "Computationally Efficient CFD Prediction of Bubbly Flow using\n  Physics-Guided Deep Learning", "comments": "This paper is under review of International Journal of Multi-phase\n  Flow", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.data-an physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To realize efficient computational fluid dynamics (CFD) prediction of\ntwo-phase flow, a multi-scale framework was proposed in this paper by applying\na physics-guided data-driven approach. Instrumental to this framework, Feature\nSimilarity Measurement (FSM) technique was developed for error estimation in\ntwo-phase flow simulation using coarse-mesh CFD, to achieve a comparable\naccuracy as fine-mesh simulations with fast-running feature. By defining\nphysics-guided parameters and variable gradients as physical features, FSM has\nthe capability to capture the underlying local patterns in the coarse-mesh CFD\nsimulation. Massive low-fidelity data and respective high-fidelity data are\nused to explore the underlying information relevant to the main simulation\nerrors and the effects of phenomenological scaling. By learning from previous\nsimulation data, a surrogate model using deep feedforward neural network (DFNN)\ncan be developed and trained to estimate the simulation error of coarse-mesh\nCFD. The research documented supports the feasibility of the physics-guided\ndeep learning methods for coarse mesh CFD simulations which has a potential for\nthe efficient industrial design.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 17:03:38 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Bao", "Han", ""], ["Feng", "Jinyong", ""], ["Dinh", "Nam", ""], ["Zhang", "Hongbin", ""]]}, {"id": "1910.08041", "submitter": "Ajay Jain", "authors": "Ajay Jain, Sergio Casas, Renjie Liao, Yuwen Xiong, Song Feng, Sean\n  Segal, Raquel Urtasun", "title": "Discrete Residual Flow for Probabilistic Pedestrian Behavior Prediction", "comments": "CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-driving vehicles plan around both static and dynamic objects, applying\npredictive models of behavior to estimate future locations of the objects in\nthe environment. However, future behavior is inherently uncertain, and models\nof motion that produce deterministic outputs are limited to short timescales.\nParticularly difficult is the prediction of human behavior. In this work, we\npropose the discrete residual flow network (DRF-Net), a convolutional neural\nnetwork for human motion prediction that captures the uncertainty inherent in\nlong-range motion forecasting. In particular, our learned network effectively\ncaptures multimodal posteriors over future human motion by predicting and\nupdating a discretized distribution over spatial locations. We compare our\nmodel against several strong competitors and show that our model outperforms\nall baselines.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 17:10:28 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Jain", "Ajay", ""], ["Casas", "Sergio", ""], ["Liao", "Renjie", ""], ["Xiong", "Yuwen", ""], ["Feng", "Song", ""], ["Segal", "Sean", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1910.08051", "submitter": "Yogesh Balaji", "authors": "Yogesh Balaji, Tom Goldstein, Judy Hoffman", "title": "Instance adaptive adversarial training: Improved accuracy tradeoffs in\n  neural nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is by far the most successful strategy for improving\nrobustness of neural networks to adversarial attacks. Despite its success as a\ndefense mechanism, adversarial training fails to generalize well to unperturbed\ntest set. We hypothesize that this poor generalization is a consequence of\nadversarial training with uniform perturbation radius around every training\nsample. Samples close to decision boundary can be morphed into a different\nclass under a small perturbation budget, and enforcing large margins around\nthese samples produce poor decision boundaries that generalize poorly.\nMotivated by this hypothesis, we propose instance adaptive adversarial training\n-- a technique that enforces sample-specific perturbation margins around every\ntraining sample. We show that using our approach, test accuracy on unperturbed\nsamples improve with a marginal drop in robustness. Extensive experiments on\nCIFAR-10, CIFAR-100 and Imagenet datasets demonstrate the effectiveness of our\nproposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 17:24:22 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Balaji", "Yogesh", ""], ["Goldstein", "Tom", ""], ["Hoffman", "Judy", ""]]}, {"id": "1910.08057", "submitter": "Tony Duan", "authors": "Tony Duan and Juho Lee", "title": "Graph Embedding VAE: A Permutation Invariant Model of Graph Structure", "comments": "Presented at the NeurIPS 2019 Workshop on Graph Representation\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative models of graph structure have applications in biology and social\nsciences. The state of the art is GraphRNN, which decomposes the graph\ngeneration process into a series of sequential steps. While effective for\nmodest sizes, it loses its permutation invariance for larger graphs. Instead,\nwe present a permutation invariant latent-variable generative model relying on\ngraph embeddings to encode structure. Using tools from the random graph\nliterature, our model is highly scalable to large graphs with likelihood\nevaluation and generation in $O(|V | + |E|)$.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 17:38:43 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Duan", "Tony", ""], ["Lee", "Juho", ""]]}, {"id": "1910.08074", "submitter": "Shen Wang", "authors": "Shen Wang, Zhengzhang Chen, Xiao Yu, Ding Li, Jingchao Ni, Lu-An Tang,\n  Jiaping Gui, Zhichun Li, Haifeng Chen, Philip S. Yu", "title": "Heterogeneous Graph Matching Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information systems have widely been the target of malware attacks.\nTraditional signature-based malicious program detection algorithms can only\ndetect known malware and are prone to evasion techniques such as binary\nobfuscation, while behavior-based approaches highly rely on the malware\ntraining samples and incur prohibitively high training cost. To address the\nlimitations of existing techniques, we propose MatchGNet, a heterogeneous Graph\nMatching Network model to learn the graph representation and similarity metric\nsimultaneously based on the invariant graph modeling of the program's execution\nbehaviors. We conduct a systematic evaluation of our model and show that it is\naccurate in detecting malicious program behavior and can help detect malware\nattacks with less false positives. MatchGNet outperforms the state-of-the-art\nalgorithms in malware detection by generating 50% less false positives while\nkeeping zero false negatives.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 08:40:29 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Wang", "Shen", ""], ["Chen", "Zhengzhang", ""], ["Yu", "Xiao", ""], ["Li", "Ding", ""], ["Ni", "Jingchao", ""], ["Tang", "Lu-An", ""], ["Gui", "Jiaping", ""], ["Li", "Zhichun", ""], ["Chen", "Haifeng", ""], ["Yu", "Philip S.", ""]]}, {"id": "1910.08077", "submitter": "Sebastian Wagner-Carena", "authors": "Sebastian Wagner-Carena, Max Hopkins, Ana Diaz Rivero, Cora Dvorkin", "title": "A Novel CMB Component Separation Method: Hierarchical Generalized\n  Morphological Component Analysis", "comments": "Updated to reflect accepted MNRAS version", "journal-ref": null, "doi": "10.1093/mnras/staa744", "report-no": null, "categories": "astro-ph.CO astro-ph.IM cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel technique for Cosmic Microwave Background (CMB) foreground\nsubtraction based on the framework of blind source separation. Inspired by\nprevious work incorporating local variation to Generalized Morphological\nComponent Analysis (GMCA), we introduce Hierarchical GMCA (HGMCA), a Bayesian\nhierarchical graphical model for source separation. We test our method on\n$N_{\\rm side}=256$ simulated sky maps that include dust, synchrotron, free-free\nand anomalous microwave emission, and show that HGMCA reduces foreground\ncontamination by $25\\%$ over GMCA in both the regions included and excluded by\nthe Planck UT78 mask, decreases the error in the measurement of the CMB\ntemperature power spectrum to the $0.02-0.03\\%$ level at $\\ell>200$ (and\n$<0.26\\%$ for all $\\ell$), and reduces correlation to all the foregrounds. We\nfind equivalent or improved performance when compared to state-of-the-art\nInternal Linear Combination (ILC)-type algorithms on these simulations,\nsuggesting that HGMCA may be a competitive alternative to foreground separation\ntechniques previously applied to observed CMB data. Additionally, we show that\nour performance does not suffer when we perturb model parameters or alter the\nCMB realization, which suggests that our algorithm generalizes well beyond our\nsimplified simulations. Our results open a new avenue for constructing CMB maps\nthrough Bayesian hierarchical analysis.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:00:00 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 21:30:55 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wagner-Carena", "Sebastian", ""], ["Hopkins", "Max", ""], ["Rivero", "Ana Diaz", ""], ["Dvorkin", "Cora", ""]]}, {"id": "1910.08091", "submitter": "Yura Perov N", "authors": "Yura Perov, Logan Graham, Kostis Gourgoulias, Jonathan G. Richens,\n  Ciar\\'an M. Lee, Adam Baker, Saurabh Johri", "title": "MultiVerse: Causal Reasoning using Importance Sampling in Probabilistic\n  Programming", "comments": "Logan and Yura have made equal contributions to the paper. Accepted\n  to the 2nd Symposium on Advances in Approximate Bayesian Inference\n  (Vancouver, Canada, 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PL stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elaborate on using importance sampling for causal reasoning, in particular\nfor counterfactual inference. We show how this can be implemented natively in\nprobabilistic programming. By considering the structure of the counterfactual\nquery, one can significantly optimise the inference process. We also consider\ndesign choices to enable further optimisations. We introduce MultiVerse, a\nprobabilistic programming prototype engine for approximate causal reasoning. We\nprovide experimental results and compare with Pyro, an existing probabilistic\nprogramming framework with some of causal reasoning tools.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:00:24 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 10:05:13 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Perov", "Yura", ""], ["Graham", "Logan", ""], ["Gourgoulias", "Kostis", ""], ["Richens", "Jonathan G.", ""], ["Lee", "Ciar\u00e1n M.", ""], ["Baker", "Adam", ""], ["Johri", "Saurabh", ""]]}, {"id": "1910.08102", "submitter": "Jiacheng Zhu", "authors": "Jiacheng Zhu, Shenghao Qin, Wenshuo Wang, and Ding Zhao", "title": "Probabilistic Trajectory Prediction for Autonomous Vehicles with\n  Attentive Recurrent Neural Process", "comments": "7 pages, 5 figures, submitted to ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting surrounding vehicle behaviors are critical to autonomous vehicles\nwhen negotiating in multi-vehicle interaction scenarios. Most existing\napproaches require tedious training process with large amounts of data and may\nfail to capture the propagating uncertainty in interaction behaviors. The\nmulti-vehicle behaviors are assumed to be generated from a stochastic process.\nThis paper proposes an attentive recurrent neural process (ARNP) approach to\novercome the above limitations, which uses a neural process (NP) to learn a\ndistribution of multi-vehicle interaction behavior. Our proposed model inherits\nthe flexibility of neural networks while maintaining Bayesian probabilistic\ncharacteristics. Constructed by incorporating NPs with recurrent neural\nnetworks (RNNs), the ARNP model predicts the distribution of a target vehicle\ntrajectory conditioned on the observed long-term sequential data of all\nsurrounding vehicles. This approach is verified by learning and predicting\nlane-changing trajectories in complex traffic scenarios. Experimental results\ndemonstrate that our proposed method outperforms previous counterparts in terms\nof accuracy and uncertainty expressiveness. Moreover, the meta-learning\ninstinct of NPs enables our proposed ARNP model to capture global information\nof all observations, thereby being able to adapt to new targets efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:26:31 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Zhu", "Jiacheng", ""], ["Qin", "Shenghao", ""], ["Wang", "Wenshuo", ""], ["Zhao", "Ding", ""]]}, {"id": "1910.08103", "submitter": "Alex Georges", "authors": "Jacek Cyranka, Alexander Georges, David Meyer", "title": "Mapper Based Classifier", "comments": "12 pages, accepted to IEEE ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological data analysis aims to extract topological quantities from data,\nwhich tend to focus on the broader global structure of the data rather than\nlocal information. The Mapper method, specifically, generalizes clustering\nmethods to identify significant global mathematical structures, which are out\nof reach of many other approaches. We propose a classifier based on applying\nthe Mapper algorithm to data projected onto a latent space. We obtain the\nlatent space by using PCA or autoencoders. Notably, a classifier based on the\nMapper method is immune to any gradient based attack, and improves robustness\nover traditional CNNs (convolutional neural networks). We report theoretical\njustification and some numerical experiments that confirm our claims.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:28:01 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 15:32:25 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Cyranka", "Jacek", ""], ["Georges", "Alexander", ""], ["Meyer", "David", ""]]}, {"id": "1910.08105", "submitter": "Matteo Fontana", "authors": "Ilia Nouretdinov, James Gammerman, Matteo Fontana, Daljit Rehal", "title": "Multi-level conformal clustering: A distribution-free technique for\n  clustering and anomaly detection", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2019.07.114", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a clustering technique called \\textit{multi-level\nconformal clustering (MLCC)}. The technique is hierarchical in nature because\nit can be performed at multiple significance levels which yields greater\ninsight into the data than performing it at just one level. We describe the\ntheoretical underpinnings of MLCC, compare and contrast it with the\nhierarchical clustering algorithm, and then apply it to real world datasets to\nassess its performance. There are several advantages to using MLCC over more\nclassical clustering techniques: Once a significance level has been set, MLCC\nis able to automatically select the number of clusters. Furthermore, thanks to\nthe conformal prediction framework the resulting clustering model has a clear\nstatistical meaning without any assumptions about the distribution of the data.\nThis statistical robustness also allows us to perform clustering and anomaly\ndetection simultaneously. Moreover, due to the flexibility of the conformal\nprediction framework, our algorithm can be used on top of many other machine\nlearning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:28:56 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 20:03:28 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Nouretdinov", "Ilia", ""], ["Gammerman", "James", ""], ["Fontana", "Matteo", ""], ["Rehal", "Daljit", ""]]}, {"id": "1910.08108", "submitter": "Anindya Sarkar", "authors": "Anindya Sarkar, Nikhil Kumar Gupta and Raghu Iyengar", "title": "Enforcing Linearity in DNN succours Robustness and Adversarial Image\n  Generation", "comments": "Adversarial Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on the adversarial vulnerability of neural networks have shown\nthat models trained with the objective of minimizing an upper bound on the\nworst-case loss over all possible adversarial perturbations improve robustness\nagainst adversarial attacks. Beside exploiting adversarial training framework,\nwe show that by enforcing a Deep Neural Network (DNN) to be linear in\ntransformed input and feature space improves robustness significantly. We also\ndemonstrate that by augmenting the objective function with Local Lipschitz\nregularizer boost robustness of the model further. Our method outperforms most\nsophisticated adversarial training methods and achieves state of the art\nadversarial accuracy on MNIST, CIFAR10 and SVHN dataset. In this paper, we also\npropose a novel adversarial image generation method by leveraging Inverse\nRepresentation Learning and Linearity aspect of an adversarially trained deep\nneural network classifier.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:38:40 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 17:00:50 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Sarkar", "Anindya", ""], ["Gupta", "Nikhil Kumar", ""], ["Iyengar", "Raghu", ""]]}, {"id": "1910.08109", "submitter": "Hsiang Hsu", "authors": "Hsiang Hsu and Shahab Asoodeh and Flavio du Pin Calmon", "title": "Obfuscation via Information Density Estimation", "comments": "24 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying features that leak information about sensitive attributes is a\nkey challenge in the design of information obfuscation mechanisms. In this\npaper, we propose a framework to identify information-leaking features via\ninformation density estimation. Here, features whose information densities\nexceed a pre-defined threshold are deemed information-leaking features. Once\nthese features are identified, we sequentially pass them through a targeted\nobfuscation mechanism with a provable leakage guarantee in terms of\n$\\mathsf{E}_\\gamma$-divergence. The core of this mechanism relies on a\ndata-driven estimate of the trimmed information density for which we propose a\nnovel estimator, named the trimmed information density estimator (TIDE). We\nthen use TIDE to implement our mechanism on three real-world datasets. Our\napproach can be used as a data-driven pipeline for designing obfuscation\nmechanisms targeting specific features.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:42:57 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Hsu", "Hsiang", ""], ["Asoodeh", "Shahab", ""], ["Calmon", "Flavio du Pin", ""]]}, {"id": "1910.08112", "submitter": "Kevin Nguyen", "authors": "Kevin P. Nguyen, Cherise Chin Fatt, Alex Treacher, Cooper Mellema,\n  Madhukar H. Trivedi, Albert Montillo", "title": "Anatomically-Informed Data Augmentation for functional MRI with\n  Applications to Deep Learning", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.NC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning to build accurate predictive models from\nfunctional neuroimaging data is often hindered by limited dataset sizes. Though\ndata augmentation can help mitigate such training obstacles, most data\naugmentation methods have been developed for natural images as in computer\nvision tasks such as CIFAR, not for medical images. This work helps to fills in\nthis gap by proposing a method for generating new functional Magnetic Resonance\nImages (fMRI) with realistic brain morphology. This method is tested on a\nchallenging task of predicting antidepressant treatment response from\npre-treatment task-based fMRI and demonstrates a 26% improvement in performance\nin predicting response using augmented images. This improvement compares\nfavorably to state-of-the-art augmentation methods for natural images. Through\nan ablative test, augmentation is also shown to substantively improve\nperformance when applied before hyperparameter optimization. These results\nsuggest the optimal order of operations and support the role of data\naugmentation method for improving predictive performance in tasks using fMRI.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:55:10 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Nguyen", "Kevin P.", ""], ["Fatt", "Cherise Chin", ""], ["Treacher", "Alex", ""], ["Mellema", "Cooper", ""], ["Trivedi", "Madhukar H.", ""], ["Montillo", "Albert", ""]]}, {"id": "1910.08123", "submitter": "Emiliano Dall'Anese", "authors": "Emiliano Dall'Anese, Andrea Simonetto, Stephen Becker, Liam Madden", "title": "Optimization and Learning with Information Streams: Time-varying\n  Algorithms and Applications", "comments": "Accepted for publication in IEEE Signal Processing Magazine. Limit of\n  40 references", "journal-ref": null, "doi": "10.1109/MSP.2020.2968813", "report-no": null, "categories": "math.OC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing cross-disciplinary effort in the broad domain of\noptimization and learning with streams of data, applied to settings where\ntraditional batch optimization techniques cannot produce solutions at time\nscales that match the inter-arrival times of the data points due to\ncomputational and/or communication bottlenecks. Special types of online\nalgorithms can handle this situation, and this article focuses on such\ntime-varying optimization algorithms, with emphasis on Machine Leaning and\nSignal Processing, as well as data-driven Control. Approaches for the design of\ntime-varying or online first-order optimization methods are discussed, with\nemphasis on algorithms that can handle errors in the gradient, as may arise\nwhen the gradient is estimated. Insights on performance metrics and\naccompanying claims are provided, along with evidence of cases where algorithms\nthat are provably convergent in batch optimization may perform poorly in an\nonline regime. The role of distributed computation is discussed. Illustrative\nnumerical examples for a number of applications of broad interest are provided\nto convey key ideas.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 19:29:47 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 17:21:35 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Dall'Anese", "Emiliano", ""], ["Simonetto", "Andrea", ""], ["Becker", "Stephen", ""], ["Madden", "Liam", ""]]}, {"id": "1910.08143", "submitter": "Huazhe Xu", "authors": "Huazhe Xu, Boyuan Chen, Yang Gao, Trevor Darrell", "title": "Zero-shot Policy Learning with Spatial Temporal RewardDecomposition on\n  Contingency-aware Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a long-standing challenge to enable an intelligent agent to learn in\none environment and generalize to an unseen environment without further data\ncollection and finetuning. In this paper, we consider a zero shot\ngeneralization problem setup that complies with biological intelligent agents'\nlearning and generalization processes. The agent is first presented with\nprevious experiences in the training environment, along with task description\nin the form of trajectory-level sparse rewards. Later when it is placed in the\nnew testing environment, it is asked to perform the task without any\ninteraction with the testing environment. We find this setting natural for\nbiological creatures and at the same time, challenging for previous methods.\nBehavior cloning, state-of-art RL along with other zero-shot learning methods\nperform poorly on this benchmark. Given a set of experiences in the training\nenvironment, our method learns a neural function that decomposes the sparse\nreward into particular regions in a contingency-aware observation as a per step\nreward. Based on such decomposed rewards, we further learn a dynamics model and\nuse Model Predictive Control (MPC) to obtain a policy. Since the rewards are\ndecomposed to finer-granularity observations, they are naturally generalizable\nto new environments that are composed of similar basic elements. We demonstrate\nour method on a wide range of environments, including a classic video game --\nSuper Mario Bros, as well as a robotic continuous control task. Please refer to\nthe project page for more visualized results.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 20:15:36 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 05:06:09 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Xu", "Huazhe", ""], ["Chen", "Boyuan", ""], ["Gao", "Yang", ""], ["Darrell", "Trevor", ""]]}, {"id": "1910.08145", "submitter": "Pouria Golshanrad", "authors": "Pouria Golshanrad, Hamid Mahini, Behnam Bahrak", "title": "Predicting passenger origin-destination in online taxi-hailing systems", "comments": "25 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of transportation planning, traffic management, and dispatch\noptimization importance, passenger origin-destination prediction has become one\nof the most important requirements for intelligent transportation systems\nmanagement. In this paper, we propose a model to predict the next specified\ntime window travels' origin and destination. To extract meaningful travel\nflows, we use K-means clustering in four-dimensional space with maximum cluster\nsize limitation for origin and destination zones. Because of the large number\nof clusters, we use non-negative matrix factorization to decrease the number of\ntravel clusters. Also, we use a stacked recurrent neural network model to\npredict travel count in each cluster. Comparing our results with other existing\nmodels shows that our proposed model has 5-7% lower mean absolute percentage\nerror (MAPE) for 1-hour time windows, and 14% lower MAPE for 30-minute time\nwindows.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 20:19:23 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 12:36:24 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 10:43:15 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Golshanrad", "Pouria", ""], ["Mahini", "Hamid", ""], ["Bahrak", "Behnam", ""]]}, {"id": "1910.08149", "submitter": "Sagar Verma", "authors": "Sagar Verma and Shikha Singh and Angshul Majumdar", "title": "Multi Label Restricted Boltzmann Machine for Non-Intrusive Load\n  Monitoring", "comments": "5 pages, ICASSP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Increasing population indicates that energy demands need to be managed in the\nresidential sector. Prior studies have reflected that the customers tend to\nreduce a significant amount of energy consumption if they are provided with\nappliance-level feedback. This observation has increased the relevance of load\nmonitoring in today's tech-savvy world. Most of the previously proposed\nsolutions claim to perform load monitoring without intrusion, but they are not\ncompletely non-intrusive. These methods require historical appliance-level data\nfor training the model for each of the devices. This data is gathered by\nputting a sensor on each of the appliances present in the home which causes\nintrusion in the building. Some recent studies have proposed that if we frame\nNon-Intrusive Load Monitoring (NILM) as a multi-label classification problem,\nthe need for appliance-level data can be avoided. In this paper, we propose\nMulti-label Restricted Boltzmann Machine(ML-RBM) for NILM and report an\nexperimental evaluation of proposed and state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 20:31:15 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Verma", "Sagar", ""], ["Singh", "Shikha", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1910.08151", "submitter": "Sean Sinclair", "authors": "Sean R. Sinclair, Siddhartha Banerjee, Christina Lee Yu", "title": "Adaptive Discretization for Episodic Reinforcement Learning in Metric\n  Spaces", "comments": "46 pages, 15 figures", "journal-ref": null, "doi": "10.1145/3366703", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient algorithm for model-free episodic reinforcement\nlearning on large (potentially continuous) state-action spaces. Our algorithm\nis based on a novel $Q$-learning policy with adaptive data-driven\ndiscretization. The central idea is to maintain a finer partition of the\nstate-action space in regions which are frequently visited in historical\ntrajectories, and have higher payoff estimates. We demonstrate how our adaptive\npartitions take advantage of the shape of the optimal $Q$-function and the\njoint space, without sacrificing the worst-case performance. In particular, we\nrecover the regret guarantees of prior algorithms for continuous state-action\nspaces, which additionally require either an optimal discretization as input,\nand/or access to a simulation oracle. Moreover, experiments demonstrate how our\nalgorithm automatically adapts to the underlying structure of the problem,\nresulting in much better performance compared both to heuristics and\n$Q$-learning with uniform discretization.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 20:40:37 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 12:59:41 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Sinclair", "Sean R.", ""], ["Banerjee", "Siddhartha", ""], ["Yu", "Christina Lee", ""]]}, {"id": "1910.08157", "submitter": "Thomas Booth", "authors": "Thomas Booth", "title": "An Update on Machine Learning in Neuro-oncology Diagnostics", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.07440", "journal-ref": null, "doi": "10.1007/978-3-030-11723-8_4", "report-no": null, "categories": "q-bio.QM cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging biomarkers in neuro-oncology are used for diagnosis, prognosis and\ntreatment response monitoring. Magnetic resonance imaging is typically used\nthroughout the patient pathway because routine structural imaging provides\ndetailed anatomical and pathological information and advanced techniques\nprovide additional physiological detail. Following image feature extraction,\nmachine learning allows accurate classification in a variety of scenarios.\nMachine learning also enables image feature extraction de novo although the low\nprevalence of brain tumours makes such approaches challenging. Much research is\napplied to determining molecular profiles, histological tumour grade and\nprognosis at the time that patients first present with a brain tumour.\nFollowing treatment, differentiating a treatment response from a post-treatment\nrelated effect is clinically important and also an area of study. Most of the\nevidence is low level having been obtained retrospectively and in single\ncentres.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 08:57:51 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Booth", "Thomas", ""]]}, {"id": "1910.08168", "submitter": "Matias Valdenegro-Toro", "authors": "Matias Valdenegro-Toro", "title": "Deep Sub-Ensembles for Fast Uncertainty Estimation in Image\n  Classification", "comments": "7 pages, 8 figures, Bayesian Deep Learning Workshop 2019 @ NeurIPS\n  2019, camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast estimates of model uncertainty are required for many robust robotics\napplications. Deep Ensembles provides state of the art uncertainty without\nrequiring Bayesian methods, but still it is computationally expensive. In this\npaper we propose deep sub-ensembles, an approximation to deep ensembles where\nthe core idea is to ensemble only the layers close to the output, and not the\nwhole model. With ResNet-20 on the CIFAR10 dataset, we obtain 1.5-2.5 speedup\nover a Deep Ensemble, with a small increase in error and NLL, and similarly up\nto 5-15 speedup with a VGG-like network on the SVHN dataset. Our results show\nthat this idea enables a trade-off between error and uncertainty quality versus\ncomputational performance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 21:07:40 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 12:23:45 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Valdenegro-Toro", "Matias", ""]]}, {"id": "1910.08181", "submitter": "Yi Ouyang", "authors": "Huidong Gao, Yi Ouyang, Masayoshi Tomizuka", "title": "Online Learning in Planar Pushing with Combined Prediction Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pushing is a useful robotic capability for positioning and reorienting\nobjects. The ability to accurately predict the effect of pushes can enable\nefficient trajectory planning and complicated object manipulation. Physical\nprediction models for planar pushing have long been established, but their\nassumptions and requirements usually don't hold in most practical settings.\nData-driven approaches can provide accurate predictions for offline data, but\nthey often have generalizability issues. In this paper, we propose a combined\nprediction model and an online learning framework for planar push prediction.\nThe combined model consists of a neural network module and analytical\ncomponents with a low-dimensional parameter. We train the neural network\noffline using pre-collected pushing data. In online situations, the\nlow-dimensional analytical parameter is learned directly from online pushes to\nquickly adapt to the new environments. We test our combined model and learning\nframework on real pushing experiments. Our experimental results show that our\nmodel is able to quickly adapt to new environments while achieving similar\nfinal prediction performance as that of pure neural network models.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 21:43:56 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Gao", "Huidong", ""], ["Ouyang", "Yi", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1910.08207", "submitter": "Kaveh Hassani", "authors": "Kaveh Hassani and Mike Haley", "title": "Unsupervised Multi-Task Feature Learning on Point Clouds", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an unsupervised multi-task model to jointly learn point and\nshape features on point clouds. We define three unsupervised tasks including\nclustering, reconstruction, and self-supervised classification to train a\nmulti-scale graph-based encoder. We evaluate our model on shape classification\nand segmentation benchmarks. The results suggest that it outperforms prior\nstate-of-the-art unsupervised models: In the ModelNet40 classification task, it\nachieves an accuracy of 89.1% and in ShapeNet segmentation task, it achieves an\nmIoU of 68.2 and accuracy of 88.6%.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 00:43:29 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Hassani", "Kaveh", ""], ["Haley", "Mike", ""]]}, {"id": "1910.08210", "submitter": "Victor Zhong", "authors": "Victor Zhong, Tim Rockt\\\"aschel, Edward Grefenstette", "title": "RTFM: Generalising to Novel Environment Dynamics via Reading", "comments": "ICLR 2020; 17 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining policies that can generalise to new environments in reinforcement\nlearning is challenging. In this work, we demonstrate that language\nunderstanding via a reading policy learner is a promising vehicle for\ngeneralisation to new environments. We propose a grounded policy learning\nproblem, Read to Fight Monsters (RTFM), in which the agent must jointly reason\nover a language goal, relevant dynamics described in a document, and\nenvironment observations. We procedurally generate environment dynamics and\ncorresponding language descriptions of the dynamics, such that agents must read\nto understand new environment dynamics instead of memorising any particular\ninformation. In addition, we propose txt2$\\pi$, a model that captures three-way\ninteractions between the goal, document, and observations. On RTFM, txt2$\\pi$\ngeneralises to new environments with dynamics not seen during training via\nreading. Furthermore, our model outperforms baselines such as FiLM and\nlanguage-conditioned CNNs on RTFM. Through curriculum learning, txt2$\\pi$\nproduces policies that excel on complex RTFM tasks requiring several reasoning\nand coreference steps.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 00:49:15 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 21:26:05 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 21:49:27 GMT"}, {"version": "v4", "created": "Tue, 28 Jan 2020 18:37:02 GMT"}, {"version": "v5", "created": "Wed, 12 Feb 2020 20:22:15 GMT"}, {"version": "v6", "created": "Mon, 1 Feb 2021 20:46:03 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Zhong", "Victor", ""], ["Rockt\u00e4schel", "Tim", ""], ["Grefenstette", "Edward", ""]]}, {"id": "1910.08211", "submitter": "Tomasz Arodz", "authors": "Xi Gao, Han Zhang, Aliakbar Panahi, Tom Arodz", "title": "Differentiable Combinatorial Losses through Generalized Gradients of\n  Linear Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When samples have internal structure, we often see a mismatch between the\nobjective optimized during training and the model's goal during inference. For\nexample, in sequence-to-sequence modeling we are interested in high-quality\ntranslated sentences, but training typically uses maximum likelihood at the\nword level. The natural training-time loss would involve a combinatorial\nproblem -- dynamic programming-based global sequence alignment -- but solutions\nto combinatorial problems are not differentiable with respect to their input\nparameters, so surrogate, differentiable losses are used instead. Here, we show\nhow to perform gradient descent over combinatorial optimization algorithms that\ninvolve continuous parameters, for example edge weights, and can be efficiently\nexpressed as linear programs. We demonstrate usefulness of gradient descent\nover combinatorial optimization in sequence-to-sequence modeling using\ndifferentiable encoder-decoder architecture with softmax or Gumbel-softmax, and\nin image classification in a weakly supervised setting where instead of the\ncorrect class for each photo, only groups of photos labeled with correct but\nunordered set of classes are available during training.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 00:53:55 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 14:39:27 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 17:31:22 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2020 16:44:27 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Gao", "Xi", ""], ["Zhang", "Han", ""], ["Panahi", "Aliakbar", ""], ["Arodz", "Tom", ""]]}, {"id": "1910.08212", "submitter": "Yiding Chen", "authors": "Zhiyan Ding, Yiding Chen, Qin Li, Xiaojin Zhu", "title": "Error Lower Bounds of Constant Step-size Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) plays a central role in modern machine\nlearning. While there is extensive work on providing error upper bound for SGD,\nnot much is known about SGD error lower bound. In this paper, we study the\nconvergence of constant step-size SGD. We provide error lower bound of SGD for\npotentially non-convex objective functions with Lipschitz gradients. To our\nknowledge, this is the first analysis for SGD error lower bound without the\nstrong convexity assumption. We use experiments to illustrate our theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 01:06:37 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Ding", "Zhiyan", ""], ["Chen", "Yiding", ""], ["Li", "Qin", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1910.08215", "submitter": "Alireza Rezvanifar", "authors": "Alireza Rezvanifar, Tunai Porto Marques, Melissa Cote, Alexandra\n  Branzan Albu, Alex Slonimer, Thomas Tolhurst, Kaan Ersahin, Todd Mudge,\n  Stephane Gauthier", "title": "A Deep Learning-based Framework for the Detection of Schools of Herring\n  in Echograms", "comments": "Accepted to NeurIPS 2019 workshop on Tackling Climate Change with\n  Machine Learning, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Tracking the abundance of underwater species is crucial for understanding the\neffects of climate change on marine ecosystems. Biologists typically monitor\nunderwater sites with echosounders and visualize data as 2D images (echograms);\nthey interpret these data manually or semi-automatically, which is\ntime-consuming and prone to inconsistencies. This paper proposes a deep\nlearning framework for the automatic detection of schools of herring from\nechograms. Experiments demonstrated that our approach outperforms a traditional\nmachine learning algorithm using hand-crafted features. Our framework could\neasily be expanded to detect more species of interest to sustainable fisheries.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 01:12:46 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Rezvanifar", "Alireza", ""], ["Marques", "Tunai Porto", ""], ["Cote", "Melissa", ""], ["Albu", "Alexandra Branzan", ""], ["Slonimer", "Alex", ""], ["Tolhurst", "Thomas", ""], ["Ersahin", "Kaan", ""], ["Mudge", "Todd", ""], ["Gauthier", "Stephane", ""]]}, {"id": "1910.08216", "submitter": "Emma Frejinger", "authors": "Emma Frejinger, Eric Larsen", "title": "A language processing algorithm for predicting tactical solutions to an\n  operational planning problem under uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the prediction of solutions to a stochastic discrete\noptimization problem. Through an application, we illustrate how we can use a\nstate-of-the-art neural machine translation (NMT) algorithm to predict the\nsolutions by defining appropriate vocabularies, syntaxes and constraints. We\nattend to applications where the predictions need to be computed in very short\ncomputing time -- in the order of milliseconds or less. The results show that\nwith minimal adaptations to the model architecture and hyperparameter tuning,\nthe NMT algorithm can produce accurate solutions within the computing time\nbudget. While these predictions are slightly less accurate than approximate\nstochastic programming solutions (sample average approximation), they can be\ncomputed faster and with less variability.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 01:16:30 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Frejinger", "Emma", ""], ["Larsen", "Eric", ""]]}, {"id": "1910.08219", "submitter": "Zhiwei Liu", "authors": "Zhiwei Liu, Lei Zheng, Jiawei Zhang, Jiayu Han, Philip S. Yu", "title": "JSCN: Joint Spectral Convolutional Network for Cross Domain\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain recommendation can alleviate the data sparsity problem in\nrecommender systems. To transfer the knowledge from one domain to another, one\ncan either utilize the neighborhood information or learn a direct mapping\nfunction. However, all existing methods ignore the high-order connectivity\ninformation in cross-domain recommendation area and suffer from the\ndomain-incompatibility problem. In this paper, we propose a \\textbf{J}oint\n\\textbf{S}pectral \\textbf{C}onvolutional \\textbf{N}etwork (JSCN) for\ncross-domain recommendation. JSCN will simultaneously operate multi-layer\nspectral convolutions on different graphs, and jointly learn a domain-invariant\nuser representation with a domain adaptive user mapping module. As a result,\nthe high-order comprehensive connectivity information can be extracted by the\nspectral convolutions and the information can be transferred across domains\nwith the domain-invariant user mapping. The domain adaptive user mapping module\ncan help the incompatible domains to transfer the knowledge across each other.\nExtensive experiments on $24$ Amazon rating datasets show the effectiveness of\nJSCN in the cross-domain recommendation, with $9.2\\%$ improvement on recall and\n$36.4\\%$ improvement on MAP compared with state-of-the-art methods. Our code is\navailable online ~\\footnote{https://github.com/JimLiu96/JSCN}.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 01:32:23 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Liu", "Zhiwei", ""], ["Zheng", "Lei", ""], ["Zhang", "Jiawei", ""], ["Han", "Jiayu", ""], ["Yu", "Philip S.", ""]]}, {"id": "1910.08222", "submitter": "Scott Sievert", "authors": "Scott Sievert", "title": "Improving the convergence of SGD through adaptive batch sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mini-batch stochastic gradient descent (SGD) and variants thereof approximate\nthe objective function's gradient with a small number of training examples, aka\nthe batch size. Small batch sizes require little computation for each model\nupdate but can yield high-variance gradient estimates, which poses some\nchallenges for optimization. Conversely, large batches require more computation\nbut can yield higher precision gradient estimates. This work presents a method\nto adapt the batch size to the model's training loss. For various function\nclasses, we show that our method requires the same order of model updates as\ngradient descent while requiring the same order of gradient computations as\nSGD. This method requires evaluating the model's loss on the entire dataset\nevery model update. However, the required computation is greatly reduced with a\npassive approximation of the adaptive method. We provide extensive experiments\nillustrating that our methods require fewer model updates without increasing\nthe total amount of computation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 01:45:03 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 18:09:16 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 22:13:52 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Sievert", "Scott", ""]]}, {"id": "1910.08233", "submitter": "Sergio Casas", "authors": "Sergio Casas, Cole Gulino, Renjie Liao, Raquel Urtasun", "title": "Spatially-Aware Graph Neural Networks for Relational Behavior\n  Forecasting from Sensor Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of relational behavior forecasting from\nsensor data. Towards this goal, we propose a novel spatially-aware graph neural\nnetwork (SpAGNN) that models the interactions between agents in the scene.\nSpecifically, we exploit a convolutional neural network to detect the actors\nand compute their initial states. A graph neural network then iteratively\nupdates the actor states via a message passing process. Inspired by Gaussian\nbelief propagation, we design the messages to be spatially-transformed\nparameters of the output distributions from neighboring agents. Our model is\nfully differentiable, thus enabling end-to-end training. Importantly, our\nprobabilistic predictions can model uncertainty at the trajectory level. We\ndemonstrate the effectiveness of our approach by achieving significant\nimprovements over the state-of-the-art on two real-world self-driving datasets:\nATG4D and nuScenes.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 03:14:10 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Casas", "Sergio", ""], ["Gulino", "Cole", ""], ["Liao", "Renjie", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1910.08234", "submitter": "Xin Yao", "authors": "Xin Yao, Tianchi Huang, Rui-Xiao Zhang, Ruiyu Li, Lifeng Sun", "title": "Federated Learning with Unbiased Gradient Aggregation and Controllable\n  Meta Updating", "comments": "This manuscript has been accepted to the Workshop on Federated\n  Learning for Data Privacy and Confidentiality (FL - NeurIPS 2019, in\n  Conjunction with NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) aims to train machine learning models in the\ndecentralized system consisting of an enormous amount of smart edge devices.\nFederated averaging (FedAvg), the fundamental algorithm in FL settings,\nproposes on-device training and model aggregation to avoid the potential heavy\ncommunication costs and privacy concerns brought by transmitting raw data.\nHowever, through theoretical analysis we argue that 1) the multiple steps of\nlocal updating will result in gradient biases and 2) there is an inconsistency\nbetween the expected target distribution and the optimization objectives\nfollowing the training paradigm in FedAvg. To tackle these problems, we first\npropose an unbiased gradient aggregation algorithm with the keep-trace gradient\ndescent and the gradient evaluation strategy. Then we introduce an additional\ncontrollable meta updating procedure with a small set of data samples,\nindicating the expected target distribution, to provide a clear and consistent\noptimization objective. Both the two improvements are model- and task-agnostic\nand can be applied individually or together. Experimental results demonstrate\nthat the proposed methods are faster in convergence and achieve higher accuracy\nwith different network architectures in various FL settings.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 03:17:22 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 09:17:12 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 06:26:36 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Yao", "Xin", ""], ["Huang", "Tianchi", ""], ["Zhang", "Rui-Xiao", ""], ["Li", "Ruiyu", ""], ["Sun", "Lifeng", ""]]}, {"id": "1910.08237", "submitter": "Kartik Gupta", "authors": "Thalaiyasingam Ajanthan, Kartik Gupta, Philip H. S. Torr, Richard\n  Hartley, Puneet K. Dokania", "title": "Mirror Descent View for Neural Network Quantization", "comments": "This paper was accepted at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantizing large Neural Networks (NN) while maintaining the performance is\nhighly desirable for resource-limited devices due to reduced memory and time\ncomplexity. It is usually formulated as a constrained optimization problem and\noptimized via a modified version of gradient descent. In this work, by\ninterpreting the continuous parameters (unconstrained) as the dual of the\nquantized ones, we introduce a Mirror Descent (MD) framework for NN\nquantization. Specifically, we provide conditions on the projections (i.e.,\nmapping from continuous to quantized ones) which would enable us to derive\nvalid mirror maps and in turn the respective MD updates. Furthermore, we\npresent a numerically stable implementation of MD that requires storing an\nadditional set of auxiliary variables (unconstrained), and show that it is\nstrikingly analogous to the Straight Through Estimator (STE) based method which\nis typically viewed as a \"trick\" to avoid vanishing gradients issue. Our\nexperiments on CIFAR-10/100, TinyImageNet, and ImageNet classification datasets\nwith VGG-16, ResNet-18, and MobileNetV2 architectures show that our MD variants\nobtain quantized networks with state-of-the-art performance. Code is available\nat https://github.com/kartikgupta-at-anu/md-bnn.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 03:19:21 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 07:20:30 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 05:13:00 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Ajanthan", "Thalaiyasingam", ""], ["Gupta", "Kartik", ""], ["Torr", "Philip H. S.", ""], ["Hartley", "Richard", ""], ["Dokania", "Puneet K.", ""]]}, {"id": "1910.08245", "submitter": "Christopher Bresten", "authors": "Christopher Bresten, Jae-Hun Jung", "title": "Detection of gravitational waves using topological data analysis and\n  convolutional neural network: An improved approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.HE cs.LG gr-qc physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gravitational wave detection problem is challenging because the noise is\ntypically overwhelming. Convolutional neural networks (CNNs) have been\nsuccessfully applied, but require a large training set and the accuracy suffers\nsignificantly in the case of low SNR. We propose an improved method that\nemploys a feature extraction step using persistent homology. The resulting\nmethod is more resilient to noise, more capable of detecting signals with\nvaried signatures and requires less training. This is a powerful improvement as\nthe detection problem can be computationally intense and is concerned with a\nrelatively large class of wave signatures.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 03:46:01 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Bresten", "Christopher", ""], ["Jung", "Jae-Hun", ""]]}, {"id": "1910.08249", "submitter": "Kaveh Hassani", "authors": "Salvatore Vivona and Kaveh Hassani", "title": "Relational Graph Representation Learning for Open-Domain Question\n  Answering", "comments": "NeurIPS 2019 Workshop on Graph Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a relational graph neural network with bi-directional attention\nmechanism and hierarchical representation learning for open-domain question\nanswering task. Our model can learn contextual representation by jointly\nlearning and updating the query, knowledge graph, and document representations.\nThe experiments suggest that our model achieves state-of-the-art on the\nWebQuestionsSP benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 03:54:58 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Vivona", "Salvatore", ""], ["Hassani", "Kaveh", ""]]}, {"id": "1910.08263", "submitter": "Keifer Lee", "authors": "Keifer Lee, Jun Jet Tai, Swee King Phang", "title": "BOBBY2: Buffer Based Robust High-Speed Object Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a novel high-speed single object tracker that is robust against\nnon-semantic distractor exemplars is introduced; dubbed BOBBY2. It incorporates\na novel exemplar buffer module that sparsely caches the target's appearance\nacross time, enabling it to adapt to potential target deformation. As for\ntraining, an augmented ImageNet-VID dataset was used in conjunction with the\none cycle policy, enabling it to reach convergence with less than 2 epoch worth\nof data. For validation, the model was benchmarked on the GOT-10k dataset and\non an additional small, albeit challenging custom UAV dataset collected with\nthe TU-3 UAV. We demonstrate that the exemplar buffer is capable of providing\nredundancies in case of unintended target drifts, a desirable trait in any\nmiddle to long term tracking. Even when the buffer is predominantly filled with\ndistractors instead of valid exemplars, BOBBY2 is capable of maintaining a\nnear-optimal level of accuracy. BOBBY2 manages to achieve a very competitive\nresult on the GOT-10k dataset and to a lesser degree on the challenging custom\nTU-3 dataset, without fine-tuning, demonstrating its generalizability. In terms\nof speed, BOBBY2 utilizes a stripped down AlexNet as feature extractor with 63%\nless parameters than a vanilla AlexNet, thus being able to run at a competitive\n85 FPS.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 05:10:33 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Lee", "Keifer", ""], ["Tai", "Jun Jet", ""], ["Phang", "Swee King", ""]]}, {"id": "1910.08264", "submitter": "Yunzhu Li", "authors": "Yunzhu Li, Hao He, Jiajun Wu, Dina Katabi, Antonio Torralba", "title": "Learning Compositional Koopman Operators for Model-Based Control", "comments": "The first two authors contributed equally to this paper. Project\n  Page: http://koopman.csail.mit.edu/ Video: https://youtu.be/MnXo_hjh1Q4 Code:\n  https://github.com/YunzhuLi/CompositionalKoopmanOperators", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding an embedding space for a linear approximation of a nonlinear\ndynamical system enables efficient system identification and control synthesis.\nThe Koopman operator theory lays the foundation for identifying the\nnonlinear-to-linear coordinate transformations with data-driven methods.\nRecently, researchers have proposed to use deep neural networks as a more\nexpressive class of basis functions for calculating the Koopman operators.\nThese approaches, however, assume a fixed dimensional state space; they are\ntherefore not applicable to scenarios with a variable number of objects. In\nthis paper, we propose to learn compositional Koopman operators, using graph\nneural networks to encode the state into object-centric embeddings and using a\nblock-wise linear transition matrix to regularize the shared structure across\nobjects. The learned dynamics can quickly adapt to new environments of unknown\nphysical parameters and produce control signals to achieve a specified goal.\nOur experiments on manipulating ropes and controlling soft robots show that the\nproposed method has better efficiency and generalization ability than existing\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 05:11:16 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 17:09:47 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Li", "Yunzhu", ""], ["He", "Hao", ""], ["Wu", "Jiajun", ""], ["Katabi", "Dina", ""], ["Torralba", "Antonio", ""]]}, {"id": "1910.08270", "submitter": "Manirupa Das", "authors": "Manirupa Das, Zhen Wang, Evan Jaffe, Madhuja Chattopadhyay, Eric\n  Fosler-Lussier and Rajiv Ramnath", "title": "Learning to Answer Subjective, Specific Product-Related Queries using\n  Customer Reviews by Adversarial Domain Adaptation", "comments": "8 pages, 1 figure, 6 tables, added additional references to end of\n  section 2.1, removed graphics from referenced works, added to argument in\n  section 2.3 corrected typos, results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online customer reviews on large-scale e-commerce websites, represent a rich\nand varied source of opinion data, often providing subjective qualitative\nassessments of product usage that can help potential customers to discover\nfeatures that meet their personal needs and preferences. Thus they have the\npotential to automatically answer specific queries about products, and to\naddress the problems of answer starvation and answer augmentation on associated\nconsumer Q & A forums, by providing good answer alternatives. In this work, we\nexplore several recently successful neural approaches to modeling sentence\npairs, that could better learn the relationship between questions and ground\ntruth answers, and thus help infer reviews that can best answer a question or\naugment a given answer. In particular, we hypothesize that our adversarial\ndomain adaptation-based approach, due to its ability to additionally learn\ndomain-invariant features from a large number of unlabeled, unpaired\nquestion-review samples, would perform better than our proposed baselines, at\nanswering specific, subjective product-related queries using reviews. We\nvalidate this hypothesis using a small gold standard dataset of question-review\npairs evaluated by human experts, significantly surpassing our chosen\nbaselines. Moreover, our approach, using no labeled question-review sentence\npair data for training, gives performance at par with another method utilizing\nlabeled question-review samples for the same task.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 05:28:46 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 07:12:45 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Das", "Manirupa", ""], ["Wang", "Zhen", ""], ["Jaffe", "Evan", ""], ["Chattopadhyay", "Madhuja", ""], ["Fosler-Lussier", "Eric", ""], ["Ramnath", "Rajiv", ""]]}, {"id": "1910.08278", "submitter": "Shunsuke Kanda", "authors": "Shunsuke Kanda, Yasuo Tabei", "title": "$b$-Bit Sketch Trie: Scalable Similarity Search on Integer Sketches", "comments": "To be appeared in the Proceedings of IEEE BigData'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, randomly mapping vectorial data to strings of discrete symbols\n(i.e., sketches) for fast and space-efficient similarity searches has become\npopular. Such random mapping is called similarity-preserving hashing and\napproximates a similarity metric by using the Hamming distance. Although many\nefficient similarity searches have been proposed, most of them are designed for\nbinary sketches. Similarity searches on integer sketches are in their infancy.\nIn this paper, we present a novel space-efficient trie named $b$-bit sketch\ntrie on integer sketches for scalable similarity searches by leveraging the\nidea behind succinct data structures (i.e., space-efficient data structures\nwhile supporting various data operations in the compressed format) and a\nfavorable property of integer sketches as fixed-length strings. Our\nexperimental results obtained using real-world datasets show that a trie-based\nindex is built from integer sketches and efficiently performs similarity\nsearches on the index by pruning useless portions of the search space, which\ngreatly improves the search time and space-efficiency of the similarity search.\nThe experimental results show that our similarity search is at most one order\nof magnitude faster than state-of-the-art similarity searches. Besides, our\nmethod needs only 10 GiB of memory on a billion-scale database, while\nstate-of-the-art similarity searches need 29 GiB of memory.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 06:23:32 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Kanda", "Shunsuke", ""], ["Tabei", "Yasuo", ""]]}, {"id": "1910.08280", "submitter": "Hiroaki Sasaki", "authors": "Hiroaki Sasaki, Tomoya Sakai, Takafumi Kanamori", "title": "Robust modal regression with direct log-density derivative estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modal regression is aimed at estimating the global mode (i.e., global\nmaximum) of the conditional density function of the output variable given input\nvariables, and has led to regression methods robust against heavy-tailed or\nskewed noises. The conditional mode is often estimated through maximization of\nthe modal regression risk (MRR). In order to apply a gradient method for the\nmaximization, the fundamental challenge is accurate approximation of the\ngradient of MRR, not MRR itself. To overcome this challenge, in this paper, we\ntake a novel approach of directly approximating the gradient of MRR. To\napproximate the gradient, we develop kernelized and neural-network-based\nversions of the least-squares log-density derivative estimator, which directly\napproximates the derivative of the log-density without density estimation. With\ndirect approximation of the MRR gradient, we first propose a modal regression\nmethod with kernels, and derive a new parameter update rule based on a\nfixed-point method. Then, the derived update rule is theoretically proved to\nhave a monotonic hill-climbing property towards the conditional mode.\nFurthermore, we indicate that our approach of directly approximating the\ngradient is compatible with recent sophisticated stochastic gradient methods\n(e.g., Adam), and then propose another modal regression method based on neural\nnetworks. Finally, the superior performance of the proposed methods is\ndemonstrated on various artificial and benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 06:46:01 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Sasaki", "Hiroaki", ""], ["Sakai", "Tomoya", ""], ["Kanamori", "Takafumi", ""]]}, {"id": "1910.08281", "submitter": "Nazanin Mehrasa", "authors": "Nazanin Mehrasa, Ruizhi Deng, Mohamed Osama Ahmed, Bo Chang, Jiawei\n  He, Thibaut Durand, Marcus Brubaker, Greg Mori", "title": "Point Process Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event sequences can be modeled by temporal point processes (TPPs) to capture\ntheir asynchronous and probabilistic nature. We propose an intensity-free\nframework that directly models the point process distribution by utilizing\nnormalizing flows. This approach is capable of capturing highly complex\ntemporal distributions and does not rely on restrictive parametric forms.\nComparisons with state-of-the-art baseline models on both synthetic and\nchallenging real-life datasets show that the proposed framework is effective at\nmodeling the stochasticity of discrete event sequences.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 06:48:26 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 02:34:27 GMT"}, {"version": "v3", "created": "Sun, 22 Dec 2019 21:31:36 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Mehrasa", "Nazanin", ""], ["Deng", "Ruizhi", ""], ["Ahmed", "Mohamed Osama", ""], ["Chang", "Bo", ""], ["He", "Jiawei", ""], ["Durand", "Thibaut", ""], ["Brubaker", "Marcus", ""], ["Mori", "Greg", ""]]}, {"id": "1910.08282", "submitter": "Kun Zhou", "authors": "Kun Zhou, Kai Zhang, Yu Wu, Shujie Liu, Jingsong Yu", "title": "Unsupervised Context Rewriting for Open Domain Conversation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context modeling has a pivotal role in open domain conversation. Existing\nworks either use heuristic methods or jointly learn context modeling and\nresponse generation with an encoder-decoder framework. This paper proposes an\nexplicit context rewriting method, which rewrites the last utterance by\nconsidering context history. We leverage pseudo-parallel data and elaborate a\ncontext rewriting network, which is built upon the CopyNet with the\nreinforcement learning method. The rewritten utterance is beneficial to\ncandidate retrieval, explainable context modeling, as well as enabling to\nemploy a single-turn framework to the multi-turn scenario. The empirical\nresults show that our model outperforms baselines in terms of the rewriting\nquality, the multi-turn response generation, and the end-to-end retrieval-based\nchatbots.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 06:49:55 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 11:41:45 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Zhou", "Kun", ""], ["Zhang", "Kai", ""], ["Wu", "Yu", ""], ["Liu", "Shujie", ""], ["Yu", "Jingsong", ""]]}, {"id": "1910.08285", "submitter": "Minne Li", "authors": "Minne Li, Lisheng Wu, Haitham Bou Ammar, Jun Wang", "title": "Multi-View Reinforcement Learning", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with multi-view reinforcement learning (MVRL), which\nallows for decision making when agents share common dynamics but adhere to\ndifferent observation models. We define the MVRL framework by extending\npartially observable Markov decision processes (POMDPs) to support more than\none observation model and propose two solution methods through observation\naugmentation and cross-view policy transfer. We empirically evaluate our method\nand demonstrate its effectiveness in a variety of environments. Specifically,\nwe show reductions in sample complexities and computational time for acquiring\npolicies that handle multi-view environments.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 07:14:46 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Li", "Minne", ""], ["Wu", "Lisheng", ""], ["Ammar", "Haitham Bou", ""], ["Wang", "Jun", ""]]}, {"id": "1910.08288", "submitter": "Xiao Sha", "authors": "Xiao Sha and Zhu Sun and Jie Zhang", "title": "Attentive Knowledge Graph Embedding for Personalized Recommendation", "comments": null, "journal-ref": null, "doi": "10.1016/j.elerap.2021.101071", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) have proven to be effective for high-quality\nrecommendation. Most efforts, however, explore KGs by either extracting\nseparate paths connecting user-item pairs, or iteratively propagating user\npreference over the entire KGs, thus failing to efficiently exploit KGs for\nenhanced recommendation. In this paper, we design a novel attentive knowledge\ngraph embedding (AKGE) framework for recommendation, which sufficiently\nexploits both semantics and topology of KGs in an interaction-specific manner.\nSpecifically, AKGE first automatically extracts high-order subgraphs that link\nuser-item pairs with rich semantics, and then encodes the subgraphs by the\nproposed attentive graph neural network to learn accurate user preference.\nExtensive experiments on three real-world datasets demonstrate that AKGE\nconsistently outperforms state-of-the-art methods. It additionally provides\npotential explanations for the recommendation results.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 07:22:02 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 14:57:09 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 09:23:47 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Sha", "Xiao", ""], ["Sun", "Zhu", ""], ["Zhang", "Jie", ""]]}, {"id": "1910.08293", "submitter": "Steven Y. Feng", "authors": "Aaron W. Li, Veronica Jiang, Steven Y. Feng, Julia Sprague, Wei Zhou,\n  Jesse Hoey", "title": "ALOHA: Artificial Learning of Human Attributes for Dialogue Agents", "comments": "AAAI 2020; Code available at https://github.com/newpro/aloha-chatbot", "journal-ref": null, "doi": "10.1609/aaai.v34i05.6328", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For conversational AI and virtual assistants to communicate with humans in a\nrealistic way, they must exhibit human characteristics such as expression of\nemotion and personality. Current attempts toward constructing human-like\ndialogue agents have presented significant difficulties. We propose Human Level\nAttributes (HLAs) based on tropes as the basis of a method for learning\ndialogue agents that can imitate the personalities of fictional characters.\nTropes are characteristics of fictional personalities that are observed\nrecurrently and determined by viewers' impressions. By combining detailed HLA\ndata with dialogue data for specific characters, we present a dataset,\nHLA-Chat, that models character profiles and gives dialogue agents the ability\nto learn characters' language styles through their HLAs. We then introduce a\nthree-component system, ALOHA (which stands for Artificial Learning of Human\nAttributes), that combines character space mapping, character community\ndetection, and language style retrieval to build a character (or personality)\nspecific language model. Our preliminary experiments demonstrate that two\nvariations of ALOHA, combined with our proposed dataset, can outperform\nbaseline models at identifying the correct dialogue responses of chosen target\ncharacters, and are stable regardless of the character's identity, the genre of\nthe show, and the context of the dialogue.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 07:52:01 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 19:18:03 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 07:52:11 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Aaron W.", ""], ["Jiang", "Veronica", ""], ["Feng", "Steven Y.", ""], ["Sprague", "Julia", ""], ["Zhou", "Wei", ""], ["Hoey", "Jesse", ""]]}, {"id": "1910.08320", "submitter": "Iman Marivani", "authors": "Iman Marivani, Evaggelia Tsiligianni, Bruno Cornelis, Nikos\n  Deligiannis", "title": "Multimodal Image Super-resolution via Deep Unfolding with Side\n  Information", "comments": "5 pages, 5 figures, 3 tables, EUSIPCO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have been successfully applied to various computer\nvision tasks. However, existing neural network architectures do not per se\nincorporate domain knowledge about the addressed problem, thus, understanding\nwhat the model has learned is an open research topic. In this paper, we rely on\nthe unfolding of an iterative algorithm for sparse approximation with side\ninformation, and design a deep learning architecture for multimodal image\nsuper-resolution that incorporates sparse priors and effectively utilizes\ninformation from another image modality. We develop two deep models performing\nreconstruction of a high-resolution image of a target image modality from its\nlow-resolution variant with the aid of a high-resolution image from a second\nmodality. We apply the proposed models to super-resolve near-infrared images\nusing as side information high-resolution RGB\\ images. Experimental results\ndemonstrate the superior performance of the proposed models against\nstate-of-the-art methods including unimodal and multimodal approaches.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 09:32:24 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Marivani", "Iman", ""], ["Tsiligianni", "Evaggelia", ""], ["Cornelis", "Bruno", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1910.08322", "submitter": "Ville Hyv\\\"onen", "authors": "Ville Hyv\\\"onen, Elias J\\\"a\\\"asaari, Teemu Roos", "title": "Approximate Nearest Neighbor Search as a Multi-Label Classification\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate approximate nearest neighbor (ANN) search as a multi-label\nclassification task. The implications are twofold. First, tree-based indexes\ncan be searched more efficiently by interpreting them as models to solve this\ntask. Second, in addition to index structures designed specifically for ANN\nsearch, any type of classifier can be used as an index.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 09:37:19 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 14:40:33 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 12:43:40 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Hyv\u00f6nen", "Ville", ""], ["J\u00e4\u00e4saari", "Elias", ""], ["Roos", "Teemu", ""]]}, {"id": "1910.08343", "submitter": "Tiexin Qin", "authors": "Yinghuan Shi, Tiexin Qin, Yong Liu, Jiwen Lu, Yang Gao and Dinggang\n  Shen", "title": "Automatic Data Augmentation by Learning the Deterministic Policy", "comments": "Sorry for withdrawing our paper, there exists a mistake in the\n  experiment, and we will reupload once we have fixed it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aiming to produce sufficient and diverse training samples, data augmentation\nhas been demonstrated for its effectiveness in training deep models. Regarding\nthat the criterion of the best augmentation is challenging to define, we in\nthis paper present a novel learning-based augmentation method termed as\nDeepAugNet, which formulates the final augmented data as a collection of\nseveral sequentially augmented subsets. Specifically, the current augmented\nsubset is required to maximize the performance improvement compared with the\nlast augmented subset by learning the deterministic augmentation policy using\ndeep reinforcement learning. By introducing an unified optimization goal,\nDeepAugNet intends to combine the data augmentation and the deep model training\nin an end-to-end training manner which is realized by simultaneously training a\nhybrid architecture of dueling deep Q-learning algorithm and a surrogate deep\nmodel. We extensively evaluated our proposed DeepAugNet on various benchmark\ndatasets including Fashion MNIST, CUB, CIFAR-100 and WebCaricature. Compared\nwith the current state-of-the-arts, our method can achieve a significant\nimprovement in small-scale datasets, and a comparable performance in\nlarge-scale datasets. Code will be available soon.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 11:22:32 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 01:04:59 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Shi", "Yinghuan", ""], ["Qin", "Tiexin", ""], ["Liu", "Yong", ""], ["Lu", "Jiwen", ""], ["Gao", "Yang", ""], ["Shen", "Dinggang", ""]]}, {"id": "1910.08345", "submitter": "Ad\\'elie Garin", "authors": "Ad\\'elie Garin and Guillaume Tauzin", "title": "A Topological \"Reading\" Lesson: Classification of MNIST using TDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a way to use Topological Data Analysis (TDA) for machine learning\ntasks on grayscale images. We apply persistent homology to generate a wide\nrange of topological features using a point cloud obtained from an image, its\nnatural grayscale filtration, and different filtrations defined on the\nbinarized image. We show that this topological machine learning pipeline can be\nused as a highly relevant dimensionality reduction by applying it to the MNIST\ndigits dataset. We conduct a feature selection and study their correlations\nwhile providing an intuitive interpretation of their importance, which is\nrelevant in both machine learning and TDA. Finally, we show that we can\nclassify digit images while reducing the size of the feature set by a factor 5\ncompared to the grayscale pixel value features and maintain similar accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 11:37:44 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 13:31:06 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Garin", "Ad\u00e9lie", ""], ["Tauzin", "Guillaume", ""]]}, {"id": "1910.08348", "submitter": "Luisa Zintgraf", "authors": "Luisa Zintgraf, Kyriacos Shiarlis, Maximilian Igl, Sebastian Schulze,\n  Yarin Gal, Katja Hofmann, Shimon Whiteson", "title": "VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trading off exploration and exploitation in an unknown environment is key to\nmaximising expected return during learning. A Bayes-optimal policy, which does\nso optimally, conditions its actions not only on the environment state but on\nthe agent's uncertainty about the environment. Computing a Bayes-optimal policy\nis however intractable for all but the smallest tasks. In this paper, we\nintroduce variational Bayes-Adaptive Deep RL (variBAD), a way to meta-learn to\nperform approximate inference in an unknown environment, and incorporate task\nuncertainty directly during action selection. In a grid-world domain, we\nillustrate how variBAD performs structured online exploration as a function of\ntask uncertainty. We further evaluate variBAD on MuJoCo domains widely used in\nmeta-RL and show that it achieves higher online return than existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 11:44:59 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 19:40:21 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zintgraf", "Luisa", ""], ["Shiarlis", "Kyriacos", ""], ["Igl", "Maximilian", ""], ["Schulze", "Sebastian", ""], ["Gal", "Yarin", ""], ["Hofmann", "Katja", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1910.08350", "submitter": "Dani Yogatama", "authors": "Lingpeng Kong, Cyprien de Masson d'Autume, Wang Ling, Lei Yu, Zihang\n  Dai, Dani Yogatama", "title": "A Mutual Information Maximization Perspective of Language Representation\n  Learning", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show state-of-the-art word representation learning methods maximize an\nobjective function that is a lower bound on the mutual information between\ndifferent parts of a word sequence (i.e., a sentence). Our formulation provides\nan alternative perspective that unifies classical word embedding models (e.g.,\nSkip-gram) and modern contextual embeddings (e.g., BERT, XLNet). In addition to\nenhancing our theoretical understanding of these methods, our derivation leads\nto a principled framework that can be used to construct new self-supervised\ntasks. We provide an example by drawing inspirations from related methods based\non mutual information maximization that have been successful in computer\nvision, and introduce a simple self-supervised objective that maximizes the\nmutual information between a global sentence representation and n-grams in the\nsentence. Our analysis offers a holistic view of representation learning\nmethods to transfer knowledge and translate progress across multiple domains\n(e.g., natural language processing, computer vision, audio processing).\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 11:47:24 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 17:59:43 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Kong", "Lingpeng", ""], ["d'Autume", "Cyprien de Masson", ""], ["Ling", "Wang", ""], ["Yu", "Lei", ""], ["Dai", "Zihang", ""], ["Yogatama", "Dani", ""]]}, {"id": "1910.08364", "submitter": "Peng Liu", "authors": "Peng Liu, Ruogu Fang", "title": "SDCNet: Smoothed Dense-Convolution Network for Restoring Low-Dose\n  Cerebral CT Perfusion", "comments": null, "journal-ref": "The IEEE International Symposium on Biomedical Imaging (ISBI 2018)", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With substantial public concerns on potential cancer risks and health hazards\ncaused by the accumulated radiation exposure in medical imaging, reducing\nradiation dose in X-ray based medical imaging such as Computed Tomography\nPerfusion (CTP) has raised significant research interests. In this paper, we\nembrace the deep Convolutional Neural Networks (CNN) based approaches and\nintroduce Smoothed Dense-Convolution Neural Network (SDCNet) to recover\nhigh-dose quality CTP images from low-dose ones. SDCNet is composed of\nsub-network blocks cascaded by skip-connections to infer the noise\n(differentials) from paired low/high-dose CT scans. SDCNet can effectively\nremove the noise in real low-dose CT scans and enhance the quality of medical\nimages. We evaluate the proposed architecture on thousands of CT perfusion\nframes for both reconstructed image denoising and perfusion map quantification\nincluding cerebral blood flow (CBF) and cerebral blood volume (CBV). SDCNet\nachieves high performance in both visual and quantitative results with\npromising computational efficiency, comparing favorably with state-of-the-art\napproaches. \\textit{The code is available at\n\\url{https://github.com/cswin/RC-Nets}}.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 12:12:42 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Liu", "Peng", ""], ["Fang", "Ruogu", ""]]}, {"id": "1910.08371", "submitter": "Taras Khakhulin", "authors": "Taras Khakhulin, Roman Schutski and Ivan Oseledets", "title": "Graph Convolutional Policy for Solving Tree Decomposition via\n  Reinforcement Learning Heuristics", "comments": "8 pages, 7 figures", "journal-ref": "NeurIPS 2020 Learning Meets Combinatorial Algorithms Workshop", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Reinforcement Learning based approach to approximately solve the\nTree Decomposition (TD) problem. TD is a combinatorial problem, which is\ncentral to the analysis of graph minor structure and computational complexity,\nas well as in the algorithms of probabilistic inference, register allocation,\nand other practical tasks. Recently, it has been shown that combinatorial\nproblems can be successively solved by learned heuristics. However, the\nmajority of existing works do not address the question of the generalization of\nlearning-based solutions. Our model is based on the graph convolution neural\nnetwork (GCN) for learning graph representations. We show that the agent\nbuilton GCN and trained on a single graph using an Actor-Critic method can\nefficiently generalize to real-world TD problem instances. We establish that\nour method successfully generalizes from small graphs, where TD can be found by\nexact algorithms, to large instances of practical interest, while still having\nvery low time-to-solution. On the other hand, the agent-based approach\nsurpasses all greedy heuristics by the quality of the solution.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 12:27:38 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 11:26:50 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Khakhulin", "Taras", ""], ["Schutski", "Roman", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1910.08385", "submitter": "Aleksei Triastcyn", "authors": "Aleksei Triastcyn, Boi Faltings", "title": "Federated Generative Privacy", "comments": "IJCAI Workshop on Federated Machine Learning for User Privacy and\n  Data Confidentiality (FL-IJCAI 2019). 7 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose FedGP, a framework for privacy-preserving data\nrelease in the federated learning setting. We use generative adversarial\nnetworks, generator components of which are trained by FedAvg algorithm, to\ndraw privacy-preserving artificial data samples and empirically assess the risk\nof information disclosure. Our experiments show that FedGP is able to generate\nlabelled data of high quality to successfully train and validate supervised\nmodels. Finally, we demonstrate that our approach significantly reduces\nvulnerability of such models to model inversion attacks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 12:41:15 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "1910.08398", "submitter": "Julien Tierny", "authors": "Max Kontak and Jules Vidal and Julien Tierny", "title": "Statistical Parameter Selection for Clustering Persistence Diagrams", "comments": "arXiv admin note: text overlap with arXiv:1907.04565", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In urgent decision making applications, ensemble simulations are an important\nway to determine different outcome scenarios based on currently available data.\nIn this paper, we will analyze the output of ensemble simulations by\nconsidering so-called persistence diagrams, which are reduced representations\nof the original data, motivated by the extraction of topological features.\nBased on a recently published progressive algorithm for the clustering of\npersistence diagrams, we determine the optimal number of clusters, and\ntherefore the number of significantly different outcome scenarios, by the\nminimization of established statistical score functions. Furthermore, we\npresent a proof-of-concept prototype implementation of the statistical\nselection of the number of clusters and provide the results of an experimental\nstudy, where this implementation has been applied to real-world ensemble data\nsets.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 07:06:36 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Kontak", "Max", ""], ["Vidal", "Jules", ""], ["Tierny", "Julien", ""]]}, {"id": "1910.08406", "submitter": "Marie-Liesse Cauwet", "authors": "M.-L. Cauwet, C. Couprie, J. Dehos, P. Luc, J. Rapin, M. Riviere, F.\n  Teytaud, O. Teytaud", "title": "Fully Parallel Hyperparameter Search: Reshaped Space-Filling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space-filling designs such as scrambled-Hammersley, Latin Hypercube Sampling\nand Jittered Sampling have been proposed for fully parallel hyperparameter\nsearch, and were shown to be more effective than random or grid search. In this\npaper, we show that these designs only improve over random search by a constant\nfactor. In contrast, we introduce a new approach based on reshaping the search\ndistribution, which leads to substantial gains over random search, both\ntheoretically and empirically. We propose two flavors of reshaping. First, when\nthe distribution of the optimum is some known $P_0$, we propose Recentering,\nwhich uses as search distribution a modified version of $P_0$ tightened closer\nto the center of the domain, in a dimension-dependent and budget-dependent\nmanner. Second, we show that in a wide range of experiments with $P_0$ unknown,\nusing a proposed Cauchy transformation, which simultaneously has a heavier tail\n(for unbounded hyperparameters) and is closer to the boundaries (for bounded\nhyperparameters), leads to improved performances. Besides artificial\nexperiments and simple real world tests on clustering or Salmon mappings, we\ncheck our proposed methods on expensive artificial intelligence tasks such as\nattend/infer/repeat, video next frame segmentation forecasting and progressive\ngenerative adversarial networks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 13:16:57 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 09:11:34 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Cauwet", "M. -L.", ""], ["Couprie", "C.", ""], ["Dehos", "J.", ""], ["Luc", "P.", ""], ["Rapin", "J.", ""], ["Riviere", "M.", ""], ["Teytaud", "F.", ""], ["Teytaud", "O.", ""]]}, {"id": "1910.08408", "submitter": "Alexander Matei", "authors": "Tristan Gally, Peter Groche, Florian Hoppe, Anja Kuttich, Alexander\n  Matei, Marc E. Pfetsch, Martin Rakowitsch, Stefan Ulbrich", "title": "Identification of Model Uncertainty via Optimal Design of Experiments\n  Applied to a Mechanical Press", "comments": null, "journal-ref": null, "doi": "10.1007/s11081-021-09600-8", "report-no": null, "categories": "stat.ML cs.LG math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In engineering applications almost all processes are described with the help\nof models. Especially forming machines heavily rely on mathematical models for\ncontrol and condition monitoring. Inaccuracies during the modeling,\nmanufacturing and assembly of these machines induce model uncertainty which\nimpairs the controller's performance. In this paper we propose an approach to\nidentify model uncertainty using parameter identification, optimal design of\nexperiments and hypothesis testing. The experimental setup is characterized by\noptimal sensor positions such that specific model parameters can be determined\nwith minimal variance. This allows for the computation of confidence regions in\nwhich the real parameters or the parameter estimates from different test sets\nhave to lie. We claim that inconsistencies in the estimated parameter values,\nconsidering their approximated confidence ellipsoids as well, cannot be\nexplained by data uncertainty but are indicators of model uncertainty. The\nproposed method is demonstrated using a component of the 3D Servo Press, a\nmulti-technology forming machine that combines spindles with eccentric servo\ndrives.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 13:27:53 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 14:21:35 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 13:45:46 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Gally", "Tristan", ""], ["Groche", "Peter", ""], ["Hoppe", "Florian", ""], ["Kuttich", "Anja", ""], ["Matei", "Alexander", ""], ["Pfetsch", "Marc E.", ""], ["Rakowitsch", "Martin", ""], ["Ulbrich", "Stefan", ""]]}, {"id": "1910.08412", "submitter": "Harshat Kumar", "authors": "Harshat Kumar and Alec Koppel and Alejandro Ribeiro", "title": "On the Sample Complexity of Actor-Critic Method for Reinforcement\n  Learning with Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning, mathematically described by Markov Decision Problems,\nmay be approached either through dynamic programming or policy search.\nActor-critic algorithms combine the merits of both approaches by alternating\nbetween steps to estimate the value function and policy gradient updates. Due\nto the fact that the updates exhibit correlated noise and biased gradient\nupdates, only the asymptotic behavior of actor-critic is known by connecting\nits behavior to dynamical systems. This work puts forth a new variant of\nactor-critic that employs Monte Carlo rollouts during the policy search\nupdates, which results in controllable bias that depends on the number of\ncritic evaluations. As a result, we are able to provide for the first time the\nconvergence rate of actor-critic algorithms when the policy search step employs\npolicy gradient, agnostic to the choice of policy evaluation technique. In\nparticular, we establish conditions under which the sample complexity is\ncomparable to stochastic gradient method for non-convex problems or slower as a\nresult of the critic estimation error, which is the main complexity bottleneck.\nThese results hold for in continuous state and action spaces with linear\nfunction approximation for the value function. We then specialize these\nconceptual results to the case where the critic is estimated by Temporal\nDifference, Gradient Temporal Difference, and Accelerated Gradient Temporal\nDifference. These learning rates are then corroborated on a navigation problem\ninvolving an obstacle, which suggests that learning more slowly may lead to\nimproved limit points, providing insight into the interplay between\noptimization and generalization in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 13:33:17 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Kumar", "Harshat", ""], ["Koppel", "Alec", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1910.08413", "submitter": "Alexander Ra{\\ss}", "authors": "Faramarz Khosravi, Alexander Ra{\\ss}, J\\\"urgen Teich", "title": "Efficient Computation of Probabilistic Dominance in Robust\n  Multi-Objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world problems typically require the simultaneous optimization of\nseveral, often conflicting objectives. Many of these multi-objective\noptimization problems are characterized by wide ranges of uncertainties in\ntheir decision variables or objective functions, which further increases the\ncomplexity of optimization. To cope with such uncertainties, robust\noptimization is widely studied aiming to distinguish candidate solutions with\nuncertain objectives specified by confidence intervals, probability\ndistributions or sampled data. However, existing techniques mostly either fail\nto consider the actual distributions or assume uncertainty as instances of\nuniform or Gaussian distributions. This paper introduces an empirical approach\nthat enables an efficient comparison of candidate solutions with uncertain\nobjectives that can follow arbitrary distributions. Given two candidate\nsolutions under comparison, this operator calculates the probability that one\nsolution dominates the other in terms of each uncertain objective. It can\nsubstitute for the standard comparison operator of existing optimization\ntechniques such as evolutionary algorithms to enable discovering robust\nsolutions to problems with multiple uncertain objectives. This paper also\nproposes to incorporate various uncertainties in well-known multi-objective\nproblems to provide a benchmark for evaluating uncertainty-aware optimization\ntechniques. The proposed comparison operator and benchmark suite are integrated\ninto an existing optimization tool that features a selection of multi-objective\noptimization problems and algorithms. Experiments show that in comparison with\nexisting techniques, the proposed approach achieves higher optimization quality\nat lower overheads.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 13:33:55 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Khosravi", "Faramarz", ""], ["Ra\u00df", "Alexander", ""], ["Teich", "J\u00fcrgen", ""]]}, {"id": "1910.08438", "submitter": "Kin Gwn Lore", "authors": "Kin Gwn Lore, Kishore K. Reddy", "title": "Implicit Context-aware Learning and Discovery for Streaming Data\n  Analytics", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of machine learning model can be further improved if\ncontextual cues are provided as input along with base features that are\ndirectly related to an inference task. In offline learning, one can inspect\nhistorical training data to identify contextual clusters either through feature\nclustering, or hand-crafting additional features to describe a context. While\noffline training enjoys the privilege of learning reliable models based on\nalready-defined contextual features, online training for streaming data may be\nmore challenging -- the data is streamed through time, and the underlying\ncontext during a data generation process may change. Furthermore, the problem\nis exacerbated when the number of possible context is not known. In this study,\nwe propose an online-learning algorithm involving the use of a neural\nnetwork-based autoencoder to identify contextual changes during training, then\ncompares the currently-inferred context to a knowledge base of learned contexts\nas training advances. Results show that classifier-training benefits from the\nautomatically discovered contexts which demonstrates quicker learning\nconvergence during contextual changes compared to current methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 14:30:27 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Lore", "Kin Gwn", ""], ["Reddy", "Kishore K.", ""]]}, {"id": "1910.08446", "submitter": "Pratik Gajane", "authors": "Pratik Gajane, Ronald Ortner, Peter Auer and Csaba Szepesvari", "title": "Autonomous exploration for navigating in non-stationary CMPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a setting in which the objective is to learn to navigate in a\ncontrolled Markov process (CMP) where transition probabilities may abruptly\nchange. For this setting, we propose a performance measure called exploration\nsteps which counts the time steps at which the learner lacks sufficient\nknowledge to navigate its environment efficiently. We devise a learning\nmeta-algorithm, MNM and prove an upper bound on the exploration steps in terms\nof the number of changes.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 14:40:26 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Gajane", "Pratik", ""], ["Ortner", "Ronald", ""], ["Auer", "Peter", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1910.08461", "submitter": "Theodore Moskovitz", "authors": "Ted Moskovitz, Rui Wang, Janice Lan, Sanyam Kapoor, Thomas Miconi,\n  Jason Yosinski, Aditya Rawal", "title": "First-Order Preconditioning via Hypergradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard gradient descent methods are susceptible to a range of issues that\ncan impede training, such as high correlations and different scaling in\nparameter space.These difficulties can be addressed by second-order approaches\nthat apply a pre-conditioning matrix to the gradient to improve convergence.\nUnfortunately, such algorithms typically struggle to scale to high-dimensional\nproblems, in part because the calculation of specific preconditioners such as\nthe inverse Hessian or Fisher information matrix is highly expensive. We\nintroduce first-order preconditioning (FOP), a fast, scalable approach that\ngeneralizes previous work on hypergradient descent (Almeida et al., 1998;\nMaclaurin et al., 2015; Baydin et al.,2017) to learn a preconditioning matrix\nthat only makes use of first-order information. Experiments show that FOP is\nable to improve the performance of standard deep learning optimizers on visual\nclassification and reinforcement learning tasks with minimal computational\noverhead. We also investigate the properties of the learned preconditioning\nmatrices and perform a preliminary theoretical analysis of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 15:12:36 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 23:12:36 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Moskovitz", "Ted", ""], ["Wang", "Rui", ""], ["Lan", "Janice", ""], ["Kapoor", "Sanyam", ""], ["Miconi", "Thomas", ""], ["Yosinski", "Jason", ""], ["Rawal", "Aditya", ""]]}, {"id": "1910.08475", "submitter": "Jordan Ash", "authors": "Jordan T. Ash and Ryan P. Adams", "title": "On Warm-Starting Neural Network Training", "comments": null, "journal-ref": "2020 Advances in Neural Information Processing Systems", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world deployments of machine learning systems, data arrive\npiecemeal. These learning scenarios may be passive, where data arrive\nincrementally due to structural properties of the problem (e.g., daily\nfinancial data) or active, where samples are selected according to a measure of\ntheir quality (e.g., experimental design). In both of these cases, we are\nbuilding a sequence of models that incorporate an increasing amount of data. We\nwould like each of these models in the sequence to be performant and take\nadvantage of all the data that are available to that point. Conventional\nintuition suggests that when solving a sequence of related optimization\nproblems of this form, it should be possible to initialize using the solution\nof the previous iterate -- to \"warm start\" the optimization rather than\ninitialize from scratch -- and see reductions in wall-clock time. However, in\npractice this warm-starting seems to yield poorer generalization performance\nthan models that have fresh random initializations, even though the final\ntraining losses are similar. While it appears that some hyperparameter settings\nallow a practitioner to close this generalization gap, they seem to only do so\nin regimes that damage the wall-clock gains of the warm start. Nevertheless, it\nis highly desirable to be able to warm-start neural network training, as it\nwould dramatically reduce the resource usage associated with the construction\nof performant deep learning systems. In this work, we take a closer look at\nthis empirical phenomenon and try to understand when and how it occurs. We also\nprovide a surprisingly simple trick that overcomes this pathology in several\nimportant situations, and present experiments that elucidate some of its\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 15:35:59 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 18:09:19 GMT"}, {"version": "v3", "created": "Thu, 31 Dec 2020 07:58:30 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ash", "Jordan T.", ""], ["Adams", "Ryan P.", ""]]}, {"id": "1910.08476", "submitter": "Nino Vieillard", "authors": "Nino Vieillard, Olivier Pietquin, Matthieu Geist", "title": "On Connections between Constrained Optimization and Reinforcement\n  Learning", "comments": "Optimization Foundations of Reinforcement Learning Workshop at\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Dynamic Programming (DP) provides standard algorithms to solve Markov\nDecision Processes. However, these algorithms generally do not optimize a\nscalar objective function. In this paper, we draw connections between DP and\n(constrained) convex optimization. Specifically, we show clear links in the\nalgorithmic structure between three DP schemes and optimization algorithms. We\nlink Conservative Policy Iteration to Frank-Wolfe, Mirror-Descent Modified\nPolicy Iteration to Mirror Descent, and Politex (Policy Iteration Using Expert\nPrediction) to Dual Averaging. These abstract DP schemes are representative of\na number of (deep) Reinforcement Learning (RL) algorithms. By highlighting\nthese connections (most of which have been noticed earlier, but in a scattered\nway), we would like to encourage further studies linking RL and convex\noptimization, that could lead to the design of new, more efficient, and better\nunderstood RL algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 15:42:35 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 13:38:59 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Vieillard", "Nino", ""], ["Pietquin", "Olivier", ""], ["Geist", "Matthieu", ""]]}, {"id": "1910.08483", "submitter": "Agni Orfanoudaki", "authors": "Dimitris Bertsimas, Agni Orfanoudaki, Rory B. Weiner", "title": "Personalized Treatment for Coronary Artery Disease Patients: A Machine\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current clinical practice guidelines for managing Coronary Artery Disease\n(CAD) account for general cardiovascular risk factors. However, they do not\npresent a framework that considers personalized patient-specific\ncharacteristics. Using the electronic health records of 21,460 patients, we\ncreated data-driven models for personalized CAD management that significantly\nimprove health outcomes relative to the standard of care. We develop binary\nclassifiers to detect whether a patient will experience an adverse event due to\nCAD within a 10-year time frame. Combining the patients' medical history and\nclinical examination results, we achieve 81.5% AUC. For each treatment, we also\ncreate a series of regression models that are based on different supervised\nmachine learning algorithms. We are able to estimate with average R squared =\n0.801 the time from diagnosis to a potential adverse event (TAE) and gain\naccurate approximations of the counterfactual treatment effects. Leveraging\ncombinations of these models, we present ML4CAD, a novel personalized\nprescriptive algorithm. Considering the recommendations of multiple predictive\nmodels at once, ML4CAD identifies for every patient the therapy with the best\nexpected outcome using a voting mechanism. We evaluate its performance by\nmeasuring the prescription effectiveness and robustness under alternative\nground truths. We show that our methodology improves the expected TAE upon the\ncurrent baseline by 24.11%, increasing it from 4.56 to 5.66 years. The\nalgorithm performs particularly well for the male (24.3% improvement) and\nHispanic (58.41% improvement) subpopulations. Finally, we create an interactive\ninterface, providing physicians with an intuitive, accurate, readily\nimplementable, and effective tool.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 15:57:46 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Orfanoudaki", "Agni", ""], ["Weiner", "Rory B.", ""]]}, {"id": "1910.08485", "submitter": "Ruth Fong", "authors": "Ruth Fong, Mandela Patrick, Andrea Vedaldi", "title": "Understanding Deep Networks via Extremal Perturbations and Smooth Masks", "comments": "Accepted at ICCV 2019 as oral; supp mat at\n  http://ruthcfong.github.io/files/fong19_extremal_supps.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of attribution is concerned with identifying the parts of an\ninput that are responsible for a model's output. An important family of\nattribution methods is based on measuring the effect of perturbations applied\nto the input. In this paper, we discuss some of the shortcomings of existing\napproaches to perturbation analysis and address them by introducing the concept\nof extremal perturbations, which are theoretically grounded and interpretable.\nWe also introduce a number of technical innovations to compute extremal\nperturbations, including a new area constraint and a parametric family of\nsmooth perturbations, which allow us to remove all tunable hyper-parameters\nfrom the optimization problem. We analyze the effect of perturbations as a\nfunction of their area, demonstrating excellent sensitivity to the spatial\nproperties of the deep neural network under stimulation. We also extend\nperturbation analysis to the intermediate layers of a network. This application\nallows us to identify the salient channels necessary for classification, which,\nwhen visualized using feature inversion, can be used to elucidate model\nbehavior. Lastly, we introduce TorchRay, an interpretability library built on\nPyTorch.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 16:02:01 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Fong", "Ruth", ""], ["Patrick", "Mandela", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1910.08489", "submitter": "Seok-Ju Hahn", "authors": "Seok-Ju Hahn, Junghye Lee", "title": "Privacy-preserving Federated Bayesian Learning of a Generative Model for\n  Imbalanced Classification of Clinical Data", "comments": "10 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In clinical research, the lack of events of interest often necessitates\nimbalanced learning. One approach to resolve this obstacle is data integration\nor sharing, but due to privacy concerns neither is practical. Therefore, there\nis an increasing demand for a platform on which an analysis can be performed in\na federated environment while maintaining privacy. However, it is quite\nchallenging to develop a federated learning algorithm that can address both\nprivacy-preserving and class imbalanced issues. In this study, we introduce a\nfederated generative model learning platform for generating samples in a\ndata-distributed environment while preserving privacy. We specifically propose\napproximate Bayesian computation-based Gaussian Mixture Model called 'Federated\nABC-GMM', which can oversample data in a minor class by estimating the\nposterior distribution of model parameters across institutions in a\nprivacy-preserving manner. PhysioNet2012, a dataset for prediction of mortality\nof patients in an Intensive Care Unit (ICU), was used to verify the performance\nof the proposed method. Experimental results show that our method boosts\nclassification performance in terms of F1 score up to nearly an ideal\nsituation. It is believed that the proposed method can be a novel alternative\nto solving class imbalance problems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 16:15:09 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 08:09:58 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 07:15:32 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hahn", "Seok-Ju", ""], ["Lee", "Junghye", ""]]}, {"id": "1910.08501", "submitter": "Mariia Dmitrieva", "authors": "Mariia Dmitrieva, Keith E. Brown, Gary J. Heald, David M. Lane", "title": "Classification of spherical objects based on the form function of\n  acoustic echoes", "comments": null, "journal-ref": "Proc. of the 4th Underwater Acoustics Conference and Exhibition\n  (UACE), Skiathos, Greece, Sept 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to recognise an object is to study how the echo has been shaped\nduring the interaction with the target. Wideband sonar allows the study of the\nenergy distribution for a large range of frequencies. The frequency\ndistribution contains information about an object, including its inner\nstructure. This information is a key for automatic recognition. The scattering\nby a target can be quantitatively described by its Form Function. The Form\nFunction can be calculated based on the data of the initial pulse, reflected\npulse and parameters of a medium where the pulse is propagating. In this work\nspherical objects are classified based on their filler material - water or air.\nWe limit the study to spherical 2 layered targets immersed in water. The Form\nFunction is used as a descriptor and fed into a Neural Network classifier,\nMultilayer Perceptron (MLP). The performance of the classifier is compared with\nSupport Vector Machine (SVM) and the Form Function descriptor is examined in\ncontrast to the Time and Frequency Representation of the echo.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 16:51:30 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Dmitrieva", "Mariia", ""], ["Brown", "Keith E.", ""], ["Heald", "Gary J.", ""], ["Lane", "David M.", ""]]}, {"id": "1910.08506", "submitter": "Sarah Tymochko", "authors": "Sarah Tymochko, Elizabeth Munch, and Firas A. Khasawneh", "title": "Adaptive Partitioning for Template Functions on Persistence Diagrams", "comments": "To appear in proceedings of IEEE ICMLA 2019", "journal-ref": "2019 18th IEEE International Conference On Machine Learning And\n  Applications (ICMLA)", "doi": "10.1109/ICMLA.2019.00202", "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the field of Topological Data Analysis continues to show success in theory\nand in applications, there has been increasing interest in using tools from\nthis field with methods for machine learning. Using persistent homology,\nspecifically persistence diagrams, as inputs to machine learning techniques\nrequires some mathematical creativity. The space of persistence diagrams does\nnot have the desirable properties for machine learning, thus methods such as\nkernel methods and vectorization methods have been developed. One such\nfeaturization of persistence diagrams by Perea, Munch and Khasawneh uses\ncontinuous, compactly supported functions, referred to as \"template functions,\"\nwhich results in a stable vector representation of the persistence diagram. In\nthis paper, we provide a method of adaptively partitioning persistence diagrams\nto improve these featurizations based on localized information in the diagrams.\nAdditionally, we provide a framework to adaptively select parameters required\nfor the template functions in order to best utilize the partitioning method. We\npresent results for application to example data sets comparing classification\nresults between template function featurizations with and without partitioning,\nin addition to other methods from the literature.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 16:56:43 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Tymochko", "Sarah", ""], ["Munch", "Elizabeth", ""], ["Khasawneh", "Firas A.", ""]]}, {"id": "1910.08512", "submitter": "Batiste Le Bars", "authors": "Batiste Le Bars and Pierre Humbert and Argyris Kalogeratos and Nicolas\n  Vayatis", "title": "Learning the piece-wise constant graph structure of a varying Ising\n  model", "comments": "18 pages (9 pages for Appendix), 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on the estimation of multiple change-points in a\ntime-varying Ising model that evolves piece-wise constantly. The aim is to\nidentify both the moments at which significant changes occur in the Ising\nmodel, as well as the underlying graph structures. For this purpose, we propose\nto estimate the neighborhood of each node by maximizing a penalized version of\nits conditional log-likelihood. The objective of the penalization is twofold:\nit imposes sparsity in the learned graphs and, thanks to a fused-type penalty,\nit also enforces them to evolve piece-wise constantly. Using few assumptions,\nwe provide two change-points consistency theorems. Those are the first in the\ncontext of unknown number of change-points detection in time-varying Ising\nmodel. Finally, experimental results on several synthetic datasets and a\nreal-world dataset demonstrate the performance of our method.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 17:20:37 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 12:51:45 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Bars", "Batiste Le", ""], ["Humbert", "Pierre", ""], ["Kalogeratos", "Argyris", ""], ["Vayatis", "Nicolas", ""]]}, {"id": "1910.08519", "submitter": "Sam Ringer", "authors": "Sam Ringer, Will Williams, Tom Ash, Remi Francis, David MacLeod", "title": "Texture Bias Of CNNs Limits Few-Shot Classification Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate image classification given small amounts of labelled data (few-shot\nclassification) remains an open problem in computer vision. In this work we\nexamine how the known texture bias of Convolutional Neural Networks (CNNs)\naffects few-shot classification performance. Although texture bias can help in\nstandard image classification, in this work we show it significantly harms\nfew-shot classification performance. After correcting this bias we demonstrate\nstate-of-the-art performance on the competitive miniImageNet task using a\nmethod far simpler than the current best performing few-shot learning\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 17:30:11 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Ringer", "Sam", ""], ["Williams", "Will", ""], ["Ash", "Tom", ""], ["Francis", "Remi", ""], ["MacLeod", "David", ""]]}, {"id": "1910.08525", "submitter": "Luca Franceschi", "authors": "Michele Donini, Luca Franceschi, Massimiliano Pontil, Orchid Majumder,\n  Paolo Frasconi", "title": "MARTHE: Scheduling the Learning Rate Via Online Hypergradients", "comments": "IJCAI 2020. Larger images. Code available at\n  https://github.com/awslabs/adatune", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of fitting task-specific learning rate schedules from\nthe perspective of hyperparameter optimization, aiming at good generalization.\nWe describe the structure of the gradient of a validation error w.r.t. the\nlearning rate schedule -- the hypergradient. Based on this, we introduce\nMARTHE, a novel online algorithm guided by cheap approximations of the\nhypergradient that uses past information from the optimization trajectory to\nsimulate future behaviour. It interpolates between two recent techniques, RTHO\n(Franceschi et al., 2017) and HD (Baydin et al. 2018), and is able to produce\nlearning rate schedules that are more stable leading to models that generalize\nbetter.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 17:42:09 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 16:04:50 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 16:43:15 GMT"}, {"version": "v4", "created": "Sun, 17 May 2020 10:32:46 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Donini", "Michele", ""], ["Franceschi", "Luca", ""], ["Pontil", "Massimiliano", ""], ["Majumder", "Orchid", ""], ["Frasconi", "Paolo", ""]]}, {"id": "1910.08527", "submitter": "Ignavier Ng", "authors": "Ignavier Ng, Zhuangyan Fang, Shengyu Zhu, Zhitang Chen, Jun Wang", "title": "Masked Gradient-Based Causal Structure Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of learning causal structures from\nobservational data. We reformulate the Structural Equation Model (SEM) in an\naugmented form with a binary graph adjacency matrix and show that, if the\noriginal SEM is identifiable, then this augmented form can be identified up to\nsuper-graphs of the true causal graph under mild conditions. Three methods are\nfurther provided to remove spurious edges to recover the true graph. We next\nutilize the augmented form to develop a masked structure learning method that\ncan be efficiently trained using gradient-based optimization methods, by\nleveraging a smooth characterization on acyclicity and the Gumbel-Softmax\napproach to approximate the binary adjacency matrix. It is found that the\nobtained entries are typically near zero or one, and can be easily thresholded\nto identify the edges. We conduct experiments on synthetic and real datasets to\nvalidate the effectiveness of the proposed method and show that the method can\nreadily include different smooth functions to model causal relationships.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 17:46:44 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 05:47:01 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ng", "Ignavier", ""], ["Fang", "Zhuangyan", ""], ["Zhu", "Shengyu", ""], ["Chen", "Zhitang", ""], ["Wang", "Jun", ""]]}, {"id": "1910.08534", "submitter": "Vivian Lai", "authors": "Vivian Lai, Jon Z. Cai, Chenhao Tan", "title": "Many Faces of Feature Importance: Comparing Built-in and Post-hoc\n  Feature Importance in Text Classification", "comments": "17 pages, 18 figures, EMNLP 2019, the code is available at\n  https://vivlai.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature importance is commonly used to explain machine predictions. While\nfeature importance can be derived from a machine learning model with a variety\nof methods, the consistency of feature importance via different methods remains\nunderstudied. In this work, we systematically compare feature importance from\nbuilt-in mechanisms in a model such as attention values and post-hoc methods\nthat approximate model behavior such as LIME. Using text classification as a\ntestbed, we find that 1) no matter which method we use, important features from\ntraditional models such as SVM and XGBoost are more similar with each other,\nthan with deep learning models; 2) post-hoc methods tend to generate more\nsimilar important features for two models than built-in methods. We further\ndemonstrate how such similarity varies across instances. Notably, important\nfeatures do not always resemble each other better when two models agree on the\npredicted label than when they disagree.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 17:59:59 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Lai", "Vivian", ""], ["Cai", "Jon Z.", ""], ["Tan", "Chenhao", ""]]}, {"id": "1910.08540", "submitter": "Wenyuan Li", "authors": "Wenyuan Li, Zichen Wang, Yuguang Yue, Jiayun Li, William Speier,\n  Mingyuan Zhou, Corey W. Arnold", "title": "Semi-supervised Learning using Adversarial Training with Good and Bad\n  Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate semi-supervised learning (SSL) for image\nclassification using adversarial training. Previous results have illustrated\nthat generative adversarial networks (GANs) can be used for multiple purposes.\nTriple-GAN, which aims to jointly optimize model components by incorporating\nthree players, generates suitable image-label pairs to compensate for the lack\nof labeled data in SSL with improved benchmark performance. Conversely, Bad (or\ncomplementary) GAN, optimizes generation to produce complementary data-label\npairs and force a classifier's decision boundary to lie between data manifolds.\nAlthough it generally outperforms Triple-GAN, Bad GAN is highly sensitive to\nthe amount of labeled data used for training. Unifying these two approaches, we\npresent unified-GAN (UGAN), a novel framework that enables a classifier to\nsimultaneously learn from both good and bad samples through adversarial\ntraining. We perform extensive experiments on various datasets and demonstrate\nthat UGAN: 1) achieves state-of-the-art performance among other deep generative\nmodels, and 2) is robust to variations in the amount of labeled data used for\ntraining.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 05:47:08 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Li", "Wenyuan", ""], ["Wang", "Zichen", ""], ["Yue", "Yuguang", ""], ["Li", "Jiayun", ""], ["Speier", "William", ""], ["Zhou", "Mingyuan", ""], ["Arnold", "Corey W.", ""]]}, {"id": "1910.08549", "submitter": "Achim Rettinger", "authors": "Achim Rettinger, Viktoria Bogdanova, Philipp Niemann", "title": "Towards Learning Cross-Modal Perception-Trace Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is a key element of state-of-the-art deep learning\napproaches. It enables to transform raw data into structured vector space\nembeddings. Such embeddings are able to capture the distributional semantics of\ntheir context, e.g. by word windows on natural language sentences, graph walks\non knowledge graphs or convolutions on images. So far, this context is manually\ndefined, resulting in heuristics which are solely optimized for computational\nperformance on certain tasks like link-prediction. However, such heuristic\nmodels of context are fundamentally different to how humans capture\ninformation. For instance, when reading a multi-modal webpage (i) humans do not\nperceive all parts of a document equally: Some words and parts of images are\nskipped, others are revisited several times which makes the perception trace\nhighly non-sequential; (ii) humans construct meaning from a document's content\nby shifting their attention between text and image, among other things, guided\nby layout and design elements. In this paper we empirically investigate the\ndifference between human perception and context heuristics of basic embedding\nmodels. We conduct eye tracking experiments to capture the underlying\ncharacteristics of human perception of media documents containing a mixture of\ntext and images. Based on that, we devise a prototypical computational\nperception-trace model, called CMPM. We evaluate empirically how CMPM can\nimprove a basic skip-gram embedding approach. Our results suggest, that even\nwith a basic human-inspired computational perception model, there is a huge\npotential for improving embeddings since such a model does inherently capture\nmultiple modalities, as well as layout and design elements.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 15:20:38 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Rettinger", "Achim", ""], ["Bogdanova", "Viktoria", ""], ["Niemann", "Philipp", ""]]}, {"id": "1910.08573", "submitter": "Gautier Cosne", "authors": "Gautier Cosne, Guillaume Maze, Pierre Tandeo", "title": "Coupling Oceanic Observation Systems to Study Mesoscale Ocean Dynamics", "comments": "Accepted as a workshop paper to NeurIPS 2019 Workshop 'Tackling\n  Climate Change with Machine Learning'", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding local currents in the North Atlantic region of the ocean is a\nkey part of modelling heat transfer and global climate patterns. Satellites\nprovide a surface signature of the temperature of the ocean with a high\nhorizontal resolution while in situ autonomous probes supply high vertical\nresolution, but horizontally sparse, knowledge of the ocean interior thermal\nstructure. The objective of this paper is to develop a methodology to combine\nthese complementary ocean observing systems measurements to obtain a\nthree-dimensional time series of ocean temperatures with high horizontal and\nvertical resolution. Within an observation-driven framework, we investigate the\nextent to which mesoscale ocean dynamics in the North Atlantic region may be\ndecomposed into a mixture of dynamical modes, characterized by different local\nregressions between Sea Surface Temperature (SST), Sea Level Anomalies (SLA)\nand Vertical Temperature fields. Ultimately we propose a Latent-class\nregression method to improve prediction of vertical ocean temperature.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 18:10:47 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Cosne", "Gautier", ""], ["Maze", "Guillaume", ""], ["Tandeo", "Pierre", ""]]}, {"id": "1910.08581", "submitter": "Shaeke Salman", "authors": "Shaeke Salman, Canlin Zhang, Xiuwen Liu, Washington Mio", "title": "Towards Quantifying Intrinsic Generalization of Deep ReLU Networks", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the underlying mechanisms that enable the empirical successes\nof deep neural networks is essential for further improving their performance\nand explaining such networks. Towards this goal, a specific question is how to\nexplain the \"surprising\" behavior of the same over-parametrized deep neural\nnetworks that can generalize well on real datasets and at the same time\n\"memorize\" training samples when the labels are randomized. In this paper, we\ndemonstrate that deep ReLU networks generalize from training samples to new\npoints via piece-wise linear interpolation. We provide a quantified analysis on\nthe generalization ability of a deep ReLU network: Given a fixed point\n$\\mathbf{x}$ and a fixed direction in the input space $\\mathcal{S}$, there is\nalways a segment such that any point on the segment will be classified the same\nas the fixed point $\\mathbf{x}$. We call this segment the $generalization \\\ninterval$. We show that the generalization intervals of a ReLU network behave\nsimilarly along pairwise directions between samples of the same label in both\nreal and random cases on the MNIST and CIFAR-10 datasets. This result suggests\nthat the same interpolation mechanism is used in both cases. Additionally, for\ndatasets using real labels, such networks provide a good approximation of the\nunderlying manifold in the data, where the changes are much smaller along\ntangent directions than along normal directions. On the other hand, however,\nfor datasets with random labels, generalization intervals along mid-lines of\ntriangles with the same label are much smaller than those on the datasets with\nreal labels, suggesting different behaviors along other directions. Our\nsystematic experiments demonstrate for the first time that such deep neural\nnetworks generalize through the same interpolation and explain the differences\nbetween their performance on datasets with real and random labels.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 18:38:22 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Salman", "Shaeke", ""], ["Zhang", "Canlin", ""], ["Liu", "Xiuwen", ""], ["Mio", "Washington", ""]]}, {"id": "1910.08589", "submitter": "Paul Scherer", "authors": "Paul Scherer, Helena Andres-Terre, Pietro Lio, Mateja Jamnik", "title": "Decoupling feature propagation from the design of graph auto-encoders", "comments": "4 pages (considering single anonymous naming during original\n  submission, now a few lines over 4). Originally submitted to NeurIPS 2019\n  Graph Representation Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two instances, L-GAE and L-VGAE, of the variational graph\nauto-encoding family (VGAE) based on separating feature propagation operations\nfrom graph convolution layers typically found in graph learning methods to a\nsingle linear matrix computation made prior to input in standard auto-encoder\narchitectures. This decoupling enables the independent and fixed design of the\nauto-encoder without requiring additional GCN layers for every desired increase\nin the size of a node's local receptive field. Fixing the auto-encoder enables\na fairer assessment on the size of a nodes receptive field in building\nrepresentations. Furthermore a by-product of fixing the auto-encoder design\noften results in substantially smaller networks than their VGAE counterparts\nespecially as we increase the number of feature propagations. A comparative\ndownstream evaluation on link prediction tasks show comparable state of the art\nperformance to similar VGAE arrangements despite considerable simplification.\nWe also show the simple application of our methodology to more challenging\nrepresentation learning scenarios such as spatio-temporal graph representation\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 19:01:41 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Scherer", "Paul", ""], ["Andres-Terre", "Helena", ""], ["Lio", "Pietro", ""], ["Jamnik", "Mateja", ""]]}, {"id": "1910.08590", "submitter": "Vien Van Mai", "authors": "Vien V. Mai and Mikael Johansson", "title": "Anderson Acceleration of Proximal Gradient Methods", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anderson acceleration is a well-established and simple technique for speeding\nup fixed-point computations with countless applications. Previous studies of\nAnderson acceleration in optimization have only been able to provide\nconvergence guarantees for unconstrained and smooth problems. This work\nintroduces novel methods for adapting Anderson acceleration to (non-smooth and\nconstrained) proximal gradient algorithms. Under some technical conditions, we\nextend the existing local convergence results of Anderson acceleration for\nsmooth fixed-point mappings to the proposed scheme. We also prove analytically\nthat it is not, in general, possible to guarantee global convergence of native\nAnderson acceleration. We therefore propose a simple scheme for stabilization\nthat combines the global worst-case guarantees of proximal gradient methods\nwith the local adaptation and practical speed-up of Anderson acceleration.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 19:05:00 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 15:14:39 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Mai", "Vien V.", ""], ["Johansson", "Mikael", ""]]}, {"id": "1910.08595", "submitter": "Brett Mullins", "authors": "Brett Mullins", "title": "Identifying the Most Explainable Classifier", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of pointwise coverage to measure the explainability\nproperties of machine learning classifiers. An explanation for a prediction is\na definably simple region of the feature space sharing the same label as the\nprediction, and the coverage of an explanation measures its size or\ngeneralizability. With this notion of explanation, we investigate whether or\nnot there is a natural characterization of the most explainable classifier.\nAccording with our intuitions, we prove that the binary linear classifier is\nuniquely the most explainable classifier up to negligible sets.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 19:24:38 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 22:05:02 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Mullins", "Brett", ""]]}, {"id": "1910.08597", "submitter": "Matteo Sordello", "authors": "Matteo Sordello, Hangfeng He and Weijie Su", "title": "Robust Learning Rate Selection for Stochastic Optimization via Splitting\n  Diagnostic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes SplitSGD, a new dynamic learning rate schedule for\nstochastic optimization. This method decreases the learning rate for better\nadaptation to the local geometry of the objective function whenever a\nstationary phase is detected, that is, the iterates are likely to bounce at\naround a vicinity of a local minimum. The detection is performed by splitting\nthe single thread into two and using the inner product of the gradients from\nthe two threads as a measure of stationarity. Owing to this simple yet provably\nvalid stationarity detection, SplitSGD is easy-to-implement and essentially\ndoes not incur additional computational cost than standard SGD. Through a\nseries of extensive experiments, we show that this method is appropriate for\nboth convex problems and training (non-convex) neural networks, with\nperformance compared favorably to other stochastic optimization methods.\nImportantly, this method is observed to be very robust with a set of default\nparameters for a wide range of problems and, moreover, yields better\ngeneralization performance than other adaptive gradient methods such as Adam.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 19:38:53 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 13:59:57 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 17:30:27 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 16:38:13 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Sordello", "Matteo", ""], ["He", "Hangfeng", ""], ["Su", "Weijie", ""]]}, {"id": "1910.08606", "submitter": "Chase Shimmin", "authors": "Benjamin Nachman and Chase Shimmin", "title": "AI Safety for High Energy Physics", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph cs.LG hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of high-energy physics (HEP), along with many scientific\ndisciplines, is currently experiencing a dramatic influx of new methodologies\npowered by modern machine learning techniques. Over the last few years, a\ngrowing body of HEP literature has focused on identifying promising\napplications of deep learning in particular, and more recently these techniques\nare starting to be realized in an increasing number of experimental\nmeasurements. The overall conclusion from this impressive and extensive set of\nstudies is that rarer and more complex physics signatures can be identified\nwith the new set of powerful tools from deep learning. However, there is an\nunstudied systematic risk associated with combining the traditional HEP\nworkflow and deep learning with high-dimensional data. In particular,\ncalibrating and validating the response of deep neural networks is in general\nnot experimentally feasible, and therefore current methods may be biased in\nways that are not covered by current uncertainty estimates. By borrowing ideas\nfrom AI safety, we illustrate these potential issues and propose a method to\nbound the size of unaccounted for uncertainty. In addition to providing a\npragmatic diagnostic, this work will hopefully begin a dialogue within the\ncommunity about the robust application of deep learning to experimental\nanalyses.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 19:54:42 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Nachman", "Benjamin", ""], ["Shimmin", "Chase", ""]]}, {"id": "1910.08613", "submitter": "Ali Girayhan Ozbay", "authors": "Ali Girayhan \\\"Ozbay, Arash Hamzehloo, Sylvain Laizet, Panagiotis\n  Tzirakis, Georgios Rizos, Bj\\\"orn Schuller", "title": "Poisson CNN: Convolutional neural networks for the solution of the\n  Poisson equation on a Cartesian mesh", "comments": "34 pages, 18 figures. Publ{\\i}shed in Data Centric Engineering. Code\n  available at https://github.com/aligirayhanozbay/poisson_CNN", "journal-ref": "Data-Centric Engineering. [Online] Cambridge University Press;\n  2021;2: e6", "doi": "10.1017/dce.2021.7", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Poisson equation is commonly encountered in engineering, for instance in\ncomputational fluid dynamics (CFD) where it is needed to compute corrections to\nthe pressure field to ensure the incompressibility of the velocity field. In\nthe present work, we propose a novel fully convolutional neural network (CNN)\narchitecture to infer the solution of the Poisson equation on a 2D Cartesian\ngrid with different resolutions given the right hand side term, arbitrary\nboundary conditions and grid parameters. It provides unprecedented versatility\nfor a CNN approach dealing with partial differential equations. The boundary\nconditions are handled using a novel approach by decomposing the original\nPoisson problem into a homogeneous Poisson problem plus four inhomogeneous\nLaplace sub-problems. The model is trained using a novel loss function\napproximating the continuous $L^p$ norm between the prediction and the target.\nEven when predicting on grids denser than previously encountered, our model\ndemonstrates encouraging capacity to reproduce the correct solution profile.\nThe proposed model, which outperforms well-known neural network models, can be\nincluded in a CFD solver to help with solving the Poisson equation. Analytical\ntest cases indicate that our CNN architecture is capable of predicting the\ncorrect solution of a Poisson problem with mean percentage errors below 10%, an\nimprovement by comparison to the first step of conventional iterative methods.\nPredictions from our model, used as the initial guess to iterative algorithms\nlike Multigrid, can reduce the RMS error after a single iteration by more than\n90% compared to a zero initial guess.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 20:29:20 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 10:33:36 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 11:00:46 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["\u00d6zbay", "Ali Girayhan", ""], ["Hamzehloo", "Arash", ""], ["Laizet", "Sylvain", ""], ["Tzirakis", "Panagiotis", ""], ["Rizos", "Georgios", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1910.08623", "submitter": "Yasaman Esfandiari", "authors": "Yasaman Esfandiari, Aditya Balu, Keivan Ebrahimi, Umesh Vaidya, Nicola\n  Elia, Soumik Sarkar", "title": "A Fast Saddle-Point Dynamical System Approach to Robust Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent focus on robustness to adversarial attacks for deep neural networks\nproduced a large variety of algorithms for training robust models. Most of the\neffective algorithms involve solving the min-max optimization problem for\ntraining robust models (min step) under worst-case attacks (max step). However,\nthey often suffer from high computational cost from running several inner\nmaximization iterations (to find an optimal attack) inside every outer\nminimization iteration. Therefore, it becomes difficult to readily apply such\nalgorithms for moderate to large size real world data sets. To alleviate this,\nwe explore the effectiveness of iterative descent-ascent algorithms where the\nmaximization and minimization steps are executed in an alternate fashion to\nsimultaneously obtain the worst-case attack and the corresponding robust model.\nSpecifically, we propose a novel discrete-time dynamical system-based algorithm\nthat aims to find the saddle point of a min-max optimization problem in the\npresence of uncertainties. Under the assumptions that the cost function is\nconvex and uncertainties enter concavely in the robust learning problem, we\nanalytically show that our algorithm converges asymptotically to the robust\noptimal solution under a general adversarial budget constraints as induced by\n$\\ell_p$ norm, for $1\\leq p\\leq \\infty$. Based on our proposed analysis, we\ndevise a fast robust training algorithm for deep neural networks. Although such\ntraining involves highly non-convex robust optimization problems, empirical\nresults show that the algorithm can achieve significant robustness compared to\nother state-of-the-art robust models on benchmark data sets.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 20:55:39 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 21:24:47 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 20:38:24 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Esfandiari", "Yasaman", ""], ["Balu", "Aditya", ""], ["Ebrahimi", "Keivan", ""], ["Vaidya", "Umesh", ""], ["Elia", "Nicola", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1910.08629", "submitter": "Yongfeng Zhang", "authors": "Shaoyun Shi, Hanxiong Chen, Min Zhang, Yongfeng Zhang", "title": "Neural Logic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the great success of deep neural networks in many\nresearch areas. The fundamental idea behind the design of most neural networks\nis to learn similarity patterns from data for prediction and inference, which\nlacks the ability of logical reasoning. However, the concrete ability of\nlogical reasoning is critical to many theoretical and practical problems. In\nthis paper, we propose Neural Logic Network (NLN), which is a dynamic neural\narchitecture that builds the computational graph according to input logical\nexpressions. It learns basic logical operations as neural modules, and conducts\npropositional logical reasoning through the network for inference. Experiments\non simulated data show that NLN achieves significant performance on solving\nlogical equations. Further experiments on real-world data show that NLN\nsignificantly outperforms state-of-the-art models on collaborative filtering\nand personalized recommendation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 01:53:37 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Shi", "Shaoyun", ""], ["Chen", "Hanxiong", ""], ["Zhang", "Min", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "1910.08635", "submitter": "Li Yang", "authors": "Li Yang, Abdallah Moubayed, Ismail Hamieh, Abdallah Shami", "title": "Tree-based Intelligent Intrusion Detection System in Internet of\n  Vehicles", "comments": "Accepted in IEEE Global Communications Conference (GLOBECOM) 2019", "journal-ref": null, "doi": "10.1109/GLOBECOM38437.2019.9013892", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of autonomous vehicles (AVs) is a promising technology in Intelligent\nTransportation Systems (ITSs) to improve safety and driving efficiency.\nVehicle-to-everything (V2X) technology enables communication among vehicles and\nother infrastructures. However, AVs and Internet of Vehicles (IoV) are\nvulnerable to different types of cyber-attacks such as denial of service,\nspoofing, and sniffing attacks. In this paper, an intelligent intrusion\ndetection system (IDS) is proposed based on tree-structure machine learning\nmodels. The results from the implementation of the proposed intrusion detection\nsystem on standard data sets indicate that the system has the ability to\nidentify various cyber-attacks in the AV networks. Furthermore, the proposed\nensemble learning and feature selection approaches enable the proposed system\nto achieve high detection rate and low computational cost simultaneously.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 21:35:33 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Yang", "Li", ""], ["Moubayed", "Abdallah", ""], ["Hamieh", "Ismail", ""], ["Shami", "Abdallah", ""]]}, {"id": "1910.08636", "submitter": "Mandana Samiei", "authors": "Mandana Samiei, Tobias W\\\"urfl, Tristan Deleu, Martin Weiss, Francis\n  Dutil, Thomas Fevens, Genevi\\`eve Boucher, Sebastien Lemieux, Joseph Paul\n  Cohen", "title": "The TCGA Meta-Dataset Clinical Benchmark", "comments": "5 Pages, Submitted to MLCB 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is bringing a paradigm shift to healthcare by changing the\nprocess of disease diagnosis and prognosis in clinics and hospitals. This\ndevelopment equips doctors and medical staff with tools to evaluate their\nhypotheses and hence make more precise decisions. Although most current\nresearch in the literature seeks to develop techniques and methods for\npredicting one particular clinical outcome, this approach is far from the\nreality of clinical decision making in which you have to consider several\nfactors simultaneously. In addition, it is difficult to follow the recent\nprogress concretely as there is a lack of consistency in benchmark datasets and\ntask definitions in the field of Genomics. To address the aforementioned\nissues, we provide a clinical Meta-Dataset derived from the publicly available\ndata hub called The Cancer Genome Atlas Program (TCGA) that contains 174 tasks.\nWe believe those tasks could be good proxy tasks to develop methods which can\nwork on a few samples of gene expression data. Also, learning to predict\nmultiple clinical variables using gene-expression data is an important task due\nto the variety of phenotypes in clinical problems and lack of samples for some\nof the rare variables. The defined tasks cover a wide range of clinical\nproblems including predicting tumor tissue site, white cell count, histological\ntype, family history of cancer, gender, and many others which we explain later\nin the paper. Each task represents an independent dataset. We use regression\nand neural network baselines for all the tasks using only 150 samples and\ncompare their performance.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 21:44:12 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Samiei", "Mandana", ""], ["W\u00fcrfl", "Tobias", ""], ["Deleu", "Tristan", ""], ["Weiss", "Martin", ""], ["Dutil", "Francis", ""], ["Fevens", "Thomas", ""], ["Boucher", "Genevi\u00e8ve", ""], ["Lemieux", "Sebastien", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "1910.08639", "submitter": "Ilya Kuzovkin", "authors": "Ashish Kumar, Toby Buckley, John B. Lanier, Qiaozhi Wang, Alicia\n  Kavelaars, Ilya Kuzovkin", "title": "OffWorld Gym: open-access physical robotics environment for real-world\n  reinforcement learning benchmark and research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Success stories of applied machine learning can be traced back to the\ndatasets and environments that were put forward as challenges for the\ncommunity. The challenge that the community sets as a benchmark is usually the\nchallenge that the community eventually solves. The ultimate challenge of\nreinforcement learning research is to train real agents to operate in the real\nenvironment, but until now there has not been a common real-world RL benchmark.\nIn this work, we present a prototype real-world environment from OffWorld Gym\n-- a collection of real-world environments for reinforcement learning in\nrobotics with free public remote access. Close integration into existing\necosystem allows the community to start using OffWorld Gym without any prior\nexperience in robotics and takes away the burden of managing a physical\nrobotics system, abstracting it under a familiar API. We introduce a navigation\ntask, where a robot has to reach a visual beacon on an uneven terrain using\nonly the camera input and provide baseline results in both the real environment\nand the simulated replica. To start training, visit https://gym.offworld.ai\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 21:58:24 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 08:51:54 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 05:19:37 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 02:59:34 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Kumar", "Ashish", ""], ["Buckley", "Toby", ""], ["Lanier", "John B.", ""], ["Wang", "Qiaozhi", ""], ["Kavelaars", "Alicia", ""], ["Kuzovkin", "Ilya", ""]]}, {"id": "1910.08640", "submitter": "Simran Kaur", "authors": "Simran Kaur, Jeremy Cohen, Zachary C. Lipton", "title": "Are Perceptually-Aligned Gradients a General Property of Robust\n  Classifiers?", "comments": "To appear in the \"Science Meets Engineering of Deep Learning\"\n  Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a standard convolutional neural network, optimizing over the input pixels\nto maximize the score of some target class will generally produce a\ngrainy-looking version of the original image. However, Santurkar et al. (2019)\ndemonstrated that for adversarially-trained neural networks, this optimization\nproduces images that uncannily resemble the target class. In this paper, we\nshow that these \"perceptually-aligned gradients\" also occur under randomized\nsmoothing, an alternative means of constructing adversarially-robust\nclassifiers. Our finding supports the hypothesis that perceptually-aligned\ngradients may be a general property of robust classifiers. We hope that our\nresults will inspire research aimed at explaining this link between\nperceptually-aligned gradients and adversarial robustness.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 22:02:41 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 16:02:06 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Kaur", "Simran", ""], ["Cohen", "Jeremy", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1910.08644", "submitter": "Fatima Batool", "authors": "Fatima Batool", "title": "Initialization methods for optimum average silhouette width clustering", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A unified clustering approach that can estimate number of clusters and\nproduce clustering against this number simultaneously is proposed. Average\nsilhouette width (ASW) is a widely used standard cluster quality index. A\ndistance based objective function that optimizes ASW for clustering is defined.\nThe proposed algorithm named as OSil, only, needs data observations as an input\nwithout any prior knowledge of the number of clusters. This work is about\nthorough investigation of the proposed methodology, its usefulness and\nlimitations. A vast spectrum of clustering structures were generated, and\nseveral well-known clustering methods including partitioning, hierarchical,\ndensity based, and spatial methods were consider as the competitor of the\nproposed methodology. Simulation reveals that OSil algorithm has shown superior\nperformance in terms of clustering quality than all clustering methods included\nin the study. OSil can find well separated, compact clusters and have shown\nbetter performance for the estimation of number of clusters as compared to\nseveral methods. Apart from the proposal of the new methodology and it's\ninvestigation the paper offers a systematic analysis on the estimation of\ncluster indices, some of which never appeared together in comparative\nsimulation setup before. The study offers many insightful findings useful for\nthe selection of the clustering methods and indices for clustering quality\nassessment.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 22:11:12 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 18:16:22 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 20:28:55 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Batool", "Fatima", ""]]}, {"id": "1910.08650", "submitter": "Mahdieh Abbasi", "authors": "Mahdieh Abbasi, Changjian Shui, Arezoo Rajabi, Christian Gagne, Rakesh\n  Bobba", "title": "Toward Metrics for Differentiating Out-of-Distribution Sets", "comments": "Workshop on Safety and Robustness in Decision Making, NeurIPS 2019", "journal-ref": "ECAI 2020 : 24th European Conference on Artificial Intelligence", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vanilla CNNs, as uncalibrated classifiers, suffer from classifying\nout-of-distribution (OOD) samples nearly as confidently as in-distribution\nsamples. To tackle this challenge, some recent works have demonstrated the\ngains of leveraging available OOD sets for training end-to-end calibrated CNNs.\nHowever, a critical question remains unanswered in these works: how to\ndifferentiate OOD sets for selecting the most effective one(s) that induce\ntraining such CNNs with high detection rates on unseen OOD sets? To address\nthis pivotal question, we provide a criterion based on generalization errors of\nAugmented-CNN, a vanilla CNN with an added extra class employed for rejection,\non in-distribution and unseen OOD sets. However, selecting the most effective\nOOD set by directly optimizing this criterion incurs a huge computational cost.\nInstead, we propose three novel computationally-efficient metrics for\ndifferentiating between OOD sets according to their \"protection\" level of\nin-distribution sub-manifolds. We empirically verify that the most protective\nOOD sets -- selected according to our metrics -- lead to A-CNNs with\nsignificantly lower generalization errors than the A-CNNs trained on the least\nprotective ones. We also empirically show the effectiveness of a protective OOD\nset for training well-generalized confidence-calibrated vanilla CNNs. These\nresults confirm that 1) all OOD sets are not equally effective for training\nwell-performing end-to-end models (i.e., A-CNNs and calibrated CNNs) for OOD\ndetection tasks and 2) the protection level of OOD sets is a viable factor for\nrecognizing the most effective one. Finally, across the image classification\ntasks, we exhibit A-CNN trained on the most protective OOD set can also detect\nblack-box FGS adversarial examples as their distance (measured by our metrics)\nis becoming larger from the protected sub-manifolds.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 22:26:49 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 17:33:37 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 16:15:21 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Abbasi", "Mahdieh", ""], ["Shui", "Changjian", ""], ["Rajabi", "Arezoo", ""], ["Gagne", "Christian", ""], ["Bobba", "Rakesh", ""]]}, {"id": "1910.08654", "submitter": "Tomasz Kornuta", "authors": "Tomasz Kornuta", "title": "PyTorchPipe: a framework for rapid prototyping of pipelines combining\n  language and vision", "comments": "Paper accepted for SysML 2019 workshop at 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to vast amounts of data along with affordable computational power\nstimulated the reincarnation of neural networks. The progress could not be\nachieved without adequate software tools, lowering the entry bar for the next\ngenerations of researchers and developers. The paper introduces PyTorchPipe\n(PTP), a framework built on top of PyTorch. Answering the recent needs and\ntrends in machine learning, PTP facilitates building and training of complex,\nmulti-modal models combining language and vision (but is not limited to those\ntwo modalities). At its core, PTP employs a component-oriented approach and\nrelies on the concept of a pipeline, defined as a directed acyclic graph of\nloosely coupled components. A user defines a pipeline using yaml-based (thus\nhuman-readable) configuration files, whereas PTP provides generic workers for\ntheir loading, training, and testing using all the computational power (CPUs\nand GPUs) that is available to the user. The paper covers the main concepts of\nPyTorchPipe, discusses its key features and briefly presents the currently\nimplemented tasks, models and components.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 22:46:37 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Kornuta", "Tomasz", ""]]}, {"id": "1910.08655", "submitter": "Ren Hu", "authors": "Ren Hu, QiFeng Li", "title": "Ensemble learning based linear power flow", "comments": "5 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops an ensemble learning-based linearization approach for\npower flow, which differs from the network-parameter based direct current (DC)\npower flow or other extended versions of linearization. As a novel data-driven\nlinearization through data mining, it firstly applies the polynomial regression\n(PR) as a basic learner to capture the linear relationships between the bus\nvoltage as the independent variable and the active or reactive power as the\ndependent variable in rectangular coordinates. Then, gradient boosting (GB) and\nbagging as ensemble learning methods are introduced to combine all basic\nlearners to boost the model performance. The fitted linear power flow model is\nalso relaxed to compute the optimal power flow (OPF). The simulating results of\nstandard IEEE cases indicate that (1) ensemble learning methods outperform PR\nand GB works better than bagging; (2) as for solving OPF, the data-driven model\nexcels the DC model and the SDP relaxation in the computational accuracy, and\nworks faster than ACOPF and SDPOPF.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 23:04:41 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Hu", "Ren", ""], ["Li", "QiFeng", ""]]}, {"id": "1910.08657", "submitter": "Nesreen Ahmed", "authors": "Nesreen K. Ahmed, Nick Duffield, Ryan A. Rossi", "title": "Temporal Network Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal networks representing a stream of timestamped edges are seemingly\nubiquitous in the real-world. However, the massive size and continuous nature\nof these networks make them fundamentally challenging to analyze and leverage\nfor descriptive and predictive modeling tasks. In this work, we propose a\ngeneral framework for temporal network sampling with unbiased estimation. We\ndevelop online, single-pass sampling algorithms and unbiased estimators for\ntemporal network sampling. The proposed algorithms enable fast, accurate, and\nmemory-efficient statistical estimation of temporal network patterns and\nproperties. In addition, we propose a temporally decaying sampling algorithm\nwith unbiased estimators for studying networks that evolve in continuous time,\nwhere the strength of links is a function of time, and the motif patterns are\ntemporally-weighted. In contrast to the prior notion of a $\\bigtriangleup\nt$-temporal motif, the proposed formulation and algorithms for counting\ntemporally weighted motifs are useful for forecasting tasks in networks such as\npredicting future links, or a future time-series variable of nodes and links.\nFinally, extensive experiments on a variety of temporal networks from different\ndomains demonstrate the effectiveness of the proposed algorithms. A detailed\nablation study is provided to understand the impact of the various components\nof the proposed framework.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 23:10:18 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 02:47:15 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Ahmed", "Nesreen K.", ""], ["Duffield", "Nick", ""], ["Rossi", "Ryan A.", ""]]}, {"id": "1910.08663", "submitter": "Kevin Hsieh", "authors": "Kevin Hsieh", "title": "Machine Learning Systems for Highly-Distributed and Rapidly-Growing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usability and practicality of any machine learning (ML) applications are\nlargely influenced by two critical but hard-to-attain factors: low latency and\nlow cost. Unfortunately, achieving low latency and low cost is very challenging\nwhen ML depends on real-world data that are highly distributed and rapidly\ngrowing (e.g., data collected by mobile phones and video cameras all over the\nworld). Such real-world data pose many challenges in communication and\ncomputation. For example, when training data are distributed across data\ncenters that span multiple continents, communication among data centers can\neasily overwhelm the limited wide-area network bandwidth, leading to\nprohibitively high latency and high cost.\n  In this dissertation, we demonstrate that the latency and cost of ML on\nhighly-distributed and rapidly-growing data can be improved by one to two\norders of magnitude by designing ML systems that exploit the characteristics of\nML algorithms, ML model structures, and ML training/serving data. We support\nthis thesis statement with three contributions. First, we design a system that\nprovides both low-latency and low-cost ML serving (inferencing) over\nlarge-scale and continuously-growing datasets, such as videos. Second, we build\na system that makes ML training over geo-distributed datasets as fast as\ntraining within a single data center. Third, we present a first detailed study\nand a system-level solution on a fundamental and largely overlooked problem: ML\ntraining over non-IID (i.e., not independent and identically distributed) data\npartitions (e.g., facial images collected by cameras varies according to the\ndemographics of each camera's location).\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 23:59:00 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Hsieh", "Kevin", ""]]}, {"id": "1910.08665", "submitter": "Abhishek Singh", "authors": "Abhishek Singh, Anubhav Garg, Jinan Zhou, Shiv Ram Dubey, Debo Dutta", "title": "NASIB: Neural Architecture Search withIn Budget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) represents a class of methods to generate\nthe optimal neural network architecture and typically iterate over candidate\narchitectures till convergence over some particular metric like validation\nloss. They are constrained by the available computation resources, especially\nin enterprise environments. In this paper, we propose a new approach for NAS,\ncalled NASIB, which adapts and attunes to the computation resources (budget)\navailable by varying the exploration vs. exploitation trade-off. We reduce the\nexpert bias by searching over an augmented search space induced by\nSuperkernels. The proposed method can provide the architecture search useful\nfor different computation resources and different domains beyond image\nclassification of natural images where we lack bespoke architecture motifs and\ndomain expertise. We show, on CIFAR10, that itis possible to search over a\nspace that comprises of 12x more candidate operations than the traditional\nprior art in just 1.5 GPU days, while reaching close to state of the art\naccuracy. While our method searches over an exponentially larger search space,\nit could lead to novel architectures that require lesser domain expertise,\ncompared to the majority of the existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 00:12:39 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Singh", "Abhishek", ""], ["Garg", "Anubhav", ""], ["Zhou", "Jinan", ""], ["Dubey", "Shiv Ram", ""], ["Dutta", "Debo", ""]]}, {"id": "1910.08670", "submitter": "Feras Batarseh", "authors": "Feras A. Batarseh and Ajay Kulkarni", "title": "Context-Driven Data Mining through Bias Removal and Data Incompleteness\n  Mitigation", "comments": "1st Workshop on Evaluation and Experimental Design in Data Mining and\n  Machine Learning (EDML 2019) At SIAM - Society for Industrial and Applied\n  Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The results of data mining endeavors are majorly driven by data quality.\nThroughout these deployments, serious show-stopper problems are still\nunresolved, such as: data collection ambiguities, data imbalance, hidden biases\nin data, the lack of domain information, and data incompleteness. This paper is\nbased on the premise that context can aid in mitigating these issues. In a\ntraditional data science lifecycle, context is not considered. Context-driven\nData Science Lifecycle (C-DSL); the main contribution of this paper, is\ndeveloped to address these challenges. Two case studies (using data-sets from\nsports events) are developed to test C-DSL. Results from both case studies are\nevaluated using common data mining metrics such as: coefficient of\ndetermination (R2 value) and confusion matrices. The work presented in this\npaper aims to re-define the lifecycle and introduce tangible improvements to\nits outcomes.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 00:42:46 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Batarseh", "Feras A.", ""], ["Kulkarni", "Ajay", ""]]}, {"id": "1910.08683", "submitter": "Elham Azari", "authors": "Elham Azari and Sarma Vrudhula", "title": "ELSA: A Throughput-Optimized Design of an LSTM Accelerator for\n  Energy-Constrained Devices", "comments": null, "journal-ref": null, "doi": "10.1145/3366634", "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next significant step in the evolution and proliferation of artificial\nintelligence technology will be the integration of neural network (NN) models\nwithin embedded and mobile systems. This calls for the design of compact,\nenergy efficient NN models in silicon. In this paper, we present a scalable\nASIC design of an LSTM accelerator named ELSA, that is suitable for\nenergy-constrained devices. It includes several architectural innovations to\nachieve small area and high energy efficiency. To reduce the area and power\nconsumption of the overall design, the compute-intensive units of ELSA employ\napproximate multiplications and still achieve high performance and accuracy.\nThe performance is further improved through efficient synchronization of the\nelastic pipeline stages to maximize the utilization. The paper also includes a\nperformance model of ELSA, as a function of the hidden nodes and time steps,\npermitting its use for the evaluation of any LSTM application. ELSA was\nimplemented in RTL and was synthesized and placed and routed in 65nm\ntechnology. Its functionality is demonstrated for language modeling-a common\napplication of LSTM. ELSA is compared against a baseline implementation of an\nLSTM accelerator with standard functional units and without any of the\narchitectural innovations of ELSA. The paper demonstrates that ELSA can achieve\nsignificant improvements in power, area and energy-efficiency when compared to\nthe baseline design and several ASIC implementations reported in the\nliterature, making it suitable for use in embedded systems and real-time\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 02:49:50 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Azari", "Elham", ""], ["Vrudhula", "Sarma", ""]]}, {"id": "1910.08685", "submitter": "Deepali Aneja", "authors": "Deepali Aneja and Wilmot Li", "title": "Real-Time Lip Sync for Live 2D Animation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of commercial tools for real-time performance-based 2D\nanimation has enabled 2D characters to appear on live broadcasts and streaming\nplatforms. A key requirement for live animation is fast and accurate lip sync\nthat allows characters to respond naturally to other actors or the audience\nthrough the voice of a human performer. In this work, we present a deep\nlearning based interactive system that automatically generates live lip sync\nfor layered 2D characters using a Long Short Term Memory (LSTM) model. Our\nsystem takes streaming audio as input and produces viseme sequences with less\nthan 200ms of latency (including processing time). Our contributions include\nspecific design decisions for our feature definition and LSTM configuration\nthat provide a small but useful amount of lookahead to produce accurate lip\nsync. We also describe a data augmentation procedure that allows us to achieve\ngood results with a very small amount of hand-animated training data (13-20\nminutes). Extensive human judgement experiments show that our results are\npreferred over several competing methods, including those that only support\noffline (non-live) processing. Video summary and supplementary results at\nGitHub link: https://github.com/deepalianeja/CharacterLipSync2D\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 03:12:26 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Aneja", "Deepali", ""], ["Li", "Wilmot", ""]]}, {"id": "1910.08693", "submitter": "Yunzong Xu", "authors": "Jinzhi Bu, David Simchi-Levi, Yunzong Xu", "title": "Online Pricing with Offline Data: Phase Transition and Inverse Square\n  Law", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the impact of pre-existing offline data on online\nlearning, in the context of dynamic pricing. We study a single-product dynamic\npricing problem over a selling horizon of $T$ periods. The demand in each\nperiod is determined by the price of the product according to a linear demand\nmodel with unknown parameters. We assume that before the start of the selling\nhorizon, the seller already has some pre-existing offline data. The offline\ndata set contains $n$ samples, each of which is an input-output pair consisting\nof a historical price and an associated demand observation. The seller wants to\nutilize both the pre-existing offline data and the sequential online data to\nminimize the regret of the online learning process.\n  We characterize the joint effect of the size, location and dispersion of the\noffline data on the optimal regret of the online learning process.\nSpecifically, the size, location and dispersion of the offline data are\nmeasured by the number of historical samples $n$, the absolute difference\nbetween the average historical price and the optimal price $\\delta$, and the\nstandard deviation of the historical prices $\\sigma$, respectively. We show\nthat the optimal regret is $\\widetilde \\Theta\\left(\\sqrt{T}\\wedge\n\\frac{T}{(n\\wedge T)\\delta^2+n\\sigma^2}\\right)$, and design a learning\nalgorithm based on the \"optimism in the face of uncertainty\" principle, whose\nregret is optimal up to a logarithmic factor. Our results reveal surprising\ntransformations of the optimal regret rate with respect to the size of the\noffline data, which we refer to as phase transitions. In addition, our results\ndemonstrate that the location and dispersion of the offline data also have an\nintrinsic effect on the optimal regret, and we quantify this effect via the\ninverse-square law.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 03:36:05 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 23:46:13 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 23:08:11 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 02:41:42 GMT"}, {"version": "v5", "created": "Sat, 2 May 2020 20:55:34 GMT"}, {"version": "v6", "created": "Thu, 20 Aug 2020 03:56:05 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Bu", "Jinzhi", ""], ["Simchi-Levi", "David", ""], ["Xu", "Yunzong", ""]]}, {"id": "1910.08697", "submitter": "Chenfei Shi", "authors": "Chenfei Shi, Yan Xue, Chuan Jiang, Hui Tian, Bei Liu", "title": "Gastroscopic Panoramic View: Application to Automatic Polyps Detection\n  under Gastroscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endoscopic diagnosis is an important means for gastric polyp detection. In\nthis paper, a panoramic image of gastroscopy is developed, which can display\nthe inner surface of the stomach intuitively and comprehensively. Moreover, the\nproposed automatic detection solution can help doctors locate the polyps\nautomatically, and reduce missed diagnosis. The main contributions of this\npaper are: firstly, a gastroscopic panorama reconstruction method is developed.\nThe reconstruction does not require additional hardware devices, and can solve\nthe problem of texture dislocation and illumination imbalance properly;\nsecondly, an end-to-end multi-object detection for gastroscopic panorama is\ntrained based on deep learning framework. Compared with traditional solutions,\nthe automatic polyp detection system can locate all polyps in the inner wall of\nstomach in real time and assist doctors to find the lesions. Thirdly, the\nsystem was evaluated in the Affiliated Hospital of Zhejiang University. The\nresults show that the average error of the panorama is less than 2 mm, the\naccuracy of the polyp detection is 95%, and the recall rate is 99%. In\naddition, the research roadmap of this paper has guiding significance for\nendoscopy-assisted detection of other human soft cavities.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 04:07:00 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Shi", "Chenfei", ""], ["Xue", "Yan", ""], ["Jiang", "Chuan", ""], ["Tian", "Hui", ""], ["Liu", "Bei", ""]]}, {"id": "1910.08701", "submitter": "Mert G\\\"urb\\\"uzbalaban", "authors": "Alireza Fallah, Mert Gurbuzbalaban, Asuman Ozdaglar, Umut Simsekli,\n  Lingjiong Zhu", "title": "Robust Distributed Accelerated Stochastic Gradient Methods for\n  Multi-Agent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed stochastic gradient (D-SG) method and its accelerated\nvariant (D-ASG) for solving decentralized strongly convex stochastic\noptimization problems where the objective function is distributed over several\ncomputational units, lying on a fixed but arbitrary connected communication\ngraph, subject to local communication constraints where noisy estimates of the\ngradients are available. We develop a framework which allows to choose the\nstepsize and the momentum parameters of these algorithms in a way to optimize\nperformance by systematically trading off the bias, variance, robustness to\ngradient noise and dependence to network effects. When gradients do not contain\nnoise, we also prove that distributed accelerated methods can \\emph{achieve\nacceleration}, requiring $\\mathcal{O}(\\kappa \\log(1/\\varepsilon))$ gradient\nevaluations and $\\mathcal{O}(\\kappa \\log(1/\\varepsilon))$ communications to\nconverge to the same fixed point with the non-accelerated variant where\n$\\kappa$ is the condition number and $\\varepsilon$ is the target accuracy. To\nour knowledge, this is the first acceleration result where the iteration\ncomplexity scales with the square root of the condition number in the context\nof \\emph{primal} distributed inexact first-order methods. For quadratic\nfunctions, we also provide finer performance bounds that are tight with respect\nto bias and variance terms. Finally, we study a multistage version of D-ASG\nwith parameters carefully varied over stages to ensure exact\n$\\mathcal{O}(-k/\\sqrt{\\kappa})$ linear decay in the bias term as well as\noptimal $\\mathcal{O}(\\sigma^2/k)$ in the variance term. We illustrate through\nnumerical experiments that our approach results in practical algorithms that\nare robust to gradient noise and that can outperform existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 04:17:29 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 18:19:52 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 17:03:20 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Fallah", "Alireza", ""], ["Gurbuzbalaban", "Mert", ""], ["Ozdaglar", "Asuman", ""], ["Simsekli", "Umut", ""], ["Zhu", "Lingjiong", ""]]}, {"id": "1910.08707", "submitter": "Ibrahim Jubran", "authors": "Ibrahim Jubran, Alaa Maalouf, Dan Feldman", "title": "Introduction to Coresets: Accurate Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A coreset (or core-set) of an input set is its small summation, such that\nsolving a problem on the coreset as its input, provably yields the same result\nas solving the same problem on the original (full) set, for a given family of\nproblems (models, classifiers, loss functions). Over the past decade, coreset\nconstruction algorithms have been suggested for many fundamental problems in\ne.g. machine/deep learning, computer vision, graphics, databases, and\ntheoretical computer science. This introductory paper was written following\nrequests from (usually non-expert, but also colleagues) regarding the many\ninconsistent coreset definitions, lack of available source code, the required\ndeep theoretical background from different fields, and the dense papers that\nmake it hard for beginners to apply coresets and develop new ones.\n  The paper provides folklore, classic and simple results including\nstep-by-step proofs and figures, for the simplest (accurate) coresets of very\nbasic problems, such as: sum of vectors, minimum enclosing ball, SVD/ PCA and\nlinear regression. Nevertheless, we did not find most of their constructions in\nthe literature. Moreover, we expect that putting them together in a\nretrospective context would help the reader to grasp modern results that\nusually extend and generalize these fundamental observations. Experts might\nappreciate the unified notation and comparison table that links between\nexisting results.\n  Open source code with example scripts are provided for all the presented\nalgorithms, to demonstrate their practical usage, and to support the readers\nwho are more familiar with programming than math.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 05:45:36 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jubran", "Ibrahim", ""], ["Maalouf", "Alaa", ""], ["Feldman", "Dan", ""]]}, {"id": "1910.08713", "submitter": "Muhammad Aslam Jarwar", "authors": "Sajjad Ali, Muhammad Aslam Jarwar, Ilyoung Chong", "title": "Microservices based Framework to Support Interoperable IoT Applications\n  for Enhanced Data Analytics", "comments": "Proceedings of Symposium of the Korean Institute of communications\n  and Information Sciences , 2019.1, 636-639", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet of things is growing with a large number of diverse objects which\ngenerate billions of data streams by sensing, actuating and communicating.\nManagement of heterogeneous IoT objects with existing approaches and processing\nof myriads of data from these objects using monolithic services have become\nmajor challenges in developing effective IoT applications. The heterogeneity\ncan be resolved by providing interoperability with semantic virtualization of\nobjects. Moreover, monolithic services can be substituted with modular\nmicroservices. This article presents an architecture that enables the\ndevelopment of IoT applications using semantically interoperable microservices\nand virtual objects. The proposed framework supports analytic features with\nknowledge-driven and data-driven techniques to provision intelligent services\non top of interoperable microservices in Web Objects enabled IoT environment.\nThe knowledge-driven aspects are supported with reasoning on semantic ontology\nmodels and the data-driven aspects are realized with machine learning pipeline.\nThe development of service functionalities is supported with microservices to\nenhance modularity and reusability. To evaluate the proposed framework a proof\nof concept implementation with a use case is discussed.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 06:59:16 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Ali", "Sajjad", ""], ["Jarwar", "Muhammad Aslam", ""], ["Chong", "Ilyoung", ""]]}, {"id": "1910.08719", "submitter": "Hareesh Kumar", "authors": "Hareesh Kumar, Priyanka Mary Mammen, Krithi Ramamritham", "title": "Explainable AI: Deep Reinforcement Learning Agents for Residential\n  Demand Side Cost Savings in Smart Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by recent advancements in Deep Reinforcement Learning (RL), we have\ndeveloped an RL agent to manage the operation of storage devices in a household\nand is designed to maximize demand-side cost savings. The proposed technique is\ndata-driven, and the RL agent learns from scratch how to efficiently use the\nenergy storage device given variable tariff structures. In most of the studies,\nthe RL agent is considered as a black box, and how the agent has learned is\noften ignored. We explain the learning progression of the RL agent, and the\nstrategies it follows based on the capacity of the storage device.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 07:57:54 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 17:39:15 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Kumar", "Hareesh", ""], ["Mammen", "Priyanka Mary", ""], ["Ramamritham", "Krithi", ""]]}, {"id": "1910.08720", "submitter": "Dmitry Kopitkov", "authors": "Dmitry Kopitkov and Vadim Indelman", "title": "Neural Spectrum Alignment: Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expressiveness and generalization of deep models was recently addressed via\nthe connection between neural networks (NNs) and kernel learning, where\nfirst-order dynamics of NN during a gradient-descent (GD) optimization were\nrelated to gradient similarity kernel, also known as Neural Tangent Kernel\n(NTK). In the majority of works this kernel is considered to be time-invariant,\nwith its properties being defined entirely by NN architecture and independent\nof the learning task at hand. In contrast, in this paper we empirically explore\nthese properties along the optimization and show that in practical applications\nthe NTK changes in a very dramatic and meaningful way, with its top\neigenfunctions aligning toward the target function learned by NN. Moreover,\nthese top eigenfunctions serve as basis functions for NN output - a function\nrepresented by NN is spanned almost completely by them for the entire\noptimization process. Further, since the learning along top eigenfunctions is\ntypically fast, their alignment with the target function improves the overall\noptimization performance. In addition, we study how the neural spectrum is\naffected by learning rate decay, typically done by practitioners, showing\nvarious trends in the kernel behavior. We argue that the presented phenomena\nmay lead to a more complete theoretical understanding behind NN learning.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 08:02:26 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 15:26:05 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 12:43:32 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Kopitkov", "Dmitry", ""], ["Indelman", "Vadim", ""]]}, {"id": "1910.08734", "submitter": "Leye Wang", "authors": "Xiao Han, Ruiqing Ding, Leye Wang, Hailiang Huang", "title": "CreditPrint: Credit Investigation via Geographic Footprints by Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit investigation is critical for financial services. Whereas, traditional\nmethods are often restricted as the employed data hardly provide sufficient,\ntimely and reliable information. With the prevalence of smart mobile devices,\npeoples' geographic footprints can be automatically and constantly collected\nnowadays, which provides an unprecedented opportunity for credit\ninvestigations. Inspired by the observation that locations are somehow related\nto peoples' credit level, this research aims to enhance credit investigation\nwith users' geographic footprints. To this end, a two-stage credit\ninvestigation framework is designed, namely CreditPrint. In the first stage,\nCreditPrint explores regions' credit characteristics and learns a credit-aware\nembedding for each region by considering both each region's individual\ncharacteristics and cross-region relationships with graph convolutional\nnetworks. In the second stage, a hierarchical attention-based credit assessment\nnetwork is proposed to aggregate the credit indications from a user's multiple\ntrajectories covering diverse regions. The results on real-life user mobility\ndatasets show that CreditPrint can increase the credit investigation accuracy\nby up to 10% compared to baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 09:48:50 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Han", "Xiao", ""], ["Ding", "Ruiqing", ""], ["Wang", "Leye", ""], ["Huang", "Hailiang", ""]]}, {"id": "1910.08747", "submitter": "Hu Weizhen", "authors": "Min Jiang, Weizhen Hu, Liming Qiu, Minghui Shi, Kay Chen Tan", "title": "Solving dynamic multi-objective optimization problems via support vector\n  machine", "comments": null, "journal-ref": null, "doi": "10.1109/ICACI.2018.8377567", "report-no": null, "categories": "cs.AI cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Multi-objective Optimization Problems (DMOPs) refer to optimization\nproblems that objective functions will change with time. Solving DMOPs implies\nthat the Pareto Optimal Set (POS) at different moments can be accurately found,\nand this is a very difficult job due to the dynamics of the optimization\nproblems. The POS that have been obtained in the past can help us to find the\nPOS of the next time more quickly and accurately. Therefore, in this paper we\npresent a Support Vector Machine (SVM) based Dynamic Multi-Objective\nEvolutionary optimization Algorithm, called SVM-DMOEA. The algorithm uses the\nPOS that has been obtained to train a SVM and then take the trained SVM to\nclassify the solutions of the dynamic optimization problem at the next moment,\nand thus it is able to generate an initial population which consists of\ndifferent individuals recognized by the trained SVM. The initial populuation\ncan be fed into any population based optimization algorithm, e.g., the\nNondominated Sorting Genetic Algorithm II (NSGA-II), to get the POS at that\nmoment. The experimental results show the validity of our proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 11:06:33 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jiang", "Min", ""], ["Hu", "Weizhen", ""], ["Qiu", "Liming", ""], ["Shi", "Minghui", ""], ["Tan", "Kay Chen", ""]]}, {"id": "1910.08771", "submitter": "Yuan Tian", "authors": "Yuan Tian", "title": "Convex Reconstruction of Structured Matrix Signals from Linear\n  Measurements (I): Theoretical Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG eess.SP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of reconstructing n-by-n structured matrix signal\nX via convex programming, where each column xj is a vector of s-sparsity and\nall columns have the same l1-norm. The regularizer in use is matrix norm\n|||X|||1=maxj|xj|1.The contribution in this paper has two parts. The first part\nis about conditions for stability and robustness in signal reconstruction via\nsolving the convex programming from noise-free or noisy measurements.We\nestablish uniform sufficient conditions which are very close to necessary\nconditions and non-uniform conditions are also discussed. Similar as the\ntraditional compressive sensing theory for reconstructing vector signals, a\nrelated RIP condition is established. In addition, stronger conditions are\ninvestigated to guarantee the reconstructed signal's support stability, sign\nstability and approximation-error robustness. The second part is to establish\nupper and lower bounds on number of measurements for robust reconstruction in\nnoise. We take the convex geometric approach in random measurement setting and\none of the critical ingredients in this approach is to estimate the related\nwidths bounds in case of Gaussian and non-Gaussian distributions. These bounds\nare explicitly controlled by signal's structural parameters r and s which\ndetermine matrix signal's column-wise sparsity and l1-column-flatness\nrespectively.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 13:44:55 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 10:11:09 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 14:01:36 GMT"}, {"version": "v4", "created": "Sun, 1 Dec 2019 11:01:10 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Tian", "Yuan", ""]]}, {"id": "1910.08778", "submitter": "Alex Markham", "authors": "Alex Markham and Moritz Grosse-Wentrup", "title": "Measurement Dependence Inducing Latent Causal Models", "comments": "10 pages, 5 figures; presented at UAI 2020; changes from previous\n  version: updated abstract, fixed errors due to TeX compilation of UAI notice\n  and page numbers in some references, added published proceedings reference", "journal-ref": "Proceedings of the 36th Conference on Uncertainty in Artificial\n  Intelligence (UAI), PMLR 124:590-599, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of causal structure learning over measurement dependence\ninducing latent (MeDIL) causal models. We show that this task can be framed in\nterms of the graph theoretic problem of finding edge clique covers,resulting in\nan algorithm for returning minimal MeDIL causal models (minMCMs). This\nalgorithm is non-parametric, requiring no assumptions about linearity or\nGaussianity. Furthermore, despite rather weak assumptions aboutthe class of\nMeDIL causal models, we show that minimality in minMCMs implies some rather\nspecific and interesting properties. By establishing MeDIL causal models as a\nsemantics for edge clique covers, we also provide a starting point for future\nwork further connecting causal structure learning to developments in graph\ntheory and network science.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 14:21:54 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 18:43:45 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 10:48:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Markham", "Alex", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "1910.08780", "submitter": "Egor Rotinov", "authors": "Egor Rotinov", "title": "Reverse Experience Replay", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes an improvement in Deep Q-learning called Reverse\nExperience Replay (also RER) that solves the problem of sparse rewards and\nhelps to deal with reward maximizing tasks by sampling transitions successively\nin reverse order. On tasks with enough experience for training and enough\nExperience Replay memory capacity, Deep Q-learning Network with Reverse\nExperience Replay shows competitive results against both Double DQN, with a\nstandard Experience Replay, and vanilla DQN. Also, RER achieves significantly\nincreased results in tasks with a lack of experience and Replay memory\ncapacity.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 14:37:13 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 18:13:59 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Rotinov", "Egor", ""]]}, {"id": "1910.08790", "submitter": "Megh Shukla", "authors": "Megh Shukla, Biplab Banerjee, Krishna Mohan Buddhiraju", "title": "LEt-SNE: A Hybrid Approach To Data Embedding and Visualization of\n  Hyperspectral Imagery", "comments": "Accepted, ICASSP 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053924", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral Imagery (and Remote Sensing in general) captured from UAVs or\nsatellites are highly voluminous in nature due to the large spatial extent and\nwavelengths captured by them. Since analyzing these images requires a huge\namount of computational time and power, various dimensionality reduction\ntechniques have been used for feature reduction. Some popular techniques among\nthese falter when applied to Hyperspectral Imagery due to the famed curse of\ndimensionality. In this paper, we propose a novel approach, LEt-SNE, which\ncombines graph based algorithms like t-SNE and Laplacian Eigenmaps into a model\nparameterized by a shallow feed forward network. We introduce a new term,\nCompression Factor, that enables our method to combat the curse of\ndimensionality. The proposed algorithm is suitable for manifold visualization\nand sample clustering with labelled or unlabelled data. We demonstrate that our\nmethod is competitive with current state-of-the-art methods on hyperspectral\nremote sensing datasets in public domain.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 15:45:15 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 17:02:12 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Shukla", "Megh", ""], ["Banerjee", "Biplab", ""], ["Buddhiraju", "Krishna Mohan", ""]]}, {"id": "1910.08795", "submitter": "Ekhine Irurozki", "authors": "Ekhine Irurozki, Jesus Lobo, Aritz Perez, Javier Del Ser", "title": "Rank aggregation for non-stationary data streams", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning over non-stationary ranking streams. The\nrankings can be interpreted as the preferences of a population and the\nnon-stationarity means that the distribution of preferences changes over time.\nOur goal is to learn, in an online manner, the current distribution of\nrankings. The bottleneck of this process is a rank aggregation problem.\n  We propose a generalization of the Borda algorithm for non-stationary ranking\nstreams. Moreover, we give bounds on the minimum number of samples required to\noutput the ground truth with high probability. Besides, we show how the optimal\nparameters are set. Then, we generalize the whole family of weighted voting\nrules (the family to which Borda belongs) to situations in which some rankings\nare more \\textit{reliable} than others and show that this generalization can\nsolve the problem of rank aggregation over non-stationary data streams.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 16:08:01 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 07:30:00 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 13:51:34 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Irurozki", "Ekhine", ""], ["Lobo", "Jesus", ""], ["Perez", "Aritz", ""], ["Del Ser", "Javier", ""]]}, {"id": "1910.08798", "submitter": "Changpeng Shao", "authors": "Changpeng Shao", "title": "Data classification by quantum radial basis function networks", "comments": "9 pages, 8 figures", "journal-ref": "Phys. Rev. A 102, 042418 (2020)", "doi": "10.1103/PhysRevA.102.042418", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radial basis function (RBF) network is a third layered neural network that is\nwidely used in function approximation and data classification. Here we propose\na quantum model of the RBF network. Similar to the classical case, we still use\nthe radial basis functions as the activation functions. Quantum linear\nalgebraic techniques and coherent states can be applied to implement these\nfunctions. Differently, we define the state of the weight as a tensor product\nof single-qubit states. This gives a simple approach to implement the quantum\nRBF network in the quantum circuits. Theoretically, we prove that the training\nis almost quadratic faster than the classical one. Numerically, we demonstrate\nthat the quantum RBF network can solve binary classification problems as good\nas the classical RBF network. While the time used for training is much shorter.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 16:20:53 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 21:47:22 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Shao", "Changpeng", ""]]}, {"id": "1910.08800", "submitter": "Etor Arza Gonzalez", "authors": "Etor Arza, Aritz Perez, Ekhine Irurozki, Josu Ceberio", "title": "Kernels of Mallows Models under the Hamming Distance for solving the\n  Quadratic Assignment Problem", "comments": "23 pages", "journal-ref": null, "doi": "10.1016/j.swevo.2020.100740", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quadratic Assignment Problem (QAP) is a well-known permutation-based\ncombinatorial optimization problem with real applications in industrial and\nlogistics environments. Motivated by the challenge that this NP-hard problem\nrepresents, it has captured the attention of the optimization community for\ndecades. As a result, a large number of algorithms have been proposed to tackle\nthis problem. Among these, exact methods are only able to solve instances of\nsize $n<40$. To overcome this limitation, many metaheuristic methods have been\napplied to the QAP.\n  In this work, we follow this direction by approaching the QAP through\nEstimation of Distribution Algorithms (EDAs). Particularly, a non-parametric\ndistance-based exponential probabilistic model is used. Based on the analysis\nof the characteristics of the QAP, and previous work in the area, we introduce\nKernels of Mallows Model under the Hamming distance to the context of EDAs.\nConducted experiments point out that the performance of the proposed algorithm\nin the QAP is superior to (i) the classical EDAs adapted to deal with the QAP,\nand also (ii) to the specific EDAs proposed in the literature to deal with\npermutation problems.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 16:25:41 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 12:37:34 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 17:36:26 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Arza", "Etor", ""], ["Perez", "Aritz", ""], ["Irurozki", "Ekhine", ""], ["Ceberio", "Josu", ""]]}, {"id": "1910.08802", "submitter": "Alexandre Reiffers-Masson", "authors": "Vivek Borkar and Alexandre Reiffers-Masson", "title": "Opinion shaping in social networks using reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study how to shape opinions in social networks when the\nmatrix of interactions is unknown. We consider classical opinion dynamics with\nsome stubborn agents and the possibility of continuously influencing the\nopinions of a few selected agents, albeit under resource constraints. We map\nthe opinion dynamics to a value iteration scheme for policy evaluation for a\nspecific stochastic shortest path problem. This leads to a representation of\nthe opinion vector as an approximate value function for a stochastic shortest\npath problem with some non-classical constraints. We suggest two possible ways\nof influencing agents. One leads to a convex optimization problem and the other\nto a non-convex one. Firstly, for both problems, we propose two different\nonline two-time scale reinforcement learning schemes that converge to the\noptimal solution of each problem. Secondly, we suggest stochastic gradient\ndescent schemes and compare these classes of algorithms with the two-time scale\nreinforcement learning schemes. Thirdly, we also derive another algorithm\ndesigned to tackle the curse of dimensionality one faces when all agents are\nobserved. Numerical studies are provided to illustrate the convergence and\nefficiency of our algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 16:42:15 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Borkar", "Vivek", ""], ["Reiffers-Masson", "Alexandre", ""]]}, {"id": "1910.08805", "submitter": "Siddharth Mitra", "authors": "Siddharth Mitra and Aditya Gopalan", "title": "On Adaptivity in Information-constrained Online Learning", "comments": "34th AAAI Conference on Artificial Intelligence (AAAI 2020). Short\n  version at 11th Optimization for Machine Learning workshop (OPT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to adapt to smoothly-varying ('easy') environments in well-known\nonline learning problems where acquiring information is expensive. For the\nproblem of label efficient prediction, which is a budgeted version of\nprediction with expert advice, we present an online algorithm whose regret\ndepends optimally on the number of labels allowed and $Q^*$ (the quadratic\nvariation of the losses of the best action in hindsight), along with a\nparameter-free counterpart whose regret depends optimally on $Q$ (the quadratic\nvariation of the losses of all the actions). These quantities can be\nsignificantly smaller than $T$ (the total time horizon), yielding an\nimprovement over existing, variation-independent results for the problem. We\nthen extend our analysis to handle label efficient prediction with bandit\nfeedback, i.e., label efficient bandits. Our work builds upon the framework of\noptimistic online mirror descent, and leverages second order corrections along\nwith a carefully designed hybrid regularizer that encodes the constrained\ninformation structure of the problem. We then consider revealing action-partial\nmonitoring games -- a version of label efficient prediction with additive\ninformation costs, which in general are known to lie in the \\textit{hard} class\nof games having minimax regret of order $T^{\\frac{2}{3}}$. We provide a\nstrategy with an $\\mathcal{O}((Q^*T)^{\\frac{1}{3}})$ bound for revealing action\ngames, along with one with a $\\mathcal{O}((QT)^{\\frac{1}{3}})$ bound for the\nfull class of hard partial monitoring games, both being strict improvements\nover current bounds.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 16:53:59 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 07:32:06 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Mitra", "Siddharth", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1910.08809", "submitter": "Nicolas Carion", "authors": "Nicolas Carion, Gabriel Synnaeve, Alessandro Lazaric, Nicolas Usunier", "title": "A Structured Prediction Approach for Generalization in Cooperative\n  Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective coordination is crucial to solve multi-agent collaborative (MAC)\nproblems. While centralized reinforcement learning methods can optimally solve\nsmall MAC instances, they do not scale to large problems and they fail to\ngeneralize to scenarios different from those seen during training. In this\npaper, we consider MAC problems with some intrinsic notion of locality (e.g.,\ngeographic proximity) such that interactions between agents and tasks are\nlocally limited. By leveraging this property, we introduce a novel structured\nprediction approach to assign agents to tasks. At each step, the assignment is\nobtained by solving a centralized optimization problem (the inference\nprocedure) whose objective function is parameterized by a learned scoring\nmodel. We propose different combinations of inference procedures and scoring\nmodels able to represent coordination patterns of increasing complexity. The\nresulting assignment policy can be efficiently learned on small problem\ninstances and readily reused in problems with more agents and tasks (i.e.,\nzero-shot generalization). We report experimental results on a toy search and\nrescue problem and on several target selection scenarios in StarCraft: Brood\nWar, in which our model significantly outperforms strong rule-based baselines\non instances with 5 times more agents and tasks than those seen during\ntraining.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 17:30:40 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Carion", "Nicolas", ""], ["Synnaeve", "Gabriel", ""], ["Lazaric", "Alessandro", ""], ["Usunier", "Nicolas", ""]]}, {"id": "1910.08823", "submitter": "Sylvestre-Alvise Rebuffi", "authors": "Sylvestre-Alvise Rebuffi, Ruth Fong, Xu Ji, Hakan Bilen, Andrea\n  Vedaldi", "title": "NormGrad: Finding the Pixels that Matter for Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The different families of saliency methods, either based on contrastive\nsignals, closed-form formulas mixing gradients with activations or on\nperturbation masks, all focus on which parts of an image are responsible for\nthe model's inference. In this paper, we are rather interested by the locations\nof an image that contribute to the model's training. First, we propose a\nprincipled attribution method that we extract from the summation formula used\nto compute the gradient of the weights for a 1x1 convolutional layer. The\nresulting formula is fast to compute and can used throughout the network,\nallowing us to efficiently produce fined-grained importance maps. We will show\nhow to extend it in order to compute saliency maps at any targeted point within\nthe network. Secondly, to make the attribution really specific to the training\nof the model, we introduce a meta-learning approach for saliency methods by\nconsidering an inner optimisation step within the loss. This way, we do not aim\nat identifying the parts of an image that contribute to the model's output but\nrather the locations that are responsible for the good training of the model on\nthis image. Conversely, we also show that a similar meta-learning approach can\nbe used to extract the adversarial locations which can lead to the degradation\nof the model.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 19:16:20 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Rebuffi", "Sylvestre-Alvise", ""], ["Fong", "Ruth", ""], ["Ji", "Xu", ""], ["Bilen", "Hakan", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1910.08828", "submitter": "Mohammed Rayyan Sheriff", "authors": "Mohammed Rayyan Sheriff and Debasish Chatterjee", "title": "Dictionary Learning with Almost Sure Error Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dictionary is a database of standard vectors, so that other vectors /\nsignals are expressed as linear combinations of dictionary vectors, and the\ntask of learning a dictionary for a given data is to find a good dictionary so\nthat the representation of data points has desirable features. Dictionary\nlearning and the related matrix factorization methods have gained significant\nprominence recently due to their applications in Wide variety of fields like\nmachine learning, signal processing, statistics etc. In this article we study\nthe dictionary learning problem for achieving desirable features in the\nrepresentation of a given data with almost sure recovery constraints. We impose\nthe constraint that every sample is reconstructed properly to within a\npredefined threshold. This problem formulation is more challenging than the\nconventional dictionary learning, which is done by minimizing a regularised\ncost function. We make use of the duality results for linear inverse problems\nto obtain an equivalent reformulation in the form of a convex-concave min-max\nproblem. The resulting min-max problem is then solved using gradient\ndescent-ascent like algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 19:34:00 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 14:24:21 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 21:58:03 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Sheriff", "Mohammed Rayyan", ""], ["Chatterjee", "Debasish", ""]]}, {"id": "1910.08842", "submitter": "Neel Guha", "authors": "Neel Guha, Zhecheng Wang, Matt Wytock, Arun Majumdar", "title": "Machine Learning for AC Optimal Power Flow", "comments": "3 pages, 2 tables. Presented at the Climate Change Workshop at ICML\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore machine learning methods for AC Optimal Powerflow (ACOPF) - the\ntask of optimizing power generation in a transmission network according while\nrespecting physical and engineering constraints. We present two formulations of\nACOPF as a machine learning problem: 1) an end-to-end prediction task where we\ndirectly predict the optimal generator settings, and 2) a constraint prediction\ntask where we predict the set of active constraints in the optimal solution. We\nvalidate these approaches on two benchmark grids.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 20:47:13 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Guha", "Neel", ""], ["Wang", "Zhecheng", ""], ["Wytock", "Matt", ""], ["Majumdar", "Arun", ""]]}, {"id": "1910.08845", "submitter": "Li-Heng Chen", "authors": "Li-Heng Chen, Christos G. Bampis, Zhi Li, Andrey Norkin, Alan C. Bovik", "title": "ProxIQA: A Proxy Approach to Perceptual Optimization of Learned Image\n  Compression", "comments": "12 pages, 12 figures, 5 tables", "journal-ref": null, "doi": "10.1109/TIP.2020.3036752", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of $\\ell_p$ $(p=1,2)$ norms has largely dominated the measurement of\nloss in neural networks due to their simplicity and analytical properties.\nHowever, when used to assess the loss of visual information, these simple norms\nare not very consistent with human perception. Here, we describe a different\n\"proximal\" approach to optimize image analysis networks against quantitative\nperceptual models. Specifically, we construct a proxy network, broadly termed\nProxIQA, which mimics the perceptual model while serving as a loss layer of the\nnetwork. We experimentally demonstrate how this optimization framework can be\napplied to train an end-to-end optimized image compression network. By building\non top of an existing deep image compression model, we are able to demonstrate\na bitrate reduction of as much as $31\\%$ over MSE optimization, given a\nspecified perceptual quality (VMAF) level.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 21:07:33 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 15:48:02 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Chen", "Li-Heng", ""], ["Bampis", "Christos G.", ""], ["Li", "Zhi", ""], ["Norkin", "Andrey", ""], ["Bovik", "Alan C.", ""]]}, {"id": "1910.08853", "submitter": "Peng Liu", "authors": "Peng Liu, Xiaoxiao Zhou, Junyi Yang, El Basha Mohammad D, Ruogu Fang", "title": "Image Restoration Using Deep Regulated Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the depth of convolutional neural networks has attracted substantial\nattention in the deep learning research, the width of these networks has\nrecently received greater interest. The width of networks, defined as the size\nof the receptive fields and the density of the channels, has demonstrated\ncrucial importance in low-level vision tasks such as image denoising and\nrestoration. However, the limited generalization ability, due to the increased\nwidth of networks, creates a bottleneck in designing wider networks. In this\npaper, we propose the Deep Regulated Convolutional Network (RC-Net), a deep\nnetwork composed of regulated sub-network blocks cascaded by skip-connections,\nto overcome this bottleneck. Specifically, the Regulated Convolution block\n(RC-block), featured by a combination of large and small convolution filters,\nbalances the effectiveness of prominent feature extraction and the\ngeneralization ability of the network. RC-Nets have several compelling\nadvantages: they embrace diversified features through large-small filter\ncombinations, alleviate the hazy boundary and blurred details in image\ndenoising and super-resolution problems, and stabilize the learning process.\nOur proposed RC-Nets outperform state-of-the-art approaches with significant\nperformance gains in various image restoration tasks while demonstrating\npromising generalization ability. The code is available at\nhttps://github.com/cswin/RC-Nets.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 22:30:23 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Liu", "Peng", ""], ["Zhou", "Xiaoxiao", ""], ["Yang", "Junyi", ""], ["D", "El Basha Mohammad", ""], ["Fang", "Ruogu", ""]]}, {"id": "1910.08862", "submitter": "Du Xu", "authors": "Di Xu, Tianhang Long, Junbin Gao", "title": "LSTM-Assisted Evolutionary Self-Expressive Subspace Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive volumes of high-dimensional data that evolves over time is\ncontinuously collected by contemporary information processing systems, which\nbrings up the problem of organizing this data into clusters, i.e. achieve the\npurpose of dimensional deduction, and meanwhile learning its temporal evolution\npatterns. In this paper, a framework for evolutionary subspace clustering,\nreferred to as LSTM-ESCM, is introduced, which aims at clustering a set of\nevolving high-dimensional data points that lie in a union of low-dimensional\nevolving subspaces. In order to obtain the parsimonious data representation at\neach time step, we propose to exploit the so-called self-expressive trait of\nthe data at each time point. At the same time, LSTM networks are implemented to\nextract the inherited temporal patterns behind data in an overall time frame.\nAn efficient algorithm has been proposed based on MATLAB. Next, experiments are\ncarried out on real-world datasets to demonstrate the effectiveness of our\nproposed approach. And the results show that the suggested algorithm\ndramatically outperforms other known similar approaches in terms of both run\ntime and accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 23:58:17 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Xu", "Di", ""], ["Long", "Tianhang", ""], ["Gao", "Junbin", ""]]}, {"id": "1910.08864", "submitter": "Yu Chen", "authors": "Yu Chen, Yuanyuan Yang, Yaochu Jin, Xiufen Zou", "title": "Identification of Interaction Clusters Using a Semi-supervised\n  Hierarchical Clustering Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.MN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Identifying interaction clusters of large gene regulatory\nnetworks (GRNs) is critical for its further investigation, while this task is\nvery challenging, attributed to data noise in experiment data, large scale of\nGRNs, and inconsistency between gene expression profiles and function modules,\netc. It is promising to semi-supervise this process by prior information, but\nshortage of prior information sometimes make it very challenging. Meanwhile, it\nis also annoying, and sometimes impossible to discovery gold standard for\nevaluation of clustering results.\\\\ Results: With assistance of an online\nenrichment tool, this research proposes a semi-supervised hierarchical\nclustering method via deconvolved correlation matrix~(SHC-DC) to discover\ninteraction clusters of large-scale GRNs. Three benchmark networks including a\n\\emph{Ecoli} network and two \\emph{Yeast} networks are employed to test\nsemi-supervision scheme of the proposed method. Then, SHC-DC is utilized to\ncluster genes in sleep study. Results demonstrates it can find interaction\nmodules that are generally enriched in various signal pathways. Besides the\nsignificant influence on blood level of interleukins, impact of sleep on\nimportant pathways mediated by them is also validated by the discovered\ninteraction modules.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 00:36:16 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Chen", "Yu", ""], ["Yang", "Yuanyuan", ""], ["Jin", "Yaochu", ""], ["Zou", "Xiufen", ""]]}, {"id": "1910.08867", "submitter": "Peng Liu", "authors": "Peng Liu, Xiaoxiao Zhou, Junyiyang Li, El Basha Mohammad D, Ruogu Fang", "title": "KRNET: Image Denoising with Kernel Regulation Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One popular strategy for image denoising is to design a generalized\nregularization term that is capable of exploring the implicit prior underlying\ndata observation. Convolutional neural networks (CNN) have shown the powerful\ncapability to learn image prior information through a stack of layers defined\nby a combination of kernels (filters) on the input. However, existing CNN-based\nmethods mainly focus on synthetic gray-scale images. These methods still\nexhibit low performance when tackling multi-channel color image denoising. In\nthis paper, we optimize CNN regularization capability by developing a kernel\nregulation module. In particular, we propose a kernel regulation network-block,\nreferred to as KR-block, by integrating the merits of both large and small\nkernels, that can effectively estimate features in solving image denoising. We\nbuild a deep CNN-based denoiser, referred to as KRNET, via concatenating\nmultiple KR-blocks. We evaluate KRNET on additive white Gaussian noise (AWGN),\nmulti-channel (MC) noise, and realistic noise, where KRNET obtains significant\nperformance gains over state-of-the-art methods across a wide spectrum of noise\nlevels.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 01:10:14 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Liu", "Peng", ""], ["Zhou", "Xiaoxiao", ""], ["Li", "Junyiyang", ""], ["D", "El Basha Mohammad", ""], ["Fang", "Ruogu", ""]]}, {"id": "1910.08874", "submitter": "Jianyou Wang", "authors": "Jianyou Wang, Michael Xue, Ryan Culhane, Enmao Diao, Jie Ding, Vahid\n  Tarokh", "title": "Speech Emotion Recognition with Dual-Sequence LSTM Architecture", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054629", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech Emotion Recognition (SER) has emerged as a critical component of the\nnext generation human-machine interfacing technologies. In this work, we\npropose a new dual-level model that predicts emotions based on both MFCC\nfeatures and mel-spectrograms produced from raw audio signals. Each utterance\nis preprocessed into MFCC features and two mel-spectrograms at different\ntime-frequency resolutions. A standard LSTM processes the MFCC features, while\na novel LSTM architecture, denoted as Dual-Sequence LSTM (DS-LSTM), processes\nthe two mel-spectrograms simultaneously. The outputs are later averaged to\nproduce a final classification of the utterance. Our proposed model achieves,\non average, a weighted accuracy of 72.7% and an unweighted accuracy of\n73.3%---a 6% improvement over current state-of-the-art unimodal models---and is\ncomparable with multimodal models that leverage textual information as well as\naudio signals.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 02:04:55 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 06:07:27 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 22:33:13 GMT"}, {"version": "v4", "created": "Thu, 13 Feb 2020 03:02:31 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Wang", "Jianyou", ""], ["Xue", "Michael", ""], ["Culhane", "Ryan", ""], ["Diao", "Enmao", ""], ["Ding", "Jie", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1910.08878", "submitter": "Jiancheng Yang", "authors": "Jiancheng Yang, Rongyao Fang, Bingbing Ni, Yamin Li, Yi Xu, Linguo Li", "title": "Probabilistic Radiomics: Ambiguous Diagnosis with Controllable Shape\n  Analysis", "comments": "MICCAI 2019 (early accept), with supplementary materials", "journal-ref": null, "doi": "10.1007/978-3-030-32226-7_73", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Radiomics analysis has achieved great success in recent years. However,\nconventional Radiomics analysis suffers from insufficiently expressive\nhand-crafted features. Recently, emerging deep learning techniques, e.g.,\nconvolutional neural networks (CNNs), dominate recent research in\nComputer-Aided Diagnosis (CADx). Unfortunately, as black-box predictors, we\nargue that CNNs are \"diagnosing\" voxels (or pixels), rather than lesions; in\nother words, visual saliency from a trained CNN is not necessarily concentrated\non the lesions. On the other hand, classification in clinical applications\nsuffers from inherent ambiguities: radiologists may produce diverse diagnosis\non challenging cases. To this end, we propose a controllable and explainable\n{\\em Probabilistic Radiomics} framework, by combining the Radiomics analysis\nand probabilistic deep learning. In our framework, 3D CNN feature is extracted\nupon lesion region only, then encoded into lesion representation, by a\ncontrollable Non-local Shape Analysis Module (NSAM) based on self-attention.\nInspired from variational auto-encoders (VAEs), an Ambiguity PriorNet is used\nto approximate the ambiguity distribution over human experts. The final\ndiagnosis is obtained by combining the ambiguity prior sample and lesion\nrepresentation, and the whole network named $DenseSharp^{+}$ is end-to-end\ntrainable. We apply the proposed method on lung nodule diagnosis on LIDC-IDRI\ndatabase to validate its effectiveness.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 02:41:07 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Yang", "Jiancheng", ""], ["Fang", "Rongyao", ""], ["Ni", "Bingbing", ""], ["Li", "Yamin", ""], ["Xu", "Yi", ""], ["Li", "Linguo", ""]]}, {"id": "1910.08880", "submitter": "Antoine Dedieu", "authors": "Antoine Dedieu", "title": "Sparse (group) learning with Lipschitz loss functions: a unified\n  analysis", "comments": "arXiv admin note: text overlap with arXiv:1810.03081", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a family of sparse estimators defined as minimizers of some\nempirical Lipschitz loss function---which include hinge, logistic and quantile\nregression losses---with a convex, sparse or group-sparse regularization. In\nparticular, we consider the L1-norm on the coefficients, its sorted Slope\nversion, and the Group L1-L2 extension. First, we propose a theoretical\nframework which simultaneously derives new L2 estimation upper bounds for all\nthree regularization schemes. For L1 and Slope regularizations, our bounds\nscale as $(k^*/n) \\log(p/k^*)$---$n\\times p$ is the size of the design matrix\nand $k^*$ the dimension of the theoretical loss minimizer $\\beta^*$---matching\nthe optimal minimax rate achieved for the least-squares case. For Group L1-L2\nregularization, our bounds scale as $(s^*/n) \\log\\left( G / s^* \\right) + m^* /\nn$---$G$ is the total number of groups and $m^*$ the number of coefficients in\nthe $s^*$ groups which contain $\\beta^*$---and improve over the least-squares\ncase. We additionally show that when the signal is strongly group-sparse Group\nL1-L2 is superior to L1 and Slope. Our bounds are achieved both in probability\nand in expectation, under common assumptions in the literature. Second, we\npropose an accelerated proximal algorithm which computes the convex estimators\nstudied when the number of variables is of the order of $100,000$. We\nadditionally compare their statistical performance of our estimators against\nstandard baselines for settings where the signal is either sparse or\ngroup-sparse. Our experiments findings reveal (i) the good empirical\nperformance of L1 and Slope regularizations for sparse binary classification\nproblems, (ii) the superiority of Group L1-L2 regularization for group-sparse\nclassification problems and (iii) the appealing properties of sparse quantile\nregression estimators for sparse regression problems with heteroscedastic\nnoise.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 02:56:37 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 04:02:41 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 18:54:50 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 19:15:25 GMT"}, {"version": "v5", "created": "Wed, 11 Dec 2019 18:04:59 GMT"}, {"version": "v6", "created": "Fri, 13 Dec 2019 23:49:00 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Dedieu", "Antoine", ""]]}, {"id": "1910.08883", "submitter": "Sambit Panda", "authors": "Sambit Panda, Cencheng Shen, Ronan Perry, Jelle Zorn, Antoine Lutz,\n  Carey E. Priebe, Joshua T. Vogelstein", "title": "Nonpar MANOVA via Independence Testing", "comments": "15 pages main + 4 pages appendix, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The $k$-sample testing problem tests whether or not $k$ groups of data points\nare sampled from the same distribution. Multivariate analysis of variance\n(MANOVA) is currently the gold standard for $k$-sample testing but makes\nstrong, often inappropriate, parametric assumptions. Moreover, independence\ntesting and $k$-sample testing are tightly related, and there are many\nnonparametric multivariate independence tests with strong theoretical and\nempirical properties, including distance correlation (Dcorr) and\nHilbert-Schmidt-Independence-Criterion (Hsic). We prove that universally\nconsistent independence tests achieve universally consistent $k$-sample testing\nand that $k$-sample statistics like Energy and Maximum Mean Discrepancy (MMD)\nare exactly equivalent to Dcorr. Empirically evaluating these tests for\n$k$-sample scenarios demonstrates that these nonparametric independence tests\ntypically outperform MANOVA, even for Gaussian distributed settings. Finally,\nwe extend these non-parametric $k$-sample testing procedures to perform\nmultiway and multilevel tests. Thus, we illustrate the existence of many\ntheoretically motivated and empirically performant $k$-sample tests. A Python\npackage with all independence and k-sample tests called hyppo is available from\nhttps://hyppo.neurodata.io/.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 03:14:20 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 23:54:01 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 01:35:09 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Panda", "Sambit", ""], ["Shen", "Cencheng", ""], ["Perry", "Ronan", ""], ["Zorn", "Jelle", ""], ["Lutz", "Antoine", ""], ["Priebe", "Carey E.", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1910.08887", "submitter": "Mengqi Zhang", "authors": "Mengqi Zhang, Shu Wu, Meng Gao, Xin Jiang, Ke Xu, Liang Wang", "title": "Personalized Graph Neural Networks with Attention Mechanism for\n  Session-Aware Recommendation", "comments": "12 pages", "journal-ref": "IEEE Transactions on Knowledge and Data Engineering 2020", "doi": "10.1109/TKDE.2020.3031329", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of session-aware recommendation aims to predict users' next click\nbased on their current session and historical sessions. Existing session-aware\nrecommendation methods have defects in capturing complex item transition\nrelationships. Other than that, most of them fail to explicitly distinguish the\neffects of different historical sessions on the current session. To this end,\nwe propose a novel method, named Personalized Graph Neural Networks with\nAttention Mechanism (A-PGNN) for brevity. A-PGNN mainly consists of two\ncomponents: one is Personalized Graph Neural Network (PGNN), which is used to\nextract the personalized structural information in each user behavior graph,\ncompared with the traditional Graph Neural Network (GNN) model, which considers\nthe role of the user when the node embeddding is updated. The other is\nDot-Product Attention mechanism, which draws on the Transformer net to\nexplicitly model the effect of historical sessions on the current session.\nExtensive experiments conducted on two real-world data sets show that A-PGNN\nevidently outperforms the state-of-the-art personalized session-aware\nrecommendation methods.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 03:41:20 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 01:47:36 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 02:39:46 GMT"}, {"version": "v4", "created": "Wed, 27 Jan 2021 13:44:52 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Zhang", "Mengqi", ""], ["Wu", "Shu", ""], ["Gao", "Meng", ""], ["Jiang", "Xin", ""], ["Xu", "Ke", ""], ["Wang", "Liang", ""]]}, {"id": "1910.08902", "submitter": "Oluwaseyi Feyisetan", "authors": "Oluwaseyi Feyisetan and Borja Balle and Thomas Drake and Tom Diethe", "title": "Privacy- and Utility-Preserving Textual Analysis via Calibrated\n  Multivariate Perturbations", "comments": "Accepted at WSDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately learning from user data while providing quantifiable privacy\nguarantees provides an opportunity to build better ML models while maintaining\nuser trust. This paper presents a formal approach to carrying out privacy\npreserving text perturbation using the notion of dx-privacy designed to achieve\ngeo-indistinguishability in location data. Our approach applies carefully\ncalibrated noise to vector representation of words in a high dimension space as\ndefined by word embedding models. We present a privacy proof that satisfies\ndx-privacy where the privacy parameter epsilon provides guarantees with respect\nto a distance metric defined by the word embedding space. We demonstrate how\nepsilon can be selected by analyzing plausible deniability statistics backed up\nby large scale analysis on GloVe and fastText embeddings. We conduct privacy\naudit experiments against 2 baseline models and utility experiments on 3\ndatasets to demonstrate the tradeoff between privacy and utility for varying\nvalues of epsilon on different task types. Our results demonstrate practical\nutility (< 2% utility loss for training binary classifiers) while providing\nbetter privacy guarantees than baseline models.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 05:12:23 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Feyisetan", "Oluwaseyi", ""], ["Balle", "Borja", ""], ["Drake", "Thomas", ""], ["Diethe", "Tom", ""]]}, {"id": "1910.08903", "submitter": "Anubhav Jain", "authors": "Anubhav Jain, Avdesh Kumar, Saumya Balodi, Pravesh Biyani", "title": "Benchmark Dataset for Timetable Optimization of Bus Routes in the City\n  of New Delhi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public transport is one of the major forms of transportation in the world.\nThis makes it vital to ensure that public transport is efficient. This research\npresents a novel real-time GPS bus transit data for over 500 routes of buses\noperating in New Delhi. The data can be used for modeling various timetable\noptimization tasks as well as in other domains such as traffic management,\ntravel time estimation, etc. The paper also presents an approach to reduce the\nwaiting time of Delhi buses by analyzing the traffic behavior and proposing a\ntimetable. This algorithm serves as a benchmark for the dataset. The algorithm\nuses a constrained clustering algorithm for classification of trips. It further\nanalyses the data statistically to provide a timetable which is efficient in\nlearning the inter- and intra-month variations.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 05:22:47 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jain", "Anubhav", ""], ["Kumar", "Avdesh", ""], ["Balodi", "Saumya", ""], ["Biyani", "Pravesh", ""]]}, {"id": "1910.08904", "submitter": "Wenjie Zheng", "authors": "Wenjie Zheng", "title": "$hv$-Block Cross Validation is not a BIBD: a Note on the Paper by Jeff\n  Racine (2000)", "comments": "Technique report. 5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST q-bio.QM stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note corrects a mistake in the paper \"consistent cross-validatory\nmodel-selection for dependent data: $hv$-block cross-validation\" by Racine\n(2000). In his paper, he implied that the therein proposed $hv$-block\ncross-validation is consistent in the sense of Shao (1993). To get this\nintuition, he relied on the speculation that $hv$-block is a balanced\nincomplete block design (BIBD). This note demonstrates that this is not the\ncase, and thus the theoretical consistency of $hv$-block remains an open\nquestion. In addition, I also provide a Python program counting the number of\noccurrences of each sample and each pair of samples.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 05:27:10 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Zheng", "Wenjie", ""]]}, {"id": "1910.08906", "submitter": "Jinting Chen", "authors": "Jinting Chen, Zhaocheng Zhu, Cheng Li, Yuming Zhao", "title": "Self-Adaptive Network Pruning", "comments": "10 pages, 5 figures, conference", "journal-ref": "Published as a conference paper at ICONIP 2019", "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have been proved successful on a wide\nrange of tasks, yet they are still hindered by their large computation cost in\nmany industrial scenarios. In this paper, we propose to reduce such cost for\nCNNs through a self-adaptive network pruning method (SANP). Our method\nintroduces a general Saliency-and-Pruning Module (SPM) for each convolutional\nlayer, which learns to predict saliency scores and applies pruning for each\nchannel. Given a total computation budget, SANP adaptively determines the\npruning strategy with respect to each layer and each sample, such that the\naverage computation cost meets the budget. This design allows SANP to be more\nefficient in computation, as well as more robust to datasets and backbones.\nExtensive experiments on 2 datasets and 3 backbones show that SANP surpasses\nstate-of-the-art methods in both classification accuracy and pruning rate.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 06:16:51 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Chen", "Jinting", ""], ["Zhu", "Zhaocheng", ""], ["Li", "Cheng", ""], ["Zhao", "Yuming", ""]]}, {"id": "1910.08909", "submitter": "Shuai Yang", "authors": "Shuai Yang, Wenqi Zhu, Yuesheng Zhu", "title": "Sparse-Dense Subspace Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering refers to the problem of clustering high-dimensional data\ninto a union of low-dimensional subspaces. Current subspace clustering\napproaches are usually based on a two-stage framework. In the first stage, an\naffinity matrix is generated from data. In the second one, spectral clustering\nis applied on the affinity matrix. However, the affinity matrix produced by\ntwo-stage methods cannot fully reveal the similarity between data points from\nthe same subspace (intra-subspace similarity), resulting in inaccurate\nclustering. Besides, most approaches fail to solve large-scale clustering\nproblems due to poor efficiency. In this paper, we first propose a new scalable\nsparse method called Iterative Maximum Correlation (IMC) to learn the affinity\nmatrix from data. Then we develop Piecewise Correlation Estimation (PCE) to\ndensify the intra-subspace similarity produced by IMC. Finally we extend our\nwork into a Sparse-Dense Subspace Clustering (SDSC) framework with a dense\nstage to optimize the affinity matrix for two-stage methods. We show that IMC\nis efficient when clustering large-scale data, and PCE ensures better\nperformance for IMC. We show the universality of our SDSC framework as well.\nExperiments on several data sets demonstrate the effectiveness of our\napproaches. Moreover, we are the first one to apply densification on affinity\nmatrix before spectral clustering, and SDSC constitutes the first attempt to\nbuild a universal three-stage subspace clustering framework.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 06:35:53 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Yang", "Shuai", ""], ["Zhu", "Wenqi", ""], ["Zhu", "Yuesheng", ""]]}, {"id": "1910.08910", "submitter": "Fanchao Qi", "authors": "Yujia Qin, Fanchao Qi, Sicong Ouyang, Zhiyuan Liu, Cheng Yang, Yasheng\n  Wang, Qun Liu, Maosong Sun", "title": "Improving Sequence Modeling Ability of Recurrent Neural Networks via\n  Sememes", "comments": "Published in IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing (TASLP). 10 pages, 2 figures", "journal-ref": null, "doi": "10.1109/TASLP.2020.3012060", "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sememes, the minimum semantic units of human languages, have been\nsuccessfully utilized in various natural language processing applications.\nHowever, most existing studies exploit sememes in specific tasks and few\nefforts are made to utilize sememes more fundamentally. In this paper, we\npropose to incorporate sememes into recurrent neural networks (RNNs) to improve\ntheir sequence modeling ability, which is beneficial to all kinds of downstream\ntasks. We design three different sememe incorporation methods and employ them\nin typical RNNs including LSTM, GRU and their bidirectional variants. In\nevaluation, we use several benchmark datasets involving PTB and WikiText-2 for\nlanguage modeling, SNLI for natural language inference and another two datasets\nfor sentiment analysis and paraphrase detection. Experimental results show\nevident and consistent improvement of our sememe-incorporated models compared\nwith vanilla RNNs, which proves the effectiveness of our sememe incorporation\nmethods. Moreover, we find the sememe-incorporated models have higher\nrobustness and outperform adversarial training in defending adversarial attack.\nAll the code and data of this work can be obtained at\nhttps://github.com/thunlp/SememeRNN.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 06:43:21 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 09:17:32 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Qin", "Yujia", ""], ["Qi", "Fanchao", ""], ["Ouyang", "Sicong", ""], ["Liu", "Zhiyuan", ""], ["Yang", "Cheng", ""], ["Wang", "Yasheng", ""], ["Liu", "Qun", ""], ["Sun", "Maosong", ""]]}, {"id": "1910.08917", "submitter": "Oluwaseyi Feyisetan", "authors": "Oluwaseyi Feyisetan and Tom Diethe and Thomas Drake", "title": "Leveraging Hierarchical Representations for Preserving Privacy and\n  Utility in Text", "comments": "Accepted at ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guaranteeing a certain level of user privacy in an arbitrary piece of text is\na challenging issue. However, with this challenge comes the potential of\nunlocking access to vast data stores for training machine learning models and\nsupporting data driven decisions. We address this problem through the lens of\ndx-privacy, a generalization of Differential Privacy to non Hamming distance\nmetrics. In this work, we explore word representations in Hyperbolic space as a\nmeans of preserving privacy in text. We provide a proof satisfying dx-privacy,\nthen we define a probability distribution in Hyperbolic space and describe a\nway to sample from it in high dimensions. Privacy is provided by perturbing\nvector representations of words in high dimensional Hyperbolic space to obtain\na semantic generalization. We conduct a series of experiments to demonstrate\nthe tradeoff between privacy and utility. Our privacy experiments illustrate\nprotections against an authorship attribution algorithm while our utility\nexperiments highlight the minimal impact of our perturbations on several\ndownstream machine learning models. Compared to the Euclidean baseline, we\nobserve > 20x greater guarantees on expected privacy against comparable worst\ncase statistics.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 07:16:29 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Feyisetan", "Oluwaseyi", ""], ["Diethe", "Tom", ""], ["Drake", "Thomas", ""]]}, {"id": "1910.08918", "submitter": "Tadahiro Taniguchi", "authors": "Tadahiro Taniguchi, Tomoaki Nakamura, Masahiro Suzuki, Ryo Kuniyasu,\n  Kaede Hayashi, Akira Taniguchi, Takato Horii, Takayuki Nagai", "title": "Neuro-SERKET: Development of Integrative Cognitive System through the\n  Composition of Deep Probabilistic Generative Models", "comments": "New Gener. Comput. (2020)", "journal-ref": null, "doi": "10.1007/s00354-019-00084-w", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a framework for the development of an integrative\ncognitive system based on probabilistic generative models (PGMs) called\nNeuro-SERKET. Neuro-SERKET is an extension of SERKET, which can compose\nelemental PGMs developed in a distributed manner and provide a scheme that\nallows the composed PGMs to learn throughout the system in an unsupervised way.\nIn addition to the head-to-tail connection supported by SERKET, Neuro-SERKET\nsupports tail-to-tail and head-to-head connections, as well as neural\nnetwork-based modules, i.e., deep generative models. As an example of a\nNeuro-SERKET application, an integrative model was developed by composing a\nvariational autoencoder (VAE), a Gaussian mixture model (GMM), latent Dirichlet\nallocation (LDA), and automatic speech recognition (ASR). The model is called\nVAE+GMM+LDA+ASR. The performance of VAE+GMM+LDA+ASR and the validity of\nNeuro-SERKET were demonstrated through a multimodal categorization task using\nimage data and a speech signal of numerical digits.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 07:35:39 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 04:41:41 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Taniguchi", "Tadahiro", ""], ["Nakamura", "Tomoaki", ""], ["Suzuki", "Masahiro", ""], ["Kuniyasu", "Ryo", ""], ["Hayashi", "Kaede", ""], ["Taniguchi", "Akira", ""], ["Horii", "Takato", ""], ["Nagai", "Takayuki", ""]]}, {"id": "1910.08922", "submitter": "Surya Karthik Mukkavilli", "authors": "Yimeng Min, S. Karthik Mukkavilli, Yoshua Bengio", "title": "Predicting ice flow using machine learning", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS),\n  Workshop on Tackling Climate Change with Machine Learning, Vancouver, Canada,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though machine learning has achieved notable success in modeling sequential\nand spatial data for speech recognition and in computer vision, applications to\nremote sensing and climate science problems are seldom considered. In this\npaper, we demonstrate techniques from unsupervised learning of future video\nframe prediction, to increase the accuracy of ice flow tracking in\nmulti-spectral satellite images. As the volume of cryosphere data increases in\ncoming years, this is an interesting and important opportunity for machine\nlearning to address a global challenge for climate change, risk management from\nfloods, and conserving freshwater resources. Future frame prediction of ice\nmelt and tracking the optical flow of ice dynamics presents modeling\ndifficulties, due to uncertainties in global temperature increase, changing\nprecipitation patterns, occlusion from cloud cover, rapid melting and glacier\nretreat due to black carbon aerosol deposition, from wildfires or human fossil\nemissions. We show the adversarial learning method helps improve the accuracy\nof tracking the optical flow of ice dynamics compared to existing methods in\nclimate science. We present a dataset, IceNet, to encourage machine learning\nresearch and to help facilitate further applications in the areas of\ncryospheric science and climate change.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 07:56:18 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Min", "Yimeng", ""], ["Mukkavilli", "S. Karthik", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1910.08925", "submitter": "Dong Dai", "authors": "Di Zhang, Dong Dai, Youbiao He, Forrest Sheng Bao, Bing Xie", "title": "RLScheduler: An Automated HPC Batch Job Scheduler Using Reinforcement\n  Learning", "comments": "14 pages; conference accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today high-performance computing (HPC) platforms are still dominated by batch\njobs. Accordingly, effective batch job scheduling is crucial to obtain high\nsystem efficiency. Existing HPC batch job schedulers typically leverage\nheuristic priority functions to prioritize and schedule jobs. But, once\nconfigured and deployed by the experts, such priority functions can hardly\nadapt to the changes of job loads, optimization goals, or system settings,\npotentially leading to degraded system efficiency when changes occur. To\naddress this fundamental issue, we present RLScheduler, an automated HPC batch\njob scheduler built on reinforcement learning. RLScheduler relies on minimal\nmanual interventions or expert knowledge, but can learn high-quality scheduling\npolicies via its own continuous 'trial and error'. We introduce a new\nkernel-based neural network structure and trajectory filtering mechanism in\nRLScheduler to improve and stabilize the learning process. Through extensive\nevaluations, we confirm that RLScheduler can learn high-quality scheduling\npolicies towards various workloads and various optimization goals with\nrelatively low computation cost. Moreover, we show that the learned models\nperform stably even when applied to unseen workloads, making them practical for\nproduction use.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 08:14:28 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 15:11:44 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 00:58:23 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Zhang", "Di", ""], ["Dai", "Dong", ""], ["He", "Youbiao", ""], ["Bao", "Forrest Sheng", ""], ["Xie", "Bing", ""]]}, {"id": "1910.08926", "submitter": "Mohamed Karim Belaid", "authors": "Van Bach Nguyen, Belaid Mohamed Karim, Bao Long Vu, J\\\"org\n  Schl\\\"otterer, Michael Granitzer", "title": "Policy Learning for Malaria Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sequential decision making is a typical problem in reinforcement learning\nwith plenty of algorithms to solve it. However, only a few of them can work\neffectively with a very small number of observations. In this report, we\nintroduce the progress to learn the policy for Malaria Control as a\nReinforcement Learning problem in the KDD Cup Challenge 2019 and propose\ndiverse solutions to deal with the limited observations problem. We apply the\nGenetic Algorithm, Bayesian Optimization, Q-learning with sequence breaking to\nfind the optimal policy for five years in a row with only 20 episodes/100\nevaluations. We evaluate those algorithms and compare their performance with\nRandom Search as a baseline. Among these algorithms, Q-Learning with sequence\nbreaking has been submitted to the challenge and got ranked 7th in KDD Cup.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 08:19:40 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Nguyen", "Van Bach", ""], ["Karim", "Belaid Mohamed", ""], ["Vu", "Bao Long", ""], ["Schl\u00f6tterer", "J\u00f6rg", ""], ["Granitzer", "Michael", ""]]}, {"id": "1910.08930", "submitter": "Subham Banga", "authors": "Vanita Jain, Piyush Agrawal, Subham Banga, Rishabh Kapoor and Shashwat\n  Gulyani", "title": "Sketch2Code: Transformation of Sketches to UI in Real-time Using Deep\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User Interface (UI) prototyping is a necessary step in the early stages of\napplication development. Transforming sketches of a Graphical User Interface\n(UI) into a coded UI application is an uninspired but time-consuming task\nperformed by a UI designer. An automated system that can replace human efforts\nfor straightforward implementation of UI designs will greatly speed up this\nprocedure. The works that propose such a system primarily focus on using UI\nwireframes as input rather than hand-drawn sketches. In this paper, we put\nforward a novel approach wherein we employ a Deep Neural Network that is\ntrained on our custom database of such sketches to detect UI elements in the\ninput sketch. Detection of objects in sketches is a peculiar visual recognition\ntask that requires a specific solution that our deep neural network model\nattempts to provide. The output from the network is a platform-independent UI\nrepresentation object. The UI representation object is a dictionary of\nkey-value pairs to represent the UI elements recognized along with their\nproperties. This is further consumed by our UI parser which creates code for\ndifferent platforms. The intrinsic platform-independence allows the model to\ncreate a UI prototype for multiple platforms with single training. This\ntwo-step approach without the need for two trained models improves over other\nmethods giving time-efficient results (average time: 129 ms) with good\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 08:59:11 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jain", "Vanita", ""], ["Agrawal", "Piyush", ""], ["Banga", "Subham", ""], ["Kapoor", "Rishabh", ""], ["Gulyani", "Shashwat", ""]]}, {"id": "1910.08945", "submitter": "Guokun Chi", "authors": "Guokun Chi and Min Jiang and Xing Gao and Weizhen Hu and Shihui Guo\n  and Kay Chen Tan", "title": "Online Bagging for Anytime Transfer Learning", "comments": "7 pages; SSCI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning techniques have been widely used in the reality that it is\ndifficult to obtain sufficient labeled data in the target domain, but a large\namount of auxiliary data can be obtained in the relevant source domain. But\nmost of the existing methods are based on offline data. In practical\napplications, it is often necessary to face online learning problems in which\nthe data samples are achieved sequentially. In this paper, We are committed to\napplying the ensemble approach to solving the problem of online transfer\nlearning so that it can be used in anytime setting. More specifically, we\npropose a novel online transfer learning framework, which applies the idea of\nonline bagging methods to anytime transfer learning problems, and constructs\nstrong classifiers through online iterations of the usefulness of multiple weak\nclassifiers. Further, our algorithm also provides two extension schemes to\nreduce the impact of negative transfer. Experiments on three real data sets\nshow that the effectiveness of our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 10:25:03 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Chi", "Guokun", ""], ["Jiang", "Min", ""], ["Gao", "Xing", ""], ["Hu", "Weizhen", ""], ["Guo", "Shihui", ""], ["Tan", "Kay Chen", ""]]}, {"id": "1910.08952", "submitter": "Patrick Putzky", "authors": "Patrick Putzky, Dimitrios Karkalousos, Jonas Teuwen, Nikita Miriakov,\n  Bart Bakker, Matthan Caan, Max Welling", "title": "i-RIM applied to the fastMRI challenge", "comments": "Abstract submitted to the fastMRI challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We, team AImsterdam, summarize our submission to the fastMRI challenge\n(Zbontar et al., 2018). Our approach builds on recent advances in invertible\nlearning to infer models as presented in Putzky and Welling (2019). Both, our\nsingle-coil and our multi-coil model share the same basic architecture.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 11:32:22 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Putzky", "Patrick", ""], ["Karkalousos", "Dimitrios", ""], ["Teuwen", "Jonas", ""], ["Miriakov", "Nikita", ""], ["Bakker", "Bart", ""], ["Caan", "Matthan", ""], ["Welling", "Max", ""]]}, {"id": "1910.08964", "submitter": "Fabio Massimo Zennaro", "authors": "Fabio Massimo Zennaro, Ke Chen", "title": "Towards Further Understanding of Sparse Filtering via Information\n  Bottleneck", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we examine a formalization of feature distribution learning\n(FDL) in information-theoretic terms relying on the analytical approach and on\nthe tools already used in the study of the information bottleneck (IB). It has\nbeen conjectured that the behavior of FDL algorithms could be expressed as an\noptimization problem over two information-theoretic quantities: the mutual\ninformation of the data with the learned representations and the entropy of the\nlearned distribution. In particular, such a formulation was offered in order to\nexplain the success of the most prominent FDL algorithm, sparse filtering (SF).\nThis conjecture was, however, left unproven. In this work, we aim at providing\npreliminary empirical support to this conjecture by performing experiments\nreminiscent of the work done on deep neural networks in the context of the IB\nresearch. Specifically, we borrow the idea of using information planes to\nanalyze the behavior of the SF algorithm and gain insights on its dynamics. A\nconfirmation of the conjecture about the dynamics of FDL may provide solid\nground to develop information-theoretic tools to assess the quality of the\nlearning process in FDL, and it may be extended to other unsupervised learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 12:56:17 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Zennaro", "Fabio Massimo", ""], ["Chen", "Ke", ""]]}, {"id": "1910.08965", "submitter": "Ningshan Zhang", "authors": "Ben Adlam, Corinna Cortes, Mehryar Mohri, Ningshan Zhang", "title": "Learning GANs and Ensembles Using Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) generate data based on minimizing a\ndivergence between two distributions. The choice of that divergence is\ntherefore critical. We argue that the divergence must take into account the\nhypothesis set and the loss function used in a subsequent learning task, where\nthe data generated by a GAN serves for training. Taking that structural\ninformation into account is also important to derive generalization guarantees.\nThus, we propose to use the discrepancy measure, which was originally\nintroduced for the closely related problem of domain adaptation and which\nprecisely takes into account the hypothesis set and the loss function. We show\nthat discrepancy admits favorable properties for training GANs and prove\nexplicit generalization guarantees. We present efficient algorithms using\ndiscrepancy for two tasks: training a GAN directly, namely DGAN, and mixing\npreviously trained generative models, namely EDGAN. Our experiments on toy\nexamples and several benchmark datasets show that DGAN is competitive with\nother GANs and that EDGAN outperforms existing GAN ensembles, such as AdaGAN.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 13:01:26 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 01:10:05 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Adlam", "Ben", ""], ["Cortes", "Corinna", ""], ["Mohri", "Mehryar", ""], ["Zhang", "Ningshan", ""]]}, {"id": "1910.08967", "submitter": "Radu Tudor Ionescu", "authors": "Petru Soviany, Claudiu Ardei, Radu Tudor Ionescu, Marius Leordeanu", "title": "Image Difficulty Curriculum for Generative Adversarial Networks (CuGAN)", "comments": "Accepted at WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the significant advances in recent years, Generative Adversarial\nNetworks (GANs) are still notoriously hard to train. In this paper, we propose\nthree novel curriculum learning strategies for training GANs. All strategies\nare first based on ranking the training images by their difficulty scores,\nwhich are estimated by a state-of-the-art image difficulty predictor. Our first\nstrategy is to divide images into gradually more difficult batches. Our second\nstrategy introduces a novel curriculum loss function for the discriminator that\ntakes into account the difficulty scores of the real images. Our third strategy\nis based on sampling from an evolving distribution, which favors the easier\nimages during the initial training stages and gradually converges to a uniform\ndistribution, in which samples are equally likely, regardless of difficulty. We\ncompare our curriculum learning strategies with the classic training procedure\non two tasks: image generation and image translation. Our experiments indicate\nthat all strategies provide faster convergence and superior results. For\nexample, our best curriculum learning strategy applied on spectrally normalized\nGANs (SNGANs) fooled human annotators in thinking that generated CIFAR-like\nimages are real in 25.0% of the presented cases, while the SNGANs trained using\nthe classic procedure fooled the annotators in only 18.4% cases. Similarly, in\nimage translation, the human annotators preferred the images produced by the\nCycle-consistent GAN (CycleGAN) trained using curriculum learning in 40.5%\ncases and those produced by CycleGAN based on classic training in only 19.8%\ncases, 39.7% cases being labeled as ties.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 13:06:26 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 22:19:01 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Soviany", "Petru", ""], ["Ardei", "Claudiu", ""], ["Ionescu", "Radu Tudor", ""], ["Leordeanu", "Marius", ""]]}, {"id": "1910.08974", "submitter": "Nan Lu", "authors": "Nan Lu, Tianyi Zhang, Gang Niu, Masashi Sugiyama", "title": "Mitigating Overfitting in Supervised Classification from Two Unlabeled\n  Datasets: A Consistent Risk Correction Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed unlabeled-unlabeled (UU) classification method allows\nus to train a binary classifier only from two unlabeled datasets with different\nclass priors. Since this method is based on the empirical risk minimization, it\nworks as if it is a supervised classification method, compatible with any model\nand optimizer. However, this method sometimes suffers from severe overfitting,\nwhich we would like to prevent in this paper. Our empirical finding in applying\nthe original UU method is that overfitting often co-occurs with the empirical\nrisk going negative, which is not legitimate. Therefore, we propose to wrap the\nterms that cause a negative empirical risk by certain correction functions.\nThen, we prove the consistency of the corrected risk estimator and derive an\nestimation error bound for the corrected risk minimizer. Experiments show that\nour proposal can successfully mitigate overfitting of the UU method and\nsignificantly improve the classification accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 13:23:19 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 05:27:12 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 01:31:10 GMT"}, {"version": "v4", "created": "Tue, 31 Mar 2020 10:21:08 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Lu", "Nan", ""], ["Zhang", "Tianyi", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1910.08978", "submitter": "Aleksandar Vakanski", "authors": "Aleksandar Vakanski, Min Xian, Phoebe Freer", "title": "Attention Enriched Deep Learning Model for Breast Tumor Segmentation in\n  Ultrasound Images", "comments": "16 pages, 5 figures", "journal-ref": "Ultrasound in Medicine and Biology, volume 46, issue 10, pages\n  2819-2833, 2020", "doi": "10.1016/j.ultrasmedbio.2020.06.015", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating human domain knowledge for breast tumor diagnosis is\nchallenging, since shape, boundary, curvature, intensity, or other common\nmedical priors vary significantly across patients and cannot be employed. This\nwork proposes a new approach for integrating visual saliency into a deep\nlearning model for breast tumor segmentation in ultrasound images. Visual\nsaliency refers to image maps containing regions that are more likely to\nattract radiologists visual attention. The proposed approach introduces\nattention blocks into a U-Net architecture, and learns feature representations\nthat prioritize spatial regions with high saliency levels. The validation\nresults demonstrate increased accuracy for tumor segmentation relative to\nmodels without salient attention layers. The approach achieved a Dice\nsimilarity coefficient of 90.5 percent on a dataset of 510 images. The salient\nattention model has potential to enhance accuracy and robustness in processing\nmedical images of other organs, by providing a means to incorporate\ntask-specific knowledge into deep learning architectures.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 13:36:33 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 02:55:49 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Vakanski", "Aleksandar", ""], ["Xian", "Min", ""], ["Freer", "Phoebe", ""]]}, {"id": "1910.09014", "submitter": "Daniel Irving Bernstein", "authors": "Daniel Irving Bernstein, Basil Saeed, Chandler Squires, Caroline Uhler", "title": "Ordering-Based Causal Structure Learning in the Presence of Latent\n  Variables", "comments": "To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of learning a causal graph in the presence of latent\nconfounders given i.i.d.~samples from the model. While current algorithms for\ncausal structure discovery in the presence of latent confounders are\nconstraint-based, we here propose a score-based approach. We prove that under\nassumptions weaker than faithfulness, any sparsest independence map (IMAP) of\nthe distribution belongs to the Markov equivalence class of the true model.\nThis motivates the \\emph{Sparsest Poset} formulation - that posets can be\nmapped to minimal IMAPs of the true model such that the sparsest of these IMAPs\nis Markov equivalent to the true model. Motivated by this result, we propose a\ngreedy algorithm over the space of posets for causal structure discovery in the\npresence of latent confounders and compare its performance to the current\nstate-of-the-art algorithms FCI and FCI+ on synthetic data.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 16:36:06 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 21:04:46 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Bernstein", "Daniel Irving", ""], ["Saeed", "Basil", ""], ["Squires", "Chandler", ""], ["Uhler", "Caroline", ""]]}, {"id": "1910.09022", "submitter": "Yan Zheng", "authors": "Ruimin Shen, Yan Zheng, Jianye Hao, Yinfeng Chen, Changjie Fan", "title": "Diverse Behavior Is What Game AI Needs: Generating Varied Human-Like\n  Playing Styles Using Evolutionary Multi-Objective Deep Reinforcement Learning", "comments": "1. there is some discrepancy between some contributors with respect\n  to the order of the authors; 2. the paper is rather \"raw\" - significant\n  effort and improvement in terms of the paper's language and structure are\n  needed to make it ready for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  this paper has been withdrawn\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 16:57:52 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 04:31:10 GMT"}, {"version": "v3", "created": "Sun, 12 Apr 2020 02:32:58 GMT"}, {"version": "v4", "created": "Tue, 14 Apr 2020 04:20:37 GMT"}, {"version": "v5", "created": "Wed, 15 Apr 2020 01:34:23 GMT"}, {"version": "v6", "created": "Thu, 16 Apr 2020 03:01:55 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Shen", "Ruimin", ""], ["Zheng", "Yan", ""], ["Hao", "Jianye", ""], ["Chen", "Yinfeng", ""], ["Fan", "Changjie", ""]]}, {"id": "1910.09024", "submitter": "Jongmin Yu", "authors": "Jongmin Yu and Hyeontaek Oh", "title": "Boosting Network Weight Separability via Feed-Backward Reconstruction", "comments": "8 pages, 6 figures", "journal-ref": "in IEEE Access, vol. 8, pp. 214923-214931, 2020", "doi": "10.1109/ACCESS.2020.3041470", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a new evaluation metric and boosting method for weight\nseparability in neural network design. In contrast to general visual\nrecognition methods designed to encourage both intra-class compactness and\ninter-class separability of latent features, we focus on estimating linear\nindependence of column vectors in weight matrix and improving the separability\nof weight vectors. To this end, we propose an evaluation metric for weight\nseparability based on semi-orthogonality of a matrix and Frobenius distance,\nand the feed-backward reconstruction loss which explicitly encourages weight\nseparability between the column vectors in the weight matrix. The experimental\nresults on image classification and face recognition demonstrate that the\nweight separability boosting via minimization of feed-backward reconstruction\nloss can improve the visual recognition performance, hence universally boosting\nthe performance on various visual recognition tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 17:04:40 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 14:05:15 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Yu", "Jongmin", ""], ["Oh", "Hyeontaek", ""]]}, {"id": "1910.09036", "submitter": "Aude Genevay", "authors": "Aude Genevay, Gabriel Dulac-Arnold, Jean-Philippe Vert", "title": "Differentiable Deep Clustering with Cluster Size Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental unsupervised learning approach. Many clustering\nalgorithms -- such as $k$-means -- rely on the euclidean distance as a\nsimilarity measure, which is often not the most relevant metric for high\ndimensional data such as images. Learning a lower-dimensional embedding that\ncan better reflect the geometry of the dataset is therefore instrumental for\nperformance. We propose a new approach for this task where the embedding is\nperformed by a differentiable model such as a deep neural network. By rewriting\nthe $k$-means clustering algorithm as an optimal transport task, and adding an\nentropic regularization, we derive a fully differentiable loss function that\ncan be minimized with respect to both the embedding parameters and the cluster\nparameters via stochastic gradient descent. We show that this new formulation\ngeneralizes a recently proposed state-of-the-art method based on soft-$k$-means\nby adding constraints on the cluster sizes. Empirical evaluations on image\nclassification benchmarks suggest that compared to state-of-the-art methods,\nour optimal transport-based approach provide better unsupervised accuracy and\ndoes not require a pre-training phase.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 17:54:45 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Genevay", "Aude", ""], ["Dulac-Arnold", "Gabriel", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "1910.09040", "submitter": "Eli Chien", "authors": "Eli Chien, Pan Li, Olgica Milenkovic", "title": "Landing Probabilities of Random Walks for Seed-Set Expansion in\n  Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the first known mean-field study of landing probabilities for\nrandom walks on hypergraphs. In particular, we examine clique-expansion and\ntensor methods and evaluate their mean-field characteristics over a class of\nrandom hypergraph models for the purpose of seed-set community expansion. We\ndescribe parameter regimes in which the two methods outperform each other and\npropose a hybrid expansion method that uses partial clique-expansion to reduce\nthe projection distortion and low-complexity tensor methods applied directly on\nthe partially expanded hypergraphs.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 18:14:30 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Chien", "Eli", ""], ["Li", "Pan", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1910.09043", "submitter": "R\\'emi Besson", "authors": "R\\'emi Besson, Erwan Le Pennec and St\\'ephanie Allassonni\\`ere", "title": "Learning from both experts and data", "comments": null, "journal-ref": null, "doi": "10.3390/e21121208", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the problem of inferring a discrete probability\ndistribution using both expert knowledge and empirical data. This is an\nimportant issue for many applications where the scarcity of data prevents a\npurely empirical approach. In this context, it is common to rely first on an\ninitial domain knowledge a priori before proceeding to an online data\nacquisition. We are particularly interested in the intermediate regime where we\ndo not have enough data to do without the initial expert a priori of the\nexperts, but enough to correct it if necessary. We present here a novel way to\ntackle this issue with a method providing an objective way to choose the weight\nto be given to experts compared to data. We show, both empirically and\ntheoretically, that our proposed estimator is always more efficient than the\nbest of the two models (expert or data) within a constant.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 18:30:23 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 12:59:36 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Besson", "R\u00e9mi", ""], ["Pennec", "Erwan Le", ""], ["Allassonni\u00e8re", "St\u00e9phanie", ""]]}, {"id": "1910.09046", "submitter": "Micha Feigin-Almon", "authors": "Micha Feigin and Manuel Zwecker and Daniel Freedman and Brian W.\n  Anthony", "title": "Detecting muscle activation using ultrasound speed of sound inversion\n  with deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.SP q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional muscle imaging is essential for diagnostics of a multitude of\nmusculoskeletal afflictions such as degenerative muscle diseases, muscle\ninjuries, muscle atrophy, and neurological related issues such as spasticity.\nHowever, there is currently no solution, imaging or otherwise, capable of\nproviding a map of active muscles over a large field of view in dynamic\nscenarios. In this work, we look at the feasibility of longitudinal sound speed\nmeasurements to the task of dynamic muscle imaging of contraction or\nactivation. We perform the assessment using a deep learning network applied to\npre-beamformed ultrasound channel data for sound speed inversion. Preliminary\nresults show that dynamic muscle contraction can be detected in the calf and\nthat this contraction can be positively assigned to the operating muscles.\nPotential frame rates in the hundreds to thousands of frames per second are\nnecessary to accomplish this.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 18:55:39 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 02:14:35 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Feigin", "Micha", ""], ["Zwecker", "Manuel", ""], ["Freedman", "Daniel", ""], ["Anthony", "Brian W.", ""]]}, {"id": "1910.09055", "submitter": "Fatih Furkan Yilmaz", "authors": "Fatih Furkan Yilmaz and Reinhard Heckel", "title": "Image recognition from raw labels collected without annotators", "comments": "Version changelog: Added content on ImageNet related experiments;\n  Re-structured the document to incorporate the new content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification problems are typically addressed by first collecting\nexamples with candidate labels, second cleaning the candidate labels manually,\nand third training a deep neural network on the clean examples. The manual\nlabeling step is often the most expensive one as it requires workers to label\nmillions of images. In this paper we propose to work without any explicitly\nlabeled data by i) directly training the deep neural network on the noisy\ncandidate labels, and ii) early stopping the training to avoid overfitting.\nWith this procedure we exploit an intriguing property of standard\noverparameterized convolutional neural networks trained with (stochastic)\ngradient descent: Clean labels are fitted faster than noisy ones. We consider\ntwo classification problems, a subset of ImageNet and CIFAR-10. For both, we\nconstruct large candidate datasets without any explicit human annotations, that\nonly contain 10%-50% correctly labeled examples per class. We show that\ntraining on the candidate examples and regularizing through early stopping\ngives higher test performance for both problems than when training on the\noriginal, clean data. This is possible because the candidate datasets contain a\nhuge number of clean examples, and, as we show in this paper, the noise\ngenerated through the label collection process is not nearly as adversarial for\nlearning as the noise generated by randomly flipping labels.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 19:58:21 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 17:55:12 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 23:11:46 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Yilmaz", "Fatih Furkan", ""], ["Heckel", "Reinhard", ""]]}, {"id": "1910.09056", "submitter": "Saeid Naderiparizi", "authors": "Saeid Naderiparizi, Adam \\'Scibior, Andreas Munk, Mehrdad Ghadiri,\n  At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Bradley Gram-Hansen, Christian Schroeder de\n  Witt, Robert Zinkov, Philip H.S. Torr, Tom Rainforth, Yee Whye Teh, Frank\n  Wood", "title": "Amortized Rejection Sampling in Universal Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to amortized inference in probabilistic programs with\nunbounded loops can produce estimators with infinite variance. An instance of\nthis is importance sampling inference in programs that explicitly include\nrejection sampling as part of the user-programmed generative procedure. In this\npaper we develop a new and efficient amortized importance sampling estimator.\nWe prove finite variance of our estimator and empirically demonstrate our\nmethod's correctness and efficiency compared to existing alternatives on\ngenerative programs containing rejection sampling loops and discuss how to\nimplement our method in a generic probabilistic programming framework.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 20:04:20 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 00:11:55 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Naderiparizi", "Saeid", ""], ["\u015acibior", "Adam", ""], ["Munk", "Andreas", ""], ["Ghadiri", "Mehrdad", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Gram-Hansen", "Bradley", ""], ["de Witt", "Christian Schroeder", ""], ["Zinkov", "Robert", ""], ["Torr", "Philip H. S.", ""], ["Rainforth", "Tom", ""], ["Teh", "Yee Whye", ""], ["Wood", "Frank", ""]]}, {"id": "1910.09057", "submitter": "Wenlin Wang", "authors": "Wenlin Wang, Hongteng Xu, Guoyin Wang, Wenqi Wang, Lawrence Carin", "title": "Zero-Shot Recognition via Optimal Transport", "comments": "To appear in WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an optimal transport (OT) framework for generalized zero-shot\nlearning (GZSL), seeking to distinguish samples for both seen and unseen\nclasses, with the assist of auxiliary attributes. The discrepancy between\nfeatures and attributes is minimized by solving an optimal transport problem.\n{Specifically, we build a conditional generative model to generate features\nfrom seen-class attributes, and establish an optimal transport between the\ndistribution of the generated features and that of the real features.} The\ngenerative model and the optimal transport are optimized iteratively with an\nattribute-based regularizer, that further enhances the discriminative power of\nthe generated features. A classifier is learned based on the features generated\nfor both the seen and unseen classes. In addition to generalized zero-shot\nlearning, our framework is also applicable to standard and transductive ZSL\nproblems. Experiments show that our optimal transport-based method outperforms\nstate-of-the-art methods on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 20:18:18 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 03:52:18 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Wang", "Wenlin", ""], ["Xu", "Hongteng", ""], ["Wang", "Guoyin", ""], ["Wang", "Wenqi", ""], ["Carin", "Lawrence", ""]]}, {"id": "1910.09061", "submitter": "Tongda Xu", "authors": "Tongda Xu, Ziming Qiu, William Das, Chuiyu Wang, Jack Langerman, Nitin\n  Nair, Orlando Aristizabal, Jonathan Mamou, Daniel H. Turnbull, Jeffrey A.\n  Ketterling, Yao Wang", "title": "Deep Mouse: An End-to-end Auto-context Refinement Framework for Brain\n  Ventricle and Body Segmentation in Embryonic Mice Ultrasound Volumes", "comments": "Full Paper Submission to ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-frequency ultrasound (HFU) is well suited for imaging embryonic mice due\nto its noninvasive and real-time characteristics. However, manual segmentation\nof the brain ventricles (BVs) and body requires substantial time and expertise.\nThis work proposes a novel deep learning based end-to-end auto-context\nrefinement framework, consisting of two stages. The first stage produces a low\nresolution segmentation of the BV and body simultaneously. The resulting\nprobability map for each object (BV or body) is then used to crop a region of\ninterest (ROI) around the target object in both the original image and the\nprobability map to provide context to the refinement segmentation network.\nJoint training of the two stages provides significant improvement in Dice\nSimilarity Coefficient (DSC) over using only the first stage (0.818 to 0.906\nfor the BV, and 0.919 to 0.934 for the body). The proposed method significantly\nreduces the inference time (102.36 to 0.09 s/volume around 1000x faster) while\nslightly improves the segmentation accuracy over the previous methods using\nslide-window approaches.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 20:49:39 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 00:53:23 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Xu", "Tongda", ""], ["Qiu", "Ziming", ""], ["Das", "William", ""], ["Wang", "Chuiyu", ""], ["Langerman", "Jack", ""], ["Nair", "Nitin", ""], ["Aristizabal", "Orlando", ""], ["Mamou", "Jonathan", ""], ["Turnbull", "Daniel H.", ""], ["Ketterling", "Jeffrey A.", ""], ["Wang", "Yao", ""]]}, {"id": "1910.09066", "submitter": "Jiawei Huang", "authors": "Jiawei Huang, Nan Jiang", "title": "From Importance Sampling to Doubly Robust Policy Gradient", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that on-policy policy gradient (PG) and its variance reduction\nvariants can be derived by taking finite difference of function evaluations\nsupplied by estimators from the importance sampling (IS) family for off-policy\nevaluation (OPE). Starting from the doubly robust (DR) estimator (Jiang & Li,\n2016), we provide a simple derivation of a very general and flexible form of\nPG, which subsumes the state-of-the-art variance reduction technique (Cheng et\nal., 2019) as its special case and immediately hints at further variance\nreduction opportunities overlooked by existing literature. We analyze the\nvariance of the new DR-PG estimator, compare it to existing methods as well as\nthe Cramer-Rao lower bound of policy gradient, and empirically show its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 21:27:36 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 18:46:30 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 00:36:45 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Huang", "Jiawei", ""], ["Jiang", "Nan", ""]]}, {"id": "1910.09077", "submitter": "Mohamed Chaabane", "authors": "Mohamed Chaabane, Ameni Trabelsi, Nathaniel Blanchard, Ross Beveridge", "title": "Looking Ahead: Anticipating Pedestrians Crossing with Future Frames\n  Prediction", "comments": null, "journal-ref": "WACV 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an end-to-end future-prediction model that focuses\non pedestrian safety. Specifically, our model uses previous video frames,\nrecorded from the perspective of the vehicle, to predict if a pedestrian will\ncross in front of the vehicle. The long term goal of this work is to design a\nfully autonomous system that acts and reacts as a defensive human driver would\n--- predicting future events and reacting to mitigate risk. We focus on\npedestrian-vehicle interactions because of the high risk of harm to the\npedestrian if their actions are miss-predicted. Our end-to-end model consists\nof two stages: the first stage is an encoder/decoder network that learns to\npredict future video frames. The second stage is a deep spatio-temporal network\nthat utilizes the predicted frames of the first stage to predict the\npedestrian's future action. Our system achieves state-of-the-art accuracy on\npedestrian behavior prediction and future frames prediction on the Joint\nAttention for Autonomous Driving (JAAD) dataset.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 23:12:13 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 22:49:17 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Chaabane", "Mohamed", ""], ["Trabelsi", "Ameni", ""], ["Blanchard", "Nathaniel", ""], ["Beveridge", "Ross", ""]]}, {"id": "1910.09083", "submitter": "Minghe Zhang", "authors": "Minghe Zhang, Liyan Xie, Yao Xie", "title": "Online Community Detection by Spectral CUSUM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG cs.SI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an online community change detection algorithm called spectral\nCUSUM to detect the emergence of a community using a subspace projection\nprocedure based on a Gaussian model setting. Theoretical analysis is provided\nto characterize the average run length (ARL) and expected detection delay\n(EDD), as well as the asymptotic optimality. Simulation and real data examples\ndemonstrate the good performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 23:47:33 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 15:48:12 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Zhang", "Minghe", ""], ["Xie", "Liyan", ""], ["Xie", "Yao", ""]]}, {"id": "1910.09085", "submitter": "Jindong Gu", "authors": "Jindong Gu, Volker Tresp", "title": "Semantics for Global and Local Interpretation of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) with high expressiveness have achieved\nstate-of-the-art performance in many tasks. However, their distributed feature\nrepresentations are difficult to interpret semantically. In this work,\nhuman-interpretable semantic concepts are associated with vectors in feature\nspace. The association process is mathematically formulated as an optimization\nproblem. The semantic vectors obtained from the optimal solution are applied to\ninterpret deep neural networks globally and locally. The global interpretations\nare useful to understand the knowledge learned by DNNs. The interpretation of\nlocal behaviors can help to understand individual decisions made by DNNs\nbetter. The empirical experiments demonstrate how to use identified semantics\nto interpret the existing DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 00:00:17 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Gu", "Jindong", ""], ["Tresp", "Volker", ""]]}, {"id": "1910.09086", "submitter": "Jindong Gu", "authors": "Jindong Gu, Volker Tresp", "title": "Contextual Prediction Difference Analysis for Explaining Individual\n  Image Classifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much effort has been devoted to understanding the decisions of deep neural\nnetworks in recent years. A number of model-aware saliency methods were\nproposed to explain individual classification decisions by creating saliency\nmaps. However, they are not applicable when the parameters and the gradients of\nthe underlying models are unavailable. Recently, model-agnostic methods have\nalso received attention. As one of them, \\textit{Prediction Difference\nAnalysis} (PDA), a probabilistic sound methodology, was proposed. In this work,\nwe first show that PDA can suffer from saturated classifiers. The saturation\nphenomenon of classifiers exists widely in current neural network-based\nclassifiers. To explain the decisions of saturated classifiers better, we\nfurther propose Contextual PDA, which runs hundreds of times faster than PDA.\nThe experiments show the superiority of our method by explaining image\nclassifications of the state-of-the-art deep convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 00:04:22 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 00:41:19 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Gu", "Jindong", ""], ["Tresp", "Volker", ""]]}, {"id": "1910.09089", "submitter": "Akshayaa Magesh", "authors": "Akshayaa Magesh and Venugopal V. Veeravalli", "title": "Decentralized Heterogeneous Multi-Player Multi-Armed Bandits with\n  Non-Zero Rewards on Collisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a fully decentralized multi-player stochastic multi-armed bandit\nsetting where the players cannot communicate with each other and can observe\nonly their own actions and rewards. The environment may appear differently to\ndifferent players, $\\textit{i.e.}$, the reward distributions for a given arm\nare heterogeneous across players. In the case of a collision (when more than\none player plays the same arm), we allow for the colliding players to receive\nnon-zero rewards. The time-horizon $T$ for which the arms are played is\n\\emph{not} known to the players. Within this setup, where the number of players\nis allowed to be greater than the number of arms, we present a policy that\nachieves near order-optimal expected regret of order $O(\\log^{1 + \\delta} T)$\nfor some $0 < \\delta < 1$ over a time-horizon of duration $T$.\n  This paper is currently under review at IEEE Transactions on Information\nTheory.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 00:27:55 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 10:37:18 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 16:18:21 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Magesh", "Akshayaa", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1910.09090", "submitter": "Jinwei Zhao", "authors": "Jinwei Zhao, Qizhou Wang, Fuqiang Zhang, Wanli Qiu, Yufei Wang, Yu\n  Liu, Guo Xie, Weigang Ma, Bin Wang, Xinhong Hei", "title": "A game method for improving the interpretability of convolution neural\n  network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real artificial intelligence always has been focused on by many machine\nlearning researchers, especially in the area of deep learning. However deep\nneural network is hard to be understood and explained, and sometimes, even\nmetaphysics. The reason is, we believe that: the network is essentially a\nperceptual model. Therefore, we believe that in order to complete complex\nintelligent activities from simple perception, it is necessary to con-struct\nanother interpretable logical network to form accurate and reasonable responses\nand explanations to external things. Researchers like Bolei Zhou and Quanshi\nZhang have found many explanatory rules for deep feature extraction aimed at\nthe feature extraction stage of convolution neural network. However, although\nresearchers like Marco Gori have also made great efforts to improve the\ninterpretability of the fully connected layers of the network, the problem is\nalso very difficult. This paper firstly analyzes its reason. Then a method of\nconstructing logical network based on the fully connected layers and extracting\nlogical relation between input and output of the layers is proposed. The game\nprocess between perceptual learning and logical abstract cognitive learning is\nimplemented to improve the interpretable performance of deep learning process\nand deep learning model. The benefits of our approach are illustrated on\nbenchmark data sets and in real-world experiments.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 00:32:40 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Zhao", "Jinwei", ""], ["Wang", "Qizhou", ""], ["Zhang", "Fuqiang", ""], ["Qiu", "Wanli", ""], ["Wang", "Yufei", ""], ["Liu", "Yu", ""], ["Xie", "Guo", ""], ["Ma", "Weigang", ""], ["Wang", "Bin", ""], ["Hei", "Xinhong", ""]]}, {"id": "1910.09091", "submitter": "Akshayaa Magesh", "authors": "Akshayaa Magesh and Venugopal V. Veeravalli", "title": "Multi-User MABs with User Dependent Rewards for Uncoordinated Spectrum\n  Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-user multi-armed bandits have emerged as a good model for uncoordinated\nspectrum access problems. In this paper we consider the scenario where users\ncannot communicate with each other. In addition, the environment may appear\ndifferently to different users, ${i.e.}$, the mean rewards as observed by\ndifferent users for the same channel may be different. With this setup, we\npresent a policy that achieves a regret of $O (\\log{T})$. This paper has been\naccepted at Asilomar Conference on Signals, Systems, and Computers 2019.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 00:32:58 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 21:36:49 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 18:58:41 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Magesh", "Akshayaa", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1910.09092", "submitter": "Michael Lingzhi Li", "authors": "Dimitris Bertsimas, Michael Lingzhi Li", "title": "Fast Exact Matrix Completion: A Unified Optimization Framework for\n  Matrix Completion", "comments": null, "journal-ref": "Journal of Machine Learning Research 21 (2020) 1-43", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate the problem of matrix completion with and without side\ninformation as a non-convex optimization problem. We design fastImpute based on\nnon-convex gradient descent and show it converges to a global minimum that is\nguaranteed to recover closely the underlying matrix while it scales to matrices\nof sizes beyond $10^5 \\times 10^5$. We report experiments on both synthetic and\nreal-world datasets that show fastImpute is competitive in both the accuracy of\nthe matrix recovered and the time needed across all cases. Furthermore, when a\nhigh number of entries are missing, fastImpute is over $75\\%$ lower in MAPE and\n$15$ times faster than current state-of-the-art matrix completion methods in\nboth the case with side information and without.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 00:37:06 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 22:23:28 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Li", "Michael Lingzhi", ""]]}, {"id": "1910.09093", "submitter": "Benjamin Petit", "authors": "Benjamin Petit, Loren Amdahl-Culleton, Yao Liu, Jimmy Smith,\n  Pierre-Luc Bacon", "title": "All-Action Policy Gradient Methods: A Numerical Integration Approach", "comments": "9 pages, 2 figures. NeurIPS 2019 Optimization Foundations of\n  Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While often stated as an instance of the likelihood ratio trick [Rubinstein,\n1989], the original policy gradient theorem [Sutton, 1999] involves an integral\nover the action space. When this integral can be computed, the resulting\n\"all-action\" estimator [Sutton, 2001] provides a conditioning effect [Bratley,\n1987] reducing the variance significantly compared to the REINFORCE estimator\n[Williams, 1992]. In this paper, we adopt a numerical integration perspective\nto broaden the applicability of the all-action estimator to general spaces and\nto any function class for the policy or critic components, beyond the Gaussian\ncase considered by [Ciosek, 2018]. In addition, we provide a new theoretical\nresult on the effect of using a biased critic which offers more guidance than\nthe previous \"compatible features\" condition of [Sutton, 1999]. We demonstrate\nthe benefit of our approach in continuous control tasks with nonlinear function\napproximation. Our results show improved performance and sample efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 00:42:48 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Petit", "Benjamin", ""], ["Amdahl-Culleton", "Loren", ""], ["Liu", "Yao", ""], ["Smith", "Jimmy", ""], ["Bacon", "Pierre-Luc", ""]]}, {"id": "1910.09094", "submitter": "Florent Chiaroni", "authors": "Sid Ali Hamideche, Florent Chiaroni, Mohamed-Cherif Rahal", "title": "Self-supervised classification of dynamic obstacles using the temporal\n  information provided by videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, autonomous driving systems can detect, segment, and classify the\nsurrounding obstacles using a monocular camera. However, state-of-the-art\nmethods solving these tasks generally perform a fully supervised learning\nprocess and require a large amount of training labeled data. On another note,\nsome self-supervised learning approaches can deal with detection and\nsegmentation of dynamic obstacles using the temporal information available in\nvideo sequences. In this work, we propose to classify the detected obstacles\ndepending on their motion pattern. We present a novel self-supervised framework\nconsisting of learning offline clusters from temporal patch sequences and\nconsidering these clusters as labeled sets to train a real-time image\nclassifier. The presented model outperforms state-of-the-art unsupervised image\nclassification methods on large-scale diverse driving video dataset BDD100K.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 00:48:14 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 18:41:56 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Hamideche", "Sid Ali", ""], ["Chiaroni", "Florent", ""], ["Rahal", "Mohamed-Cherif", ""]]}, {"id": "1910.09100", "submitter": "Okyaz Eminaga", "authors": "Okyaz Eminaga, Mahmood Abbas, Yuri Tolkach, Rosalie Nolley, Christian\n  Kunder, Axel Semjonow, Martin Boegemann", "title": "Biologic and Prognostic Feature Scores from Whole-Slide Histology Images\n  Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histopathology is a reflection of the molecular changes and provides\nprognostic phenotypes representing the disease progression. In this study, we\nintroduced feature scores generated from hematoxylin and eosin histology images\nbased on deep learning (DL) models developed for prostate pathology. We\ndemonstrated that these feature scores were significantly prognostic for time\nto event endpoints (biochemical recurrence and cancer-specific survival) and\nhad simultaneously molecular biologic associations to relevant genomic\nalterations and molecular subtypes using already trained DL models that were\nnot previously exposed to the datasets of the current study. Further, we\ndiscussed the potential of such feature scores to improve the current tumor\ngrading system and the challenges that are associated with tumor heterogeneity\nand the development of prognostic models from histology images. Our findings\nuncover the potential of feature scores from histology images as digital\nbiomarkers in precision medicine and as an expanding utility for digital\npathology.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 01:18:42 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 06:15:11 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 14:49:55 GMT"}, {"version": "v4", "created": "Thu, 7 May 2020 01:24:51 GMT"}, {"version": "v5", "created": "Sat, 25 Jul 2020 07:17:33 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Eminaga", "Okyaz", ""], ["Abbas", "Mahmood", ""], ["Tolkach", "Yuri", ""], ["Nolley", "Rosalie", ""], ["Kunder", "Christian", ""], ["Semjonow", "Axel", ""], ["Boegemann", "Martin", ""]]}, {"id": "1910.09103", "submitter": "Xiaoran Qin", "authors": "Jintao Ke, Xiaoran Qin, Hai Yang, Zhengfei Zheng, Zheng Zhu, Jieping\n  Ye", "title": "Predicting origin-destination ride-sourcing demand with a\n  spatio-temporal encoder-decoder residual multi-graph convolutional network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of mobile-internet technologies, on-demand\nride-sourcing services have become increasingly popular and largely reshaped\nthe way people travel. Demand prediction is one of the most fundamental\ncomponents in supply-demand management systems of ride-sourcing platforms. With\naccurate short-term prediction for origin-destination (OD) demand, the\nplatforms make precise and timely decisions on real-time matching, idle vehicle\nreallocations and ride-sharing vehicle routing, etc. Compared to zone-based\ndemand prediction that has been examined by many previous studies, OD-based\ndemand prediction is more challenging. This is mainly due to the complicated\nspatial and temporal dependencies among demand of different OD pairs. To\novercome this challenge, we propose the Spatio-Temporal Encoder-Decoder\nResidual Multi-Graph Convolutional network (ST-ED-RMGC), a novel deep learning\nmodel for predicting ride-sourcing demand of various OD pairs. Firstly, the\nmodel constructs OD graphs, which utilize adjacent matrices to characterize the\nnon-Euclidean pair-wise geographical and semantic correlations among different\nOD pairs. Secondly, based on the constructed graphs, a residual multi-graph\nconvolutional (RMGC) network is designed to encode the contextual-aware spatial\ndependencies, and a long-short term memory (LSTM) network is used to encode the\ntemporal dependencies, into a dense vector space. Finally, we reuse the RMGC\nnetworks to decode the compressed vector back to OD graphs and predict the\nfuture OD demand. Through extensive experiments on the for-hire-vehicles\ndatasets in Manhattan, New York City, we show that our proposed deep learning\nframework outperforms the state-of-arts by a significant margin.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 13:27:25 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Ke", "Jintao", ""], ["Qin", "Xiaoran", ""], ["Yang", "Hai", ""], ["Zheng", "Zhengfei", ""], ["Zhu", "Zheng", ""], ["Ye", "Jieping", ""]]}, {"id": "1910.09106", "submitter": "Yoann Boget", "authors": "Yoann Boget (University of Neuch\\^atel)", "title": "Adversarial Regression. Generative Adversarial Networks for Non-Linear\n  Regression: Theory and Assessment", "comments": "Master thesis. Grade: 5.5/6", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adversarial Regression is a proposition to perform high dimensional\nnon-linear regression with uncertainty estimation. We used Conditional\nGenerative Adversarial Network to obtain an estimate of the full predictive\ndistribution for a new observation. Generative Adversarial Networks (GAN) are\nimplicit generative models which produce samples from a distribution\napproximating the distribution of the data. The conditional version of it\n(CGAN) takes the following expression: $\\min\\limits_G \\max\\limits_D V(D, G) =\n\\mathbb{E}_{x\\sim p_{r}(x)} [log(D(x, y))] + \\mathbb{E}_{z\\sim p_{z}(z)} [log\n(1-D(G(z, y)))]$. An approximate solution can be found by training\nsimultaneously two neural networks to model D and G and feeding G with a random\nnoise vector $z$. After training, we have that $G(z, y)\\mathrel{\\dot\\sim}\np_{data}(x, y)$. By fixing $y$, we have $G(z|y) \\mathrel{\\dot\\sim}\np{data}(x|y)$. By sampling $z$, we can therefore obtain samples following\napproximately $p(x|y)$, which is the predictive distribution of $x$ for a new\n$y$. We ran experiments to test various loss functions, data distributions,\nsample size, size of the noise vector, etc. Even if we observed differences, no\nexperiment outperformed consistently the others. The quality of CGAN for\nregression relies on fine-tuning a range of hyperparameters. In a broader view,\nthe results show that CGANs are very promising methods to perform uncertainty\nestimation for high dimensional non-linear regression.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 15:01:00 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Boget", "Yoann", "", "University of Neuch\u00e2tel"]]}, {"id": "1910.09108", "submitter": "Jongmin Yu", "authors": "Jongmin Yu", "title": "Boosting Mapping Functionality of Neural Networks via Latent Feature\n  Generation based on Reversible Learning", "comments": "9 pages, 5 figures, have been submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses a boosting method for mapping functionality of neural\nnetworks in visual recognition such as image classification and face\nrecognition. We present reversible learning for generating and learning latent\nfeatures using the network itself. By generating latent features corresponding\nto hard samples and applying the generated features in a training stage,\nreversible learning can improve a mapping functionality without additional data\naugmentation or handling the bias of dataset. We demonstrate an efficiency of\nthe proposed method on the MNIST,Cifar-10/100, and Extremely Biased and poorly\ncategorized dataset (EBPC dataset). The experimental results show that the\nproposed method can outperform existing state-of-the-art methods in visual\nrecognition. Extensive analysis shows that our method can efficiently improve\nthe mapping capability of a network.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 01:46:32 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Yu", "Jongmin", ""]]}, {"id": "1910.09113", "submitter": "Paul Soulos", "authors": "Paul Soulos, Tom McCoy, Tal Linzen, Paul Smolensky", "title": "Discovering the Compositional Structure of Vector Representations with\n  Role Learning Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can neural networks perform so well on compositional tasks even though\nthey lack explicit compositional representations? We use a novel analysis\ntechnique called ROLE to show that recurrent neural networks perform well on\nsuch tasks by converging to solutions which implicitly represent symbolic\nstructure. This method uncovers a symbolic structure which, when properly\nembedded in vector space, closely approximates the encodings of a standard\nseq2seq network trained to perform the compositional SCAN task. We verify the\ncausal importance of the discovered symbolic structure by showing that, when we\nsystematically manipulate hidden embeddings based on this symbolic structure,\nthe model's output is changed in the way predicted by our analysis.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 02:12:51 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 16:38:33 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 20:23:51 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Soulos", "Paul", ""], ["McCoy", "Tom", ""], ["Linzen", "Tal", ""], ["Smolensky", "Paul", ""]]}, {"id": "1910.09115", "submitter": "Jiaming Song", "authors": "Jiaming Song and Yang Song and Stefano Ermon", "title": "Unsupervised Out-of-Distribution Detection with Batch Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood from a generative model is a natural statistic for detecting\nout-of-distribution (OoD) samples. However, generative models have been shown\nto assign higher likelihood to OoD samples compared to ones from the training\ndistribution, preventing simple threshold-based detection rules. We demonstrate\nthat OoD detection fails even when using more sophisticated statistics based on\nthe likelihoods of individual samples. To address these issues, we propose a\nnew method that leverages batch normalization. We argue that batch\nnormalization for generative models challenges the traditional i.i.d. data\nassumption and changes the corresponding maximum likelihood objective. Based on\nthis insight, we propose to exploit in-batch dependencies for OoD detection.\nEmpirical results suggest that this leads to more robust detection for\nhigh-dimensional images.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 02:14:16 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Song", "Jiaming", ""], ["Song", "Yang", ""], ["Ermon", "Stefano", ""]]}, {"id": "1910.09116", "submitter": "Burhaneddin Yaman", "authors": "Burhaneddin Yaman, Seyed Amir Hossein Hosseini, Steen Moeller, Jutta\n  Ellermann, K\\^amil U\\v{g}urbil, Mehmet Ak\\c{c}akaya", "title": "Self-Supervised Physics-Based Deep Learning MRI Reconstruction Without\n  Fully-Sampled Data", "comments": "5 Pages, 5 Figures", "journal-ref": "Proceedings of IEEE ISBI, 2020", "doi": "10.1109/ISBI45749.2020.9098514", "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) has emerged as a tool for improving accelerated MRI\nreconstruction. A common strategy among DL methods is the physics-based\napproach, where a regularized iterative algorithm alternating between data\nconsistency and a regularizer is unrolled for a finite number of iterations.\nThis unrolled network is then trained end-to-end in a supervised manner, using\nfully-sampled data as ground truth for the network output. However, in a number\nof scenarios, it is difficult to obtain fully-sampled datasets, due to\nphysiological constraints such as organ motion or physical constraints such as\nsignal decay. In this work, we tackle this issue and propose a self-supervised\nlearning strategy that enables physics-based DL reconstruction without\nfully-sampled data. Our approach is to divide the acquired sub-sampled points\nfor each scan into training and validation subsets. During training, data\nconsistency is enforced over the training subset, while the validation subset\nis used to define the loss function. Results show that the proposed\nself-supervised learning method successfully reconstructs images without\nfully-sampled data, performing similarly to the supervised approach that is\ntrained with fully-sampled references. This has implications for physics-based\ninverse problem approaches for other settings, where fully-sampled data is not\navailable or possible to acquire.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 02:20:15 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Yaman", "Burhaneddin", ""], ["Hosseini", "Seyed Amir Hossein", ""], ["Moeller", "Steen", ""], ["Ellermann", "Jutta", ""], ["U\u01e7urbil", "K\u00e2mil", ""], ["Ak\u00e7akaya", "Mehmet", ""]]}, {"id": "1910.09119", "submitter": "Fei Deng", "authors": "Fei Deng, Zhuo Zhi, Sungjin Ahn", "title": "Generative Hierarchical Models for Parts, Objects, and Scenes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositional structures between parts and objects are inherent in natural\nscenes. Modeling such compositional hierarchies via unsupervised learning can\nbring various benefits such as interpretability and transferability, which are\nimportant in many downstream tasks. In this paper, we propose the first deep\nlatent variable model, called RICH, for learning Representation of\nInterpretable Compositional Hierarchies. At the core of RICH is a latent scene\ngraph representation that organizes the entities of a scene into a tree\nstructure according to their compositional relationships. During inference,\ntaking top-down approach, RICH is able to use higher-level representation to\nguide lower-level decomposition. This avoids the difficult problem of routing\nbetween parts and objects that is faced by bottom-up approaches. In experiments\non images containing multiple objects with different part compositions, we\ndemonstrate that RICH is able to learn the latent compositional hierarchy and\ngenerate imaginary scenes.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 02:28:16 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Deng", "Fei", ""], ["Zhi", "Zhuo", ""], ["Ahn", "Sungjin", ""]]}, {"id": "1910.09122", "submitter": "Chris Cannella", "authors": "Chris Cannella, Jie Ding, Mohammadreza Soltani, Vahid Tarokh", "title": "Perception-Distortion Trade-off with Restricted Boltzmann Machines", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a new procedure for applying Restricted Boltzmann\nMachines (RBMs) to missing data inference tasks, based on linearization of the\neffective energy function governing the distribution of observations. We\ncompare the performance of our proposed procedure with those obtained using\nexisting reconstruction procedures trained on incomplete data. We place these\nperformance comparisons within the context of the perception-distortion\ntrade-off observed in other data reconstruction tasks, which has, until now,\nremained unexplored in tasks relying on incomplete training data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 02:39:28 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Cannella", "Chris", ""], ["Ding", "Jie", ""], ["Soltani", "Mohammadreza", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1910.09126", "submitter": "Xiang Li", "authors": "Xiang Li, Wenhao Yang, Shusen Wang, Zhihua Zhang", "title": "Communication-Efficient Local Decentralized SGD Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the technique of local updates is a powerful tool in centralized\nsettings to improve communication efficiency via periodical communication. For\ndecentralized settings, it is still unclear how to efficiently combine local\nupdates and decentralized communication. In this work, we propose an algorithm\nnamed as LD-SGD, which incorporates arbitrary update schemes that alternate\nbetween multiple Local updates and multiple Decentralized SGDs, and provide an\nanalytical framework for LD-SGD. Under the framework, we present a sufficient\ncondition to guarantee the convergence. We show that LD-SGD converges to a\ncritical point for a wide range of update schemes when the objective is\nnon-convex and the training data are non-identically independent distributed.\nMoreover, our framework brings many insights into the design of update schemes\nfor decentralized optimization. As examples, we specify two update schemes and\nshow how they help improve communication efficiency. Specifically, the first\nscheme alternates the number of local and global update steps. From our\nanalysis, the ratio of the number of local updates to that of decentralized SGD\ntrades off communication and computation. The second scheme is to periodically\nshrink the length of local updates. We show that the decaying strategy helps\nimprove communication efficiency both theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 02:51:54 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 03:26:10 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 07:09:43 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 05:33:56 GMT"}, {"version": "v5", "created": "Mon, 5 Apr 2021 12:06:57 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Li", "Xiang", ""], ["Yang", "Wenhao", ""], ["Wang", "Shusen", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1910.09129", "submitter": "Pinky Sitikhu", "authors": "Pinky Sitikhu, Kritish Pahi, Pujan Thapa, Subarna Shakya", "title": "A Comparison of Semantic Similarity Methods for Maximum Human\n  Interpretability", "comments": "Accepted in IEEE International Conference on Artificial Intelligence\n  for Transforming Business and Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inclusion of semantic information in any similarity measures improves the\nefficiency of the similarity measure and provides human interpretable results\nfor further analysis. The similarity calculation method that focuses on\nfeatures related to the text's words only, will give less accurate results.\nThis paper presents three different methods that not only focus on the text's\nwords but also incorporates semantic information of texts in their feature\nvector and computes semantic similarities. These methods are based on\ncorpus-based and knowledge-based methods, which are: cosine similarity using\ntf-idf vectors, cosine similarity using word embedding and soft cosine\nsimilarity using word embedding. Among these three, cosine similarity using\ntf-idf vectors performed best in finding similarities between short news texts.\nThe similar texts given by the method are easy to interpret and can be used\ndirectly in other information retrieval applications.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 03:09:02 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 02:10:04 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Sitikhu", "Pinky", ""], ["Pahi", "Kritish", ""], ["Thapa", "Pujan", ""], ["Shakya", "Subarna", ""]]}, {"id": "1910.09131", "submitter": "Zhenwei Dai", "authors": "Zhenwei Dai, Anshumali Shrivastava", "title": "Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the\n  Classifier", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work suggests improving the performance of Bloom filter by\nincorporating a machine learning model as a binary classifier. However, such\nlearned Bloom filter does not take full advantage of the predicted probability\nscores. We proposed new algorithms that generalize the learned Bloom filter by\nusing the complete spectrum of the scores regions. We proved our algorithms\nhave lower False Positive Rate (FPR) and memory usage compared with the\nexisting approaches to learned Bloom filter. We also demonstrated the improved\nperformance of our algorithms on real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 03:21:24 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Dai", "Zhenwei", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1910.09139", "submitter": "Polina Zablotskaia", "authors": "Polina Zablotskaia, Aliaksandr Siarohin, Bo Zhao, Leonid Sigal", "title": "DwNet: Dense warp-based network for pose-guided human video generation", "comments": "Accepted to BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generation of realistic high-resolution videos of human subjects is a\nchallenging and important task in computer vision. In this paper, we focus on\nhuman motion transfer - generation of a video depicting a particular subject,\nobserved in a single image, performing a series of motions exemplified by an\nauxiliary (driving) video. Our GAN-based architecture, DwNet, leverages dense\nintermediate pose-guided representation and refinement process to warp the\nrequired subject appearance, in the form of the texture, from a source image\ninto a desired pose. Temporal consistency is maintained by further conditioning\nthe decoding process within a GAN on the previously generated frame. In this\nway a video is generated in an iterative and recurrent fashion. We illustrate\nthe efficacy of our approach by showing state-of-the-art quantitative and\nqualitative performance on two benchmark datasets: TaiChi and Fashion Modeling.\nThe latter is collected by us and will be made publicly available to the\ncommunity.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 03:56:51 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Zablotskaia", "Polina", ""], ["Siarohin", "Aliaksandr", ""], ["Zhao", "Bo", ""], ["Sigal", "Leonid", ""]]}, {"id": "1910.09143", "submitter": "Yijia Wang", "authors": "Yijia Wang, Matthias Poloczek, Daniel R. Jiang", "title": "Exploration via Cost-Aware Subgoal Design", "comments": "Presented at TARL, ICLR 2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of exploration in unknown environments continues to pose a\nchallenge for reinforcement learning algorithms, as interactions with the\nenvironment are usually expensive or limited. The technique of setting subgoals\nwith an intrinsic reward allows for the use of supplemental feedback to aid\nagent in environment with sparse and delayed rewards. In fact, it can be an\neffective tool in directing the exploration behavior of the agent toward useful\nparts of the state space. In this paper, we consider problems where an agent\nfaces an unknown task in the future and is given prior opportunities to\n``practice'' on related tasks where the interactions are still expensive. We\npropose a one-step Bayes-optimal algorithm for selecting subgoal designs, along\nwith the number of episodes and the episode length, to efficiently maximize the\nexpected performance of an agent. We demonstrate its excellent performance on a\nvariety of tasks and also prove an asymptotic optimality guarantee.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 04:24:29 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 00:02:42 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Wang", "Yijia", ""], ["Poloczek", "Matthias", ""], ["Jiang", "Daniel R.", ""]]}, {"id": "1910.09152", "submitter": "Gang Chen", "authors": "Gang Chen", "title": "A New Framework for Multi-Agent Reinforcement Learning -- Centralized\n  Training and Exploration with Decentralized Execution via Policy Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) is a booming area of artificial\nintelligence. Many practical applications of DRL naturally involve more than\none collaborative learners, making it important to study DRL in a multi-agent\ncontext. Previous research showed that effective learning in complex\nmulti-agent systems demands for highly coordinated environment exploration\namong all the participating agents. Many researchers attempted to cope with\nthis challenge through learning centralized value functions. However, the\ncommon strategy for every agent to learn their local policies directly often\nfail to nurture strong inter-agent collaboration and can be sample inefficient\nwhenever agents alter their communication channels. To address these issues, we\npropose a new framework known as centralized training and exploration with\ndecentralized execution via policy distillation. Guided by this framework and\nthe maximum-entropy learning technique, we will first train agents' policies\nwith shared global component to foster coordinated and effective learning.\nLocally executable policies will be derived subsequently from the trained\nglobal policies via policy distillation. Experiments show that our new\nframework and algorithm can achieve significantly better performance and higher\nsample efficiency than a cutting-edge baseline on several multi-agent DRL\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 05:07:42 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Chen", "Gang", ""]]}, {"id": "1910.09153", "submitter": "Lu Bai", "authors": "Lu Bai, Lixin Cui, Lixiang Xu, Yue Wang, Zhihong Zhang, Edwin R.\n  Hancock", "title": "Entropic Dynamic Time Warping Kernels for Co-evolving Financial Time\n  Series Analysis", "comments": "Previously, the original version of this manuscript appeared as\n  arXiv:1902.09947v2, that was submitted as a replacement by a mistake. Now,\n  that article has been replaced to correct the error, and this manuscript is\n  distinct from that article", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2020", "doi": "10.1109/TNNLS.2020.3006738", "report-no": null, "categories": "q-fin.ST cs.AI cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a novel framework to measure the similarity between\ndynamic financial networks, i.e., time-varying financial networks.\nParticularly, we explore whether the proposed similarity measure can be\nemployed to understand the structural evolution of the financial networks with\ntime. For a set of time-varying financial networks with each vertex\nrepresenting the individual time series of a different stock and each edge\nbetween a pair of time series representing the absolute value of their Pearson\ncorrelation, our start point is to compute the commute time matrix associated\nwith the weighted adjacency matrix of the network structures, where each\nelement of the matrix can be seen as the enhanced correlation value between\npairwise stocks. For each network, we show how the commute time matrix allows\nus to identify a reliable set of dominant correlated time series as well as an\nassociated dominant probability distribution of the stock belonging to this\nset. Furthermore, we represent each original network as a discrete dominant\nShannon entropy time series computed from the dominant probability\ndistribution. With the dominant entropy time series for each pair of financial\nnetworks to hand, we develop a similarity measure based on the classical\ndynamic time warping framework, for analyzing the financial time-varying\nnetworks. We show that the proposed similarity measure is positive definite and\nthus corresponds to a kernel measure on graphs. The proposed kernel bridges the\ngap between graph kernels and the classical dynamic time warping framework for\nmultiple financial time series analysis. Experiments on time-varying networks\nextracted through New York Stock Exchange (NYSE) database demonstrate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 05:08:09 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Bai", "Lu", ""], ["Cui", "Lixin", ""], ["Xu", "Lixiang", ""], ["Wang", "Yue", ""], ["Zhang", "Zhihong", ""], ["Hancock", "Edwin R.", ""]]}, {"id": "1910.09158", "submitter": "S Indrapriyadarsini", "authors": "S. Indrapriyadarsini, Shahrzad Mahboubi, Hiroshi Ninomiya and Hideki\n  Asai", "title": "Implementation of a modified Nesterov's Accelerated quasi-Newton Method\n  on Tensorflow", "comments": "Paper published in 2018 17th IEEE International Conference on Machine\n  Learning and Applications (ICMLA)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00185", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies incorporate Nesterov's accelerated gradient method for the\nacceleration of gradient based training. The Nesterov's Accelerated\nQuasi-Newton (NAQ) method has shown to drastically improve the convergence\nspeed compared to the conventional quasi-Newton method. This paper implements\nNAQ for non-convex optimization on Tensorflow. Two modifications have been\nproposed to the original NAQ algorithm to ensure global convergence and\neliminate linesearch. The performance of the proposed algorithm - mNAQ is\nevaluated on standard non-convex function approximation benchmark problems and\nmicrowave circuit modelling problems. The results show that the improved\nalgorithm converges better and faster compared to first order optimizers such\nas AdaGrad, RMSProp, Adam, and the second order methods such as the\nquasi-Newton method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 05:59:19 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Indrapriyadarsini", "S.", ""], ["Mahboubi", "Shahrzad", ""], ["Ninomiya", "Hiroshi", ""], ["Asai", "Hideki", ""]]}, {"id": "1910.09161", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu, Henry Shaowu Yuchi, Minghe Zhang, Yao Xie", "title": "Sequential Adversarial Anomaly Detection for One-Class Event Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the sequential anomaly detection problem in the one-class setting\nwhen only the anomalous sequences are available and propose an adversarial\nsequential detector by solving a minimax problem to find an optimal detector\nagainst the worst-case sequences from a generator. The generator captures the\ndependence in sequential events using the marked point process model. The\ndetector sequentially evaluates the likelihood of a test sequence and compares\nit with a time-varying threshold, also learned from data through the minimax\nproblem. We demonstrate our proposed method's good performance using numerical\nexperiments on simulations and proprietary large-scale credit card fraud\ndatasets. The proposed method can generally apply to detecting anomalous\nsequences.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 06:12:47 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 19:25:55 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 23:23:18 GMT"}, {"version": "v4", "created": "Sun, 21 Feb 2021 23:46:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zhu", "Shixiang", ""], ["Yuchi", "Henry Shaowu", ""], ["Zhang", "Minghe", ""], ["Xie", "Yao", ""]]}, {"id": "1910.09165", "submitter": "Xingyu Liu", "authors": "Xingyu Liu, Mengyuan Yan, Jeannette Bohg", "title": "MeteorNet: Deep Learning on Dynamic 3D Point Cloud Sequences", "comments": "ICCV 2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding dynamic 3D environment is crucial for robotic agents and many\nother applications. We propose a novel neural network architecture called\n$MeteorNet$ for learning representations for dynamic 3D point cloud sequences.\nDifferent from previous work that adopts a grid-based representation and\napplies 3D or 4D convolutions, our network directly processes point clouds. We\npropose two ways to construct spatiotemporal neighborhoods for each point in\nthe point cloud sequence. Information from these neighborhoods is aggregated to\nlearn features per point. We benchmark our network on a variety of 3D\nrecognition tasks including action recognition, semantic segmentation and scene\nflow estimation. MeteorNet shows stronger performance than previous grid-based\nmethods while achieving state-of-the-art performance on Synthia. MeteorNet also\noutperforms previous baseline methods that are able to process at most two\nconsecutive point clouds. To the best of our knowledge, this is the first work\non deep learning for dynamic raw point cloud sequences.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 06:31:48 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 00:22:14 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Liu", "Xingyu", ""], ["Yan", "Mengyuan", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1910.09168", "submitter": "Pritam Anand South Asian University", "authors": "Pritam Anand, Reshma Rastogi and Suresh Chandra", "title": "A $\\nu$- support vector quantile regression model with automatic\n  accuracy control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel '$\\nu$-support vector quantile regression'\n($\\nu$-SVQR) model for the quantile estimation. It can facilitate the automatic\ncontrol over accuracy by creating a suitable asymmetric $\\epsilon$-insensitive\nzone according to the variance present in data. The proposed $\\nu$-SVQR model\nuses the $\\nu$ fraction of training data points for the estimation of the\nquantiles. In the $\\nu$-SVQR model, training points asymptotically appear above\nand below of the asymmetric $\\epsilon$-insensitive tube in the ratio of\n$1-\\tau$ and $\\tau$. Further, there are other interesting properties of the\nproposed $\\nu$-SVQR model, which we have briefly described in this paper. These\nproperties have been empirically verified using the artificial and real world\ndataset also.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 06:40:05 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Anand", "Pritam", ""], ["Rastogi", "Reshma", ""], ["Chandra", "Suresh", ""]]}, {"id": "1910.09170", "submitter": "Sangwoo Mo", "authors": "Sangwoo Mo, Chiheon Kim, Sungwoong Kim, Minsu Cho, Jinwoo Shin", "title": "Mining GOLD Samples for Conditional GANs", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional generative adversarial networks (cGANs) have gained a\nconsiderable attention in recent years due to its class-wise controllability\nand superior quality for complex generation tasks. We introduce a simple yet\neffective approach to improving cGANs by measuring the discrepancy between the\ndata distribution and the model distribution on given samples. The proposed\nmeasure, coined the gap of log-densities (GOLD), provides an effective\nself-diagnosis for cGANs while being efficienty computed from the\ndiscriminator. We propose three applications of the GOLD: example re-weighting,\nrejection sampling, and active learning, which improve the training, inference,\nand data selection of cGANs, respectively. Our experimental results demonstrate\nthat the proposed methods outperform corresponding baselines for all three\napplications on different image datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 06:49:32 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Mo", "Sangwoo", ""], ["Kim", "Chiheon", ""], ["Kim", "Sungwoong", ""], ["Cho", "Minsu", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1910.09172", "submitter": "Cong Luong Nguyen", "authors": "Huy T. Nguyen, Nguyen Cong Luong, Jun Zhao, Chau Yuen, and Dusit\n  Niyato", "title": "Resource Allocation in Mobility-Aware Federated Learning Networks: A\n  Deep Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning allows mobile devices, i.e., workers, to use their local\ndata to collaboratively train a global model required by the model owner.\nFederated learning thus addresses the privacy issues of traditional machine\nlearning. However, federated learning faces the energy constraints of the\nworkers and the high network resource cost due to the fact that a number of\nglobal model transmissions may be required to achieve the target accuracy. To\naddress the energy constraint, a power beacon can be used that recharges energy\nto the workers. However, the model owner may need to pay an energy cost to the\npower beacon for the energy recharge. To address the high network resource\ncost, the model owner can use a WiFi channel, called default channel, for the\nglobal model transmissions. However, communication interruptions may occur due\nto the instability of the default channel quality. For this, special channels\nsuch as LTE channels can be used, but this incurs channel cost. As such, the\nproblem of the model owner is to decide amounts of energy recharged to the\nworkers and to choose channels used to transmit its global model to the workers\nto maximize the number of global model transmissions while minimizing the\nenergy and channel costs. This is challenging for the model owner under the\nuncertainty of the channel, energy and mobility states of the workers. In this\npaper, we thus propose to employ the Deep Q-Network (DQN) that enables the\nmodel owner to find the optimal decisions on the energy and the channels\nwithout any a priori network knowledge. Simulation results show that the\nproposed DQN always achieves better performance compared to the conventional\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 06:54:52 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Nguyen", "Huy T.", ""], ["Luong", "Nguyen Cong", ""], ["Zhao", "Jun", ""], ["Yuen", "Chau", ""], ["Niyato", "Dusit", ""]]}, {"id": "1910.09185", "submitter": "Zhuang Liu", "authors": "Zhuang Liu, Tinghui Zhou, Hung-Ju Wang, Zhiqiang Shen, Bingyi Kang,\n  Evan Shelhamer, Trevor Darrell", "title": "Transferable Recognition-Aware Image Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in image recognition has stimulated the deployment of vision\nsystems at an unprecedented scale. As a result, visual data are now often\nconsumed not only by humans but also by machines. Existing image processing\nmethods only optimize for better human perception, yet the resulting images may\nnot be accurately recognized by machines. This can be undesirable, e.g., the\nimages can be improperly handled by search engines or recommendation systems.\nIn this work, we propose simple approaches to improve machine interpretability\nof processed images: optimizing the recognition loss directly on the image\nprocessing network or through an intermediate transforming model.\nInterestingly, the processing model's ability to enhance recognition quality\ncan transfer when evaluated on models of different architectures, recognized\ncategories, tasks and training datasets. This makes the solutions applicable\neven when we do not have the knowledge of future recognition models, e.g., if\nwe upload processed images to the Internet. We conduct experiments on multiple\nimage processing tasks, with ImageNet classification and PASCAL VOC detection\nas recognition tasks. With our simple methods, substantial accuracy gain can be\nachieved with strong transferability and minimal image quality loss. Through a\nuser study we further show that the accuracy gain can transfer to a black-box,\nthird-party cloud model. Finally, we try to explain this transferability\nphenomenon by demonstrating the similarities of different models' decision\nboundaries. Code is available at https://github.com/liuzhuang13/Transferable_RA .\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 07:36:15 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 14:32:36 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Liu", "Zhuang", ""], ["Zhou", "Tinghui", ""], ["Wang", "Hung-Ju", ""], ["Shen", "Zhiqiang", ""], ["Kang", "Bingyi", ""], ["Shelhamer", "Evan", ""], ["Darrell", "Trevor", ""]]}, {"id": "1910.09191", "submitter": "Zhuang Liu", "authors": "Zhuang Liu, Xuanlin Li, Bingyi Kang, Trevor Darrell", "title": "Regularization Matters in Policy Optimization -- An Empirical Study on\n  Continuous Control", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (Deep RL) has been receiving increasingly more\nattention thanks to its encouraging performance on a variety of control tasks.\nYet, conventional regularization techniques in training neural networks (e.g.,\n$L_2$ regularization, dropout) have been largely ignored in RL methods,\npossibly because agents are typically trained and evaluated in the same\nenvironment, and because the deep RL community focuses more on high-level\nalgorithm designs. In this work, we present the first comprehensive study of\nregularization techniques with multiple policy optimization algorithms on\ncontinuous control tasks. Interestingly, we find conventional regularization\ntechniques on the policy networks can often bring large improvement, especially\non harder tasks. Our findings are shown to be robust against training\nhyperparameter variations. We also compare these techniques with the more\nwidely used entropy regularization. In addition, we study regularizing\ndifferent components and find that only regularizing the policy network is\ntypically the best. We further analyze why regularization may help\ngeneralization in RL from four perspectives - sample complexity, reward\ndistribution, weight norm, and noise robustness. We hope our study provides\nguidance for future practices in regularizing policy optimization algorithms.\nOur code is available at https://github.com/xuanlinli17/iclr2021_rlreg .\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 08:00:33 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 10:19:31 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 13:53:13 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 04:57:59 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Liu", "Zhuang", ""], ["Li", "Xuanlin", ""], ["Kang", "Bingyi", ""], ["Darrell", "Trevor", ""]]}, {"id": "1910.09200", "submitter": "Zhikang Wang Mr.", "authors": "Zhikang T. Wang, Yuto Ashida, Masahito Ueda", "title": "Deep Reinforcement Learning Control of Quantum Cartpoles", "comments": "5+4 pages, 2+2 figures, 2+2 tables, 5 videos at an external link", "journal-ref": "Phys. Rev. Lett. 125, 100401 (2020)", "doi": "10.1103/PhysRevLett.125.100401", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize a standard benchmark of reinforcement learning, the classical\ncartpole balancing problem, to the quantum regime by stabilizing a particle in\nan unstable potential through measurement and feedback. We use state-of-the-art\ndeep reinforcement learning to stabilize a quantum cartpole and find that our\ndeep learning approach performs comparably to or better than other strategies\nin standard control theory. Our approach also applies to measurement-feedback\ncooling of quantum oscillators, showing the applicability of deep learning to\ngeneral continuous-space quantum control.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 08:24:24 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 08:19:17 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 13:42:02 GMT"}, {"version": "v4", "created": "Sat, 5 Sep 2020 09:29:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Wang", "Zhikang T.", ""], ["Ashida", "Yuto", ""], ["Ueda", "Masahito", ""]]}, {"id": "1910.09223", "submitter": "Chao Zhang", "authors": "Chao Zhang, Jiahao Xie, Zebang Shen, Peilin Zhao, Tengfei Zhou, Hui\n  Qian", "title": "Aggregated Gradient Langevin Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore a general Aggregated Gradient Langevin Dynamics\nframework (AGLD) for the Markov Chain Monte Carlo (MCMC) sampling. We\ninvestigate the nonasymptotic convergence of AGLD with a unified analysis for\ndifferent data accessing (e.g. random access, cyclic access and random\nreshuffle) and snapshot updating strategies, under convex and nonconvex\nsettings respectively. It is the first time that bounds for I/O friendly\nstrategies such as cyclic access and random reshuffle have been established in\nthe MCMC literature. The theoretic results also indicate that methods in AGLD\npossess the merits of both the low per-iteration computational complexity and\nthe short mixture time. Empirical studies demonstrate that our framework allows\nto derive novel schemes to generate high-quality samples for large-scale\nBayesian posterior learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 09:18:20 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Zhang", "Chao", ""], ["Xie", "Jiahao", ""], ["Shen", "Zebang", ""], ["Zhao", "Peilin", ""], ["Zhou", "Tengfei", ""], ["Qian", "Hui", ""]]}, {"id": "1910.09227", "submitter": "Alisa Kirichenko", "authors": "Rianne de Heide and Alisa Kirichenko and Nishant Mehta and Peter\n  Gr\\\"unwald", "title": "Safe-Bayesian Generalized Linear Regression", "comments": "Final version. Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study generalized Bayesian inference under misspecification, i.e. when the\nmodel is 'wrong but useful'. Generalized Bayes equips the likelihood with a\nlearning rate $\\eta$. We show that for generalized linear models (GLMs),\n$\\eta$-generalized Bayes concentrates around the best approximation of the\ntruth within the model for specific $\\eta \\neq 1$, even under severely\nmisspecified noise, as long as the tails of the true distribution are\nexponential. We derive MCMC samplers for generalized Bayesian lasso and\nlogistic regression and give examples of both simulated and real-world data in\nwhich generalized Bayes substantially outperforms standard Bayes.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 09:32:26 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:20:14 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 21:52:38 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["de Heide", "Rianne", ""], ["Kirichenko", "Alisa", ""], ["Mehta", "Nishant", ""], ["Gr\u00fcnwald", "Peter", ""]]}, {"id": "1910.09234", "submitter": "Tobias Alt", "authors": "Tobias Alt and Joachim Weickert", "title": "Learning a Generic Adaptive Wavelet Shrinkage Function for Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of machine learning in image processing has created a gap between\ntrainable data-driven and classical model-driven approaches: While\nlearning-based models often show superior performance, classical ones are often\nmore transparent. To reduce this gap, we introduce a generic wavelet shrinkage\nfunction for denoising which is adaptive to both the wavelet scales as well as\nthe noise standard deviation. It is inferred from trained results of a tightly\nparametrised function which is inherited from nonlinear diffusion. Our proposed\nshrinkage function is smooth and compact while only using two parameters. In\ncontrast to many existing shrinkage functions, it is able to enhance image\nstructures by amplifying wavelet coefficients. Experiments show that it\noutperforms classical shrinkage functions by a significant margin.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 09:38:19 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 07:18:23 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 08:30:31 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Alt", "Tobias", ""], ["Weickert", "Joachim", ""]]}, {"id": "1910.09239", "submitter": "Jan Philip G\\\"opfert", "authors": "Jan Philip G\\\"opfert and Heiko Wersing and Barbara Hammer", "title": "Recovering Localized Adversarial Attacks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30487-4_24", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have achieved great successes over recent\nyears, particularly in the domain of computer vision. They are fast,\nconvenient, and -- thanks to mature frameworks -- relatively easy to implement\nand deploy. However, their reasoning is hidden inside a black box, in spite of\na number of proposed approaches that try to provide human-understandable\nexplanations for the predictions of neural networks. It is still a matter of\ndebate which of these explainers are best suited for which situations, and how\nto quantitatively evaluate and compare them. In this contribution, we focus on\nthe capabilities of explainers for convolutional deep neural networks in an\nextreme situation: a setting in which humans and networks fundamentally\ndisagree. Deep neural networks are susceptible to adversarial attacks that\ndeliberately modify input samples to mislead a neural network's classification,\nwithout affecting how a human observer interprets the input. Our goal with this\ncontribution is to evaluate explainers by investigating whether they can\nidentify adversarially attacked regions of an image. In particular, we\nquantitatively and qualitatively investigate the capability of three popular\nexplainers of classifications -- classic salience, guided backpropagation, and\nLIME -- with respect to their ability to identify regions of attack as the\nexplanatory regions for the (incorrect) prediction in representative examples\nfrom image classification. We find that LIME outperforms the other explainers.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 09:53:44 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["G\u00f6pfert", "Jan Philip", ""], ["Wersing", "Heiko", ""], ["Hammer", "Barbara", ""]]}, {"id": "1910.09246", "submitter": "Federico Cabitza", "authors": "Federico Cabitza and Andrea Campagner", "title": "Who wants accurate models? Arguing for a different metrics to take\n  classification models seriously", "comments": "https://github.com/AndreaCampagner/uncertainpy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the increasing availability of AI-based decision support, there is an\nincreasing need for their certification by both AI manufacturers and notified\nbodies, as well as the pragmatic (real-world) validation of these systems.\nTherefore, there is the need for meaningful and informative ways to assess the\nperformance of AI systems in clinical practice. Common metrics (like accuracy\nscores and areas under the ROC curve) have known problems and they do not take\ninto account important information about the preferences of clinicians and the\nneeds of their specialist practice, like the likelihood and impact of errors\nand the complexity of cases. In this paper, we present a new accuracy measure,\nthe H-accuracy (Ha), which we claim is more informative in the medical domain\n(and others of similar needs) for the elements it encompasses. We also provide\nproof that the H-accuracy is a generalization of the balanced accuracy and\nestablish a relation between the H-accuracy and the Net Benefit. Finally, we\nillustrate an experimentation in two user studies to show the descriptive power\nof the Ha score and how complementary and differently informative measures can\nbe derived from its formulation (a Python script to compute Ha is also made\navailable).\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 10:04:50 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 12:32:56 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Cabitza", "Federico", ""], ["Campagner", "Andrea", ""]]}, {"id": "1910.09255", "submitter": "Gaurav Singh", "authors": "Gaurav Singh, Zahra Sabet, John Shawe-Taylor, James Thomas", "title": "Constructing Artificial Data for Fine-tuning for Low-Resource Biomedical\n  Text Tagging with Applications in PICO Annotation", "comments": "International Workshop on Health Intelligence (W3PHIAI-20); AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical text tagging systems are plagued by the dearth of labeled training\ndata. There have been recent attempts at using pre-trained encoders to deal\nwith this issue. Pre-trained encoder provides representation of the input text\nwhich is then fed to task-specific layers for classification. The entire\nnetwork is fine-tuned on the labeled data from the target task. Unfortunately,\na low-resource biomedical task often has too few labeled instances for\nsatisfactory fine-tuning. Also, if the label space is large, it contains few or\nno labeled instances for majority of the labels. Most biomedical tagging\nsystems treat labels as indexes, ignoring the fact that these labels are often\nconcepts expressed in natural language e.g. `Appearance of lesion on brain\nimaging'. To address these issues, we propose constructing extra labeled\ninstances using label-text (i.e. label's name) as input for the corresponding\nlabel-index (i.e. label's index). In fact, we propose a number of strategies\nfor manufacturing multiple artificial labeled instances from a single label.\nThe network is then fine-tuned on a combination of real and these newly\nconstructed artificial labeled instances. We evaluate the proposed approach on\nan important low-resource biomedical task called \\textit{PICO annotation},\nwhich requires tagging raw text describing clinical trials with labels\ncorresponding to different aspects of the trial i.e. PICO (Population,\nIntervention/Control, Outcome) characteristics of the trial. Our empirical\nresults show that the proposed method achieves a new state-of-the-art\nperformance for PICO annotation with very significant improvements over\ncompetitive baselines.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 10:19:53 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 15:10:16 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 22:29:49 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Singh", "Gaurav", ""], ["Sabet", "Zahra", ""], ["Shawe-Taylor", "John", ""], ["Thomas", "James", ""]]}, {"id": "1910.09259", "submitter": "Michael Pearce", "authors": "Michael Pearce, Matthias Poloczek, Juergen Branke", "title": "Bayesian Optimization Allowing for Common Random Numbers", "comments": "21 pages + Appendix, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a powerful tool for expensive stochastic black-box\noptimization problems such as simulation-based optimization or machine learning\nhyperparameter tuning. Many stochastic objective functions implicitly require a\nrandom number seed as input. By explicitly reusing a seed a user can exploit\ncommon random numbers, comparing two or more inputs under the same randomly\ngenerated scenario, such as a common customer stream in a job shop problem, or\nthe same random partition of training data into training and validation set for\na machine learning algorithm. With the aim of finding an input with the best\naverage performance over infinitely many seeds, we propose a novel Gaussian\nprocess model that jointly models both the output for each seed and the\naverage. We then introduce the Knowledge gradient for Common Random Numbers\nthat iteratively determines a combination of input and random seed to evaluate\nthe objective and automatically trades off reusing old seeds and querying new\nseeds, thus overcoming the need to evaluate inputs in batches or measuring\ndifferences of pairs as suggested in previous methods. We investigate the\nKnowledge Gradient for Common Random Numbers both theoretically and\nempirically, finding it achieves significant performance improvements with only\nmoderate added computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 10:43:07 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Pearce", "Michael", ""], ["Poloczek", "Matthias", ""], ["Branke", "Juergen", ""]]}, {"id": "1910.09266", "submitter": "Emad Grais", "authors": "Emad M. Grais, Fei Zhao, Mark D. Plumbley", "title": "Multi-Band Multi-Resolution Fully Convolutional Neural Networks for\n  Singing Voice Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks with convolutional layers usually process the entire\nspectrogram of an audio signal with the same time-frequency resolutions, number\nof filters, and dimensionality reduction scale. According to the constant-Q\ntransform, good features can be extracted from audio signals if the low\nfrequency bands are processed with high frequency resolution filters and the\nhigh frequency bands with high time resolution filters. In the spectrogram of a\nmixture of singing voices and music signals, there is usually more information\nabout the voice in the low frequency bands than the high frequency bands. These\nraise the need for processing each part of the spectrogram differently. In this\npaper, we propose a multi-band multi-resolution fully convolutional neural\nnetwork (MBR-FCN) for singing voice separation. The MBR-FCN processes the\nfrequency bands that have more information about the target signals with more\nfilters and smaller dimentionality reduction scale than the bands with less\ninformation. Furthermore, the MBR-FCN processes the low frequency bands with\nhigh frequency resolution filters and the high frequency bands with high time\nresolution filters. Our experimental results show that the proposed MBR-FCN\nwith very few parameters achieves better singing voice separation performance\nthan other deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 11:29:29 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Grais", "Emad M.", ""], ["Zhao", "Fei", ""], ["Plumbley", "Mark D.", ""]]}, {"id": "1910.09276", "submitter": "Ezra Tampubolon", "authors": "Ezra Tampubolon and Holger Boche", "title": "Semi-Decentralized Coordinated Online Learning for Continuous Games with\n  Coupled Constraints via Augmented Lagrangian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of concave continuous games in which the corresponding\nadmissible strategy profile of each player underlies affine coupling\nconstraints. We propose a novel algorithm that leads the relevant population\ndynamic toward Nash equilibrium. This algorithm is based on a mirror ascent\nalgorithm, which suits with the framework of no-regret online learning, and on\nthe augmented Lagrangian method. The decentralization aspect of the algorithm\ncorresponds to the aspects that the iterate of each player requires the local\ninformation about how she contributes to the coupling constraints and the price\nvector broadcasted by a central coordinator. So each player needs not know\nabout the population action. Moreover, no specific control by the central\nprimary coordinator is required. We give a condition on the step sizes and the\ndegree of the augmentation of the Lagrangian, such that the proposed algorithm\nconverges to a generalized Nash equilibrium.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 11:55:39 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Tampubolon", "Ezra", ""], ["Boche", "Holger", ""]]}, {"id": "1910.09279", "submitter": "Markus Gusenbauer", "authors": "Markus Gusenbauer, Harald Oezelt, Johann Fischbacher, Alexander\n  Kovacs, Panpan Zhao, Thomas George Woodcock and Thomas Schrefl", "title": "Extracting local switching fields in permanent magnets using machine\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microstructural features play an important role for the quality of permanent\nmagnets. The coercivity is greatly influenced by crystallographic defects,\nwhich is well known for MnAl-C, for example. In this work we show a direct link\nof microstructural features to the local coercivity of MnAl-C grains by machine\nlearning. A large number of micromagnetic simulations is performed directly\nfrom Electron Backscatter Diffraction (EBSD) data using an automated meshing,\nmodeling and simulation procedure. Decision trees are trained with the\nsimulation results and predict local switching fields from new microscopic data\nwithin seconds.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:03:34 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 12:49:48 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 10:12:04 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Gusenbauer", "Markus", ""], ["Oezelt", "Harald", ""], ["Fischbacher", "Johann", ""], ["Kovacs", "Alexander", ""], ["Zhao", "Panpan", ""], ["Woodcock", "Thomas George", ""], ["Schrefl", "Thomas", ""]]}, {"id": "1910.09281", "submitter": "Joshua Hare", "authors": "Joshua Hare", "title": "Dealing with Sparse Rewards in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successfully navigating a complex environment to obtain a desired outcome is\na difficult task, that up to recently was believed to be capable only by\nhumans. This perception has been broken down over time, especially with the\nintroduction of deep reinforcement learning, which has greatly increased the\ndifficulty of tasks that can be automated. However, for traditional\nreinforcement learning agents this requires an environment to be able to\nprovide frequent extrinsic rewards, which are not known or accessible for many\nreal-world environments. This project aims to explore and contrast existing\nreinforcement learning solutions that circumnavigate the difficulties of an\nenvironment that provide sparse rewards. Different reinforcement solutions will\nbe implemented over a several video game environments with varying difficulty\nand varying frequency of rewards, as to properly investigate the applicability\nof these solutions. This project introduces a novel reinforcement learning\nsolution by combining aspects of two existing state of the art sparse reward\nsolutions, curiosity driven exploration and unsupervised auxiliary tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:06:28 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 14:18:31 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Hare", "Joshua", ""]]}, {"id": "1910.09282", "submitter": "Ezra Tampubolon", "authors": "Ezra Tampubolon and Holger Boche", "title": "Robust Online Learning for Resource Allocation -- Beyond Euclidean\n  Projection and Dynamic Fit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online-learning literature has focused on designing algorithms that ensure\nsub-linear growth of the cumulative long-term constraint violations. The\ndrawback of this guarantee is that strictly feasible actions may cancel out\nconstraint violations on other time slots. For this reason, we introduce a new\nperformance measure called $\\hCFit$, whose particular instance is the\ncumulative positive part of the constraint violations. We propose a class of\nnon-causal algorithms for online-decision making, which guarantees, in slowly\nchanging environments, sub-linear growth of this quantity despite noisy\nfirst-order feedback. Furthermore, we demonstrate by numerical experiments the\nperformance gain of our method relative to the state of art.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:09:38 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Tampubolon", "Ezra", ""], ["Boche", "Holger", ""]]}, {"id": "1910.09284", "submitter": "Andreas Barthelme", "authors": "Andreas Barthelme, Reinhard Wiesmayr and Wolfgang Utschick", "title": "Model Order Selection in DoA Scenarios via Cross-Entropy based Machine\n  Learning Techniques", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053029", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a machine learning approach for estimating the\nnumber of incident wavefronts in a direction of arrival scenario. In contrast\nto previous works, a multilayer neural network with a cross-entropy objective\nis trained. Furthermore, we investigate an online training procedure that\nallows an adaption of the neural network to imperfections of an antenna array\nwithout explicitly calibrating the array manifold. We show via simulations that\nthe proposed method outperforms classical model order selection schemes based\non information criteria in terms of accuracy, especially for a small number of\nsnapshots and at low signal-to-noise-ratios. Also, the online training\nprocedure enables the neural network to adapt with only a few online training\nsamples, if initialized by offline training on artificial data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:13:24 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Barthelme", "Andreas", ""], ["Wiesmayr", "Reinhard", ""], ["Utschick", "Wolfgang", ""]]}, {"id": "1910.09293", "submitter": "Yang Qu", "authors": "Ming-Xi Wang, Yang Qu", "title": "Approximation capabilities of neural networks on unbounded domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove that a shallow neural network with a monotone\nsigmoid, ReLU, ELU, Softplus, or LeakyReLU activation function can arbitrarily\nwell approximate any L^p(p>=2) integrable functions defined on R*[0,1]^n. We\nalso prove that a shallow neural network with a sigmoid, ReLU, ELU, Softplus,\nor LeakyReLU activation function expresses no nonzero integrable function\ndefined on the Euclidean plane. Together with a recent result that the deep\nReLU network can arbitrarily well approximate any integrable function on\nEuclidean spaces, we provide a new perspective on the advantage of multiple\nhidden layers in the context of ReLU networks. Lastly, we prove that the ReLU\nnetwork with depth 3 is a universal approximator in L^p(R^n).\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:25:29 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 10:02:34 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 21:24:22 GMT"}, {"version": "v4", "created": "Wed, 1 Jan 2020 00:04:32 GMT"}, {"version": "v5", "created": "Thu, 20 Feb 2020 22:32:35 GMT"}, {"version": "v6", "created": "Sun, 16 Aug 2020 14:31:59 GMT"}, {"version": "v7", "created": "Thu, 20 Aug 2020 08:24:48 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Wang", "Ming-Xi", ""], ["Qu", "Yang", ""]]}, {"id": "1910.09308", "submitter": "Dominik M\\\"uller", "authors": "Dominik M\\\"uller and Frank Kramer", "title": "MIScnn: A Framework for Medical Image Segmentation with Convolutional\n  Neural Networks and Deep Learning", "comments": "Open-source Python framework available on GitHub\n  (https://github.com/frankkramer-lab/MIScnn) and PyPI (miscnn). 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased availability and usage of modern medical imaging induced a\nstrong need for automatic medical image segmentation. Still, current image\nsegmentation platforms do not provide the required functionalities for plain\nsetup of medical image segmentation pipelines. Already implemented pipelines\nare commonly standalone software, optimized on a specific public data set.\nTherefore, this paper introduces the open-source Python library MIScnn. The aim\nof MIScnn is to provide an intuitive API allowing fast building of medical\nimage segmentation pipelines including data I/O, preprocessing, data\naugmentation, patch-wise analysis, metrics, a library with state-of-the-art\ndeep learning models and model utilization like training, prediction, as well\nas fully automatic evaluation (e.g. cross-validation). Similarly, high\nconfigurability and multiple open interfaces allow full pipeline customization.\nRunning a cross-validation with MIScnn on the Kidney Tumor Segmentation\nChallenge 2019 data set (multi-class semantic segmentation with 300 CT scans)\nresulted into a powerful predictor based on the standard 3D U-Net model. With\nthis experiment, we could show that the MIScnn framework enables researchers to\nrapidly set up a complete medical image segmentation pipeline by using just a\nfew lines of code. The source code for MIScnn is available in the Git\nrepository: https://github.com/frankkramer-lab/MIScnn.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:43:25 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["M\u00fcller", "Dominik", ""], ["Kramer", "Frank", ""]]}, {"id": "1910.09309", "submitter": "Yinan Yu", "authors": "Yinan Yu and Tomas McKelvey", "title": "Learning Hierarchical Feature Space Using CLAss-specific Subspace\n  Multiple Kernel -- Metric Learning for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric learning for classification has been intensively studied over the last\ndecade. The idea is to learn a metric space induced from a normed vector space\non which data from different classes are well separated. Different measures of\nthe separation thus lead to various designs of the objective function in the\nmetric learning model. One classical metric is the Mahalanobis distance, where\na linear transformation matrix is designed and applied on the original dataset\nto obtain a new subspace equipped with the Euclidean norm. The kernelized\nversion has also been developed, followed by Multiple-Kernel learning models.\nIn this paper, we consider metric learning to be the identification of the best\nkernel function with respect to a high class separability in the corresponding\nmetric space. The contribution is twofold: 1) No pairwise computations are\nrequired as in most metric learning techniques; 2) Better flexibility and lower\ncomputational complexity is achieved using the CLAss-Specific (Multiple) Kernel\n- Metric Learning (CLAS(M)K-ML). The proposed techniques can be considered as a\npreprocessing step to any kernel method or kernel approximation technique. An\nextension to a hierarchical learning structure is also proposed to further\nimprove the classification performance, where on each layer, the CLASMK is\ncomputed based on a selected \"marginal\" subset and feature vectors are\nconstructed by concatenating the features from all previous layers.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:44:04 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Yu", "Yinan", ""], ["McKelvey", "Tomas", ""]]}, {"id": "1910.09313", "submitter": "Tobias Weber", "authors": "Tobias Weber, Dieter Kranzlm\\\"uller, Michael Fromm, Nelson Tavares de\n  Sousa", "title": "Using Supervised Learning to Classify Metadata of Research Data by\n  Discipline of Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated classification of metadata of research data by their discipline(s)\nof research can be used in scientometric research, by repository service\nproviders, and in the context of research data aggregation services. Openly\navailable metadata of the DataCite index for research data were used to compile\na large training and evaluation set comprised of 609,524 records, which is\npublished alongside this paper. These data allow to reproducibly assess\nclassification approaches, such as tree-based models and neural networks.\nAccording to our experiments with 20 base classes (multi-label classification),\nmulti-layer perceptron models perform best with a f1-macro score of 0.760\nclosely followed by Long Short-Term Memory models (f1-macro score of 0.755). A\npossible application of the trained classification models is the quantitative\nanalysis of trends towards interdisciplinarity of digital scholarly output or\nthe characterization of growth patterns of research data, stratified by\ndiscipline of research. Both applications perform at scale with the proposed\nmodels which are available for re-use.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 07:51:37 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Weber", "Tobias", ""], ["Kranzlm\u00fcller", "Dieter", ""], ["Fromm", "Michael", ""], ["de Sousa", "Nelson Tavares", ""]]}, {"id": "1910.09314", "submitter": "Ezra Tampubolon", "authors": "Ezra Tampubolon and Holger Boche", "title": "Pricing Mechanism for Resource Sustainability in Competitive Online\n  Learning Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA cs.SY econ.TH eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of resource congestion control for\ncompeting online learning agents. On the basis of non-cooperative game as the\nmodel for the interaction between the agents, and the noisy online mirror\nascent as the model for rational behavior of the agents, we propose a novel\npricing mechanism which gives the agents incentives for sustainable use of the\nresources. Our mechanism is distributed and resource-centric, in the sense that\nit is done by the resources themselves and not by a centralized instance, and\nthat it is based rather on the congestion state of the resources than the\npreferences of the agents. In case that the noise is persistent, and for\nseveral choices of the intrinsic parameter of the agents, such as their\nlearning rate, and of the mechanism parameters, such as the learning rate of -,\nthe progressivity of the price-setters, and the extrinsic price sensitivity of\nthe agents, we show that the accumulative violation of the resource constraints\nof the resulted iterates is sub-linear w.r.t. the time horizon. Moreover, we\nprovide numerical simulations to support our theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:49:00 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Tampubolon", "Ezra", ""], ["Boche", "Holger", ""]]}, {"id": "1910.09322", "submitter": "Nino Vieillard", "authors": "Nino Vieillard, Bruno Scherrer, Olivier Pietquin, Matthieu Geist", "title": "Momentum in Reinforcement Learning", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We adapt the optimization's concept of momentum to reinforcement learning.\nSeeing the state-action value functions as an analog to the gradients in\noptimization, we interpret momentum as an average of consecutive $q$-functions.\nWe derive Momentum Value Iteration (MoVI), a variation of Value Iteration that\nincorporates this momentum idea. Our analysis shows that this allows MoVI to\naverage errors over successive iterations. We show that the proposed approach\ncan be readily extended to deep learning. Specifically, we propose a simple\nimprovement on DQN based on MoVI, and experiment it on Atari games.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:51:38 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 10:25:46 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Vieillard", "Nino", ""], ["Scherrer", "Bruno", ""], ["Pietquin", "Olivier", ""], ["Geist", "Matthieu", ""]]}, {"id": "1910.09323", "submitter": "Jiacheng Zhu", "authors": "Shenghao Qin, Jiacheng Zhu, Jimmy Qin, Wenshuo Wang, Ding Zhao", "title": "Recurrent Attentive Neural Process for Sequential Data", "comments": "12 pages, 6 figures, NeurIPS 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural processes (NPs) learn stochastic processes and predict the\ndistribution of target output adaptively conditioned on a context set of\nobserved input-output pairs. Furthermore, Attentive Neural Process (ANP)\nimproved the prediction accuracy of NPs by incorporating attention mechanism\namong contexts and targets. In a number of real-world applications such as\nrobotics, finance, speech, and biology, it is critical to learn the temporal\norder and recurrent structure from sequential data. However, the capability of\nNPs capturing these properties is limited due to its permutation invariance\ninstinct. In this paper, we proposed the Recurrent Attentive Neural Process\n(RANP), or alternatively, Attentive Neural Process-RecurrentNeural\nNetwork(ANP-RNN), in which the ANP is incorporated into a recurrent neural\nnetwork. The proposed model encapsulates both the inductive biases of recurrent\nneural networks and also the strength of NPs for modelling uncertainty. We\ndemonstrate that RANP can effectively model sequential data and outperforms NPs\nand LSTMs remarkably in a 1D regression toy example as well as\nautonomous-driving applications.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:13:47 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Qin", "Shenghao", ""], ["Zhu", "Jiacheng", ""], ["Qin", "Jimmy", ""], ["Wang", "Wenshuo", ""], ["Zhao", "Ding", ""]]}, {"id": "1910.09324", "submitter": "Nupoor Gandhi", "authors": "Nupoor Gandhi, Alex Morales, Dolores Albarracin", "title": "Multi-dimensional Features for Prediction with Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of opioid abuse in the US, there has been a growth of\noverlapping hotspots for overdose-related and HIV-related deaths in\nSpringfield, Boston, Fall River, New Bedford, and parts of Cape Cod. With a\nlarge part of population, including rural communities, active on social media,\nit is crucial that we leverage the predictive power of social media as a\npreventive measure. We explore the predictive power of micro-blogging social\nmedia website Twitter with respect to HIV new diagnosis rates per county. While\ntrending work in Twitter NLP has focused on primarily text-based features, we\nshow that multi-dimensional feature construction can significantly improve the\npredictive power of topic features alone with respect STI's (sexually\ntransmitted infections). By multi-dimensional features, we mean leveraging not\nonly the topical features (text) of a corpus, but also location-based\ninformation (counties) about the tweets in feature-construction. We develop\nnovel text-location-based smoothing features to predict new diagnoses of HIV.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:45:42 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Gandhi", "Nupoor", ""], ["Morales", "Alex", ""], ["Albarracin", "Dolores", ""]]}, {"id": "1910.09328", "submitter": "Alexandra Gessner", "authors": "Alexandra Gessner, Oindrila Kanjilal, Philipp Hennig", "title": "Integrals over Gaussians under Linear Domain Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrals of linearly constrained multivariate Gaussian densities are a\nfrequent problem in machine learning and statistics, arising in tasks like\ngeneralized linear models and Bayesian optimization. Yet they are notoriously\nhard to compute, and to further complicate matters, the numerical values of\nsuch integrals may be very small. We present an efficient black-box algorithm\nthat exploits geometry for the estimation of integrals over a small, truncated\nGaussian volume, and to simulate therefrom. Our algorithm uses the\nHolmes-Diaconis-Ross (HDR) method combined with an analytic version of\nelliptical slice sampling (ESS). Adapted to the linear setting, ESS allows for\nrejection-free sampling, because intersections of ellipses and domain\nboundaries have closed-form solutions. The key idea of HDR is to decompose the\nintegral into easier-to-compute conditional probabilities by using a sequence\nof nested domains. Remarkably, it allows for direct computation of the\nlogarithm of the integral value and thus enables the computation of extremely\nsmall probability masses. We demonstrate the effectiveness of our tailored\ncombination of HDR and ESS on high-dimensional integrals and on entropy search\nfor Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:59:02 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 13:41:14 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Gessner", "Alexandra", ""], ["Kanjilal", "Oindrila", ""], ["Hennig", "Philipp", ""]]}, {"id": "1910.09337", "submitter": "Wenhao Zhang", "authors": "Wenhao Zhang, Wentian Bao, Xiao-Yang Liu, Keping Yang, Quan Lin, Hong\n  Wen, Ramin Ramezani", "title": "Large-scale Causal Approaches to Debiasing Post-click Conversion Rate\n  Estimation with Multi-task Learning", "comments": "14 pages, 6 figures, 4 tables; Accepted at The Web Conference 2020;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-click conversion rate (CVR) estimation is a critical task in e-commerce\nrecommender systems. This task is deemed quite challenging under the industrial\nsetting with two major issues: 1) selection bias caused by user self-selection,\nand 2) data sparsity due to the rare click events. A successful conversion\ntypically has the following sequential events: \"exposure -> click ->\nconversion\". Conventional CVR estimators are trained in the click space, but\nthe inference is done in the entire exposure space. They fail to account for\nthe causes of the missing data and treat them as missing at random. Hence,\ntheir estimations are highly likely to deviate from the real values by large.\nIn addition, the data sparsity issue can also handicap many industrial CVR\nestimators which usually have large parameter spaces.\n  In this paper, we propose two principled, efficient and highly effective CVR\nestimators for industrial CVR estimation, namely, Multi-IPW and Multi-DR. The\nproposed models approach the CVR estimation from a causal perspective and\naccount for the causes of missing not at random. In addition, our methods are\nbased on the multi-task learning framework and mitigate the data sparsity\nissue. Extensive experiments on industrial-level datasets show that our methods\noutperform the state-of-the-art CVR models.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:46:11 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 06:01:09 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhang", "Wenhao", ""], ["Bao", "Wentian", ""], ["Liu", "Xiao-Yang", ""], ["Yang", "Keping", ""], ["Lin", "Quan", ""], ["Wen", "Hong", ""], ["Ramezani", "Ramin", ""]]}, {"id": "1910.09338", "submitter": "Sven Gowal", "authors": "Sven Gowal, Jonathan Uesato, Chongli Qin, Po-Sen Huang, Timothy Mann,\n  Pushmeet Kohli", "title": "An Alternative Surrogate Loss for PGD-based Adversarial Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial testing methods based on Projected Gradient Descent (PGD) are\nwidely used for searching norm-bounded perturbations that cause the inputs of\nneural networks to be misclassified. This paper takes a deeper look at these\nmethods and explains the effect of different hyperparameters (i.e., optimizer,\nstep size and surrogate loss). We introduce the concept of MultiTargeted\ntesting, which makes clever use of alternative surrogate losses, and explain\nwhen and how MultiTargeted is guaranteed to find optimal perturbations.\nFinally, we demonstrate that MultiTargeted outperforms more sophisticated\nmethods and often requires less iterative steps than other variants of PGD\nfound in the literature. Notably, MultiTargeted ranks first on MadryLab's\nwhite-box MNIST and CIFAR-10 leaderboards, reducing the accuracy of their MNIST\nmodel to 88.36% (with $\\ell_\\infty$ perturbations of $\\epsilon = 0.3$) and the\naccuracy of their CIFAR-10 model to 44.03% (at $\\epsilon = 8/255$).\nMultiTargeted also ranks first on the TRADES leaderboard reducing the accuracy\nof their CIFAR-10 model to 53.07% (with $\\ell_\\infty$ perturbations of\n$\\epsilon = 0.031$).\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:08:54 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Gowal", "Sven", ""], ["Uesato", "Jonathan", ""], ["Qin", "Chongli", ""], ["Huang", "Po-Sen", ""], ["Mann", "Timothy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1910.09340", "submitter": "Mohammad Saberian", "authors": "Mohammad Saberian and Pablo Delgado and Yves Raimond", "title": "Gradient Boosted Decision Tree Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a method to build a neural network that is similar\nto an ensemble of decision trees. We first illustrate how to convert a learned\nensemble of decision trees to a single neural network with one hidden layer and\nan input transformation. We then relax some properties of this network such as\nthresholds and activation functions to train an approximately equivalent\ndecision tree ensemble. The final model, Hammock, is surprisingly simple: a\nfully connected two layers neural network where the input is quantized and\none-hot encoded. Experiments on large and small datasets show this simple\nmethod can achieve performance similar to that of Gradient Boosted Decision\nTrees.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:21:43 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 22:18:48 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Saberian", "Mohammad", ""], ["Delgado", "Pablo", ""], ["Raimond", "Yves", ""]]}, {"id": "1910.09347", "submitter": "Gabriel Terejanu", "authors": "Asif J. Chowdhury, Gabriel Terejanu", "title": "Approximate Sampling using an Accelerated Metropolis-Hastings based on\n  Bayesian Optimization and Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Chain Monte Carlo (MCMC) methods have a drawback when working with a\ntarget distribution or likelihood function that is computationally expensive to\nevaluate, specially when working with big data. This paper focuses on\nMetropolis-Hastings (MH) algorithm for unimodal distributions. Here, an\nenhanced MH algorithm is proposed that requires less number of expensive\nfunction evaluations, has shorter burn-in period, and uses a better proposal\ndistribution. The main innovations include the use of Bayesian optimization to\nreach the high probability region quickly, emulating the target distribution\nusing Gaussian processes (GP), and using Laplace approximation of the GP to\nbuild a proposal distribution that captures the underlying correlation better.\nThe experiments show significant improvement over the regular MH. Statistical\ncomparison between the results from two algorithms is presented.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:17:03 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Chowdhury", "Asif J.", ""], ["Terejanu", "Gabriel", ""]]}, {"id": "1910.09349", "submitter": "Alexander Terenin", "authors": "Steindor Saemundsson, Alexander Terenin, Katja Hofmann, Marc Peter\n  Deisenroth", "title": "Variational Integrator Networks for Physically Structured Embeddings", "comments": null, "journal-ref": "Artificial Intelligence and Statistics, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning workable representations of dynamical systems is becoming an\nincreasingly important problem in a number of application areas. By leveraging\nrecent work connecting deep neural networks to systems of differential\nequations, we propose \\emph{variational integrator networks}, a class of neural\nnetwork architectures designed to preserve the geometric structure of physical\nsystems. This class of network architectures facilitates accurate long-term\nprediction, interpretability, and data-efficient learning, while still\nremaining highly flexible and capable of modeling complex behavior. We\ndemonstrate that they can accurately learn dynamical systems from both noisy\nobservations in phase space and from image pixels within which the unknown\ndynamics are embedded.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:17:33 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 13:41:51 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Saemundsson", "Steindor", ""], ["Terenin", "Alexander", ""], ["Hofmann", "Katja", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1910.09351", "submitter": "Ming-Chuan Yang", "authors": "Ming-Chuan Yang, Meng Chang Chen", "title": "Theoretical Investigation of Composite Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work theoretically investigates the performance of a composite neural\nnetwork. A composite neural network is a rooted directed acyclic graph\ncombining a set of pre-trained and non-instantiated neural network models,\nwhere a pre-trained neural network model is well-crafted for a specific task\nand targeted to approximate a specific function with instantiated weights. The\nadvantages of adopting such a pre-trained model in a composite neural network\nare two folds. One is to benefit from other's intelligence and diligence, and\nthe other is saving the efforts in data preparation and resources and time in\ntraining. However, the overall performance of composite neural network is still\nnot clear. In this work, we prove that a composite neural network, with high\nprobability, performs better than any of its pre-trained components under\ncertain assumptions. In addition, if an extra pre-trained component is added to\na composite network, with high probability the overall performance will be\nimproved. In the empirical evaluations, distinctively different applications\nsupport the above findings.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 10:47:32 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 08:23:28 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Yang", "Ming-Chuan", ""], ["Chen", "Meng Chang", ""]]}, {"id": "1910.09356", "submitter": "Ramya Akula", "authors": "Ramya Akula, Ni Nguyen, Ivan Garibay", "title": "Supervised Machine Learning based Ensemble Model for Accurate Prediction\n  of Type 2 Diabetes", "comments": "9 Pages, # Tables and 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the American Diabetes Association(ADA), 30.3 million people in\nthe United States have diabetes, but only 7.2 million may be undiagnosed and\nunaware of their condition. Type 2 diabetes is usually diagnosed for most\npatients later on in life whereas the less common Type 1 diabetes is diagnosed\nearly on in life. People can live healthy and happy lives while living with\ndiabetes, but early detection produces a better overall outcome on most\npatient's health. Thus, to test the accurate prediction of Type 2 diabetes, we\nuse the patients' information from an electronic health records company called\nPractice Fusion, which has about 10,000 patient records from 2009 to 2012. This\ndata contains individual key biometrics, including age, diastolic and systolic\nblood pressure, gender, height, and weight. We use this data on popular machine\nlearning algorithms and for each algorithm, we evaluate the performance of\nevery model based on their classification accuracy, precision, sensitivity,\nspecificity/recall, negative predictive value, and F1 score. In our study, we\nfind that all algorithms other than Naive Bayes suffered from very low\nprecision. Hence, we take a step further and incorporate all the algorithms\ninto a weighted average or soft voting ensemble model where each algorithm will\ncount towards a majority vote towards the decision outcome of whether a patient\nhas diabetes or not. The accuracy of the Ensemble model on Practice Fusion is\n85\\%, by far our ensemble approach is new in this space. We firmly believe that\nthe weighted average ensemble model not only performed well in overall metrics\nbut also helped to recover wrong predictions and aid in accurate prediction of\nType 2 diabetes. Our accurate novel model can be used as an alert for the\npatients to seek medical evaluation in time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 01:30:25 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Akula", "Ramya", ""], ["Nguyen", "Ni", ""], ["Garibay", "Ivan", ""]]}, {"id": "1910.09357", "submitter": "Di Chen", "authors": "Di Chen, Yada Zhu, Xiaodong Cui, Carla P. Gomes", "title": "Task-Based Learning via Task-Oriented Prediction Network with\n  Applications in Finance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world applications often involve domain-specific and task-based\nperformance objectives that are not captured by the standard machine learning\nlosses, but are critical for decision making. A key challenge for direct\nintegration of more meaningful domain and task-based evaluation criteria into\nan end-to-end gradient-based training process is the fact that often such\nperformance objectives are not necessarily differentiable and may even require\nadditional decision-making optimization processing. We propose the\nTask-Oriented Prediction Network (TOPNet), an end-to-end learning scheme that\nautomatically integrates task-based evaluation criteria into the learning\nprocess via a learnable surrogate loss function, which directly guides the\nmodel towards the task-based goal. A major benefit of the proposed TOPNet\nlearning scheme lies in its capability of automatically integrating\nnon-differentiable evaluation criteria, which makes it particularly suitable\nfor diversified and customized task-based evaluation criteria in real-world\ntasks. We validate the performance of TOPNet on two real-world financial\nprediction tasks, revenue surprise forecasting and credit risk modeling. The\nexperimental results demonstrate that TOPNet significantly outperforms both\ntraditional modeling with standard losses and modeling with hand-crafted\nheuristic differentiable surrogate losses.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 22:58:56 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 18:04:05 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 02:58:55 GMT"}, {"version": "v4", "created": "Fri, 26 Jun 2020 17:30:20 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Chen", "Di", ""], ["Zhu", "Yada", ""], ["Cui", "Xiaodong", ""], ["Gomes", "Carla P.", ""]]}, {"id": "1910.09358", "submitter": "Homayun Afrabandpey", "authors": "Homayun Afrabandpey, Tomi Peltola, Juho Piironen, Aki Vehtari and\n  Samuel Kaski", "title": "A Decision-Theoretic Approach for Model Interpretability in Bayesian\n  Framework", "comments": "This version contains more experiments including a comparison with\n  baseline methods from the literature and complemented some of the existing\n  results in the previous version", "journal-ref": "Machine Learning (2020)", "doi": "10.1007/s10994-020-05901-8", "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A salient approach to interpretable machine learning is to restrict modeling\nto simple models. In the Bayesian framework, this can be pursued by restricting\nthe model structure and prior to favor interpretable models. Fundamentally,\nhowever, interpretability is about users' preferences, not the data generation\nmechanism; it is more natural to formulate interpretability as a utility\nfunction. In this work, we propose an interpretability utility, which\nexplicates the trade-off between explanation fidelity and interpretability in\nthe Bayesian framework. The method consists of two steps. First, a reference\nmodel, possibly a black-box Bayesian predictive model which does not compromise\naccuracy, is fitted to the training data. Second, a proxy model from an\ninterpretable model family that best mimics the predictive behaviour of the\nreference model is found by optimizing the interpretability utility function.\nThe approach is model agnostic -- neither the interpretable model nor the\nreference model are restricted to a certain class of models -- and the\noptimization problem can be solved using standard tools. Through experiments on\nreal-word data sets, using decision trees as interpretable models and Bayesian\nadditive regression models as reference models, we show that for the same level\nof interpretability, our approach generates more accurate models than the\nalternative of restricting the prior. We also propose a systematic way to\nmeasure stability of interpretabile models constructed by different\ninterpretability approaches and show that our proposed approach generates more\nstable models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:22:44 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 21:34:35 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Afrabandpey", "Homayun", ""], ["Peltola", "Tomi", ""], ["Piironen", "Juho", ""], ["Vehtari", "Aki", ""], ["Kaski", "Samuel", ""]]}, {"id": "1910.09359", "submitter": "Yinan Yu", "authors": "Samuel Scheidegger and Yinan Yu and Tomas McKelvey", "title": "Separable Convolutional Eigen-Filters (SCEF): Building Efficient CNNs\n  Using Redundancy Analysis", "comments": "key words: subspace analysis, convolutional neural networks, FLOPs,\n  number of parameters, depth, depthwise separable convolutions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (CNNs) have been widely used in computer\nvision due to its effectiveness. While the high model complexity of CNN enables\nremarkable learning capacity, the large number of trainable parameters comes\nwith a high cost. In addition to the demand of a large amount of resources, the\nhigh complexity of the network can result in a high variance in its\ngeneralization performance from a statistical learning theory perspective. One\nway to reduce the complexity of a network without sacrificing its accuracy is\nto define and identify redundancies in order to remove them. In this work, we\npropose a method to observe and analyze redundancies in the weights of 2D\nconvolutional (Conv2D) filters. From our experiments, we observe that 1) the\nvectorized Conv2D filters exhibit low rank behaviors; 2) the effective ranks of\nthese filters typically decrease when the network goes deeper, and 3) these\neffective ranks are converging over training steps. Inspired by these\nobservations, we propose a new layer called Separable Convolutional\nEigen-Filters (SCEF) as an alternative parameterization to Conv2D filters. A\nSCEF layer can be easily implemented using the depthwise separable convolutions\ntrained with our proposed training strategy. In addition to the decreased\nnumber of trainable parameters by using SCEF, depthwise separable convolutions\nare known to be more computationally efficient compared to Conv2D operations,\nwhich reduces the runtime FLOPs as well. Experiments are conducted on the\nCIFAR-10 and ImageNet datasets by replacing the Conv2D layers with SCEF. The\nresults have shown an increased accuracy using about 2/3 of the original\nparameters and reduce the number of FLOPs to 2/3 of the base net.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:28:28 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 07:50:08 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Scheidegger", "Samuel", ""], ["Yu", "Yinan", ""], ["McKelvey", "Tomas", ""]]}, {"id": "1910.09368", "submitter": "Youssef Mourchid", "authors": "Youssef Mourchid, Benjamin Renoust, Olivier Roupin, Le Van, Hocine\n  Cherifi, Mohammed El Hassouni", "title": "Movienet: A Movie Multilayer Network Model using Visual and Textual\n  Semantic Cues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering content and stories in movies is one of the most important\nconcepts in multimedia content research studies. Network models have proven to\nbe an efficient choice for this purpose. When an audience watches a movie, they\nusually compare the characters and the relationships between them. For this\nreason, most of the models developed so far are based on social networks\nanalysis. They focus essentially on the characters at play. By analyzing\ncharacters' interactions, we can obtain a broad picture of the narration's\ncontent. Other works have proposed to exploit semantic elements such as scenes,\ndialogues, etc. However, they are always captured from a single facet.\nMotivated by these limitations, we introduce in this work a multilayer network\nmodel to capture the narration of a movie based on its script, its subtitles,\nand the movie content. After introducing the model and the extraction process\nfrom the raw data, we perform a comparative analysis of the whole 6-movie cycle\nof the Star Wars saga. Results demonstrate the effectiveness of the proposed\nframework for video content representation and analysis.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 17:22:15 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Mourchid", "Youssef", ""], ["Renoust", "Benjamin", ""], ["Roupin", "Olivier", ""], ["Van", "Le", ""], ["Cherifi", "Hocine", ""], ["Hassouni", "Mohammed El", ""]]}, {"id": "1910.09383", "submitter": "Sarath Shekkizhar", "authors": "Sarath Shekkizhar and Antonio Ortega", "title": "Graph Construction from Data using Non Negative Kernel regression (NNK\n  Graphs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data driven graph constructions are often used in various applications,\nincluding several machine learning tasks, where the goal is to make predictions\nand discover patterns. However, learning an optimal graph from data is still a\nchallenging task. Weighted $K$-nearest neighbor and $\\epsilon$-neighborhood\nmethods are among the most common graph construction methods, due to their\ncomputational simplicity but the choice of parameters such as $K$ and\n$\\epsilon$ associated with these methods is often ad hoc and lacks a clear\ninterpretation. We formulate graph construction as the problem of finding a\nsparse signal approximation in kernel space, identifying key similarities\nbetween methods in signal approximation and existing graph learning methods. We\npropose non-negative kernel regression~(NNK), an improved approach for graph\nconstruction with interesting geometric and theoretical properties. We show\nexperimentally the efficiency of NNK graphs, its robustness to choice of\nsparsity $K$ and better performance over state of the art graph methods in semi\nsupervised learning tasks on real world data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:58:14 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Shekkizhar", "Sarath", ""], ["Ortega", "Antonio", ""]]}, {"id": "1910.09387", "submitter": "Konstantinos Drossos", "authors": "Konstantinos Drossos and Samuel Lipping and Tuomas Virtanen", "title": "Clotho: An Audio Captioning Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio captioning is the novel task of general audio content description using\nfree text. It is an intermodal translation task (not speech-to-text), where a\nsystem accepts as an input an audio signal and outputs the textual description\n(i.e. the caption) of that signal. In this paper we present Clotho, a dataset\nfor audio captioning consisting of 4981 audio samples of 15 to 30 seconds\nduration and 24 905 captions of eight to 20 words length, and a baseline method\nto provide initial results. Clotho is built with focus on audio content and\ncaption diversity, and the splits of the data are not hampering the training or\nevaluation of methods. All sounds are from the Freesound platform, and captions\nare crowdsourced using Amazon Mechanical Turk and annotators from English\nspeaking countries. Unique words, named entities, and speech transcription are\nremoved with post-processing. Clotho is freely available online\n(https://zenodo.org/record/3490684).\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 14:06:01 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Drossos", "Konstantinos", ""], ["Lipping", "Samuel", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1910.09388", "submitter": "Zhi-Hua Zhou", "authors": "Yu-Jie Zhang and Peng Zhao and Zhi-Hua Zhou", "title": "An Unbiased Risk Estimator for Learning with Augmented Classes", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of learning with augmented classes (LAC),\nwhere augmented classes unobserved in the training data might emerge in the\ntesting phase. Previous studies generally attempt to discover augmented classes\nby exploiting geometric properties, achieving inspiring empirical performance\nyet lacking theoretical understandings particularly on the generalization\nability. In this paper we show that, by using unlabeled training data to\napproximate the potential distribution of augmented classes, an unbiased risk\nestimator of the testing distribution can be established for the LAC problem\nunder mild assumptions, which paves a way to develop a sound approach with\ntheoretical guarantees. Moreover, the proposed approach can adapt to complex\nchanging environments where augmented classes may appear and the prior of known\nclasses may change simultaneously. Extensive experiments confirm the\neffectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 14:06:29 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 13:09:31 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Zhang", "Yu-Jie", ""], ["Zhao", "Peng", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1910.09394", "submitter": "Mehmet A. S\\\"uzen PhD", "authors": "Mehmet S\\\"uzen and Alper Yegenoglu", "title": "Generalised learning of time-series: Ornstein-Uhlenbeck processes", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In machine learning, statistics, econometrics and statistical physics\ncross-validation (CV) is used as a standard approach in quantifying the\ngeneralization performance of a statistical model. In practice, direct usage of\nCV is avoided for time-series due to several issues. A direct application of CV\nin time-series leads to the loss of serial correlations, a requirement of\npreserving any non-stationarity and the prediction of the past data using\nfuture data. In this work, we propose a meta-algorithm called reconstructive\ncross-validation (rCV ) that avoids all these issues. At first, k folds are\nformed with non-overlapping randomly selected subsets of the original\ntime-series. Then, we generate k new partial time-series by removing data\npoints from a given fold: every new partial time-series have missing points at\nrandom from a different entire fold. A suitable imputation or a smoothing\ntechnique is used to reconstruct k time-series. We call these reconstructions\nsecondary models. Thereafter, we build the primary k time-series models using\nnew time-series coming from the secondary models. The performance of the\nprimary models is evaluated simultaneously by computing the deviations from the\noriginally removed data points and out-of-sample (OSS) data. These amounts to\nreconstruction and prediction errors. If the secondary models use a technique\nthat retains the data points exactly, such as Gaussian process regression,\nthere will be no errors present on the data points that are not removed. By\nthis procedure serial correlations are retained, any non-stationarity is\npreserved within models and there will be no prediction of past data using the\nfuture data points. The cross-validation in time-series model can be practised\nwith rCV. Moreover, we can build time-series learning curves by repeating rCV\nprocedure with different k values.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 14:16:05 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:23:12 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["S\u00fczen", "Mehmet", ""], ["Yegenoglu", "Alper", ""]]}, {"id": "1910.09396", "submitter": "Jiahao Xie", "authors": "Jiahao Xie, Zebang Shen, Chao Zhang, Boyu Wang, Hui Qian", "title": "Efficient Projection-Free Online Methods with Stochastic Recursive\n  Gradient", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on projection-free methods for solving smooth Online\nConvex Optimization (OCO) problems. Existing projection-free methods either\nachieve suboptimal regret bounds or have high per-iteration computational\ncosts. To fill this gap, two efficient projection-free online methods called\nORGFW and MORGFW are proposed for solving stochastic and adversarial OCO\nproblems, respectively. By employing a recursive gradient estimator, our\nmethods achieve optimal regret bounds (up to a logarithmic factor) while\npossessing low per-iteration computational costs. Experimental results\ndemonstrate the efficiency of the proposed methods compared to\nstate-of-the-arts.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 14:22:26 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 03:06:01 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Xie", "Jiahao", ""], ["Shen", "Zebang", ""], ["Zhang", "Chao", ""], ["Wang", "Boyu", ""], ["Qian", "Hui", ""]]}, {"id": "1910.09398", "submitter": "Martin Pawelczyk", "authors": "Martin Pawelczyk, Johannes Haug, Klaus Broelemann, Gjergji Kasneci", "title": "Learning Model-Agnostic Counterfactual Explanations for Tabular Data", "comments": "Update version: from Neurips Workshop to WWW publication. In\n  Proceedings of The Web Conference 2020 (WWW 20), April 20-24, 2020, Taipei,\n  Taiwan", "journal-ref": null, "doi": "10.1145/3366423.3380087", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual explanations can be obtained by identifying the smallest\nchange made to a feature vector to qualitatively influence a prediction; for\nexample, from 'loan rejected' to 'awarded' or from 'high risk of cardiovascular\ndisease' to 'low risk'. Previous approaches often emphasized that\ncounterfactuals should be easily interpretable to humans, motivating sparse\nsolutions with few changes to the feature vectors. However, these approaches\nwould not ensure that the produced counterfactuals be proximate (i.e., not\nlocal outliers) and connected to regions with substantial data density (i.e.,\nclose to correctly classified observations), two requirements known as\ncounterfactual faithfulness. These requirements are fundamental when making\nsuggestions to individuals that are indeed attainable. Our contribution is\ntwofold. On one hand, we suggest to complement the catalogue of counterfactual\nquality measures [1] using a criterion to quantify the degree of difficulty for\na certain counterfactual suggestion. On the other hand, drawing ideas from the\nmanifold learning literature, we develop a framework that generates attainable\ncounterfactuals. We suggest the counterfactual conditional heterogeneous\nvariational autoencoder (C-CHVAE) to identify attainable counterfactuals that\nlie within regions of high data density.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 14:23:13 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 14:14:55 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Pawelczyk", "Martin", ""], ["Haug", "Johannes", ""], ["Broelemann", "Klaus", ""], ["Kasneci", "Gjergji", ""]]}, {"id": "1910.09399", "submitter": "Haicheng Tao", "authors": "Jorge Agnese, Jonathan Herrera, Haicheng Tao, Xingquan Zhu", "title": "A Survey and Taxonomy of Adversarial Neural Networks for Text-to-Image\n  Synthesis", "comments": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery.\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-to-image synthesis refers to computational methods which translate human\nwritten textual descriptions, in the form of keywords or sentences, into images\nwith similar semantic meaning to the text. In earlier research, image synthesis\nrelied mainly on word to image correlation analysis combined with supervised\nmethods to find best alignment of the visual content matching to the text.\nRecent progress in deep learning (DL) has brought a new set of unsupervised\ndeep learning methods, particularly deep generative models which are able to\ngenerate realistic visual images using suitably trained neural network models.\nIn this paper, we review the most recent development in the text-to-image\nsynthesis research domain. Our survey first introduces image synthesis and its\nchallenges, and then reviews key concepts such as generative adversarial\nnetworks (GANs) and deep convolutional encoder-decoder neural networks (DCNN).\nAfter that, we propose a taxonomy to summarize GAN based text-to-image\nsynthesis into four major categories: Semantic Enhancement GANs, Resolution\nEnhancement GANs, Diversity Enhancement GANS, and Motion Enhancement GANs. We\nelaborate the main objective of each group, and further review typical GAN\narchitectures in each group. The taxonomy and the review outline the techniques\nand the evolution of different approaches, and eventually provide a clear\nroadmap to summarize the list of contemporaneous solutions that utilize GANs\nand DCNNs to generate enthralling results in categories such as human faces,\nbirds, flowers, room interiors, object reconstruction from edge maps (games)\netc. The survey will conclude with a comparison of the proposed solutions,\nchallenges that remain unresolved, and future developments in the text-to-image\nsynthesis domain.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 14:23:14 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Agnese", "Jorge", ""], ["Herrera", "Jonathan", ""], ["Tao", "Haicheng", ""], ["Zhu", "Xingquan", ""]]}, {"id": "1910.09402", "submitter": "Juanping Zhu", "authors": "Juanping Zhu, Qi Meng, Wei Chen, Zhi-ming Ma", "title": "Interpreting Basis Path Set in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on basis path set, G-SGD algorithm significantly outperforms\nconventional SGD algorithm in optimizing neural networks. However, how the\ninner mechanism of basis paths work remains mysterious. From the aspect of\ngraph theory, this paper defines basis path, investigates structure properties\nof basis paths in regular fully connected neural network and interprets the\ngraph representation of basis path set. Moreover, we propose hierarchical\nalgorithm HBPS to find basis path set B in fully connected neural network by\ndecomposing the network into several independent and parallel substructures.\nAlgorithm HBPS demands that there doesn't exist shared edges between any two\nindependent substructure paths.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 08:54:28 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Zhu", "Juanping", ""], ["Meng", "Qi", ""], ["Chen", "Wei", ""], ["Ma", "Zhi-ming", ""]]}, {"id": "1910.09417", "submitter": "Amir Emad Marvasti", "authors": "Amir Emad Marvasti, Ehsan Emad Marvasti, Ulas Bagci, Hassan Foroosh", "title": "Maximum Probability Theorem: A Framework for Probabilistic Learning", "comments": "in IEEE Transactions on Artificial Intelligence", "journal-ref": null, "doi": "10.1109/TAI.2021.3086046", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theoretical framework of probabilistic learning derived by\nMaximum Probability (MP) Theorem shown in the current paper. In this\nprobabilistic framework, a model is defined as an event in the probability\nspace, and a model or the associated event -- either the true underlying model\nor the parameterized model -- have a quantified probability measure. This\nquantification of a model's probability measure is derived by the MP Theorem,\nin which we have shown that an event's probability measure has an upper-bound\ngiven its conditional distribution on an arbitrary random variable. Through\nthis alternative framework, the notion of model parameters is encompassed in\nthe definition of the model or the associated event. Therefore, this framework\ndeviates from the conventional approach of assuming a prior on the model\nparameters. Instead, the regularizing effects of assuming prior over parameters\nis seen through maximizing probabilities of models or according to information\ntheory, minimizing the information content of a model. The probability of a\nmodel in our framework is invariant to reparameterization and is solely\ndependent on the model's likelihood function. Also, rather than maximizing the\nposterior in a conventional Bayesian setting, the objective function in our\nalternative framework is defined as the probability of set operations (e.g.\nintersection) on the event of the true underlying model and the event of the\nmodel at hand. Our theoretical framework, as a derivation of MP theorem, adds\nclarity to probabilistic learning through solidifying the definition of\nprobabilistic models, quantifying their probabilities, and providing a visual\nunderstanding of objective functions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 14:46:05 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 16:03:30 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 19:54:26 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 18:39:08 GMT"}, {"version": "v5", "created": "Mon, 14 Jun 2021 16:18:59 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Marvasti", "Amir Emad", ""], ["Marvasti", "Ehsan Emad", ""], ["Bagci", "Ulas", ""], ["Foroosh", "Hassan", ""]]}, {"id": "1910.09430", "submitter": "Oier Mees", "authors": "Oier Mees, Markus Merklinger, Gabriel Kalweit, Wolfram Burgard", "title": "Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video", "comments": "Accepted at the 2020 IEEE International Conference on Robotics and\n  Automation (ICRA). Video at https://www.youtube.com/watch?v=z8gG1k9kSqA\n  Project page at http://robotskills.cs.uni-freiburg.de", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key challenges for the deployment of reinforcement learning (RL) agents in\nthe real world are the discovery, representation and reuse of skills in the\nabsence of a reward function. To this end, we propose a novel approach to learn\na task-agnostic skill embedding space from unlabeled multi-view videos. Our\nmethod learns a general skill embedding independently from the task context by\nusing an adversarial loss. We combine a metric learning loss, which utilizes\ntemporal video coherence to learn a state representation, with an entropy\nregularized adversarial skill-transfer loss. The metric learning loss learns a\ndisentangled representation by attracting simultaneous viewpoints of the same\nobservations and repelling visually similar frames from temporal neighbors. The\nadversarial skill-transfer loss enhances re-usability of learned skill\nembeddings over multiple task domains. We show that the learned embedding\nenables training of continuous control policies to solve novel tasks that\nrequire the interpolation of previously seen skills. Our extensive evaluation\nwith both simulation and real world data demonstrates the effectiveness of our\nmethod in learning transferable skills from unlabeled interaction videos and\ncomposing them for new tasks. Code, pretrained models and dataset are available\nat http://robotskills.cs.uni-freiburg.de\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:06:03 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 16:28:34 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Mees", "Oier", ""], ["Merklinger", "Markus", ""], ["Kalweit", "Gabriel", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1910.09433", "submitter": "Alex Lamb", "authors": "Tarin Clanuwat, Alex Lamb, Asanobu Kitamoto", "title": "KuroNet: Pre-Modern Japanese Kuzushiji Character Recognition with Deep\n  Learning", "comments": "International Conference on Document Recognition (ICDAR) 2019 [oral]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kuzushiji, a cursive writing style, had been used in Japan for over a\nthousand years starting from the 8th century. Over 3 millions books on a\ndiverse array of topics, such as literature, science, mathematics and even\ncooking are preserved. However, following a change to the Japanese writing\nsystem in 1900, Kuzushiji has not been included in regular school curricula.\nTherefore, most Japanese natives nowadays cannot read books written or printed\njust 150 years ago. Museums and libraries have invested a great deal of effort\ninto creating digital copies of these historical documents as a safeguard\nagainst fires, earthquakes and tsunamis. The result has been datasets with\nhundreds of millions of photographs of historical documents which can only be\nread by a small number of specially trained experts. Thus there has been a\ngreat deal of interest in using Machine Learning to automatically recognize\nthese historical texts and transcribe them into modern Japanese characters.\nNevertheless, several challenges in Kuzushiji recognition have made the\nperformance of existing systems extremely poor. To tackle these challenges, we\npropose KuroNet, a new end-to-end model which jointly recognizes an entire page\nof text by using a residual U-Net architecture which predicts the location and\nidentity of all characters given a page of text (without any pre-processing).\nThis allows the model to handle long range context, large vocabularies, and\nnon-standardized character layouts. We demonstrate that our system is able to\nsuccessfully recognize a large fraction of pre-modern Japanese documents, but\nalso explore areas where our system is limited and suggest directions for\nfuture work.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:09:13 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Clanuwat", "Tarin", ""], ["Lamb", "Alex", ""], ["Kitamoto", "Asanobu", ""]]}, {"id": "1910.09434", "submitter": "Oliver Wallscheid", "authors": "Arne Traue, Gerrit Book, Wilhelm Kirchg\\\"assner, Oliver Wallscheid", "title": "Towards a Reinforcement Learning Environment Toolbox for Intelligent\n  Electric Motor Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electric motors are used in many applications and their efficiency is\nstrongly dependent on their control. Among others, PI approaches or model\npredictive control methods are well-known in the scientific literature and\nindustrial practice. A novel approach is to use reinforcement learning (RL) to\nhave an agent learn electric drive control from scratch merely by interacting\nwith a suitable control environment. RL achieved remarkable results with\nsuper-human performance in many games (e.g. Atari classics or Go) and also\nbecomes more popular in control tasks like cartpole or swinging pendulum\nbenchmarks. In this work, the open-source Python package gym-electric-motor\n(GEM) is developed for ease of training of RL-agents for electric motor\ncontrol. Furthermore, this package can be used to compare the trained agents\nwith other state-of-the-art control approaches. It is based on the OpenAI Gym\nframework that provides a widely used interface for the evaluation of\nRL-agents. The initial package version covers different DC motor variants and\nthe prevalent permanent magnet synchronous motor as well as different power\nelectronic converters and a mechanical load model. Due to the modular setup of\nthe proposed toolbox, additional motor, load, and power electronic devices can\nbe easily extended in the future. Furthermore, different secondary effects like\ncontroller interlocking time or noise are considered. An intelligent controller\nexample based on the deep deterministic policy gradient algorithm which\ncontrols a series DC motor is presented and compared to a cascaded\nPI-controller as a baseline for future research. Fellow researchers are\nencouraged to use the framework in their RL investigations or to contribute to\nthe functional scope (e.g. further motor types) of the package.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:11:07 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Traue", "Arne", ""], ["Book", "Gerrit", ""], ["Kirchg\u00e4ssner", "Wilhelm", ""], ["Wallscheid", "Oliver", ""]]}, {"id": "1910.09442", "submitter": "Daniel Tang", "authors": "Daniel Tang", "title": "Data assimilation in Agent-based models using creation and annihilation\n  operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Agent-based models are a powerful tool for studying the behaviour of complex\nsystems that can be described in terms of multiple, interacting ``agents''.\nHowever, because of their inherently discrete and often highly non-linear\nnature, it is very difficult to reason about the relationship between the state\nof the model, on the one hand, and our observations of the real world on the\nother. In this paper we consider agents that have a discrete set of states\nthat, at any instant, act with a probability that may depend on the environment\nor the state of other agents. Given this, we show how the mathematical\napparatus of quantum field theory can be used to reason probabilistically about\nthe state and dynamics the model, and describe an algorithm to update our\nbelief in the state of the model in the light of new, real-world observations.\nUsing a simple predator-prey model on a 2-dimensional spatial grid as an\nexample, we demonstrate the assimilation of incomplete, noisy observations and\nshow that this leads to an increase in the mutual information between the\nactual state of the observed system and the posterior distribution given the\nobservations, when compared to a null model.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 16:15:57 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Tang", "Daniel", ""]]}, {"id": "1910.09444", "submitter": "Paul Duckworth", "authors": "Wolfgang Fr\\\"uhwirt and Paul Duckworth", "title": "Towards better healthcare: What could and should be automated?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While artificial intelligence (AI) and other automation technologies might\nlead to enormous progress in healthcare, they may also have undesired\nconsequences for people working in the field. In this interdisciplinary study,\nwe capture empirical evidence of not only what healthcare work could be\nautomated, but also what should be automated. We quantitatively investigate\nthese research questions by utilizing probabilistic machine learning models\ntrained on thousands of ratings, provided by both healthcare practitioners and\nautomation experts. Based on our findings, we present an analytical tool\n(Automatability-Desirability Matrix) to support policymakers and organizational\nleaders in developing practical strategies on how to harness the positive power\nof automation technologies, while accompanying change and empowering\nstakeholders in a participatory fashion.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:23:39 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Fr\u00fchwirt", "Wolfgang", ""], ["Duckworth", "Paul", ""]]}, {"id": "1910.09446", "submitter": "Hyeonwoo Yu", "authors": "Hyeonwoo Yu and Beomhee Lee", "title": "Zero-shot Learning via Simultaneous Generating and Learning", "comments": "To appear in the proceeding of NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To overcome the absence of training data for unseen classes, conventional\nzero-shot learning approaches mainly train their model on seen datapoints and\nleverage the semantic descriptions for both seen and unseen classes. Beyond\nexploiting relations between classes of seen and unseen, we present a deep\ngenerative model to provide the model with experience about both seen and\nunseen classes. Based on the variational auto-encoder with class-specific\nmulti-modal prior, the proposed method learns the conditional distribution of\nseen and unseen classes. In order to circumvent the need for samples of unseen\nclasses, we treat the non-existing data as missing examples. That is, our\nnetwork aims to find optimal unseen datapoints and model parameters, by\niteratively following the generating and learning strategy. Since we obtain the\nconditional generative model for both seen and unseen classes, classification\nas well as generation can be performed directly without any off-the-shell\nclassifiers. In experimental results, we demonstrate that the proposed\ngenerating and learning strategy makes the model achieve the outperforming\nresults compared to that trained only on the seen classes, and also to the\nseveral state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:25:27 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Yu", "Hyeonwoo", ""], ["Lee", "Beomhee", ""]]}, {"id": "1910.09451", "submitter": "Mathieu Seurin", "authors": "Geoffrey Cideron, Mathieu Seurin, Florian Strub, and Olivier Pietquin", "title": "HIGhER : Improving instruction following with Hindsight Generation for\n  Experience Replay", "comments": "Accepted at ADPRL'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language creates a compact representation of the world and allows the\ndescription of unlimited situations and objectives through compositionality.\nWhile these characterizations may foster instructing, conditioning or\nstructuring interactive agent behavior, it remains an open-problem to correctly\nrelate language understanding and reinforcement learning in even simple\ninstruction following scenarios. This joint learning problem is alleviated\nthrough expert demonstrations, auxiliary losses, or neural inductive biases. In\nthis paper, we propose an orthogonal approach called Hindsight Generation for\nExperience Replay (HIGhER) that extends the Hindsight Experience Replay (HER)\napproach to the language-conditioned policy setting. Whenever the agent does\nnot fulfill its instruction, HIGhER learns to output a new directive that\nmatches the agent trajectory, and it relabels the episode with a positive\nreward. To do so, HIGhER learns to map a state into an instruction by using\npast successful trajectories, which removes the need to have external expert\ninterventions to relabel episodes as in vanilla HER. We show the efficiency of\nour approach in the BabyAI environment, and demonstrate how it complements\nother instruction following methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:31:29 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 15:36:42 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 16:01:45 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Cideron", "Geoffrey", ""], ["Seurin", "Mathieu", ""], ["Strub", "Florian", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1910.09457", "submitter": "Eyke H\\\"ullermeier", "authors": "Eyke H\\\"ullermeier and Willem Waegeman", "title": "Aleatoric and Epistemic Uncertainty in Machine Learning: An Introduction\n  to Concepts and Methods", "comments": "59 pages", "journal-ref": null, "doi": "10.1007/s10994-021-05946-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of uncertainty is of major importance in machine learning and\nconstitutes a key element of machine learning methodology. In line with the\nstatistical tradition, uncertainty has long been perceived as almost synonymous\nwith standard probability and probabilistic predictions. Yet, due to the\nsteadily increasing relevance of machine learning for practical applications\nand related issues such as safety requirements, new problems and challenges\nhave recently been identified by machine learning scholars, and these problems\nmay call for new methodological developments. In particular, this includes the\nimportance of distinguishing between (at least) two different types of\nuncertainty, often referred to as aleatoric and epistemic. In this paper, we\nprovide an introduction to the topic of uncertainty in machine learning as well\nas an overview of attempts so far at handling uncertainty in general and\nformalizing this distinction in particular.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:41:28 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 14:55:47 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 06:34:50 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["H\u00fcllermeier", "Eyke", ""], ["Waegeman", "Willem", ""]]}, {"id": "1910.09458", "submitter": "Geoffrey Roman Jimenez", "authors": "Geoffrey Roman-Jimenez, Patrice Guyot, Thierry Malon, Sylvie Chambon,\n  Vincent Charvillat, Alain Crouzil, Andr\\'e P\\'eninou, Julien Pinquier,\n  Florence Sedes, Christine S\\'enac", "title": "Improving Vehicle Re-Identification using CNN Latent Spaces: Metrics\n  Comparison and Track-to-track Extension", "comments": "This paper is a postprint of a paper submitted to and accepted for\n  publication in the journal IET Computer Vision and is subject to Institution\n  of Engineering and Technology Copyright. The copy of record is available at\n  the IET Digital Library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of vehicle re-identification using distance\ncomparison of images in CNN latent spaces.\n  Firstly, we study the impact of the distance metrics, comparing performances\nobtained with different metrics: the minimal Euclidean distance (MED), the\nminimal cosine distance (MCD), and the residue of the sparse coding\nreconstruction (RSCR). These metrics are applied using features extracted from\nfive different CNN architectures, namely ResNet18, AlexNet, VGG16, InceptionV3\nand DenseNet201. We use the specific vehicle re-identification dataset VeRi to\nfine-tune these CNNs and evaluate results. In overall, independently of the CNN\nused, MCD outperforms MED, commonly used in the literature. These results are\nconfirmed on other vehicle retrieval datasets. Secondly, we extend the\nstate-of-the-art image-to-track process (I2TP) to a track-to-track process\n(T2TP). The three distance metrics are extended to measure distance between\ntracks, enabling T2TP. We compared T2TP with I2TP using the same CNN models.\nResults show that T2TP outperforms I2TP for MCD and RSCR. T2TP combining\nDenseNet201 and MCD-based metrics exhibits the best performances, outperforming\nthe state-of-the-art I2TP-based models. Finally, experiments highlight two main\nresults: i) the impact of metric choice in vehicle re-identification, and ii)\nT2TP improves the performances compared to I2TP, especially when coupled with\nMCD-based metrics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:41:59 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 08:39:58 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Roman-Jimenez", "Geoffrey", ""], ["Guyot", "Patrice", ""], ["Malon", "Thierry", ""], ["Chambon", "Sylvie", ""], ["Charvillat", "Vincent", ""], ["Crouzil", "Alain", ""], ["P\u00e9ninou", "Andr\u00e9", ""], ["Pinquier", "Julien", ""], ["Sedes", "Florence", ""], ["S\u00e9nac", "Christine", ""]]}, {"id": "1910.09464", "submitter": "Yangjun Ruan", "authors": "Yangjun Ruan, Yuanhao Xiong, Sashank Reddi, Sanjiv Kumar, Cho-Jui\n  Hsieh", "title": "Learning to Learn by Zeroth-Order Oracle", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the learning to learn (L2L) framework, we cast the design of optimization\nalgorithms as a machine learning problem and use deep neural networks to learn\nthe update rules. In this paper, we extend the L2L framework to zeroth-order\n(ZO) optimization setting, where no explicit gradient information is available.\nOur learned optimizer, modeled as recurrent neural network (RNN), first\napproximates gradient by ZO gradient estimator and then produces parameter\nupdate utilizing the knowledge of previous iterations. To reduce high variance\neffect due to ZO gradient estimator, we further introduce another RNN to learn\nthe Gaussian sampling rule and dynamically guide the query direction sampling.\nOur learned optimizer outperforms hand-designed algorithms in terms of\nconvergence rate and final solution on both synthetic and practical ZO\noptimization tasks (in particular, the black-box adversarial attack task, which\nis one of the most widely used tasks of ZO optimization). We finally conduct\nextensive analytical experiments to demonstrate the effectiveness of our\nproposed optimizer.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:48:46 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 06:45:00 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Ruan", "Yangjun", ""], ["Xiong", "Yuanhao", ""], ["Reddi", "Sashank", ""], ["Kumar", "Sanjiv", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1910.09466", "submitter": "Giulio Franzese", "authors": "Rosa Candela, Giulio Franzese, Maurizio Filippone, Pietro Michiardi", "title": "Sparsification as a Remedy for Staleness in Distributed Asynchronous SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale machine learning is increasingly relying on distributed\noptimization, whereby several machines contribute to the training process of a\nstatistical model. In this work we study the performance of asynchronous,\ndistributed settings, when applying sparsification, a technique used to reduce\ncommunication overheads. In particular, for the first time in an asynchronous,\nnon-convex setting, we theoretically prove that, in presence of staleness,\nsparsification does not harm SGD performance: the ergodic convergence rate\nmatches the known result of standard SGD, that is $\\mathcal{O} \\left(\n1/\\sqrt{T} \\right)$. We also carry out an empirical study to complement our\ntheory, and confirm that the effects of sparsification on the convergence rate\nare negligible, when compared to 'vanilla' SGD, even in the challenging\nscenario of an asynchronous, distributed system.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:51:16 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 15:01:06 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 08:41:09 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Candela", "Rosa", ""], ["Franzese", "Giulio", ""], ["Filippone", "Maurizio", ""], ["Michiardi", "Pietro", ""]]}, {"id": "1910.09469", "submitter": "Enrique Sanchez", "authors": "Enrique Sanchez and Georgios Tzimiropoulos", "title": "Object landmark discovery through unsupervised adaptation", "comments": "NeurIPS 2019. Code is available\n  https://github.com/ESanchezLozano/SAIC-Unsupervised-landmark-detection-NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method to ease the unsupervised learning of object\nlandmark detectors. Similarly to previous methods, our approach is fully\nunsupervised in a sense that it does not require or make any use of annotated\nlandmarks for the target object category. Contrary to previous works, we do\nhowever assume that a landmark detector, which has already learned a structured\nrepresentation for a given object category in a fully supervised manner, is\navailable. Under this setting, our main idea boils down to adapting the given\npre-trained network to the target object categories in a fully unsupervised\nmanner. To this end, our method uses the pre-trained network as a core which\nremains frozen and does not get updated during training, and learns, in an\nunsupervised manner, only a projection matrix to perform the adaptation to the\ntarget categories. By building upon an existing structured representation\nlearned in a supervised manner, the optimization problem solved by our method\nis much more constrained with significantly less parameters to learn which\nseems to be important for the case of unsupervised learning. We show that our\nmethod surpasses fully unsupervised techniques trained from scratch as well as\na strong baseline based on fine-tuning, and produces state-of-the-art results\non several datasets. Code can be found at\nhttps://github.com/ESanchezLozano/SAIC-Unsupervised-landmark-detection-NeurIPS2019 .\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:58:57 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Sanchez", "Enrique", ""], ["Tzimiropoulos", "Georgios", ""]]}, {"id": "1910.09471", "submitter": "Rae Jeong", "authors": "Rae Jeong, Jackie Kay, Francesco Romano, Thomas Lampe, Tom Rothorl,\n  Abbas Abdolmaleki, Tom Erez, Yuval Tassa, Francesco Nori", "title": "Modelling Generalized Forces with Reinforcement Learning for Sim-to-Real\n  Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robotic control policies in the real world gives rise to challenges\nin data efficiency, safety, and controlling the initial condition of the\nsystem. On the other hand, simulations are a useful alternative as they provide\nan abundant source of data without the restrictions of the real world.\nUnfortunately, simulations often fail to accurately model complex real-world\nphenomena. Traditional system identification techniques are limited in\nexpressiveness by the analytical model parameters, and usually are not\nsufficient to capture such phenomena. In this paper we propose a general\nframework for improving the analytical model by optimizing state dependent\ngeneralized forces. State dependent generalized forces are expressive enough to\nmodel constraints in the equations of motion, while maintaining a clear\nphysical meaning and intuition. We use reinforcement learning to efficiently\noptimize the mapping from states to generalized forces over a discounted\ninfinite horizon. We show that using only minutes of real world data improves\nthe sim-to-real control policy transfer. We demonstrate the feasibility of our\napproach by validating it on a nonprehensile manipulation task on the Sawyer\nrobot.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:01:05 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jeong", "Rae", ""], ["Kay", "Jackie", ""], ["Romano", "Francesco", ""], ["Lampe", "Thomas", ""], ["Rothorl", "Tom", ""], ["Abdolmaleki", "Abbas", ""], ["Erez", "Tom", ""], ["Tassa", "Yuval", ""], ["Nori", "Francesco", ""]]}, {"id": "1910.09472", "submitter": "Giorgio Terracina", "authors": "Francesco Calimeri, Francesco Cauteruccio, Luca Cinelli, Aldo\n  Marzullo, Claudio Stamile, Giorgio Terracina, Francoise Durand-Dubief,\n  Dominique Sappey-Marinier", "title": "A Logic-Based Framework Leveraging Neural Networks for Studying the\n  Evolution of Neurological Disorders", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deductive formalisms have been strongly developed in recent years; among\nthem, Answer Set Programming (ASP) gained some momentum, and has been lately\nfruitfully employed in many real-world scenarios. Nonetheless, in spite of a\nlarge number of success stories in relevant application areas, and even in\nindustrial contexts, deductive reasoning cannot be considered the ultimate,\ncomprehensive solution to AI; indeed, in several contexts, other approaches\nresult to be more useful. Typical Bioinformatics tasks, for instance\nclassification, are currently carried out mostly by Machine Learning (ML) based\nsolutions. In this paper, we focus on the relatively new problem of analyzing\nthe evolution of neurological disorders. In this context, ML approaches already\ndemonstrated to be a viable solution for classification tasks; here, we show\nhow ASP can play a relevant role in the brain evolution simulation task. In\nparticular, we propose a general and extensible framework to support physicians\nand researchers at understanding the complex mechanisms underlying neurological\ndisorders. The framework relies on a combined use of ML and ASP, and is general\nenough to be applied in several other application scenarios, which are outlined\nin the paper.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:01:48 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Calimeri", "Francesco", ""], ["Cauteruccio", "Francesco", ""], ["Cinelli", "Luca", ""], ["Marzullo", "Aldo", ""], ["Stamile", "Claudio", ""], ["Terracina", "Giorgio", ""], ["Durand-Dubief", "Francoise", ""], ["Sappey-Marinier", "Dominique", ""]]}, {"id": "1910.09477", "submitter": "Romain Bourqui", "authors": "L. Giovannangeli and R. Bourqui and R. Giot and D. Auber", "title": "Toward automatic comparison of visualization techniques: Application to\n  graph visualization", "comments": "35 pages, 6 figures, 4 tables", "journal-ref": "Visual Informatics (2020)", "doi": "10.1016/j.visinf.2020.04.002", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many end-user evaluations of data visualization techniques have been run\nduring the last decades. Their results are cornerstones to build efficient\nvisualization systems. However, designing such an evaluation is always complex\nand time-consuming and may end in a lack of statistical evidence and\nreproducibility. We believe that modern and efficient computer vision\ntechniques, such as deep convolutional neural networks (CNNs), may help\nvisualization researchers to build and/or adjust their evaluation hypothesis.\nThe basis of our idea is to train machine learning models on several\nvisualization techniques to solve a specific task. Our assumption is that it is\npossible to compare the efficiency of visualization techniques based on the\nperformance of their corresponding model. As current machine learning models\nare not able to strictly reflect human capabilities, including their\nimperfections, such results should be interpreted with caution. However, we\nthink that using machine learning-based pre-evaluation, as a pre-process of\nstandard user evaluations, should help researchers to perform a more exhaustive\nstudy of their design space. Thus, it should improve their final user\nevaluation by providing it better test cases. In this paper, we present the\nresults of two experiments we have conducted to assess how correlated the\nperformance of users and computer vision techniques can be. That study compares\ntwo mainstream graph visualization techniques: node-link (\\NL) and\nadjacency-matrix (\\MD) diagrams. Using two well-known deep convolutional neural\nnetworks, we partially reproduced user evaluations from Ghoniem \\textit{et al.}\nand from Okoe \\textit{et al.}. These experiments showed that some user\nevaluation results can be reproduced automatically.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:09:32 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 14:48:07 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Giovannangeli", "L.", ""], ["Bourqui", "R.", ""], ["Giot", "R.", ""], ["Auber", "D.", ""]]}, {"id": "1910.09483", "submitter": "Hanbaek Lyu", "authors": "Hanbaek Lyu, Facundo Memoli, and David Sivakoff", "title": "Sampling random graph homomorphisms and applications to network data\n  analysis", "comments": "51 pages, 33 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph homomorphism is a map between two graphs that preserves adjacency\nrelations. We consider the problem of sampling a random graph homomorphism from\na graph $F$ into a large network $\\mathcal{G}$. We propose two complementary\nMCMC algorithms for sampling a random graph homomorphisms and establish bounds\non their mixing times and concentration of their time averages. Based on our\nsampling algorithms, we propose a novel framework for network data analysis\nthat circumvents some of the drawbacks in methods based on independent and\nneigborhood sampling. Various time averages of the MCMC trajectory give us\nvarious computable observables, including well-known ones such as homomorphism\ndensity and average clustering coefficient and their generalizations.\nFurthermore, we show that these network observables are stable with respect to\na suitably renormalized cut distance between networks. We provide various\nexamples and simulations demonstrating our framework through synthetic\nnetworks. We also apply our framework for network clustering and classification\nproblems using the Facebook100 dataset and Word Adjacency Networks of a set of\nclassic novels.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:20:03 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 07:31:57 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Lyu", "Hanbaek", ""], ["Memoli", "Facundo", ""], ["Sivakoff", "David", ""]]}, {"id": "1910.09495", "submitter": "Saeed Reza Kheradpisheh", "authors": "Saeed Reza Kheradpisheh and Timoth\\'ee Masquelier", "title": "S4NN: temporal backpropagation for spiking neural networks with one\n  spike per neuron", "comments": null, "journal-ref": "International Journal of Neural Systems 2020", "doi": "10.1142/S0129065720500276", "report-no": null, "categories": "cs.NE cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new supervised learning rule for multilayer spiking neural\nnetworks (SNNs) that use a form of temporal coding known as rank-order-coding.\nWith this coding scheme, all neurons fire exactly one spike per stimulus, but\nthe firing order carries information. In particular, in the readout layer, the\nfirst neuron to fire determines the class of the stimulus. We derive a new\nlearning rule for this sort of network, named S4NN, akin to traditional error\nbackpropagation, yet based on latencies. We show how approximated error\ngradients can be computed backward in a feedforward network with any number of\nlayers. This approach reaches state-of-the-art performance with supervised\nmulti fully-connected layer SNNs: test accuracy of 97.4% for the MNIST dataset,\nand 99.2% for the Caltech Face/Motorbike dataset. Yet, the neuron model that we\nuse, non-leaky integrate-and-fire, is much simpler than the one used in all\nprevious works. The source codes of the proposed S4NN are publicly available at\nhttps://github.com/SRKH/S4NN.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:39:42 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 15:43:30 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 09:23:11 GMT"}, {"version": "v4", "created": "Sat, 13 Jun 2020 10:33:19 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kheradpisheh", "Saeed Reza", ""], ["Masquelier", "Timoth\u00e9e", ""]]}, {"id": "1910.09496", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Bin Hu, Tamer Ba\\c{s}ar", "title": "Policy Optimization for $\\mathcal{H}_2$ Linear Control with\n  $\\mathcal{H}_\\infty$ Robustness Guarantee: Implicit Regularization and Global\n  Convergence", "comments": "Addressed comments from L4DC and SICON; strengthened the landscape\n  and global convergence results; added simulation comparisons with existing\n  solvers to justify the numerical efficiency of our methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy optimization (PO) is a key ingredient for reinforcement learning (RL).\nFor control design, certain constraints are usually enforced on the policies to\noptimize, accounting for either the stability, robustness, or safety concerns\non the system. Hence, PO is by nature a constrained (nonconvex) optimization in\nmost cases, whose global convergence is challenging to analyze in general. More\nimportantly, some constraints that are safety-critical, e.g., the\n$\\mathcal{H}_\\infty$-norm constraint that guarantees the system robustness, are\ndifficult to enforce as the PO methods proceed. Recently, policy gradient\nmethods have been shown to converge to the global optimum of linear quadratic\nregulator (LQR), a classical optimal control problem, without\nregularizing/projecting the control iterates onto the stabilizing set, its\n(implicit) feasible set. This striking result is built upon the coercive\nproperty of the cost, ensuring that the iterates remain feasible as the cost\ndecreases. In this paper, we study the convergence theory of PO for\n$\\mathcal{H}_2$ linear control with $\\mathcal{H}_\\infty$-norm robustness\nguarantee. One significant new feature of this problem is the lack of\ncoercivity, i.e., the cost may have finite value around the feasible set\nboundary, breaking the existing analysis for LQR. Interestingly, we show that\ntwo PO methods enjoy the implicit regularization property, i.e., the iterates\npreserve the $\\mathcal{H}_\\infty$ robustness constraint as if they are\nregularized by the algorithms. Furthermore, despite the nonconvexity of the\nproblem, we show that these algorithms converge to the globally optimal\npolicies with globally sublinear rates, avoiding all suboptimal stationary\npoints/local minima, and with locally (super-)linear rates under certain\nconditions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:39:56 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 17:11:43 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 00:14:14 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Hu", "Bin", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1910.09499", "submitter": "Miaoyan Wang", "authors": "Zhuoyan Xu, Jiaxin Hu, and Miaoyan Wang", "title": "Generalized tensor regression with covariates on multiple modes", "comments": "25 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of tensor-response regression given covariates on\nmultiple modes. Such data problems arise frequently in applications such as\nneuroimaging, network analysis, and spatial-temporal modeling. We propose a new\nfamily of tensor response regression models that incorporate covariates, and\nestablish the theoretical accuracy guarantees. Unlike earlier methods, our\nestimation allows high-dimensionality in both the tensor response and the\ncovariate matrices on multiple modes. An efficient alternating updating\nalgorithm is further developed. Our proposal handles a broad range of data\ntypes, including continuous, count, and binary observations. Through simulation\nand applications to two real datasets, we demonstrate the outperformance of our\napproach over the state-of-art.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:43:26 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Xu", "Zhuoyan", ""], ["Hu", "Jiaxin", ""], ["Wang", "Miaoyan", ""]]}, {"id": "1910.09505", "submitter": "Frederic Sala", "authors": "Frederic Sala, Paroma Varma, Jason Fries, Daniel Y. Fu, Shiori Sagawa,\n  Saelig Khattar, Ashwini Ramamoorthy, Ke Xiao, Kayvon Fatahalian, James\n  Priest, Christopher R\\'e", "title": "Multi-Resolution Weak Supervision for Sequential Data", "comments": "NeurIPS 2019 (Conference on Neural Information Processing Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since manually labeling training data is slow and expensive, recent\nindustrial and scientific research efforts have turned to weaker or noisier\nforms of supervision sources. However, existing weak supervision approaches\nfail to model multi-resolution sources for sequential data, like video, that\ncan assign labels to individual elements or collections of elements in a\nsequence. A key challenge in weak supervision is estimating the unknown\naccuracies and correlations of these sources without using labeled data.\nMulti-resolution sources exacerbate this challenge due to complex correlations\nand sample complexity that scales in the length of the sequence. We propose\nDugong, the first framework to model multi-resolution weak supervision sources\nwith complex correlations to assign probabilistic labels to training data.\nTheoretically, we prove that Dugong, under mild conditions, can uniquely\nrecover the unobserved accuracy and correlation parameters and use parameter\nsharing to improve sample complexity. Our method assigns clinician-validated\nlabels to population-scale biomedical video repositories, helping outperform\ntraditional supervision by 36.8 F1 points and addressing a key use case where\nmachine learning has been severely limited by the lack of expert labeled data.\nOn average, Dugong improves over traditional supervision by 16.0 F1 points and\nexisting weak supervision approaches by 24.2 F1 points across several video and\nsensor classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:48:18 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Sala", "Frederic", ""], ["Varma", "Paroma", ""], ["Fries", "Jason", ""], ["Fu", "Daniel Y.", ""], ["Sagawa", "Shiori", ""], ["Khattar", "Saelig", ""], ["Ramamoorthy", "Ashwini", ""], ["Xiao", "Ke", ""], ["Fatahalian", "Kayvon", ""], ["Priest", "James", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1910.09508", "submitter": "Dongge Han", "authors": "Dongge Han, Wendelin Boehmer, Michael Wooldridge, Alex Rogers", "title": "Multi-agent Hierarchical Reinforcement Learning with Dynamic Termination", "comments": "PRICAI 2019", "journal-ref": null, "doi": "10.1007/978-3-030-29911-8_7", "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multi-agent system, an agent's optimal policy will typically depend on\nthe policies chosen by others. Therefore, a key issue in multi-agent systems\nresearch is that of predicting the behaviours of others, and responding\npromptly to changes in such behaviours. One obvious possibility is for each\nagent to broadcast their current intention, for example, the currently executed\noption in a hierarchical reinforcement learning framework. However, this\napproach results in inflexibility of agents if options have an extended\nduration and are dynamic. While adjusting the executed option at each step\nimproves flexibility from a single-agent perspective, frequent changes in\noptions can induce inconsistency between an agent's actual behaviour and its\nbroadcast intention. In order to balance flexibility and predictability, we\npropose a dynamic termination Bellman equation that allows the agents to\nflexibly terminate their options. We evaluate our model empirically on a set of\nmulti-agent pursuit and taxi tasks, and show that our agents learn to adapt\nflexibly across scenarios that require different termination behaviours.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:54:49 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Han", "Dongge", ""], ["Boehmer", "Wendelin", ""], ["Wooldridge", "Michael", ""], ["Rogers", "Alex", ""]]}, {"id": "1910.09522", "submitter": "Tito Spadini", "authors": "Tito Spadini, Ricardo Suyama", "title": "Comparative Study between Adversarial Networks and Classical Techniques\n  for Speech Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Speech enhancement is a crucial task for several applications. Among the most\nexplored techniques are the Wiener filter and the LogMMSE, but approaches\nexploring deep learning adapted to this task, such as SEGAN, have presented\nrelevant results. This study compared the performance of the mentioned\ntechniques in 85 noise conditions regarding quality, intelligibility, and\ndistortion; and concluded that classical techniques continue to exhibit\nsuperior results for most scenarios, but, in severe noise scenarios, SEGAN\nperformed better and with lower variance.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 17:28:12 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Spadini", "Tito", ""], ["Suyama", "Ricardo", ""]]}, {"id": "1910.09529", "submitter": "Yura Malitsky", "authors": "Yura Malitsky, Konstantin Mishchenko", "title": "Adaptive Gradient Descent without Descent", "comments": null, "journal-ref": "Proceedings of the 37-th International Conference on Machine\n  Learning, Online, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a strikingly simple proof that two rules are sufficient to\nautomate gradient descent: 1) don't increase the stepsize too fast and 2) don't\noverstep the local curvature. No need for functional values, no line search, no\ninformation about the function except for the gradients. By following these\nrules, you get a method adaptive to the local geometry, with convergence\nguarantees depending only on the smoothness in a neighborhood of a solution.\nGiven that the problem is convex, our method converges even if the global\nsmoothness constant is infinity. As an illustration, it can minimize arbitrary\ncontinuously twice-differentiable convex function. We examine its performance\non a range of convex and nonconvex problems, including logistic regression and\nmatrix factorization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 17:49:29 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 20:00:34 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Malitsky", "Yura", ""], ["Mishchenko", "Konstantin", ""]]}, {"id": "1910.09532", "submitter": "Mikul\\'a\\v{s} Zelinka", "authors": "Mikul\\'a\\v{s} Zelinka, Xingdi Yuan, Marc-Alexandre C\\^ot\\'e, Romain\n  Laroche, Adam Trischler", "title": "Building Dynamic Knowledge Graphs from Text-based Games", "comments": "NeurIPS 2019, Graph Representation Learning (GRL) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in learning how to update Knowledge Graphs (KG) from text.\nIn this preliminary work, we propose a novel Sequence-to-Sequence (Seq2Seq)\narchitecture to generate elementary KG operations. Furthermore, we introduce a\nnew dataset for KG extraction built upon text-based game transitions (over 300k\ndata points). We conduct experiments and discuss the results.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 17:55:25 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 01:20:36 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 22:53:16 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zelinka", "Mikul\u00e1\u0161", ""], ["Yuan", "Xingdi", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Laroche", "Romain", ""], ["Trischler", "Adam", ""]]}, {"id": "1910.09573", "submitter": "David Madras", "authors": "David Madras, James Atwood, Alex D'Amour", "title": "Detecting Extrapolation with Local Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present local ensembles, a method for detecting extrapolation at test time\nin a pre-trained model. We focus on underdetermination as a key component of\nextrapolation: we aim to detect when many possible predictions are consistent\nwith the training data and model class. Our method uses local second-order\ninformation to approximate the variance of predictions across an ensemble of\nmodels from the same class. We compute this approximation by estimating the\nnorm of the component of a test point's gradient that aligns with the\nlow-curvature directions of the Hessian, and provide a tractable method for\nestimating this quantity. Experimentally, we show that our method is capable of\ndetecting when a pre-trained model is extrapolating on test data, with\napplications to out-of-distribution detection, detecting spurious correlates,\nand active learning.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:05:52 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Madras", "David", ""], ["Atwood", "James", ""], ["D'Amour", "Alex", ""]]}, {"id": "1910.09578", "submitter": "Zhe Dong", "authors": "Zhe Dong, Deniz Oktay, Ben Poole, Alexander A. Alemi", "title": "On Predictive Information in RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain biological neurons demonstrate a remarkable capability to optimally\ncompress the history of sensory inputs while being maximally informative about\nthe future. In this work, we investigate if the same can be said of artificial\nneurons in recurrent neural networks (RNNs) trained with maximum likelihood.\nEmpirically, we find that RNNs are suboptimal in the information plane. Instead\nof optimally compressing past information, they extract additional information\nthat is not relevant for predicting the future. We show that constraining past\ninformation by injecting noise into the hidden state can improve RNNs in\nseveral ways: optimality in the predictive information plane, sample quality,\nheldout likelihood, and downstream classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:12:43 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 20:53:42 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Dong", "Zhe", ""], ["Oktay", "Deniz", ""], ["Poole", "Ben", ""], ["Alemi", "Alexander A.", ""]]}, {"id": "1910.09588", "submitter": "Zhe Dong", "authors": "Zhe Dong, Bryan A. Seybold, Kevin P. Murphy, Hung H. Bui", "title": "Collapsed Amortized Variational Inference for Switching Nonlinear\n  Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient inference method for switching nonlinear dynamical\nsystems. The key idea is to learn an inference network which can be used as a\nproposal distribution for the continuous latent variables, while performing\nexact marginalization of the discrete latent variables. This allows us to use\nthe reparameterization trick, and apply end-to-end training with stochastic\ngradient descent. We show that the proposed method can successfully segment\ntime series data, including videos and 3D human pose, into meaningful\n``regimes'' by using the piece-wise nonlinear dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:28:10 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 20:02:27 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Dong", "Zhe", ""], ["Seybold", "Bryan A.", ""], ["Murphy", "Kevin P.", ""], ["Bui", "Hung H.", ""]]}, {"id": "1910.09589", "submitter": "Vassilis N. Ioannidis", "authors": "Vassilis N. Ioannidis, Dimitris Berberidis, Georgios B. Giannakis", "title": "GraphSAC: Detecting anomalies in large-scale graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph-based sampling and consensus (GraphSAC) approach is introduced to\neffectively detect anomalous nodes in large-scale graphs. Existing approaches\nrely on connectivity and attributes of all nodes to assign an anomaly score per\nnode. However, nodal attributes and network links might be compromised by\nadversaries, rendering these holistic approaches vulnerable. Alleviating this\nlimitation, GraphSAC randomly draws subsets of nodes, and relies on graph-aware\ncriteria to judiciously filter out sets contaminated by anomalous nodes, before\nemploying a semi-supervised learning (SSL) module to estimate nominal label\ndistributions per node. These learned nominal distributions are minimally\naffected by the anomalous nodes, and hence can be directly adopted for anomaly\ndetection. Rigorous analysis provides performance guarantees for GraphSAC, by\nbounding the required number of draws. The per-draw complexity grows linearly\nwith the number of edges, which implies efficient SSL, while draws can be run\nin parallel, thereby ensuring scalability to large graphs. GraphSAC is tested\nunder different anomaly generation models based on random walks, clustered\nanomalies, as well as contemporary adversarial attacks for graph data.\nExperiments with real-world graphs showcase the advantage of GraphSAC relative\nto state-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:30:03 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Ioannidis", "Vassilis N.", ""], ["Berberidis", "Dimitris", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1910.09590", "submitter": "Vassilis N. Ioannidis", "authors": "Vassilis N. Ioannidis and Georgios B. Giannakis", "title": "Edge Dithering for Robust Adaptive Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) are vulnerable to perturbations of the\ngraph structure that are either random, or, adversarially designed. The\nperturbed links modify the graph neighborhoods, which critically affects the\nperformance of GCNs in semi-supervised learning (SSL) tasks. Aiming at\nrobustifying GCNs conditioned on the perturbed graph, the present paper\ngenerates multiple auxiliary graphs, each having its binary 0-1 edge weights\nflip values with probabilities designed to enhance robustness. The resultant\nedge-dithered auxiliary graphs are leveraged by an adaptive (A)GCN that\nperforms SSL. Robustness is enabled through learnable graph-combining weights\nalong with suitable regularizers. Relative to GCN, the novel AGCN achieves\nmarkedly improved performance in tests with noisy inputs, graph perturbations,\nand state-of-the-art adversarial attacks. Further experiments with protein\ninteraction networks showcase the competitive performance of AGCN for SSL over\nmultiple graphs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:30:11 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Ioannidis", "Vassilis N.", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1910.09594", "submitter": "Nicolas Skatchkovsky", "authors": "Nicolas Skatchkovsky, Hyeryung Jang, and Osvaldo Simeone", "title": "Federated Neuromorphic Learning of Spiking Neural Networks for Low-Power\n  Edge Intelligence", "comments": "submitted for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) offer a promising alternative to conventional\nArtificial Neural Networks (ANNs) for the implementation of on-device low-power\nonline learning and inference. On-device training is, however, constrained by\nthe limited amount of data available at each device. In this paper, we propose\nto mitigate this problem via cooperative training through Federated Learning\n(FL). To this end, we introduce an online FL-based learning rule for networked\non-device SNNs, which we refer to as FL-SNN. FL-SNN leverages local feedback\nsignals within each SNN, in lieu of backpropagation, and global feedback\nthrough communication via a base station. The scheme demonstrates significant\nadvantages over separate training and features a flexible trade-off between\ncommunication load and accuracy via the selective exchange of synaptic weights.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:36:17 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Skatchkovsky", "Nicolas", ""], ["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "1910.09597", "submitter": "Farid Kenarangi", "authors": "Farid Kenarangi, Inna Partin-Vaisband", "title": "A Single-MOSFET MAC for Confidence and Resolution (CORE) Driven Machine\n  Learning Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed-signal machine-learning classification has recently been demonstrated\nas an efficient alternative for classification with power expensive digital\ncircuits. In this paper, a high-COnfidence high-REsolution (CORE) mixed-signal\nclassifier is proposed for classifying high-dimensional input data into\nmulti-class output space with less power and area than state-of-the-art\nclassifiers. A high-resolution multiplication is facilitated within a\nsingle-MOSFET by feeding the features and feature weights into, respectively,\nthe body and gate inputs. High-resolution classifier that considers the\nconfidence of the individual predictors is designed at 45 nm technology node\nand operates at 100 MHz in subthreshold region. To evaluate the performance of\nthe classifier, a reduced MNIST dataset is generated by downsampling the MNIST\ndigit images from 28 $\\times$ 28 features to 9 $\\times$ 9 features. The system\nis simulated across a wide range of PVT variations, exhibiting nominal accuracy\nof 90%, energy consumption of 6.2 pJ per classification (over 45 times lower\nthan state-of-the-art classifiers), area of 2,179 $\\mu$$m^{2}$ (over 7.3 times\nlower than state-of-the-art classifiers), and a stable response under PVT\nvariations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:40:06 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Kenarangi", "Farid", ""], ["Partin-Vaisband", "Inna", ""]]}, {"id": "1910.09599", "submitter": "Johannes M\\\"uller", "authors": "Johannes M\\\"uller", "title": "On the space-time expressivity of ResNets", "comments": "Extended abstract of master's thesis; presented at the ICLR 2020\n  Workshop on Integration of Deep Neural Models and Differential Equations;\n  full version of the thesis available under\n  https://freidok.uni-freiburg.de/data/151788", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.NE math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual networks (ResNets) are a deep learning architecture that\nsubstantially improved the state of the art performance in certain supervised\nlearning tasks. Since then, they have received continuously growing attention.\nResNets have a recursive structure $x_{k+1} = x_k + R_k(x_k)$ where $R_k$ is a\nneural network called a residual block. This structure can be seen as the Euler\ndiscretisation of an associated ordinary differential equation (ODE) which is\ncalled a neural ODE. Recently, ResNets were proposed as the space-time\napproximation of ODEs which are not of this neural type. To elaborate this\nconnection we show that by increasing the number of residual blocks as well as\ntheir expressivity the solution of an arbitrary ODE can be approximated in\nspace and time simultaneously by deep ReLU ResNets. Further, we derive\nestimates on the complexity of the residual blocks required to obtain a\nprescribed accuracy under certain regularity assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:43:50 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 18:55:45 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 18:06:36 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2020 20:58:33 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["M\u00fcller", "Johannes", ""]]}, {"id": "1910.09600", "submitter": "Paul Bertin", "authors": "Mohammad Hashir, Paul Bertin, Martin Weiss, Vincent Frappier, Theodore\n  J. Perkins, Genevi\\`eve Boucher and Joseph Paul Cohen", "title": "Is graph-based feature selection of genes better than random?", "comments": "Accepted to the Machine Learning in Computational Biology (MLCB)\n  meeting 2019. 7 pages. 4 figures. arXiv admin note: substantial text overlap\n  with arXiv:1905.02295", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene interaction graphs aim to capture various relationships between genes\nand represent decades of biology research. When trying to make predictions from\ngenomic data, those graphs could be used to overcome the curse of\ndimensionality by making machine learning models sparser and more consistent\nwith biological common knowledge. In this work, we focus on assessing whether\nthose graphs capture dependencies seen in gene expression data better than\nrandom. We formulate a condition that graphs should satisfy to provide a good\nprior knowledge and propose to test it using a `Single Gene Inference' (SGI)\ntask. We compare random graphs with seven major gene interaction graphs\npublished by different research groups, aiming to measure the true benefit of\nusing biologically relevant graphs in this context. Our analysis finds that\ndependencies can be captured almost as well at random which suggests that, in\nterms of gene expression levels, the relevant information about the state of\nthe cell is spread across many genes.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:51:25 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 23:35:05 GMT"}, {"version": "v3", "created": "Fri, 27 Dec 2019 17:43:20 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hashir", "Mohammad", ""], ["Bertin", "Paul", ""], ["Weiss", "Martin", ""], ["Frappier", "Vincent", ""], ["Perkins", "Theodore J.", ""], ["Boucher", "Genevi\u00e8ve", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "1910.09615", "submitter": "Yongshuai Liu", "authors": "Yongshuai Liu, Jiaxin Ding, Xin Liu", "title": "IPO: Interior-point Policy Optimization under Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study reinforcement learning (RL) algorithms to solve\nreal-world decision problems with the objective of maximizing the long-term\nreward as well as satisfying cumulative constraints. We propose a novel\nfirst-order policy optimization method, Interior-point Policy Optimization\n(IPO), which augments the objective with logarithmic barrier functions,\ninspired by the interior-point method. Our proposed method is easy to implement\nwith performance guarantees and can handle general types of cumulative\nmulticonstraint settings. We conduct extensive evaluations to compare our\napproach with state-of-the-art baselines. Our algorithm outperforms the\nbaseline algorithms, in terms of reward maximization and constraint\nsatisfaction.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 19:22:14 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Liu", "Yongshuai", ""], ["Ding", "Jiaxin", ""], ["Liu", "Xin", ""]]}, {"id": "1910.09616", "submitter": "Siddharth Roheda", "authors": "Siddharth Roheda, Hamid Krim", "title": "Conquering the CNN Over-Parameterization Dilemma: A Volterra Filtering\n  Approach for Action Recognition", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i07.6870", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of inference in Machine Learning (ML) has led to an explosive\nnumber of different proposals in ML, and particularly in Deep Learning. In an\nattempt to reduce the complexity of Convolutional Neural Networks, we propose a\nVolterra filter-inspired Network architecture. This architecture introduces\ncontrolled non-linearities in the form of interactions between the delayed\ninput samples of data. We propose a cascaded implementation of Volterra\nFiltering so as to significantly reduce the number of parameters required to\ncarry out the same classification task as that of a conventional Neural\nNetwork. We demonstrate an efficient parallel implementation of this Volterra\nNeural Network (VNN), along with its remarkable performance while retaining a\nrelatively simpler and potentially more tractable structure. Furthermore, we\nshow a rather sophisticated adaptation of this network to nonlinearly fuse the\nRGB (spatial) information and the Optical Flow (temporal) information of a\nvideo sequence for action recognition. The proposed approach is evaluated on\nUCF-101 and HMDB-51 datasets for action recognition, and is shown to outperform\nstate of the art CNN approaches.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 19:22:38 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 21:48:35 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 15:10:55 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Roheda", "Siddharth", ""], ["Krim", "Hamid", ""]]}, {"id": "1910.09620", "submitter": "Yunkai Zhang", "authors": "Yunkai Zhang, Qiao Jiang, Shurui Li, Xiaoyong Jin, Xueying Ma, Xifeng\n  Yan", "title": "You May Not Need Order in Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting with limited data is a challenging yet critical task.\nWhile transformers have achieved outstanding performances in time series\nforecasting, they often require many training samples due to the large number\nof trainable parameters. In this paper, we propose a training technique for\ntransformers that prepares the training windows through random sampling. As\ninput time steps need not be consecutive, the number of distinct samples\nincreases from linearly to combinatorially many. By breaking the temporal\norder, this technique also helps transformers to capture dependencies among\ntime steps in finer granularity. We achieve competitive results compared to the\nstate-of-the-art on real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 19:28:24 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Zhang", "Yunkai", ""], ["Jiang", "Qiao", ""], ["Li", "Shurui", ""], ["Jin", "Xiaoyong", ""], ["Ma", "Xueying", ""], ["Yan", "Xifeng", ""]]}, {"id": "1910.09626", "submitter": "Abhishek Panigrahi", "authors": "Abhishek Panigrahi, Raghav Somani, Navin Goyal, Praneeth Netrapalli", "title": "Non-Gaussianity of Stochastic Gradient Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What enables Stochastic Gradient Descent (SGD) to achieve better\ngeneralization than Gradient Descent (GD) in Neural Network training? This\nquestion has attracted much attention. In this paper, we study the distribution\nof the Stochastic Gradient Noise (SGN) vectors during the training. We observe\nthat for batch sizes 256 and above, the distribution is best described as\nGaussian at-least in the early phases of training. This holds across data-sets,\narchitectures, and other choices.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 19:42:14 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 17:35:46 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Panigrahi", "Abhishek", ""], ["Somani", "Raghav", ""], ["Goyal", "Navin", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1910.09638", "submitter": "Hammad Ayyubi", "authors": "Hammad A. Ayyubi", "title": "GANspection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) have been used extensively and quite\nsuccessfully for unsupervised learning. As GANs don't approximate an explicit\nprobability distribution, it's an interesting study to inspect the latent space\nrepresentations learned by GANs. The current work seeks to push the boundaries\nof such inspection methods to further understand in more detail the manifold\nbeing learned by GANs. Various interpolation and extrapolation techniques along\nwith vector arithmetic is used to understand the learned manifold. We show\nthrough experiments that GANs indeed learn a data probability distribution\nrather than memorize images/data. Further, we prove that GANs encode\nsemantically relevant information in the learned probability distribution. The\nexperiments have been performed on two publicly available datasets - Large\nScale Scene Understanding (LSUN) and CelebA.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 20:26:54 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Ayyubi", "Hammad A.", ""]]}, {"id": "1910.09643", "submitter": "Pratik Mazumder", "authors": "Pratik Mazumder, Pravendra Singh, Vinay Namboodiri", "title": "CPWC: Contextual Point Wise Convolution for Object Recognition", "comments": "Accepted in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional layers are a major driving force behind the successes of deep\nlearning. Pointwise convolution (PWC) is a 1x1 convolutional filter that is\nprimarily used for parameter reduction. However, the PWC ignores the spatial\ninformation around the points it is processing. This design is by choice, in\norder to reduce the overall parameters and computations. However, we\nhypothesize that this shortcoming of PWC has a significant impact on the\nnetwork performance. We propose an alternative design for pointwise\nconvolution, which uses spatial information from the input efficiently. Our\ndesign significantly improves the performance of the networks without\nsubstantially increasing the number of parameters and computations. We\nexperimentally show that our design results in significant improvement in the\nperformance of the network for classification as well as detection.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 20:41:22 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 11:57:36 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Mazumder", "Pratik", ""], ["Singh", "Pravendra", ""], ["Namboodiri", "Vinay", ""]]}, {"id": "1910.09644", "submitter": "Rahul Krishna", "authors": "Rahul Krishna, Chong Tang, Kevin Sullivan, Baishakhi Ray", "title": "ConEx: Efficient Exploration of Big-Data System Configurations for\n  Better Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Configuration space complexity makes the big-data software systems hard to\nconfigure well. Consider Hadoop, with over nine hundred parameters, developers\noften just use the default configurations provided with Hadoop distributions.\nThe opportunity costs in lost performance are significant. Popular\nlearning-based approaches to auto-tune software does not scale well for\nbig-data systems because of the high cost of collecting training data. We\npresent a new method based on a combination of Evolutionary Markov Chain Monte\nCarlo (EMCMC) sampling and cost reduction techniques to cost-effectively find\nbetter-performing configurations for big data systems. For cost reduction, we\ndeveloped and experimentally tested and validated two approaches: using\nscaled-up big data jobs as proxies for the objective function for larger jobs\nand using a dynamic job similarity measure to infer that results obtained for\none kind of big data problem will work well for similar problems. Our\nexperimental results suggest that our approach promises to significantly\nimprove the performance of big data systems and that it outperforms competing\napproaches based on random sampling, basic genetic algorithms (GA), and\npredictive model learning. Our experimental results support the conclusion that\nour approach has strongly demonstrated potential to significantly and\ncost-effectively improve the performance of big data systems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 20:37:07 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 21:13:24 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Krishna", "Rahul", ""], ["Tang", "Chong", ""], ["Sullivan", "Kevin", ""], ["Ray", "Baishakhi", ""]]}, {"id": "1910.09645", "submitter": "Harald Steck", "authors": "Harald Steck", "title": "Markov Random Fields for Collaborative Filtering", "comments": "9 pages", "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we model the dependencies among the items that are recommended\nto a user in a collaborative-filtering problem via a Gaussian Markov Random\nField (MRF). We build upon Besag's auto-normal parameterization and\npseudo-likelihood, which not only enables computationally efficient learning,\nbut also connects the areas of MRFs and sparse inverse covariance estimation\nwith autoencoders and neighborhood models, two successful approaches in\ncollaborative filtering. We propose a novel approximation for learning sparse\nMRFs, where the trade-off between recommendation-accuracy and training-time can\nbe controlled. At only a small fraction of the training-time compared to\nvarious baselines, including deep nonlinear models, the proposed approach\nachieved competitive ranking-accuracy on all three well-known data-sets used in\nour experiments, and notably a 20% gain in accuracy on the data-set with the\nlargest number of items.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 20:46:42 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Steck", "Harald", ""]]}, {"id": "1910.09648", "submitter": "Max Little", "authors": "Max A. Little, Reham Badawy", "title": "Causal bootstrapping", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  To draw scientifically meaningful conclusions and build reliable models of\nquantitative phenomena, cause and effect must be taken into consideration\n(either implicitly or explicitly). This is particularly challenging when the\nmeasurements are not from controlled experimental (interventional) settings,\nsince cause and effect can be obscured by spurious, indirect influences. Modern\npredictive techniques from machine learning are capable of capturing\nhigh-dimensional, nonlinear relationships between variables while relying on\nfew parametric or probabilistic model assumptions. However, since these\ntechniques are associational, applied to observational data they are prone to\npicking up spurious influences from non-experimental (observational) data,\nmaking their predictions unreliable. Techniques from causal inference, such as\nprobabilistic causal diagrams and do-calculus, provide powerful (nonparametric)\ntools for drawing causal inferences from such observational data. However,\nthese techniques are often incompatible with modern, nonparametric machine\nlearning algorithms since they typically require explicit probabilistic models.\nHere, we develop causal bootstrapping for augmenting classical nonparametric\nbootstrap resampling with information on the causal relationship between\nvariables. This makes it possible to resample observational data such that, if\nit is possible to identify an interventional relationship from that data, new\ndata representing that relationship can be simulated from the original\nobservational data. In this way, we can use modern machine learning algorithms\nunaltered to make statistically powerful, yet causally-robust, predictions. We\ndevelop several causal bootstrapping algorithms for drawing interventional\ninferences from observational data, for classification and regression problems,\nand demonstrate, using synthetic and real-world examples, the value of this\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 20:52:56 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 20:51:57 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 00:23:44 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Little", "Max A.", ""], ["Badawy", "Reham", ""]]}, {"id": "1910.09652", "submitter": "Michael Arbel", "authors": "Michael Arbel and Arthur Gretton and Wuchen Li and Guido Montufar", "title": "Kernelized Wasserstein Natural Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems can be expressed as the optimization of some\ncost functional over a parametric family of probability distributions. It is\noften beneficial to solve such optimization problems using natural gradient\nmethods. These methods are invariant to the parametrization of the family, and\nthus can yield more effective optimization. Unfortunately, computing the\nnatural gradient is challenging as it requires inverting a high dimensional\nmatrix at each iteration. We propose a general framework to approximate the\nnatural gradient for the Wasserstein metric, by leveraging a dual formulation\nof the metric restricted to a Reproducing Kernel Hilbert Space. Our approach\nleads to an estimator for gradient direction that can trade-off accuracy and\ncomputational cost, with theoretical guarantees. We verify its accuracy on\nsimple examples, and show the advantage of using such an estimator in\nclassification tasks on Cifar10 and Cifar100 empirically.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 21:03:28 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 18:36:47 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 23:42:42 GMT"}, {"version": "v4", "created": "Thu, 13 Feb 2020 10:48:41 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Arbel", "Michael", ""], ["Gretton", "Arthur", ""], ["Li", "Wuchen", ""], ["Montufar", "Guido", ""]]}, {"id": "1910.09655", "submitter": "Fernando Gama", "authors": "Fernando Gama, Joan Bruna, Alejandro Ribeiro", "title": "Stability of Graph Neural Networks to Relative Perturbations", "comments": "Submitted to Int. Conf. on Acoustics, Speech and Signal Processing\n  (ICASSP) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs), consisting of a cascade of layers applying a\ngraph convolution followed by a pointwise nonlinearity, have become a powerful\narchitecture to process signals supported on graphs. Graph convolutions (and\nthus, GNNs), rely heavily on knowledge of the graph for operation. However, in\nmany practical cases the GSO is not known and needs to be estimated, or might\nchange from training time to testing time. In this paper, we are set to study\nthe effect that a change in the underlying graph topology that supports the\nsignal has on the output of a GNN. We prove that graph convolutions with\nintegral Lipschitz filters lead to GNNs whose output change is bounded by the\nsize of the relative change in the topology. Furthermore, we leverage this\nresult to show that the main reason for the success of GNNs is that they are\nstable architectures capable of discriminating features on high eigenvalues,\nwhich is a feat that cannot be achieved by linear graph filters (which are\neither stable or discriminative, but cannot be both). Finally, we comment on\nthe use of this result to train GNNs with increased stability and run\nexperiments on movie recommendation systems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 21:03:38 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Gama", "Fernando", ""], ["Bruna", "Joan", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1910.09657", "submitter": "Gege Wen", "authors": "Gege Wen and Meng Tang and Sally M. Benson", "title": "Multiphase flow prediction with deep neural networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijggc.2020.103223", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a deep neural network approach for predicting multiphase\nflow in heterogeneous domains with high computational efficiency. The deep\nneural network model is able to handle permeability heterogeneity in high\ndimensional systems, and can learn the interplay of viscous, gravity, and\ncapillary forces from small data sets. Using the example of carbon dioxide\n(CO2) storage, we demonstrate that the model can generate highly accurate\npredictions of a CO2 saturation distribution given a permeability field,\ninjection duration, injection rate, and injection location. The trained neural\nnetwork model has an excellent ability to interpolate and to a limited extent,\nthe ability to extrapolate beyond the training data ranges. To improve the\nprediction accuracy when the neural network model needs to extrapolate, we\npropose a transfer learning (fine-tuning) procedure that can quickly teach the\nneural network model new information without going through massive data\ncollection and retraining. Based on this trained neural network model, a\nweb-based tool is provided that allows users to perform CO2-water multiphase\nflow calculations online. With the tools provided in this paper, the deep\nneural network approach can provide a computationally efficient substitute for\nrepetitive forward multiphase flow simulations, which can be adopted to the\ncontext of history matching and uncertainty quantification.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 21:06:55 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Wen", "Gege", ""], ["Tang", "Meng", ""], ["Benson", "Sally M.", ""]]}, {"id": "1910.09664", "submitter": "Valts Blukis", "authors": "Valts Blukis, Yannick Terme, Eyvind Niklasson, Ross A. Knepper, Yoav\n  Artzi", "title": "Learning to Map Natural Language Instructions to Physical Quadcopter\n  Control using Simulated Flight", "comments": "Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a joint simulation and real-world learning framework for mapping\nnavigation instructions and raw first-person observations to continuous\ncontrol. Our model estimates the need for environment exploration, predicts the\nlikelihood of visiting environment positions during execution, and controls the\nagent to both explore and visit high-likelihood positions. We introduce\nSupervised Reinforcement Asynchronous Learning (SuReAL). Learning uses both\nsimulation and real environments without requiring autonomous flight in the\nphysical environment during training, and combines supervised learning for\npredicting positions to visit and reinforcement learning for continuous\ncontrol. We evaluate our approach on a natural language instruction-following\ntask with a physical quadcopter, and demonstrate effective execution and\nexploration behavior.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 21:19:33 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Blukis", "Valts", ""], ["Terme", "Yannick", ""], ["Niklasson", "Eyvind", ""], ["Knepper", "Ross A.", ""], ["Artzi", "Yoav", ""]]}, {"id": "1910.09667", "submitter": "Guillaume Bellegarda", "authors": "Guillaume Bellegarda and Katie Byl", "title": "Combining Benefits from Trajectory Optimization and Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs both in reinforcement learning and trajectory\noptimization have made significant advances towards real world robotic system\ndeployment. Reinforcement learning (RL) can be applied to many problems without\nneeding any modeling or intuition about the system, at the cost of high sample\ncomplexity and the inability to prove any metrics about the learned policies.\nTrajectory optimization (TO) on the other hand allows for stability and\nrobustness analyses on generated motions and trajectories, but is only as good\nas the often over-simplified derived model, and may have prohibitively\nexpensive computation times for real-time control. This paper seeks to combine\nthe benefits from these two areas while mitigating their drawbacks by (1)\ndecreasing RL sample complexity by using existing knowledge of the problem with\noptimal control, and (2) providing an upper bound estimate on the\ntime-to-arrival of the combined learned-optimized policy, allowing online\npolicy deployment at any point in the training process by using the TO as a\nworst-case scenario action. This method is evaluated for a car model, with\napplicability to any mobile robotic system. A video showing policy execution\ncomparisons can be found at https://youtu.be/mv2xw83NyWU .\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 21:44:15 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Bellegarda", "Guillaume", ""], ["Byl", "Katie", ""]]}, {"id": "1910.09670", "submitter": "Kaiyi Ji", "authors": "Kaiyi Ji, Zhe Wang, Bowen Weng, Yi Zhou, Wei Zhang and Yingbin Liang", "title": "History-Gradient Aided Batch Size Adaptation for Variance Reduced\n  Algorithms", "comments": "46 pages, 23 figures; Published in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance-reduced algorithms, although achieve great theoretical performance,\ncan run slowly in practice due to the periodic gradient estimation with a large\nbatch of data. Batch-size adaptation thus arises as a promising approach to\naccelerate such algorithms. However, existing schemes either apply prescribed\nbatch-size adaption rule or exploit the information along optimization path via\nadditional backtracking and condition verification steps. In this paper, we\npropose a novel scheme, which eliminates backtracking line search but still\nexploits the information along optimization path by adapting the batch size via\nhistory stochastic gradients. We further theoretically show that such a scheme\nsubstantially reduces the overall complexity for popular variance-reduced\nalgorithms SVRG and SARAH/SPIDER for both conventional nonconvex optimization\nand reinforcement learning problems. To this end, we develop a new convergence\nanalysis framework to handle the dependence of the batch size on history\nstochastic gradients. Extensive experiments validate the effectiveness of the\nproposed batch-size adaptation scheme.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 21:58:07 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 21:41:27 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 18:53:30 GMT"}, {"version": "v4", "created": "Mon, 27 Jul 2020 03:12:54 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ji", "Kaiyi", ""], ["Wang", "Zhe", ""], ["Weng", "Bowen", ""], ["Zhou", "Yi", ""], ["Zhang", "Wei", ""], ["Liang", "Yingbin", ""]]}, {"id": "1910.09671", "submitter": "Zhenglin Geng", "authors": "Zhenglin Geng, Dan Johnson, Ronald Fedkiw", "title": "Coercing Machine Learning to Output Physically Accurate Results", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2019.109099", "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine/deep learning artificial neural networks are trained to simply\nbe interpolation functions that map input variables to output values\ninterpolated from the training data in a linear/nonlinear fashion. Even when\nthe input/output pairs of the training data are physically accurate (e.g. the\nresults of an experiment or numerical simulation), interpolated quantities can\ndeviate quite far from being physically accurate. Although one could project\nthe output of a network into a physically feasible region, such a postprocess\nis not captured by the energy function minimized when training the network;\nthus, the final projected result could incorrectly deviate quite far from the\ntraining data. We propose folding any such projection or postprocess directly\ninto the network so that the final result is correctly compared to the training\ndata by the energy function. Although we propose a general approach, we\nillustrate its efficacy on a specific convolutional neural network that takes\nin human pose parameters (joint rotations) and outputs a prediction of vertex\npositions representing a triangulated cloth mesh. While the original network\noutputs vertex positions with erroneously high stretching and compression\nenergies, the new network trained with our physics prior remedies these issues\nproducing highly improved results.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 21:58:26 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 00:04:29 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Geng", "Zhenglin", ""], ["Johnson", "Dan", ""], ["Fedkiw", "Ronald", ""]]}, {"id": "1910.09676", "submitter": "Rama Kumar Pasumarthi", "authors": "Rama Kumar Pasumarthi, Xuanhui Wang, Michael Bendersky, Marc Najork", "title": "Self-Attentive Document Interaction Networks for Permutation Equivariant\n  Ranking", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to leverage cross-document interactions to improve ranking performance is\nan important topic in information retrieval (IR) research. However, this topic\nhas not been well-studied in the learning-to-rank setting and most of the\nexisting work still treats each document independently while scoring. The\nrecent development of deep learning shows strength in modeling complex\nrelationships across sequences and sets. It thus motivates us to study how to\nleverage cross-document interactions for learning-to-rank in the deep learning\nframework. In this paper, we formally define the permutation-equivariance\nrequirement for a scoring function that captures cross-document interactions.\nWe then propose a self-attention based document interaction network and show\nthat it satisfies the permutation-equivariant requirement, and can generate\nscores for document sets of varying sizes. Our proposed methods can\nautomatically learn to capture document interactions without any auxiliary\ninformation, and can scale across large document sets. We conduct experiments\non three ranking datasets: the benchmark Web30k, a Gmail search, and a Google\nDrive Quick Access dataset. Experimental results show that our proposed methods\nare both more effective and efficient than baselines.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 22:14:19 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 05:57:22 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Pasumarthi", "Rama Kumar", ""], ["Wang", "Xuanhui", ""], ["Bendersky", "Michael", ""], ["Najork", "Marc", ""]]}, {"id": "1910.09687", "submitter": "Shengye Wang", "authors": "Shengye Wang, Li Wan, Yang Yu, Ignacio Lopez Moreno", "title": "Signal Combination for Language Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Google's multilingual speech recognition system combines low-level acoustic\nsignals with language-specific recognizer signals to better predict the\nlanguage of an utterance. This paper presents our experience with different\nsignal combination methods to improve overall language identification accuracy.\nWe compare the performance of a lattice-based ensemble model and a deep neural\nnetwork model to combine signals from recognizers with that of a baseline that\nonly uses low-level acoustic signals. Experimental results show that the deep\nneural network model outperforms the lattice-based ensemble model, and it\nreduced the error rate from 5.5% in the baseline to 4.3%, which is a 21.8%\nrelative reduction.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 23:00:47 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 17:34:01 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wang", "Shengye", ""], ["Wan", "Li", ""], ["Yu", "Yang", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1910.09688", "submitter": "Benson Chen", "authors": "Benson Chen, Tianxiao Shen, Tommi S. Jaakkola, Regina Barzilay", "title": "Learning to Make Generalizable and Diverse Predictions for\n  Retrosynthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model for making generalizable and diverse retrosynthetic\nreaction predictions. Given a target compound, the task is to predict the\nlikely chemical reactants to produce the target. This generative task can be\nframed as a sequence-to-sequence problem by using the SMILES representations of\nthe molecules. Building on top of the popular Transformer architecture, we\npropose two novel pre-training methods that construct relevant auxiliary tasks\n(plausible reactions) for our problem. Furthermore, we incorporate a discrete\nlatent variable model into the architecture to encourage the model to produce a\ndiverse set of alternative predictions. On the 50k subset of reaction examples\nfrom the United States patent literature (USPTO-50k) benchmark dataset, our\nmodel greatly improves performance over the baseline, while also generating\npredictions that are more diverse.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 23:03:21 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Chen", "Benson", ""], ["Shen", "Tianxiao", ""], ["Jaakkola", "Tommi S.", ""], ["Barzilay", "Regina", ""]]}, {"id": "1910.09700", "submitter": "Victor Schmidt", "authors": "Alexandre Lacoste, Alexandra Luccioni, Victor Schmidt, Thomas Dandres", "title": "Quantifying the Carbon Emissions of Machine Learning", "comments": "Machine Learning Emissions Calculator:\n  https://mlco2.github.io/impact/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  From an environmental standpoint, there are a few crucial aspects of training\na neural network that have a major impact on the quantity of carbon that it\nemits. These factors include: the location of the server used for training and\nthe energy grid that it uses, the length of the training procedure, and even\nthe make and model of hardware on which the training takes place. In order to\napproximate these emissions, we present our Machine Learning Emissions\nCalculator, a tool for our community to better understand the environmental\nimpact of training ML models. We accompany this tool with an explanation of the\nfactors cited above, as well as concrete actions that individual practitioners\nand organizations can take to mitigate their carbon emissions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 23:57:32 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 20:37:33 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Lacoste", "Alexandre", ""], ["Luccioni", "Alexandra", ""], ["Schmidt", "Victor", ""], ["Dandres", "Thomas", ""]]}, {"id": "1910.09701", "submitter": "Boxin Zhao", "authors": "Boxin Zhao, Y. Samuel Wang, Mladen Kolar", "title": "Direct Estimation of Differential Functional Graphical Models", "comments": "21 pages, 3 figures, to be published in NeurIPS 2019; added link to\n  code", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the difference between two functional\nundirected graphical models with shared structures. In many applications, data\nare naturally regarded as high-dimensional random function vectors rather than\nmultivariate scalars. For example, electroencephalography (EEG) data are more\nappropriately treated as functions of time. In these problems, not only can the\nnumber of functions measured per sample be large, but each function is itself\nan infinite dimensional object, making estimation of model parameters\nchallenging. We develop a method that directly estimates the difference of\ngraphs, avoiding separate estimation of each graph, and show it is consistent\nin certain high-dimensional settings. We illustrate finite sample properties of\nour method through simulation studies. Finally, we apply our method to EEG data\nto uncover differences in functional brain connectivity between alcoholics and\ncontrol subjects.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 00:05:44 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 16:53:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhao", "Boxin", ""], ["Wang", "Y. Samuel", ""], ["Kolar", "Mladen", ""]]}, {"id": "1910.09703", "submitter": "Qiujia Li", "authors": "Qiujia Li, Florian L. Kreyssig, Chao Zhang, and Philip C. Woodland", "title": "Discriminative Neural Clustering for Speaker Diarisation", "comments": "Accepted as a conference paper at the 8th IEEE Spoken Language\n  Technology Workshop (SLT 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CV cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Discriminative Neural Clustering (DNC) that\nformulates data clustering with a maximum number of clusters as a supervised\nsequence-to-sequence learning problem. Compared to traditional unsupervised\nclustering algorithms, DNC learns clustering patterns from training data\nwithout requiring an explicit definition of a similarity measure. An\nimplementation of DNC based on the Transformer architecture is shown to be\neffective on a speaker diarisation task using the challenging AMI dataset.\nSince AMI contains only 147 complete meetings as individual input sequences,\ndata scarcity is a significant issue for training a Transformer model for DNC.\nAccordingly, this paper proposes three data augmentation schemes: sub-sequence\nrandomisation, input vector randomisation, and Diaconis augmentation, which\ngenerates new data samples by rotating the entire input sequence of\nL2-normalised speaker embeddings. Experimental results on AMI show that DNC\nachieves a reduction in speaker error rate (SER) of 29.4% relative to spectral\nclustering.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 00:09:22 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 15:32:03 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Li", "Qiujia", ""], ["Kreyssig", "Florian L.", ""], ["Zhang", "Chao", ""], ["Woodland", "Philip C.", ""]]}, {"id": "1910.09706", "submitter": "Uchenna Akujuobi", "authors": "Uchenna Akujuobi, Han Yufei, Qiannan Zhang, Xiangliang Zhang", "title": "Collaborative Graph Walk for Semi-supervised Multi-Label Node\n  Classification", "comments": "Accepted for IEEE International Conference on Data Mining (ICDM) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study semi-supervised multi-label node classification\nproblem in attributed graphs. Classic solutions to multi-label node\nclassification follow two steps, first learn node embedding and then build a\nnode classifier on the learned embedding. To improve the discriminating power\nof the node embedding, we propose a novel collaborative graph walk, named\nMulti-Label-Graph-Walk, to finely tune node representations with the available\nlabel assignments in attributed graphs via reinforcement learning. The proposed\nmethod formulates the multi-label node classification task as simultaneous\ngraph walks conducted by multiple label-specific agents. Furthermore, policies\nof the label-wise graph walks are learned in a cooperative way to capture first\nthe predictive relation between node labels and structural attributes of\ngraphs; and second, the correlation among the multiple label-specific\nclassification tasks. A comprehensive experimental study demonstrates that the\nproposed method can achieve significantly better multi-label classification\nperformance than the state-of-the-art approaches and conduct more efficient\ngraph exploration.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 00:20:47 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 21:30:09 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Akujuobi", "Uchenna", ""], ["Yufei", "Han", ""], ["Zhang", "Qiannan", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1910.09714", "submitter": "Ahmadreza Momeni", "authors": "Yonatan Gur, Ahmadreza Momeni, Stefan Wager", "title": "Smoothness-Adaptive Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a non-parametric multi-armed bandit problem with stochastic\ncovariates, where a key complexity driver is the smoothness of payoff functions\nwith respect to covariates. Previous studies have focused on deriving\nminimax-optimal algorithms in cases where it is a priori known how smooth the\npayoff functions are. In practice, however, the smoothness of payoff functions\nis typically not known in advance, and misspecification of smoothness may\nseverely deteriorate the performance of existing methods. In this work, we\nconsider a framework where the smoothness of payoff functions is not known, and\nstudy when and how algorithms may adapt to unknown smoothness. First, we\nestablish that designing algorithms that adapt to unknown smoothness of payoff\nfunctions is, in general, impossible. However, under a self-similarity\ncondition (which does not reduce the minimax complexity of the dynamic\noptimization problem at hand), we establish that adapting to unknown smoothness\nis possible, and further devise a general policy for achieving\nsmoothness-adaptive performance. Our policy infers the smoothness of payoffs\nthroughout the decision-making process, while leveraging the structure of\nnon-adaptive off-the-shelf policies. We establish that for problem settings\nwith either differentiable or non-differentiable payoff functions this policy\nmatches (up to a logarithmic scale) the regret rate that is achievable when the\nsmoothness of payoffs is known a priori.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 00:57:55 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 01:12:19 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 00:22:14 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 18:30:25 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Gur", "Yonatan", ""], ["Momeni", "Ahmadreza", ""], ["Wager", "Stefan", ""]]}, {"id": "1910.09715", "submitter": "David Heckerman", "authors": "David Heckerman and Chris Meek", "title": "Embedded Bayesian Network Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": "Microsoft Research Technical Report MS-TR-97-06, March 1997", "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-dimensional probability models for local distribution functions in a\nBayesian network include decision trees, decision graphs, and causal\nindependence models. We describe a new probability model for discrete Bayesian\nnetworks, which we call an embedded Bayesian network classifier or EBNC. The\nmodel for a node $Y$ given parents $\\bf X$ is obtained from a (usually\ndifferent) Bayesian network for $Y$ and $\\bf X$ in which $\\bf X$ need not be\nthe parents of $Y$. We show that an EBNC is a special case of a softmax\npolynomial regression model. Also, we show how to identify a non-redundant set\nof parameters for an EBNC, and describe an asymptotic approximation for\nlearning the structure of Bayesian networks that contain EBNCs. Unlike the\ndecision tree, decision graph, and causal independence models, we are unaware\nof a semantic justification for the use of these models. Experiments are needed\nto determine whether the models presented in this paper are useful in practice.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 01:02:51 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Heckerman", "David", ""], ["Meek", "Chris", ""]]}, {"id": "1910.09716", "submitter": "Mohammad Sadegh Norouzzadeh", "authors": "Mohammad Sadegh Norouzzadeh, Dan Morris, Sara Beery, Neel Joshi,\n  Nebojsa Jojic, and Jeff Clune", "title": "A deep active learning system for species identification and counting in\n  camera trap images", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biodiversity conservation depends on accurate, up-to-date information about\nwildlife population distributions. Motion-activated cameras, also known as\ncamera traps, are a critical tool for population surveys, as they are cheap and\nnon-intrusive. However, extracting useful information from camera trap images\nis a cumbersome process: a typical camera trap survey may produce millions of\nimages that require slow, expensive manual review. Consequently, critical\ninformation is often lost due to resource limitations, and critical\nconservation questions may be answered too slowly to support decision-making.\nComputer vision is poised to dramatically increase efficiency in image-based\nbiodiversity surveys, and recent studies have harnessed deep learning\ntechniques for automatic information extraction from camera trap images.\nHowever, the accuracy of results depends on the amount, quality, and diversity\nof the data available to train models, and the literature has focused on\nprojects with millions of relevant, labeled training images. Many camera trap\nprojects do not have a large set of labeled images and hence cannot benefit\nfrom existing machine learning techniques. Furthermore, even projects that do\nhave labeled data from similar ecosystems have struggled to adopt deep learning\nmethods because image classification models overfit to specific image\nbackgrounds (i.e., camera locations). In this paper, we focus not on automating\nthe labeling of camera trap images, but on accelerating this process. We\ncombine the power of machine intelligence and human intelligence to build a\nscalable, fast, and accurate active learning system to minimize the manual work\nrequired to identify and count animals in camera trap images. Our proposed\nscheme can match the state of the art accuracy on a 3.2 million image dataset\nwith as few as 14,100 manual labels, which means decreasing manual labeling\neffort by over 99.5%.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 01:03:33 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Norouzzadeh", "Mohammad Sadegh", ""], ["Morris", "Dan", ""], ["Beery", "Sara", ""], ["Joshi", "Neel", ""], ["Jojic", "Nebojsa", ""], ["Clune", "Jeff", ""]]}, {"id": "1910.09719", "submitter": "Boonserm Kijsirikul", "authors": "Panayu Keelawat, Nattapong Thammasan, Masayuki Numao, and Boonserm\n  Kijsirikul", "title": "Spatiotemporal Emotion Recognition using Deep CNN Based on EEG during\n  Music Listening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition based on EEG has become an active research area. As one\nof the machine learning models, CNN has been utilized to solve diverse problems\nincluding issues in this domain. In this work, a study of CNN and its\nspatiotemporal feature extraction has been conducted in order to explore\ncapabilities of the model in varied window sizes and electrode orders. Our\ninvestigation was conducted in subject-independent fashion. Results have shown\nthat temporal information in distinct window sizes significantly affects\nrecognition performance in both 10-fold and leave-one-subject-out cross\nvalidation. Spatial information from varying electrode order has modicum effect\non classification. SVM classifier depending on spatiotemporal knowledge on the\nsame dataset was previously employed and compared to these empirical results.\nEven though CNN and SVM have a homologous trend in window size effect, CNN\noutperformed SVM using leave-one-subject-out cross validation. This could be\ncaused by different extracted features in the elicitation process.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 01:30:47 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Keelawat", "Panayu", ""], ["Thammasan", "Nattapong", ""], ["Numao", "Masayuki", ""], ["Kijsirikul", "Boonserm", ""]]}, {"id": "1910.09722", "submitter": "Jongmin Yu", "authors": "Jongmin Yu, Sangwoo Park, Sangwook Lee, and Moongu Jeon", "title": "Drivers Drowsiness Detection using Condition-Adaptive Representation\n  Learning Framework", "comments": "IEEE Transactions on Intelligent Transportation Systems publication\n  information (2018)", "journal-ref": null, "doi": "10.1109/TITS.2018.2883823", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a condition-adaptive representation learning framework for the\ndriver drowsiness detection based on 3D-deep convolutional neural network. The\nproposed framework consists of four models: spatio-temporal representation\nlearning, scene condition understanding, feature fusion, and drowsiness\ndetection. The spatio-temporal representation learning extracts features that\ncan describe motions and appearances in video simultaneously. The scene\ncondition understanding classifies the scene conditions related to various\nconditions about the drivers and driving situations such as statuses of wearing\nglasses, illumination condition of driving, and motion of facial elements such\nas head, eye, and mouth. The feature fusion generates a condition-adaptive\nrepresentation using two features extracted from above models. The detection\nmodel recognizes drivers drowsiness status using the condition-adaptive\nrepresentation. The condition-adaptive representation learning framework can\nextract more discriminative features focusing on each scene condition than the\ngeneral representation so that the drowsiness detection method can provide more\naccurate results for the various driving situations. The proposed framework is\nevaluated with the NTHU Drowsy Driver Detection video dataset. The experimental\nresults show that our framework outperforms the existing drowsiness detection\nmethods based on visual analysis.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 01:51:43 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Yu", "Jongmin", ""], ["Park", "Sangwoo", ""], ["Lee", "Sangwook", ""], ["Jeon", "Moongu", ""]]}, {"id": "1910.09728", "submitter": "Zhizhe Liu", "authors": "Zhizhe Liu, Xingxing Zhang, Zhenfeng Zhu, Shuai Zheng, Yao Zhao, Jian\n  Cheng", "title": "Convolutional Prototype Learning for Zero-Shot Recognition", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) has received increasing attention in recent years\nespecially in areas of fine-grained object recognition, retrieval, and image\ncaptioning. The key to ZSL is to transfer knowledge from the seen to the unseen\nclasses via auxiliary class attribute vectors. However, the popularly learned\nprojection functions in previous works cannot generalize well since they assume\nthe distribution consistency between seen and unseen domains at\nsample-level.Besides, the provided non-visual and unique class attributes can\nsignificantly degrade the recognition performance in semantic space. In this\npaper, we propose a simple yet effective convolutional prototype learning (CPL)\nframework for zero-shot recognition. By assuming distribution consistency at\ntask-level, our CPL is capable of transferring knowledge smoothly to recognize\nunseen samples.Furthermore, inside each task, discriminative visual prototypes\nare learned via a distance based training mechanism. Consequently, we can\nperform recognition in visual space, instead of semantic space. An extensive\ngroup of experiments are then carefully designed and presented, demonstrating\nthat CPL obtains more favorable effectiveness, over currently available\nalternatives under various settings.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 02:15:46 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 06:53:51 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 02:56:56 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Liu", "Zhizhe", ""], ["Zhang", "Xingxing", ""], ["Zhu", "Zhenfeng", ""], ["Zheng", "Shuai", ""], ["Zhao", "Yao", ""], ["Cheng", "Jian", ""]]}, {"id": "1910.09731", "submitter": "Xiang Wang", "authors": "Xiang Wang, Tie Liu", "title": "Multiple Sample Clustering", "comments": "17 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clustering algorithms that view each object data as a single sample drawn\nfrom a certain distribution, Gaussian distribution, for example, has been a hot\ntopic for decades. Many clustering algorithms: such as k-means and spectral\nclustering are proposed based on the single sample assumption. However, in real\nlife, each input object can usually be the multiple samples drawn from a\ncertain hidden distribution. The traditional clustering algorithms cannot\nhandle such a situation. This calls for the multiple sample clustering\nalgorithm. But the traditional multiple sample clustering algorithms can only\nhandle scalar samples or samples from Gaussian distribution. This constrains\nthe application field of multiple sample clustering algorithms. In this paper,\nwe purpose a general framework for multiple sample clustering. Various\nalgorithms can be generated by this framework. We apply two specific cases of\nthis framework: Wasserstein distance version and Bhattacharyya distance version\non both synthetic data and stock price data. The simulation results show that\nthe sufficient statistic can greatly improve the clustering accuracy and\nstability.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 02:29:16 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 00:22:50 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 04:53:05 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Wang", "Xiang", ""], ["Liu", "Tie", ""]]}, {"id": "1910.09732", "submitter": "Xinjie Lan", "authors": "Xinjie Lan, Kenneth E. Barner", "title": "Explicitly Bayesian Regularizations in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Generalization is essential for deep learning. In contrast to previous works\nclaiming that Deep Neural Networks (DNNs) have an implicit regularization\nimplemented by the stochastic gradient descent, we demonstrate explicitly\nBayesian regularizations in a specific category of DNNs, i.e., Convolutional\nNeural Networks (CNNs). First, we introduce a novel probabilistic\nrepresentation for the hidden layers of CNNs and demonstrate that CNNs\ncorrespond to Bayesian networks with the serial connection. Furthermore, we\nshow that the hidden layers close to the input formulate prior distributions,\nthus CNNs have explicitly Bayesian regularizations based on the Bayesian\nregularization theory. In addition, we clarify two recently observed empirical\nphenomena that are inconsistent with traditional theories of generalization.\nFinally, we validate the proposed theory on a synthetic dataset\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 02:32:03 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Lan", "Xinjie", ""], ["Barner", "Kenneth E.", ""]]}, {"id": "1910.09734", "submitter": "Chun-Na Li", "authors": "Chun-Na Li, Yuan-Hai Shao, Huajun Wang, Yu-Ting Zhao, Ling-Wei Huang,\n  Naihua Xiu and Nai-Yang Deng", "title": "Single and Union Non-parallel Support Vector Machine Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the classification problem, we summarize the nonparallel support\nvector machines with the nonparallel hyperplanes to two types of frameworks.\nThe first type constructs the hyperplanes separately. It solves a series of\nsmall optimization problems to obtain a series of hyperplanes, but is hard to\nmeasure the loss of each sample. The other type constructs all the hyperplanes\nsimultaneously, and it solves one big optimization problem with the ascertained\nloss of each sample. We give the characteristics of each framework and compare\nthem carefully. In addition, based on the second framework, we construct a\nmax-min distance-based nonparallel support vector machine for multiclass\nclassification problem, called NSVM. It constructs hyperplanes with large\ndistance margin by solving an optimization problem. Experimental results on\nbenchmark data sets show the advantages of our NSVM.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 02:34:34 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 00:03:40 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 06:56:34 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Li", "Chun-Na", ""], ["Shao", "Yuan-Hai", ""], ["Wang", "Huajun", ""], ["Zhao", "Yu-Ting", ""], ["Huang", "Ling-Wei", ""], ["Xiu", "Naihua", ""], ["Deng", "Nai-Yang", ""]]}, {"id": "1910.09738", "submitter": "Ali Madani", "authors": "Ali Madani, Cyna Shirazinejad, Jia Rui Ong, Hengameh Shams, Mohammad\n  Mofrad", "title": "ProDyn0: Inferring calponin homology domain stretching behavior using\n  graph neural networks", "comments": "8 pages, 2 figures, 2 tables", "journal-ref": "ICLR 2019: Representation learning on graphs and manifolds", "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Graph neural networks are a quickly emerging field for non-Euclidean data\nthat leverage the inherent graphical structure to predict node, edge, and\nglobal-level properties of a system. Protein properties can not easily be\nunderstood as a simple sum of their parts (i.e. amino acids), therefore,\nunderstanding their dynamical properties in the context of graphs is attractive\nfor revealing how perturbations to their structure can affect their global\nfunction. To tackle this problem, we generate a database of 2020 mutated\ncalponin homology (CH) domains undergoing large-scale separation in molecular\ndynamics. To predict the mechanosensitive force response, we develop neural\nmessage passing networks and residual gated graph convnets which predict the\nprotein dependent force separation at 86.63 percent, 81.59 kJ/mol/nm MAE, 76.99\npsec MAE for force mode classification, max force magnitude, max force time\nrespectively-- significantly better than non-graph-based deep learning\ntechniques. Towards uniting geometric learning techniques and biophysical\nobservables, we premiere our simulation database as a benchmark dataset for\nfurther development/evaluation of graph neural network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 02:42:58 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Madani", "Ali", ""], ["Shirazinejad", "Cyna", ""], ["Ong", "Jia Rui", ""], ["Shams", "Hengameh", ""], ["Mofrad", "Mohammad", ""]]}, {"id": "1910.09739", "submitter": "Ming-Chuan Yang", "authors": "Ming-Chuan Yang, Meng Chang Chen", "title": "Composite Neural Network: Theory and Application to PM2.5 Prediction", "comments": "This version is accepted by IEEE TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the framework and performance issues of the composite\nneural network, which is composed of a collection of pre-trained and\nnon-instantiated neural network models connected as a rooted directed acyclic\ngraph for solving complicated applications. A pre-trained neural network model\nis generally well trained, targeted to approximate a specific function. Despite\na general belief that a composite neural network may perform better than a\nsingle component, the overall performance characteristics are not clear. In\nthis work, we construct the framework of a composite network, and prove that a\ncomposite neural network performs better than any of its pre-trained components\nwith a high probability bound. In addition, if an extra pre-trained component\nis added to a composite network, with high probability, the overall performance\nwill not be degraded. In the study, we explore a complicated application --\nPM2.5 prediction -- to illustrate the correctness of the proposed composite\nnetwork theory. In the empirical evaluations of PM2.5 prediction, the\nconstructed composite neural network models support the proposed theory and\nperform better than other machine learning models, demonstrate the advantages\nof the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 02:43:17 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 04:35:03 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yang", "Ming-Chuan", ""], ["Chen", "Meng Chang", ""]]}, {"id": "1910.09745", "submitter": "Wen-Yu Chang", "authors": "Wen-Yu Chang, Tsung-Nan Lin", "title": "Vanishing Nodes: Another Phenomenon That Makes Training Deep Neural\n  Networks Difficult", "comments": "16 pages, 9 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the problem of vanishing/exploding gradients is a\nchallenge when training deep networks. In this paper, we describe another\nphenomenon, called vanishing nodes, that also increases the difficulty of\ntraining deep neural networks. As the depth of a neural network increases, the\nnetwork's hidden nodes have more highly correlated behavior. This results in\ngreat similarities between these nodes. The redundancy of hidden nodes thus\nincreases as the network becomes deeper. We call this problem vanishing nodes,\nand we propose the metric vanishing node indicator (VNI) for quantitatively\nmeasuring the degree of vanishing nodes. The VNI can be characterized by the\nnetwork parameters, which is shown analytically to be proportional to the depth\nof the network and inversely proportional to the network width. The theoretical\nresults show that the effective number of nodes vanishes to one when the VNI\nincreases to one (its maximal value), and that vanishing/exploding gradients\nand vanishing nodes are two different challenges that increase the difficulty\nof training deep neural networks. The numerical results from the experiments\nsuggest that the degree of vanishing nodes will become more evident during\nback-propagation training, and that when the VNI is equal to 1, the network\ncannot learn simple tasks (e.g. the XOR problem) even when the gradients are\nneither vanishing nor exploding. We refer to this kind of gradients as the\nwalking dead gradients, which cannot help the network converge when having a\nrelatively large enough scale. Finally, the experiments show that the\nlikelihood of failed training increases as the depth of the network increases.\nThe training will become much more difficult due to the lack of network\nrepresentation capability.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 03:11:26 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Chang", "Wen-Yu", ""], ["Lin", "Tsung-Nan", ""]]}, {"id": "1910.09754", "submitter": "Hamed Sarvari", "authors": "Hamed Sarvari, Carlotta Domeniconi, Bardh Prenkaj, Giovanni Stilo", "title": "Unsupervised Boosting-based Autoencoder Ensembles for Outlier Detection", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders, as a dimensionality reduction technique, have been recently\napplied to outlier detection. However, neural networks are known to be\nvulnerable to overfitting, and therefore have limited potential in the\nunsupervised outlier detection setting. Current approaches to ensemble-based\nautoencoders do not generate a sufficient level of diversity to avoid the\noverfitting issue. To overcome the aforementioned limitations we develop a\nBoosting-based Autoencoder Ensemble approach (in short, BAE). BAE is an\nunsupervised ensemble method that, similarly to the boosting approach, builds\nan adaptive cascade of autoencoders to achieve improved and robust results. BAE\ntrains the autoencoder components sequentially by performing a weighted\nsampling of the data, aimed at reducing the amount of outliers used during\ntraining, and at injecting diversity in the ensemble. We perform extensive\nexperiments and show that the proposed methodology outperforms state-of-the-art\napproaches under a variety of conditions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 03:47:39 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Sarvari", "Hamed", ""], ["Domeniconi", "Carlotta", ""], ["Prenkaj", "Bardh", ""], ["Stilo", "Giovanni", ""]]}, {"id": "1910.09763", "submitter": "Thomas Merkh", "authors": "Thomas Merkh and Guido Mont\\'ufar", "title": "Stochastic Feedforward Neural Networks: Universal Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter we take a look at the universal approximation question for\nstochastic feedforward neural networks. In contrast to deterministic networks,\nwhich represent mappings from a set of inputs to a set of outputs, stochastic\nnetworks represent mappings from a set of inputs to a set of probability\ndistributions over the set of outputs. In particular, even if the sets of\ninputs and outputs are finite, the class of stochastic mappings in question is\nnot finite. Moreover, while for a deterministic function the values of all\noutput variables can be computed independently of each other given the values\nof the inputs, in the stochastic setting the values of the output variables may\nneed to be correlated, which requires that their values are computed jointly. A\nprominent class of stochastic feedforward networks which has played a key role\nin the resurgence of deep learning are deep belief networks. The\nrepresentational power of these networks has been studied mainly in the\ngenerative setting, as models of probability distributions without an input, or\nin the discriminative setting for the special case of deterministic mappings.\nWe study the representational power of deep sigmoid belief networks in terms of\ncompositions of linear transformations of probability distributions, Markov\nkernels, that can be expressed by the layers of the network. We investigate\ndifferent types of shallow and deep architectures, and the minimal number of\nlayers and units per layer that are sufficient and necessary in order for the\nnetwork to be able to approximate any given stochastic mapping from the set of\ninputs to the set of outputs arbitrarily well.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 04:49:43 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Merkh", "Thomas", ""], ["Mont\u00fafar", "Guido", ""]]}, {"id": "1910.09768", "submitter": "Qiulei Dong", "authors": "Qiulei Dong and Jiayin Sun and Zhanyi Hu", "title": "Face representation by deep learning: a linear encoding in a parameter\n  space?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Convolutional Neural Networks (CNNs) have achieved tremendous\nperformances on face recognition, and one popular perspective regarding CNNs'\nsuccess is that CNNs could learn discriminative face representations from face\nimages with complex image feature encoding. However, it is still unclear what\nis the intrinsic mechanism of face representation in CNNs. In this work, we\ninvestigate this problem by formulating face images as points in a\nshape-appearance parameter space, and our results demonstrate that: (i) The\nencoding and decoding of the neuron responses (representations) to face images\nin CNNs could be achieved under a linear model in the parameter space, in\nagreement with the recent discovery in primate IT face neurons, but different\nfrom the aforementioned perspective on CNNs' face representation with complex\nimage feature encoding; (ii) The linear model for face encoding and decoding in\nthe parameter space could achieve close or even better performances on face\nrecognition and verification than state-of-the-art CNNs, which might provide\nnew lights on the design strategies for face recognition systems; (iii) The\nneuron responses to face images in CNNs could not be adequately modelled by the\naxis model, a model recently proposed on face modelling in primate IT cortex.\nAll these results might shed some lights on the often complained blackbox\nnature behind CNNs' tremendous performances on face recognition.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 05:01:28 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Dong", "Qiulei", ""], ["Sun", "Jiayin", ""], ["Hu", "Zhanyi", ""]]}, {"id": "1910.09772", "submitter": "Rui Shu", "authors": "Rui Shu, Yining Chen, Abhishek Kumar, Stefano Ermon, Ben Poole", "title": "Weakly Supervised Disentanglement with Guarantees", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disentangled representations that correspond to factors of variation\nin real-world data is critical to interpretable and human-controllable machine\nlearning. Recently, concerns about the viability of learning disentangled\nrepresentations in a purely unsupervised manner has spurred a shift toward the\nincorporation of weak supervision. However, there is currently no formalism\nthat identifies when and how weak supervision will guarantee disentanglement.\nTo address this issue, we provide a theoretical framework to assist in\nanalyzing the disentanglement guarantees (or lack thereof) conferred by weak\nsupervision when coupled with learning algorithms based on distribution\nmatching. We empirically verify the guarantees and limitations of several weak\nsupervision methods (restricted labeling, match-pairing, and rank-pairing),\ndemonstrating the predictive power and usefulness of our theoretical framework.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 05:21:51 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 21:39:33 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Shu", "Rui", ""], ["Chen", "Yining", ""], ["Kumar", "Abhishek", ""], ["Ermon", "Stefano", ""], ["Poole", "Ben", ""]]}, {"id": "1910.09777", "submitter": "Peike Li", "authors": "Peike Li, Yunqiu Xu, Yunchao Wei, Yi Yang", "title": "Self-Correction for Human Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Labeling pixel-level masks for fine-grained semantic segmentation tasks, e.g.\nhuman parsing, remains a challenging task. The ambiguous boundary between\ndifferent semantic parts and those categories with similar appearance usually\nare confusing, leading to unexpected noises in ground truth masks. To tackle\nthe problem of learning with label noises, this work introduces a purification\nstrategy, called Self-Correction for Human Parsing (SCHP), to progressively\npromote the reliability of the supervised labels as well as the learned models.\nIn particular, starting from a model trained with inaccurate annotations as\ninitialization, we design a cyclically learning scheduler to infer more\nreliable pseudo-masks by iteratively aggregating the current learned model with\nthe former optimal one in an online manner. Besides, those correspondingly\ncorrected labels can in turn to further boost the model performance. In this\nway, the models and the labels will reciprocally become more robust and\naccurate during the self-correction learning cycles. Benefiting from the\nsuperiority of SCHP, we achieve the best performance on two popular\nsingle-person human parsing benchmarks, including LIP and Pascal-Person-Part\ndatasets. Our overall system ranks 1st in CVPR2019 LIP Challenge. Code is\navailable at https://github.com/PeikeLi/Self-Correction-Human-Parsing.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 05:49:54 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Li", "Peike", ""], ["Xu", "Yunqiu", ""], ["Wei", "Yunchao", ""], ["Yang", "Yi", ""]]}, {"id": "1910.09778", "submitter": "Hye-jin Shim", "authors": "Hye-jin Shim, Hee-Soo Heo, Jee-weon Jung, and Ha-Jin Yu", "title": "Self-supervised pre-training with acoustic configurations for replay\n  spoofing detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing a dataset for replay spoofing detection requires a physical\nprocess of playing an utterance and re-recording it, presenting a challenge to\nthe collection of large-scale datasets. In this study, we propose a\nself-supervised framework for pretraining acoustic configurations using\ndatasets published for other tasks, such as speaker verification. Here,\nacoustic configurations refer to the environmental factors generated during the\nprocess of voice recording but not the voice itself, including microphone\ntypes, place and ambient noise levels. Specifically, we select pairs of\nsegments from utterances and train deep neural networks to determine whether\nthe acoustic configurations of the two segments are identical. We validate the\neffectiveness of the proposed method based on the ASVspoof 2019 physical access\ndataset utilizing two well-performing systems. The experimental results\ndemonstrate that the proposed method outperforms the baseline approach by 30%.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 05:54:41 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 05:00:37 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Shim", "Hye-jin", ""], ["Heo", "Hee-Soo", ""], ["Jung", "Jee-weon", ""], ["Yu", "Ha-Jin", ""]]}, {"id": "1910.09779", "submitter": "Jiaming Song", "authors": "Jiaming Song and Stefano Ermon", "title": "Bridging the Gap Between $f$-GANs and Wasserstein GANs", "comments": "updated for ICML camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have enjoyed much success in learning\nhigh-dimensional distributions. Learning objectives approximately minimize an\n$f$-divergence ($f$-GANs) or an integral probability metric (Wasserstein GANs)\nbetween the model and the data distribution using a discriminator. Wasserstein\nGANs enjoy superior empirical performance, but in $f$-GANs the discriminator\ncan be interpreted as a density ratio estimator which is necessary in some GAN\napplications. In this paper, we bridge the gap between $f$-GANs and Wasserstein\nGANs (WGANs). First, we list two constraints over variational $f$-divergence\nestimation objectives that preserves the optimal solution. Next, we minimize\nover a Lagrangian relaxation of the constrained objective, and show that it\ngeneralizes critic objectives of both $f$-GAN and WGAN. Based on this\ngeneralization, we propose a novel practical objective, named KL-Wasserstein\nGAN (KL-WGAN). We demonstrate empirical success of KL-WGAN on synthetic\ndatasets and real-world image generation benchmarks, and achieve\nstate-of-the-art FID scores on CIFAR10 image generation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 05:55:03 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 20:53:50 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "1910.09792", "submitter": "Jisoo Lee", "authors": "Jisoo Lee, Sae-Young Chung", "title": "Robust Training with Ensemble Consensus", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since deep neural networks are over-parameterized, they can memorize noisy\nexamples. We address such a memorization issue in the presence of label noise.\nFrom the fact that deep neural networks cannot generalize to neighborhoods of\nmemorized features, we hypothesize that noisy examples do not consistently\nincur small losses on the network under a certain perturbation. Based on this,\nwe propose a novel training method called Learning with Ensemble Consensus\n(LEC) that prevents overfitting to noisy examples by removing them based on the\nconsensus of an ensemble of perturbed networks. One of the proposed LECs, LTEC\noutperforms the current state-of-the-art methods on noisy MNIST, CIFAR-10, and\nCIFAR-100 in an efficient manner.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 06:58:10 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 03:33:50 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 09:59:16 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Lee", "Jisoo", ""], ["Chung", "Sae-Young", ""]]}, {"id": "1910.09798", "submitter": "Shruti Jadon", "authors": "Shruti Jadon, Aditya Acrot Srinivasan", "title": "Improving Siamese Networks for One Shot Learning using Kernel Based\n  Activation functions", "comments": "15 pages, 8 figures", "journal-ref": "Advances in Intelligent Systems and Computing book series (AISC,\n  volume 1175) Springer 2020", "doi": "10.1007/978-981-15-5619-7_25", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The lack of a large amount of training data has always been the constraining\nfactor in solving a lot of problems in machine learning, making One Shot\nLearning one of the most intriguing ideas in machine learning. It aims to learn\ninformation about object categories from one, or only a few training examples.\nThis process of learning in deep learning is usually accomplished by proper\nobjective function, i.e; loss function and embeddings extraction i.e;\narchitecture. In this paper, we discussed about metrics based deep learning\narchitectures for one shot learning such as Siamese neural networks and present\na method to improve on their accuracy using Kafnets (kernel-based\nnon-parametric activation functions for neural networks) by learning proper\nembeddings with relatively less number of epochs. Using kernel activation\nfunctions, we are able to achieve strong results which exceed those of ReLU\nbased deep learning models in terms of embeddings structure, loss convergence,\nand accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 07:17:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jadon", "Shruti", ""], ["Srinivasan", "Aditya Acrot", ""]]}, {"id": "1910.09804", "submitter": "Efthymios Tzinis", "authors": "Efthymios Tzinis, Shrikant Venkataramani, Zhepei Wang, Cem Subakan and\n  Paris Smaragdis", "title": "Two-Step Sound Source Separation: Training on Learned Latent Targets", "comments": "Submitted to ICASSP 2020", "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP40776.2020.9054172", "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a two-step training procedure for source separation\nvia a deep neural network. In the first step we learn a transform (and it's\ninverse) to a latent space where masking-based separation performance using\noracles is optimal. For the second step, we train a separation module that\noperates on the previously learned space. In order to do so, we also make use\nof a scale-invariant signal to distortion ratio (SI-SDR) loss function that\nworks in the latent space, and we prove that it lower-bounds the SI-SDR in the\ntime domain. We run various sound separation experiments that show how this\napproach can obtain better performance as compared to systems that learn the\ntransform and the separation module jointly. The proposed methodology is\ngeneral enough to be applicable to a large class of neural network end-to-end\nseparation systems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 07:49:21 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 18:45:42 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Tzinis", "Efthymios", ""], ["Venkataramani", "Shrikant", ""], ["Wang", "Zhepei", ""], ["Subakan", "Cem", ""], ["Smaragdis", "Paris", ""]]}, {"id": "1910.09808", "submitter": "Alessandro Betti", "authors": "Lorenzo Gigoni, Alessandro Betti, Mauro Tucci and Emanuele Crisostomi", "title": "A Scalable Predictive Maintenance Model for Detecting Wind Turbine\n  Component Failures Based on SCADA Data", "comments": "Paper presented at the conference IEEE PES General Meeting 2019,\n  August 4-8 (Atlanta, USA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a novel predictive maintenance system is presented and applied\nto the main components of wind turbines. The proposed model is based on machine\nlearning and statistical process control tools applied to SCADA (Supervisory\nControl And Data Acquisition) data of critical components. The test campaign\nwas divided into two stages: a first two years long offline test, and a second\none year long real-time test. The offline test used historical faults from six\nwind farms located in Italy and Romania, corresponding to a total of 150 wind\nturbines and an overall installed nominal power of 283 MW. The results\ndemonstrate outstanding capabilities of anomaly prediction up to 2 months\nbefore device unscheduled downtime. Furthermore, the real-time 12-months test\nconfirms the ability of the proposed system to detect several anomalies,\ntherefore allowing the operators to identify the root causes, and to schedule\nmaintenance actions before reaching a catastrophic stage.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 07:55:15 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Gigoni", "Lorenzo", ""], ["Betti", "Alessandro", ""], ["Tucci", "Mauro", ""], ["Crisostomi", "Emanuele", ""]]}, {"id": "1910.09821", "submitter": "Dan Peng", "authors": "Dan Peng, Zizhan Zheng, Linhao Luo, Xiaofeng Zhang", "title": "Structure Matters: Towards Generating Transferable Adversarial Images", "comments": "accepted to ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on adversarial examples for image classification focus on\ndirectly modifying pixels with minor perturbations. The small perturbation\nrequirement is imposed to ensure the generated adversarial examples being\nnatural and realistic to humans, which, however, puts a curb on the attack\nspace thus limiting the attack ability and transferability especially for\nsystems protected by a defense mechanism. In this paper, we propose the novel\nconcepts of structure patterns and structure-aware perturbations that relax the\nsmall perturbation constraint while still keeping images natural. The key idea\nof our approach is to allow perceptible deviation in adversarial examples while\nkeeping structure patterns that are central to a human classifier. Built upon\nthese concepts, we propose a \\emph{structure-preserving attack (SPA)} for\ngenerating natural adversarial examples with extremely high transferability.\nEmpirical results on the MNIST and the CIFAR10 datasets show that SPA exhibits\nstrong attack ability in both the white-box and black-box setting even defenses\nare applied. Moreover, with the integration of PGD or CW attack, its attack\nability escalates sharply under the white-box setting, without losing the\noutstanding transferability inherited from SPA.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 08:20:00 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 15:21:15 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 10:33:59 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Peng", "Dan", ""], ["Zheng", "Zizhan", ""], ["Luo", "Linhao", ""], ["Zhang", "Xiaofeng", ""]]}, {"id": "1910.09840", "submitter": "Sebastian Lapuschkin", "authors": "Maximilian Kohlbrenner, Alexander Bauer, Shinichi Nakajima, Alexander\n  Binder, Wojciech Samek, Sebastian Lapuschkin", "title": "Towards Best Practice in Explaining Neural Network Decisions with LRP", "comments": "7 pages, 4 figures, 1 table. fixed table row compared to v2.\n  Presented virtually at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Within the last decade, neural network based predictors have demonstrated\nimpressive - and at times super-human - capabilities. This performance is often\npaid for with an intransparent prediction process and thus has sparked numerous\ncontributions in the novel field of explainable artificial intelligence (XAI).\nIn this paper, we focus on a popular and widely used method of XAI, the\nLayer-wise Relevance Propagation (LRP). Since its initial proposition LRP has\nevolved as a method, and a best practice for applying the method has tacitly\nemerged, based however on humanly observed evidence alone. In this paper we\ninvestigate - and for the first time quantify - the effect of this current best\npractice on feedforward neural networks in a visual object detection setting.\nThe results verify that the layer-dependent approach to LRP applied in recent\nliterature better represents the model's reasoning, and at the same time\nincreases the object localization and class discriminativity of LRP.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 08:58:54 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 14:06:45 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 20:00:09 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Kohlbrenner", "Maximilian", ""], ["Bauer", "Alexander", ""], ["Nakajima", "Shinichi", ""], ["Binder", "Alexander", ""], ["Samek", "Wojciech", ""], ["Lapuschkin", "Sebastian", ""]]}, {"id": "1910.09851", "submitter": "Firuz Kamalov", "authors": "Firuz Kamalov", "title": "Orthogonal variance decomposition based feature selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing feature selection methods fail to properly account for interactions\nbetween features when evaluating feature subsets. In this paper, we attempt to\nremedy this issue by using orthogonal variance decomposition to evaluate\nfeatures. The orthogonality of the decomposition allows us to directly\ncalculate the total contribution of a feature to the output variance. Thus we\nobtain an efficient algorithm for feature evaluation which takes into account\ninteractions among features. Numerical experiments demonstrate that our method\naccurately identifies relevant features and improves the accuracy of numerical\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 09:18:39 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Kamalov", "Firuz", ""]]}, {"id": "1910.09857", "submitter": "Nuri Mert Vural", "authors": "N. Mert Vural, Salih Erg\\\"ut and Suleyman S. Kozat", "title": "An Efficient and Effective Second-Order Training Algorithm for\n  LSTM-based Adaptive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adaptive (or online) nonlinear regression with\nLong-Short-Term-Memory (LSTM) based networks, i.e., LSTM-based adaptive\nlearning. In this context, we introduce an efficient Extended Kalman filter\n(EKF) based second-order training algorithm. Our algorithm is truly online,\ni.e., it does not assume any underlying data generating process and future\ninformation, except that the target sequence is bounded. Through an extensive\nset of experiments, we demonstrate significant performance gains achieved by\nour algorithm with respect to the state-of-the-art methods. Here, we mainly\nshow that our algorithm consistently provides 10 to 45\\% improvement in the\naccuracy compared to the widely-used adaptive methods Adam, RMSprop, and DEKF,\nand comparable performance to EKF with a 10 to 15 times reduction in the\nrun-time.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 09:30:41 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 16:40:10 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 16:12:42 GMT"}, {"version": "v4", "created": "Sat, 15 Aug 2020 13:43:54 GMT"}, {"version": "v5", "created": "Mon, 31 May 2021 15:39:14 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vural", "N. Mert", ""], ["Erg\u00fct", "Salih", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1910.09862", "submitter": "Guillaume Doras", "authors": "Guillaume Doras, Geoffroy Peeters", "title": "A Prototypical Triplet Loss for Cover Detection", "comments": "Corrections after reviewers comments. Correct erroneous figure 5 in\n  original version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic cover detection -- the task of finding in a audio dataset all\ncovers of a query track -- has long been a challenging theoretical problem in\nMIR community. It also became a practical need for music composers societies\nrequiring to detect automatically if an audio excerpt embeds musical content\nbelonging to their catalog.\n  In a recent work, we addressed this problem with a convolutional neural\nnetwork mapping each track's dominant melody to an embedding vector, and\ntrained to minimize cover pairs distance in the embeddings space, while\nmaximizing it for non-covers. We showed in particular that training this model\nwith enough works having five or more covers yields state-of-the-art results.\n  This however does not reflect the realistic use case, where music catalogs\ntypically contain works with zero or at most one or two covers. We thus\nintroduce here a new test set incorporating these constraints, and propose two\ncontributions to improve our model's accuracy under these stricter conditions:\nwe replace dominant melody with multi-pitch representation as input data, and\ndescribe a novel prototypical triplet loss designed to improve covers\nclustering. We show that these changes improve results significantly for two\nconcrete use cases, large dataset lookup and live songs identification.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 09:39:59 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 09:48:08 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Doras", "Guillaume", ""], ["Peeters", "Geoffroy", ""]]}, {"id": "1910.09876", "submitter": "Arnab Sanyal", "authors": "Arnab Sanyal, Peter A. Beerel, Keith M. Chugg", "title": "Neural Network Training with Approximate Logarithmic Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high computational complexity associated with training deep neural\nnetworks limits online and real-time training on edge devices. This paper\nproposed an end-to-end training and inference scheme that eliminates\nmultiplications by approximate operations in the log-domain which has the\npotential to significantly reduce implementation complexity. We implement the\nentire training procedure in the log-domain, with fixed-point data\nrepresentations. This training procedure is inspired by hardware-friendly\napproximations of log-domain addition which are based on look-up tables and\nbit-shifts. We show that our 16-bit log-based training can achieve\nclassification accuracy within approximately 1% of the equivalent\nfloating-point baselines for a number of commonly used datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 10:11:16 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Sanyal", "Arnab", ""], ["Beerel", "Peter A.", ""], ["Chugg", "Keith M.", ""]]}, {"id": "1910.09880", "submitter": "Ruben Ohana", "authors": "Ruben Ohana, Jonas Wacker, Jonathan Dong, S\\'ebastien Marmin, Florent\n  Krzakala, Maurizio Filippone, Laurent Daudet", "title": "Kernel computations from large-scale random features obtained by Optical\n  Processing Units", "comments": "5 pages, 3 figures, submitted to ICASSP 2020", "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP40776.2020.9053272", "report-no": null, "categories": "cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximating kernel functions with random features (RFs)has been a\nsuccessful application of random projections for nonparametric estimation.\nHowever, performing random projections presents computational challenges for\nlarge-scale problems. Recently, a new optical hardware called Optical\nProcessing Unit (OPU) has been developed for fast and energy-efficient\ncomputation of large-scale RFs in the analog domain. More specifically, the OPU\nperforms the multiplication of input vectors by a large random matrix with\ncomplex-valued i.i.d. Gaussian entries, followed by the application of an\nelement-wise squared absolute value operation - this last nonlinearity being\nintrinsic to the sensing process. In this paper, we show that this operation\nresults in a dot-product kernel that has connections to the polynomial kernel,\nand we extend this computation to arbitrary powers of the feature map.\nExperiments demonstrate that the OPU kernel and its RF approximation achieve\ncompetitive performance in applications using kernel ridge regression and\ntransfer learning for image classification. Crucially, thanks to the use of the\nOPU, these results are obtained with time and energy savings.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 10:37:08 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 09:48:52 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Ohana", "Ruben", ""], ["Wacker", "Jonas", ""], ["Dong", "Jonathan", ""], ["Marmin", "S\u00e9bastien", ""], ["Krzakala", "Florent", ""], ["Filippone", "Maurizio", ""], ["Daudet", "Laurent", ""]]}, {"id": "1910.09890", "submitter": "Albert Gu", "authors": "Albert Gu, Caglar Gulcehre, Tom Le Paine, Matt Hoffman, Razvan Pascanu", "title": "Improving the Gating Mechanism of Recurrent Neural Networks", "comments": "International Conference on Machine Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gating mechanisms are widely used in neural network models, where they allow\ngradients to backpropagate more easily through depth or time. However, their\nsaturation property introduces problems of its own. For example, in recurrent\nmodels these gates need to have outputs near 1 to propagate information over\nlong time-delays, which requires them to operate in their saturation regime and\nhinders gradient-based learning of the gate mechanism. We address this problem\nby deriving two synergistic modifications to the standard gating mechanism that\nare easy to implement, introduce no additional hyperparameters, and improve\nlearnability of the gates when they are close to saturation. We show how these\nchanges are related to and improve on alternative recently proposed gating\nmechanisms such as chrono initialization and Ordered Neurons. Empirically, our\nsimple gating mechanisms robustly improve the performance of recurrent models\non a range of applications, including synthetic memorization tasks, sequential\nimage classification, language modeling, and reinforcement learning,\nparticularly when long-term dependencies are involved.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 11:03:00 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 20:20:55 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Gu", "Albert", ""], ["Gulcehre", "Caglar", ""], ["Paine", "Tom Le", ""], ["Hoffman", "Matt", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1910.09918", "submitter": "Hajime Yoshino", "authors": "Hajime Yoshino", "title": "From complex to simple : hierarchical free-energy landscape renormalized\n  in deep neural networks", "comments": "61 pages, 20 figures, revised version, to appear in SciPost Phys Core", "journal-ref": "SciPost Phys. Core 2, 005 (2020)", "doi": "10.21468/SciPostPhysCore.2.2.005", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a statistical mechanical approach based on the replica method to\nstudy the design space of deep and wide neural networks constrained to meet a\nlarge number of training data. Specifically, we analyze the configuration space\nof the synaptic weights and neurons in the hidden layers in a simple\nfeed-forward perceptron network for two scenarios: a setting with random\ninputs/outputs and a teacher-student setting. By increasing the strength of\nconstraints,~i.e. increasing the number of training data, successive 2nd order\nglass transition (random inputs/outputs) or 2nd order crystalline transition\n(teacher-student setting) take place layer-by-layer starting next to the\ninputs/outputs boundaries going deeper into the bulk with the thickness of the\nsolid phase growing logarithmically with the data size. This implies the\ntypical storage capacity of the network grows exponentially fast with the\ndepth. In a deep enough network, the central part remains in the liquid phase.\nWe argue that in systems of finite width N, the weak bias field can remain in\nthe center and plays the role of a symmetry-breaking field that connects the\nopposite sides of the system. The successive glass transitions bring about a\nhierarchical free-energy landscape with ultrametricity, which evolves in space:\nit is most complex close to the boundaries but becomes renormalized into\nprogressively simpler ones in deeper layers. These observations provide clues\nto understand why deep neural networks operate efficiently. Finally, we present\nsome numerical simulations of learning which reveal spatially heterogeneous\nglassy dynamics truncated by a finite width $N$ effect.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 12:21:06 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 15:20:48 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 04:22:32 GMT"}, {"version": "v4", "created": "Fri, 10 Apr 2020 02:30:29 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Yoshino", "Hajime", ""]]}, {"id": "1910.09933", "submitter": "Suyi Li", "authors": "Suyi Li, Yong Cheng, Yang Liu, Wei Wang, Tianjian Chen", "title": "Abnormal Client Behavior Detection in Federated Learning", "comments": "7 pages, 1 figure, 2nd International Workshop on Federated Learning\n  for Data Privacy and Confidentiality, in Conjunction with NeurIPS 2019\n  (FL-NeurIPS 19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In federated learning systems, clients are autonomous in that their behaviors\nare not fully governed by the server. Consequently, a client may intentionally\nor unintentionally deviate from the prescribed course of federated model\ntraining, resulting in abnormal behaviors, such as turning into a malicious\nattacker or a malfunctioning client. Timely detecting those anomalous clients\nis therefore critical to minimize their adverse impacts. In this work, we\npropose to detect anomalous clients at the server side. In particular, we\ngenerate low-dimensional surrogates of model weight vectors and use them to\nperform anomaly detection. We evaluate our solution through experiments on\nimage classification model training over the FEMNIST dataset. Experimental\nresults show that the proposed detection-based approach significantly\noutperforms the conventional defense-based methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 12:48:07 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 06:13:55 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Li", "Suyi", ""], ["Cheng", "Yong", ""], ["Liu", "Yang", ""], ["Wang", "Wei", ""], ["Chen", "Tianjian", ""]]}, {"id": "1910.09935", "submitter": "Wei Zou", "authors": "Ruixiong Zhang, Wei Zou, Xiangang Li", "title": "Cross-task pre-training for on-device acoustic scene classification", "comments": "presented at Interspeech workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic scene classification (ASC) and acoustic event detection (AED) are\ndifferent but related tasks. Acoustic events can provide useful information for\nrecognizing acoustic scenes. However, most of the datasets are provided without\neither the acoustic event or scene labels. To utilize the acoustic event\ninformation to improve the performance of ASC tasks, we present the cross-task\npre-training mechanism which utilizes acoustic event information from the\npre-trained AED model for ASC tasks. On the other hand, most of the models were\ndesigned and implemented on platforms with rich computing resources, and the\non-device applications were limited. To solve this problem, we use model\ndistillation method to compress our cross-task model to enable on-device\nacoustic scene classification. In this paper, the cross-task models and their\nstudent model were trained and evaluated on two datasets: TAU Urban Acoustic\nScenes 2019 dataset and TUT Acoustic Scenes 2017 dataset. Results have shown\nthat cross-task pre-training mechanism can significantly improve the\nperformance of ASC tasks. The performance of our best model improved relatively\n9.5% in the TAU Urban Acoustic Scenes 2019 dataset, and also improved 10% in\nthe TUT Acoustic Scenes 2017 dataset compared with the official baseline. At\nthe same time, the performance of the student model is much better than that of\nthe model without teachers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 12:53:48 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 05:19:12 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhang", "Ruixiong", ""], ["Zou", "Wei", ""], ["Li", "Xiangang", ""]]}, {"id": "1910.09943", "submitter": "Ilya Amburg", "authors": "Ilya Amburg, Nate Veldt, Austin R. Benson", "title": "Clustering in graphs and hypergraphs with categorical edge labels", "comments": "In Proceedings of The Web Conference 2020 (WWW '20), April 20-24,\n  2020, Taipei, Taiwan", "journal-ref": null, "doi": "10.1145/3366423.3380152", "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern graph or network datasets often contain rich structure that goes\nbeyond simple pairwise connections between nodes. This calls for complex\nrepresentations that can capture, for instance, edges of different types as\nwell as so-called \"higher-order interactions\" that involve more than two nodes\nat a time. However, we have fewer rigorous methods that can provide insight\nfrom such representations. Here, we develop a computational framework for the\nproblem of clustering hypergraphs with categorical edge labels --- or different\ninteraction types --- where clusters corresponds to groups of nodes that\nfrequently participate in the same type of interaction.\n  Our methodology is based on a combinatorial objective function that is\nrelated to correlation clustering on graphs but enables the design of much more\nefficient algorithms that also seamlessly generalize to hypergraphs. When there\nare only two label types, our objective can be optimized in polynomial time,\nusing an algorithm based on minimum cuts. Minimizing our objective becomes\nNP-hard with more than two label types, but we develop fast approximation\nalgorithms based on linear programming relaxations that have theoretical\ncluster quality guarantees. We demonstrate the efficacy of our algorithms and\nthe scope of the model through problems in edge-label community detection,\nclustering with temporal data, and exploratory data analysis.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 13:01:16 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 19:26:53 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Amburg", "Ilya", ""], ["Veldt", "Nate", ""], ["Benson", "Austin R.", ""]]}, {"id": "1910.09945", "submitter": "Sangwoo Park", "authors": "Sangwoo Park, Osvaldo Simeone, Joonhyuk Kang", "title": "Meta-Learning to Communicate: Fast End-to-End Training for Fading\n  Channels", "comments": "submitted for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a channel model is available, learning how to communicate on fading\nnoisy channels can be formulated as the (unsupervised) training of an\nautoencoder consisting of the cascade of encoder, channel, and decoder. An\nimportant limitation of the approach is that training should be generally\ncarried out from scratch for each new channel. To cope with this problem, prior\nworks considered joint training over multiple channels with the aim of finding\na single pair of encoder and decoder that works well on a class of channels. As\na result, joint training ideally mimics the operation of non-coherent\ntransmission schemes. In this paper, we propose to obviate the limitations of\njoint training via meta-learning: Rather than training a common model for all\nchannels, meta-learning finds a common initialization vector that enables fast\ntraining on any channel. The approach is validated via numerical results,\ndemonstrating significant training speed-ups, with effective encoders and\ndecoders obtained with as little as one iteration of Stochastic Gradient\nDescent.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 13:04:38 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Park", "Sangwoo", ""], ["Simeone", "Osvaldo", ""], ["Kang", "Joonhyuk", ""]]}, {"id": "1910.09952", "submitter": "Wenjun Yan", "authors": "Wenjun Yan, Qing Ling, Limin Zhang", "title": "Convolutional Neural Networks for Space-Time Block Coding Recognition", "comments": "4 pages,7figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the latest advances in machine learning with deep neural networks to\nthe tasks of radio modulation recognition, channel coding recognition, and\nspectrum monitoring. This paper first proposes an identification algorithm for\nspace-time block coding of a signal. The feature between spatial multiplexing\nand Alamouti signals is extracted by adapting convolutional neural networks\nafter preprocessing the received sequence. Unlike other algorithms, this method\nrequires no prior information of channel coefficients and noise power, and\nconsequently is well-suited for noncooperative contexts. Results show that the\nproposed algorithm performs well even at a low signal-to-noise ratio\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 02:09:13 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 07:29:15 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Yan", "Wenjun", ""], ["Ling", "Qing", ""], ["Zhang", "Limin", ""]]}, {"id": "1910.09972", "submitter": "Yuki Saito", "authors": "Yuki Saito, Takuma Nakamura, Hirotaka Hachiya, Kenji Fukumizu", "title": "Exchangeable deep neural networks for set-to-set matching and learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58520-4_37", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching two different sets of items, called heterogeneous set-to-set\nmatching problem, has recently received attention as a promising problem. The\ndifficulties are to extract features to match a correct pair of different sets\nand also preserve two types of exchangeability required for set-to-set\nmatching: the pair of sets, as well as the items in each set, should be\nexchangeable. In this study, we propose a novel deep learning architecture to\naddress the abovementioned difficulties and also an efficient training\nframework for set-to-set matching. We evaluate the methods through experiments\nbased on two industrial applications: fashion set recommendation and group\nre-identification. In these experiments, we show that the proposed method\nprovides significant improvements and results compared with the\nstate-of-the-art methods, thereby validating our architecture for the\nheterogeneous set matching problem.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 13:42:39 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 09:34:59 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Saito", "Yuki", ""], ["Nakamura", "Takuma", ""], ["Hachiya", "Hirotaka", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "1910.09979", "submitter": "Junjun Pan", "authors": "Junjun Pan, Michael K. Ng, Ye Liu, Xiongjun Zhang, Hong Yan", "title": "Orthogonal Nonnegative Tucker Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the nonnegative tensor data and propose an orthogonal\nnonnegative Tucker decomposition (ONTD). We discuss some properties of ONTD and\ndevelop a convex relaxation algorithm of the augmented Lagrangian function to\nsolve the optimization problem. The convergence of the algorithm is given. We\nemploy ONTD on the image data sets from the real world applications including\nface recognition, image representation, hyperspectral unmixing. Numerical\nresults are shown to illustrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 11:18:21 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 11:48:17 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Pan", "Junjun", ""], ["Ng", "Michael K.", ""], ["Liu", "Ye", ""], ["Zhang", "Xiongjun", ""], ["Yan", "Hong", ""]]}, {"id": "1910.09989", "submitter": "Merlijn Blaauw", "authors": "Merlijn Blaauw, Jordi Bonada", "title": "Sequence-to-sequence Singing Synthesis Using the Feed-forward\n  Transformer", "comments": "5 pages, 1 figure, accepted at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a sequence-to-sequence singing synthesizer, which avoids the need\nfor training data with pre-aligned phonetic and acoustic features. Rather than\nthe more common approach of a content-based attention mechanism combined with\nan autoregressive decoder, we use a different mechanism suitable for\nfeed-forward synthesis. Given that phonetic timings in singing are highly\nconstrained by the musical score, we derive an approximate initial alignment\nwith the help of a simple duration model. Then, using a decoder based on a\nfeed-forward variant of the Transformer model, a series of self-attention and\nconvolutional layers refines the result of the initial alignment to reach the\ntarget acoustic features. Advantages of this approach include faster inference\nand avoiding the exposure bias issues that affect autoregressive models trained\nby teacher forcing. We evaluate the effectiveness of this model compared to an\nautoregressive baseline, the importance of self-attention, and the importance\nof the accuracy of the duration model.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 14:04:50 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 11:42:15 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Blaauw", "Merlijn", ""], ["Bonada", "Jordi", ""]]}, {"id": "1910.09991", "submitter": "Fabrizio De Fausti", "authors": "Fabrizio De Fausti, Francesco Pugliese and Diego Zardetto", "title": "Towards Automated Website Classification by Deep Learning", "comments": null, "journal-ref": "Rivista di Statistica Ufficiale, n. 3/2020, Istat, pag. 9-50, ISSN\n  1828-1982", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the interest in Big Data sources has been steadily growing\nwithin the Official Statistic community. The Italian National Institute of\nStatistics (Istat) is currently carrying out several Big Data pilot studies.\nOne of these studies, the ICT Big Data pilot, aims at exploiting massive\namounts of textual data automatically scraped from the websites of Italian\nenterprises in order to predict a set of target variables (e.g. e-commerce)\nthat are routinely observed by the traditional ICT Survey. In this paper, we\nshow that Deep Learning techniques can successfully address this problem.\nEssentially, we tackle a text classification task: an algorithm must learn to\ninfer whether an Italian enterprise performs e-commerce from the textual\ncontent of its website. To reach this goal, we developed a sophisticated\nprocessing pipeline and evaluated its performance through extensive\nexperiments. Our pipeline uses Convolutional Neural Networks and relies on Word\nEmbeddings to encode raw texts into grayscale images (i.e. normalized numeric\nmatrices). Web-scraped texts are huge and have very low signal to noise ratio:\nto overcome these issues, we adopted a framework known as False Positive\nReduction, which has seldom (if ever) been applied before to text\nclassification tasks. Several original contributions enable our processing\npipeline to reach good classification results. Empirical evidence shows that\nour proposal outperforms all the alternative Machine Learning solutions already\ntested in Istat for the same task.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 14:07:17 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 23:07:25 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["De Fausti", "Fabrizio", ""], ["Pugliese", "Francesco", ""], ["Zardetto", "Diego", ""]]}, {"id": "1910.09998", "submitter": "Tingxiang Fan", "authors": "Tingxiang Fan, Pinxin Long, Wenxi Liu, Jia Pan, Ruigang Yang, Dinesh\n  Manocha", "title": "Learning Resilient Behaviors for Navigation Under Uncertainty", "comments": "accepted to ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has great potential to acquire complex, adaptive\nbehaviors for autonomous agents automatically. However, the underlying neural\nnetwork polices have not been widely deployed in real-world applications,\nespecially in these safety-critical tasks (e.g., autonomous driving). One of\nthe reasons is that the learned policy cannot perform flexible and resilient\nbehaviors as traditional methods to adapt to diverse environments. In this\npaper, we consider the problem that a mobile robot learns adaptive and\nresilient behaviors for navigating in unseen uncertain environments while\navoiding collisions. We present a novel approach for uncertainty-aware\nnavigation by introducing an uncertainty-aware predictor to model the\nenvironmental uncertainty, and we propose a novel uncertainty-aware navigation\nnetwork to learn resilient behaviors in the prior unknown environments. To\ntrain the proposed uncertainty-aware network more stably and efficiently, we\npresent the temperature decay training paradigm, which balances exploration and\nexploitation during the training process. Our experimental evaluation\ndemonstrates that our approach can learn resilient behaviors in diverse\nenvironments and generate adaptive trajectories according to environmental\nuncertainties.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 14:15:20 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 08:58:23 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 07:15:15 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Fan", "Tingxiang", ""], ["Long", "Pinxin", ""], ["Liu", "Wenxi", ""], ["Pan", "Jia", ""], ["Yang", "Ruigang", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1910.10013", "submitter": "Zheng-Hua Tan", "authors": "Saeid Samizade, Zheng-Hua Tan, Chao Shen and Xiaohong Guan", "title": "Adversarial Example Detection by Classification for Deep Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning systems are vulnerable to adversarial attacks and will\nhighly likely produce incorrect outputs under these attacks. There are\nwhite-box and black-box attacks regarding to adversary's access level to the\nvictim learning algorithm. To defend the learning systems from these attacks,\nexisting methods in the speech domain focus on modifying input signals and\ntesting the behaviours of speech recognizers. We, however, formulate the\ndefense as a classification problem and present a strategy for systematically\ngenerating adversarial example datasets: one for white-box attacks and one for\nblack-box attacks, containing both adversarial and normal examples. The\nwhite-box attack is a gradient-based method on Baidu DeepSpeech with the\nMozilla Common Voice database while the black-box attack is a gradient-free\nmethod on a deep model-based keyword spotting system with the Google Speech\nCommand dataset. The generated datasets are used to train a proposed\nConvolutional Neural Network (CNN), together with cepstral features, to detect\nadversarial examples. Experimental results show that, it is possible to\naccurately distinct between adversarial and normal examples for known attacks,\nin both single-condition and multi-condition training settings, while the\nperformance degrades dramatically for unknown attacks. The adversarial datasets\nand the source code are made publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 14:46:00 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Samizade", "Saeid", ""], ["Tan", "Zheng-Hua", ""], ["Shen", "Chao", ""], ["Guan", "Xiaohong", ""]]}, {"id": "1910.10024", "submitter": "Michael Patrick Sheehan", "authors": "Michael P. Sheehan, Antoine Gonon, Mike E. Davies", "title": "Compressive Learning for Semi-Parametric Models", "comments": "5 pages, 5 figure, submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the compressive learning theory, instead of solving a statistical learning\nproblem from the input data, a so-called sketch is computed from the data prior\nto learning. The sketch has to capture enough information to solve the problem\ndirectly from it, allowing to discard the dataset from the memory. This is\nuseful when dealing with large datasets as the size of the sketch does not\nscale with the size of the database. In this paper, we reformulate the original\ncompressive learning framework to explicitly cater for the class of\nsemi-parametric models. The reformulation takes account of the inherent\ntopology and structure of semi-parametric models, creating an intuitive pathway\nto the development of compressive learning algorithms. We apply our developed\nframework to both the semi-parametric models of independent component analysis\nand subspace clustering, demonstrating the robustness of the framework to\nexplicitly show when a compression in complexity can be achieved.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:00:29 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Sheehan", "Michael P.", ""], ["Gonon", "Antoine", ""], ["Davies", "Mike E.", ""]]}, {"id": "1910.10027", "submitter": "Waqas Sultani", "authors": "Waqas Sultani and Mubarak Shah", "title": "Human Action Recognition in Drone Videos using a Few Aerial Training\n  Examples", "comments": "CVIU, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drones are enabling new forms of human actions surveillance due to their low\ncost and fast mobility. However, using deep neural networks for automatic\naerial action recognition is difficult due to the need for a large number of\ntraining aerial human action videos. Collecting a large number of human action\naerial videos is costly, time-consuming, and difficult. In this paper, we\nexplore two alternative data sources to improve aerial action classification\nwhen only a few training aerial examples are available. As a first data source,\nwe resort to video games. We collect plenty of aerial game action videos using\ntwo gaming engines. For the second data source, we leverage conditional\nWasserstein Generative Adversarial Networks to generate aerial features from\nground videos. Given that both data sources have some limitations, e.g. game\nvideos are biased towards specific actions categories (fighting, shooting,\netc.,), and it is not easy to generate good discriminative GAN-generated\nfeatures for all types of actions, we need to efficiently integrate two dataset\nsources with few available real aerial training videos. To address this\nchallenge of the heterogeneous nature of the data, we propose to use a disjoint\nmultitask learning framework. We feed the network with real and game, or real\nand GAN-generated data in an alternating fashion to obtain an improved action\nclassifier. We validate the proposed approach on two aerial action datasets and\ndemonstrate that features from aerial game videos and those generated from GAN\ncan be extremely useful for an improved action recognition in real aerial\nvideos when only a few real aerial training examples are available.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:02:36 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 08:35:04 GMT"}, {"version": "v3", "created": "Sat, 12 Sep 2020 19:44:21 GMT"}, {"version": "v4", "created": "Fri, 2 Apr 2021 12:33:37 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Sultani", "Waqas", ""], ["Shah", "Mubarak", ""]]}, {"id": "1910.10045", "submitter": "Javier Del Ser Dr.", "authors": "Alejandro Barredo Arrieta, Natalia D\\'iaz-Rodr\\'iguez, Javier Del Ser,\n  Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garc\\'ia, Sergio\n  Gil-L\\'opez, Daniel Molina, Richard Benjamins, Raja Chatila, Francisco\n  Herrera", "title": "Explainable Artificial Intelligence (XAI): Concepts, Taxonomies,\n  Opportunities and Challenges toward Responsible AI", "comments": "67 pages, 13 figures, accepted for its publication in Information\n  Fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, Artificial Intelligence (AI) has achieved a notable\nmomentum that may deliver the best of expectations over many application\nsectors across the field. For this to occur, the entire community stands in\nfront of the barrier of explainability, an inherent problem of AI techniques\nbrought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not\npresent in the last hype of AI. Paradigms underlying this problem fall within\nthe so-called eXplainable AI (XAI) field, which is acknowledged as a crucial\nfeature for the practical deployment of AI models. This overview examines the\nexisting literature in the field of XAI, including a prospect toward what is\nyet to be reached. We summarize previous efforts to define explainability in\nMachine Learning, establishing a novel definition that covers prior conceptual\npropositions with a major focus on the audience for which explainability is\nsought. We then propose and discuss about a taxonomy of recent contributions\nrelated to the explainability of different Machine Learning models, including\nthose aimed at Deep Learning methods for which a second taxonomy is built. This\nliterature analysis serves as the background for a series of challenges faced\nby XAI, such as the crossroads between data fusion and explainability. Our\nprospects lead toward the concept of Responsible Artificial Intelligence,\nnamely, a methodology for the large-scale implementation of AI methods in real\norganizations with fairness, model explainability and accountability at its\ncore. Our ultimate goal is to provide newcomers to XAI with a reference\nmaterial in order to stimulate future research advances, but also to encourage\nexperts and professionals from other disciplines to embrace the benefits of AI\nin their activity sectors, without any prior bias for its lack of\ninterpretability.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:27:30 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 08:09:25 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Arrieta", "Alejandro Barredo", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Del Ser", "Javier", ""], ["Bennetot", "Adrien", ""], ["Tabik", "Siham", ""], ["Barbado", "Alberto", ""], ["Garc\u00eda", "Salvador", ""], ["Gil-L\u00f3pez", "Sergio", ""], ["Molina", "Daniel", ""], ["Benjamins", "Richard", ""], ["Chatila", "Raja", ""], ["Herrera", "Francisco", ""]]}, {"id": "1910.10046", "submitter": "Vanessa B\\\"ohm", "authors": "Vanessa B\\\"ohm, Fran\\c{c}ois Lanusse, Uro\\v{s} Seljak", "title": "Uncertainty Quantification with Generative Models", "comments": "accepted submission to the Bayesian Deep Learning NeurIPS 2019\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML astro-ph.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a generative model-based approach to Bayesian inverse problems,\nsuch as image reconstruction from noisy and incomplete images. Our framework\naddresses two common challenges of Bayesian reconstructions: 1) It makes use of\ncomplex, data-driven priors that comprise all available information about the\nuncorrupted data distribution. 2) It enables computationally tractable\nuncertainty quantification in the form of posterior analysis in latent and data\nspace. The method is very efficient in that the generative model only has to be\ntrained once on an uncorrupted data set, after that, the procedure can be used\nfor arbitrary corruption types.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:27:41 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["B\u00f6hm", "Vanessa", ""], ["Lanusse", "Fran\u00e7ois", ""], ["Seljak", "Uro\u0161", ""]]}, {"id": "1910.10053", "submitter": "Anurag Ranjan", "authors": "Anurag Ranjan and Joel Janai and Andreas Geiger and Michael J. Black", "title": "Attacking Optical Flow", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural nets achieve state-of-the-art performance on the problem of\noptical flow estimation. Since optical flow is used in several safety-critical\napplications like self-driving cars, it is important to gain insights into the\nrobustness of those techniques. Recently, it has been shown that adversarial\nattacks easily fool deep neural networks to misclassify objects. The robustness\nof optical flow networks to adversarial attacks, however, has not been studied\nso far. In this paper, we extend adversarial patch attacks to optical flow\nnetworks and show that such attacks can compromise their performance. We show\nthat corrupting a small patch of less than 1% of the image size can\nsignificantly affect optical flow estimates. Our attacks lead to noisy flow\nestimates that extend significantly beyond the region of the attack, in many\ncases even completely erasing the motion of objects in the scene. While\nnetworks using an encoder-decoder architecture are very sensitive to these\nattacks, we found that networks using a spatial pyramid architecture are less\naffected. We analyse the success and failure of attacking both architectures by\nvisualizing their feature maps and comparing them to classical optical flow\ntechniques which are robust to these attacks. We also demonstrate that such\nattacks are practical by placing a printed pattern into real scenes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:47:56 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Ranjan", "Anurag", ""], ["Janai", "Joel", ""], ["Geiger", "Andreas", ""], ["Black", "Michael J.", ""]]}, {"id": "1910.10067", "submitter": "Jack Kenney B.S.", "authors": "Jack Kenney, John Valcore, Scott Riggs, Edward Rietman", "title": "Deep Learning Regression of VLSI Plasma Etch Metrology", "comments": "13 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer chip manufacturing, the study of etch patterns on silicon wafers,\nor metrology, occurs on the nano-scale and is therefore subject to large\nvariation from small, yet significant, perturbations in the manufacturing\nenvironment. An enormous amount of information can be gathered from a single\netch process, a sequence of actions taken to produce an etched wafer from a\nblank piece of silicon. Each final wafer, however, is costly to take\nmeasurements from, which limits the number of examples available to train a\npredictive model. Part of the significance of this work is the success we saw\nfrom the models despite the limited number of examples. In order to accommodate\nthe high dimensional process signatures, we isolated important sensor variables\nand applied domain-specific summarization on the data using multiple feature\nengineering techniques. We used a neural network architecture consisting of the\nsummarized inputs, a single hidden layer of 4032 units, and an output layer of\none unit. Two different models were learned, corresponding to the metrology\nmeasurements in the dataset, Recess and Remaining Mask. The outputs are related\nabstractly and do not form a two dimensional space, thus two separate models\nwere learned. Our results approach the error tolerance of the microscopic\nimaging system. The model can make predictions for a class of etch recipes that\ninclude the correct number of etch steps and plasma reactors with the\nappropriate sensors, which are chambers containing an ionized gas that\ndetermine the manufacture environment. Notably, this method is not restricted\nto some maximum process length due to the summarization techniques used. This\nallows the method to be adapted to new processes that satisfy the\naforementioned requirements. In order to automate semiconductor manufacturing,\nmodels like these will be needed throughout the process to evaluate production\nquality.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 14:10:37 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Kenney", "Jack", ""], ["Valcore", "John", ""], ["Riggs", "Scott", ""], ["Rietman", "Edward", ""]]}, {"id": "1910.10071", "submitter": "Joaquin Perez-Lapillo", "authors": "Joaquin Perez-Lapillo, Oleksandr Galkin, Tillman Weyde", "title": "Improving singing voice separation with the Wave-U-Net using Minimum\n  Hyperspherical Energy", "comments": "Paper submitted to ICASSP 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, deep learning has surpassed traditional approaches to the\nproblem of singing voice separation. The Wave-U-Net is a recent deep network\narchitecture that operates directly on the time domain. The standard Wave-U-Net\nis trained with data augmentation and early stopping to prevent overfitting.\nMinimum hyperspherical energy (MHE) regularization has recently proven to\nincrease generalization in image classification problems by encouraging a\ndiversified filter configuration. In this work, we apply MHE regularization to\nthe 1D filters of the Wave-U-Net. We evaluated this approach for separating the\nvocal part from mixed music audio recordings on the MUSDB18 dataset. We found\nthat adding MHE regularization to the loss function consistently improves\nsinging voice separation, as measured in the Signal to Distortion Ratio on test\nrecordings, leading to the current best time-domain system for singing voice\nextraction.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:14:25 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Perez-Lapillo", "Joaquin", ""], ["Galkin", "Oleksandr", ""], ["Weyde", "Tillman", ""]]}, {"id": "1910.10073", "submitter": "Maha Elbayad", "authors": "Maha Elbayad and Jiatao Gu and Edouard Grave and Michael Auli", "title": "Depth-Adaptive Transformer", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art sequence-to-sequence models for large scale tasks perform a\nfixed number of computations for each input sequence regardless of whether it\nis easy or hard to process. In this paper, we train Transformer models which\ncan make output predictions at different stages of the network and we\ninvestigate different ways to predict how much computation is required for a\nparticular sequence. Unlike dynamic computation in Universal Transformers,\nwhich applies the same set of layers iteratively, we apply different layers at\nevery step to adjust both the amount of computation as well as the model\ncapacity. On IWSLT German-English translation our approach matches the accuracy\nof a well tuned baseline Transformer while using less than a quarter of the\ndecoder layers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:15:58 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 18:32:39 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 17:26:49 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 20:49:40 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Elbayad", "Maha", ""], ["Gu", "Jiatao", ""], ["Grave", "Edouard", ""], ["Auli", "Michael", ""]]}, {"id": "1910.10075", "submitter": "Xuan Guo", "authors": "Yiren Zhao, Xitong Gao, Xuan Guo, Junyi Liu, Erwei Wang, Robert\n  Mullins, Peter Y. K. Cheung, George Constantinides, Cheng-Zhong Xu", "title": "Automatic Generation of Multi-precision Multi-arithmetic CNN\n  Accelerators for FPGAs", "comments": "To be published in International Conference on Field Programmable\n  Technology 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep Convolutional Neural Networks (CNNs) are computationally\ndemanding, yet real applications often require high throughput and low latency.\nTo help tackle these problems, we propose Tomato, a framework designed to\nautomate the process of generating efficient CNN accelerators. The generated\ndesign is pipelined and each convolution layer uses different arithmetics at\nvarious precisions. Using Tomato, we showcase state-of-the-art multi-precision\nmulti-arithmetic networks, including MobileNet-V1, running on FPGAs. To our\nknowledge, this is the first multi-precision multi-arithmetic auto-generation\nframework for CNNs. In software, Tomato fine-tunes pretrained networks to use a\nmixture of short powers-of-2 and fixed-point weights with a minimal loss in\nclassification accuracy. The fine-tuned parameters are combined with the\ntemplated hardware designs to automatically produce efficient inference\ncircuits in FPGAs. We demonstrate how our approach significantly reduces model\nsizes and computation complexities, and permits us to pack a complete ImageNet\nnetwork onto a single FPGA without accessing off-chip memories for the first\ntime. Furthermore, we show how Tomato produces implementations of networks with\nvarious sizes running on single or multiple FPGAs. To the best of our\nknowledge, our automatically generated accelerators outperform closest\nFPGA-based competitors by at least 2-4x for lantency and throughput; the\ngenerated accelerator runs ImageNet classification at a rate of more than 3000\nframes per second.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:39:06 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Zhao", "Yiren", ""], ["Gao", "Xitong", ""], ["Guo", "Xuan", ""], ["Liu", "Junyi", ""], ["Wang", "Erwei", ""], ["Mullins", "Robert", ""], ["Cheung", "Peter Y. K.", ""], ["Constantinides", "George", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "1910.10076", "submitter": "Mastaneh Torkamani-Azar", "authors": "Mastaneh Torkamani-Azar, Sumeyra Demir Kanik, Serap Aydin, and Mujdat\n  Cetin", "title": "Prediction of Reaction Time and Vigilance Variability from\n  Spatiospectral Features of Resting-State EEG in a Long Sustained Attention\n  Task", "comments": "11 pages, 6 figures; submitted to the Journal of Biomedical and\n  Health Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resting-state brain networks represent the intrinsic state of the brain\nduring the majority of cognitive and sensorimotor tasks. However, no study has\nyet presented concise predictors of task-induced vigilance variability from\nspectrospatial features of the pre-task, resting-state electroencephalograms\n(EEG). We asked ten healthy volunteers (6 females, 4 males) to participate in\n105-minute fixed-sequence-varying-duration sessions of sustained attention to\nresponse task (SART). A novel and adaptive vigilance scoring scheme was\ndesigned based on the performance and response time in consecutive trials, and\ndemonstrated large inter-participant variability in terms of maintaining\nconsistent tonic performance. Multiple linear regression using feature\nrelevance analysis obtained significant predictors of the mean cumulative\nvigilance score (CVS), mean response time, and variabilities of these scores\nfrom the resting-state, band-power ratios of EEG signals, p<0.05. Single-layer\nneural networks trained with cross-validation also captured different\nassociations for the beta sub-bands. Increase in the gamma (28-48 Hz) and upper\nbeta ratios from the left central and temporal regions predicted slower\nreactions and more inconsistent vigilance as explained by the increased\nactivation of default mode network (DMN) and differences between the high- and\nlow-attention networks at temporal regions. Higher ratios of parietal alpha\nfrom the Brodmann's areas 18, 19, and 37 during the eyes-open states predicted\nslower responses but more consistent CVS and reactions associated with the\nsuperior ability in vigilance maintenance. The proposed framework and these\nfindings on the most stable and significant attention predictors from the\nintrinsic EEG power ratios can be used to model attention variations during the\ncalibration sessions of BCI applications and vigilance monitoring systems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:41:31 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Torkamani-Azar", "Mastaneh", ""], ["Kanik", "Sumeyra Demir", ""], ["Aydin", "Serap", ""], ["Cetin", "Mujdat", ""]]}, {"id": "1910.10077", "submitter": "Danny Smyl", "authors": "Danny Smyl and Dong Liu", "title": "Optimizing electrode positions in 2D Electrical Impedance Tomography\n  using deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrical Impedance Tomography (EIT) is a powerful tool for non-destructive\nevaluation, state estimation, and process tomography - among numerous other use\ncases. For these applications, and in order to reliably reconstruct images of a\ngiven process using EIT, we must obtain high-quality voltage measurements from\nthe target of interest. As such, it is obvious that the locations of electrodes\nused for measuring plays a key role in this task. Yet, to date, methods for\noptimally placing electrodes either require knowledge on the EIT target (which\nis, in practice, never fully known) or are computationally difficult to\nimplement numerically. In this paper, we circumvent these challenges and\npresent a straightforward deep learning based approach for optimizing\nelectrodes positions. It is found that the optimized electrode positions\noutperformed \"standard\" uniformly-distributed electrode layouts in all test\ncases. Further, it is found that the use of optimized electrode positions\ncomputed using the approach derived herein can reduce errors in EIT\nreconstructions as well as improve the distinguishability of EIT measurements.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 09:23:52 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 10:54:45 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Smyl", "Danny", ""], ["Liu", "Dong", ""]]}, {"id": "1910.10080", "submitter": "Sanjukta Krishnagopal", "authors": "Sanjukta Krishnagopal, Michelle Girvan, Edward Ott, Brian Hunt", "title": "Separation of Chaotic Signals by Reservoir Computing", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": "10.1063/1.5132766", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the utility of machine learning in the separation of\nsuperimposed chaotic signals using a technique called Reservoir Computing. We\nassume no knowledge of the dynamical equations that produce the signals, and\nrequire only training data consisting of finite time samples of the component\nsignals. We test our method on signals that are formed as linear combinations\nof signals from two Lorenz systems with different parameters. Comparing our\nnonlinear method with the optimal linear solution to the separation problem,\nthe Wiener filter, we find that our method significantly outperforms the Wiener\nfilter in all the scenarios we study. Furthermore, this difference is\nparticularly striking when the component signals have similar frequency\nspectra. Indeed, our method works well when the component frequency spectra are\nindistinguishable - a case where a Wiener filter performs essentially no\nseparation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 02:21:31 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 17:03:49 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Krishnagopal", "Sanjukta", ""], ["Girvan", "Michelle", ""], ["Ott", "Edward", ""], ["Hunt", "Brian", ""]]}, {"id": "1910.10086", "submitter": "Yujie Lin", "authors": "Yujie Lin, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Dongxiao Yu, Jun\n  Ma, Maarten de Rijke, Xiuzhen Cheng", "title": "Meta Matrix Factorization for Federated Rating Predictions", "comments": "The code has been transferred to https://github.com/TempSDU/MetaMF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated recommender systems have distinct advantages in terms of privacy\nprotection over traditional recommender systems that are centralized at a data\ncenter. However, previous work on federated recommender systems does not fully\nconsider the limitations of storage, RAM, energy and communication bandwidth in\na mobile environment. The scales of the models proposed are too large to be\neasily run on mobile devices. And existing federated recommender systems need\nto fine-tune recommendation models on each device, making it hard to\neffectively exploit collaborative filtering information among users/devices.\nOur goal in this paper is to design a novel federated learning framework for\nrating prediction (RP) for mobile environments. We introduce a federated matrix\nfactorization (MF) framework, named meta matrix factorization (MetaMF). Given a\nuser, we first obtain a collaborative vector by collecting useful information\nwith a collaborative memory module. Then, we employ a meta recommender module\nto generate private item embeddings and a RP model based on the collaborative\nvector in the server. To address the challenge of generating a large number of\nhigh-dimensional item embeddings, we devise a rise-dimensional generation\nstrategy that first generates a low-dimensional item embedding matrix and a\nrise-dimensional matrix, and then multiply them to obtain high-dimensional\nembeddings. We use the generated model to produce private RPs for the given\nuser on her device. MetaMF shows a high capacity even with a small RP model,\nwhich can adapt to the limitations of a mobile environment. We conduct\nextensive experiments on four benchmark datasets to compare MetaMF with\nexisting MF methods and find that MetaMF can achieve competitive performance.\nMoreover, we find MetaMF achieves higher RP performance over existing federated\nmethods by better exploiting collaborative filtering among users/devices.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:29:51 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 16:39:37 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 08:12:11 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Lin", "Yujie", ""], ["Ren", "Pengjie", ""], ["Chen", "Zhumin", ""], ["Ren", "Zhaochun", ""], ["Yu", "Dongxiao", ""], ["Ma", "Jun", ""], ["de Rijke", "Maarten", ""], ["Cheng", "Xiuzhen", ""]]}, {"id": "1910.10087", "submitter": "Pablo Moreno-Mu\\~noz", "authors": "Pablo Moreno-Mu\\~noz, David Ram\\'irez and Antonio Art\\'es-Rodr\\'iguez", "title": "Continual Learning for Infinite Hierarchical Change-Point Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Change-point detection (CPD) aims to locate abrupt transitions in the\ngenerative model of a sequence of observations. When Bayesian methods are\nconsidered, the standard practice is to infer the posterior distribution of the\nchange-point locations. However, for complex models (high-dimensional or\nheterogeneous), it is not possible to perform reliable detection. To circumvent\nthis problem, we propose to use a hierarchical model, which yields observations\nthat belong to a lower-dimensional manifold. Concretely, we consider a\nlatent-class model with an unbounded number of categories, which is based on\nthe chinese-restaurant process (CRP). For this model we derive a continual\nlearning mechanism that is based on the sequential construction of the CRP and\nthe expectation-maximization (EM) algorithm with a stochastic maximization\nstep. Our results show that the proposed method is able to recursively infer\nthe number of underlying latent classes and perform CPD in a reliable manner.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:30:14 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Moreno-Mu\u00f1oz", "Pablo", ""], ["Ram\u00edrez", "David", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""]]}, {"id": "1910.10095", "submitter": "Chao Pan", "authors": "Chao Pan, S. M. Hossein Tabatabaei Yazdi, S Kasra Tabatabaei, Alvaro\n  G. Hernandez, Charles Schroeder, Olgica Milenkovic", "title": "Image processing in DNA", "comments": "5 pages, revision of ICASSP version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The main obstacles for the practical deployment of DNA-based data storage\nplatforms are the prohibitively high cost of synthetic DNA and the large number\nof errors introduced during synthesis. In particular, synthetic DNA products\ncontain both individual oligo (fragment) symbol errors as well as missing DNA\noligo errors, with rates that exceed those of modern storage systems by orders\nof magnitude. These errors can be corrected either through the use of a large\nnumber of redundant oligos or through cycles of writing, reading, and rewriting\nof information that eliminate the errors. Both approaches add to the overall\nstorage cost and are hence undesirable. Here we propose the first method for\nstoring quantized images in DNA that uses signal processing and machine\nlearning techniques to deal with error and cost issues without resorting to the\nuse of redundant oligos or rewriting. Our methods rely on decoupling the RGB\nchannels of images, performing specialized quantization and compression on the\nindividual color channels, and using new discoloration detection and image\ninpainting techniques. We demonstrate the performance of our approach\nexperimentally on a collection of movie posters stored in DNA.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:34:04 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 00:50:20 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Pan", "Chao", ""], ["Yazdi", "S. M. Hossein Tabatabaei", ""], ["Tabatabaei", "S Kasra", ""], ["Hernandez", "Alvaro G.", ""], ["Schroeder", "Charles", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1910.10105", "submitter": "Marco A. Mart\\'inez Ram\\'irez", "authors": "Marco A. Mart\\'inez Ram\\'irez, Emmanouil Benetos, Joshua D. Reiss", "title": "Modeling plate and spring reverberation using a DSP-informed deep neural\n  network", "comments": "Presented at the IEEE International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP), Barcelona, Spain, May 2020. Source code,\n  dataset, audio examples and more detailed diagrams:\n  https://mchijmma.github.io/modeling-plate-spring-reverb/", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053093", "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plate and spring reverberators are electromechanical systems first used and\nresearched as means to substitute real room reverberation. Nowadays they are\noften used in music production for aesthetic reasons due to their particular\nsonic characteristics. The modeling of these audio processors and their\nperceptual qualities is difficult since they use mechanical elements together\nwith analog electronics resulting in an extremely complex response. Based on\ndigital reverberators that use sparse FIR filters, we propose a signal\nprocessing-informed deep learning architecture for the modeling of artificial\nreverberators. We explore the capabilities of deep neural networks to learn\nsuch highly nonlinear electromechanical responses and we perform modeling of\nplate and spring reverberators. In order to measure the performance of the\nmodel, we conduct a perceptual evaluation experiment and we also analyze how\nthe given task is accomplished and what the model is actually learning.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:45:38 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 13:12:46 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Ram\u00edrez", "Marco A. Mart\u00ednez", ""], ["Benetos", "Emmanouil", ""], ["Reiss", "Joshua D.", ""]]}, {"id": "1910.10106", "submitter": "Alessandro Lameiras Koerich", "authors": "Karl Michel Koerich, Mohammad Esmaeilpour, Sajjad Abdoli, Alceu de\n  Souza Britto Jr., Alessandro Lameiras Koerich", "title": "Cross-Representation Transferability of Adversarial Attacks: From\n  Spectrograms to Audio Waveforms", "comments": "8 pages", "journal-ref": "IEEE International Joint Conference on Neural Networks (IJCNN\n  2020), Glasgow, UK", "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows the susceptibility of spectrogram-based audio classifiers to\nadversarial attacks and the transferability of such attacks to audio waveforms.\nSome commonly used adversarial attacks to images have been applied to\nMel-frequency and short-time Fourier transform spectrograms, and such perturbed\nspectrograms are able to fool a 2D convolutional neural network (CNN). Such\nattacks produce perturbed spectrograms that are visually imperceptible by\nhumans. Furthermore, the audio waveforms reconstructed from the perturbed\nspectrograms are also able to fool a 1D CNN trained on the original audio.\nExperimental results on a dataset of western music have shown that the 2D CNN\nachieves up to 81.87% of mean accuracy on legitimate examples and such\nperformance drops to 12.09% on adversarial examples. Likewise, the 1D CNN\nachieves up to 78.29% of mean accuracy on original audio samples and such\nperformance drops to 27.91% on adversarial audio waveforms reconstructed from\nthe perturbed spectrograms.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:46:37 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 21:18:07 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 16:38:44 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2020 11:16:58 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Koerich", "Karl Michel", ""], ["Esmaeilpour", "Mohammad", ""], ["Abdoli", "Sajjad", ""], ["Britto", "Alceu de Souza", "Jr."], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "1910.10109", "submitter": "Mhadi Shamsi", "authors": "Mahdi Shamsi, Alireza Moslemi Haghighi, Farokh Marvasti", "title": "Distributed interference cancellation in multi-agent scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.RO cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of detecting impaired and noisy nodes over\nnetwork. In a distributed algorithm, lots of processing units are incorporating\nand communicating with each other to reach a global goal. Due to each one's\nstate in the shared environment, they can help the other nodes or mislead them\n(due to noise or a deliberate attempt). Previous works mainly focused on proper\nlocating agents and weight assignment based on initial environment state to\nminimize malfunctioning of noisy nodes. We propose an algorithm to be able to\nadapt sharing weights according to behavior of the agents. Applying the\nintroduced algorithm to a multi-agent RL scenario and the well-known diffusion\nLMS demonstrates its capability and generality.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:53:28 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Shamsi", "Mahdi", ""], ["Haghighi", "Alireza Moslemi", ""], ["Marvasti", "Farokh", ""]]}, {"id": "1910.10114", "submitter": "Eda Bayram", "authors": "Eda Bayram, Dorina Thanou, Elif Vural and Pascal Frossard", "title": "Mask Combination of Multi-layer Graphs for Global Structure Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structure inference is an important task for network data processing and\nanalysis in data science. In recent years, quite a few approaches have been\ndeveloped to learn the graph structure underlying a set of observations\ncaptured in a data space. Although real-world data is often acquired in\nsettings where relationships are influenced by a priori known rules, such\ndomain knowledge is still not well exploited in structure inference problems.\nIn this paper, we identify the structure of signals defined in a data space\nwhose inner relationships are encoded by multi-layer graphs. We aim at properly\nexploiting the information originating from each layer to infer the global\nstructure underlying the signals. We thus present a novel method for combining\nthe multiple graphs into a global graph using mask matrices, which are\nestimated through an optimization problem that accommodates the multi-layer\ngraph information and a signal representation model. The proposed mask\ncombination method also estimates the contribution of each graph layer in the\nstructure of signals. The experiments conducted both on synthetic and\nreal-world data suggest that integrating the multi-layer graph representation\nof the data in the structure inference framework enhances the learning\nprocedure considerably by adapting to the quality and the quantity of the input\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:59:26 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 08:59:28 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Bayram", "Eda", ""], ["Thanou", "Dorina", ""], ["Vural", "Elif", ""], ["Frossard", "Pascal", ""]]}, {"id": "1910.10122", "submitter": "Eugene Wong", "authors": "Eugene Wong", "title": "Class Mean Vectors, Self Monitoring and Self Learning for Neural\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the role of sample mean in building a neural network\nfor classification. This role is surprisingly extensive and includes: direct\ncomputation of weights without training, performance monitoring for samples\nwithout known classification, and self-training for unlabeled data.\nExperimental computation on a CIFAR-10 data set provides promising empirical\nevidence on the efficacy of a simple and widely applicable approach to some\ndifficult problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 17:13:45 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Wong", "Eugene", ""]]}, {"id": "1910.10143", "submitter": "Alexandra Luccioni", "authors": "Sharon Zhou, Alexandra Luccioni, Gautier Cosne, Michael S. Bernstein,\n  Yoshua Bengio", "title": "Establishing an Evaluation Metric to Quantify Climate Change Image\n  Realism", "comments": "Accepted to the NeurIPS 2019 Workshop, Tackling Climate Change with\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With success on controlled tasks, generative models are being increasingly\napplied to humanitarian applications [1,2]. In this paper, we focus on the\nevaluation of a conditional generative model that illustrates the consequences\nof climate change-induced flooding to encourage public interest and awareness\non the issue. Because metrics for comparing the realism of different modes in a\nconditional generative model do not exist, we propose several automated and\nhuman-based methods for evaluation. To do this, we adapt several existing\nmetrics, and assess the automated metrics against gold standard human\nevaluation. We find that using Fr\\'echet Inception Distance (FID) with\nembeddings from an intermediary Inception-V3 layer that precedes the auxiliary\nclassifier produces results most correlated with human realism. While\ninsufficient alone to establish a human-correlated automatic evaluation metric,\nwe believe this work begins to bridge the gap between human and automated\ngenerative evaluation procedures.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 17:59:38 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Zhou", "Sharon", ""], ["Luccioni", "Alexandra", ""], ["Cosne", "Gautier", ""], ["Bernstein", "Michael S.", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1910.10147", "submitter": "Hong Qin", "authors": "Hong Qin", "title": "Machine learning and serving of discrete field theories -- when\n  artificial intelligence meets the discrete universe", "comments": "25 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG hep-lat", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for machine learning and serving of discrete field theories in\nphysics is developed. The learning algorithm trains a discrete field theory\nfrom a set of observational data on a spacetime lattice, and the serving\nalgorithm uses the learned discrete field theory to predict new observations of\nthe field for new boundary and initial conditions. The approach to learn\ndiscrete field theories overcomes the difficulties associated with learning\ncontinuous theories by artificial intelligence. The serving algorithm of\ndiscrete field theories belongs to the family of structure-preserving geometric\nalgorithms, which have been proven to be superior to the conventional\nalgorithms based on discretization of differential equations. The effectiveness\nof the method and algorithms developed is demonstrated using the examples of\nnonlinear oscillations and the Kepler problem. In particular, the learning\nalgorithm learns a discrete field theory from a set of data of planetary orbits\nsimilar to what Kepler inherited from Tycho Brahe in 1601, and the serving\nalgorithm correctly predicts other planetary orbits, including parabolic and\nhyperbolic escaping orbits, of the solar system without learning or knowing\nNewton's laws of motion and universal gravitation. The proposed algorithms are\nalso applicable when effects of special relativity and general relativity are\nimportant. The illustrated advantages of discrete field theories relative to\ncontinuous theories in terms of machine learning compatibility are consistent\nwith Bostrom's simulation hypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 14:46:46 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 05:05:45 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Qin", "Hong", ""]]}, {"id": "1910.10174", "submitter": "Ciar\\'an M. Gilligan-Lee", "authors": "Ciar\\'an M. Lee, Christopher Hart, Jonathan G. Richens, Saurabh Johri", "title": "Leveraging directed causal discovery to detect latent common causes", "comments": "Presented at Frontiers of AI-Assisted Care 2019 (Scientific\n  Symposium, Stanford Medicine). 13 pages, 5 figures, 4 tables. Comments\n  welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of causal relationships is a fundamental problem in science and\nmedicine. In recent years, many elegant approaches to discovering causal\nrelationships between two variables from observational data have been proposed.\nHowever, most of these deal only with purely directed causal relationships and\ncannot detect latent common causes. Here, we devise a general heuristic which\ntakes a causal discovery algorithm that can only distinguish purely directed\ncausal relations and modifies it to also detect latent common causes. We apply\nour method to two directed causal discovery algorithms, the Information\nGeometric Causal Inference of (Daniusis et al., 2010) and the Kernel\nConditional Deviance for Causal Inference of (Mitrovic, Sejdinovic, & Teh,\n2018), and extensively test on synthetic data -- detecting latent common causes\nin additive, multiplicative and complex noise regimes -- and on real data,\nwhere we are able to detect known common causes. In addition to detecting\nlatent common causes, our experiments demonstrate that both the modified\nalgorithms preserve the performance of the original in distinguishing directed\ncausal relations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 18:00:57 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 13:06:19 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 12:23:41 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Lee", "Ciar\u00e1n M.", ""], ["Hart", "Christopher", ""], ["Richens", "Jonathan G.", ""], ["Johri", "Saurabh", ""]]}, {"id": "1910.10194", "submitter": "Kuangen Zhang", "authors": "Kuangen Zhang, Zhimin Hou, Clarence W. de Silva, Haoyong Yu, and\n  Chenglong Fu", "title": "Teach Biped Robots to Walk via Gait Principles and Reinforcement\n  Learning with Adversarial Critics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlling a biped robot to walk stably is a challenging task considering\nits nonlinearity and hybrid dynamics. Reinforcement learning can address these\nissues by directly mapping the observed states to optimal actions that maximize\nthe cumulative reward. However, the local minima caused by unsuitable rewards\nand the overestimation of the cumulative reward impede the maximization of the\ncumulative reward. To increase the cumulative reward, this paper designs a gait\nreward based on walking principles, which compensates the local minima for\nunnatural motions. Besides, an Adversarial Twin Delayed Deep Deterministic\n(ATD3) policy gradient algorithm with a recurrent neural network (RNN) is\nproposed to further boost the cumulative reward by mitigating the\noverestimation of the cumulative reward. Experimental results in the Roboschool\nWalker2d and Webots Atlas simulators indicate that the test rewards increase by\n23.50% and 9.63% after adding the gait reward. The test rewards further\nincrease by 15.96% and 12.68% after using the ATD3_RNN, and the reason may be\nthat the ATD3_RNN decreases the error of estimating cumulative reward from\n19.86% to 3.35%. Besides, the cosine kinetic similarity between the human and\nthe biped robot trained by the gait reward and ATD3_RNN increases by over\n69.23%. Consequently, the designed gait reward and ATD3_RNN boost the\ncumulative reward and teach biped robots to walk better.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 18:37:30 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Zhang", "Kuangen", ""], ["Hou", "Zhimin", ""], ["de Silva", "Clarence W.", ""], ["Yu", "Haoyong", ""], ["Fu", "Chenglong", ""]]}, {"id": "1910.10196", "submitter": "Zhenxun Zhuang", "authors": "Zhenxun Zhuang, Yunlong Wang, Kezi Yu, Songtao Lu", "title": "No-regret Non-convex Online Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The online meta-learning framework is designed for the continual lifelong\nlearning setting. It bridges two fields: meta-learning which tries to extract\nprior knowledge from past tasks for fast learning of future tasks, and\nonline-learning which deals with the sequential setting where problems are\nrevealed one by one. In this paper, we generalize the original framework from\nconvex to non-convex setting, and introduce the local regret as the alternative\nperformance measure. We then apply this framework to stochastic settings, and\nshow theoretically that it enjoys a logarithmic local regret, and is robust to\nany hyperparameter initialization. The empirical test on a real-world task\ndemonstrates its superiority compared with traditional methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 18:45:15 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 16:08:21 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 01:10:11 GMT"}, {"version": "v4", "created": "Wed, 19 Feb 2020 02:52:52 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhuang", "Zhenxun", ""], ["Wang", "Yunlong", ""], ["Yu", "Kezi", ""], ["Lu", "Songtao", ""]]}, {"id": "1910.10202", "submitter": "Muqiao Yang", "authors": "Muqiao Yang, Martin Q. Ma, Dongyu Li, Yao-Hung Hubert Tsai, Ruslan\n  Salakhutdinov", "title": "Complex Transformer: A Framework for Modeling Complex-Valued Sequence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has received a surge of interest in a variety of fields\nin recent years, major deep learning models barely use complex numbers.\nHowever, speech, signal and audio data are naturally complex-valued after\nFourier Transform, and studies have shown a potentially richer representation\nof complex nets. In this paper, we propose a Complex Transformer, which\nincorporates the transformer model as a backbone for sequence modeling; we also\ndevelop attention and encoder-decoder network operating for complex input. The\nmodel achieves state-of-the-art performance on the MusicNet dataset and an\nIn-phase Quadrature (IQ) signal dataset.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 19:21:12 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Yang", "Muqiao", ""], ["Ma", "Martin Q.", ""], ["Li", "Dongyu", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1910.10209", "submitter": "Amey Chaware", "authors": "Amey Chaware, Colin L. Cooke, Kanghyun Kim, Roarke Horstmeyer", "title": "Towards an Intelligent Microscope: adaptively learned illumination for\n  optimal sample classification", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent machine learning techniques have dramatically changed how we process\ndigital images. However, the way in which we capture images is still largely\ndriven by human intuition and experience. This restriction is in part due to\nthe many available degrees of freedom that alter the image acquisition process\n(lens focus, exposure, filtering, etc). Here we focus on one such degree of\nfreedom - illumination within a microscope - which can drastically alter\ninformation captured by the image sensor. We present a reinforcement learning\nsystem that adaptively explores optimal patterns to illuminate specimens for\nimmediate classification. The agent uses a recurrent latent space to encode a\nlarge set of variably-illuminated samples and illumination patterns. We train\nour agent using a reward that balances classification confidence with image\nacquisition cost. By synthesizing knowledge over multiple snapshots, the agent\ncan classify on the basis of all previous images with higher accuracy than from\nnaively illuminated images, thus demonstrating a smarter way to physically\ncapture task-specific information.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 19:49:06 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 22:26:55 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Chaware", "Amey", ""], ["Cooke", "Colin L.", ""], ["Kim", "Kanghyun", ""], ["Horstmeyer", "Roarke", ""]]}, {"id": "1910.10211", "submitter": "Amrith Setlur", "authors": "Amrith Setlur, Barnab\\'as P\\'ocz\\'os", "title": "Better Approximate Inference for Partial Likelihood Models with a Latent\n  Structure", "comments": null, "journal-ref": "NeurIPS 2019 Workshop on Learning with Temporal Point Processes", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Temporal Point Processes (TPP) with partial likelihoods involving a latent\nstructure often entail an intractable marginalization, thus making inference\nhard. We propose a novel approach to Maximum Likelihood Estimation (MLE)\ninvolving approximate inference over the latent variables by minimizing a tight\nupper bound on the approximation gap. Given a discrete latent variable $Z$, the\nproposed approximation reduces inference complexity from $O(|Z|^c)$ to\n$O(|Z|)$. We use convex conjugates to determine this upper bound in a closed\nform and show that its addition to the optimization objective results in\nimproved results for models assuming proportional hazards as in Survival\nAnalysis.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 19:54:11 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 07:59:10 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Setlur", "Amrith", ""], ["P\u00f3cz\u00f3s", "Barnab\u00e1s", ""]]}, {"id": "1910.10231", "submitter": "Sahar Voghoei", "authors": "Sahar Voghoei, Navid Hashemi Tonekaboni, Jason G. Wallace, Hamid R.\n  Arabnia", "title": "Deep Learning at the Edge", "comments": "7 Pages, 79 References, CSCI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing number of Internet of Things (IoT) devices has created a\nnew computing paradigm, called edge computing, where most of the computations\nare performed at the edge devices, rather than on centralized servers. An edge\ndevice is an electronic device that provides connections to service providers\nand other edge devices; typically, such devices have limited resources. Since\nedge devices are resource-constrained, the task of launching algorithms,\nmethods, and applications onto edge devices is considered to be a significant\nchallenge. In this paper, we discuss one of the most widely used machine\nlearning methods, namely, Deep Learning (DL) and offer a short survey on the\nrecent approaches used to map DL onto the edge computing paradigm. We also\nprovide relevant discussions about selected applications that would greatly\nbenefit from DL at the edge.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 21:08:09 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Voghoei", "Sahar", ""], ["Tonekaboni", "Navid Hashemi", ""], ["Wallace", "Jason G.", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "1910.10232", "submitter": "Luckeciano Melo", "authors": "Luckeciano C. Melo, Marcos R. O. A. Maximo, Adilson Marques da Cunha", "title": "Bottom-Up Meta-Policy Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite of the recent progress in agents that learn through interaction,\nthere are several challenges in terms of sample efficiency and generalization\nacross unseen behaviors during training. To mitigate these problems, we propose\nand apply a first-order Meta-Learning algorithm called Bottom-Up Meta-Policy\nSearch (BUMPS), which works with two-phase optimization procedure: firstly, in\na meta-training phase, it distills few expert policies to create a meta-policy\ncapable of generalizing knowledge to unseen tasks during training; secondly, it\napplies a fast adaptation strategy named Policy Filtering, which evaluates few\npolicies sampled from the meta-policy distribution and selects which best\nsolves the task. We conducted all experiments in the RoboCup 3D Soccer\nSimulation domain, in the context of kick motion learning. We show that, given\nour experimental setup, BUMPS works in scenarios where simple multi-task\nReinforcement Learning does not. Finally, we performed experiments in a way to\nevaluate each component of the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 21:12:54 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 11:41:39 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Melo", "Luckeciano C.", ""], ["Maximo", "Marcos R. O. A.", ""], ["da Cunha", "Adilson Marques", ""]]}, {"id": "1910.10238", "submitter": "Mattia Antonino Di Gangi", "authors": "Mattia Antonino Di Gangi and Robert Enyedi and Alessandra Brusadin and\n  Marcello Federico", "title": "Robust Neural Machine Translation for Clean and Noisy Speech Transcripts", "comments": "6 pages, accepted at IWSLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation models have shown to achieve high quality when\ntrained and fed with well structured and punctuated input texts. Unfortunately,\nthe latter condition is not met in spoken language translation, where the input\nis generated by an automatic speech recognition (ASR) system. In this paper, we\nstudy how to adapt a strong NMT system to make it robust to typical ASR errors.\nAs in our application scenarios transcripts might be post-edited by human\nexperts, we propose adaptation strategies to train a single system that can\ntranslate either clean or noisy input with no supervision on the input type.\nOur experimental results on a public speech translation data set show that\nadapting a model on a significant amount of parallel data including ASR\ntranscripts is beneficial with test data of the same type, but produces a small\ndegradation when translating clean text. Adapting on both clean and noisy\nvariants of the same data leads to the best results on both input types.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 21:24:24 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Di Gangi", "Mattia Antonino", ""], ["Enyedi", "Robert", ""], ["Brusadin", "Alessandra", ""], ["Federico", "Marcello", ""]]}, {"id": "1910.10245", "submitter": "Ryan Theisen", "authors": "Ryan Theisen, Jason M. Klusowski, Huan Wang, Nitish Shirish Keskar,\n  Caiming Xiong and Richard Socher", "title": "Global Capacity Measures for Deep ReLU Networks via Path Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical results on the statistical complexity of linear models have\ncommonly identified the norm of the weights $\\|w\\|$ as a fundamental capacity\nmeasure. Generalizations of this measure to the setting of deep networks have\nbeen varied, though a frequently identified quantity is the product of weight\nnorms of each layer. In this work, we show that for a large class of networks\npossessing a positive homogeneity property, similar bounds may be obtained\ninstead in terms of the norm of the product of weights. Our proof technique\ngeneralizes a recently proposed sampling argument, which allows us to\ndemonstrate the existence of sparse approximants of positive homogeneous\nnetworks. This yields covering number bounds, which can be converted to\ngeneralization bounds for multi-class classification that are comparable to,\nand in certain cases improve upon, existing results in the literature. Finally,\nwe investigate our sampling procedure empirically, which yields results\nconsistent with our theory.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 21:49:44 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Theisen", "Ryan", ""], ["Klusowski", "Jason M.", ""], ["Wang", "Huan", ""], ["Keskar", "Nitish Shirish", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1910.10246", "submitter": "Vincent Lostanlen", "authors": "Vincent Lostanlen, Sripathi Sridhar, Brian McFee, Andrew Farnsworth,\n  Juan Pablo Bello", "title": "Learning the helix topology of musical pitch", "comments": "5 pages, 6 figures. To appear in the Proceedings of the IEEE\n  International Conference on Acoustics, Speech, and Signal Processing\n  (ICASSP). Barcelona, Spain, May 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  To explain the consonance of octaves, music psychologists represent pitch as\na helix where azimuth and axial coordinate correspond to pitch class and pitch\nheight respectively. This article addresses the problem of discovering this\nhelical structure from unlabeled audio data. We measure Pearson correlations in\nthe constant-Q transform (CQT) domain to build a K-nearest neighbor graph\nbetween frequency subbands. Then, we run the Isomap manifold learning algorithm\nto represent this graph in a three-dimensional space in which straight lines\napproximate graph geodesics. Experiments on isolated musical notes demonstrate\nthat the resulting manifold resembles a helix which makes a full turn at every\noctave. A circular shape is also found in English speech, but not in urban\nnoise. We discuss the impact of various design choices on the visualization:\ninstrumentarium, loudness mapping function, and number of neighbors K.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 21:56:16 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 19:49:35 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Lostanlen", "Vincent", ""], ["Sridhar", "Sripathi", ""], ["McFee", "Brian", ""], ["Farnsworth", "Andrew", ""], ["Bello", "Juan Pablo", ""]]}, {"id": "1910.10252", "submitter": "Kangkang Wang", "authors": "Kangkang Wang, Rajiv Mathews, Chlo\\'e Kiddon, Hubert Eichner,\n  Fran\\c{c}oise Beaufays, Daniel Ramage", "title": "Federated Evaluation of On-device Personalization", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed, on-device computation framework that\nenables training global models without exporting sensitive user data to\nservers. In this work, we describe methods to extend the federation framework\nto evaluate strategies for personalization of global models. We present tools\nto analyze the effects of personalization and evaluate conditions under which\npersonalization yields desirable models. We report on our experiments\npersonalizing a language model for a virtual keyboard for smartphones with a\npopulation of tens of millions of users. We show that a significant fraction of\nusers benefit from personalization.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 22:16:15 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Wang", "Kangkang", ""], ["Mathews", "Rajiv", ""], ["Kiddon", "Chlo\u00e9", ""], ["Eichner", "Hubert", ""], ["Beaufays", "Fran\u00e7oise", ""], ["Ramage", "Daniel", ""]]}, {"id": "1910.10254", "submitter": "Ganesh Sivaraman", "authors": "Ganesh Sivaraman, Anand Narayanan Krishnamoorthy, Matthias Baur,\n  Christian Holm, Marius Stan, Gabor Cs\\'anyi, Chris Benmore, \\'Alvaro\n  V\\'azquez-Mayagoitia", "title": "Machine Learning Inter-Atomic Potentials Generation Driven by Active\n  Learning: A Case Study for Amorphous and Liquid Hafnium dioxide", "comments": "to be submitted NPJ Computational Materials", "journal-ref": "npj Computational Materials 6 (2020) 1-8", "doi": "10.1038/s41524-020-00367-7", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel active learning scheme for automatically sampling a\nminimum number of uncorrelated configurations for fitting the Gaussian\nApproximation Potential (GAP). Our active learning scheme consists of an\nunsupervised machine learning (ML) scheme coupled to Bayesian optimization\ntechnique that evaluates the GAP model. We apply this scheme to a Hafnium\ndioxide (HfO2) dataset generated from a melt-quench ab initio molecular\ndynamics (AIMD) protocol. Our results show that the active learning scheme,\nwith no prior knowledge of the dataset is able to extract a configuration that\nreaches the required energy fit tolerance. Further, molecular dynamics (MD)\nsimulations performed using this active learned GAP model on 6144-atom systems\nof amorphous and liquid state elucidate the structural properties of HfO2 with\nnear ab initio precision and quench rates (i.e. 1.0 K/ps) not accessible via\nAIMD. The melt and amorphous x-ray structural factors generated from our\nsimulation are in good agreement with experiment. Additionally, the calculated\ndiffusion constants are in good agreement with previous ab initio studies.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 22:18:25 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Sivaraman", "Ganesh", ""], ["Krishnamoorthy", "Anand Narayanan", ""], ["Baur", "Matthias", ""], ["Holm", "Christian", ""], ["Stan", "Marius", ""], ["Cs\u00e1nyi", "Gabor", ""], ["Benmore", "Chris", ""], ["V\u00e1zquez-Mayagoitia", "\u00c1lvaro", ""]]}, {"id": "1910.10255", "submitter": "Hanchen Wang", "authors": "Hanchen Wang, Nina Grgic-Hlaca, Preethi Lahoti, Krishna P. Gummadi,\n  Adrian Weller", "title": "An Empirical Study on Learning Fairness Metrics for COMPAS Data with\n  Human Supervision", "comments": "Accepted at NeurIPS 2019 HCML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The notion of individual fairness requires that similar people receive\nsimilar treatment. However, this is hard to achieve in practice since it is\ndifficult to specify the appropriate similarity metric. In this work, we\nattempt to learn such similarity metric from human annotated data. We gather a\nnew dataset of human judgments on a criminal recidivism prediction (COMPAS)\ntask. By assuming the human supervision obeys the principle of individual\nfairness, we leverage prior work on metric learning, evaluate the performance\nof several metric learning methods on our dataset, and show that the learned\nmetrics outperform the Euclidean and Precision metric under various criteria.\nWe do not provide a way to directly learn a similarity metric satisfying the\nindividual fairness, but to provide an empirical study on how to derive the\nsimilarity metric from human supervisors, then future work can use this as a\ntool to understand human supervision.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 22:22:59 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 14:47:27 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Wang", "Hanchen", ""], ["Grgic-Hlaca", "Nina", ""], ["Lahoti", "Preethi", ""], ["Gummadi", "Krishna P.", ""], ["Weller", "Adrian", ""]]}, {"id": "1910.10262", "submitter": "Ali Hasan", "authors": "Ali Hasan, Jo\\~ao M. Pereira, Robert Ravier, Sina Farsiu, Vahid Tarokh", "title": "Learning Partial Differential Equations from Data Using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for estimating unknown partial differential equations\nfrom noisy data, using a deep learning approach. Given noisy samples of a\nsolution to an unknown PDE, our method interpolates the samples using a neural\nnetwork, and extracts the PDE by equating derivatives of the neural network\napproximation. Our method applies to PDEs which are linear combinations of\nuser-defined dictionary functions, and generalizes previous methods that only\nconsider parabolic PDEs. We introduce a regularization scheme that prevents the\nfunction approximation from overfitting the data and forces it to be a solution\nof the underlying PDE. We validate the model on simulated data generated by the\nknown PDEs and added Gaussian noise, and we study our method under different\nlevels of noise. We also compare the error of our method with a Cramer-Rao\nlower bound for an ordinary differential equation. Our results indicate that\nour method outperforms other methods in estimating PDEs, especially in the low\nsignal-to-noise regime.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 22:38:50 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Hasan", "Ali", ""], ["Pereira", "Jo\u00e3o M.", ""], ["Ravier", "Robert", ""], ["Farsiu", "Sina", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1910.10266", "submitter": "Uchenna Akujuobi", "authors": "Uchenna Akujuobi, Qiannan Zhang, Han Yufei, Xiangliang Zhang", "title": "Recurrent Attention Walk for Semi-supervised Classification", "comments": "Accepted for WSDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the graph-based semi-supervised learning for\nclassifying nodes in attributed networks, where the nodes and edges possess\ncontent information. Recent approaches like graph convolution networks and\nattention mechanisms have been proposed to ensemble the first-order neighbors\nand incorporate the relevant neighbors. However, it is costly (especially in\nmemory) to consider all neighbors without a prior differentiation. We propose\nto explore the neighborhood in a reinforcement learning setting and find a walk\npath well-tuned for classifying the unlabelled target nodes. We let an agent\n(of node classification task) walk over the graph and decide where to direct to\nmaximize classification accuracy. We define the graph walk as a partially\nobservable Markov decision process (POMDP). The proposed method is flexible for\nworking in both transductive and inductive setting. Extensive experiments on\nfour datasets demonstrate that our proposed method outperforms several\nstate-of-the-art methods. Several case studies also illustrate the meaningful\nmovement trajectory made by the agent.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 22:53:32 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Akujuobi", "Uchenna", ""], ["Zhang", "Qiannan", ""], ["Yufei", "Han", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1910.10271", "submitter": "Michal Yemini", "authors": "Michal Yemini, Amir Leshem, Anelia Somekh-Baruch", "title": "The Restless Hidden Markov Bandit with Linear Rewards and Side\n  Information", "comments": "Accepted for publication in the IEEE Transactions on Signal\n  Processing. A summary of the results presented in this paper was accepted to\n  the 59th Conference on Decision and Control (CDC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a model for the hidden Markovian bandit problem with\nlinear rewards. As opposed to current work on Markovian bandits, we do not\nassume that the state is known to the decision maker before making the\ndecision. Furthermore, we assume structural side information where the decision\nmaker knows in advance that there are two types of hidden states; one is common\nto all arms and evolves according to a Markovian distribution, and the other is\nunique to each arm and is distributed according to an i.i.d. process that is\nunique to each arm. We present an algorithm and regret analysis to this\nproblem. Surprisingly, we can recover the hidden states and maintain\nlogarithmic regret in the case of a convex polytope action set. Furthermore, we\nshow that the structural side information leads to expected regret that does\nnot depend on the number of extreme points in the action space. Therefore, we\nobtain practical solutions even in high dimensional problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 23:13:44 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 01:50:59 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 05:20:14 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2021 19:14:41 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Yemini", "Michal", ""], ["Leshem", "Amir", ""], ["Somekh-Baruch", "Anelia", ""]]}, {"id": "1910.10277", "submitter": "Sephora Madjiheurem", "authors": "Sephora Madjiheurem and Laura Toni", "title": "State2vec: Off-Policy Successor Features Approximators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in reinforcement learning (RL) is the design of agents that\nare able to generalize across tasks that share common dynamics. A viable\nsolution is meta-reinforcement learning, which identifies common structures\namong past tasks to be then generalized to new tasks (meta-test). In\nmeta-training, the RL agent learns state representations that encode prior\ninformation from a set of tasks, used to generalize the value function\napproximation. This has been proposed in the literature as successor\nrepresentation approximators. While promising, these methods do not generalize\nwell across optimal policies, leading to sampling-inefficiency during meta-test\nphases. In this paper, we propose state2vec, an efficient and low-complexity\nframework for learning successor features which (i) generalize across policies,\n(ii) ensure sample-efficiency during meta-test. We extend the well known\nnode2vec framework to learn state embeddings that account for the discounted\nfuture state transitions in RL. The proposed off-policy state2vec captures the\ngeometry of the underlying state space, making good basis functions for linear\nvalue function approximation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 23:22:58 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Madjiheurem", "Sephora", ""], ["Toni", "Laura", ""]]}, {"id": "1910.10283", "submitter": "Hema Venkata Krishna Giri Narra", "authors": "Zhifeng Lin, Krishna Giri Narra, Mingchao Yu, Salman Avestimehr,\n  Murali Annavaram", "title": "Train Where the Data is: A Case for Bandwidth Efficient Coded Training", "comments": "10 pages, Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a machine learning model is both compute and data-intensive. Most of\nthe model training is performed on high performance compute nodes and the\ntraining data is stored near these nodes for faster training. But there is a\ngrowing interest in enabling training near the data. For instance, mobile\ndevices are rich sources of training data. It may not be feasible to\nconsolidate the data from mobile devices into a cloud service, due to bandwidth\nand data privacy reasons. Training at mobile devices is however fraught with\nchallenges. First mobile devices may join or leave the distributed setting,\neither voluntarily or due to environmental uncertainties, such as lack of\npower. Tolerating uncertainties is critical to the success of distributed\nmobile training. One proactive approach to tolerate computational uncertainty\nis to store data in a coded format and perform training on coded data. Encoding\ndata is a challenging task since erasure codes require multiple devices to\nexchange their data to create a coded data partition, which places a\nsignificant bandwidth constraint. Furthermore, coded computing traditionally\nrelied on a central node to encode and distribute data to all the worker nodes,\nwhich is not practical in a distributed mobile setting.\n  In this paper, we tackle the uncertainty in distributed mobile training using\na bandwidth-efficient encoding strategy. We use a Random Linear Network coding\n(RLNC) which reduces the need to exchange data partitions across all\nparticipating mobile devices, while at the same time preserving the property of\ncoded computing to tolerate uncertainties. We implement gradient descent for\nlogistic regression and SVM to evaluate the effectiveness of our mobile\ntraining framework. We demonstrate a 50% reduction in total required\ncommunication bandwidth compared to MDS coded computation, one of the popular\nerasure codes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 23:48:05 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Lin", "Zhifeng", ""], ["Narra", "Krishna Giri", ""], ["Yu", "Mingchao", ""], ["Avestimehr", "Salman", ""], ["Annavaram", "Murali", ""]]}, {"id": "1910.10287", "submitter": "Panayiotis Georgiou", "authors": "Prashanth Gurunath Shivakumar, Naveen Kumar, Panayiotis Georgiou,\n  Shrikanth Narayanan", "title": "RNN based Incremental Online Spoken Language Understanding", "comments": "Accepted for publication at IEEE Spoken Language Technology Workshop\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken Language Understanding (SLU) typically comprises of an automatic\nspeech recognition (ASR) followed by a natural language understanding (NLU)\nmodule. The two modules process signals in a blocking sequential fashion, i.e.,\nthe NLU often has to wait for the ASR to finish processing on an utterance\nbasis, potentially leading to high latencies that render the spoken interaction\nless natural. In this paper, we propose recurrent neural network (RNN) based\nincremental processing towards the SLU task of intent detection. The proposed\nmethodology offers lower latencies than a typical SLU system, without any\nsignificant reduction in system accuracy. We introduce and analyze different\nrecurrent neural network architectures for incremental and online processing of\nthe ASR transcripts and compare it to the existing offline systems. A lexical\nEnd-of-Sentence (EOS) detector is proposed for segmenting the stream of\ntranscript into sentences for intent classification. Intent detection\nexperiments are conducted on benchmark ATIS, Snips and Facebook's multilingual\ntask oriented dialog datasets modified to emulate a continuous incremental\nstream of words with no utterance demarcation. We also analyze the prospects of\nearly intent detection, before EOS, with our proposed system.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 00:17:26 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 18:27:56 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shivakumar", "Prashanth Gurunath", ""], ["Kumar", "Naveen", ""], ["Georgiou", "Panayiotis", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1910.10288", "submitter": "Eric Battenberg", "authors": "Eric Battenberg, RJ Skerry-Ryan, Soroosh Mariooryad, Daisy Stanton,\n  David Kao, Matt Shannon, Tom Bagby", "title": "Location-Relative Attention Mechanisms For Robust Long-Form Speech\n  Synthesis", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the ability to produce human-level speech for in-domain text,\nattention-based end-to-end text-to-speech (TTS) systems suffer from text\nalignment failures that increase in frequency for out-of-domain text. We show\nthat these failures can be addressed using simple location-relative attention\nmechanisms that do away with content-based query/key comparisons. We compare\ntwo families of attention mechanisms: location-relative GMM-based mechanisms\nand additive energy-based mechanisms. We suggest simple modifications to\nGMM-based attention that allow it to align quickly and consistently during\ntraining, and introduce a new location-relative attention mechanism to the\nadditive energy-based family, called Dynamic Convolution Attention (DCA). We\ncompare the various mechanisms in terms of alignment speed and consistency\nduring training, naturalness, and ability to generalize to long utterances, and\nconclude that GMM attention and DCA can generalize to very long utterances,\nwhile preserving naturalness for shorter, in-domain utterances.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 00:21:33 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 23:08:58 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Battenberg", "Eric", ""], ["Skerry-Ryan", "RJ", ""], ["Mariooryad", "Soroosh", ""], ["Stanton", "Daisy", ""], ["Kao", "David", ""], ["Shannon", "Matt", ""], ["Bagby", "Tom", ""]]}, {"id": "1910.10294", "submitter": "Mohit Rajpal", "authors": "Mohit Rajpal and Bryan Kian Hsiang Low", "title": "A Unifying Framework of Bilinear LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel unifying framework of bilinear LSTMs that can\nrepresent and utilize the nonlinear interaction of the input features present\nin sequence datasets for achieving superior performance over a linear LSTM and\nyet not incur more parameters to be learned. To realize this, our unifying\nframework allows the expressivity of the linear vs. bilinear terms to be\nbalanced by correspondingly trading off between the hidden state vector size\nvs. approximation quality of the weight matrix in the bilinear term so as to\noptimize the performance of our bilinear LSTM, while not incurring more\nparameters to be learned. We empirically evaluate the performance of our\nbilinear LSTM in several language-based sequence learning tasks to demonstrate\nits general applicability.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 00:50:29 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Rajpal", "Mohit", ""], ["Low", "Bryan Kian Hsiang", ""]]}, {"id": "1910.10307", "submitter": "Vahdat Abdelzad", "authors": "Vahdat Abdelzad, Krzysztof Czarnecki, Rick Salay, Taylor Denounden,\n  Sachin Vernekar, Buu Phan", "title": "Detecting Out-of-Distribution Inputs in Deep Neural Networks Using an\n  Early-Layer Output", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks achieve superior performance in challenging tasks such\nas image classification. However, deep classifiers tend to incorrectly classify\nout-of-distribution (OOD) inputs, which are inputs that do not belong to the\nclassifier training distribution. Several approaches have been proposed to\ndetect OOD inputs, but the detection task is still an ongoing challenge. In\nthis paper, we propose a new OOD detection approach that can be easily applied\nto an existing classifier and does not need to have access to OOD samples. The\ndetector is a one-class classifier trained on the output of an early layer of\nthe original classifier fed with its original training set. We apply our\napproach to several low- and high-dimensional datasets and compare it to the\nstate-of-the-art detection approaches. Our approach achieves substantially\nbetter results over multiple metrics.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 01:27:48 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Abdelzad", "Vahdat", ""], ["Czarnecki", "Krzysztof", ""], ["Salay", "Rick", ""], ["Denounden", "Taylor", ""], ["Vernekar", "Sachin", ""], ["Phan", "Buu", ""]]}, {"id": "1910.10308", "submitter": "Yilin Kang", "authors": "Yilin Kang, Yong Liu, Weiping Wang", "title": "Weighted Distributed Differential Privacy ERM: Convex and Non-convex", "comments": null, "journal-ref": null, "doi": "10.1016/j.cose.2021.102275", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning is an approach allowing different parties to\nlearn a model over all data sets without disclosing their own data. In this\npaper, we propose a weighted distributed differential privacy (WD-DP) empirical\nrisk minimization (ERM) method to train a model in distributed setting,\nconsidering different weights of different clients. We guarantee differential\nprivacy by gradient perturbation, adding Gaussian noise, and advance the\nstate-of-the-art on gradient perturbation method in distributed setting. By\ndetailed theoretical analysis, we show that in distributed setting, the noise\nbound and the excess empirical risk bound can be improved by considering\ndifferent weights held by multiple parties. Moreover, considering that the\nconstraint of convex loss function in ERM is not easy to achieve in some\nsituations, we generalize our method to non-convex loss functions which satisfy\nPolyak-Lojasiewicz condition. Experiments on real data sets show that our\nmethod is more reliable and we improve the performance of distributed\ndifferential privacy ERM, especially in the case that data scale on different\nclients is uneven.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 01:28:51 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 02:27:53 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Kang", "Yilin", ""], ["Liu", "Yong", ""], ["Wang", "Weiping", ""]]}, {"id": "1910.10317", "submitter": "Antonia Lovjer", "authors": "Antonia Lovjer, Minsu Yeom, Benedikt D. Schifferer, Iddo Drori", "title": "Using Segmentation Masks in the ICCV 2019 Learning to Drive Challenge", "comments": null, "journal-ref": "ICCV Autonomous Driving Workshop, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we predict vehicle speed and steering angle given camera image\nframes. Our key contribution is using an external pre-trained neural network\nfor segmentation. We augment the raw images with their segmentation masks and\nmirror images. We ensemble three diverse neural network models (i) a CNN using\na single image and its segmentation mask, (ii) a stacked CNN taking as input a\nsequence of images and segmentation masks, and (iii) a bidirectional GRU,\nextracting image features using a pre-trained ResNet34, DenseNet121 and our own\nCNN single image model. We achieve the second best performance for MSE angle\nand second best performance overall, to win 2nd place in the ICCV Learning to\nDrive challenge. We make our models and code publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 02:24:28 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Lovjer", "Antonia", ""], ["Yeom", "Minsu", ""], ["Schifferer", "Benedikt D.", ""], ["Drori", "Iddo", ""]]}, {"id": "1910.10318", "submitter": "Michael Diodato", "authors": "Michael Diodato, Yu Li, Manik Goyal, Iddo Drori", "title": "Winning the ICCV 2019 Learning to Drive Challenge", "comments": null, "journal-ref": "ICCV Autonomous Driving Workshop, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving has a significant impact on society. Predicting vehicle\ntrajectories, specifically, angle and speed, is important for safe and\ncomfortable driving. This work focuses on fusing inputs from camera sensors and\nvisual map data which lead to significant improvement in performance and plays\na key role in winning the challenge. We use pre-trained CNN's for processing\nimage frames, a neural network for fusing the image representation with visual\nmap data, and train a sequence model for time series prediction. We demonstrate\nthe best performing MSE angle and best performance overall, to win the ICCV\n2019 Learning to Drive challenge. We make our models and code publicly\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 02:31:18 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Diodato", "Michael", ""], ["Li", "Yu", ""], ["Goyal", "Manik", ""], ["Drori", "Iddo", ""]]}, {"id": "1910.10320", "submitter": "Shuhan Tan", "authors": "Shuhan Tan, Xingchao Peng, Kate Saenko", "title": "Class-imbalanced Domain Adaptation: An Empirical Odyssey", "comments": "ECCV 2020 Workshops - TASK-CV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation is a promising way to generalize deep models\nto novel domains. However, the current literature assumes that the label\ndistribution is domain-invariant and only aligns the feature distributions or\nvice versa. In this work, we explore the more realistic task of\nClass-imbalanced Domain Adaptation: How to align feature distributions across\ndomains while the label distributions of the two domains are also different?\nTaking a practical step towards this problem, we constructed the first\nbenchmark with 22 cross-domain tasks from 6real-image datasets. We conducted\ncomprehensive experiments on 10 recent domain adaptation methods and find most\nof them are very fragile in the face of coexisting feature and label\ndistribution shift. Towards a better solution, we further proposed a feature\nand label distribution CO-ALignment (COAL) model with a novel combination of\nexisting ideas. COAL is empirically shown to outperform the most recent domain\nadaptation methods on our benchmarks. We believe the provided benchmarks,\nempirical analysis results, and the COAL baseline could stimulate and\nfacilitate future research towards this important problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 02:35:46 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 07:58:59 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tan", "Shuhan", ""], ["Peng", "Xingchao", ""], ["Saenko", "Kate", ""]]}, {"id": "1910.10324", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Chunxi Liu, Frank Zhang, Xiaohui Zhang, Yongqiang\n  Wang, Gabriel Synnaeve, Satoshi Nakamura, Geoffrey Zweig", "title": "Deja-vu: Double Feature Presentation and Iterated Loss in Deep\n  Transformer Networks", "comments": "Accepted in IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep acoustic models typically receive features in the first layer of the\nnetwork, and process increasingly abstract representations in the subsequent\nlayers. Here, we propose to feed the input features at multiple depths in the\nacoustic model. As our motivation is to allow acoustic models to re-examine\ntheir input features in light of partial hypotheses we introduce intermediate\nmodel heads and loss function. We study this architecture in the context of\ndeep Transformer networks, and we use an attention mechanism over both the\nprevious layer activations and the input features. To train this model's\nintermediate output hypothesis, we apply the objective function at each layer\nright before feature re-use. We find that the use of such iterated loss\nsignificantly improves performance by itself, as well as enabling input feature\nre-use. We present results on both Librispeech, and a large scale video\ndataset, with relative improvements of 10 - 20% for Librispeech and 3.2 - 13%\nfor videos.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 02:48:30 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 06:07:18 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Tjandra", "Andros", ""], ["Liu", "Chunxi", ""], ["Zhang", "Frank", ""], ["Zhang", "Xiaohui", ""], ["Wang", "Yongqiang", ""], ["Synnaeve", "Gabriel", ""], ["Nakamura", "Satoshi", ""], ["Zweig", "Geoffrey", ""]]}, {"id": "1910.10335", "submitter": "Amila Silva", "authors": "Amila Silva, Shanika Karunasekera, Christopher Leckie and Ling Luo", "title": "USTAR: Online Multimodal Embedding for Modeling User-Guided\n  Spatiotemporal Activity", "comments": "10 pages, IEEE International Conference on Big Data 2019 (IEEE Big\n  Data 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building spatiotemporal activity models for people's activities in urban\nspaces is important for understanding the ever-increasing complexity of urban\ndynamics. With the emergence of Geo-Tagged Social Media (GTSM) records,\nprevious studies demonstrate the potential of GTSM records for spatiotemporal\nactivity modeling. State-of-the-art methods for this task embed different\nmodalities (location, time, and text) of GTSM records into a single embedding\nspace. However, they ignore Non-GeoTagged Social Media (NGTSM) records, which\ngenerally account for the majority of posts (e.g., more than 95\\% in Twitter),\nand could represent a great source of information to alleviate the sparsity of\nGTSM records. Furthermore, in the current spatiotemporal embedding techniques,\nless focus has been given to the users, who exhibit spatially motivated\nbehaviors. To bridge this research gap, this work proposes USTAR, a novel\nonline learning method for User-guided SpatioTemporal Activity Representation,\nwhich (1) embeds locations, time, and text along with users into the same\nembedding space to capture their correlations; (2) uses a novel collaborative\nfiltering approach based on two different empirically studied user behaviors to\nincorporate both NGTSM and GTSM records in learning; and (3) introduces a novel\nsampling technique to learn spatiotemporal representations in an online fashion\nto accommodate recent information into the embedding space, while avoiding\noverfitting to recent records and frequently appearing units in social media\nstreams. Our results show that USTAR substantially improves the\nstate-of-the-art for region retrieval and keyword retrieval and its potential\nto be applied to other downstream applications such as local event detection.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 04:02:20 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Silva", "Amila", ""], ["Karunasekera", "Shanika", ""], ["Leckie", "Christopher", ""], ["Luo", "Ling", ""]]}, {"id": "1910.10336", "submitter": "Satoshi Takabe", "authors": "Satoshi Takabe, Yuki Yamauchi, Tadashi Wadayama", "title": "Trainable Projected Gradient Detector for Sparsely Spread Code Division\n  Multiple Access", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsely spread code division multiple access (SCDMA) is a promising\nnon-orthogonal multiple access technique for future wireless communications. In\nthis paper, we propose a novel trainable multiuser detector called sparse\ntrainable projected gradient (STPG) detector, which is based on the notion of\ndeep unfolding. In the STPG detector, trainable parameters are embedded to a\nprojected gradient descent algorithm, which can be trained by standard deep\nlearning techniques such as back propagation and stochastic gradient descent.\nAdvantages of the detector are its low computational cost and small number of\ntrainable parameters, which enables us to treat massive SCDMA systems. In\nparticular, its computational cost is smaller than a conventional belief\npropagation (BP) detector while the STPG detector exhibits nearly same\ndetection performance with a BP detector. We also propose a scalable joint\nlearning of signature sequences and the STPG detector for signature design.\nNumerical results show that the joint learning improves multiuser detection\nperformance particular in the low SNR regime.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 04:03:49 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Takabe", "Satoshi", ""], ["Yamauchi", "Yuki", ""], ["Wadayama", "Tadashi", ""]]}, {"id": "1910.10341", "submitter": "Suya Wu", "authors": "Suya Wu, Enmao Diao, Jie Ding, Vahid Tarokh", "title": "Deep Clustering of Compressed Variational Embeddings", "comments": "Submitted to the IEEE International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP), Barcelona, Spain, May 2020", "journal-ref": null, "doi": "10.1109/DCC47342.2020.00051", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the ever-increasing demands for limited communication bandwidth\nand low-power consumption, we propose a new methodology, named joint\nVariational Autoencoders with Bernoulli mixture models (VAB), for performing\nclustering in the compressed data domain. The idea is to reduce the data\ndimension by Variational Autoencoders (VAEs) and group data representations by\nBernoulli mixture models (BMMs). Once jointly trained for compression and\nclustering, the model can be decomposed into two parts: a data vendor that\nencodes the raw data into compressed data, and a data consumer that classifies\nthe received (compressed) data. In this way, the data vendor benefits from data\nsecurity and communication bandwidth, while the data consumer benefits from low\ncomputational complexity. To enable training using the gradient descent\nalgorithm, we propose to use the Gumbel-Softmax distribution to resolve the\ninfeasibility of the back-propagation algorithm when assessing categorical\nsamples.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 04:14:40 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Wu", "Suya", ""], ["Diao", "Enmao", ""], ["Ding", "Jie", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1910.10356", "submitter": "Kartikeya Bhardwaj", "authors": "Kartikeya Bhardwaj, Naveen Suda, Radu Marculescu", "title": "EdgeAI: A Vision for Deep Learning in IoT Era", "comments": "To appear in IEEE Design and Test", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The significant computational requirements of deep learning present a major\nbottleneck for its large-scale adoption on hardware-constrained IoT-devices.\nHere, we envision a new paradigm called EdgeAI to address major impediments\nassociated with deploying deep networks at the edge. Specifically, we discuss\nthe existing directions in computation-aware deep learning and describe two new\nchallenges in the IoT era: (1) Data-independent deployment of learning, and (2)\nCommunication-aware distributed inference. We further present new directions\nfrom our recent research to alleviate the latter two challenges. Overcoming\nthese challenges is crucial for rapid adoption of learning on IoT-devices in\norder to truly enable EdgeAI.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 05:16:32 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Bhardwaj", "Kartikeya", ""], ["Suda", "Naveen", ""], ["Marculescu", "Radu", ""]]}, {"id": "1910.10362", "submitter": "John Miller", "authors": "John Miller, Smitha Milli, Moritz Hardt", "title": "Strategic Classification is Causal Modeling in Disguise", "comments": "This paper was previously titled \"Strategic Adaptation to\n  Classifiers: A Causal Perspective.\" The current version subsumes all previous\n  versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consequential decision-making incentivizes individuals to strategically adapt\ntheir behavior to the specifics of the decision rule. While a long line of work\nhas viewed strategic adaptation as gaming and attempted to mitigate its\neffects, recent work has instead sought to design classifiers that incentivize\nindividuals to improve a desired quality. Key to both accounts is a cost\nfunction that dictates which adaptations are rational to undertake. In this\nwork, we develop a causal framework for strategic adaptation. Our causal\nperspective clearly distinguishes between gaming and improvement and reveals an\nimportant obstacle to incentive design. We prove any procedure for designing\nclassifiers that incentivize improvement must inevitably solve a non-trivial\ncausal inference problem. Moreover, we show a similar result holds for\ndesigning cost functions that satisfy the requirements of previous work. With\nthe benefit of hindsight, our results show much of the prior work on strategic\nclassification is causal modeling in disguise.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 05:36:59 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 07:41:51 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 01:24:08 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Miller", "John", ""], ["Milli", "Smitha", ""], ["Hardt", "Moritz", ""]]}, {"id": "1910.10367", "submitter": "Sanjay Thakur", "authors": "Sanjay Thakur, Herke Van Hoof, Gunshi Gupta, David Meger", "title": "Unifying Variational Inference and PAC-Bayes for Supervised Learning\n  that Scales", "comments": "13 pages, 8 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural Network based controllers hold enormous potential to learn complex,\nhigh-dimensional functions. However, they are prone to overfitting and\nunwarranted extrapolations. PAC Bayes is a generalized framework which is more\nresistant to overfitting and that yields performance bounds that hold with\narbitrarily high probability even on the unjustified extrapolations. However,\noptimizing to learn such a function and a bound is intractable for complex\ntasks. In this work, we propose a method to simultaneously learn such a\nfunction and estimate performance bounds that scale organically to\nhigh-dimensions, non-linear environments without making any explicit\nassumptions about the environment. We build our approach on a parallel that we\ndraw between the formulations called ELBO and PAC Bayes when the risk metric is\nnegative log likelihood. Through our experiments on multiple high dimensional\nMuJoCo locomotion tasks, we validate the correctness of our theory, show its\nability to generalize better, and investigate the factors that are important\nfor its learning. The code for all the experiments is available at\nhttps://bit.ly/2qv0JjA.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 05:48:26 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 15:37:20 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Thakur", "Sanjay", ""], ["Van Hoof", "Herke", ""], ["Gupta", "Gunshi", ""], ["Meger", "David", ""]]}, {"id": "1910.10368", "submitter": "Dongmin Park", "authors": "Dongmin Park, Susik Yoon, Hwanjun Song, Jae-Gil Lee", "title": "MLAT: Metric Learning for kNN in Streaming Time Series", "comments": "In Proc. 5th Workshop on Mining and Learning from Time Series\n  (MiLeTS) in conjunction with KDD'19", "journal-ref": "MileTS. Workshop on SIGKDD'19. (2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a good distance measure for distance-based classification in time\nseries leads to significant performance improvement in many tasks.\nSpecifically, it is critical to effectively deal with variations and temporal\ndependencies in time series. However, existing metric learning approaches focus\non tackling variations mainly using a strict alignment of two sequences,\nthereby being not able to capture temporal dependencies. To overcome this\nlimitation, we propose MLAT, which covers both alignment and temporal\ndependencies at the same time. MLAT achieves the alignment effect as well as\npreserves temporal dependencies by augmenting a given time series using a\nsliding window. Furthermore, MLAT employs time-invariant metric learning to\nderive the most appropriate distance measure from the augmented samples which\ncan also capture the temporal dependencies among them well. We show that MLAT\noutperforms other existing algorithms in the extensive experiments on various\nreal-world data sets.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 05:48:33 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Park", "Dongmin", ""], ["Yoon", "Susik", ""], ["Song", "Hwanjun", ""], ["Lee", "Jae-Gil", ""]]}, {"id": "1910.10369", "submitter": "Oluwafemi Azeez", "authors": "Azeez Oluwafemi, Yang Zou, B.V.K. Vijaya Kumar", "title": "Deep Classification Network for Monocular Depth Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monocular Depth Estimation is usually treated as a supervised and regression\nproblem when it actually is very similar to semantic segmentation task since\nthey both are fundamentally pixel-level classification tasks. We applied depth\nincrements that increases with depth in discretizing depth values and then\napplied Deeplab v2 and the result was higher accuracy. We were able to achieve\na state-of-the-art result on the KITTI dataset and outperformed existing\narchitecture by an 8% margin.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 05:50:04 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Oluwafemi", "Azeez", ""], ["Zou", "Yang", ""], ["Kumar", "B. V. K. Vijaya", ""]]}, {"id": "1910.10379", "submitter": "Zhenhua Huang", "authors": "Huang Zhenhua, Wang Zhenyu, Zhang Rui, Zhao Yangyang, Xie Xiaohui,\n  Sharad Mehrotra", "title": "Network2Vec Learning Node Representation Based on Space Mapping in\n  Networks", "comments": "8 pages. 8 figures. Will appear at workshop on the conference ICDM\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks represented as node adjacency matrices constrains the\napplication of machine learning and parallel algorithms. To address this\nlimitation, network embedding (i.e., graph representation) has been intensively\nstudied to learn a fixed-length vector for each node in an embedding space,\nwhere the node properties in the original graph are preserved. Existing methods\nmainly focus on learning embedding vectors to preserve nodes proximity, i.e.,\nnodes next to each other in the graph space should also be closed in the\nembedding space, but do not enforce algebraic statistical properties to be\nshared between the embedding space and graph space. In this work, we propose a\nlightweight model, entitled Network2Vec, to learn network embedding on the base\nof semantic distance mapping between the graph space and embedding space. The\nmodel builds a bridge between the two spaces leveraging the property of group\nhomomorphism. Experiments on different learning tasks, including node\nclassification, link prediction, and community visualization, demonstrate the\neffectiveness and efficiency of the new embedding method, which improves the\nstate-of-the-art model by 19% in node classification and 7% in link prediction\ntasks at most. In addition, our method is significantly faster, consuming only\na fraction of the time used by some famous methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 06:32:16 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Zhenhua", "Huang", ""], ["Zhenyu", "Wang", ""], ["Rui", "Zhang", ""], ["Yangyang", "Zhao", ""], ["Xiaohui", "Xie", ""], ["Mehrotra", "Sharad", ""]]}, {"id": "1910.10386", "submitter": "Felix McGregor Mr", "authors": "Felix McGregor, Arnu Pretorius, Johan du Preez, Steve Kroon", "title": "Stabilising priors for robust Bayesian deep learning", "comments": "3 pages, accepted at Bayesian Deep learning workshop NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNNs) have developed into useful tools for\nprobabilistic modelling due to recent advances in variational inference\nenabling large scale BNNs. However, BNNs remain brittle and hard to train,\nespecially: (1) when using deep architectures consisting of many hidden layers\nand (2) in situations with large weight variances. We use signal propagation\ntheory to quantify these challenges and propose self-stabilising priors. This\nis achieved by a reformulation of the ELBO to allow the prior to influence\nnetwork signal propagation. Then, we develop a stabilising prior, where the\ndistributional parameters of the prior are adjusted before each forward pass to\nensure stability of the propagating signal. This stabilised signal propagation\nleads to improved convergence and robustness making it possible to train deeper\nnetworks and in more noisy settings.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 07:01:17 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["McGregor", "Felix", ""], ["Pretorius", "Arnu", ""], ["Preez", "Johan du", ""], ["Kroon", "Steve", ""]]}, {"id": "1910.10397", "submitter": "Heung-Chang Lee", "authors": "Heung-Chang Lee, Do-Guk Kim, Bohyung Han", "title": "Efficient Decoupled Neural Architecture Search by Structure and\n  Operation Sampling", "comments": null, "journal-ref": "IEEE ICASSP 2020", "doi": "10.1109/ICASSP40776.2020.9053197", "report-no": "9053197", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural architecture search algorithm via reinforcement\nlearning by decoupling structure and operation search processes. Our approach\nsamples candidate models from the multinomial distribution on the policy\nvectors defined on the two search spaces independently. The proposed technique\nimproves the efficiency of architecture search process significantly compared\nto the conventional methods based on reinforcement learning with the RNN\ncontrollers while achieving competitive accuracy and model size in target\ntasks. Our policy vectors are easily interpretable throughout the training\nprocedure, which allows to analyze the search progress and the discovered\narchitectures; the black-box characteristics of the RNN controllers hamper\nunderstanding training progress in terms of policy parameter updates. Our\nexperiments demonstrate outstanding performance compared to the\nstate-of-the-art methods with a fraction of search cost.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 08:00:22 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Lee", "Heung-Chang", ""], ["Kim", "Do-Guk", ""], ["Han", "Bohyung", ""]]}, {"id": "1910.10398", "submitter": "Christoph Angermann", "authors": "Christoph Angermann and Markus Haltmeier", "title": "Random 2.5D U-net for Fully 3D Segmentation", "comments": "Submission for joint MICCAI-Workshops on Computing and Visualization\n  for Intravascular Imaging and Computer Assisted Stenting (CVII-STENT) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks are state-of-the-art for various segmentation\ntasks. While for 2D images these networks are also computationally efficient,\n3D convolutions have huge storage requirements and therefore, end-to-end\ntraining is limited by GPU memory and data size. To overcome this issue, we\nintroduce a network structure for volumetric data without 3D convolution\nlayers. The main idea is to include projections from different directions to\ntransform the volumetric data to a sequence of images, where each image\ncontains information of the full data. We then apply 2D convolutions to these\nprojection images and lift them again to volumetric data using a trainable\nreconstruction algorithm. The proposed architecture can be applied end-to-end\nto very large data volumes without cropping or sliding-window techniques. For a\ntested sparse binary segmentation task, it outperforms already known standard\napproaches and is more resistant to generation of artefacts.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 08:02:09 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Angermann", "Christoph", ""], ["Haltmeier", "Markus", ""]]}, {"id": "1910.10400", "submitter": "Manuel Pariente", "authors": "Manuel Pariente, Samuele Cornell, Antoine Deleforge and Emmanuel\n  Vincent", "title": "Filterbank design for end-to-end speech separation", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-channel speech separation has recently made great progress thanks to\nlearned filterbanks as used in ConvTasNet. In parallel, parameterized\nfilterbanks have been proposed for speaker recognition where only center\nfrequencies and bandwidths are learned. In this work, we extend real-valued\nlearned and parameterized filterbanks into complex-valued analytic filterbanks\nand define a set of corresponding representations and masking strategies. We\nevaluate these filterbanks on a newly released noisy speech separation dataset\n(WHAM). The results show that the proposed analytic learned filterbank\nconsistently outperforms the real-valued filterbank of ConvTasNet. Also, we\nvalidate the use of parameterized filterbanks and show that complex-valued\nrepresentations and masks are beneficial in all conditions. Finally, we show\nthat the STFT achieves its best performance for 2ms windows.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 08:08:26 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 11:48:11 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Pariente", "Manuel", ""], ["Cornell", "Samuele", ""], ["Deleforge", "Antoine", ""], ["Vincent", "Emmanuel", ""]]}, {"id": "1910.10410", "submitter": "Phanideep Gampa", "authors": "Phanideep Gampa, Sumio Fujita", "title": "BanditRank: Learning to Rank Using Contextual Bandits", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extensible deep learning method that uses reinforcement\nlearning to train neural networks for offline ranking in information retrieval\n(IR). We call our method BanditRank as it treats ranking as a contextual bandit\nproblem. In the domain of learning to rank for IR, current deep learning models\nare trained on objective functions different from the measures they are\nevaluated on. Since most evaluation measures are discrete quantities, they\ncannot be leveraged by directly using gradient descent algorithms without an\napproximation. BanditRank bridges this gap by directly optimizing a\ntask-specific measure, such as mean average precision (MAP), using gradient\ndescent. Specifically, a contextual bandit whose action is to rank input\ndocuments is trained using a policy gradient algorithm to directly maximize the\nreward. The reward can be a single measure, such as MAP, or a combination of\nseveral measures. The notion of ranking is also inherent in BanditRank, similar\nto the current \\textit{listwise} approaches. To evaluate the effectiveness of\nBanditRank, we conducted a series of experiments on datasets related to three\ndifferent tasks, i.e., web search, community, and factoid question answering.\nWe found that it performs better than state-of-the-art methods when applied on\nthe question answering datasets. On the web search dataset, we found that\nBanditRank performed better than four strong listwise baselines including\nLambdaMART, AdaRank, ListNet and Coordinate Ascent.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 08:32:14 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Gampa", "Phanideep", ""], ["Fujita", "Sumio", ""]]}, {"id": "1910.10428", "submitter": "Mahdi Boloursaz Mashhadi", "authors": "Mahdi Boloursaz Mashhadi, Qianqian Yang, Deniz Gunduz", "title": "CNN-based Analog CSI Feedback in FDD MIMO-OFDM Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive multiple-input multiple-output (MIMO) systems require downlink\nchannel state information (CSI) at the base station (BS) to better utilize the\navailable spatial diversity and multiplexing gains. However, in a frequency\ndivision duplex (FDD) massive MIMO system, CSI feedback overhead degrades the\noverall spectral efficiency. Convolutional neural network (CNN)-based CSI\nfeedback compression schemes has received a lot of attention recently due to\nsignificant improvements in compression efficiency; however, they still require\nreliable feedback links to convey the compressed CSI information to the BS.\nInstead, we propose here a CNN-based analog feedback scheme, called\nAnalogDeepCMC, which directly maps the downlink CSI to uplink channel input.\nCorresponding noisy channel outputs are used by another CNN to reconstruct the\nDL channel estimate. Not only the proposed outperforms existing digital CSI\nfeedback schemes in terms of the achievable downlink rate, but also simplifies\nthe operation as it does not require explicit quantization, coding and\nmodulation, and provides a low-latency alternative particularly in rapidly\nchanging MIMO channels, where the CSI needs to be estimated and fed back\nperiodically.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 09:26:13 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Mashhadi", "Mahdi Boloursaz", ""], ["Yang", "Qianqian", ""], ["Gunduz", "Deniz", ""]]}, {"id": "1910.10453", "submitter": "Jihong Park", "authors": "Anis Elgabli, Jihong Park, Amrit S. Bedi, Chaouki Ben Issaid, Mehdi\n  Bennis, Vaneet Aggarwal", "title": "Q-GADMM: Quantized Group ADMM for Communication Efficient Decentralized\n  Machine Learning", "comments": "19 pages, 8 figures; to appear in IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a communication-efficient decentralized machine\nlearning (ML) algorithm, coined quantized group ADMM (Q-GADMM). To reduce the\nnumber of communication links, every worker in Q-GADMM communicates only with\ntwo neighbors, while updating its model via the group alternating direction\nmethod of multipliers (GADMM). Moreover, each worker transmits the quantized\ndifference between its current model and its previously quantized model,\nthereby decreasing the communication payload size. However, due to the lack of\ncentralized entity in decentralized ML, the spatial sparsity and payload\ncompression may incur error propagation, hindering model training convergence.\nTo overcome this, we develop a novel stochastic quantization method to\nadaptively adjust model quantization levels and their probabilities, while\nproving the convergence of Q-GADMM for convex objective functions. Furthermore,\nto demonstrate the feasibility of Q-GADMM for non-convex and stochastic\nproblems, we propose quantized stochastic GADMM (Q-SGADMM) that incorporates\ndeep neural network architectures and stochastic sampling. Simulation results\ncorroborate that Q-GADMM significantly outperforms GADMM in terms of\ncommunication efficiency while achieving the same accuracy and convergence\nspeed for a linear regression task. Similarly, for an image classification task\nusing DNN, Q-SGADMM achieves significantly less total communication cost with\nidentical accuracy and convergence speed compared to its counterpart without\nquantization, i.e., stochastic GADMM (SGADMM).\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 10:47:06 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 13:40:21 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 17:31:00 GMT"}, {"version": "v4", "created": "Mon, 27 Jul 2020 19:33:13 GMT"}, {"version": "v5", "created": "Mon, 3 Aug 2020 09:37:46 GMT"}, {"version": "v6", "created": "Sat, 3 Oct 2020 18:28:18 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Elgabli", "Anis", ""], ["Park", "Jihong", ""], ["Bedi", "Amrit S.", ""], ["Issaid", "Chaouki Ben", ""], ["Bennis", "Mehdi", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1910.10455", "submitter": "Zhiwu Huang", "authors": "Zhiwu Huang, Danda Pani Paudel, Guanju Li, Jiqing Wu, Radu Timofte,\n  Luc Van Gool", "title": "Divide-and-Conquer Adversarial Learning for High-Resolution Image and\n  Video Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a divide-and-conquer inspired adversarial learning\n(DACAL) approach for photo enhancement. The key idea is to decompose the photo\nenhancement process into hierarchically multiple sub-problems, which can be\nbetter conquered from bottom to up. On the top level, we propose a\nperception-based division to learn additive and multiplicative components,\nrequired to translate a low-quality image or video into its high-quality\ncounterpart. On the intermediate level, we use a frequency-based division with\ngenerative adversarial network (GAN) to weakly supervise the photo enhancement\nprocess. On the lower level, we design a dimension-based division that enables\nthe GAN model to better approximates the distribution distance on multiple\nindependent one-dimensional data to train the GAN model. While considering all\nthree hierarchies, we develop multiscale and recurrent training approaches to\noptimize the image and video enhancement process in a weakly-supervised manner.\nBoth quantitative and qualitative results clearly demonstrate that the proposed\nDACAL achieves the state-of-the-art performance for high-resolution image and\nvideo enhancement.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 11:00:51 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Huang", "Zhiwu", ""], ["Paudel", "Danda Pani", ""], ["Li", "Guanju", ""], ["Wu", "Jiqing", ""], ["Timofte", "Radu", ""], ["Van Gool", "Luc", ""]]}, {"id": "1910.10479", "submitter": "Yong-Siang Shih", "authors": "Yong-Siang Shih, Wei-Cheng Chang, Yiming Yang", "title": "XL-Editor: Post-editing Sentences with XLNet", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural sequence generation models achieve initial success for many NLP\napplications, the canonical decoding procedure with left-to-right generation\norder (i.e., autoregressive) in one-pass can not reflect the true nature of\nhuman revising a sentence to obtain a refined result. In this work, we propose\nXL-Editor, a novel training framework that enables state-of-the-art generalized\nautoregressive pretraining methods, XLNet specifically, to revise a given\nsentence by the variable-length insertion probability. Concretely, XL-Editor\ncan (1) estimate the probability of inserting a variable-length sequence into a\nspecific position of a given sentence; (2) execute post-editing operations such\nas insertion, deletion, and replacement based on the estimated variable-length\ninsertion probability; (3) complement existing sequence-to-sequence models to\nrefine the generated sequences. Empirically, we first demonstrate better\npost-editing capabilities of XL-Editor over XLNet on the text insertion and\ndeletion tasks, which validates the effectiveness of our proposed framework.\nFurthermore, we extend XL-Editor to the unpaired text style transfer task,\nwhere transferring the target style onto a given sentence can be naturally\nviewed as post-editing the sentence into the target style. XL-Editor achieves\nsignificant improvement in style transfer accuracy and also maintains coherent\nsemantic of the original sentence, showing the broad applicability of our\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 21:39:03 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Shih", "Yong-Siang", ""], ["Chang", "Wei-Cheng", ""], ["Yang", "Yiming", ""]]}, {"id": "1910.10485", "submitter": "Gabriele Prato", "authors": "Gabriele Prato, Ella Charlaix, Mehdi Rezagholizadeh", "title": "Fully Quantized Transformer for Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art neural machine translation methods employ massive amounts of\nparameters. Drastically reducing computational costs of such methods without\naffecting performance has been up to this point unsuccessful. To this end, we\npropose FullyQT: an all-inclusive quantization strategy for the Transformer. To\nthe best of our knowledge, we are the first to show that it is possible to\navoid any loss in translation quality with a fully quantized Transformer.\nIndeed, compared to full-precision, our 8-bit models score greater or equal\nBLEU on most tasks. Comparing ourselves to all previously proposed methods, we\nachieve state-of-the-art quantization results.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 01:29:12 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 22:44:17 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 19:06:55 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Prato", "Gabriele", ""], ["Charlaix", "Ella", ""], ["Rezagholizadeh", "Mehdi", ""]]}, {"id": "1910.10487", "submitter": "David Donahue", "authors": "David Donahue, Yuanliang Meng, Anna Rumshisky", "title": "Memory-Augmented Recurrent Networks for Dialogue Coherence", "comments": "Honors project, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent dialogue approaches operate by reading each word in a conversation\nhistory, and aggregating accrued dialogue information into a single state. This\nfixed-size vector is not expandable and must maintain a consistent format over\ntime. Other recent approaches exploit an attention mechanism to extract useful\ninformation from past conversational utterances, but this introduces an\nincreased computational complexity. In this work, we explore the use of the\nNeural Turing Machine (NTM) to provide a more permanent and flexible storage\nmechanism for maintaining dialogue coherence. Specifically, we introduce two\nseparate dialogue architectures based on this NTM design. The first design\nfeatures a sequence-to-sequence architecture with two separate NTM modules, one\nfor each participant in the conversation. The second memory architecture\nincorporates a single NTM module, which stores parallel context information for\nboth speakers. This second design also replaces the sequence-to-sequence\narchitecture with a neural language model, to allow for longer context of the\nNTM and greater understanding of the dialogue history. We report perplexity\nperformance for both models, and compare them to existing baselines.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:59:33 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Donahue", "David", ""], ["Meng", "Yuanliang", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1910.10488", "submitter": "David Donahue", "authors": "David Donahue, Vladislav Lialin, Anna Rumshisky", "title": "Injecting Hierarchy with U-Net Transformers", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer architecture has become increasingly popular over the past\ntwo years, owing to its impressive performance on a number of natural language\nprocessing (NLP) tasks. However, all Transformer computations occur at the\nlevel of word representations and therefore, it may be argued that Transformer\nmodels do not explicitly attempt to learn hierarchical structure which is\nwidely assumed to be integral to language. In the present work, we introduce\nhierarchical processing into the Transformer model, taking inspiration from the\nU-Net architecture, popular in computer vision for its hierarchical view of\nnatural images. We empirically demonstrate that the proposed architecture\noutperforms both the vanilla Transformer and some strong baselines in the\ndomain of chit-chat dialogue.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:48:46 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 19:41:09 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Donahue", "David", ""], ["Lialin", "Vladislav", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1910.10490", "submitter": "Janyl Jumadinova", "authors": "Xingbang Liu and Janyl Jumadinova", "title": "Automated Text Summarization for the Enhancement of Public Services", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Natural language processing and machine learning algorithms have been shown\nto be effective in a variety of applications. In this work, we contribute to\nthe area of AI adoption in the public sector. We present an automated system\nthat was used to process textual information, generate important keywords, and\nautomatically summarize key elements of the Meadville community statements. We\nalso describe the process of collaboration with My Meadville administrators\nduring the development of our system. My Meadville, a community initiative,\nsupported by the city of Meadville conducted a large number of interviews with\nthe residents of Meadville during the community events and transcribed these\ninterviews into textual data files. Their goal was to uncover the issues of\nimportance to the Meadville residents in an attempt to enhance public services.\nOur AI system cleans and pre-processes the interview data, then using machine\nlearning algorithms it finds important keywords and key excerpts from each\ninterview. It also provides searching functionality to find excerpts from\nrelevant interviews based on specific keywords. Our automated system allowed\nthe city to save over 300 hours of human labor that would have taken to read\nall interviews and highlight important points. Our findings are being used by\nMy Meadville initiative to locate important information from the collected data\nset for ongoing community enhancement projects, to highlight relevant community\nassets, and to assist in identifying the steps to be taken based on the\nconcerns and areas of improvement identified by the community members.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 13:55:02 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Liu", "Xingbang", ""], ["Jumadinova", "Janyl", ""]]}, {"id": "1910.10491", "submitter": "Rajhersh Patel", "authors": "Raj Patel, Carlotta Domeniconi", "title": "Estimator Vectors: OOV Word Embeddings based on Subword and Context Clue\n  Estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic representations of words have been successfully extracted from\nunlabeled corpuses using neural network models like word2vec. These\nrepresentations are generally high quality and are computationally inexpensive\nto train, making them popular. However, these approaches generally fail to\napproximate out of vocabulary (OOV) words, a task humans can do quite easily,\nusing word roots and context clues. This paper proposes a neural network model\nthat learns high quality word representations, subword representations, and\ncontext clue representations jointly. Learning all three types of\nrepresentations together enhances the learning of each, leading to enriched\nword vectors, along with strong estimates for OOV words, via the combination of\nthe corresponding context clue and subword embeddings. Our model, called\nEstimator Vectors (EV), learns strong word embeddings and is competitive with\nstate of the art methods for OOV estimation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 06:17:07 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Patel", "Raj", ""], ["Domeniconi", "Carlotta", ""]]}, {"id": "1910.10495", "submitter": "Junhua Liu", "authors": "Junhua Liu, Yung Chuen Ng, Kristin L. Wood, Kwan Hui Lim", "title": "IPOD: An Industrial and Professional Occupations Dataset and its\n  Applications to Occupational Data Mining and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Occupational data mining and analysis is an important task in understanding\ntoday's industry and job market. Various machine learning techniques are\nproposed and gradually deployed to improve companies' operations for upstream\ntasks, such as employee churn prediction, career trajectory modelling and\nautomated interview. Job titles analysis and embedding, as the fundamental\nbuilding blocks, are crucial upstream tasks to address these occupational data\nmining and analysis problems. In this work, we present the Industrial and\nProfessional Occupations Dataset (IPOD), which consists of over 190,000 job\ntitles crawled from over 56,000 profiles from Linkedin. We also illustrate the\nusefulness of IPOD by addressing two challenging upstream tasks, including: (i)\nproposing Title2vec, a contextual job title vector representation using a\nbidirectional Language Model (biLM) approach; and (ii) addressing the important\noccupational Named Entity Recognition problem using Conditional Random Fields\n(CRF) and bidirectional Long Short-Term Memory with CRF (LSTM-CRF). Both CRF\nand LSTM-CRF outperform human and baselines in both exact-match accuracy and F1\nscores. The dataset and pre-trained embeddings are available at\nhttps://www.github.com/junhua/ipod.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 08:30:26 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 16:50:11 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Liu", "Junhua", ""], ["Ng", "Yung Chuen", ""], ["Wood", "Kristin L.", ""], ["Lim", "Kwan Hui", ""]]}, {"id": "1910.10502", "submitter": "Maaike De Boer", "authors": "Hella Haanstra and Maaike H. T. de Boer", "title": "Opinion aspect extraction in Dutch childrens diary entries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect extraction can be used in dialogue systems to understand the topic of\nopinionated text. Expressing an empathetic reaction to an opinion can\nstrengthen the bond between a human and, for example, a robot. The aim of this\nstudy is three-fold: 1. create a new annotated dataset for both aspect\nextraction and opinion words for Dutch childrens language, 2. acquire aspect\nextraction results for this task and 3. improve current results for aspect\nextraction in Dutch reviews. This was done by training a deep learning Gated\nRecurrent Unit (GRU) model, originally developed for an English review dataset,\non Dutch restaurant review data to classify both opinion words and their\nrespective aspects. We obtained state-of-the-art performance on the Dutch\nrestaurant review dataset. Additionally, we acquired aspect extraction results\nfor the Dutch childrens dataset. Since the model was trained on standardised\nlanguage, these results are quite promising.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 09:33:09 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Haanstra", "Hella", ""], ["de Boer", "Maaike H. T.", ""]]}, {"id": "1910.10508", "submitter": "Kim Albertsson", "authors": "Kim Albertsson, Federico Meloni", "title": "Towards Fast Displaced Vertex Finding", "comments": "Poster presentation at Connecting the Dots and Workshop on\n  Intelligent Tracker (CTD/WIT 2019). 4 pages. 3 figures. 2 tables", "journal-ref": null, "doi": null, "report-no": "PROC-CTD19-014", "categories": "physics.ins-det cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Standard Model extensions predict metastable massive particles that can\nbe detected by looking for displaced decay vertices in the inner detector\nvolume. Current approaches to search for these events in high-energy particle\ncollisions rely on the presence of additional energetic signatures to make an\nonline selection during data-taking, as the reconstruction of displaced\nvertices is computationally intensive. Enabling trigger-level reconstruction of\ndisplaced vertices could significantly enhance the reach of such searches.\n  This work is a first step approximating the location of the primary vertex in\nan idealised detector geometry using a 4-layer dense neural networks for\nregression of the vertex location yielding a precision of $O(1\\ \\mathrm{mm})$\n[$O(20\\ \\mathrm{mm})$] RMS in a low [high] track multiplicity environment.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 12:06:09 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Albertsson", "Kim", ""], ["Meloni", "Federico", ""]]}, {"id": "1910.10513", "submitter": "Puning Zhao", "authors": "Puning Zhao, Lifeng Lai", "title": "Minimax Rate Optimal Adaptive Nearest Neighbor Classification and\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  k Nearest Neighbor (kNN) method is a simple and popular statistical method\nfor classification and regression. For both classification and regression\nproblems, existing works have shown that, if the distribution of the feature\nvector has bounded support and the probability density function is bounded away\nfrom zero in its support, the convergence rate of the standard kNN method, in\nwhich k is the same for all test samples, is minimax optimal. On the contrary,\nif the distribution has unbounded support, we show that there is a gap between\nthe convergence rate achieved by the standard kNN method and the minimax bound.\nTo close this gap, we propose an adaptive kNN method, in which different k is\nselected for different samples. Our selection rule does not require precise\nknowledge of the underlying distribution of features. The new proposed method\nsignificantly outperforms the standard one. We characterize the convergence\nrate of the proposed adaptive method, and show that it matches the minimax\nlower bound.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:56:53 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Zhao", "Puning", ""], ["Lai", "Lifeng", ""]]}, {"id": "1910.10528", "submitter": "Ivan Homoliak", "authors": "Ivan Homoliak and Petr Hanacek", "title": "ASNM Datasets: A Collection of Network Traffic Features for Testing of\n  Adversarial Classifiers and Network Intrusion Detectors", "comments": null, "journal-ref": "IEEE Access-2020", "doi": "10.1109/ACCESS.2020.3001768", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present three datasets that have been built from network\ntraffic traces using ASNM features, designed in our previous work. The first\ndataset was built using a state-of-the-art dataset called CDX 2009, while the\nremaining two datasets were collected by us in 2015 and 2018, respectively.\nThese two datasets contain several adversarial obfuscation techniques that were\napplied onto malicious as well as legitimate traffic samples during the\nexecution of particular TCP network connections. Adversarial obfuscation\ntechniques were used for evading machine learning-based network intrusion\ndetection classifiers. Further, we showed that the performance of such\nclassifiers can be improved when partially augmenting their training data by\nsamples obtained from obfuscation techniques. In detail, we utilized tunneling\nobfuscation in HTTP(S) protocol and non-payload-based obfuscations modifying\nvarious properties of network traffic by, e.g., TCP segmentation,\nre-transmissions, corrupting and reordering of packets, etc. To the best of our\nknowledge, this is the first collection of network traffic metadata that\ncontains adversarial techniques and is intended for non-payload-based network\nintrusion detection and adversarial classification. Provided datasets enable\ntesting of the evasion resistance of arbitrary classifier that is using ASNM\nfeatures.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 12:44:31 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Homoliak", "Ivan", ""], ["Hanacek", "Petr", ""]]}, {"id": "1910.10536", "submitter": "Marc Ru{\\ss}wurm", "authors": "Marc Ru{\\ss}wurm, Marco K\\\"orner", "title": "Self-attention for raw optical Satellite Time Series Classification", "comments": null, "journal-ref": "ISPRS Journal of Photogrammetry and Remote Sensing, Volume 169,\n  November 2020, Pages 421-435", "doi": "10.1016/j.isprsjprs.2020.06.006", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The amount of available Earth observation data has increased dramatically in\nthe recent years. Efficiently making use of the entire body information is a\ncurrent challenge in remote sensing and demands for light-weight\nproblem-agnostic models that do not require region- or problem-specific expert\nknowledge. End-to-end trained deep learning models can make use of raw sensory\ndata by learning feature extraction and classification in one step solely from\ndata. Still, many methods proposed in remote sensing research require implicit\nfeature extraction through data preprocessing or explicit design of features.\n  In this work, we compare recent deep learning models on crop type\nclassification on raw and preprocessed Sentinel 2 data. We concentrate on the\ncommon neural network architectures for time series, i.e., 1D-convolutions,\nrecurrence, a shallow random forest baseline, and focus on the novel\nself-attention architecture. Our central findings are that data preprocessing\nstill increased the overall classification performance for all models while the\nchoice of model was less crucial. Self-attention and recurrent neural networks,\nby their architecture, outperformed convolutional neural networks on raw\nsatellite time series. We explore this by a feature importance analysis based\non gradient back-propagation that exploits the differentiable nature of deep\nlearning models. Further, we qualitatively show how self-attention scores focus\nselectively on few classification-relevant observations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 12:56:16 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 15:25:48 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 12:04:50 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Ru\u00dfwurm", "Marc", ""], ["K\u00f6rner", "Marco", ""]]}, {"id": "1910.10537", "submitter": "William Clements", "authors": "Reda Bahi Slaoui, William R. Clements, Jakob N. Foerster, S\\'ebastien\n  Toth", "title": "Robust Visual Domain Randomization for Reinforcement Learning", "comments": "Accepted at the BeTR-RL Workshop at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Producing agents that can generalize to a wide range of visually different\nenvironments is a significant challenge in reinforcement learning. One method\nfor overcoming this issue is visual domain randomization, whereby at the start\nof each training episode some visual aspects of the environment are randomized\nso that the agent is exposed to many possible variations. However, domain\nrandomization is highly inefficient and may lead to policies with high variance\nacross domains. Instead, we propose a regularization method whereby the agent\nis only trained on one variation of the environment, and its learned state\nrepresentations are regularized during training to be invariant across domains.\nWe conduct experiments that demonstrate that our technique leads to more\nefficient and robust learning than standard domain randomization, while\nachieving equal generalization scores.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 12:58:08 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 09:11:04 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Slaoui", "Reda Bahi", ""], ["Clements", "William R.", ""], ["Foerster", "Jakob N.", ""], ["Toth", "S\u00e9bastien", ""]]}, {"id": "1910.10563", "submitter": "Fabio Pizzati", "authors": "Fabio Pizzati, Raoul de Charette, Michela Zaccaria, Pietro Cerri", "title": "Domain Bridge for Unpaired Image-to-Image Translation and Unsupervised\n  Domain Adaptation", "comments": "WACV 20 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image-to-image translation architectures may have limited effectiveness in\nsome circumstances. For example, while generating rainy scenarios, they may\nfail to model typical traits of rain as water drops, and this ultimately\nimpacts the synthetic images realism. With our method, called domain bridge,\nweb-crawled data are exploited to reduce the domain gap, leading to the\ninclusion of previously ignored elements in the generated images. We make use\nof a network for clear to rain translation trained with the domain bridge to\nextend our work to Unsupervised Domain Adaptation (UDA). In that context, we\nintroduce an online multimodal style-sampling strategy, where image translation\nmultimodality is exploited at training time to improve performances. Finally, a\nnovel approach for self-supervised learning is presented, and used to further\nalign the domains. With our contributions, we simultaneously increase the\nrealism of the generated images, while reaching on par performances with\nrespect to the UDA state-of-the-art, with a simpler approach.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 13:51:40 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 12:40:19 GMT"}, {"version": "v3", "created": "Sat, 14 Mar 2020 16:18:04 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Pizzati", "Fabio", ""], ["de Charette", "Raoul", ""], ["Zaccaria", "Michela", ""], ["Cerri", "Pietro", ""]]}, {"id": "1910.10566", "submitter": "Sophie Giffard-Roisin", "authors": "Sophie Giffard-Roisin, Mo Yang, Guillaume Charpiat, Christina\n  Kumler-Bonfanti, Bal\\'azs K\\'egl and Claire Monteleoni", "title": "Tropical Cyclone Track Forecasting using Fused Deep Learning from\n  Aligned Reanalysis Data", "comments": null, "journal-ref": null, "doi": "10.3389/fdata.2020.00001", "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The forecast of tropical cyclone trajectories is crucial for the protection\nof people and property. Although forecast dynamical models can provide\nhigh-precision short-term forecasts, they are computationally demanding, and\ncurrent statistical forecasting models have much room for improvement given\nthat the database of past hurricanes is constantly growing. Machine learning\nmethods, that can capture non-linearities and complex relations, have only been\nscarcely tested for this application. We propose a neural network model fusing\npast trajectory data and reanalysis atmospheric images (wind and pressure 3D\nfields). We use a moving frame of reference that follows the storm center for\nthe 24h tracking forecast. The network is trained to estimate the longitude and\nlatitude displacement of tropical cyclones and depressions from a large\ndatabase from both hemispheres (more than 3000 storms since 1979, sampled at a\n6 hour frequency). The advantage of the fused network is demonstrated and a\ncomparison with current forecast models shows that deep learning methods could\nprovide a valuable and complementary prediction. Moreover, our method can give\na forecast for a new storm in a few seconds, which is an important asset for\nreal-time forecasts compared to traditional forecasts.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 13:56:23 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 09:03:59 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Giffard-Roisin", "Sophie", ""], ["Yang", "Mo", ""], ["Charpiat", "Guillaume", ""], ["Kumler-Bonfanti", "Christina", ""], ["K\u00e9gl", "Bal\u00e1zs", ""], ["Monteleoni", "Claire", ""]]}, {"id": "1910.10579", "submitter": "Richard Preen", "authors": "Richard J. Preen and Stewart W. Wilson and Larry Bull", "title": "Autoencoding with a Classifier System", "comments": null, "journal-ref": "IEEE Transactions on Evolutionary Computation (2021)", "doi": "10.1109/TEVC.2021.3079320", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders are data-specific compression algorithms learned automatically\nfrom examples. The predominant approach has been to construct single large\nglobal models that cover the domain. However, training and evaluating models of\nincreasing size comes at the price of additional time and computational cost.\nConditional computation, sparsity, and model pruning techniques can reduce\nthese costs while maintaining performance. Learning classifier systems (LCS)\nare a framework for adaptively subdividing input spaces into an ensemble of\nsimpler local approximations that together cover the domain. LCS perform\nconditional computation through the use of a population of individual\ngating/guarding components, each associated with a local approximation. This\narticle explores the use of an LCS to adaptively decompose the input domain\ninto a collection of small autoencoders where local solutions of different\ncomplexity may emerge. In addition to benefits in convergence time and\ncomputational cost, it is shown possible to reduce code size as well as the\nresulting decoder computational cost when compared with the global model\nequivalent.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 14:27:29 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 17:51:44 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 10:09:48 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 14:32:16 GMT"}, {"version": "v5", "created": "Tue, 27 Oct 2020 17:55:15 GMT"}, {"version": "v6", "created": "Mon, 2 Nov 2020 09:59:31 GMT"}, {"version": "v7", "created": "Thu, 25 Feb 2021 16:14:08 GMT"}, {"version": "v8", "created": "Wed, 12 May 2021 13:20:17 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Preen", "Richard J.", ""], ["Wilson", "Stewart W.", ""], ["Bull", "Larry", ""]]}, {"id": "1910.10583", "submitter": "Soroosh Shafieezadeh-Abadeh", "authors": "Viet Anh Nguyen, Soroosh Shafieezadeh-Abadeh, Man-Chung Yue, Daniel\n  Kuhn, Wolfram Wiesemann", "title": "Optimistic Distributionally Robust Optimization for Nonparametric\n  Likelihood Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The likelihood function is a fundamental component in Bayesian statistics.\nHowever, evaluating the likelihood of an observation is computationally\nintractable in many applications. In this paper, we propose a non-parametric\napproximation of the likelihood that identifies a probability measure which\nlies in the neighborhood of the nominal measure and that maximizes the\nprobability of observing the given sample point. We show that when the\nneighborhood is constructed by the Kullback-Leibler divergence, by moment\nconditions or by the Wasserstein distance, then our \\textit{optimistic\nlikelihood} can be determined through the solution of a convex optimization\nproblem, and it admits an analytical expression in particular cases. We also\nshow that the posterior inference problem with our optimistic likelihood\napproximation enjoys strong theoretical performance guarantees, and it performs\ncompetitively in a probabilistic classification task.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 14:34:40 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Nguyen", "Viet Anh", ""], ["Shafieezadeh-Abadeh", "Soroosh", ""], ["Yue", "Man-Chung", ""], ["Kuhn", "Daniel", ""], ["Wiesemann", "Wolfram", ""]]}, {"id": "1910.10593", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Rex Ying, Matilde Padovano, Raia Hadsell,\n  Charles Blundell", "title": "Neural Execution of Graph Algorithms", "comments": "To appear at ICLR 2020. 13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are a powerful representational tool for solving\nproblems on graph-structured inputs. In almost all cases so far, however, they\nhave been applied to directly recovering a final solution from raw inputs,\nwithout explicit guidance on how to structure their problem-solving. Here,\ninstead, we focus on learning in the space of algorithms: we train several\nstate-of-the-art GNN architectures to imitate individual steps of classical\ngraph algorithms, parallel (breadth-first search, Bellman-Ford) as well as\nsequential (Prim's algorithm). As graph algorithms usually rely on making\ndiscrete decisions within neighbourhoods, we hypothesise that\nmaximisation-based message passing neural networks are best-suited for such\nobjectives, and validate this claim empirically. We also demonstrate how\nlearning in the space of algorithms can yield new opportunities for positive\ntransfer between tasks---showing how learning a shortest-path algorithm can be\nsubstantially improved when simultaneously learning a reachability algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 14:50:45 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 16:47:33 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Ying", "Rex", ""], ["Padovano", "Matilde", ""], ["Hadsell", "Raia", ""], ["Blundell", "Charles", ""]]}, {"id": "1910.10596", "submitter": "Jiaxin Shi", "authors": "Jiaxin Shi, Michalis K. Titsias, Andriy Mnih", "title": "Sparse Orthogonal Variational Inference for Gaussian Processes", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new interpretation of sparse variational approximations for\nGaussian processes using inducing points, which can lead to more scalable\nalgorithms than previous methods. It is based on decomposing a Gaussian process\nas a sum of two independent processes: one spanned by a finite basis of\ninducing points and the other capturing the remaining variation. We show that\nthis formulation recovers existing approximations and at the same time allows\nto obtain tighter lower bounds on the marginal likelihood and new stochastic\nvariational inference algorithms. We demonstrate the efficiency of these\nalgorithms in several Gaussian process models ranging from standard regression\nto multi-class classification using (deep) convolutional Gaussian processes and\nreport state-of-the-art results on CIFAR-10 among purely GP-based models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:01:28 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 16:08:41 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 15:47:20 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Shi", "Jiaxin", ""], ["Titsias", "Michalis K.", ""], ["Mnih", "Andriy", ""]]}, {"id": "1910.10597", "submitter": "Aditya Modi", "authors": "Aditya Modi, Nan Jiang, Ambuj Tewari, Satinder Singh", "title": "Sample Complexity of Reinforcement Learning using Linearly Combined\n  Model Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) methods have been shown to be capable of learning\nintelligent behavior in rich domains. However, this has largely been done in\nsimulated domains without adequate focus on the process of building the\nsimulator. In this paper, we consider a setting where we have access to an\nensemble of pre-trained and possibly inaccurate simulators (models). We\napproximate the real environment using a state-dependent linear combination of\nthe ensemble, where the coefficients are determined by the given state features\nand some unknown parameters. Our proposed algorithm provably learns a\nnear-optimal policy with a sample complexity polynomial in the number of\nunknown parameters, and incurs no dependence on the size of the state (or\naction) space. As an extension, we also consider the more challenging problem\nof model selection, where the state features are unknown and can be chosen from\na large candidate set. We provide exponential lower bounds that illustrate the\nfundamental hardness of this problem, and develop a provably efficient\nalgorithm under additional natural assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:02:30 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Modi", "Aditya", ""], ["Jiang", "Nan", ""], ["Tewari", "Ambuj", ""], ["Singh", "Satinder", ""]]}, {"id": "1910.10605", "submitter": "Ondrej Klejch", "authors": "Ond\\v{r}ej Klejch, Joachim Fainberg, Peter Bell, Steve Renals", "title": "Speaker Adaptive Training using Model Agnostic Meta-Learning", "comments": "Accepted to IEEE ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker adaptive training (SAT) of neural network acoustic models learns\nmodels in a way that makes them more suitable for adaptation to test\nconditions. Conventionally, model-based speaker adaptive training is performed\nby having a set of speaker dependent parameters that are jointly optimised with\nspeaker independent parameters in order to remove speaker variation. However,\nthis does not scale well if all neural network weights are to be adapted to the\nspeaker. In this paper we formulate speaker adaptive training as a\nmeta-learning task, in which an adaptation process using gradient descent is\nencoded directly into the training of the model. We compare our approach with\ntest-only adaptation of a standard baseline model and a SAT-LHUC model with a\nlearned speaker adaptation schedule and demonstrate that the meta-learning\napproach achieves comparable results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:22:22 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Klejch", "Ond\u0159ej", ""], ["Fainberg", "Joachim", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "1910.10620", "submitter": "Luckeciano Melo", "authors": "Luckeciano C. Melo and Marcos R. O. A. Maximo", "title": "Learning Humanoid Robot Running Skills through Proximal Policy\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current level of evolution of Soccer 3D, motion control is a key\nfactor in team's performance. Recent works takes advantages of model-free\napproaches based on Machine Learning to exploit robot dynamics in order to\nobtain faster locomotion skills, achieving running policies and, therefore,\nopening a new research direction in the Soccer 3D environment.\n  In this work, we present a methodology based on Deep Reinforcement Learning\nthat learns running skills without any prior knowledge, using a neural network\nwhose inputs are related to robot's dynamics. Our results outperformed the\nprevious state-of-the-art sprint velocity reported in Soccer 3D literature by a\nsignificant margin. It also demonstrated improvement in sample efficiency,\nbeing able to learn how to run in just few hours.\n  We reported our results analyzing the training procedure and also evaluating\nthe policies in terms of speed, reliability and human similarity. Finally, we\npresented key factors that lead us to improve previous results and shared some\nideas for future work.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 13:08:11 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Melo", "Luckeciano C.", ""], ["Maximo", "Marcos R. O. A.", ""]]}, {"id": "1910.10628", "submitter": "Nishanth Kumar", "authors": "Jonathan Chang, Nishanth Kumar, Sean Hastings, Aaron Gokaslan, Diego\n  Romeres, Devesh Jha, Daniel Nikovski, George Konidaris and Stefanie Tellex", "title": "Learning Deep Parameterized Skills from Demonstration for Re-targetable\n  Visuomotor Control", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robots need to learn skills that can not only generalize across similar\nproblems but also be directed to a specific goal. Previous methods either train\na new skill for every different goal or do not infer the specific target in the\npresence of multiple goals from visual data. We introduce an end-to-end method\nthat represents targetable visuomotor skills as a goal-parameterized neural\nnetwork policy. By training on an informative subset of available goals with\nthe associated target parameters, we are able to learn a policy that can\nzero-shot generalize to previously unseen goals. We evaluate our method in a\nrepresentative 2D simulation of a button-grid and on both button-pressing and\npeg-insertion tasks on two different physical arms. We demonstrate that our\nmodel trained on 33% of the possible goals is able to generalize to more than\n90% of the targets in the scene for both simulation and robot experiments. We\nalso successfully learn a mapping from target pixel coordinates to a robot\npolicy to complete a specified goal.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:54:32 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 23:31:58 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Chang", "Jonathan", ""], ["Kumar", "Nishanth", ""], ["Hastings", "Sean", ""], ["Gokaslan", "Aaron", ""], ["Romeres", "Diego", ""], ["Jha", "Devesh", ""], ["Nikovski", "Daniel", ""], ["Konidaris", "George", ""], ["Tellex", "Stefanie", ""]]}, {"id": "1910.10651", "submitter": "Ruth Fong", "authors": "Ruth Fong, Andrea Vedaldi", "title": "Occlusions for Effective Data Augmentation in Image Classification", "comments": "Accepted to 2019 ICCV Workshop on Interpreting and Explaining Visual\n  Artificial Intelligence Models (v2: corrected references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks for visual recognition are known to leverage \"easy to\nrecognise\" portions of objects such as faces and distinctive texture patterns.\nThe lack of a holistic understanding of objects may increase fragility and\noverfitting. In recent years, several papers have proposed to address this\nissue by means of occlusions as a form of data augmentation. However, successes\nhave been limited to tasks such as weak localization and model interpretation,\nbut no benefit was demonstrated on image classification on large-scale\ndatasets. In this paper, we show that, by using a simple technique based on\nbatch augmentation, occlusions as data augmentation can result in better\nperformance on ImageNet for high-capacity models (e.g., ResNet50). We also show\nthat varying amounts of occlusions used during training can be used to study\nthe robustness of different neural network architectures.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 16:19:22 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 15:25:57 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Fong", "Ruth", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1910.10660", "submitter": "Nikola Milo\\v{s}evi\\'c Dr", "authors": "Nikola Milosevic, Junfan Huang", "title": "Deep learning guided Android malware and anomaly detection", "comments": "First (draft) version of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past decade, the cyber-crime related to mobile devices has increased.\nMobile devices, especially the ones running on Android operating system are\nparticularly interesting to malware creators, as the users often keep the\nbiggest amount of personal information on their mobile devices, such as their\ncontacts, social media profiles, emails, and bank accounts. Both dynamic and\nstatic malware analysis is necessary to prevent and detect malware, as both\ntechniques have their benefits and shortcomings. In this paper, we propose a\ndeep learning technique that relies on LSTM and encoder-decoder neural network\narchitectures for dynamic malware analysis based on CPU, memory and battery\nusage. The proposed system is able to detect and notify users about anomalies\nin system that is likely consequence of malware behaviour. The method was\nimplemented as a part of OWASP Seraphimdroids anti-malware mechanism and\nnotifies users about anomalies on their devices. The method proved to perform\nwith an F1-score of 79.2%.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 16:34:41 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Milosevic", "Nikola", ""], ["Huang", "Junfan", ""]]}, {"id": "1910.10666", "submitter": "Jinming Xu", "authors": "Jinming Xu, Ye Tian, Ying Sun, Gesualdo Scutari", "title": "Accelerated Primal-Dual Algorithms for Distributed Smooth Convex\n  Optimization over Networks", "comments": "final version for AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel family of primal-dual-based distributed\nalgorithms for smooth, convex, multi-agent optimization over networks that uses\nonly gradient information and gossip communications. The algorithms can also\nemploy acceleration on the computation and communications. We provide a unified\nanalysis of their convergence rate, measured in terms of the Bregman distance\nassociated to the saddle point reformation of the distributed optimization\nproblem. When acceleration is employed, the rate is shown to be optimal, in the\nsense that it matches (under the proposed metric) existing complexity lower\nbounds of distributed algorithms applicable to such a class of problem and\nusing only gradient information and gossip communications. Preliminary\nnumerical results on distributed least-square regression problems show that the\nproposed algorithm compares favorably on existing distributed schemes.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:05:00 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 01:15:54 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Xu", "Jinming", ""], ["Tian", "Ye", ""], ["Sun", "Ying", ""], ["Scutari", "Gesualdo", ""]]}, {"id": "1910.10670", "submitter": "Jun Liu", "authors": "Jun Liu, Jiedan Zhu, Vishal Kathuria, Fuchun Peng", "title": "Efficient Dynamic WFST Decoding for Personalized Language Models", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a two-layer cache mechanism to speed up dynamic WFST decoding with\npersonalized language models. The first layer is a public cache that stores\nmost of the static part of the graph. This is shared globally among all users.\nA second layer is a private cache that caches the graph that represents the\npersonalized language model, which is only shared by the utterances from a\nparticular user. We also propose two simple yet effective pre-initialization\nmethods, one based on breadth-first search, and another based on a data-driven\nexploration of decoder states using previous utterances. Experiments with a\ncalling speech recognition task using a personalized contact list demonstrate\nthat the proposed public cache reduces decoding time by factor of three\ncompared to decoding without pre-initialization. Using the private cache\nprovides additional efficiency gains, reducing the decoding time by a factor of\nfive.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:10:26 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Liu", "Jun", ""], ["Zhu", "Jiedan", ""], ["Kathuria", "Vishal", ""], ["Peng", "Fuchun", ""]]}, {"id": "1910.10671", "submitter": "Ruizhi Li", "authors": "Ruizhi Li, Gregory Sell, Xiaofei Wang, Shinji Watanabe, Hynek\n  Hermansky", "title": "A practical two-stage training strategy for multi-stream end-to-end\n  speech recognition", "comments": "submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-stream paradigm of audio processing, in which several sources are\nsimultaneously considered, has been an active research area for information\nfusion. Our previous study offered a promising direction within end-to-end\nautomatic speech recognition, where parallel encoders aim to capture diverse\ninformation followed by a stream-level fusion based on attention mechanisms to\ncombine the different views. However, with an increasing number of streams\nresulting in an increasing number of encoders, the previous approach could\nrequire substantial memory and massive amounts of parallel data for joint\ntraining. In this work, we propose a practical two-stage training scheme.\nStage-1 is to train a Universal Feature Extractor (UFE), where encoder outputs\nare produced from a single-stream model trained with all data. Stage-2\nformulates a multi-stream scheme intending to solely train the attention fusion\nmodule using the UFE features and pretrained components from Stage-1.\nExperiments have been conducted on two datasets, DIRHA and AMI, as a\nmulti-stream scenario. Compared with our previous method, this strategy\nachieves relative word error rate reductions of 8.2--32.4%, while consistently\noutperforming several conventional combination methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:12:48 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Li", "Ruizhi", ""], ["Sell", "Gregory", ""], ["Wang", "Xiaofei", ""], ["Watanabe", "Shinji", ""], ["Hermansky", "Hynek", ""]]}, {"id": "1910.10672", "submitter": "Krishna Murthy Jatavallabhula", "authors": "Krishna Murthy Jatavallabhula, Soroush Saryazdi, Ganesh Iyer, Liam\n  Paull", "title": "gradSLAM: Automagically differentiable SLAM", "comments": "Video: https://youtu.be/2ygtSJTmo08 . Project page and code:\n  https://gradslam.github.io This tech report is an extended version of the\n  ICRA 2020 paper \"gradSLAM: Dense SLAM meets automatic differentiation\". The\n  first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blending representation learning approaches with simultaneous localization\nand mapping (SLAM) systems is an open question, because of their highly modular\nand complex nature. Functionally, SLAM is an operation that transforms raw\nsensor inputs into a distribution over the state(s) of the robot and the\nenvironment. If this transformation (SLAM) were expressible as a differentiable\nfunction, we could leverage task-based error signals to learn representations\nthat optimize task performance. However, several components of a typical dense\nSLAM system are non-differentiable. In this work, we propose gradSLAM, a\nmethodology for posing SLAM systems as differentiable computational graphs,\nwhich unifies gradient-based learning and SLAM. We propose differentiable\ntrust-region optimizers, surface measurement and fusion schemes, and\nraycasting, without sacrificing accuracy. This amalgamation of dense SLAM with\ncomputational graphs enables us to backprop all the way from 3D maps to 2D\npixels, opening up new possibilities in gradient-based learning for SLAM.\n  TL;DR: We leverage the power of automatic differentiation frameworks to make\ndense SLAM differentiable.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:13:41 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 18:55:05 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 18:53:59 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Jatavallabhula", "Krishna Murthy", ""], ["Saryazdi", "Soroush", ""], ["Iyer", "Ganesh", ""], ["Paull", "Liam", ""]]}, {"id": "1910.10679", "submitter": "Leslie Smith", "authors": "Leslie N. Smith", "title": "A Useful Taxonomy for Adversarial Robustness of Neural Networks", "comments": "NRL Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks and defenses are currently active areas of research for\nthe deep learning community. A recent review paper divided the defense\napproaches into three categories; gradient masking, robust optimization, and\nadversarial example detection. We divide gradient masking and robust\noptimization differently: (1) increasing intra-class compactness and\ninter-class separation of the feature vectors improves adversarial robustness,\nand (2) marginalization or removal of non-robust image features also improves\nadversarial robustness. By reframing these topics differently, we provide a\nfresh perspective that provides insight into the underlying factors that enable\ntraining more robust networks and can help inspire novel solutions. In\naddition, there are several papers in the literature of adversarial defenses\nthat claim there is a cost for adversarial robustness, or a trade-off between\nrobustness and accuracy but, under this proposed taxonomy, we hypothesis that\nthis is not universal. We follow up on our taxonomy with several challenges to\nthe deep learning research community that builds on the connections and\ninsights in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:33:15 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Smith", "Leslie N.", ""]]}, {"id": "1910.10682", "submitter": "Deepak Bhaskar Acharya", "authors": "Deepak Bhaskar Acharya, Dr. Huaming Zhang", "title": "Feature Selection and Extraction for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been a latest hot research topic in data\nscience, due to the fact that they use the ubiquitous data structure graphs as\nthe underlying elements for constructing and training neural networks. In a\nGNN, each node has numerous features associated with it. The entire task (for\nexample, classification, or clustering) utilizes the features of the nodes to\nmake decisions, at node level or graph level. In this paper, (1) we extend the\nfeature selection algorithm presented in via Gumbel Softmax to GNNs. We conduct\na series of experiments on our feature selection algorithms, using various\nbenchmark datasets: Cora, Citeseer and Pubmed. (2) We implement a mechanism to\nrank the extracted features. We demonstrate the effectiveness of our\nalgorithms, for both feature selection and ranking. For the Cora dataset, (1)\nwe use the algorithm to select 225 features out of 1433 features. Our\nexperimental results demonstrate their effectiveness for the same\nclassification problem. (2) We extract features such that they are linear\ncombinations of the original features, where the coefficients for each\nextracted features are non-negative and sum up to one. We propose an algorithm\nto rank the extracted features in the sense that when using them for the same\nclassification problem, the accuracy goes down gradually for the extracted\nfeatures within the rank 1 - 50, 51 - 100, 100 - 150, and 151 - 200.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:35:55 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 00:03:52 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Acharya", "Deepak Bhaskar", ""], ["Zhang", "Dr. Huaming", ""]]}, {"id": "1910.10683", "submitter": "Colin Raffel", "authors": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan\n  Narang, Michael Matena, Yanqi Zhou, Wei Li and Peter J. Liu", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text\n  Transformer", "comments": "Final version as published in JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning, where a model is first pre-trained on a data-rich task\nbefore being fine-tuned on a downstream task, has emerged as a powerful\ntechnique in natural language processing (NLP). The effectiveness of transfer\nlearning has given rise to a diversity of approaches, methodology, and\npractice. In this paper, we explore the landscape of transfer learning\ntechniques for NLP by introducing a unified framework that converts all\ntext-based language problems into a text-to-text format. Our systematic study\ncompares pre-training objectives, architectures, unlabeled data sets, transfer\napproaches, and other factors on dozens of language understanding tasks. By\ncombining the insights from our exploration with scale and our new ``Colossal\nClean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks\ncovering summarization, question answering, text classification, and more. To\nfacilitate future work on transfer learning for NLP, we release our data set,\npre-trained models, and code.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:37:36 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 15:13:50 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2020 13:10:01 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Raffel", "Colin", ""], ["Shazeer", "Noam", ""], ["Roberts", "Adam", ""], ["Lee", "Katherine", ""], ["Narang", "Sharan", ""], ["Matena", "Michael", ""], ["Zhou", "Yanqi", ""], ["Li", "Wei", ""], ["Liu", "Peter J.", ""]]}, {"id": "1910.10685", "submitter": "Jennifer Wei", "authors": "Benjamin Sanchez-Lengeling, Jennifer N. Wei, Brian K. Lee, Richard C.\n  Gerkin, Al\\'an Aspuru-Guzik, and Alexander B. Wiltschko", "title": "Machine Learning for Scent: Learning Generalizable Perceptual\n  Representations of Small Molecules", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the relationship between a molecule's structure and its odor\nremains a difficult, decades-old task. This problem, termed quantitative\nstructure-odor relationship (QSOR) modeling, is an important challenge in\nchemistry, impacting human nutrition, manufacture of synthetic fragrance, the\nenvironment, and sensory neuroscience. We propose the use of graph neural\nnetworks for QSOR, and show they significantly out-perform prior methods on a\nnovel data set labeled by olfactory experts. Additional analysis shows that the\nlearned embeddings from graph neural networks capture a meaningful odor space\nrepresentation of the underlying relationship between structure and odor, as\ndemonstrated by strong performance on two challenging transfer learning tasks.\nMachine learning has already had a large impact on the senses of sight and\nsound. Based on these early results with graph neural networks for molecular\nproperties, we hope machine learning can eventually do for olfaction what it\nhas already done for vision and hearing.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:38:47 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 17:57:31 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Sanchez-Lengeling", "Benjamin", ""], ["Wei", "Jennifer N.", ""], ["Lee", "Brian K.", ""], ["Gerkin", "Richard C.", ""], ["Aspuru-Guzik", "Al\u00e1n", ""], ["Wiltschko", "Alexander B.", ""]]}, {"id": "1910.10692", "submitter": "Yizhe Zhu", "authors": "Kameron Decker Harris, Yizhe Zhu", "title": "Deterministic tensor completion with hypergraph expanders", "comments": "35 pages, 4 figures. To appear in SIAM Journal on Mathematics of Data\n  Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel analysis of low-rank tensor completion based on hypergraph\nexpanders. As a proxy for rank, we minimize the max-quasinorm of the tensor,\nwhich generalizes the max-norm for matrices. Our analysis is deterministic and\nshows that the number of samples required to approximately recover an order-$t$\ntensor with at most $n$ entries per dimension is linear in $n$, under the\nassumption that the rank and order of the tensor are $O(1)$. As steps in our\nproof, we find a new expander mixing lemma for a $t$-partite, $t$-uniform\nregular hypergraph model, and prove several new properties about tensor\nmax-quasinorm. To the best of our knowledge, this is the first deterministic\nanalysis of tensor completion. We develop a practical algorithm that solves a\nrelaxed version of the max-quasinorm minimization problem, and we demonstrate\nits efficacy with numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:51:13 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 23:28:33 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 22:48:23 GMT"}, {"version": "v4", "created": "Thu, 29 Jul 2021 16:50:59 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Harris", "Kameron Decker", ""], ["Zhu", "Yizhe", ""]]}, {"id": "1910.10699", "submitter": "Yonglong Tian", "authors": "Yonglong Tian, Dilip Krishnan, Phillip Isola", "title": "Contrastive Representation Distillation", "comments": "ICLR 2020. Project Page: http://hobbitlong.github.io/CRD/, Code:\n  http://github.com/HobbitLong/RepDistiller", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Often we wish to transfer representational knowledge from one neural network\nto another. Examples include distilling a large network into a smaller one,\ntransferring knowledge from one sensory modality to a second, or ensembling a\ncollection of models into a single estimator. Knowledge distillation, the\nstandard approach to these problems, minimizes the KL divergence between the\nprobabilistic outputs of a teacher and student network. We demonstrate that\nthis objective ignores important structural knowledge of the teacher network.\nThis motivates an alternative objective by which we train a student to capture\nsignificantly more information in the teacher's representation of the data. We\nformulate this objective as contrastive learning. Experiments demonstrate that\nour resulting new objective outperforms knowledge distillation and other\ncutting-edge distillers on a variety of knowledge transfer tasks, including\nsingle model compression, ensemble distillation, and cross-modal transfer. Our\nmethod sets a new state-of-the-art in many transfer tasks, and sometimes even\noutperforms the teacher network when combined with knowledge distillation.\nCode: http://github.com/HobbitLong/RepDistiller.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:59:18 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 10:09:39 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Tian", "Yonglong", ""], ["Krishnan", "Dilip", ""], ["Isola", "Phillip", ""]]}, {"id": "1910.10702", "submitter": "Roopam Gupta", "authors": "Roopam K. Gupta, Graham D. Bruce, Simon J. Powis and Kishan Dholakia", "title": "Deep learning enabled laser speckle wavemeter with a high dynamic range", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": "10.1002/lpor.202000120", "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The speckle pattern produced when a laser is scattered by a disordered medium\nhas recently been shown to give a surprisingly accurate or broadband\nmeasurement of wavelength. Here it is shown that deep learning is an ideal\napproach to analyse wavelength variations using a speckle wavemeter due to its\nability to identify trends and overcome low signal to noise ratio in complex\ndatasets. This combination enables wavelength measurement at high precision\nover a broad operating range in a single step, with a remarkable capability to\nreject instrumental and environmental noise, which has not been possible with\nprevious approaches. It is demonstrated that the noise rejection capabilities\nof deep learning provide attometre-scale wavelength precision over an operating\nrange from 488 nm to 976 nm. This dynamic range is six orders of magnitude\nbeyond the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 09:24:20 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 13:42:35 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Gupta", "Roopam K.", ""], ["Bruce", "Graham D.", ""], ["Powis", "Simon J.", ""], ["Dholakia", "Kishan", ""]]}, {"id": "1910.10754", "submitter": "Heejin Jeong", "authors": "Heejin Jeong, Brent Schlotfeldt, Hamed Hassani, Manfred Morari, Daniel\n  D. Lee, George J. Pappas", "title": "Learning Q-network for Active Information Acquisition", "comments": "IROS 2019, Video https://youtu.be/0ZFyOWJ2ulo", "journal-ref": "IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel Reinforcement Learning approach for solving\nthe Active Information Acquisition problem, which requires an agent to choose a\nsequence of actions in order to acquire information about a process of interest\nusing on-board sensors. The classic challenges in the information acquisition\nproblem are the dependence of a planning algorithm on known models and the\ndifficulty of computing information-theoretic cost functions over arbitrary\ndistributions. In contrast, the proposed framework of reinforcement learning\ndoes not require any knowledge on models and alleviates the problems during an\nextended training stage. It results in policies that are efficient to execute\nonline and applicable for real-time control of robotic systems. Furthermore,\nthe state-of-the-art planning methods are typically restricted to short\nhorizons, which may become problematic with local minima. Reinforcement\nlearning naturally handles the issue of planning horizon in information\nproblems as it maximizes a discounted sum of rewards over a long finite or\ninfinite time horizon. We discuss the potential benefits of the proposed\nframework and compare the performance of the novel algorithm to an existing\ninformation acquisition method for multi-target tracking scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 18:21:16 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Jeong", "Heejin", ""], ["Schlotfeldt", "Brent", ""], ["Hassani", "Hamed", ""], ["Morari", "Manfred", ""], ["Lee", "Daniel D.", ""], ["Pappas", "George J.", ""]]}, {"id": "1910.10766", "submitter": "Kemal Davaslioglu", "authors": "Kemal Davaslioglu and Yalin E. Sagduyu", "title": "Trojan Attacks on Wireless Signal Classification with Adversarial\n  Machine Learning", "comments": "2019 - IEEE International Symposium on Dynamic Spectrum Access\n  Networks (DySPAN) Workshop on Data-Driven Dynamic Spectrum Sharing, 6 pages,\n  7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Trojan (backdoor or trapdoor) attack that targets deep learning\napplications in wireless communications. A deep learning classifier is\nconsidered to classify wireless signals using raw (I/Q) samples as features and\nmodulation types as labels. An adversary slightly manipulates training data by\ninserting Trojans (i.e., triggers) to only few training data samples by\nmodifying their phases and changing the labels of these samples to a target\nlabel. This poisoned training data is used to train the deep learning\nclassifier. In test (inference) time, an adversary transmits signals with the\nsame phase shift that was added as a trigger during training. While the\nreceiver can accurately classify clean (unpoisoned) signals without triggers,\nit cannot reliably classify signals poisoned with triggers. This stealth attack\nremains hidden until activated by poisoned inputs (Trojans) to bypass a signal\nclassifier (e.g., for authentication). We show that this attack is successful\nover different channel conditions and cannot be mitigated by simply\npreprocessing the training and test data with random phase variations. To\ndetect this attack, activation based outlier detection is considered with\nstatistical as well as clustering techniques. We show that the latter one can\ndetect Trojan attacks even if few samples are poisoned.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 18:47:30 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Davaslioglu", "Kemal", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "1910.10769", "submitter": "Blake Zimmerman", "authors": "Blake E. Zimmerman (1,2), Sara Johnson (2), Henrik Od\\'een (3), Jill\n  Shea (4), Markus D. Foote (1,2), Nicole Winkler (4), Sarang C. Joshi (1,2),\n  Allison Payne (3) ((1) Scientific Computing and Imaging Institute, University\n  of Utah, (2) Department of Biomedical Engineering, University of Utah, (3)\n  Department of Radiology and Imaging Sciences, University of Utah, (4)\n  Department of Surgery, University of Utah)", "title": "Learning Multiparametric Biomarkers for Assessing MR-Guided Focused\n  Ultrasound Treatment of Malignant Tumors", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": "10.1109/TBME.2020.3024826", "report-no": null, "categories": "eess.IV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noninvasive MR-guided focused ultrasound (MRgFUS) treatments are promising\nalternatives to the surgical removal of malignant tumors. A significant\nchallenge is assessing the viability of treated tissue during and immediately\nafter MRgFUS procedures. Current clinical assessment uses the nonperfused\nvolume (NPV) biomarker immediately after treatment from contrast-enhanced MRI.\nThe NPV has variable accuracy, and the use of contrast agent prevents\ncontinuing MRgFUS treatment if tumor coverage is inadequate. This work presents\na novel, noncontrast, learned multiparametric MR biomarker that can be used\nduring treatment for intratreatment assessment, validated in a VX2 rabbit tumor\nmodel. A deep convolutional neural network was trained on noncontrast\nmultiparametric MR images using the NPV biomarker from follow-up MR imaging\n(3-5 days after MRgFUS treatment) as the accurate label of nonviable tissue. A\nnovel volume-conserving registration algorithm yielded a voxel-wise correlation\nbetween treatment and follow-up NPV, providing a rigorous validation of the\nbiomarker. The learned noncontrast multiparametric MR biomarker predicted the\nfollow-up NPV with an average DICE coefficient of 0.71, substantially\noutperforming the current clinical standard (DICE coefficient = 0.53).\nNoncontrast multiparametric MR imaging integrated with a deep convolutional\nneural network provides a more accurate prediction of MRgFUS treatment outcome\nthan current contrast-based techniques.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 19:02:43 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 19:24:43 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Zimmerman", "Blake E.", ""], ["Johnson", "Sara", ""], ["Od\u00e9en", "Henrik", ""], ["Shea", "Jill", ""], ["Foote", "Markus D.", ""], ["Winkler", "Nicole", ""], ["Joshi", "Sarang C.", ""], ["Payne", "Allison", ""]]}, {"id": "1910.10775", "submitter": "Eli Bingham", "authors": "Fritz Obermeyer, Eli Bingham, Martin Jankowiak, Du Phan, Jonathan P.\n  Chen", "title": "Functional Tensors for Probabilistic Programming", "comments": "Submitted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a significant challenge to design probabilistic programming systems\nthat can accommodate a wide variety of inference strategies within a unified\nframework. Noting that the versatility of modern automatic differentiation\nframeworks is based in large part on the unifying concept of tensors, we\ndescribe a software abstraction for integration --functional tensors-- that\ncaptures many of the benefits of tensors, while also being able to describe\ncontinuous probability distributions. Moreover, functional tensors are a\nnatural candidate for generalized variable elimination and parallel-scan\nfiltering algorithms that enable parallel exact inference for a large family of\ntractable modeling motifs. We demonstrate the versatility of functional tensors\nby integrating them into the modeling frontend and inference backend of the\nPyro programming language. In experiments we show that the resulting framework\nenables a large variety of inference strategies, including those that mix exact\nand approximate inference.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 19:36:09 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 19:36:31 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Obermeyer", "Fritz", ""], ["Bingham", "Eli", ""], ["Jankowiak", "Martin", ""], ["Phan", "Du", ""], ["Chen", "Jonathan P.", ""]]}, {"id": "1910.10777", "submitter": "Hagit Grushka-Cohen", "authors": "Hagit Grushka-Cohen, Ofer Biller, Oded Sofer, Lior Rokach and Bracha\n  Shapira", "title": "Diversifying Database Activity Monitoring with Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Database activity monitoring (DAM) systems are commonly used by organizations\nto protect the organizational data, knowledge and intellectual properties. In\norder to protect organizations database DAM systems have two main roles,\nmonitoring (documenting activity) and alerting to anomalous activity. Due to\nhigh-velocity streams and operating costs, such systems are restricted to\nexamining only a sample of the activity. Current solutions use policies,\nmanually crafted by experts, to decide which transactions to monitor and log.\nThis limits the diversity of the data collected. Bandit algorithms, which use\nreward functions as the basis for optimization while adding diversity to the\nrecommended set, have gained increased attention in recommendation systems for\nimproving diversity.\n  In this work, we redefine the data sampling problem as a special case of the\nmulti-armed bandit (MAB) problem and present a novel algorithm, which combines\nexpert knowledge with random exploration. We analyze the effect of diversity on\ncoverage and downstream event detection tasks using a simulated dataset. In\ndoing so, we find that adding diversity to the sampling using the bandit-based\napproach works well for this task and maximizing population coverage without\ndecreasing the quality in terms of issuing alerts about events.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 19:39:51 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Grushka-Cohen", "Hagit", ""], ["Biller", "Ofer", ""], ["Sofer", "Oded", ""], ["Rokach", "Lior", ""], ["Shapira", "Bracha", ""]]}, {"id": "1910.10781", "submitter": "Raghavendra Reddy Pappagari", "authors": "Raghavendra Pappagari, Piotr \\.Zelasko, Jes\\'us Villalba, Yishay\n  Carmiel and Najim Dehak", "title": "Hierarchical Transformers for Long Document Classification", "comments": "4 figures, 7 pages", "journal-ref": "Automatic Speech Recognition and Understanding Workshop, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  BERT, which stands for Bidirectional Encoder Representations from\nTransformers, is a recently introduced language representation model based upon\nthe transfer learning paradigm. We extend its fine-tuning procedure to address\none of its major limitations - applicability to inputs longer than a few\nhundred words, such as transcripts of human call conversations. Our method is\nconceptually simple. We segment the input into smaller chunks and feed each of\nthem into the base model. Then, we propagate each output through a single\nrecurrent layer, or another transformer, followed by a softmax activation. We\nobtain the final classification decision after the last segment has been\nconsumed. We show that both BERT extensions are quick to fine-tune and converge\nafter as little as 1 epoch of training on a small, domain-specific data set. We\nsuccessfully apply them in three different tasks involving customer call\nsatisfaction prediction and topic classification, and obtain a significant\nimprovement over the baseline models in two of them.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 19:51:50 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Pappagari", "Raghavendra", ""], ["\u017belasko", "Piotr", ""], ["Villalba", "Jes\u00fas", ""], ["Carmiel", "Yishay", ""], ["Dehak", "Najim", ""]]}, {"id": "1910.10783", "submitter": "Alexander Levine", "authors": "Alexander Levine, Soheil Feizi", "title": "Wasserstein Smoothing: Certified Robustness against Wasserstein\n  Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last couple of years, several adversarial attack methods based on\ndifferent threat models have been proposed for the image classification\nproblem. Most existing defenses consider additive threat models in which sample\nperturbations have bounded L_p norms. These defenses, however, can be\nvulnerable against adversarial attacks under non-additive threat models. An\nexample of an attack method based on a non-additive threat model is the\nWasserstein adversarial attack proposed by Wong et al. (2019), where the\ndistance between an image and its adversarial example is determined by the\nWasserstein metric (\"earth-mover distance\") between their normalized pixel\nintensities. Until now, there has been no certifiable defense against this type\nof attack. In this work, we propose the first defense with certified robustness\nagainst Wasserstein Adversarial attacks using randomized smoothing. We develop\nthis certificate by considering the space of possible flows between images, and\nrepresenting this space such that Wasserstein distance between images is\nupper-bounded by L_1 distance in this flow-space. We can then apply existing\nrandomized smoothing certificates for the L_1 metric. In MNIST and CIFAR-10\ndatasets, we find that our proposed defense is also practically effective,\ndemonstrating significantly improved accuracy under Wasserstein adversarial\nattack compared to unprotected models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 19:54:27 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Levine", "Alexander", ""], ["Feizi", "Soheil", ""]]}, {"id": "1910.10786", "submitter": "Reazul Hasan Russel", "authors": "Bahram Behzadian, Reazul Hasan Russel, Marek Petrik, Chin Pang Ho", "title": "Optimizing Percentile Criterion Using Robust MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of computing reliable policies in reinforcement\nlearning problems with limited data. In particular, we compute policies that\nachieve good returns with high confidence when deployed. This objective, known\nas the \\emph{percentile criterion}, can be optimized using Robust MDPs~(RMDPs).\nRMDPs generalize MDPs to allow for uncertain transition probabilities chosen\nadversarially from given ambiguity sets. We show that the RMDP solution's\nsub-optimality depends on the spans of the ambiguity sets along the value\nfunction. We then propose new algorithms that minimize the span of ambiguity\nsets defined by weighted $L_1$ and $L_\\infty$ norms. Our primary focus is on\nBayesian guarantees, but we also describe how our methods apply to frequentist\nguarantees and derive new concentration inequalities for weighted $L_1$ and\n$L_\\infty$ norms. Experimental results indicate that our optimized ambiguity\nsets improve significantly on prior construction methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 20:00:11 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 13:08:55 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 22:34:25 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Behzadian", "Bahram", ""], ["Russel", "Reazul Hasan", ""], ["Petrik", "Marek", ""], ["Ho", "Chin Pang", ""]]}, {"id": "1910.10791", "submitter": "Wei Deng", "authors": "Wei Deng, Xiao Zhang, Faming Liang, Guang Lin", "title": "An Adaptive Empirical Bayesian Method for Sparse Deep Learning", "comments": "Accepted by NeurIPS 2019; Update the assumption on the regularity of\n  Poisson equation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adaptive empirical Bayesian method for sparse deep\nlearning, where the sparsity is ensured via a class of self-adaptive\nspike-and-slab priors. The proposed method works by alternatively sampling from\nan adaptive hierarchical posterior distribution using stochastic gradient\nMarkov Chain Monte Carlo (MCMC) and smoothly optimizing the hyperparameters\nusing stochastic approximation (SA). We further prove the convergence of the\nproposed method to the asymptotically correct distribution under mild\nconditions. Empirical applications of the proposed method lead to the\nstate-of-the-art performance on MNIST and Fashion MNIST with shallow\nconvolutional neural networks and the state-of-the-art compression performance\non CIFAR10 with Residual Networks. The proposed method also improves resistance\nto adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 20:05:57 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 18:57:23 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Deng", "Wei", ""], ["Zhang", "Xiao", ""], ["Liang", "Faming", ""], ["Lin", "Guang", ""]]}, {"id": "1910.10793", "submitter": "Carianne Martinez", "authors": "Tyler LaBonte, Carianne Martinez, Scott A. Roberts", "title": "We Know Where We Don't Know: 3D Bayesian CNNs for Credible Geometric\n  Uncertainty", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": "SAND2020-3269 R", "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been successfully applied to the segmentation of 3D\nComputed Tomography (CT) scans. Establishing the credibility of these\nsegmentations requires uncertainty quantification (UQ) to identify\nuntrustworthy predictions. Recent UQ architectures include Monte Carlo dropout\nnetworks (MCDNs), which approximate deep Gaussian processes, and Bayesian\nneural networks (BNNs), which learn the distribution of the weight space. BNNs\nare advantageous over MCDNs for UQ but are thought to be computationally\ninfeasible in high dimension, and neither architecture has produced\ninterpretable geometric uncertainty maps. We propose a novel 3D Bayesian\nconvolutional neural network (BCNN), the first deep learning method which\ngenerates statistically credible geometric uncertainty maps and scales for\napplication to 3D data. We present experimental results on CT scans of graphite\nelectrodes and laser-welded metals and show that our BCNN outperforms an MCDN\nin recent uncertainty metrics. The geometric uncertainty maps generated by our\nBCNN capture distributions of sigmoid values that are interpretable as\nconfidence intervals, critical for applications that rely on deep learning for\nhigh-consequence decisions. Code available at\nhttps://github.com/sandialabs/bcnn.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 20:07:24 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 00:35:12 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["LaBonte", "Tyler", ""], ["Martinez", "Carianne", ""], ["Roberts", "Scott A.", ""]]}, {"id": "1910.10797", "submitter": "Oscar Leong", "authors": "Oscar Leong and Wesam Sakla", "title": "Low Shot Learning with Untrained Neural Networks for Imaging Inverse\n  Problems", "comments": "Deep Inverse NeurIPS 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Employing deep neural networks as natural image priors to solve inverse\nproblems either requires large amounts of data to sufficiently train expressive\ngenerative models or can succeed with no data via untrained neural networks.\nHowever, very few works have considered how to interpolate between these no- to\nhigh-data regimes. In particular, how can one use the availability of a small\namount of data (even $5-25$ examples) to one's advantage in solving these\ninverse problems and can a system's performance increase as the amount of data\nincreases as well? In this work, we consider solving linear inverse problems\nwhen given a small number of examples of images that are drawn from the same\ndistribution as the image of interest. Comparing to untrained neural networks\nthat use no data, we show how one can pre-train a neural network with a few\ngiven examples to improve reconstruction results in compressed sensing and\nsemantic image recovery problems such as colorization. Our approach leads to\nimproved reconstruction as the amount of available data increases and is on par\nwith fully trained generative models, while requiring less than $1 \\%$ of the\ndata needed to train a generative model.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 20:23:22 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Leong", "Oscar", ""], ["Sakla", "Wesam", ""]]}, {"id": "1910.10798", "submitter": "Zhen Liu", "authors": "Zhen Liu, Borui Xiao, Yuemeng Li, Yong Fan", "title": "Context-endcoding for neural network based skull stripping in magnetic\n  resonance imaging", "comments": "draft for skull strip", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skull stripping is usually the first step for most brain analysisprocess in\nmagnetic resonance images. A lot of deep learn-ing neural network based methods\nhave been developed toachieve higher accuracy. Since the 3D deep learning\nmodelssuffer from high computational cost and are subject to GPUmemory limit\nchallenge, a variety of 2D deep learning meth-ods have been developed. However,\nexisting 2D deep learn-ing methods are not equipped to effectively capture 3D\nse-mantic information that is needed to achieve higher accuracy.In this paper,\nwe propose a context-encoding method to em-power the 2D network to capture the\n3D context information.For the context-encoding method, firstly we encode the\n2Dfeatures of original 2D network, secondly we encode the sub-volume of 3D MRI\nimages, finally we fuse the encoded 2Dfeatures and 3D features with semantic\nencoding classifica-tion loss. To get computational efficiency, although we\nen-code the sub-volume of 3D MRI images instead of buildinga 3D neural network,\nextensive experiments on three bench-mark Datasets demonstrate our method can\nachieve superioraccuracy to state-of-the-art alternative methods with the\ndicescore 99.6% on NFBS and 99.09 % on LPBA40 and 99.17 %on OASIS.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 20:23:44 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Liu", "Zhen", ""], ["Xiao", "Borui", ""], ["Li", "Yuemeng", ""], ["Fan", "Yong", ""]]}, {"id": "1910.10806", "submitter": "Vishwa Karia", "authors": "Vishwa Karia, Wenhao Zhang, Arash Naeim, Ramin Ramezani", "title": "GenSample: A Genetic Algorithm for Oversampling in Imbalanced Datasets", "comments": "7 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced datasets are ubiquitous. Classification performance on imbalanced\ndatasets is generally poor for the minority class as the classifier cannot\nlearn decision boundaries well. However, in sensitive applications like fraud\ndetection, medical diagnosis, and spam identification, it is extremely\nimportant to classify the minority instances correctly. In this paper, we\npresent a novel technique based on genetic algorithms, GenSample, for\noversampling the minority class in imbalanced datasets. GenSample decides the\nrate of oversampling a minority example by taking into account the difficulty\nin learning that example, along with the performance improvement achieved by\noversampling it. This technique terminates the oversampling process when the\nperformance of the classifier begins to deteriorate. Consequently, it produces\nsynthetic data only as long as a performance boost is obtained. The algorithm\nwas tested on 9 real-world imbalanced datasets of varying sizes and imbalance\nratios. It achieved the highest F-Score on 8 out of 9 datasets, confirming its\nability to better handle imbalanced data compared to other existing\nmethodologies.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 20:48:54 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Karia", "Vishwa", ""], ["Zhang", "Wenhao", ""], ["Naeim", "Arash", ""], ["Ramezani", "Ramin", ""]]}, {"id": "1910.10808", "submitter": "Rusheng Zhang", "authors": "Rusheng Zhang, Romain Leteurtre, Benjamin Striner, Ammar Alanazi,\n  Abdullah Alghafis, Ozan K. Tonguz", "title": "Partially Detected Intelligent Traffic Signal Control: Environmental\n  Adaptation", "comments": "Accepted by ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially Detected Intelligent Traffic Signal Control (PD-ITSC) systems that\ncan optimize traffic signals based on limited detected information could be a\ncost-efficient solution for mitigating traffic congestion in the future. In\nthis paper, we focus on a particular problem in PD-ITSC - adaptation to\nchanging environments. To this end, we investigate different reinforcement\nlearning algorithms, including Q-learning, Proximal Policy Optimization (PPO),\nAdvantage Actor-Critic (A2C), and Actor-Critic with Kronecker-Factored Trust\nRegion (ACKTR). Our findings suggest that RL algorithms can find optimal\nstrategies under partial vehicle detection; however, policy-based algorithms\ncan adapt to changing environments more efficiently than value-based\nalgorithms. We use these findings to draw conclusions about the value of\ndifferent models for PD-ITSC systems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 21:01:53 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Zhang", "Rusheng", ""], ["Leteurtre", "Romain", ""], ["Striner", "Benjamin", ""], ["Alanazi", "Ammar", ""], ["Alghafis", "Abdullah", ""], ["Tonguz", "Ozan K.", ""]]}, {"id": "1910.10809", "submitter": "Laurent Barthes", "authors": "Mohamed Djallel Dilmi, Laurent Barth\\`es, C\\'ecile Mallet, Aymeric\n  Chazottes", "title": "Study of the impact of climate change on precipitation in Paris area\n  using method based on iterative multiscale dynamic time warping (IMS-DTW)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying the impact of climate change on precipitation is constrained by\nfinding a way to evaluate the evolution of precipitation variability over time.\nClassical approaches (feature-based) have shown their limitations for this\nissue due to the intermittent and irregular nature of precipitation. In this\nstudy, we present a novel variant of the Dynamic time warping method\nquantifying the dissimilarity between two rainfall time series based on shapes\ncomparisons, for clustering annual time series recorded at daily scale. This\nshape based approach considers the whole information (variability, trends and\nintermittency). We further labeled each cluster using a feature-based approach.\nWhile testing the proposed approach on the time series of Paris Montsouris, we\nfound that the precipitation variability increased over the years in Paris\narea.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:34:02 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Dilmi", "Mohamed Djallel", ""], ["Barth\u00e8s", "Laurent", ""], ["Mallet", "C\u00e9cile", ""], ["Chazottes", "Aymeric", ""]]}, {"id": "1910.10831", "submitter": "Alexander Alemi", "authors": "Alexander A. Alemi", "title": "Variational Predictive Information Bottleneck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classic papers, Zellner demonstrated that Bayesian inference could be\nderived as the solution to an information theoretic functional. Below we derive\na generalized form of this functional as a variational lower bound of a\npredictive information bottleneck objective. This generalized functional\nencompasses most modern inference procedures and suggests novel ones.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 22:48:28 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Alemi", "Alexander A.", ""]]}, {"id": "1910.10832", "submitter": "Luke de Oliveira", "authors": "Alexandre Matton and Luke de Oliveira", "title": "Emergent Properties of Finetuned Language Representation Models", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large, self-supervised transformer-based language representation models have\nrecently received significant amounts of attention, and have produced\nstate-of-the-art results across a variety of tasks simply by scaling up\npre-training on larger and larger corpora. Such models usually produce high\ndimensional vectors, on top of which additional task-specific layers and\narchitectural modifications are added to adapt them to specific downstream\ntasks. Though there exists ample evidence that such models work well, we aim to\nunderstand what happens when they work well. We analyze the redundancy and\nlocation of information contained in output vectors for one such language\nrepresentation model -- BERT. We show empirical evidence that the [CLS]\nembedding in BERT contains highly redundant information, and can be compressed\nwith minimal loss of accuracy, especially for finetuned models, dovetailing\ninto open threads in the field about the role of over-parameterization in\nlearning. We also shed light on the existence of specific output dimensions\nwhich alone give very competitive results when compared to using all dimensions\nof output vectors.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 23:01:10 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Matton", "Alexandre", ""], ["de Oliveira", "Luke", ""]]}, {"id": "1910.10835", "submitter": "Steven Chen", "authors": "Steven W. Chen, Tianyu Wang, Nikolay Atanasov, Vijay Kumar, and\n  Manfred Morari", "title": "Large Scale Model Predictive Control with Neural Networks and Primal\n  Active Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an explicit-implicit procedure to compute a model\npredictive control (MPC) law with guarantees on recursive feasibility and\nasymptotic stability. The approach combines an offline-trained fully-connected\nneural network with an online primal active set solver. The neural network\nprovides a control input initialization while the primal active set method\nensures recursive feasibility and asymptotic stability. The neural network is\ntrained with a primal-dual loss function, aiming to generate control sequences\nthat are primal feasible and meet a desired level of suboptimality. Since the\nneural network alone does not guarantee constraint satisfaction, its output is\nused to warm start the primal active set method online. We demonstrate that\nthis approach scales to large problems with thousands of optimization\nvariables, which are challenging for current approaches. Our method achieves a\n2x reduction in online inference time compared to the best method in a\nbenchmark suite of different solver and initialization strategies.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 23:15:18 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 21:50:16 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Chen", "Steven W.", ""], ["Wang", "Tianyu", ""], ["Atanasov", "Nikolay", ""], ["Kumar", "Vijay", ""], ["Morari", "Manfred", ""]]}, {"id": "1910.10840", "submitter": "Patrik Reizinger", "authors": "Patrik Reizinger and M\\'arton Szemenyei", "title": "Attention-based Curiosity-driven Exploration in Deep Reinforcement\n  Learning", "comments": "Submitted to ICASSP2020, 5 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning enables to train an agent via interaction with the\nenvironment. However, in the majority of real-world scenarios, the extrinsic\nfeedback is sparse or not sufficient, thus intrinsic reward formulations are\nneeded to successfully train the agent. This work investigates and extends the\nparadigm of curiosity-driven exploration. First, a probabilistic approach is\ntaken to exploit the advantages of the attention mechanism, which is\nsuccessfully applied in other domains of Deep Learning. Combining them, we\npropose new methods, such as AttA2C, an extension of the Actor-Critic\nframework. Second, another curiosity-based approach - ICM - is extended. The\nproposed model utilizes attention to emphasize features for the dynamic models\nwithin ICM, moreover, we also modify the loss function, resulting in a new\ncuriosity formulation, which we call rational curiosity. The corresponding\nimplementation can be found at https://github.com/rpatrik96/AttA2C/.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 23:31:21 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Reizinger", "Patrik", ""], ["Szemenyei", "M\u00e1rton", ""]]}, {"id": "1910.10843", "submitter": "Kevin Huang", "authors": "Kevin Huang, Yun Tang, Jing Huang, Xiaodong He, and Bowen Zhou", "title": "Relation Module for Non-answerable Prediction on Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension(MRC) has attracted significant amounts of\nresearch attention recently, due to an increase of challenging reading\ncomprehension datasets. In this paper, we aim to improve a MRC model's ability\nto determine whether a question has an answer in a given context (e.g. the\nrecently proposed SQuAD 2.0 task). Our solution is a relation module that is\nadaptable to any MRC model. The relation module consists of both semantic\nextraction and relational information. We first extract high level semantics as\nobjects from both question and context with multi-head self-attentive pooling.\nThese semantic objects are then passed to a relation network, which generates\nrelationship scores for each object pair in a sentence. These scores are used\nto determine whether a question is non-answerable. We test the relation module\non the SQuAD 2.0 dataset using both BiDAF and BERT models as baseline readers.\nWe obtain 1.8% gain of F1 on top of the BiDAF reader, and 1.0% on top of the\nBERT base model. These results show the effectiveness of our relation module on\nMRC\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 23:55:23 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Huang", "Kevin", ""], ["Tang", "Yun", ""], ["Huang", "Jing", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1910.10844", "submitter": "Johannes Royset", "authors": "Matthew Norton and Johannes O. Royset", "title": "Diametrical Risk Minimization: Theory and Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theoretical and empirical performance of Empirical Risk Minimization\n(ERM) often suffers when loss functions are poorly behaved with large Lipschitz\nmoduli and spurious sharp minimizers. We propose and analyze a counterpart to\nERM called Diametrical Risk Minimization (DRM), which accounts for worst-case\nempirical risks within neighborhoods in parameter space. DRM has generalization\nbounds that are independent of Lipschitz moduli for convex as well as nonconvex\nproblems and it can be implemented using a practical algorithm based on\nstochastic gradient descent. Numerical results illustrate the ability of DRM to\nfind quality solutions with low generalization error in sharp empirical risk\nlandscapes from benchmark neural network classification problems with corrupted\nlabels.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 00:12:12 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 00:25:24 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 15:03:55 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Norton", "Matthew", ""], ["Royset", "Johannes O.", ""]]}, {"id": "1910.10845", "submitter": "Shuai Zhang", "authors": "Eyasu Mequanint, Shuai Zhang, Bijan Forutanpour, Yingyong Qi, Ning Bi", "title": "Weakly-Supervised Degree of Eye-Closeness Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following recent technological advances there is a growing interest in\nbuilding non-intrusive methods that help us communicate with computing devices.\nIn this regard, accurate information from eye is a promising input medium\nbetween a user and computing devices. In this paper we propose a method that\ncaptures the degree of eye closeness. Although many methods exist for detection\nof eyelid openness, they are inherently unable to satisfactorily perform in\nreal world applications. Detailed eye state estimation is more important, in\nextracting meaningful information, than estimating whether eyes are open or\nclosed. However, learning reliable eye state estimator requires accurate\nannotations which is cost prohibitive. In this work, we leverage synthetic face\nimages which can be generated via computer graphics rendering techniques and\nautomatically annotated with different levels of eye openness. These\nsynthesized training data images, however, have a domain shift from real-world\ndata. To alleviate this issue, we propose a weakly-supervised method which\nutilizes the accurate annotation from the synthetic data set, to learn accurate\ndegree of eye openness, and the weakly labeled (open or closed) real world eye\ndata set to control the domain shift. We introduce a data set of 1.3M synthetic\nface images with detail eye openness and eye gaze information, and 21k\nreal-world images with open/closed annotation. The dataset will be released\nonline upon acceptance. Extensive experiments validate the effectiveness of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 00:14:28 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Mequanint", "Eyasu", ""], ["Zhang", "Shuai", ""], ["Forutanpour", "Bijan", ""], ["Qi", "Yingyong", ""], ["Bi", "Ning", ""]]}, {"id": "1910.10857", "submitter": "Xiaochen Hou", "authors": "Xiaochen Hou, Jing Huang, Guangtao Wang, Xiaodong He, Bowen Zhou", "title": "Selective Attention Based Graph Convolutional Networks for Aspect-Level\n  Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-level sentiment classification aims to identify the sentiment polarity\ntowards a specific aspect term in a sentence. Most current approaches mainly\nconsider the semantic information by utilizing attention mechanisms to capture\nthe interactions between the context and the aspect term. In this paper, we\npropose to employ graph convolutional networks (GCNs) on the dependency tree to\nlearn syntax-aware representations of aspect terms. GCNs often show the best\nperformance with two layers, and deeper GCNs do not bring additional gain due\nto over-smoothing problem. However, in some cases, important context words\ncannot be reached within two hops on the dependency tree. Therefore we design a\nselective attention based GCN block (SA-GCN) to find the most important context\nwords, and directly aggregate these information into the aspect-term\nrepresentation. We conduct experiments on the SemEval 2014 Task 4 datasets. Our\nexperimental results show that our model outperforms the current\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 00:33:39 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 04:05:51 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 04:33:13 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 02:19:25 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Hou", "Xiaochen", ""], ["Huang", "Jing", ""], ["Wang", "Guangtao", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1910.10860", "submitter": "Sangkyun Lee", "authors": "Sangkyun Lee, Piotr Sobczyk, Malgorzata Bogdan", "title": "Structure Learning of Gaussian Markov Random Fields with False Discovery\n  Rate Control", "comments": null, "journal-ref": "https://www.mdpi.com/2073-8994/11/10/1311", "doi": "10.3390/symxx010005", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a new estimation procedure for discovering the\nstructure of Gaussian Markov random fields (MRFs) with false discovery rate\n(FDR) control, making use of the sorted l1-norm (SL1) regularization. A\nGaussian MRF is an acyclic graph representing a multivariate Gaussian\ndistribution, where nodes are random variables and edges represent the\nconditional dependence between the connected nodes. Since it is possible to\nlearn the edge structure of Gaussian MRFs directly from data, Gaussian MRFs\nprovide an excellent way to understand complex data by revealing the dependence\nstructure among many inputs features, such as genes, sensors, users, documents,\netc. In learning the graphical structure of Gaussian MRFs, it is desired to\ndiscover the actual edges of the underlying but unknown probabilistic graphical\nmodel-it becomes more complicated when the number of random variables\n(features) p increases, compared to the number of data points n. In particular,\nwhen p >> n, it is statistically unavoidable for any estimation procedure to\ninclude false edges. Therefore, there have been many trials to reduce the false\ndetection of edges, in particular, using different types of regularization on\nthe learning parameters. Our method makes use of the SL1 regularization,\nintroduced recently for model selection in linear regression. We focus on the\nbenefit of SL1 regularization that it can be used to control the FDR of\ndetecting important random variables. Adapting SL1 for probabilistic graphical\nmodels, we show that SL1 can be used for the structure learning of Gaussian\nMRFs using our suggested procedure nsSLOPE (neighborhood selection Sorted L-One\nPenalized Estimation), controlling the FDR of detecting edges.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 00:45:26 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Lee", "Sangkyun", ""], ["Sobczyk", "Piotr", ""], ["Bogdan", "Malgorzata", ""]]}, {"id": "1910.10866", "submitter": "Asiri Wijesinghe", "authors": "Asiri Wijesinghe and Qing Wang", "title": "DFNets: Spectral CNNs for Graphs with Feedback-Looped Filters", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel spectral convolutional neural network (CNN) model on graph\nstructured data, namely Distributed Feedback-Looped Networks (DFNets). This\nmodel is incorporated with a robust class of spectral graph filters, called\nfeedback-looped filters, to provide better localization on vertices, while\nstill attaining fast convergence and linear memory requirements. Theoretically,\nfeedback-looped filters can guarantee convergence w.r.t. a specified error\nbound, and be applied universally to any graph without knowing its structure.\nFurthermore, the propagation rule of this model can diversify features from the\npreceding layers to produce strong gradient flows. We have evaluated our model\nusing two benchmark tasks: semi-supervised document classification on citation\nnetworks and semi-supervised entity classification on a knowledge graph. The\nexperimental results show that our model considerably outperforms the\nstate-of-the-art methods in both benchmark tasks over all datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 01:07:11 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 01:17:14 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 09:22:38 GMT"}, {"version": "v4", "created": "Tue, 24 Dec 2019 01:00:17 GMT"}, {"version": "v5", "created": "Fri, 17 Jan 2020 01:39:56 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Wijesinghe", "Asiri", ""], ["Wang", "Qing", ""]]}, {"id": "1910.10871", "submitter": "Andrew Tomkins", "authors": "Benjamin Spector and Ravi Kumar and Andrew Tomkins", "title": "Preventing Adversarial Use of Datasets through Fair Core-Set\n  Construction", "comments": "6 pages, 2 figures, NeurIPS 2019 Privacy In Machine Learning Workshop\n  (PriML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose improving the privacy properties of a dataset by publishing only a\nstrategically chosen \"core-set\" of the data containing a subset of the\ninstances. The core-set allows strong performance on primary tasks, but forces\npoor performance on unwanted tasks. We give methods for both linear models and\nneural networks and demonstrate their efficacy on data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 01:28:58 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Spector", "Benjamin", ""], ["Kumar", "Ravi", ""], ["Tomkins", "Andrew", ""]]}, {"id": "1910.10873", "submitter": "Lin Chen", "authors": "Lin Chen, Qian Yu, Hannah Lawrence, Amin Karbasi", "title": "Minimax Regret of Switching-Constrained Online Convex Optimization: No\n  Phase Transition", "comments": "First two authors contributed equally. Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of switching-constrained online convex optimization\n(OCO), where the player has a limited number of opportunities to change her\naction. While the discrete analog of this online learning task has been studied\nextensively, previous work in the continuous setting has neither established\nthe minimax rate nor algorithmically achieved it. In this paper, we show that $\nT $-round switching-constrained OCO with fewer than $ K $ switches has a\nminimax regret of $ \\Theta(\\frac{T}{\\sqrt{K}}) $. In particular, it is at least\n$ \\frac{T}{\\sqrt{2K}} $ for one dimension and at least $ \\frac{T}{\\sqrt{K}} $\nfor higher dimensions. The lower bound in higher dimensions is attained by an\northogonal subspace argument. In one dimension, a novel adversarial strategy\nyields the lower bound of $O(\\frac{T}{\\sqrt{K}})$, but a precise minimax\nanalysis including constants is more involved. To establish the tighter\none-dimensional result, we introduce the \\emph{fugal game} relaxation, whose\nminimax regret lower bounds that of switching-constrained OCO. We show that the\nminimax regret of the fugal game is at least $ \\frac{T}{\\sqrt{2K}} $ and\nthereby establish the optimal minimax lower bound in one dimension. To\nestablish the dimension-independent upper bound, we next show that a\nmini-batching algorithm provides an $ O(\\frac{T}{\\sqrt{K}}) $ upper bound, and\ntherefore conclude that the minimax regret of switching-constrained OCO is $\n\\Theta(\\frac{T}{\\sqrt{K}}) $ for any $K$. This is in sharp contrast to its\ndiscrete counterpart, the switching-constrained prediction-from-experts\nproblem, which exhibits a phase transition in minimax regret between the\nlow-switching and high-switching regimes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 01:36:09 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 05:51:55 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 16:58:07 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Chen", "Lin", ""], ["Yu", "Qian", ""], ["Lawrence", "Hannah", ""], ["Karbasi", "Amin", ""]]}, {"id": "1910.10881", "submitter": "Evgeny Pavlovskiy", "authors": "Akilesh Sivaswamy, Evgeny Pavlovskiy", "title": "Superposition as Data Augmentation using LSTM and HMM in Small Training\n  Sets", "comments": "Presented on the Quantum Techniques in Machine Learning, 20-24 Oct.\n  2019, Daejeon, South Korea", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Considering audio and image data as having quantum nature (data are\nrepresented by density matrices), we achieved better results on training\narchitectures such as 3-layer stacked LSTM and HMM by mixing training samples\nusing superposition augmentation and compared with plain default training and\nmix-up augmentation. This augmentation technique originates from the mix-up\napproach but provides more solid theoretical reasoning based on quantum\nproperties. We achieved 3% improvement (from 68% to 71%) by using 38% lesser\nnumber of training samples in Russian audio-digits recognition task and 7,16%\nbetter accuracy than mix-up augmentation by training only 500 samples using HMM\non the same task. Also, we achieved 1.1% better accuracy than mix-up on first\n900 samples in MNIST using 3-layer stacked LSTM.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 02:14:09 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Sivaswamy", "Akilesh", ""], ["Pavlovskiy", "Evgeny", ""]]}, {"id": "1910.10885", "submitter": "Shuo Li", "authors": "Shuo Li, Osbert Bastani", "title": "Robust Model Predictive Shielding for Safe Reinforcement Learning with\n  Stochastic Dynamics", "comments": "8 pages, 5 figures, accepted by ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a framework for safe reinforcement learning that can\nhandle stochastic nonlinear dynamical systems. We focus on the setting where\nthe nominal dynamics are known, and are subject to additive stochastic\ndisturbances with known distribution. Our goal is to ensure the safety of a\ncontrol policy trained using reinforcement learning, e.g., in a simulated\nenvironment. We build on the idea of model predictive shielding (MPS), where a\nbackup controller is used to override the learned policy as needed to ensure\nsafety. The key challenge is how to compute a backup policy in the context of\nstochastic dynamics. We propose to use a tube-based robust NMPC controller as\nthe backup controller. We estimate the tubes using sampled trajectories,\nleveraging ideas from statistical learning theory to obtain high-probability\nguarantees. We empirically demonstrate that our approach can ensure safety in\nstochastic systems, including cart-pole and a non-holonomic particle with\nrandom obstacles.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 02:22:42 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 03:12:03 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Li", "Shuo", ""], ["Bastani", "Osbert", ""]]}, {"id": "1910.10897", "submitter": "Avnish Narayan", "authors": "Tianhe Yu, Deirdre Quillen, Zhanpeng He, Ryan Julian, Avnish Narayan,\n  Hayden Shively, Adithya Bellathur, Karol Hausman, Chelsea Finn, Sergey Levine", "title": "Meta-World: A Benchmark and Evaluation for Multi-Task and Meta\n  Reinforcement Learning", "comments": "This is an update version of a manuscript that originally appeared at\n  CoRL 2019. Videos are here: meta-world.github.io, open-sourced code are\n  available at: https://github.com/rlworkgroup/metaworld, and the baselines can\n  be found at https://github.com/rlworkgroup/garage", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-reinforcement learning algorithms can enable robots to acquire new\nskills much more quickly, by leveraging prior experience to learn how to learn.\nHowever, much of the current research on meta-reinforcement learning focuses on\ntask distributions that are very narrow. For example, a commonly used\nmeta-reinforcement learning benchmark uses different running velocities for a\nsimulated robot as different tasks. When policies are meta-trained on such\nnarrow task distributions, they cannot possibly generalize to more quickly\nacquire entirely new tasks. Therefore, if the aim of these methods is to enable\nfaster acquisition of entirely new behaviors, we must evaluate them on task\ndistributions that are sufficiently broad to enable generalization to new\nbehaviors. In this paper, we propose an open-source simulated benchmark for\nmeta-reinforcement learning and multi-task learning consisting of 50 distinct\nrobotic manipulation tasks. Our aim is to make it possible to develop\nalgorithms that generalize to accelerate the acquisition of entirely new,\nheld-out tasks. We evaluate 7 state-of-the-art meta-reinforcement learning and\nmulti-task learning algorithms on these tasks. Surprisingly, while each task\nand its variations (e.g., with different object positions) can be learned with\nreasonable success, these algorithms struggle to learn with multiple tasks at\nthe same time, even with as few as ten distinct training tasks. Our analysis\nand open-source environments pave the way for future research in multi-task\nlearning and meta-learning that can enable meaningful generalization, thereby\nunlocking the full potential of these methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 03:19:46 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 18:45:16 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Yu", "Tianhe", ""], ["Quillen", "Deirdre", ""], ["He", "Zhanpeng", ""], ["Julian", "Ryan", ""], ["Narayan", "Avnish", ""], ["Shively", "Hayden", ""], ["Bellathur", "Adithya", ""], ["Hausman", "Karol", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "1910.10902", "submitter": "Chunnnan Wang", "authors": "Chunnan Wang, Hongzhi Wang, Tianyu Mu, Jianzhong Li, Hong Gao", "title": "Auto-Model: Utilizing Research Papers and HPO Techniques to Deal with\n  the CASH problem", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields, a mass of algorithms with completely different\nhyperparameters have been developed to address the same type of problems.\nChoosing the algorithm and hyperparameter setting correctly can promote the\noverall performance greatly, but users often fail to do so due to the absence\nof knowledge. How to help users to effectively and quickly select the suitable\nalgorithm and hyperparameter settings for the given task instance is an\nimportant research topic nowadays, which is known as the CASH problem. In this\npaper, we design the Auto-Model approach, which makes full use of known\ninformation in the related research paper and introduces hyperparameter\noptimization techniques, to solve the CASH problem effectively. Auto-Model\ntremendously reduces the cost of algorithm implementations and hyperparameter\nconfiguration space, and thus capable of dealing with the CASH problem\nefficiently and easily. To demonstrate the benefit of Auto-Model, we compare it\nwith classical Auto-Weka approach. The experimental results show that our\nproposed approach can provide superior results and achieves better performance\nin a short time.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 03:44:10 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 05:35:59 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Chunnan", ""], ["Wang", "Hongzhi", ""], ["Mu", "Tianyu", ""], ["Li", "Jianzhong", ""], ["Gao", "Hong", ""]]}, {"id": "1910.10906", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Christian Kroer and Tuomas Sandholm", "title": "Optimistic Regret Minimization for Extensive-Form Games via Dilated\n  Distance-Generating Functions", "comments": "Extended NeurIPS 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of optimistic regret-minimization algorithms for\nboth minimizing regret in, and computing Nash equilibria of, zero-sum\nextensive-form games. In order to apply these algorithms to extensive-form\ngames, a distance-generating function is needed. We study the use of the\ndilated entropy and dilated Euclidean distance functions. For the dilated\nEuclidean distance function we prove the first explicit bounds on the\nstrong-convexity parameter for general treeplexes. Furthermore, we show that\nthe use of dilated distance-generating functions enable us to decompose the\nmirror descent algorithm, and its optimistic variant, into local mirror descent\nalgorithms at each information set. This decomposition mirrors the structure of\nthe counterfactual regret minimization framework, and enables important\ntechniques in practice, such as distributed updates and pruning of cold parts\nof the game tree. Our algorithms provably converge at a rate of $T^{-1}$, which\nis superior to prior counterfactual regret minimization algorithms. We\nexperimentally compare to the popular algorithm CFR+, which has a theoretical\nconvergence rate of $T^{-0.5}$ in theory, but is known to often converge at a\nrate of $T^{-1}$, or better, in practice. We give an example matrix game where\nCFR+ experimentally converges at a relatively slow rate of $T^{-0.74}$, whereas\nour optimistic methods converge faster than $T^{-1}$. We go on to show that our\nfast rate also holds in the Kuhn poker game, which is an extensive-form game.\nFor games with deeper game trees however, we find that CFR+ is still faster.\nFinally we show that when the goal is minimizing regret, rather than computing\na Nash equilibrium, our optimistic methods can outperform CFR+, even in deep\ngame trees.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 04:08:22 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 06:24:17 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1910.10912", "submitter": "Ziye Yang", "authors": "Ziye Yang and Xiao-Lei Zhang", "title": "Multi-channel Speech Separation Using Deep Embedding Model with\n  Multilayer Bootstrap Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep clustering (DPCL) based speaker-independent speech separation\nhas drawn much attention, since it needs little speaker prior information.\nHowever, it still has much room of improvement, particularly in reverberant\nenvironments. If the training and test environments mismatch which is a common\ncase, the embedding vectors produced by DPCL may contain much noise and many\nsmall variations. To deal with the problem, we propose a variant of DPCL, named\nDPCL++, by applying a recent unsupervised deep learning method---multilayer\nbootstrap networks(MBN)---to further reduce the noise and small variations of\nthe embedding vectors in an unsupervised way in the test stage, which\nfascinates k-means to produce a good result. MBN builds a gradually narrowed\nnetwork from bottom-up via a stack of k-centroids clustering ensembles, where\nthe k-centroids clusterings are trained independently by random sampling and\none-nearest-neighbor optimization. To further improve the robustness of DPCL++\nin reverberant environments, we take spatial features as part of its input.\nExperimental results demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 04:35:11 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Yang", "Ziye", ""], ["Zhang", "Xiao-Lei", ""]]}, {"id": "1910.10929", "submitter": "Zijie Yan", "authors": "Zijie Yan", "title": "Gradient Sparification for Asynchronous Distributed Training", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern large scale machine learning applications require stochastic\noptimization algorithms to be implemented on distributed computational\narchitectures. A key bottleneck is the communication overhead for exchanging\ninformation, such as stochastic gradients, among different nodes. Recently,\ngradient sparsification techniques have been proposed to reduce communications\ncost and thus alleviate the network overhead. However, most of gradient\nsparsification techniques consider only synchronous parallelism and cannot be\napplied in asynchronous scenarios, such as asynchronous distributed training\nfor federated learning at mobile devices.\n  In this paper, we present a dual-way gradient sparsification approach (DGS)\nthat is suitable for asynchronous distributed training. We let workers download\nmodel difference, instead of the global model, from the server, and the model\ndifference information is also sparsified so that the information exchanged\noverhead is reduced by sparsifying the dual-way communication between the\nserver and workers. To preserve accuracy under dual-way sparsification, we\ndesign a sparsification aware momentum (SAMomentum) to turn sparsification into\nadaptive batch size between each parameter. We conduct experiments at a cluster\nof 32 workers, and the results show that, with the same compression ratio but\nmuch lower communication cost, our approach can achieve better scalability and\ngeneralization ability.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 06:16:28 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Yan", "Zijie", ""]]}, {"id": "1910.10937", "submitter": "Vinod Raman", "authors": "Vinod Raman and Daniel T. Zhang and Young Hun Jung and Ambuj Tewari", "title": "Online Boosting for Multilabel Ranking with Top-k Feedback", "comments": "Under review for AISTATS 2021. Fixed small errors throughout the\n  manuscript and added new content comparing/contrasting various randomization\n  procedures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present online boosting algorithms for multilabel ranking with top-k\nfeedback, where the learner only receives information about the top k items\nfrom the ranking it provides. We propose a novel surrogate loss function and\nunbiased estimator, allowing weak learners to update themselves with limited\ninformation. Using these techniques we adapt full information multilabel\nranking algorithms (Jung and Tewari, 2018) to the top-k feedback setting and\nprovide theoretical performance bounds which closely match the bounds of their\nfull information counterparts, with the cost of increased sample complexity.\nThese theoretical results are further substantiated by our experiments, which\nshow a small gap in performance between the algorithms for the top-k feedback\nsetting and that for the full information setting across various datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 06:44:01 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 07:02:52 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 04:26:51 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Raman", "Vinod", ""], ["Zhang", "Daniel T.", ""], ["Jung", "Young Hun", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1910.10942", "submitter": "Simon Leglaive", "authors": "Simon Leglaive (IETR), Xavier Alameda-Pineda (PERCEPTION), Laurent\n  Girin (GIPSA-CRISSP, PERCEPTION), Radu Horaud (PERCEPTION)", "title": "A Recurrent Variational Autoencoder for Speech Enhancement", "comments": null, "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), May 2020, Barcelona, Spain", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a generative approach to speech enhancement based on a\nrecurrent variational autoencoder (RVAE). The deep generative speech model is\ntrained using clean speech signals only, and it is combined with a nonnegative\nmatrix factorization noise model for speech enhancement. We propose a\nvariational expectation-maximization algorithm where the encoder of the RVAE is\nfine-tuned at test time, to approximate the distribution of the latent\nvariables given the noisy speech observations. Compared with previous\napproaches based on feed-forward fully-connected architectures, the proposed\nrecurrent deep generative speech model induces a posterior temporal dynamic\nover the latent variables, which is shown to improve the speech enhancement\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 06:54:36 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 09:36:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Leglaive", "Simon", "", "IETR"], ["Alameda-Pineda", "Xavier", "", "PERCEPTION"], ["Girin", "Laurent", "", "GIPSA-CRISSP, PERCEPTION"], ["Horaud", "Radu", "", "PERCEPTION"]]}, {"id": "1910.10944", "submitter": "Adish Singla", "authors": "Farnam Mansouri, Yuxin Chen, Ara Vartanian, Xiaojin Zhu, Adish Singla", "title": "Preference-Based Batch and Sequential Teaching: Towards a Unified View\n  of Models", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic machine teaching studies the interaction between a teacher and a\nlearner where the teacher selects labeled examples aiming at teaching a target\nhypothesis. In a quest to lower teaching complexity and to achieve more natural\nteacher-learner interactions, several teaching models and complexity measures\nhave been proposed for both the batch settings (e.g., worst-case, recursive,\npreference-based, and non-clashing models) as well as the sequential settings\n(e.g., local preference-based model). To better understand the connections\nbetween these different batch and sequential models, we develop a novel\nframework which captures the teaching process via preference functions\n$\\Sigma$. In our framework, each function $\\sigma \\in \\Sigma$ induces a\nteacher-learner pair with teaching complexity as $\\TD(\\sigma)$. We show that\nthe above-mentioned teaching models are equivalent to specific types/families\nof preference functions in our framework. This equivalence, in turn, allows us\nto study the differences between two important teaching models, namely $\\sigma$\nfunctions inducing the strongest batch (i.e., non-clashing) model and $\\sigma$\nfunctions inducing a weak sequential (i.e., local preference-based) model.\nFinally, we identify preference functions inducing a novel family of sequential\nmodels with teaching complexity linear in the VC dimension of the hypothesis\nclass: this is in contrast to the best known complexity result for the batch\nmodels which is quadratic in the VC dimension.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 07:03:55 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Mansouri", "Farnam", ""], ["Chen", "Yuxin", ""], ["Vartanian", "Ara", ""], ["Zhu", "Xiaojin", ""], ["Singla", "Adish", ""]]}, {"id": "1910.10945", "submitter": "Xuedong Shang", "authors": "Xuedong Shang, Rianne de Heide, Emilie Kaufmann, Pierre M\\'enard,\n  Michal Valko", "title": "Fixed-Confidence Guarantees for Bayesian Best-Arm Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate and provide new insights on the sampling rule called Top-Two\nThompson Sampling (TTTS). In particular, we justify its use for\nfixed-confidence best-arm identification. We further propose a variant of TTTS\ncalled Top-Two Transportation Cost (T3C), which disposes of the computational\nburden of TTTS. As our main contribution, we provide the first sample\ncomplexity analysis of TTTS and T3C when coupled with a very natural Bayesian\nstopping rule, for bandits with Gaussian rewards, solving one of the open\nquestions raised by Russo (2016). We also provide new posterior convergence\nresults for TTTS under two models that are commonly used in practice: bandits\nwith Gaussian and Bernoulli rewards and conjugate priors.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 07:07:35 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 07:36:18 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 12:37:18 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Shang", "Xuedong", ""], ["de Heide", "Rianne", ""], ["Kaufmann", "Emilie", ""], ["M\u00e9nard", "Pierre", ""], ["Valko", "Michal", ""]]}, {"id": "1910.10953", "submitter": "JianYu Wang", "authors": "Jianyu Wang and Xiao-Lei Zhang", "title": "Deep topic modeling by multilayer bootstrap network and lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling is widely studied for the dimension reduction and analysis of\ndocuments. However, it is formulated as a difficult optimization problem.\nCurrent approximate solutions also suffer from inaccurate model- or\ndata-assumptions. To deal with the above problems, we propose a polynomial-time\ndeep topic model with no model and data assumptions. Specifically, we first\napply multilayer bootstrap network (MBN), which is an unsupervised deep model,\nto reduce the dimension of documents, and then use the low-dimensional data\nrepresentations or their clustering results as the target of supervised Lasso\nfor topic word discovery. To our knowledge, this is the first time that MBN and\nLasso are applied to unsupervised topic modeling. Experimental comparison\nresults with five representative topic models on the 20-newsgroups and TDT2\ncorpora illustrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 07:35:28 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Wang", "Jianyu", ""], ["Zhang", "Xiao-Lei", ""]]}, {"id": "1910.10958", "submitter": "Asifullah Khan", "authors": "Muhammad Furqan Rafique, Muhammad Ali, Aqsa Saeed Qureshi, Asifullah\n  Khan, and Anwar Majid Mirza", "title": "Malware Classification using Deep Learning based Feature Extraction and\n  Wrapper based Feature Selection Technique", "comments": "21 pages, 8 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the case of malware analysis, categorization of malicious files is an\nessential part after malware detection. Numerous static and dynamic techniques\nhave been reported so far for categorizing malware. This research presents a\ndeep learning-based malware detection (DLMD) technique based on static methods\nfor classifying different malware families. The proposed DLMD technique uses\nboth the byte and ASM files for feature engineering, thus classifying malware\nfamilies. First, features are extracted from byte files using two different\nDeep Convolutional Neural Networks (CNN). After that, essential and\ndiscriminative opcode features are selected using a wrapper-based mechanism,\nwhere Support Vector Machine (SVM) is used as a classifier. The idea is to\nconstruct a hybrid feature space by combining the different feature spaces to\novercome the shortcoming of particular feature space and thus, reduce the\nchances of missing a malware. Finally, the hybrid feature space is used to\ntrain a Multilayer Perceptron, which classifies all nine different malware\nfamilies. Experimental results show that proposed DLMD technique achieves\nlog-loss of 0.09 for ten independent runs. Moreover, the proposed DLMD\ntechnique's performance is compared against different classifiers and shows its\neffectiveness in categorizing malware. The relevant code and database can be\nfound at\nhttps://github.com/cyberhunters/Malware-Detection-Using-Machine-Learning.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 07:47:20 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 15:01:43 GMT"}, {"version": "v3", "created": "Sat, 26 Dec 2020 19:58:16 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Rafique", "Muhammad Furqan", ""], ["Ali", "Muhammad", ""], ["Qureshi", "Aqsa Saeed", ""], ["Khan", "Asifullah", ""], ["Mirza", "Anwar Majid", ""]]}, {"id": "1910.10986", "submitter": "Xin Yao", "authors": "Xin Yao, Tianchi Huang, Chenglei Wu, Rui-Xiao Zhang, Lifeng Sun", "title": "Adversarial Feature Alignment: Avoid Catastrophic Forgetting in\n  Incremental Task Lifelong Learning", "comments": null, "journal-ref": "Neural Computation, Volume 31, Issue 11, November 2019,\n  p.2266-2291", "doi": "10.1162/neco_a_01232", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human beings are able to master a variety of knowledge and skills with\nongoing learning. By contrast, dramatic performance degradation is observed\nwhen new tasks are added to an existing neural network model. This phenomenon,\ntermed as \\emph{Catastrophic Forgetting}, is one of the major roadblocks that\nprevent deep neural networks from achieving human-level artificial\nintelligence. Several research efforts, e.g. \\emph{Lifelong} or\n\\emph{Continual} learning algorithms, have been proposed to tackle this\nproblem. However, they either suffer from an accumulating drop in performance\nas the task sequence grows longer, or require to store an excessive amount of\nmodel parameters for historical memory, or cannot obtain competitive\nperformance on the new tasks. In this paper, we focus on the incremental\nmulti-task image classification scenario. Inspired by the learning process of\nhuman students, where they usually decompose complex tasks into easier goals,\nwe propose an adversarial feature alignment method to avoid catastrophic\nforgetting. In our design, both the low-level visual features and high-level\nsemantic features serve as soft targets and guide the training process in\nmultiple stages, which provide sufficient supervised information of the old\ntasks and help to reduce forgetting. Due to the knowledge distillation and\nregularization phenomenons, the proposed method gains even better performance\nthan finetuning on the new tasks, which makes it stand out from other methods.\nExtensive experiments in several typical lifelong learning scenarios\ndemonstrate that our method outperforms the state-of-the-art methods in both\naccuracies on new tasks and performance preservation on old tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 09:23:02 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Yao", "Xin", ""], ["Huang", "Tianchi", ""], ["Wu", "Chenglei", ""], ["Zhang", "Rui-Xiao", ""], ["Sun", "Lifeng", ""]]}, {"id": "1910.10997", "submitter": "Ziwei Liu", "authors": "Hang Zhou, Ziwei Liu, Xudong Xu, Ping Luo, Xiaogang Wang", "title": "Vision-Infused Deep Audio Inpainting", "comments": "To appear in ICCV 2019. Code, models, dataset and video results are\n  available at the project page:\n  https://hangz-nju-cuhk.github.io/projects/AudioInpainting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modality perception is essential to develop interactive intelligence.\nIn this work, we consider a new task of visual information-infused audio\ninpainting, \\ie synthesizing missing audio segments that correspond to their\naccompanying videos. We identify two key aspects for a successful inpainter:\n(1) It is desirable to operate on spectrograms instead of raw audios. Recent\nadvances in deep semantic image inpainting could be leveraged to go beyond the\nlimitations of traditional audio inpainting. (2) To synthesize visually\nindicated audio, a visual-audio joint feature space needs to be learned with\nsynchronization of audio and video. To facilitate a large-scale study, we\ncollect a new multi-modality instrument-playing dataset called MUSIC-Extra-Solo\n(MUSICES) by enriching MUSIC dataset. Extensive experiments demonstrate that\nour framework is capable of inpainting realistic and varying audio segments\nwith or without visual contexts. More importantly, our synthesized audio\nsegments are coherent with their video counterparts, showing the effectiveness\nof our proposed Vision-Infused Audio Inpainter (VIAI). Code, models, dataset\nand video results are available at\nhttps://hangz-nju-cuhk.github.io/projects/AudioInpainting\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 09:41:44 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Zhou", "Hang", ""], ["Liu", "Ziwei", ""], ["Xu", "Xudong", ""], ["Luo", "Ping", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1910.11015", "submitter": "Nargiz Humbatova", "authors": "Nargiz Humbatova, Gunel Jahangirova, Gabriele Bavota, Vincenzo Riccio,\n  Andrea Stocco, Paolo Tonella", "title": "Taxonomy of Real Faults in Deep Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growing application of deep neural networks in safety-critical domains\nmakes the analysis of faults that occur in such systems of enormous importance.\nIn this paper we introduce a large taxonomy of faults in deep learning (DL)\nsystems. We have manually analysed 1059 artefacts gathered from GitHub commits\nand issues of projects that use the most popular DL frameworks (TensorFlow,\nKeras and PyTorch) and from related Stack Overflow posts. Structured interviews\nwith 20 researchers and practitioners describing the problems they have\nencountered in their experience have enriched our taxonomy with a variety of\nadditional faults that did not emerge from the other two sources. Our final\ntaxonomy was validated with a survey involving an additional set of 21\ndevelopers, confirming that almost all fault categories (13/15) were\nexperienced by at least 50% of the survey participants.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 10:23:59 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 14:43:38 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2019 13:19:46 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Humbatova", "Nargiz", ""], ["Jahangirova", "Gunel", ""], ["Bavota", "Gabriele", ""], ["Riccio", "Vincenzo", ""], ["Stocco", "Andrea", ""], ["Tonella", "Paolo", ""]]}, {"id": "1910.11016", "submitter": "Tarun Yenamandra", "authors": "Tarun Yenamandra, Florian Bernard, Jiayi Wang, Franziska Mueller,\n  Christian Theobalt", "title": "Convex Optimisation for Inverse Kinematics", "comments": null, "journal-ref": null, "doi": "10.1109/3DV.2019.00043", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inverse kinematics (IK), where one wants to find\nthe parameters of a given kinematic skeleton that best explain a set of\nobserved 3D joint locations. The kinematic skeleton has a tree structure, where\neach node is a joint that has an associated geometric transformation that is\npropagated to all its child nodes. The IK problem has various applications in\nvision and graphics, for example for tracking or reconstructing articulated\nobjects, such as human hands or bodies. Most commonly, the IK problem is\ntackled using local optimisation methods. A major downside of these approaches\nis that, due to the non-convex nature of the problem, such methods are prone to\nconverge to unwanted local optima and therefore require a good initialisation.\nIn this paper we propose a convex optimisation approach for the IK problem\nbased on semidefinite programming, which admits a polynomial-time algorithm\nthat globally solves (a relaxation of) the IK problem. Experimentally, we\ndemonstrate that the proposed method significantly outperforms local\noptimisation methods using different real-world skeletons.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 10:25:23 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Yenamandra", "Tarun", ""], ["Bernard", "Florian", ""], ["Wang", "Jiayi", ""], ["Mueller", "Franziska", ""], ["Theobalt", "Christian", ""]]}, {"id": "1910.11030", "submitter": "Tu  Nguyen", "authors": "Tu Nguyen", "title": "Spatiotemporal Tile-based Attention-guided LSTMs for Traffic Video\n  Prediction", "comments": "Neurips 2019 Traffic4Cast Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This extended abstract describes our solution for the Traffic4Cast Challenge\n2019. The key problem we addressed is to properly model both low-level (pixel\nbased) and high-level spatial information while still preserve the temporal\nrelations among the frames. Our approach is inspired by the recent adoption of\nconvolutional features into a recurrent neural networks such as LSTM to jointly\ncapture the spatio-temporal dependency. While this approach has been proven to\nsurpass the traditional stacked CNNs (using 2D or 3D kernels) in action\nrecognition, we observe suboptimal performance in traffic prediction setting.\nTherefore, we apply a number of adaptations in the frame encoder-decoder layers\nand in sampling procedure to better capture the high-resolution trajectories,\nand to increase the training efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 11:05:22 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 19:16:00 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 22:06:32 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Nguyen", "Tu", ""]]}, {"id": "1910.11033", "submitter": "Tristan Hascoet", "authors": "Tristan Hascoet, Xuejiao Deng, Kiyoto Tai, Mari Sugiyama, Yuji Adachi,\n  Sachiko Nakamura, Yasuo Ariki, Tomoko Hayashi, Tetusya Takiguchi", "title": "Assisting human experts in the interpretation of their visual process: A\n  case study on assessing copper surface adhesive potency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are often though to lack interpretability due to the\ndistributed nature of their internal representations. In contrast, humans can\ngenerally justify, in natural language, for their answer to a visual question\nwith simple common sense reasoning. However, human introspection abilities have\ntheir own limits as one often struggles to justify for the recognition process\nbehind our lowest level feature recognition ability: for instance, it is\ndifficult to precisely explain why a given texture seems more characteristic of\nthe surface of a finger nail rather than a plastic bottle. In this paper, we\nshowcase an application in which deep learning models can actually help human\nexperts justify for their own low-level visual recognition process: We study\nthe problem of assessing the adhesive potency of copper sheets from microscopic\npictures of their surface. Although highly trained material experts are able to\nqualitatively assess the surface adhesive potency, they are often unable to\nprecisely justify for their decision process. We present a model that, under\ncareful design considerations, is able to provide visual clues for human\nexperts to understand and justify for their own recognition process. Not only\ncan our model assist human experts in their interpretation of the surface\ncharacteristics, we show how this model can be used to test different\nhypothesis of the copper surface response to different manufacturing processes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 11:23:58 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Hascoet", "Tristan", ""], ["Deng", "Xuejiao", ""], ["Tai", "Kiyoto", ""], ["Sugiyama", "Mari", ""], ["Adachi", "Yuji", ""], ["Nakamura", "Sachiko", ""], ["Ariki", "Yasuo", ""], ["Hayashi", "Tomoko", ""], ["Takiguchi", "Tetusya", ""]]}, {"id": "1910.11065", "submitter": "Anthony Bourached", "authors": "Anthony Bourached, Parashkev Nachev", "title": "Unsupervised Videographic Analysis of Rodent Behaviour", "comments": "Resubmission with fixed typos and updated data source information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animal behaviour is complex and the amount of data in the form of video, if\nextracted, is copious. Manual analysis of behaviour is massively limited by two\ninsurmountable obstacles, the complexity of the behavioural patterns and human\nbias. Automated visual analysis has the potential to eliminate both of these\nissues and also enable continuous analysis allowing a much higher bandwidth of\ndata collection which is vital to capture complex behaviour at many different\ntime scales. Behaviour is not confined to a finite set modules and thus we can\nonly model it by inferring the generative distribution. In this way\nunpredictable, anomalous behaviour may be considered. Here we present a method\nof unsupervised behavioural analysis from nothing but high definition video\nrecordings taken from a single, fixed perspective. We demonstrate that the\nidentification of stereotyped rodent behaviour can be extracted in this way.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 14:44:55 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 01:06:20 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Bourached", "Anthony", ""], ["Nachev", "Parashkev", ""]]}, {"id": "1910.11067", "submitter": "Cat Le", "authors": "Cat P. Le, Yi Zhou, Jie Ding, Vahid Tarokh", "title": "Supervised Encoding for Discrete Representation Learning", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054118", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical supervised classification tasks search for a nonlinear mapping that\nmaps each encoded feature directly to a probability mass over the labels. Such\na learning framework typically lacks the intuition that encoded features from\nthe same class tend to be similar and thus has little interpretability for the\nlearned features. In this paper, we propose a novel supervised learning model\nnamed Supervised-Encoding Quantizer (SEQ). The SEQ applies a quantizer to\ncluster and classify the encoded features. We found that the quantizer provides\nan interpretable graph where each cluster in the graph represents a class of\ndata samples that have a particular style. We also trained a decoder that can\ndecode convex combinations of the encoded features from similar and different\nclusters and provide guidance on style transfer between sub-classes.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 02:42:10 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Le", "Cat P.", ""], ["Zhou", "Yi", ""], ["Ding", "Jie", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1910.11072", "submitter": "Kyu Beom Lee", "authors": "Kyu-Beom Lee and Hyu-Soung Shin", "title": "Self-enhancement of automatic tunnel accident detection (TAD) on CCTV by\n  AI deep-learning", "comments": "13 pages, 8 figures, 4 tables, The 2019 International Conference on\n  Tunnels and Underground Spaces(ICTUS 19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep-learning-based tunnel accident detection (TAD) system (Lee 2019) has\ninstalled a system capable of monitoring 9 CCTVs at XX site in November, 2018.\nThe initial deep-learning training was started by studying 70,914 labeled\nimages and label data. However, sunlight, the tail light of a vehicle, and the\nwarning light of the working vehicle were recognized as a fire, and many\npedestrians were detected in the lane of the tunnel or a black elongated black\nobject. To solve these problems, as shown in Fig. 1, the false detection data\ndetected in the field were trained with labeled data and reapplied in the\nfield. As a result, false detection of pedestrians and fire could be\nsignificantly reduced.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 04:19:56 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Lee", "Kyu-Beom", ""], ["Shin", "Hyu-Soung", ""]]}, {"id": "1910.11080", "submitter": "Alexander Usvyatsov", "authors": "Alexander Usvyatsov", "title": "On sample complexity of neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider functions defined by deep neural networks as definable objects in\nan o-miminal expansion of the real field, and derive an almost linear (in the\nnumber of weights) bound on sample complexity of such networks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 13:38:08 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Usvyatsov", "Alexander", ""]]}, {"id": "1910.11086", "submitter": "Ethan Harris", "authors": "Ethan Harris, Daniela Mihai, Jonathon Hare", "title": "Spatial and Colour Opponency in Anatomically Constrained Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colour vision has long fascinated scientists, who have sought to understand\nboth the physiology of the mechanics of colour vision and the psychophysics of\ncolour perception. We consider representations of colour in anatomically\nconstrained convolutional deep neural networks. Following ideas from\nneuroscience, we classify cells in early layers into groups relating to their\nspectral and spatial functionality. We show the emergence of single and double\nopponent cells in our networks and characterise how the distribution of these\ncells changes under the constraint of a retinal bottleneck. Our experiments not\nonly open up a new understanding of how deep networks process spatial and\ncolour information, but also provide new tools to help understand the black box\nof deep learning. The code for all experiments is avaialable at\n\\url{https://github.com/ecs-vlc/opponency}.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 15:28:44 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Harris", "Ethan", ""], ["Mihai", "Daniela", ""], ["Hare", "Jonathon", ""]]}, {"id": "1910.11089", "submitter": "Jiahuan Luo", "authors": "Jiahuan Luo, Xueyang Wu, Yun Luo, Anbu Huang, Yunfeng Huang, Yang Liu\n  and Qiang Yang", "title": "Real-World Image Datasets for Federated Learning", "comments": "This paper is published at the 2nd International Workshop on\n  Federated Learning for Data Privacy and Confidentiality, in Conjunction with\n  NeurIPS 2019 (FL-NeurIPS 19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a new machine learning paradigm which allows data\nparties to build machine learning models collaboratively while keeping their\ndata secure and private. While research efforts on federated learning have been\ngrowing tremendously in the past two years, most existing works still depend on\npre-existing public datasets and artificial partitions to simulate data\nfederations due to the lack of high-quality labeled data generated from\nreal-world edge applications. Consequently, advances on benchmark and model\nevaluations for federated learning have been lagging behind. In this paper, we\nintroduce a real-world image dataset. The dataset contains more than 900 images\ngenerated from 26 street cameras and 7 object categories annotated with\ndetailed bounding box. The data distribution is non-IID and unbalanced,\nreflecting the characteristic real-world federated learning scenarios. Based on\nthis dataset, we implemented two mainstream object detection algorithms (YOLO\nand Faster R-CNN) and provided an extensive benchmark on model performance,\nefficiency, and communication in a federated learning setting. Both the dataset\nand algorithms are made publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 09:33:26 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 09:22:56 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 06:31:32 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Luo", "Jiahuan", ""], ["Wu", "Xueyang", ""], ["Luo", "Yun", ""], ["Huang", "Anbu", ""], ["Huang", "Yunfeng", ""], ["Liu", "Yang", ""], ["Yang", "Qiang", ""]]}, {"id": "1910.11090", "submitter": "Dimitrios Kollias", "authors": "Aritra Banerjee and Dimitrios Kollias", "title": "Emotion Generation and Recognition: A StarGAN Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main idea of this ISO is to use StarGAN (A type of GAN model) to perform\ntraining and testing on an emotion dataset resulting in a emotion recognition\nwhich can be generated by the valence arousal score of the 7 basic expressions.\nWe have created an entirely new dataset consisting of 4K videos. This dataset\nconsists of all the basic 7 types of emotions: Happy, Sad, Angry, Surprised,\nFear, Disgust, Neutral. We have performed face detection and alignment followed\nby annotating basic valence arousal values to the frames/images in the dataset\ndepending on the emotions manually. Then the existing StarGAN model is trained\non our created dataset after which some manual subjects were chosen to test the\nefficiency of the trained StarGAN model.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 16:24:46 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Banerjee", "Aritra", ""], ["Kollias", "Dimitrios", ""]]}, {"id": "1910.11093", "submitter": "Ivan Sosnovik", "authors": "Ivan Sosnovik, Micha{\\l} Szmaja, Arnold Smeulders", "title": "Scale-Equivariant Steerable Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of Convolutional Neural Networks (CNNs) has been\nsubstantially attributed to their built-in property of translation\nequivariance. However, CNNs do not have embedded mechanisms to handle other\ntypes of transformations. In this work, we pay attention to scale changes,\nwhich regularly appear in various tasks due to the changing distances between\nthe objects and the camera. First, we introduce the general theory for building\nscale-equivariant convolutional networks with steerable filters. We develop\nscale-convolution and generalize other common blocks to be scale-equivariant.\nWe demonstrate the computational efficiency and numerical stability of the\nproposed method. We compare the proposed models to the previously developed\nmethods for scale equivariance and local scale invariance. We demonstrate\nstate-of-the-art results on MNIST-scale dataset and on STL-10 dataset in the\nsupervised learning setting.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:46:34 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 14:09:17 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Sosnovik", "Ivan", ""], ["Szmaja", "Micha\u0142", ""], ["Smeulders", "Arnold", ""]]}, {"id": "1910.11094", "submitter": "Kyu Beom Lee", "authors": "Kyu-Beom Lee and Hyu-Soung Shin", "title": "An application of a deep learning algorithm for automatic detection of\n  unexpected accidents under bad CCTV monitoring conditions in tunnels", "comments": "10 pages, 5 figures, 2019 International Conference on Deep Learning\n  and Machine Learning in Emerging Applications (Deep-ML)", "journal-ref": "978-1-7281-2914-3/19/$31.00 \\c{opyright}2019 IEEE", "doi": "10.1109/Deep-ML.2019.00010", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, Object Detection and Tracking System (ODTS) in combination\nwith a well-known deep learning network, Faster Regional Convolution Neural\nNetwork (Faster R-CNN), for Object Detection and Conventional Object Tracking\nalgorithm will be introduced and applied for automatic detection and monitoring\nof unexpected events on CCTVs in tunnels, which are likely to (1) Wrong-Way\nDriving (WWD), (2) Stop, (3) Person out of vehicle in tunnel (4) Fire. ODTS\naccepts a video frame in time as an input to obtain Bounding Box (BBox) results\nby Object Detection and compares the BBoxs of the current and previous video\nframes to assign a unique ID number to each moving and detected object. This\nsystem makes it possible to track a moving object in time, which is not usual\nto be achieved in conventional object detection frameworks. A deep learning\nmodel in ODTS was trained with a dataset of event images in tunnels to Average\nPrecision (AP) values of 0.8479, 0.7161 and 0.9085 for target objects: Car,\nPerson, and Fire, respectively. Then, based on trained deep learning model, the\nODTS based Tunnel CCTV Accident Detection System was tested using four accident\nvideos which including each accident. As a result, the system can detect all\naccidents within 10 seconds. The more important point is that the detection\ncapacity of ODTS could be enhanced automatically without any changes in the\nprogram codes as the training dataset becomes rich.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 04:28:44 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Lee", "Kyu-Beom", ""], ["Shin", "Hyu-Soung", ""]]}, {"id": "1910.11097", "submitter": "Neofytos Dimitriou", "authors": "Neofytos Dimitriou, Ognjen Arandjelovi\\'c, Peter D Caie", "title": "Deep Learning for Whole Slide Image Analysis: An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread adoption of whole slide imaging has increased the demand for\neffective and efficient gigapixel image analysis. Deep learning is at the\nforefront of computer vision, showcasing significant improvements over previous\nmethodologies on visual understanding. However, whole slide images have\nbillions of pixels and suffer from high morphological heterogeneity as well as\nfrom different types of artefacts. Collectively, these impede the conventional\nuse of deep learning. For the clinical translation of deep learning solutions\nto become a reality, these challenges need to be addressed. In this paper, we\nreview work on the interdisciplinary attempt of training deep neural networks\nusing whole slide images, and highlight the different ideas underlying these\nmethodologies.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 17:53:42 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Dimitriou", "Neofytos", ""], ["Arandjelovi\u0107", "Ognjen", ""], ["Caie", "Peter D", ""]]}, {"id": "1910.11099", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Gaoyuan Zhang, Sijia Liu, Quanfu Fan, Mengshu Sun, Hongge\n  Chen, Pin-Yu Chen, Yanzhi Wang, Xue Lin", "title": "Adversarial T-shirt! Evading Person Detectors in A Physical World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that deep neural networks (DNNs) are vulnerable to adversarial\nattacks. The so-called physical adversarial examples deceive DNN-based\ndecisionmakers by attaching adversarial patches to real objects. However, most\nof the existing works on physical adversarial attacks focus on static objects\nsuch as glass frames, stop signs and images attached to cardboard. In this\nwork, we proposed adversarial T-shirts, a robust physical adversarial example\nfor evading person detectors even if it could undergo non-rigid deformation due\nto a moving person's pose changes. To the best of our knowledge, this is the\nfirst work that models the effect of deformation for designing physical\nadversarial examples with respect to-rigid objects such as T-shirts. We show\nthat the proposed method achieves74% and 57% attack success rates in the\ndigital and physical worlds respectively against YOLOv2. In contrast, the\nstate-of-the-art physical attack method to fool a person detector only achieves\n18% attack success rate. Furthermore, by leveraging min-max optimization, we\nextend our method to the ensemble attack setting against two object detectors\nYOLO-v2 and Faster R-CNN simultaneously.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 02:20:17 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 00:37:43 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 03:06:26 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Xu", "Kaidi", ""], ["Zhang", "Gaoyuan", ""], ["Liu", "Sijia", ""], ["Fan", "Quanfu", ""], ["Sun", "Mengshu", ""], ["Chen", "Hongge", ""], ["Chen", "Pin-Yu", ""], ["Wang", "Yanzhi", ""], ["Lin", "Xue", ""]]}, {"id": "1910.11104", "submitter": "Lucas C. Uzal", "authors": "Facundo Tuesca, Lucas C. Uzal", "title": "Exploiting video sequences for unsupervised disentangling in generative\n  adversarial networks", "comments": "This preprint is the result of the work done for the undergraduate\n  dissertation of F. Tuesca supervised by L.C. Uzal and presented in June 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present an adversarial training algorithm that exploits\ncorrelations in video to learn --without supervision-- an image generator model\nwith a disentangled latent space. The proposed methodology requires only a few\nmodifications to the standard algorithm of Generative Adversarial Networks\n(GAN) and involves training with sets of frames taken from short videos. We\ntrain our model over two datasets of face-centered videos which present\ndifferent people speaking or moving the head: VidTIMIT and YouTube Faces\ndatasets. We found that our proposal allows us to split the generator latent\nspace into two subspaces. One of them controls content attributes, those that\ndo not change along short video sequences. For the considered datasets, this is\nthe identity of the generated face. The other subspace controls motion\nattributes, those attributes that are observed to change along short videos. We\nobserved that these motion attributes are face expressions, head orientation,\nlips and eyes movement. The presented experiments provide quantitative and\nqualitative evidence supporting that the proposed methodology induces a\ndisentangling of this two kinds of attributes in the latent space.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:37:43 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Tuesca", "Facundo", ""], ["Uzal", "Lucas C.", ""]]}, {"id": "1910.11105", "submitter": "Lior Wolf", "authors": "Barak Battash, Lior Wolf", "title": "Adaptive and Iteratively Improving Recurrent Lateral Connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current leading computer vision models are typically feed forward neural\nmodels, in which the output of one computational block is passed to the next\none sequentially. This is in sharp contrast to the organization of the primate\nvisual cortex, in which feedback and lateral connections are abundant. In this\nwork, we propose a computational model for the role of lateral connections in a\ngiven block, in which the weights of the block vary dynamically as a function\nof its activations, and the input from the upstream blocks is iteratively\nreintroduced. We demonstrate how this novel architectural modification can lead\nto sizable gains in performance, when applied to visual action recognition\nwithout pretraining and that it outperforms the literature architectures with\nrecurrent feedback processing on ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 16:58:26 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Battash", "Barak", ""], ["Wolf", "Lior", ""]]}, {"id": "1910.11106", "submitter": "David Donahue", "authors": "David Donahue", "title": "Label-Conditioned Next-Frame Video Generation with Neural Flows", "comments": "Computer Vision class project, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art video generation systems employ Generative\nAdversarial Networks (GANs) or Variational Autoencoders (VAEs) to produce novel\nvideos. However, VAE models typically produce blurry outputs when faced with\nsub-optimal conditioning of the input, and GANs are known to be unstable for\nlarge output sizes. In addition, the output videos of these models are\ndifficult to evaluate, partly because the GAN loss function is not an accurate\nmeasure of convergence. In this work, we propose using a state-of-the-art\nneural flow generator called Glow to generate videos conditioned on a textual\nlabel, one frame at a time. Neural flow models are more stable than standard\nGANs, as they only optimize a single cross entropy loss function, which is\nmonotonic and avoids the circular convergence issues of the GAN minimax\nobjective. In addition, we also show how to condition Glow on external context,\nwhile still preserving the invertible nature of each \"flow\" layer. Finally, we\nevaluate the proposed Glow model by calculating cross entropy on a held-out\nvalidation set of videos, in order to compare multiple versions of the proposed\nmodel via an ablation study. We show generated videos and discuss future\nimprovements.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 16:08:28 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Donahue", "David", ""]]}, {"id": "1910.11111", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias and Viktoriia Sharmanska and Stefanos Zafeiriou", "title": "Face Behavior a la carte: Expressions, Affect and Action Units in a\n  Single Network", "comments": "filed as a patent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic facial behavior analysis has a long history of studies in the\nintersection of computer vision, physiology and psychology. However it is only\nrecently, with the collection of large-scale datasets and powerful machine\nlearning methods such as deep neural networks, that automatic facial behavior\nanalysis started to thrive. Three of its iconic tasks are automatic recognition\nof basic expressions (e.g. happy, sad, surprised), estimation of continuous\nemotions (e.g., valence and arousal), and detection of facial action units\n(activations of e.g. upper/inner eyebrows, nose wrinkles). Up until now these\ntasks have been mostly studied independently collecting a dataset for the task.\nWe present the first and the largest study of all facial behaviour tasks\nlearned jointly in a single multi-task, multi-domain and multi-label network,\nwhich we call FaceBehaviorNet. For this we utilize all publicly available\ndatasets in the community (around 5M images) that study facial behaviour tasks\nin-the-wild. We demonstrate that training jointly an end-to-end network for all\ntasks has consistently better performance than training each of the single-task\nnetworks. Furthermore, we propose two simple strategies for coupling the tasks\nduring training, co-annotation and distribution matching, and show the\nadvantages of this approach. Finally we show that FaceBehaviorNet has learned\nfeatures that encapsulate all aspects of facial behaviour, and can be\nsuccessfully applied to perform tasks (compound emotion recognition) beyond the\nones that it has been trained in a zero- and few-shot learning setting.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:45:41 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 23:35:29 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 02:35:49 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Sharmanska", "Viktoriia", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1910.11117", "submitter": "Shubham Dokania", "authors": "Shubham Dokania, Vasudev Singh", "title": "Graph Representation learning for Audio & Music genre Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music genre is arguably one of the most important and discriminative\ninformation for music and audio content. Visual representation based approaches\nhave been explored on spectrograms for music genre classification. However,\nlack of quality data and augmentation techniques makes it difficult to employ\ndeep learning techniques successfully. We discuss the application of graph\nneural networks on such task due to their strong inductive bias, and show that\ncombination of CNN and GNN is able to achieve state-of-the-art results on\nGTZAN, and AudioSet (Imbalanced Music) datasets. We also discuss the role of\nSiamese Neural Networks as an analogous to GNN for learning edge similarity\nweights. Furthermore, we also perform visual analysis to understand the\nfield-of-view of our model into the spectrogram based on genre labels.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 13:59:23 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Dokania", "Shubham", ""], ["Singh", "Vasudev", ""]]}, {"id": "1910.11118", "submitter": "Kyle Robinson", "authors": "Kyle Robinson, Dan Brown", "title": "Shallow Art: Art Extension Through Simple Machine Learning", "comments": "5 pages, 9 figures, presented at the 10th International Conference on\n  Computational Creativity (ICCC 2019)", "journal-ref": "Proceedings of the 10th International Conference on Computational\n  Creativity (2019) 316-320 [ISBN: 978-989-54160-1-1]", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Shallow Art presents, implements, and tests the use of simple single-output\nclassification and regression models for the purpose of art generation. Various\nmachine learning algorithms are trained on collections of computer generated\nimages, artworks from Vincent van Gogh, and artworks from Rembrandt van Rijn.\nThese models are then provided half of an image and asked to complete the\nmissing side. The resulting images are displayed, and we explore implications\nfor computational creativity.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:47:06 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Robinson", "Kyle", ""], ["Brown", "Dan", ""]]}, {"id": "1910.11119", "submitter": "Jianri Li", "authors": "Jianri Li, Jae-whan Lee, Woo-sang Song, Ki-young Shin, Byung-hyun Go", "title": "Designovel's system description for Fashion-IQ challenge 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Designovel's systems which are submitted to the Fashion\nIQ Challenge 2019. Goal of the challenge is building an image retrieval system\nwhere input query is a candidate image plus two text phrases describe user's\nfeedback about visual differences between the candidate image and the search\ntarget. We built the systems by combining methods from recent work on deep\nmetric learning, multi-modal retrieval and natual language processing. First,\nwe encode both candidate and target images with CNNs into high-level\nrepresentations, and encode text descriptions to a single text vector using\nTransformer-based encoder. Then we compose candidate image vector and text\nrepresentation into a single vector which is exptected to be biased toward\ntarget image vector. Finally, we compute cosine similarities between composed\nvector and encoded vectors of whole dataset, and rank them in desceding order\nto get ranked list. We experimented with Fashion IQ 2019 dataset in various\nsettings of hyperparameters, achieved 39.12% average recall by a single model\nand 43.67% average recall by an ensemble of 16 models on test dataset.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:06:26 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Li", "Jianri", ""], ["Lee", "Jae-whan", ""], ["Song", "Woo-sang", ""], ["Shin", "Ki-young", ""], ["Go", "Byung-hyun", ""]]}, {"id": "1910.11122", "submitter": "Sheng Zou", "authors": "Sheng Zou, Yu-Chien Tseng, Alina Zare, Diane Rowland, Barry Tillman,\n  Seung-Chul Yoon", "title": "Peanut Maturity Classification using Hyperspectral Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seed maturity in peanut (Arachis hypogaea L.) determines economic return to a\nproducer because of its impact on seed weight (yield), and critically\ninfluences seed vigor and other quality characteristics. During seed\ndevelopment, the inner mesocarp layer of the pericarp (hull) transitions in\ncolor from white to black as the seed matures. The maturity assessment process\ninvolves the removal of the exocarp of the hull and visually categorizing the\nmesocarp color into varying color classes from immature (white, yellow, orange)\nto mature (brown, and black). This visual color classification is time\nconsuming because the exocarp must be manually removed. In addition, the visual\nclassification process involves human assessment of colors, which leads to\nlarge variability of color classification from observer to observer. A more\nobjective, digital imaging approach to peanut maturity is needed, optimally\nwithout the requirement of removal of the hull's exocarp. This study examined\nthe use of a hyperspectral imaging (HSI) process to determine pod maturity with\nintact pericarps. The HSI method leveraged spectral differences between mature\nand immature pods within a classification algorithm to identify the mature and\nimmature pods. The results showed a high classification accuracy with\nconsistency using samples from different years and cultivars. In addition, the\nproposed method was capable of estimating a continuous-valued, pixel-level\nmaturity value for individual peanut pods, allowing for a valuable tool that\ncan be utilized in seed quality research. This new method solves issues of\nlabor intensity and subjective error that all current methods of peanut\nmaturity determination have.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 22:51:49 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 00:33:46 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Zou", "Sheng", ""], ["Tseng", "Yu-Chien", ""], ["Zare", "Alina", ""], ["Rowland", "Diane", ""], ["Tillman", "Barry", ""], ["Yoon", "Seung-Chul", ""]]}, {"id": "1910.11123", "submitter": "Hamed Majidifard", "authors": "Hamed Majidifard, Peng Jin, Yaw Adu-Gyamfi, William G. Buttlar", "title": "Pavement Image Datasets: A New Benchmark Dataset to Classify and Densify\n  Pavement Distresses", "comments": null, "journal-ref": null, "doi": "10.1177/0361198120907283", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated pavement distresses detection using road images remains a\nchallenging topic in the computer vision research community. Recent\ndevelopments in deep learning has led to considerable research activity\ndirected towards improving the efficacy of automated pavement distress\nidentification and rating. Deep learning models require a large ground truth\ndata set, which is often not readily available in the case of pavements. In\nthis study, a labeled dataset approach is introduced as a first step towards a\nmore robust, easy-to-deploy pavement condition assessment system. The technique\nis termed herein as the Pavement Image Dataset (PID) method. The dataset\nconsists of images captured from two camera views of an identical pavement\nsegment, i.e., a wide-view and a top-down view. The wide-view images were used\nto classify the distresses and to train the deep learning frameworks, while the\ntop-down view images allowed calculation of distress density, which will be\nused in future studies aimed at automated pavement rating. For the wide view\ngroup dataset, 7,237 images were manually annotated and distresses classified\ninto nine categories. Images were extracted using the Google Application\nProgramming Interface (API), selecting street-view images using a python-based\ncode developed for this project. The new dataset was evaluated using two\nmainstream deep learning frameworks: You Only Look Once (YOLO v2) and Faster\nRegion Convolution Neural Network (Faster R-CNN). Accuracy scores using the F1\nindex were found to be 0.84 for YOLOv2 and 0.65 for the Faster R-CNN model\nruns; both quite acceptable considering the convenience of utilizing Google\nmaps images.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 04:55:37 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 06:10:33 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Majidifard", "Hamed", ""], ["Jin", "Peng", ""], ["Adu-Gyamfi", "Yaw", ""], ["Buttlar", "William G.", ""]]}, {"id": "1910.11124", "submitter": "Hammad Ayyubi", "authors": "Hammad A. Ayyubi, Md. Mehrab Tanjim and David J. Kriegman", "title": "Enforcing Reasoning in Visual Commonsense Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of Visual Commonsense Reasoning is extremely challenging in the\nsense that the model has to not only be able to answer a question given an\nimage, but also be able to learn to reason. The baselines introduced in this\ntask are quite limiting because two networks are trained for predicting answers\nand rationales separately. Question and image is used as input to train answer\nprediction network while question, image and correct answer are used as input\nin the rationale prediction network. As rationale is conditioned on the correct\nanswer, it is based on the assumption that we can solve Visual Question\nAnswering task without any error - which is over ambitious. Moreover, such an\napproach makes both answer and rationale prediction two completely independent\nVQA tasks rendering cognition task meaningless. In this paper, we seek to\naddress these issues by proposing an end-to-end trainable model which considers\nboth answers and their reasons jointly. Specifically, we first predict the\nanswer for the question and then use the chosen answer to predict the\nrationale. However, a trivial design of such a model becomes non-differentiable\nwhich makes it difficult to train. We solve this issue by proposing four\napproaches - softmax, gumbel-softmax, reinforcement learning based sampling and\ndirect cross entropy against all pairs of answers and rationales. We\ndemonstrate through experiments that our model performs competitively against\ncurrent state-of-the-art. We conclude with an analysis of presented approaches\nand discuss avenues for further work.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 02:33:18 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 10:09:58 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Ayyubi", "Hammad A.", ""], ["Tanjim", "Md. Mehrab", ""], ["Kriegman", "David J.", ""]]}, {"id": "1910.11126", "submitter": "Enea Ceolini", "authors": "Enea Ceolini, Gemma Taverni, Lyes Khacef, Melika Payvand, Elisa Donati", "title": "Sensor fusion using EMG and vision for hand gesture classification in\n  mobile applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discrimination of human gestures using wearable solutions is extremely\nimportant as a supporting technique for assisted living, healthcare of the\nelderly and neurorehabilitation. This paper presents a mobile electromyography\n(EMG) analysis framework to be an auxiliary component in physiotherapy sessions\nor as a feedback for neuroprosthesis calibration. We implemented a framework\nthat allows the integration of multisensors, EMG and visual information, to\nperform sensor fusion and to improve the accuracy of hand gesture recognition\ntasks. In particular, we used an event-based camera adapted to run on the\nlimited computational resources of mobile phones. We introduced a new publicly\navailable dataset of sensor fusion for hand gesture recognition recorded from\n10 subjects and used it to train the recognition models offline. We compare the\nonline results of the hand gesture recognition using the fusion approach with\nthe individual sensors with an improvement in the accuracy of 13% and 11%, for\nEMG and vision respectively, reaching 85%.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 00:02:48 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Ceolini", "Enea", ""], ["Taverni", "Gemma", ""], ["Khacef", "Lyes", ""], ["Payvand", "Melika", ""], ["Donati", "Elisa", ""]]}, {"id": "1910.11133", "submitter": "Prem Seetharaman", "authors": "Prem Seetharaman, Gordon Wichern, Jonathan Le Roux, Bryan Pardo", "title": "Bootstrapping deep music separation from primitive auditory grouping\n  principles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating an audio scene such as a cocktail party into constituent,\nmeaningful components is a core task in computer audition. Deep networks are\nthe state-of-the-art approach. They are trained on synthetic mixtures of audio\nmade from isolated sound source recordings so that ground truth for the\nseparation is known. However, the vast majority of available audio is not\nisolated. The brain uses primitive cues that are independent of the\ncharacteristics of any particular sound source to perform an initial\nsegmentation of the audio scene. We present a method for bootstrapping a deep\nmodel for music source separation without ground truth by using multiple\nprimitive cues. We apply our method to train a network on a large set of\nunlabeled music recordings from YouTube to separate vocals from accompaniment\nwithout the need for ground truth isolated sources or artificial training\nmixtures.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:44:13 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Seetharaman", "Prem", ""], ["Wichern", "Gordon", ""], ["Roux", "Jonathan Le", ""], ["Pardo", "Bryan", ""]]}, {"id": "1910.11141", "submitter": "Alexey Radul", "authors": "Alexey Radul, Brian Patton, Dougal Maclaurin, Matthew D. Hoffman and\n  Rif A. Saurous", "title": "Automatically Batching Control-Intensive Programs for Modern\n  Accelerators", "comments": "10 pages; Machine Learning and Systems 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a general approach to batching arbitrary computations for\naccelerators such as GPUs. We show orders-of-magnitude speedups using our\nmethod on the No U-Turn Sampler (NUTS), a workhorse algorithm in Bayesian\nstatistics. The central challenge of batching NUTS and other Markov chain Monte\nCarlo algorithms is data-dependent control flow and recursion. We overcome this\nby mechanically transforming a single-example implementation into a form that\nexplicitly tracks the current program point for each batch member, and only\nsteps forward those in the same place. We present two different batching\nalgorithms: a simpler, previously published one that inherits recursion from\nthe host Python, and a more complex, novel one that implemenents recursion\ndirectly and can batch across it. We implement these batching methods as a\ngeneral program transformation on Python source. Both the batching system and\nthe NUTS implementation presented here are available as part of the popular\nTensorFlow Probability software package.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 14:06:18 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 15:56:56 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Radul", "Alexey", ""], ["Patton", "Brian", ""], ["Maclaurin", "Dougal", ""], ["Hoffman", "Matthew D.", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1910.11144", "submitter": "Hossein Baktash", "authors": "Hossein Baktash (CRISAM, SUT), Emanuele Natale (COATI), Laurent\n  Viennot (GANG)", "title": "A Comparative Study of Neural Network Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been an increasing desire to evaluate neural networks\nlocally on computationally-limited devices in order to exploit their recent\neffectiveness for several applications; such effectiveness has nevertheless\ncome together with a considerable increase in the size of modern neural\nnetworks, which constitute a major downside in several of the aforementioned\ncomputationally-limited settings. There has thus been a demand of compression\ntechniques for neural networks. Several proposal in this direction have been\nmade, which famously include hashing-based methods and pruning-based ones.\nHowever, the evaluation of the efficacy of these techniques has so far been\nheterogeneous, with no clear evidence in favor of any of them over the others.\nThe goal of this work is to address this latter issue by providing a\ncomparative study. While most previous studies test the capability of a\ntechnique in reducing the number of parameters of state-of-the-art networks ,\nwe follow [CWT + 15] in evaluating their performance on basic ar-chitectures on\nthe MNIST dataset and variants of it, which allows for a clearer analysis of\nsome aspects of their behavior. To the best of our knowledge, we are the first\nto directly compare famous approaches such as HashedNet, Optimal Brain Damage\n(OBD), and magnitude-based pruning with L1 and L2 regularization among them and\nagainst equivalent-size feed-forward neural networks with simple\n(fully-connected) and structural (convolutional) neural networks. Rather\nsurprisingly, our experiments show that (iterative) pruning-based methods are\nsubstantially better than the HashedNet architecture, whose compression doesn't\nappear advantageous to a carefully chosen convolutional network. We also show\nthat, when the compression level is high, the famous OBD pruning heuristics\ndeteriorates to the point of being less efficient than simple magnitude-based\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 14:08:51 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Baktash", "Hossein", "", "CRISAM, SUT"], ["Natale", "Emanuele", "", "COATI"], ["Viennot", "Laurent", "", "GANG"]]}, {"id": "1910.11148", "submitter": "Qiegen Liu", "authors": "Zhuonan He, Jinjie Zhou, Dong Liang, Yuhao Wang, Qiegen Liu", "title": "Learning Priors in High-frequency Domain for Inverse Imaging\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ill-posed inverse problems in imaging remain an active research topic in\nseveral decades, with new approaches constantly emerging. Recognizing that the\npopular dictionary learning and convolutional sparse coding are both\nessentially modeling the high-frequency component of an image, which convey\nmost of the semantic information such as texture details, in this work we\npropose a novel multi-profile high-frequency transform-guided denoising\nautoencoder as prior (HF-DAEP). To achieve this goal, we first extract a set of\nmulti-profile high-frequency components via a specific transformation and add\nthe artificial Gaussian noise to these high-frequency components as training\nsamples. Then, as the high-frequency prior information is learned, we\nincorporate it into classical iterative reconstruction process by proximal\ngradient descent technique. Preliminary results on highly under-sampled\nmagnetic resonance imaging and sparse-view computed tomography reconstruction\ndemonstrate that the proposed method can efficiently reconstruct feature\ndetails and present advantages over state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 14:15:42 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["He", "Zhuonan", ""], ["Zhou", "Jinjie", ""], ["Liang", "Dong", ""], ["Wang", "Yuhao", ""], ["Liu", "Qiegen", ""]]}, {"id": "1910.11160", "submitter": "Rulin Shao", "authors": "Rulin Shao, Hongyu He, Hui Liu, Dianbo Liu", "title": "Stochastic Channel-Based Federated Learning for Medical Data Privacy\n  Preserving", "comments": "6 pages including references, 2 figures, Machine Learning for Health\n  (ML4H) at NeurIPS 2019 - Extended Abstract. arXiv admin note: substantial\n  text overlap with arXiv:1910.02115", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial neural network has achieved unprecedented success in the medical\ndomain. This success depends on the availability of massive and representative\ndatasets. However, data collection is often prevented by privacy concerns and\npeople want to take control over their sensitive information during both\ntraining and using processes. To address this problem, we propose a\nprivacy-preserving method for the distributed system, Stochastic Channel-Based\nFederated Learning (SCBF), which enables the participants to train a\nhigh-performance model cooperatively without sharing their inputs.\nSpecifically, we design, implement and evaluate a channel-based update\nalgorithm for the central server in a distributed system, which selects the\nchannels with regard to the most active features in a training loop and uploads\nthem as learned information from local datasets. A pruning process is applied\nto the algorithm based on the validation set, which serves as a model\naccelerator. In the experiment, our model presents better performances and\nhigher saturating speed than the Federated Averaging method which reveals all\nthe parameters of local models to the server when updating. We also demonstrate\nthat the saturating rate of performance could be promoted by introducing a\npruning process. And further improvement could be achieved by tuning the\npruning rate. Our experiment shows that 57% of the time is saved by the pruning\nprocess with only a reduction of 0.0047 in AUCROC performance and a reduction\nof 0.0068 in AUCPR.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 05:08:55 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 08:26:57 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 15:00:57 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Shao", "Rulin", ""], ["He", "Hongyu", ""], ["Liu", "Hui", ""], ["Liu", "Dianbo", ""]]}, {"id": "1910.11162", "submitter": "Mathias Perslev", "authors": "Mathias Perslev, Michael Hejselbak Jensen, Sune Darkner, Poul\n  J{\\o}rgen Jennum, Christian Igel", "title": "U-Time: A Fully Convolutional Network for Time Series Segmentation\n  Applied to Sleep Staging", "comments": "To appear in Advances in Neural Information Processing Systems\n  (NeurIPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are becoming more and more popular for the analysis of\nphysiological time-series. The most successful deep learning systems in this\ndomain combine convolutional and recurrent layers to extract useful features to\nmodel temporal relations. Unfortunately, these recurrent models are difficult\nto tune and optimize. In our experience, they often require task-specific\nmodifications, which makes them challenging to use for non-experts. We propose\nU-Time, a fully feed-forward deep learning approach to physiological time\nseries segmentation developed for the analysis of sleep data. U-Time is a\ntemporal fully convolutional network based on the U-Net architecture that was\noriginally proposed for image segmentation. U-Time maps sequential inputs of\narbitrary length to sequences of class labels on a freely chosen temporal\nscale. This is done by implicitly classifying every individual time-point of\nthe input signal and aggregating these classifications over fixed intervals to\nform the final predictions. We evaluated U-Time for sleep stage classification\non a large collection of sleep electroencephalography (EEG) datasets. In all\ncases, we found that U-Time reaches or outperforms current state-of-the-art\ndeep learning models while being much more robust in the training process and\nwithout requiring architecture or hyperparameter adaptation across tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 14:20:47 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Perslev", "Mathias", ""], ["Jensen", "Michael Hejselbak", ""], ["Darkner", "Sune", ""], ["Jennum", "Poul J\u00f8rgen", ""], ["Igel", "Christian", ""]]}, {"id": "1910.11174", "submitter": "Zheng Lian", "authors": "Zheng Lian, Ya Li, Jianhua Tao, Jian Huang", "title": "Speech Emotion Recognition via Contrastive Loss under Siamese Networks", "comments": "ASMMC-MMAC 2018 Proceedings of the Joint Workshop of the 4th Workshop\n  on Affective Social Multimedia Computing and first Multi-Modal Affective\n  Computing of Large-Scale Multimedia Data", "journal-ref": null, "doi": "10.1145/3267935.3267946", "report-no": null, "categories": "cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech emotion recognition is an important aspect of human-computer\ninteraction. Prior work proposes various end-to-end models to improve the\nclassification performance. However, most of them rely on the cross-entropy\nloss together with softmax as the supervision component, which does not\nexplicitly encourage discriminative learning of features. In this paper, we\nintroduce the contrastive loss function to encourage intra-class compactness\nand inter-class separability between learnable features. Furthermore, multiple\nfeature selection methods and pairwise sample selection methods are evaluated.\nTo verify the performance of the proposed system, we conduct experiments on The\nInteractive Emotional Dyadic Motion Capture (IEMOCAP) database, a common\nevaluation corpus. Experimental results reveal the advantages of the proposed\nmethod, which reaches 62.19% in the weighted accuracy and 63.21% in the\nunweighted accuracy. It outperforms the baseline system that is optimized\nwithout the contrastive loss function with 1.14% and 2.55% in the weighted\naccuracy and the unweighted accuracy, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:43:42 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Lian", "Zheng", ""], ["Li", "Ya", ""], ["Tao", "Jianhua", ""], ["Huang", "Jian", ""]]}, {"id": "1910.11215", "submitter": "Sudeep Dasari", "authors": "Sudeep Dasari, Frederik Ebert, Stephen Tian, Suraj Nair, Bernadette\n  Bucher, Karl Schmeckpeper, Siddharth Singh, Sergey Levine, Chelsea Finn", "title": "RoboNet: Large-Scale Multi-Robot Learning", "comments": "accepted at the Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot learning has emerged as a promising tool for taming the complexity and\ndiversity of the real world. Methods based on high-capacity models, such as\ndeep networks, hold the promise of providing effective generalization to a wide\nrange of open-world environments. However, these same methods typically require\nlarge amounts of diverse training data to generalize effectively. In contrast,\nmost robotic learning experiments are small-scale, single-domain, and\nsingle-robot. This leads to a frequent tension in robotic learning: how can we\nlearn generalizable robotic controllers without having to collect impractically\nlarge amounts of data for each separate experiment? In this paper, we propose\nRoboNet, an open database for sharing robotic experience, which provides an\ninitial pool of 15 million video frames, from 7 different robot platforms, and\nstudy how it can be used to learn generalizable models for vision-based robotic\nmanipulation. We combine the dataset with two different learning algorithms:\nvisual foresight, which uses forward video prediction models, and supervised\ninverse models. Our experiments test the learned algorithms' ability to work\nacross new objects, new tasks, new scenes, new camera viewpoints, new grippers,\nor even entirely new robots. In our final experiment, we find that by\npre-training on RoboNet and fine-tuning on data from a held-out Franka or Kuka\nrobot, we can exceed the performance of a robot-specific training approach that\nuses 4x-20x more data. For videos and data, see the project webpage:\nhttps://www.robonet.wiki/\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 15:20:03 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 06:26:37 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Dasari", "Sudeep", ""], ["Ebert", "Frederik", ""], ["Tian", "Stephen", ""], ["Nair", "Suraj", ""], ["Bucher", "Bernadette", ""], ["Schmeckpeper", "Karl", ""], ["Singh", "Siddharth", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1910.11217", "submitter": "Yangyang Xu", "authors": "Yibo Xu and Yangyang Xu", "title": "Katyusha Acceleration for Convex Finite-Sum Compositional Optimization", "comments": "Accepted in INFORMS J. on Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured problems arise in many applications. To solve these problems, it\nis important to leverage the structure information. This paper focuses on\nconvex problems with a finite-sum compositional structure. Finite-sum problems\nappear as the sample average approximation of a stochastic optimization problem\nand also arise in machine learning with a huge amount of training data. One\npopularly used numerical approach for finite-sum problems is the stochastic\ngradient method (SGM). However, the additional compositional structure\nprohibits easy access to unbiased stochastic approximation of the gradient, so\ndirectly applying the SGM to a finite-sum compositional optimization problem\n(COP) is often inefficient.\n  We design new algorithms for solving strongly-convex and also convex\ntwo-level finite-sum COPs. Our design incorporates the Katyusha acceleration\ntechnique and adopts the mini-batch sampling from both outer-level and\ninner-level finite-sum. We first analyze the algorithm for strongly-convex\nfinite-sum COPs. Similar to a few existing works, we obtain linear convergence\nrate in terms of the expected objective error, and from the convergence rate\nresult, we then establish complexity results of the algorithm to produce an\n$\\varepsilon$-solution. Our complexity results have the same dependence on the\nnumber of component functions as existing works. However, due to the use of\nKatyusha acceleration, our results have better dependence on the condition\nnumber $\\kappa$ and improve to $\\kappa^{2.5}$ from the best-known $\\kappa^3$.\nFinally, we analyze the algorithm for convex finite-sum COPs, which uses as a\nsubroutine the algorithm for strongly-convex finite-sum COPs. Again, we obtain\nbetter complexity results than existing works in terms of the dependence on\n$\\varepsilon$, improving to $\\varepsilon^{-2.5}$ from the best-known\n$\\varepsilon^{-3}$.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 15:22:24 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 18:43:18 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Xu", "Yibo", ""], ["Xu", "Yangyang", ""]]}, {"id": "1910.11235", "submitter": "Yifan Xu", "authors": "Yifan Xu, Kening Zhang, Haoyu Dong, Yuezhou Sun, Wenlong Zhao, Zhuowen\n  Tu", "title": "Rethinking Exposure Bias In Language Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exposure bias describes the phenomenon that a language model trained under\nthe teacher forcing schema may perform poorly at the inference stage when its\npredictions are conditioned on its previous predictions unseen from the\ntraining corpus. Recently, several generative adversarial networks (GANs) and\nreinforcement learning (RL) methods have been introduced to alleviate this\nproblem. Nonetheless, a common issue in RL and GANs training is the sparsity of\nreward signals. In this paper, we adopt two simple strategies, multi-range\nreinforcing, and multi-entropy sampling, to amplify and denoise the reward\nsignal. Our model produces an improvement over competing models with regards to\nBLEU scores and road exam, a new metric we designed to measure the robustness\nagainst exposure bias in language models.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 23:34:04 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 22:46:12 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Xu", "Yifan", ""], ["Zhang", "Kening", ""], ["Dong", "Haoyu", ""], ["Sun", "Yuezhou", ""], ["Zhao", "Wenlong", ""], ["Tu", "Zhuowen", ""]]}, {"id": "1910.11238", "submitter": "Joon Son Chung", "authors": "Joon Son Chung, Jaesung Huh, Seongkyu Mun", "title": "Delving into VoxCeleb: environment invariant speaker recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in speaker recognition has recently seen significant progress due to\nthe application of neural network models and the availability of new\nlarge-scale datasets. There has been a plethora of work in search for more\npowerful architectures or loss functions suitable for the task, but these works\ndo not consider what information is learnt by the models, apart from being able\nto predict the given labels.\n  In this work, we introduce an environment adversarial training framework in\nwhich the network can effectively learn speaker-discriminative and\nenvironment-invariant embeddings without explicit domain shift during training.\nWe achieve this by utilising the previously unused `video' information in the\nVoxCeleb dataset. The environment adversarial training allows the network to\ngeneralise better to unseen conditions. The method is evaluated on both speaker\nidentification and verification tasks using the VoxCeleb dataset, on which we\ndemonstrate significant performance improvements over baselines.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 15:41:35 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 07:02:23 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Chung", "Joon Son", ""], ["Huh", "Jaesung", ""], ["Mun", "Seongkyu", ""]]}, {"id": "1910.11240", "submitter": "Xiao Liang", "authors": "Seyed Omid Sajedi and Xiao Liang", "title": "Intensity-Based Feature Selection for Near Real-Time Damage Diagnosis of\n  Building Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near real-time damage diagnosis of building structures after extreme events\n(e.g., earthquakes) is of great importance in structural health monitoring.\nUnlike conventional methods that are usually time-consuming and require human\nexpertise, pattern recognition algorithms have the potential to interpret\nsensor recordings as soon as this information is available. This paper proposes\na robust framework to build a damage prediction model for building structures.\nSupport vector machines are used to predict the existence as well as the\nprobable location of the damage. The model is designed to consider\nprobabilistic approaches in determining hazard intensity given the existing\nattenuation models in performance-based earthquake engineering. Performance of\nthe model regarding accurate and safe predictions is enhanced using Bayesian\noptimization. The proposed framework is evaluated on a reinforced concrete\nmoment frame. Targeting a selected large earthquake scenario, 6,240 nonlinear\ntime history analyses are performed using OpenSees. Simulation results are\nengineered to extract low-dimensional intensity-based features that can be used\nas damage indicators. For the given case study, the proposed model achieves a\npromising accuracy of 83.1% to identify damage location, demonstrating the\ngreat potential of model capabilities.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 02:54:53 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Sajedi", "Seyed Omid", ""], ["Liang", "Xiao", ""]]}, {"id": "1910.11241", "submitter": "Dattaraj Rao", "authors": "Amogh Kamat Tarcar, Aashis Tiwari, Vineet Naique Dhaimodker, Penjo\n  Rebelo, Rahul Desai, Dattaraj Rao", "title": "Healthcare NER Models Using Language Model Pretraining", "comments": "This work was presented at the first Health Search and Data Mining\n  Workshop (HSDM 2020) as part of WSDM 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our approach to extracting structured information\nfrom unstructured Electronic Health Records (EHR) [2] which can be used to, for\nexample, study adverse drug reactions in patients due to chemicals in their\nproducts. Our solution uses a combination of Natural Language Processing (NLP)\ntechniques and a web-based annotation tool to optimize the performance of a\ncustom Named Entity Recognition (NER) [1] model trained on a limited amount of\nEHR training data. This work was presented at the first Health Search and Data\nMining Workshop (HSDM 2020) [26]. We showcase a combination of tools and\ntechniques leveraging the recent advancements in NLP aimed at targeting domain\nshifts by applying transfer learning and language model pre-training techniques\n[3]. We present a comparison of our technique to the current popular approaches\nand show the effective increase in performance of the NER model and the\nreduction in time to annotate data.A key observation of the results presented\nis that the F1 score of model (0.734) trained with our approach with just 50%\nof available training data outperforms the F1 score of the blank spaCy model\nwithout language model component (0.704) trained with 100% of the available\ntraining data. We also demonstrate an annotation tool to minimize domain expert\ntime and the manual effort required to generate such a training dataset.\nFurther, we plan to release the annotated dataset as well as the pre-trained\nmodel to the community to further research in medical health records.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 07:37:14 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 07:12:58 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Tarcar", "Amogh Kamat", ""], ["Tiwari", "Aashis", ""], ["Dhaimodker", "Vineet Naique", ""], ["Rebelo", "Penjo", ""], ["Desai", "Rahul", ""], ["Rao", "Dattaraj", ""]]}, {"id": "1910.11242", "submitter": "Prabhakar Gupta", "authors": "Prabhakar Gupta", "title": "A context sensitive real-time Spell Checker with language adaptability", "comments": "7 pages, 6 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel language adaptable spell checking system which detects\nspelling errors and suggests context sensitive corrections in real-time. We\nshow that our system can be extended to new languages with minimal\nlanguage-specific processing. Available literature majorly discusses spell\ncheckers for English but there are no publicly available systems which can be\nextended to work for other languages out of the box. Most of the systems do not\nwork in real-time. We explain the process of generating a language's word\ndictionary and n-gram probability dictionaries using Wikipedia-articles data\nand manually curated video subtitles. We present the results of generating a\nlist of suggestions for a misspelled word. We also propose three approaches to\ncreate noisy channel datasets of real-world typographic errors. We compare our\nsystem with industry-accepted spell checker tools for 11 languages. Finally, we\nshow the performance of our system on synthetic datasets for 24 languages.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:00:39 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Gupta", "Prabhakar", ""]]}, {"id": "1910.11247", "submitter": "Philip N. Garner", "authors": "Philip N. Garner and Sibo Tong", "title": "A Bayesian Approach to Recurrence in Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TPAMI.2020.2976978", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We begin by reiterating that common neural network activation functions have\nsimple Bayesian origins. In this spirit, we go on to show that Bayes's theorem\nalso implies a simple recurrence relation; this leads to a Bayesian recurrent\nunit with a prescribed feedback formulation. We show that introduction of a\ncontext indicator leads to a variable feedback that is similar to the forget\nmechanism in conventional recurrent units. A similar approach leads to a\nprobabilistic input gate. The Bayesian formulation leads naturally to the two\npass algorithm of the Kalman smoother or forward-backward algorithm, meaning\nthat inference naturally depends upon future inputs as well as past ones.\nExperiments on speech recognition confirm that the resulting architecture can\nperform as well as a bidirectional recurrent network with the same number of\nparameters as a unidirectional one. Further, when configured explicitly\nbidirectionally, the architecture can exceed the performance of a conventional\nbidirectional recurrence.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 15:48:52 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 14:45:05 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 16:49:04 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Garner", "Philip N.", ""], ["Tong", "Sibo", ""]]}, {"id": "1910.11256", "submitter": "Thejan Rajapakshe", "authors": "Thejan Rajapakshe, Rajib Rana, Siddique Latif, Sara Khalifa, and\n  Bj\\\"orn W. Schuller", "title": "Pre-training in Deep Reinforcement Learning for Automatic Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (deep RL) is a combination of deep learning with\nreinforcement learning principles to create efficient methods that can learn by\ninteracting with its environment. This led to breakthroughs in many complex\ntasks that were previously difficult to solve. However, deep RL requires a\nlarge amount of training time that makes it difficult to use in various\nreal-life applications like human-computer interaction (HCI). Therefore, in\nthis paper, we study pre-training in deep RL to reduce the training time and\nimprove the performance in speech recognition, a popular application of HCI. We\nachieve significantly improved performance in less time on a publicly available\nspeech command recognition dataset.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 15:56:14 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 14:20:20 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Rajapakshe", "Thejan", ""], ["Rana", "Rajib", ""], ["Latif", "Siddique", ""], ["Khalifa", "Sara", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "1910.11263", "submitter": "Zheng Lian", "authors": "Zheng Lian, Jianhua Tao, Bin Liu, Jian Huang", "title": "Conversational Emotion Analysis via Attention Mechanisms", "comments": null, "journal-ref": "Proc. Interspeech 2019, 1936-1940", "doi": "10.21437/Interspeech.2019-1577", "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from the emotion recognition in individual utterances, we propose a\nmultimodal learning framework using relation and dependencies among the\nutterances for conversational emotion analysis. The attention mechanism is\napplied to the fusion of the acoustic and lexical features. Then these fusion\nrepresentations are fed into the self-attention based bi-directional gated\nrecurrent unit (GRU) layer to capture long-term contextual information. To\nimitate real interaction patterns of different speakers, speaker embeddings are\nalso utilized as additional inputs to distinguish the speaker identities during\nconversational dialogs. To verify the effectiveness of the proposed method, we\nconduct experiments on the IEMOCAP database. Experimental results demonstrate\nthat our method shows absolute 2.42% performance improvement over the\nstate-of-the-art strategies.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 16:16:45 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Lian", "Zheng", ""], ["Tao", "Jianhua", ""], ["Liu", "Bin", ""], ["Huang", "Jian", ""]]}, {"id": "1910.11292", "submitter": "Nadav Oved", "authors": "Nadav Oved, Amir Feder, Roi Reichart", "title": "Predicting In-game Actions from Interviews of NBA Players", "comments": "First two authors contributed equally. To be published in the\n  Computational Linguistics journal. Code is available at:\n  https://github.com/nadavo/mood", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sports competitions are widely researched in computer and social science,\nwith the goal of understanding how players act under uncertainty. While there\nis an abundance of computational work on player metrics prediction based on\npast performance, very few attempts to incorporate out-of-game signals have\nbeen made. Specifically, it was previously unclear whether linguistic signals\ngathered from players' interviews can add information which does not appear in\nperformance metrics. To bridge that gap, we define text classification tasks of\npredicting deviations from mean in NBA players' in-game actions, which are\nassociated with strategic choices, player behavior and risk, using their choice\nof language prior to the game. We collected a dataset of transcripts from key\nNBA players' pre-game interviews and their in-game performance metrics,\ntotalling in 5,226 interview-metric pairs. We design neural models for players'\naction prediction based on increasingly more complex aspects of the language\nsignals in their open-ended interviews. Our models can make their predictions\nbased on the textual signal alone, or on a combination with signals from\npast-performance metrics. Our text-based models outperform strong baselines\ntrained on performance metrics only, demonstrating the importance of language\nusage for action prediction. Moreover, the models that employ both textual\ninput and past-performance metrics produced the best results. Finally, as\nneural networks are notoriously difficult to interpret, we propose a method for\ngaining further insight into what our models have learned. Particularly, we\npresent an LDA-based analysis, where we interpret model predictions in terms of\ncorrelated topics. We find that our best performing textual model is most\nassociated with topics that are intuitively related to each prediction task and\nthat better models yield higher correlation with more informative topics.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 17:10:34 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 01:29:32 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 17:46:33 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Oved", "Nadav", ""], ["Feder", "Amir", ""], ["Reichart", "Roi", ""]]}, {"id": "1910.11296", "submitter": "Kelvin Wong", "authors": "Kelvin Wong, Shenlong Wang, Mengye Ren, Ming Liang, and Raquel Urtasun", "title": "Identifying Unknown Instances for Autonomous Driving", "comments": "3rd Conference on Robot Learning (CoRL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, we have seen great progress in perception algorithms,\nparticular through the use of deep learning. However, most existing approaches\nfocus on a few categories of interest, which represent only a small fraction of\nthe potential categories that robots need to handle in the real-world. Thus,\nidentifying objects from unknown classes remains a challenging yet crucial\ntask. In this paper, we develop a novel open-set instance segmentation\nalgorithm for point clouds which can segment objects from both known and\nunknown classes in a holistic way. Our method uses a deep convolutional neural\nnetwork to project points into a category-agnostic embedding space in which\nthey can be clustered into instances irrespective of their semantics.\nExperiments on two large-scale self-driving datasets validate the effectiveness\nof our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 17:24:43 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Wong", "Kelvin", ""], ["Wang", "Shenlong", ""], ["Ren", "Mengye", ""], ["Liang", "Ming", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1910.11299", "submitter": "Andrei Patrascu", "authors": "Paul Irofti, Andrei Patrascu, Andra Baltoiu", "title": "Quick survey of graph-based fraud detection methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, anomaly detection is the problem of distinguishing between normal\ndata samples with well defined patterns or signatures and those that do not\nconform to the expected profiles. Financial transactions, customer reviews,\nsocial media posts are all characterized by relational information. In these\nnetworks, fraudulent behaviour may appear as a distinctive graph edge, such as\nspam message, a node or a larger subgraph structure, such as when a group of\nclients engage in money laundering schemes. Most commonly, these networks are\nrepresented as attributed graphs, with numerical features complementing\nrelational information. We present a survey on anomaly detection techniques\nused for fraud detection that exploit both the graph structure underlying the\ndata and the contextual information contained in the attributes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 17:30:09 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 07:28:08 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 12:56:47 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Irofti", "Paul", ""], ["Patrascu", "Andrei", ""], ["Baltoiu", "Andra", ""]]}, {"id": "1910.11313", "submitter": "Andrei Patrascu", "authors": "Andra Baltoiu, Andrei Patrascu, Paul Irofti", "title": "Community-Level Anomaly Detection for Anti-Money Laundering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in networks often boils down to identifying an underlying\ngraph structure on which the abnormal occurrence rests on. Financial fraud\nschemes are one such example, where more or less intricate schemes are employed\nin order to elude transaction security protocols. We investigate the problem of\nlearning graph structure representations using adaptations of dictionary\nlearning aimed at encoding connectivity patterns. In particular, we adapt\ndictionary learning strategies to the specificity of network topologies and\npropose new methods that impose Laplacian structure on the dictionaries\nthemselves. In one adaption we focus on classifying topologies by working\ndirectly on the graph Laplacian and cast the learning problem to accommodate\nits 2D structure. We tackle the same problem by learning dictionaries which\nconsist of vectorized atomic Laplacians, and provide a block coordinate descent\nscheme to solve the new dictionary learning formulation. Imposing Laplacian\nstructure on the dictionaries is also proposed in an adaptation of the Single\nBlock Orthogonal learning method. Results on synthetic graph datasets\ncomprising different graph topologies confirm the potential of dictionaries to\ndirectly represent graph structure information.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 17:44:37 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Baltoiu", "Andra", ""], ["Patrascu", "Andrei", ""], ["Irofti", "Paul", ""]]}, {"id": "1910.11339", "submitter": "Christian Hennig", "authors": "Fatima Batool and Christian Hennig", "title": "Clustering with the Average Silhouette Width", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Average Silhouette Width (ASW; Rousseeuw (1987)) is a popular cluster\nvalidation index to estimate the number of clusters. Here we address the\nquestion whether it also is suitable as a general objective function to be\noptimized for finding a clustering. We will propose two algorithms (the\nstandard version OSil and a fast version FOSil) and compare them with existing\nclustering methods in an extensive simulation study covering the cases of a\nknown and unknown number of clusters. Real data sets are also analysed, partly\nexploring the use of the new methods with non-Euclidean distances. We will also\nshow that the ASW satisfies some axioms that have been proposed for cluster\nquality functions (Ackerman and Ben-David (2009)). The new methods prove useful\nand sensible in many cases, but some weaknesses are also highlighted. These\nalso concern the use of the ASW for estimating the number of clusters together\nwith other methods, which is of general interest due to the popularity of the\nASW for this task.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 13:41:30 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 20:19:27 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 13:23:12 GMT"}, {"version": "v4", "created": "Sun, 22 Nov 2020 00:00:43 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Batool", "Fatima", ""], ["Hennig", "Christian", ""]]}, {"id": "1910.11356", "submitter": "Ciar\\'an M. Lee", "authors": "Anish Dhir, Ciar\\'an M. Lee", "title": "Integrating overlapping datasets using bivariate causal discovery", "comments": "Accepted to the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20). 8+2 pages, 3+3 figures. Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal knowledge is vital for effective reasoning in science, as causal\nrelations, unlike correlations, allow one to reason about the outcomes of\ninterventions. Algorithms that can discover causal relations from observational\ndata are based on the assumption that all variables have been jointly measured\nin a single dataset. In many cases this assumption fails. Previous approaches\nto overcoming this shortcoming devised algorithms that returned all joint\ncausal structures consistent with the conditional independence information\ncontained in each individual dataset. But, as conditional independence tests\nonly determine causal structure up to Markov equivalence, the number of\nconsistent joint structures returned by these approaches can be quite large.\nThe last decade has seen the development of elegant algorithms for discovering\ncausal relations beyond conditional independence, which can distinguish among\nMarkov equivalent structures. In this work we adapt and extend these so-called\nbivariate causal discovery algorithms to the problem of learning consistent\ncausal structures from multiple datasets with overlapping variables belonging\nto the same generating process, providing a sound and complete algorithm that\noutperforms previous approaches on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 18:01:03 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 13:20:14 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Dhir", "Anish", ""], ["Lee", "Ciar\u00e1n M.", ""]]}, {"id": "1910.11363", "submitter": "Vickram Rajendran", "authors": "Vickram Rajendran, William LeVine", "title": "Accurate Layerwise Interpretable Competence Estimation", "comments": "Proceedings of the 33rd Conference in Neural Information Processing\n  Systems (2019), 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating machine learning performance 'in the wild' is both an important\nand unsolved problem. In this paper, we seek to examine, understand, and\npredict the pointwise competence of classification models. Our contributions\nare twofold: First, we establish a statistically rigorous definition of\ncompetence that generalizes the common notion of classifier confidence; second,\nwe present the ALICE (Accurate Layerwise Interpretable Competence Estimation)\nScore, a pointwise competence estimator for any classifier. By considering\ndistributional, data, and model uncertainty, ALICE empirically shows accurate\ncompetence estimation in common failure situations such as class-imbalanced\ndatasets, out-of-distribution datasets, and poorly trained models. Our\ncontributions allow us to accurately predict the competence of any\nclassification model given any input and error function. We compare our score\nwith state-of-the-art confidence estimators such as model confidence and Trust\nScore, and show significant improvements in competence prediction over these\nmethods on datasets such as DIGITS, CIFAR10, and CIFAR100.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 18:10:35 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Rajendran", "Vickram", ""], ["LeVine", "William", ""]]}, {"id": "1910.11368", "submitter": "Viet Lai", "authors": "Viet Dac Lai and Thien Huu Nguyen", "title": "Extending Event Detection to New Types with Learning from Keywords", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditional event detection classifies a word or a phrase in a given sentence\nfor a set of predefined event types. The limitation of such predefined set is\nthat it prevents the adaptation of the event detection models to new event\ntypes. We study a novel formulation of event detection that describes types via\nseveral keywords to match the contexts in documents. This facilitates the\noperation of the models to new types. We introduce a novel feature-based\nattention mechanism for convolutional neural networks for event detection in\nthe new formulation. Our extensive experiments demonstrate the benefits of the\nnew formulation for new type extension for event detection as well as the\nproposed attention mechanism for this problem.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 18:20:48 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Lai", "Viet Dac", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "1910.11369", "submitter": "Mathieu Blondel", "authors": "Mathieu Blondel", "title": "Structured Prediction with Projection Oracles", "comments": "In proceedings of NeurIPS 2019 (v2: minor modifications in Appendix\n  A)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose in this paper a general framework for deriving loss functions for\nstructured prediction. In our framework, the user chooses a convex set\nincluding the output space and provides an oracle for projecting onto that set.\nGiven that oracle, our framework automatically generates a corresponding convex\nand smooth loss function. As we show, adding a projection as output layer\nprovably makes the loss smaller. We identify the marginal polytope, the output\nspace's convex hull, as the best convex set on which to project. However,\nbecause the projection onto the marginal polytope can sometimes be expensive to\ncompute, we allow to use any convex superset instead, with potentially\ncheaper-to-compute projection. Since efficient projection algorithms are\navailable for numerous convex sets, this allows us to construct loss functions\nfor a variety of tasks. On the theoretical side, when combined with calibrated\ndecoding, we prove that our loss functions can be used as a consistent\nsurrogate for a (potentially non-convex) target loss function of interest. We\ndemonstrate our losses on label ranking, ordinal regression and multilabel\nclassification, confirming the improved accuracy enabled by projections.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 18:26:18 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 16:20:06 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Blondel", "Mathieu", ""]]}, {"id": "1910.11374", "submitter": "Bruno Scalzo Dees", "authors": "Jean P. Chereau, Bruno Scalzo Dees, Danilo P. Mandic", "title": "Robust Principal Component Analysis Based On Maximum Correntropy Power\n  Iterations", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is recognised as a quintessential data\nanalysis technique when it comes to describing linear relationships between the\nfeatures of a dataset. However, the well-known sensitivity of PCA to\nnon-Gaussian samples and/or outliers often makes it unreliable in practice. To\nthis end, a robust formulation of PCA is derived based on the maximum\ncorrentropy criterion (MCC) so as to maximise the expected likelihood of\nGaussian distributed reconstruction errors. In this way, the proposed solution\nreduces to a generalised power iteration, whereby: (i) robust estimates of the\nprincipal components are obtained even in the presence of outliers; (ii) the\nnumber of principal components need not be specified in advance; and (iii) the\nentire set of principal components can be obtained, unlike existing approaches.\nThe advantages of the proposed maximum correntropy power iteration (MCPI) are\ndemonstrated through an intuitive numerical example.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 18:51:27 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Chereau", "Jean P.", ""], ["Dees", "Bruno Scalzo", ""], ["Mandic", "Danilo P.", ""]]}, {"id": "1910.11375", "submitter": "Gregory Meyer", "authors": "Gregory P. Meyer and Niranjan Thakurdesai", "title": "Learning an Uncertainty-Aware Object Detector for Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability to detect objects is a core part of autonomous driving. Due to\nsensor noise and incomplete data, perfectly detecting and localizing every\nobject is infeasible. Therefore, it is important for a detector to provide the\namount of uncertainty in each prediction. Providing the autonomous system with\nreliable uncertainties enables the vehicle to react differently based on the\nlevel of uncertainty. Previous work has estimated the uncertainty in a\ndetection by predicting a probability distribution over object bounding boxes.\nIn this work, we propose a method to improve the ability to learn the\nprobability distribution by considering the potential noise in the ground-truth\nlabeled data. Our proposed approach improves not only the accuracy of the\nlearned distribution but also the object detection performance.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 18:52:28 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 16:29:08 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Meyer", "Gregory P.", ""], ["Thakurdesai", "Niranjan", ""]]}, {"id": "1910.11385", "submitter": "David Widmann", "authors": "David Widmann and Fredrik Lindsten and Dave Zachariah", "title": "Calibration tests in multi-class classification: A unifying framework", "comments": "Corrected version that 1) fixes the ECE evaluation with bins of\n  uniform size (does not affect our conclusions and discussions) and 2)\n  contains additional experimental results in the supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In safety-critical applications a probabilistic model is usually required to\nbe calibrated, i.e., to capture the uncertainty of its predictions accurately.\nIn multi-class classification, calibration of the most confident predictions\nonly is often not sufficient. We propose and study calibration measures for\nmulti-class classification that generalize existing measures such as the\nexpected calibration error, the maximum calibration error, and the maximum mean\ncalibration error. We propose and evaluate empirically different consistent and\nunbiased estimators for a specific class of measures based on matrix-valued\nkernels. Importantly, these estimators can be interpreted as test statistics\nassociated with well-defined bounds and approximations of the p-value under the\nnull hypothesis that the model is calibrated, significantly improving the\ninterpretability of calibration measures, which otherwise lack any meaningful\nunit or scale.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 19:13:19 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 17:01:33 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Widmann", "David", ""], ["Lindsten", "Fredrik", ""], ["Zachariah", "Dave", ""]]}, {"id": "1910.11390", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Deep Learning for Molecular Graphs with Tiered Graph Autoencoders and\n  Graph Prediction", "comments": "arXiv admin note: text overlap with arXiv:1806.08804 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tiered graph autoencoders provide the architecture and mechanisms for\nlearning tiered latent representations and latent spaces for molecular graphs\nthat explicitly represent and utilize groups (e.g., functional groups). This\nenables the utilization and exploration of tiered molecular latent spaces,\neither individually - the node (atom) tier, the group tier, or the graph\n(molecule) tier - or jointly, as well as navigation across the tiers. In this\npaper, we discuss the use of tiered graph autoencoders together with graph\nprediction for molecular graphs. We show features of molecular graphs used, and\ngroups in molecular graphs identified for some sample molecules. We briefly\nreview graph prediction and the QM9 dataset for background information, and\ndiscuss the use of tiered graph embeddings for graph prediction, particularly\nweighted group pooling. We find that functional groups and ring groups\neffectively capture and represent the chemical essence of molecular graphs\n(structures). Further, tiered graph autoencoders and graph prediction together\nprovide effective, efficient and interpretable deep learning for molecular\ngraphs, with the former providing unsupervised, transferable learning and the\nlatter providing supervised, task-optimized learning.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 19:23:14 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 16:05:48 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "1910.11424", "submitter": "Abhinav Gupta", "authors": "Cinjon Resnick, Abhinav Gupta, Jakob Foerster, Andrew M. Dai,\n  Kyunghyun Cho", "title": "Capacity, Bandwidth, and Compositionality in Emergent Language Learning", "comments": "The first two authors contributed equally. Accepted at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent works have discussed the propensity, or lack thereof, for\nemergent languages to exhibit properties of natural languages. A favorite in\nthe literature is learning compositionality. We note that most of those works\nhave focused on communicative bandwidth as being of primary importance. While\nimportant, it is not the only contributing factor. In this paper, we\ninvestigate the learning biases that affect the efficacy and compositionality\nof emergent languages. Our foremost contribution is to explore how capacity of\na neural network impacts its ability to learn a compositional language. We\nadditionally introduce a set of evaluation metrics with which we analyze the\nlearned languages. Our hypothesis is that there should be a specific range of\nmodel capacity and channel bandwidth that induces compositional structure in\nthe resulting language and consequently encourages systematic generalization.\nWhile we empirically see evidence for the bottom of this range, we curiously do\nnot find evidence for the top part of the range and believe that this is an\nopen question for the community.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 21:06:38 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 22:36:24 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 07:54:53 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Resnick", "Cinjon", ""], ["Gupta", "Abhinav", ""], ["Foerster", "Jakob", ""], ["Dai", "Andrew M.", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1910.11432", "submitter": "Chengshu Li", "authors": "Chengshu Li, Fei Xia, Roberto Martin-Martin, Silvio Savarese", "title": "HRL4IN: Hierarchical Reinforcement Learning for Interactive Navigation\n  with Mobile Manipulators", "comments": "Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most common navigation tasks in human environments require auxiliary arm\ninteractions, e.g. opening doors, pressing buttons and pushing obstacles away.\nThis type of navigation tasks, which we call Interactive Navigation, requires\nthe use of mobile manipulators: mobile bases with manipulation capabilities.\nInteractive Navigation tasks are usually long-horizon and composed of\nheterogeneous phases of pure navigation, pure manipulation, and their\ncombination. Using the wrong part of the embodiment is inefficient and hinders\nprogress. We propose HRL4IN, a novel Hierarchical RL architecture for\nInteractive Navigation tasks. HRL4IN exploits the exploration benefits of HRL\nover flat RL for long-horizon tasks thanks to temporally extended commitments\ntowards subgoals. Different from other HRL solutions, HRL4IN handles the\nheterogeneous nature of the Interactive Navigation task by creating subgoals in\ndifferent spaces in different phases of the task. Moreover, HRL4IN selects\ndifferent parts of the embodiment to use for each phase, improving energy\nefficiency. We evaluate HRL4IN against flat PPO and HAC, a state-of-the-art HRL\nalgorithm, on Interactive Navigation in two environments - a 2D grid-world\nenvironment and a 3D environment with physics simulation. We show that HRL4IN\nsignificantly outperforms its baselines in terms of task performance and energy\nefficiency. More information is available at\nhttps://sites.google.com/view/hrl4in.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 21:34:29 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Li", "Chengshu", ""], ["Xia", "Fei", ""], ["Martin-Martin", "Roberto", ""], ["Savarese", "Silvio", ""]]}, {"id": "1910.11436", "submitter": "Filippo Maria Bianchi", "authors": "Filippo Maria Bianchi, Daniele Grattarola, Lorenzo Livi, Cesare Alippi", "title": "Hierarchical Representation Learning in Graph Neural Networks with Node\n  Decimation Pooling", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.3044146", "report-no": null, "categories": "cs.LG math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In graph neural networks (GNNs), pooling operators compute local summaries of\ninput graphs to capture their global properties, and they are fundamental for\nbuilding deep GNNs that learn hierarchical representations. In this work, we\npropose the Node Decimation Pooling (NDP), a pooling operator for GNNs that\ngenerates coarser graphs while preserving the overall graph topology. During\ntraining, the GNN learns new node representations and fits them to a pyramid of\ncoarsened graphs, which is computed offline in a pre-processing stage. NDP\nconsists of three steps. First, a node decimation procedure selects the nodes\nbelonging to one side of the partition identified by a spectral algorithm that\napproximates the \\maxcut{} solution. Afterwards, the selected nodes are\nconnected with Kron reduction to form the coarsened graph. Finally, since the\nresulting graph is very dense, we apply a sparsification procedure that prunes\nthe adjacency matrix of the coarsened graph to reduce the computational cost in\nthe GNN. Notably, we show that it is possible to remove many edges without\nsignificantly altering the graph structure. Experimental results show that NDP\nis more efficient compared to state-of-the-art graph pooling operators while\nreaching, at the same time, competitive performance on a significant variety of\ngraph classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 21:42:12 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 14:57:29 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Grattarola", "Daniele", ""], ["Livi", "Lorenzo", ""], ["Alippi", "Cesare", ""]]}, {"id": "1910.11452", "submitter": "Ananth Balashankar", "authors": "Ananth Balashankar, Alyssa Lees", "title": "Fairness Sample Complexity and the Case for Human Intervention", "comments": "Where is the Human? Bridging the Gap Between AI and HCI, CHI Workshop\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the aim of building machine learning systems that incorporate standards\nof fairness and accountability, we explore explicit subgroup sample complexity\nbounds. The work is motivated by the observation that classifier predictions\nfor real world datasets often demonstrate drastically different metrics, such\nas accuracy, when subdivided by specific sensitive variable subgroups. The\nreasons for these discrepancies are varied and not limited to the influence of\nmitigating variables, institutional bias, underlying population distributions\nas well as sampling bias. Among the numerous definitions of fairness that\nexist, we argue that at a minimum, principled ML practices should ensure that\nclassification predictions are able to mirror the underlying sub-population\ndistributions. However, as the number of sensitive variables increase,\npopulations meeting at the intersectionality of these variables may simply not\nexist or may not be large enough to provide accurate samples for\nclassification. In these increasingly likely scenarios, we make the case for\nhuman intervention and applying situational and individual definitions of\nfairness. In this paper we present lower bounds of subgroup sample complexity\nfor metric-fair learning based on the theory of Probably Approximately Metric\nFair Learning. We demonstrate that for a classifier to approach a definition of\nfairness in terms of specific sensitive variables, adequate subgroup population\nsamples need to exist and the model dimensionality has to be aligned with\nsubgroup population distributions. In cases where this is not feasible, we\npropose an approach using individual fairness definitions for achieving\nalignment. We look at two commonly explored UCI datasets under this lens and\nsuggest human interventions for data collection for specific subgroups to\nachieve approximate individual fairness for linear hypotheses.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 23:10:59 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Balashankar", "Ananth", ""], ["Lees", "Alyssa", ""]]}, {"id": "1910.11470", "submitter": "Vikas Yadav", "authors": "Vikas Yadav and Steven Bethard", "title": "A Survey on Recent Advances in Named Entity Recognition from Deep\n  Learning models", "comments": "Published at COLING 2018", "journal-ref": null, "doi": null, "report-no": "C18-1182", "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named Entity Recognition (NER) is a key component in NLP systems for question\nanswering, information retrieval, relation extraction, etc. NER systems have\nbeen studied and developed widely for decades, but accurate systems using deep\nneural networks (NN) have only been introduced in the last few years. We\npresent a comprehensive survey of deep neural network architectures for NER,\nand contrast them with previous approaches to NER based on feature engineering\nand other supervised or semi-supervised learning algorithms. Our results\nhighlight the improvements achieved by neural networks, and show how\nincorporating some of the lessons learned from past work on feature-based NER\nsystems can yield further improvements.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 00:45:48 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Yadav", "Vikas", ""], ["Bethard", "Steven", ""]]}, {"id": "1910.11472", "submitter": "Manoj Kumar", "authors": "Rimita Lahiri and Manoj Kumar and Somer Bishop and Shrikanth Narayanan", "title": "Learning Domain Invariant Representations for Child-Adult Classification\n  from Speech", "comments": "Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnostic procedures for ASD (autism spectrum disorder) involve\nsemi-naturalistic interactions between the child and a clinician. Computational\nmethods to analyze these sessions require an end-to-end speech and language\nprocessing pipeline that go from raw audio to clinically-meaningful behavioral\nfeatures. An important component of this pipeline is the ability to\nautomatically detect who is speaking when i.e., perform child-adult speaker\nclassification. This binary classification task is often confounded due to\nvariability associated with the participants' speech and background conditions.\nFurther, scarcity of training data often restricts direct application of\nconventional deep learning methods. In this work, we address two major sources\nof variability - age of the child and data source collection location - using\ndomain adversarial learning which does not require labeled target domain data.\nWe use two methods, generative adversarial training with inverted label loss\nand gradient reversal layer to learn speaker embeddings invariant to the above\nsources of variability, and analyze different conditions under which the\nproposed techniques improve over conventional learning methods. Using a large\ncorpus of ADOS-2 (autism diagnostic observation schedule, 2nd edition)\nsessions, we demonstrate upto 13.45% and 6.44% relative improvements over\nconventional learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 00:53:25 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Lahiri", "Rimita", ""], ["Kumar", "Manoj", ""], ["Bishop", "Somer", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1910.11480", "submitter": "Eunwoo Song", "authors": "Ryuichi Yamamoto, Eunwoo Song, Jae-Min Kim", "title": "Parallel WaveGAN: A fast waveform generation model based on generative\n  adversarial networks with multi-resolution spectrogram", "comments": "Accepted to the conference of ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Parallel WaveGAN, a distillation-free, fast, and small-footprint\nwaveform generation method using a generative adversarial network. In the\nproposed method, a non-autoregressive WaveNet is trained by jointly optimizing\nmulti-resolution spectrogram and adversarial loss functions, which can\neffectively capture the time-frequency distribution of the realistic speech\nwaveform. As our method does not require density distillation used in the\nconventional teacher-student framework, the entire model can be easily trained.\nFurthermore, our model is able to generate high-fidelity speech even with its\ncompact architecture. In particular, the proposed Parallel WaveGAN has only\n1.44 M parameters and can generate 24 kHz speech waveform 28.68 times faster\nthan real-time on a single GPU environment. Perceptual listening test results\nverify that our proposed method achieves 4.16 mean opinion score within a\nTransformer-based text-to-speech framework, which is comparative to the best\ndistillation-based Parallel WaveNet system.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 01:16:38 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 09:34:21 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Yamamoto", "Ryuichi", ""], ["Song", "Eunwoo", ""], ["Kim", "Jae-Min", ""]]}, {"id": "1910.11482", "submitter": "Zeeshan Ahmad", "authors": "Zeeshan Ahmad, Naimul Khan", "title": "Human Action Recognition Using Deep Multilevel Multimodal (M2) Fusion of\n  Depth and Inertial Sensors", "comments": "10 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multimodal fusion frameworks for Human Action Recognition (HAR) using depth\nand inertial sensor data have been proposed over the years. In most of the\nexisting works, fusion is performed at a single level (feature level or\ndecision level), missing the opportunity to fuse rich mid-level features\nnecessary for better classification. To address this shortcoming, in this\npaper, we propose three novel deep multilevel multimodal fusion frameworks to\ncapitalize on different fusion strategies at various stages and to leverage the\nsuperiority of multilevel fusion. At input, we transform the depth data into\ndepth images called sequential front view images (SFIs) and inertial sensor\ndata into signal images. Each input modality, depth and inertial, is further\nmade multimodal by taking convolution with the Prewitt filter. Creating\n\"modality within modality\" enables further complementary and discriminative\nfeature extraction through Convolutional Neural Networks (CNNs). CNNs are\ntrained on input images of each modality to learn low-level, high-level and\ncomplex features. Learned features are extracted and fused at different stages\nof the proposed frameworks to combine discriminative and complementary\ninformation. These highly informative features are served as input to a\nmulti-class Support Vector Machine (SVM). We evaluate the proposed frameworks\non three publicly available multimodal HAR datasets, namely, UTD Multimodal\nHuman Action Dataset (MHAD), Berkeley MHAD, and UTD-MHAD Kinect V2.\nExperimental results show the supremacy of the proposed fusion frameworks over\nexisting methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 01:29:58 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Ahmad", "Zeeshan", ""], ["Khan", "Naimul", ""]]}, {"id": "1910.11488", "submitter": "Jingchi Zhang", "authors": "Jingchi Zhang, Jonathan Huang, Michael Deisher, Hai Li, Yiran Chen", "title": "Structural sparsification for Far-field Speaker Recognition with GNA", "comments": "submitted to icassp2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks (DNN) have been widely used in speaker\nrecognition area. In order to achieve fast response time and high accuracy, the\nrequirements for hardware resources increase rapidly. However, as the speaker\nrecognition application is often implemented on mobile devices, it is necessary\nto maintain a low computational cost while keeping high accuracy in far-field\ncondition. In this paper, we apply structural sparsification on time-delay\nneural networks (TDNN) to remove redundant structures and accelerate the\nexecution. On our targeted hardware, our model can remove 60% of parameters and\nonly slightly increasing equal error rate (EER) by 0.18% while our structural\nsparse model can achieve more than 1.5x speedup.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 02:02:21 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 19:59:40 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhang", "Jingchi", ""], ["Huang", "Jonathan", ""], ["Deisher", "Michael", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "1910.11490", "submitter": "Tong Zhang", "authors": "Haishan Ye and Tong Zhang", "title": "Mirror Natural Evolution Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution Strategies such as CMA-ES (covariance matrix adaptation evolution\nstrategy) and NES (natural evolution strategy) have been widely used in machine\nlearning applications, where an objective function is optimized without using\nits derivatives. However, the convergence behaviors of these algorithms have\nnot been carefully studied. In particular, there is no rigorous analysis for\nthe convergence of the estimated covariance matrix, and it is unclear how does\nthe estimated covariance matrix help the converge of the algorithm. The\nrelationship between Evolution Strategies and derivative free optimization\nalgorithms is also not clear. In this paper, we propose a new algorithm closely\nrelated toNES, which we call MiNES (mirror descent natural evolution strategy),\nfor which we can establish rigorous convergence results. We show that the\nestimated covariance matrix of MiNES converges to the inverse of Hessian matrix\nof the objective function with a sublinear convergence rate. Moreover, we show\nthat some derivative free optimization algorithms are special cases of MiNES.\nOur empirical studies demonstrate that MiNES is a query-efficient optimization\nalgorithm competitive to classical algorithms including NES and CMA-ES.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 02:10:07 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Ye", "Haishan", ""], ["Zhang", "Tong", ""]]}, {"id": "1910.11492", "submitter": "Vikas Ramachandra", "authors": "Vikas Ramachandra", "title": "Causal inference for climate change events from satellite image time\n  series using computer vision and deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for causal inference using satellite image time series,\nin order to determine the treatment effects of interventions which impact\nclimate change, such as deforestation. Simply put, the aim is to quantify the\n'before versus after' effect of climate related human driven interventions,\nsuch as urbanization; as well as natural disasters, such as hurricanes and\nforest fires. As a concrete example, we focus on quantifying forest tree cover\nchange/ deforestation due to human led causes. The proposed method involves the\nfollowing steps. First, we uae computer vision and machine learning/deep\nlearning techniques to detect and quantify forest tree coverage levels over\ntime, at every time epoch. We then look at this time series to identify\nchangepoints. Next, we estimate the expected (forest tree cover) values using a\nBayesian structural causal model and projecting/forecasting the counterfactual.\nThis is compared to the values actually observed post intervention, and the\ndifference in the two values gives us the effect of the intervention (as\ncompared to the non intervention scenario, i.e. what would have possibly\nhappened without the intervention). As a specific use case, we analyze\ndeforestation levels before and after the hyperinflation event (intervention)\nin Brazil (which ended in 1993-94), for the Amazon rainforest region, around\nRondonia, Brazil. For this deforestation use case, using our causal inference\nframework can help causally attribute change/reduction in forest tree cover and\nincreasing deforestation rates due to human activities at various points in\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 02:16:15 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Ramachandra", "Vikas", ""]]}, {"id": "1910.11499", "submitter": "Yoshihide Sawada PhD", "authors": "Yoshihide Sawada, Koji Morikawa, Mikiya Fujii", "title": "Study of Deep Generative Models for Inorganic Chemical Compositions", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models based on generative adversarial networks (GANs) and\nvariational autoencoders (VAEs) have been widely studied in the fields of image\ngeneration, speech generation, and drug discovery, but, only a few studies have\nfocused on the generation of inorganic materials. Such studies use the crystal\nstructures of materials, but material researchers rarely store this\ninformation. Thus, we generate chemical compositions without using crystal\ninformation. We use a conditional VAE (CondVAE) and a conditional GAN (CondGAN)\nand show that CondGAN using the bag-of-atom representation with physical\ndescriptors generates better compositions than other generative models. Also,\nwe evaluate the effectiveness of the Metropolis-Hastings-based atomic valency\nmodification and the extrapolation performance, which is important to material\ndiscovery.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 02:44:42 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Sawada", "Yoshihide", ""], ["Morikawa", "Koji", ""], ["Fujii", "Mikiya", ""]]}, {"id": "1910.11508", "submitter": "Tong Zhang", "authors": "Cong Fang and Hanze Dong and Tong Zhang", "title": "Over Parameterized Two-level Neural Networks Can Learn Near Optimal\n  Feature Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, over-parameterized neural networks have been extensively analyzed\nin the literature. However, the previous studies cannot satisfactorily explain\nwhy fully trained neural networks are successful in practice. In this paper, we\npresent a new theoretical framework for analyzing over-parameterized neural\nnetworks which we call neural feature repopulation. Our analysis can\nsatisfactorily explain the empirical success of two level neural networks that\nare trained by standard learning algorithms. Our key theoretical result is that\nin the limit of infinite number of hidden neurons, over-parameterized two-level\nneural networks trained via the standard (noisy) gradient descent learns a\nwell-defined feature distribution (population), and the limiting feature\ndistribution is nearly optimal for the underlying learning task under certain\nconditions. Empirical studies confirm that predictions of our theory are\nconsistent with the results observed in real practice.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 03:06:06 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Fang", "Cong", ""], ["Dong", "Hanze", ""], ["Zhang", "Tong", ""]]}, {"id": "1910.11509", "submitter": "Wassim Bouachir", "authors": "Imanne El Maachi, Guillaume-Alexandre Bilodeau, Wassim Bouachir", "title": "Deep 1D-Convnet for accurate Parkinson disease detection and severity\n  prediction from gait", "comments": "Source code available at\n  https://github.com/imanneelmaachi/Parkinson-disease-detection-and-severity-prediction-from-gait", "journal-ref": "Expert Systems with Applications, 113075 (2019)", "doi": "10.1016/j.eswa.2019.113075", "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosing Parkinson's disease is a complex task that requires the evaluation\nof several motor and non-motor symptoms. During diagnosis, gait abnormalities\nare among the important symptoms that physicians should consider. However, gait\nevaluation is challenging and relies on the expertise and subjectivity of\nclinicians. In this context, the use of an intelligent gait analysis algorithm\nmay assist physicians in order to facilitate the diagnosis process. This paper\nproposes a novel intelligent Parkinson detection system based on deep learning\ntechniques to analyze gait information. We used 1D convolutional neural network\n(1D-Convnet) to build a Deep Neural Network (DNN) classifier. The proposed\nmodel processes 18 1D-signals coming from foot sensors measuring the vertical\nground reaction force (VGRF). The first part of the network consists of 18\nparallel 1D-Convnet corresponding to system inputs. The second part is a fully\nconnected network that connects the concatenated outputs of the 1D-Convnets to\nobtain a final classification. We tested our algorithm in Parkinson's detection\nand in the prediction of the severity of the disease with the Unified\nParkinson's Disease Rating Scale (UPDRS). Our experiments demonstrate the high\nefficiency of the proposed method in the detection of Parkinson disease based\non gait data. The proposed algorithm achieved an accuracy of 98.7 %. To our\nknowledge, this is the state-of-the-start performance in Parkinson's gait\nrecognition. Furthermore, we achieved an accuracy of 85.3 % in Parkinson's\nseverity prediction. To the best of our knowledge, this is the first algorithm\nto perform a severity prediction based on the UPDRS. Our results show that the\nmodel is able to learn intrinsic characteristics from gait data and to\ngeneralize to unseen subjects, which could be helpful in a clinical diagnosis.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 03:14:54 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 02:03:44 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 02:23:21 GMT"}, {"version": "v4", "created": "Sat, 16 May 2020 18:50:52 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Maachi", "Imanne El", ""], ["Bilodeau", "Guillaume-Alexandre", ""], ["Bouachir", "Wassim", ""]]}, {"id": "1910.11516", "submitter": "Ryo Tamura", "authors": "Xiaolin Sun, Zhufeng Hou, Masato Sumita, Shinsuke Ishihara, Ryo\n  Tamura, and Koji Tsuda", "title": "Leveraging Legacy Data to Accelerate Materials Design via Preference\n  Learning", "comments": "10 pages, 4 figures", "journal-ref": "New Journal of Physics 22, 055001 (2020)", "doi": "10.1088/1367-2630/ab82b9", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applications in materials science are often hampered by\nshortage of experimental data. Integration with legacy data from past\nexperiments is a viable way to solve the problem, but complex calibration is\noften necessary to use the data obtained under different conditions. In this\npaper, we present a novel calibration-free strategy to enhance the performance\nof Bayesian optimization with preference learning. The entire learning process\nis solely based on pairwise comparison of quantities (i.e., higher or lower) in\nthe same dataset, and experimental design can be done without comparing\nquantities in different datasets. We demonstrate that Bayesian optimization is\nsignificantly enhanced via addition of legacy data for organic molecules and\ninorganic solid-state materials.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 04:10:01 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Sun", "Xiaolin", ""], ["Hou", "Zhufeng", ""], ["Sumita", "Masato", ""], ["Ishihara", "Shinsuke", ""], ["Tamura", "Ryo", ""], ["Tsuda", "Koji", ""]]}, {"id": "1910.11519", "submitter": "Raef Bassily", "authors": "Noga Alon, Raef Bassily, Shay Moran", "title": "Limits of Private Learning with Access to Public Data", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning problems where the training set consists of two types of\nexamples: private and public. The goal is to design a learning algorithm that\nsatisfies differential privacy only with respect to the private examples. This\nsetting interpolates between private learning (where all examples are private)\nand classical learning (where all examples are public).\n  We study the limits of learning in this setting in terms of private and\npublic sample complexities. We show that any hypothesis class of VC-dimension\n$d$ can be agnostically learned up to an excess error of $\\alpha$ using only\n(roughly) $d/\\alpha$ public examples and $d/\\alpha^2$ private labeled examples.\nThis result holds even when the public examples are unlabeled. This gives a\nquadratic improvement over the standard $d/\\alpha^2$ upper bound on the public\nsample complexity (where private examples can be ignored altogether if the\npublic examples are labeled). Furthermore, we give a nearly matching lower\nbound, which we prove via a generic reduction from this setting to the one of\nprivate learning without public data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 04:27:26 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Alon", "Noga", ""], ["Bassily", "Raef", ""], ["Moran", "Shay", ""]]}, {"id": "1910.11525", "submitter": "Umar Islambekov", "authors": "Umar Islambekov and Yulia Gel", "title": "Unsupervised Space-Time Clustering using Persistent Homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a new clustering algorithm for space-time data based on\nthe concepts of topological data analysis and in particular, persistent\nhomology. Employing persistent homology - a flexible mathematical tool from\nalgebraic topology used to extract topological information from data - in\nunsupervised learning is an uncommon and a novel approach. A notable aspect of\nthis methodology consists in analyzing data at multiple resolutions which\nallows to distinguish true features from noise based on the extent of their\npersistence. We evaluate the performance of our algorithm on synthetic data and\ncompare it to other well-known clustering algorithms such as K-means,\nhierarchical clustering and DBSCAN. We illustrate its application in the\ncontext of a case study of water quality in the Chesapeake Bay.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 04:51:30 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Islambekov", "Umar", ""], ["Gel", "Yulia", ""]]}, {"id": "1910.11540", "submitter": "Kenji Yamanishi", "authors": "Kenji Yamanishi", "title": "Descriptive Dimensionality and Its Characterization of MDL-based\n  Learning and Change Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new notion of dimensionality of probabilistic models\nfrom an information-theoretic view point. We call it the \"descriptive\ndimension\"(Ddim). We show that Ddim coincides with the number of independent\nparameters for the parametric class, and can further be extended to real-valued\ndimensionality when a number of models are mixed. The paper then derives the\nrate of convergence of the MDL (Minimum Description Length) learning algorithm\nwhich outputs a normalized maximum likelihood (NML) distribution with model of\nthe shortest NML codelength. The paper proves that the rate is governed by\nDdim. The paper also derives error probabilities of the MDL-based test for\nmultiple model change detection. It proves that they are also governed by Ddim.\nThrough the analysis, we demonstrate that Ddim is an intrinsic quantity which\ncharacterizes the performance of the MDL-based learning and change detection.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 05:55:25 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Yamanishi", "Kenji", ""]]}, {"id": "1910.11544", "submitter": "Alkis Gotovos", "authors": "Alkis Gotovos", "title": "Strong Log-Concavity Does Not Imply Log-Submodularity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We disprove a recent conjecture regarding discrete distributions and their\ngenerating polynomials stating that strong log-concavity implies\nlog-submodularity.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 06:13:08 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Gotovos", "Alkis", ""]]}, {"id": "1910.11552", "submitter": "Jie He", "authors": "Jie He, Tao Chen, Zhijun Zhang", "title": "A Gegenbauer Neural Network with Regularized Weights Direct\n  Determination for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-hidden layer feed forward neural networks (SLFNs) are widely used in\npattern classification problems, but a huge bottleneck encountered is the slow\nspeed and poor performance of the traditional iterative gradient-based learning\nalgorithms. Although the famous extreme learning machine (ELM) has successfully\naddressed the problems of slow convergence, it still has computational\nrobustness problems brought by input weights and biases randomly assigned.\nThus, in order to overcome the aforementioned problems, in this paper, a novel\ntype neural network based on Gegenbauer orthogonal polynomials, termed as GNN,\nis constructed and investigated. This model could overcome the computational\nrobustness problems of ELM, while still has comparable structural simplicity\nand approximation capability. Based on this, we propose a regularized weights\ndirect determination (R-WDD) based on equality-constrained optimization to\ndetermine the optimal output weights. The R-WDD tends to minimize the empirical\nrisks and structural risks of the network, thus to lower the risk of over\nfitting and improve the generalization ability. This leads us to a the final\nGNN with R-WDD, which is a unified learning mechanism for binary and\nmulti-class classification problems. Finally, as is verified in the various\ncomparison experiments, GNN with R-WDD tends to have comparable (or even\nbetter) generalization performances, computational scalability and efficiency,\nand classification robustness, compared to least square support vector machine\n(LS-SVM), ELM with Gaussian kernel.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 07:04:21 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["He", "Jie", ""], ["Chen", "Tao", ""], ["Zhang", "Zhijun", ""]]}, {"id": "1910.11555", "submitter": "Zhiqing Sun", "authors": "Zhiqing Sun, Zhuohan Li, Haoqing Wang, Zi Lin, Di He, Zhi-Hong Deng", "title": "Fast Structured Decoding for Sequence Models", "comments": "Accepted to NeurIPS 2019 (Previous title: Structured Decoding for\n  Non-Autoregressive Machine Translation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive sequence models achieve state-of-the-art performance in\ndomains like machine translation. However, due to the autoregressive\nfactorization nature, these models suffer from heavy latency during inference.\nRecently, non-autoregressive sequence models were proposed to reduce the\ninference time. However, these models assume that the decoding process of each\ntoken is conditionally independent of others. Such a generation process\nsometimes makes the output sentence inconsistent, and thus the learned\nnon-autoregressive models could only achieve inferior accuracy compared to\ntheir autoregressive counterparts. To improve then decoding consistency and\nreduce the inference cost at the same time, we propose to incorporate a\nstructured inference module into the non-autoregressive models. Specifically,\nwe design an efficient approximation for Conditional Random Fields (CRF) for\nnon-autoregressive sequence models, and further propose a dynamic transition\ntechnique to model positional contexts in the CRF. Experiments in machine\ntranslation show that while increasing little latency (8~14ms), our model could\nachieve significantly better translation performance than previous\nnon-autoregressive models on different translation datasets. In particular, for\nthe WMT14 En-De dataset, our model obtains a BLEU score of 26.80, which largely\noutperforms the previous non-autoregressive baselines and is only 0.61 lower in\nBLEU than purely autoregressive models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 07:32:52 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 08:25:23 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Sun", "Zhiqing", ""], ["Li", "Zhuohan", ""], ["Wang", "Haoqing", ""], ["Lin", "Zi", ""], ["He", "Di", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "1910.11561", "submitter": "Mojm\\'ir Mutn\\'y", "authors": "Mojm\\'ir Mutn\\'y and Micha{\\l} Derezi\\'nski and Andreas Krause", "title": "Convergence Analysis of Block Coordinate Algorithms with Determinantal\n  Sampling", "comments": null, "journal-ref": "AISTATS 2020", "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyze the convergence rate of the randomized Newton-like method\nintroduced by Qu et. al. (2016) for smooth and convex objectives, which uses\nrandom coordinate blocks of a Hessian-over-approximation matrix $\\bM$ instead\nof the true Hessian. The convergence analysis of the algorithm is challenging\nbecause of its complex dependence on the structure of $\\bM$. However, we show\nthat when the coordinate blocks are sampled with probability proportional to\ntheir determinant, the convergence rate depends solely on the eigenvalue\ndistribution of matrix $\\bM$, and has an analytically tractable form. To do so,\nwe derive a fundamental new expectation formula for determinantal point\nprocesses. We show that determinantal sampling allows us to reason about the\noptimal subset size of blocks in terms of the spectrum of $\\bM$. Additionally,\nwe provide a numerical evaluation of our analysis, demonstrating cases where\ndeterminantal sampling is superior or on par with uniform sampling.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 07:49:57 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 16:55:43 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 17:01:55 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Mutn\u00fd", "Mojm\u00edr", ""], ["Derezi\u0144ski", "Micha\u0142", ""], ["Krause", "Andreas", ""]]}, {"id": "1910.11563", "submitter": "Jian Li", "authors": "Jian Li, Yan Wang, Xiubao Zhang, Weihong Deng, Haifeng Shen", "title": "Metric Classification Network in Actual Face Recognition Scene", "comments": "arXiv admin note: text overlap with arXiv:1504.03641 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to make facial features more discriminative, some new models have\nrecently been proposed. However, almost all of these models use the traditional\nface verification method, where the cosine operation is performed using the\nfeatures of the bottleneck layer output. However, each of these models needs to\nchange a threshold each time it is operated on a different test set. This is\nvery inappropriate for application in real-world scenarios. In this paper, we\ntrain a validation classifier to normalize the decision threshold, which means\nthat the result can be obtained directly without replacing the threshold. We\nrefer to our model as validation classifier, which achieves best result on the\nstructure consisting of one convolution layer and six fully connected layers.\nTo test our approach, we conduct extensive experiments on Labeled Face in the\nWild (LFW) and Youtube Faces (YTF), and the relative error reduction is 25.37%\nand 26.60% than traditional method respectively. These experiments confirm the\neffectiveness of validation classifier on face recognition task.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 07:58:10 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Li", "Jian", ""], ["Wang", "Yan", ""], ["Zhang", "Xiubao", ""], ["Deng", "Weihong", ""], ["Shen", "Haifeng", ""]]}, {"id": "1910.11567", "submitter": "Mathieu Galtier", "authors": "Mathieu N Galtier, Camille Marini", "title": "Substra: a framework for privacy-preserving, traceable and collaborative\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine learning is promising, but it often needs to process vast amounts of\nsensitive data which raises concerns about privacy. In this white-paper, we\nintroduce Substra, a distributed framework for privacy-preserving, traceable\nand collaborative Machine Learning. Substra gathers data providers and\nalgorithm designers into a network of nodes that can train models on demand but\nunder advanced permission regimes. To guarantee data privacy, Substra\nimplements distributed learning: the data never leave their nodes; only\nalgorithms, predictive models and non-sensitive metadata are exchanged on the\nnetwork. The computations are orchestrated by a Distributed Ledger Technology\nwhich guarantees traceability and authenticity of information without needing\nto trust a third party. Although originally developed for Healthcare\napplications, Substra is not data, algorithm or programming language specific.\nIt supports many types of computation plans including parallel computation plan\ncommonly used in Federated Learning. With appropriate guidelines, it can be\ndeployed for numerous Machine Learning use-cases with data or algorithm\nproviders where trust is limited.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 08:25:03 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Galtier", "Mathieu N", ""], ["Marini", "Camille", ""]]}, {"id": "1910.11577", "submitter": "Wei Yu", "authors": "Wei Yu, Yichao Lu, Steve Easterbrook, Sanja Fidler", "title": "CrevNet: Conditionally Reversible Video Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying resolution-preserving blocks is a common practice to maximize\ninformation preservation in video prediction, yet their high memory consumption\ngreatly limits their application scenarios. We propose CrevNet, a Conditionally\nReversible Network that uses reversible architectures to build a bijective\ntwo-way autoencoder and its complementary recurrent predictor. Our model enjoys\nthe theoretically guaranteed property of no information loss during the feature\nextraction, much lower memory consumption and computational efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 08:59:32 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Yu", "Wei", ""], ["Lu", "Yichao", ""], ["Easterbrook", "Steve", ""], ["Fidler", "Sanja", ""]]}, {"id": "1910.11583", "submitter": "Esma Balkir", "authors": "Esma Balkir, Masha Naslidnyk, Dave Palfrey, Arpit Mittal", "title": "Using Pairwise Occurrence Information to Improve Knowledge Graph\n  Completion on Large-Scale Datasets", "comments": "8 pages, 3 figures, accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilinear models such as DistMult and ComplEx are effective methods for\nknowledge graph (KG) completion. However, they require large batch sizes, which\nbecomes a performance bottleneck when training on large scale datasets due to\nmemory constraints. In this paper we use occurrences of entity-relation pairs\nin the dataset to construct a joint learning model and to increase the quality\nof sampled negatives during training. We show on three standard datasets that\nwhen these two techniques are combined, they give a significant improvement in\nperformance, especially when the batch size and the number of generated\nnegative examples are low relative to the size of the dataset. We then apply\nour techniques to a dataset containing 2 million entities and demonstrate that\nour model outperforms the baseline by 2.8% absolute on hits@1.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 09:05:16 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Balkir", "Esma", ""], ["Naslidnyk", "Masha", ""], ["Palfrey", "Dave", ""], ["Mittal", "Arpit", ""]]}, {"id": "1910.11585", "submitter": "Amin Ghiasi", "authors": "Ali Shafahi, Amin Ghiasi, Furong Huang, Tom Goldstein", "title": "Label Smoothing and Logit Squeezing: A Replacement for Adversarial\n  Training?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is one of the strongest defenses against adversarial\nattacks, but it requires adversarial examples to be generated for every\nmini-batch during optimization. The expense of producing these examples during\ntraining often precludes adversarial training from use on complex image\ndatasets. In this study, we explore the mechanisms by which adversarial\ntraining improves classifier robustness, and show that these mechanisms can be\neffectively mimicked using simple regularization methods, including label\nsmoothing and logit squeezing. Remarkably, using these simple regularization\nmethods in combination with Gaussian noise injection, we are able to achieve\nstrong adversarial robustness -- often exceeding that of adversarial training\n-- using no adversarial examples.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 09:06:15 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Shafahi", "Ali", ""], ["Ghiasi", "Amin", ""], ["Huang", "Furong", ""], ["Goldstein", "Tom", ""]]}, {"id": "1910.11599", "submitter": "Saad Mohamad", "authors": "Saad Mohamad and Abdelhamid Bouchachia", "title": "Online Gaussian LDA for Unsupervised Pattern Mining from Utility Usage\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Non-intrusive load monitoring (NILM) aims at separating a whole-home energy\nsignal into its appliance components. Such method can be harnessed to provide\nvarious services to better manage and control energy consumption (optimal\nplanning and saving). NILM has been traditionally approached from signal\nprocessing and electrical engineering perspectives. Recently, machine learning\nhas started to play an important role in NILM. While most work has focused on\nsupervised algorithms, unsupervised approaches can be more interesting and of\npractical use in real case scenarios. Specifically, they do not require\nlabelled training data to be acquired from individual appliances and the\nalgorithm can be deployed to operate on the measured aggregate data directly.\nIn this paper, we propose a fully unsupervised NILM framework based on Bayesian\nhierarchical mixture models. In particular, we develop a new method based on\nGaussian Latent Dirichlet Allocation (GLDA) in order to extract global\ncomponents that summarise the energy signal. These components provide a\nrepresentation of the consumption patterns. Designed to cope with big data, our\nalgorithm, unlike existing NILM ones, does not focus on appliance recognition.\nTo handle this massive data, GLDA works online. Another novelty of this work\ncompared to the existing NILM is that the data involves different utilities\n(e.g, electricity, water and gas) as well as some sensors measurements.\nFinally, we propose different evaluation methods to analyse the results which\nshow that our algorithm finds useful patterns.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 09:46:52 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Mohamad", "Saad", ""], ["Bouchachia", "Abdelhamid", ""]]}, {"id": "1910.11603", "submitter": "Panagiotis Linardos", "authors": "Panagiotis Linardos, Suzanne Little, Kevin McGuinness", "title": "MediaEval 2019: Concealed FGSM Perturbations for Privacy Preservation", "comments": "MediaEval 2019 - Pixel Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work tackles the Pixel Privacy task put forth by MediaEval 2019. Our\ngoal is to manipulate images in a way that conceals them from automatic scene\nclassifiers while preserving the original image quality. We use the fast\ngradient sign method, which normally has a corrupting influence on image\nappeal, and devise two methods to minimize the damage. The first approach uses\na map of pixel locations that are either salient or flat, and directs\nperturbations away from them. The second approach subtracts the gradient of an\naesthetics evaluation model from the gradient of the attack model to guide the\nperturbations towards a direction that preserves appeal. We make our code\navailable at: https://git.io/JesXr.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 10:19:29 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Linardos", "Panagiotis", ""], ["Little", "Suzanne", ""], ["McGuinness", "Kevin", ""]]}, {"id": "1910.11605", "submitter": "Koyel Mukherjee", "authors": "Koyel Mukherjee, Alind Khare, Ashish Verma", "title": "A Simple Dynamic Learning Rate Tuning Algorithm For Automated Training\n  of DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks on image datasets generally require extensive\nexperimentation to find the optimal learning rate regime. Especially, for the\ncases of adversarial training or for training a newly synthesized model, one\nwould not know the best learning rate regime beforehand. We propose an\nautomated algorithm for determining the learning rate trajectory, that works\nacross datasets and models for both natural and adversarial training, without\nrequiring any dataset/model specific tuning. It is a stand-alone,\nparameterless, adaptive approach with no computational overhead. We\ntheoretically discuss the algorithm's convergence behavior. We empirically\nvalidate our algorithm extensively. Our results show that our proposed approach\n\\emph{consistently} achieves top-level accuracy compared to SOTA baselines in\nthe literature in natural as well as adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 10:23:12 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Mukherjee", "Koyel", ""], ["Khare", "Alind", ""], ["Verma", "Ashish", ""]]}, {"id": "1910.11609", "submitter": "Li Lyna Zhang", "authors": "Li Lyna Zhang, Yuqing Yang, Yuhang Jiang, Wenwu Zhu, Yunxin Liu", "title": "Fast Hardware-Aware Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing accurate and efficient convolutional neural architectures for vast\namount of hardware is challenging because hardware designs are complex and\ndiverse. This paper addresses the hardware diversity challenge in Neural\nArchitecture Search (NAS). Unlike previous approaches that apply search\nalgorithms on a small, human-designed search space without considering hardware\ndiversity, we propose HURRICANE that explores the automatic hardware-aware\nsearch over a much larger search space and a two-stage search algorithm, to\nefficiently generate tailored models for different types of hardware. Extensive\nexperiments on ImageNet demonstrate that our algorithm outperforms\nstate-of-the-art hardware-aware NAS methods under the same latency constraint\non three types of hardware. Moreover, the discovered architectures achieve much\nlower latency and higher accuracy than current state-of-the-art efficient\nmodels. Remarkably, HURRICANE achieves a 76.67% top-1 accuracy on ImageNet with\na inference latency of only 16.5 ms for DSP, which is a 3.47% higher accuracy\nand a 6.35x inference speedup than FBNet-iPhoneX, respectively. For VPU, we\nachieve a 0.53% higher top-1 accuracy than Proxyless-mobile with a 1.49x\nspeedup. Even for well-studied mobile CPU, we achieve a 1.63% higher top-1\naccuracy than FBNet-iPhoneX with a comparable inference latency. HURRICANE also\nreduces the training time by 30.4% compared to SPOS.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 10:40:57 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 02:50:26 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 02:05:46 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Zhang", "Li Lyna", ""], ["Yang", "Yuqing", ""], ["Jiang", "Yuhang", ""], ["Zhu", "Wenwu", ""], ["Liu", "Yunxin", ""]]}, {"id": "1910.11615", "submitter": "David Ditter", "authors": "David Ditter and Timo Gerkmann", "title": "A Multi-Phase Gammatone Filterbank for Speech Separation via TasNet", "comments": "Accepted at ICASSP 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053602", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate if the learned encoder of the end-to-end\nconvolutional time domain audio separation network (Conv-TasNet) is the key to\nits recent success, or if the encoder can just as well be replaced by a\ndeterministic hand-crafted filterbank. Motivated by the resemblance of the\ntrained encoder of Conv-TasNet to auditory filterbanks, we propose to employ a\ndeterministic gammatone filterbank. In contrast to a common gammatone\nfilterbank, our filters are restricted to 2 ms length to allow for low-latency\nprocessing. Inspired by the encoder learned by Conv-TasNet, in addition to the\nlogarithmically spaced filters, the proposed filterbank holds multiple\ngammatone filters at the same center frequency with varying phase shifts. We\nshow that replacing the learned encoder with our proposed multi-phase gammatone\nfilterbank (MP-GTF) even leads to a scale-invariant source-to-noise ratio\n(SI-SNR) improvement of 0.7 dB. Furthermore, in contrast to using the learned\nencoder we show that the number of filters can be reduced from 512 to 128\nwithout loss of performance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 10:51:43 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:33:17 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ditter", "David", ""], ["Gerkmann", "Timo", ""]]}, {"id": "1910.11617", "submitter": "Hoang Duy Trinh", "authors": "Hoang Duy Trinh, Angel Fernandez Gambin, Lorenza Giupponi, Michele\n  Rossi, Paolo Dini", "title": "Mobile Traffic Classification through Physical Channel Fingerprinting: a\n  Deep Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic classification of applications and services is an invaluable\nfeature for new generation mobile networks. Here, we propose and validate\nalgorithms to perform this task, at runtime, from the raw physical channel of\nan operative mobile network, without having to decode and/or decrypt the\ntransmitted flows. Towards this, we decode Downlink Control Information (DCI)\nmessages carried within the LTE Physical Downlink Control CHannel (PDCCH). DCI\nmessages are sent by the radio cell in clear text and, in this paper, are\nutilized to classify the applications and services executed at the connected\nmobile terminals. Two datasets are collected through a large measurement\ncampaign: one labeled, used to train the classification algorithms, and one\nunlabeled, collected from four radio cells in the metropolitan area of\nBarcelona, in Spain. Among other approaches, our Convolutional Neural Network\n(CNN) classifier provides the highest classification accuracy of 99%. The CNN\nclassifier is then augmented with the capability of rejecting sessions whose\npatterns do not conform to those learned during the training phase, and is\nsubsequently utilized to attain a fine grained decomposition of the traffic for\nthe four monitored radio cells, in an online and unsupervised fashion.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 11:05:15 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 12:58:41 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 18:44:12 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Trinh", "Hoang Duy", ""], ["Gambin", "Angel Fernandez", ""], ["Giupponi", "Lorenza", ""], ["Rossi", "Michele", ""], ["Dini", "Paolo", ""]]}, {"id": "1910.11623", "submitter": "Alexis Laignelet", "authors": "Batuhan G\\\"uler, Alexis Laignelet, Panos Parpas", "title": "Towards Robust and Stable Deep Learning Algorithms for Forward Backward\n  Stochastic Differential Equations", "comments": "Accepted at NeurIPS 2019 Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications in quantitative finance such as optimal trade execution, risk\nmanagement of options, and optimal asset allocation involve the solution of\nhigh dimensional and nonlinear Partial Differential Equations (PDEs). The\nconnection between PDEs and systems of Forward-Backward Stochastic Differential\nEquations (FBSDEs) enables the use of advanced simulation techniques to be\napplied even in the high dimensional setting. Unfortunately, when the\nunderlying application contains nonlinear terms, then classical methods both\nfor simulation and numerical methods for PDEs suffer from the curse of\ndimensionality. Inspired by the success of deep learning, several researchers\nhave recently proposed to address the solution of FBSDEs using deep learning.\nWe discuss the dynamical systems point of view of deep learning and compare\nseveral architectures in terms of stability, generalization, and robustness. In\norder to speed up the computations, we propose to use a multilevel\ndiscretization technique. Our preliminary results suggest that the multilevel\ndiscretization method improves solutions times by an order of magnitude\ncompared to existing methods without sacrificing stability or robustness.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 11:16:01 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["G\u00fcler", "Batuhan", ""], ["Laignelet", "Alexis", ""], ["Parpas", "Panos", ""]]}, {"id": "1910.11626", "submitter": "David Bau iii", "authors": "David Bau, Jun-Yan Zhu, Jonas Wulff, William Peebles, Hendrik\n  Strobelt, Bolei Zhou, Antonio Torralba", "title": "Seeing What a GAN Cannot Generate", "comments": "ICCV 2019 oral; http://ganseeing.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of Generative Adversarial Networks (GANs), mode collapse\nremains a serious issue during GAN training. To date, little work has focused\non understanding and quantifying which modes have been dropped by a model. In\nthis work, we visualize mode collapse at both the distribution level and the\ninstance level. First, we deploy a semantic segmentation network to compare the\ndistribution of segmented objects in the generated images with the target\ndistribution in the training set. Differences in statistics reveal object\nclasses that are omitted by a GAN. Second, given the identified omitted object\nclasses, we visualize the GAN's omissions directly. In particular, we compare\nspecific differences between individual photos and their approximate inversions\nby a GAN. To this end, we relax the problem of inversion and solve the\ntractable problem of inverting a GAN layer instead of the entire generator.\nFinally, we use this framework to analyze several recent GANs trained on\nmultiple datasets and identify their typical failure cases.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 17:56:04 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Bau", "David", ""], ["Zhu", "Jun-Yan", ""], ["Wulff", "Jonas", ""], ["Peebles", "William", ""], ["Strobelt", "Hendrik", ""], ["Zhou", "Bolei", ""], ["Torralba", "Antonio", ""]]}, {"id": "1910.11632", "submitter": "Michael J. Klaiber", "authors": "Michael J. Klaiber, Sebastian Vogel, Axel Acosta, Robert Korn,\n  Leonardo Ecco, Kristine Back, Andre Guntoro, Ingo Feldner", "title": "An End-to-End HW/SW Co-Design Methodology to Design Efficient Deep\n  Neural Network Systems using Virtual Models", "comments": null, "journal-ref": "Embedded Systems Week 2019, INTelligent Embedded Systems\n  Architectures and Applications Workshop 2019", "doi": "10.1145/3372394.3372396", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end performance estimation and measurement of deep neural network\n(DNN) systems become more important with increasing complexity of DNN systems\nconsisting of hardware and software components. The methodology proposed in\nthis paper aims at a reduced turn-around time for evaluating different design\nchoices of hardware and software components of DNN systems. This reduction is\nachieved by moving the performance estimation from the implementation phase to\nthe concept phase by employing virtual hardware models instead of gathering\nmeasurement results from physical prototypes. Deep learning compilers introduce\nhardware-specific transformations and are, therefore, considered a part of the\ndesign flow of virtual system models to extract end-to-end performance\nestimations. To validate the run-time accuracy of the proposed methodology, a\nsystem processing the DilatedVGG DNN is realized both as virtual system model\nand as hardware implementation. The results show that up to 92 % accuracy can\nbe reached in predicting the processing time of the DNN inference.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 11:42:00 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 11:35:18 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Klaiber", "Michael J.", ""], ["Vogel", "Sebastian", ""], ["Acosta", "Axel", ""], ["Korn", "Robert", ""], ["Ecco", "Leonardo", ""], ["Back", "Kristine", ""], ["Guntoro", "Andre", ""], ["Feldner", "Ingo", ""]]}, {"id": "1910.11643", "submitter": "Chau Luu", "authors": "Chau Luu, Peter Bell, Steve Renals", "title": "Channel adversarial training for speaker verification and diarization", "comments": "Submitted to IEEE ICASSP 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053323", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has encouraged domain-invariance in deep speaker embedding by\nadversarially classifying the dataset or labelled environment to which the\ngenerated features belong. We propose a training strategy which aims to produce\nfeatures that are invariant at the granularity of the recording or channel, a\nfiner grained objective than dataset- or environment-invariance. By training an\nadversary to predict whether pairs of same-speaker embeddings belong to the\nsame recording in a Siamese fashion, learned features are discouraged from\nutilizing channel information that may be speaker discriminative during\ntraining. Experiments for verification on VoxCeleb and diarization and\nverification on CALLHOME show promising improvements over a strong baseline in\naddition to outperforming a dataset-adversarial model. The VoxCeleb model in\nparticular performs well, achieving a $4\\%$ relative improvement in EER over a\nKaldi baseline, while using a similar architecture and less training data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 12:14:17 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Luu", "Chau", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "1910.11664", "submitter": "Marco Tagliasacchi", "authors": "Beat Gfeller, Christian Frank, Dominik Roblek, Matt Sharifi, Marco\n  Tagliasacchi, Mihajlo Velimirovi\\'c", "title": "SPICE: Self-supervised Pitch Estimation", "comments": "Accepted to IEEE Transactions on Audio, Speech and Language\n  Processing", "journal-ref": "in IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing, vol. 28, pp. 1118-1128, 2020", "doi": "10.1109/TASLP.2020.2982285", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model to estimate the fundamental frequency in monophonic audio,\noften referred to as pitch estimation. We acknowledge the fact that obtaining\nground truth annotations at the required temporal and frequency resolution is a\nparticularly daunting task. Therefore, we propose to adopt a self-supervised\nlearning technique, which is able to estimate pitch without any form of\nsupervision. The key observation is that pitch shift maps to a simple\ntranslation when the audio signal is analysed through the lens of the\nconstant-Q transform (CQT). We design a self-supervised task by feeding two\nshifted slices of the CQT to the same convolutional encoder, and require that\nthe difference in the outputs is proportional to the corresponding difference\nin pitch. In addition, we introduce a small model head on top of the encoder,\nwhich is able to determine the confidence of the pitch estimate, so as to\ndistinguish between voiced and unvoiced audio. Our results show that the\nproposed method is able to estimate pitch at a level of accuracy comparable to\nfully supervised models, both on clean and noisy audio samples, although it\ndoes not require access to large labeled datasets.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 12:45:20 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 10:40:39 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Gfeller", "Beat", ""], ["Frank", "Christian", ""], ["Roblek", "Dominik", ""], ["Sharifi", "Matt", ""], ["Tagliasacchi", "Marco", ""], ["Velimirovi\u0107", "Mihajlo", ""]]}, {"id": "1910.11667", "submitter": "Anurag Ranjan", "authors": "Anurag Ranjan and David T. Hoffmann and Dimitrios Tzionas and Siyu\n  Tang and Javier Romero and Michael J. Black", "title": "Learning Multi-Human Optical Flow", "comments": "arXiv admin note: text overlap with arXiv:1806.05666", "journal-ref": "International Journal of Computer Vision (IJCV) 2019", "doi": "10.1007/s11263-019-01279-w", "report-no": "2019", "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optical flow of humans is well known to be useful for the analysis of\nhuman action. Recent optical flow methods focus on training deep networks to\napproach the problem. However, the training data used by them does not cover\nthe domain of human motion. Therefore, we develop a dataset of multi-human\noptical flow and train optical flow networks on this dataset. We use a 3D model\nof the human body and motion capture data to synthesize realistic flow fields\nin both single- and multi-person images. We then train optical flow networks to\nestimate human flow fields from pairs of images. We demonstrate that our\ntrained networks are more accurate than a wide range of top methods on held-out\ntest data and that they can generalize well to real image sequences. The code,\ntrained models and the dataset are available for research.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 11:44:46 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 10:48:45 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Ranjan", "Anurag", ""], ["Hoffmann", "David T.", ""], ["Tzionas", "Dimitrios", ""], ["Tang", "Siyu", ""], ["Romero", "Javier", ""], ["Black", "Michael J.", ""]]}, {"id": "1910.11670", "submitter": "Ashvin Nair", "authors": "Ashvin Nair, Shikhar Bahl, Alexander Khazatsky, Vitchyr Pong, Glen\n  Berseth, Sergey Levine", "title": "Contextual Imagined Goals for Self-Supervised Robotic Learning", "comments": "12 pages, to be presented at Conference on Robot Learning (CoRL)\n  2019. Project website: https://ccrig.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While reinforcement learning provides an appealing formalism for learning\nindividual skills, a general-purpose robotic system must be able to master an\nextensive repertoire of behaviors. Instead of learning a large collection of\nskills individually, can we instead enable a robot to propose and practice its\nown behaviors automatically, learning about the affordances and behaviors that\nit can perform in its environment, such that it can then repurpose this\nknowledge once a new task is commanded by the user? In this paper, we study\nthis question in the context of self-supervised goal-conditioned reinforcement\nlearning. A central challenge in this learning regime is the problem of goal\nsetting: in order to practice useful skills, the robot must be able to\nautonomously set goals that are feasible but diverse. When the robot's\nenvironment and available objects vary, as they do in most open-world settings,\nthe robot must propose to itself only those goals that it can accomplish in its\npresent setting with the objects that are at hand. Previous work only studies\nself-supervised goal-conditioned RL in a single-environment setting, where goal\nproposals come from the robot's past experience or a generative model are\nsufficient. In more diverse settings, this frequently leads to impossible goals\nand, as we show experimentally, prevents effective learning. We propose a\nconditional goal-setting model that aims to propose goals that are feasible\nfrom the robot's current state. We demonstrate that this enables\nself-supervised goal-conditioned off-policy learning with raw image\nobservations in the real world, enabling a robot to manipulate a variety of\nobjects and generalize to new objects that were not seen during training.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 18:00:18 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Nair", "Ashvin", ""], ["Bahl", "Shikhar", ""], ["Khazatsky", "Alexander", ""], ["Pong", "Vitchyr", ""], ["Berseth", "Glen", ""], ["Levine", "Sergey", ""]]}, {"id": "1910.11680", "submitter": "Marcel Keller", "authors": "Marcel Keller and Ke Sun", "title": "A Note on Our Submission to Track 4 of iDASH 2019", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  iDASH is a competition soliciting implementations of cryptographic schemes of\ninterest in the context of biology. In 2019, one track asked for multi-party\ncomputation implementations of training of a machine learning model suitable\nfor two datasets from cancer research. In this note, we describe our solution\nsubmitted to the competition. We found that the training can be run on three\nAWS c5.9xlarge instances in less then one minute using MPC tolerating one\nsemi-honest corruption, and less than ten seconds at a slightly lower accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 10:18:02 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Keller", "Marcel", ""], ["Sun", "Ke", ""]]}, {"id": "1910.11690", "submitter": "Kazuhiro Nakamura", "authors": "Kazuhiro Nakamura, Shinji Takaki, Kei Hashimoto, Keiichiro Oura,\n  Yoshihiko Nankaku, Keiichi Tokuda", "title": "Fast and High-Quality Singing Voice Synthesis System based on\n  Convolutional Neural Networks", "comments": "Accepted to ICASSP 2020. Singing voice samples (Japanese, English,\n  Chinese): https://www.techno-speech.com/news-20181214a-en. arXiv admin note:\n  substantial text overlap with arXiv:1904.06868", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper describes singing voice synthesis based on convolutional\nneural networks (CNNs). Singing voice synthesis systems based on deep neural\nnetworks (DNNs) are currently being proposed and are improving the naturalness\nof synthesized singing voices. As singing voices represent a rich form of\nexpression, a powerful technique to model them accurately is required. In the\nproposed technique, long-term dependencies of singing voices are modeled by\nCNNs. An acoustic feature sequence is generated for each segment that consists\nof long-term frames, and a natural trajectory is obtained without the parameter\ngeneration algorithm. Furthermore, a computational complexity reduction\ntechnique, which drives the DNNs in different time units depending on type of\nmusical score features, is proposed. Experimental results show that the\nproposed method can synthesize natural sounding singing voices much faster than\nthe conventional method.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 04:25:47 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 00:30:04 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Nakamura", "Kazuhiro", ""], ["Takaki", "Shinji", ""], ["Hashimoto", "Kei", ""], ["Oura", "Keiichiro", ""], ["Nankaku", "Yoshihiko", ""], ["Tokuda", "Keiichi", ""]]}, {"id": "1910.11703", "submitter": "Vikram Krishnamurthy", "authors": "William Hoiles and Vikram Krishnamurthy and Kunal Pattanayak", "title": "Rationally Inattentive Inverse Reinforcement Learning Explains YouTube\n  Commenting Behavior", "comments": "arXiv admin note: substantial text overlap with arXiv:1812.09640", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel application of inverse reinforcement learning with\nbehavioral economics constraints to model, learn and predict the commenting\nbehavior of YouTube viewers. Each group of users is modeled as a rationally\ninattentive Bayesian agent which solves a contextual bandit problem. Our\nmethodology integrates three key components. First, to identify distinct\ncommenting patterns, we use deep embedded clustering to estimate framing\ninformation (essential extrinsic features) that clusters users into distinct\ngroups.Second, we present an inverse reinforcement learning algorithm that uses\nBayesian revealed preferences to test for rationality: does there exist a\nutility function that rationalizes the given data, and if yes, can it be used\nto predict commenting behavior? Finally, we impose behavioral economics\nconstraints stemming from rational inattention to characterize the attention\nspan of groups of users. The test imposes a R{\\'e}nyi mutual information cost\nconstraint which impacts how the agent can select attention strategies to\nmaximize their expected utility. After a careful analysis of a massive YouTube\ndataset, our surprising result is that in most YouTube user groups, the\ncommenting behavior is consistent with optimizing a Bayesian utility with\nrationally inattentive constraints. The paper also highlights how the rational\ninattention model can accurately predict commenting behavior. The massive\nYouTube dataset and analysis used in this paper are available on GitHub and\ncompletely reproducible.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 10:46:30 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 17:42:33 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Hoiles", "William", ""], ["Krishnamurthy", "Vikram", ""], ["Pattanayak", "Kunal", ""]]}, {"id": "1910.11710", "submitter": "Zhiqin Xu", "authors": "Wei Cai, Zhi-Qin John Xu", "title": "Multi-scale Deep Neural Networks for Solving High Dimensional PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the idea of radial scaling in frequency domain and\nactivation functions with compact support to produce a multi-scale DNN\n(MscaleDNN), which will have the multi-scale capability in approximating high\nfrequency and high dimensional functions and speeding up the solution of high\ndimensional PDEs. Numerical results on high dimensional function fitting and\nsolutions of high dimensional PDEs, using loss functions with either Ritz\nenergy or least squared PDE residuals, have validated the increased power of\nmulti-scale resolution and high frequency capturing of the proposed MscaleDNN.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 13:26:39 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Cai", "Wei", ""], ["Xu", "Zhi-Qin John", ""]]}, {"id": "1910.11721", "submitter": "Zhibing Zhao", "authors": "Zhibing Zhao, Lirong Xia", "title": "Learning Mixtures of Plackett-Luce Models from Structured Partial Orders", "comments": "15 pages, 5 figures, accepted by NeurIPS 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixtures of ranking models have been widely used for heterogeneous\npreferences. However, learning a mixture model is highly nontrivial, especially\nwhen the dataset consists of partial orders. In such cases, the parameter of\nthe model may not be even identifiable. In this paper, we focus on three\npopular structures of partial orders: ranked top-$l_1$, $l_2$-way, and choice\ndata over a subset of alternatives. We prove that when the dataset consists of\ncombinations of ranked top-$l_1$ and $l_2$-way (or choice data over up to $l_2$\nalternatives), mixture of $k$ Plackett-Luce models is not identifiable when\n$l_1+l_2\\le 2k-1$ ($l_2$ is set to $1$ when there are no $l_2$-way orders). We\nalso prove that under some combinations, including ranked top-$3$, ranked\ntop-$2$ plus $2$-way, and choice data over up to $4$ alternatives, mixtures of\ntwo Plackett-Luce models are identifiable. Guided by our theoretical results,\nwe propose efficient generalized method of moments (GMM) algorithms to learn\nmixtures of two Plackett-Luce models, which are proven consistent. Our\nexperiments demonstrate the efficacy of our algorithms. Moreover, we show that\nwhen full rankings are available, learning from different marginal events\n(partial orders) provides tradeoffs between statistical efficiency and\ncomputational efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 13:39:34 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Zhao", "Zhibing", ""], ["Xia", "Lirong", ""]]}, {"id": "1910.11758", "submitter": "Florian Mai", "authors": "Prabhu Teja Sivaprasad (1 and 2), Florian Mai (1 and 2), Thijs Vogels\n  (2), Martin Jaggi (2), Fran\\c{c}ois Fleuret (2 and 3) ((1) Idiap Research\n  Institute, (2) EPFL, (3) University of Geneva)", "title": "Optimizer Benchmarking Needs to Account for Hyperparameter Tuning", "comments": "published at International Conference on Machine Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of optimizers, particularly in deep learning, depends\nconsiderably on their chosen hyperparameter configuration. The efficacy of\noptimizers is often studied under near-optimal problem-specific\nhyperparameters, and finding these settings may be prohibitively costly for\npractitioners. In this work, we argue that a fair assessment of optimizers'\nperformance must take the computational cost of hyperparameter tuning into\naccount, i.e., how easy it is to find good hyperparameter configurations using\nan automatic hyperparameter search. Evaluating a variety of optimizers on an\nextensive set of standard datasets and architectures, our results indicate that\nAdam is the most practical solution, particularly in low-budget scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 14:27:00 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 14:21:17 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 12:15:51 GMT"}, {"version": "v4", "created": "Sat, 15 Aug 2020 14:55:09 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sivaprasad", "Prabhu Teja", "", "1 and 2"], ["Mai", "Florian", "", "1 and 2"], ["Vogels", "Thijs", "", "2 and 3"], ["Jaggi", "Martin", "", "2 and 3"], ["Fleuret", "Fran\u00e7ois", "", "2 and 3"]]}, {"id": "1910.11760", "submitter": "Chuang Gan", "authors": "Chuang Gan, Hang Zhao, Peihao Chen, David Cox, Antonio Torralba", "title": "Self-supervised Moving Vehicle Tracking with Stereo Sound", "comments": "To appear at ICCV 2019. Project page:\n  http://sound-track.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to localize objects in the environment using both visual and\nauditory cues, integrating information from multiple modalities into a common\nreference frame. We introduce a system that can leverage unlabeled audio-visual\ndata to learn to localize objects (moving vehicles) in a visual reference\nframe, purely using stereo sound at inference time. Since it is labor-intensive\nto manually annotate the correspondences between audio and object bounding\nboxes, we achieve this goal by using the co-occurrence of visual and audio\nstreams in unlabeled videos as a form of self-supervision, without resorting to\nthe collection of ground-truth annotations. In particular, we propose a\nframework that consists of a vision \"teacher\" network and a stereo-sound\n\"student\" network. During training, knowledge embodied in a well-established\nvisual vehicle detection model is transferred to the audio domain using\nunlabeled videos as a bridge. At test time, the stereo-sound student network\ncan work independently to perform object localization us-ing just stereo audio\nand camera meta-data, without any visual input. Experimental results on a newly\ncollected Au-ditory Vehicle Tracking dataset verify that our proposed approach\noutperforms several baseline approaches. We also demonstrate that our\ncross-modal auditory localization approach can assist in the visual\nlocalization of moving vehicles under poor lighting conditions.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 14:28:55 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Gan", "Chuang", ""], ["Zhao", "Hang", ""], ["Chen", "Peihao", ""], ["Cox", "David", ""], ["Torralba", "Antonio", ""]]}, {"id": "1910.11768", "submitter": "Muhammad Osama", "authors": "Chen Liu, Anderson de Andrade, Muhammad Osama", "title": "Exploring Multilingual Syntactic Sentence Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study methods for learning sentence embeddings with syntactic structure.\nWe focus on methods of learning syntactic sentence-embeddings by using a\nmultilingual parallel-corpus augmented by Universal Parts-of-Speech tags. We\nevaluate the quality of the learned embeddings by examining sentence-level\nnearest neighbours and functional dissimilarity in the embedding space. We also\nevaluate the ability of the method to learn syntactic sentence-embeddings for\nlow-resource languages and demonstrate strong evidence for transfer learning.\nOur results show that syntactic sentence-embeddings can be learned while using\nless training data, fewer model parameters, and resulting in better evaluation\nmetrics than state-of-the-art language models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 14:38:18 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Liu", "Chen", ""], ["de Andrade", "Anderson", ""], ["Osama", "Muhammad", ""]]}, {"id": "1910.11777", "submitter": "Teresa Ara\\'ujo", "authors": "Teresa Ara\\'ujo, Guilherme Aresta, Lu\\'is Mendon\\c{c}a, Susana Penas,\n  Carolina Maia, \\^Angela Carneiro, Ana Maria Mendon\\c{c}a, Aur\\'elio Campilho", "title": "DR$\\vert$GRADUATE: uncertainty-aware deep learning-based diabetic\n  retinopathy grading in eye fundus images", "comments": "Published at Medical Image Analysis (Elsevier). Publication licensed\n  under the Creative Commons CC-BY-NC-ND 4.0 license\n  https://creativecommons.org/licenses/by-nc-nd/4.0/. Figures are compressed\n  due to file size constraints", "journal-ref": "Medical Image Analysis, Volume 63, July 2020, 101715", "doi": "10.1016/j.media.2020.101715", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetic retinopathy (DR) grading is crucial in determining the adequate\ntreatment and follow up of patients, but the screening process can be tiresome\nand prone to errors. Deep learning approaches have shown promising performance\nas computer-aided diagnosis(CAD) systems, but their black-box behaviour hinders\nthe clinical application. We propose DR$\\vert$GRADUATE, a novel deep\nlearning-based DR grading CAD system that supports its decision by providing a\nmedically interpretable explanation and an estimation of how uncertain that\nprediction is, allowing the ophthalmologist to measure how much that decision\nshould be trusted. We designed DR$\\vert$GRADUATE taking into account the\nordinal nature of the DR grading problem. A novel Gaussian-sampling approach\nbuilt upon a Multiple Instance Learning framework allow DR$\\vert$GRADUATE to\ninfer an image grade associated with an explanation map and a prediction\nuncertainty while being trained only with image-wise labels. DR$\\vert$GRADUATE\nwas trained on the Kaggle training set and evaluated across multiple datasets.\nIn DR grading, a quadratic-weighted Cohen's kappa (QWK) between 0.71 and 0.84\nwas achieved in five different datasets. We show that high QWK values occur for\nimages with low prediction uncertainty, thus indicating that this uncertainty\nis a valid measure of the predictions' quality. Further, bad quality images are\ngenerally associated with higher uncertainties, showing that images not\nsuitable for diagnosis indeed lead to less trustworthy predictions.\nAdditionally, tests on unfamiliar medical image data types suggest that\nDR$\\vert$GRADUATE allows outlier detection. The attention maps generally\nhighlight regions of interest for diagnosis. These results show the great\npotential of DR$\\vert$GRADUATE as a second-opinion system in DR severity\ngrading.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 14:56:15 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 14:55:20 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Ara\u00fajo", "Teresa", ""], ["Aresta", "Guilherme", ""], ["Mendon\u00e7a", "Lu\u00eds", ""], ["Penas", "Susana", ""], ["Maia", "Carolina", ""], ["Carneiro", "\u00c2ngela", ""], ["Mendon\u00e7a", "Ana Maria", ""], ["Campilho", "Aur\u00e9lio", ""]]}, {"id": "1910.11779", "submitter": "Flavien Prost", "authors": "Flavien Prost, Hai Qian, Qiuwen Chen, Ed H. Chi, Jilin Chen, Alex\n  Beutel", "title": "Toward a better trade-off between performance and fairness with\n  kernel-based distribution matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As recent literature has demonstrated how classifiers often carry unintended\nbiases toward some subgroups, deploying machine learned models to users demands\ncareful consideration of the social consequences. How should we address this\nproblem in a real-world system? How should we balance core performance and\nfairness metrics? In this paper, we introduce a MinDiff framework for\nregularizing classifiers toward different fairness metrics and analyze a\ntechnique with kernel-based statistical dependency tests. We run a thorough\nstudy on an academic dataset to compare the Pareto frontier achieved by\ndifferent regularization approaches, and apply our kernel-based method to two\nlarge-scale industrial systems demonstrating real-world improvements.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 15:03:11 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Prost", "Flavien", ""], ["Qian", "Hai", ""], ["Chen", "Qiuwen", ""], ["Chi", "Ed H.", ""], ["Chen", "Jilin", ""], ["Beutel", "Alex", ""]]}, {"id": "1910.11789", "submitter": "Anurag Kumar", "authors": "Anurag Kumar, Vamsi Krishna Ithapu", "title": "Secost: Sequential co-supervision for large scale weakly labeled audio\n  event detection", "comments": "Accepted IEEE ICASSP 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053613", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly supervised learning algorithms are critical for scaling audio event\ndetection to several hundreds of sound categories. Such learning models should\nnot only disambiguate sound events efficiently with minimal class-specific\nannotation but also be robust to label noise, which is more apparent with weak\nlabels instead of strong annotations. In this work, we propose a new framework\nfor designing learning models with weak supervision by bridging ideas from\nsequential learning and knowledge distillation. We refer to the proposed\nmethodology as SeCoST (pronounced Sequest) -- Sequential Co-supervision for\ntraining generations of Students. SeCoST incrementally builds a cascade of\nstudent-teacher pairs via a novel knowledge transfer method. Our evaluations on\nAudioset (the largest weakly labeled dataset available) show that SeCoST\nachieves a mean average precision of 0.383 while outperforming prior state of\nthe art by a considerable margin.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 15:15:30 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 23:14:06 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 06:48:15 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Kumar", "Anurag", ""], ["Ithapu", "Vamsi Krishna", ""]]}, {"id": "1910.11800", "submitter": "Alessia Amelio Dr.", "authors": "Radmila Jankovi\\'c, Ivan Mihajlovi\\'c, Alessia Amelio", "title": "Time Series Vector Autoregression Prediction of the Ecological Footprint\n  based on Energy Parameters", "comments": "8 pages, 3 figures, accepted at 5th Jubilee Virtual International\n  Conference on Science, Technology and Management in Energy (eNergetics 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.DM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sustainability became the most important component of world development, as\ncountries worldwide fight the battle against the climate change. To understand\nthe effects of climate change, the ecological footprint, along with the\nbiocapacity should be observed. The big part of the ecological footprint, the\ncarbon footprint, is most directly associated with the energy, and specifically\nfuel sources. This paper develops a time series vector autoregression\nprediction model of the ecological footprint based on energy parameters. The\nobjective of the paper is to forecast the EF based solely on energy parameters\nand determine the relationship between the energy and the EF. The dataset\nincluded global yearly observations of the variables for the period 1971-2014.\nPredictions were generated for every variable that was used in the model for\nthe period 2015-2024. The results indicate that the ecological footprint of\nconsumption will continue increasing, as well as the primary energy consumption\nfrom different sources. However, the energy consumption from coal sources is\npredicted to have a declining trend.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 15:30:40 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Jankovi\u0107", "Radmila", ""], ["Mihajlovi\u0107", "Ivan", ""], ["Amelio", "Alessia", ""]]}, {"id": "1910.11831", "submitter": "Lingxi Xie", "authors": "Kaifeng Bi, Changping Hu, Lingxi Xie, Xin Chen, Longhui Wei, Qi Tian", "title": "Stabilizing DARTS with Amended Gradient Estimation on Architectural\n  Parameters", "comments": "22 pages, 12 figures, submitted to ICML 2020, updated experiments on\n  Penn Treebank", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DARTS is a popular algorithm for neural architecture search (NAS). Despite\nits great advantage in search efficiency, DARTS often suffers weak stability,\nwhich reflects in the large variation among individual trials as well as the\nsensitivity to the hyper-parameters of the search process. This paper owes such\ninstability to an optimization gap between the super-network and its\nsub-networks, namely, improving the validation accuracy of the super-network\ndoes not necessarily lead to a higher expectation on the performance of the\nsampled sub-networks. Then, we point out that the gap is due to the inaccurate\nestimation of the architectural gradients, based on which we propose an amended\nestimation method. Mathematically, our method guarantees a bounded error from\nthe true gradients while the original estimation does not. Our approach bridges\nthe gap from two aspects, namely, amending the estimation on the architectural\ngradients, and unifying the hyper-parameter settings in the search and\nre-training stages. Experiments on CIFAR10 and ImageNet demonstrate that our\napproach largely improves search stability and, more importantly, enables\nDARTS-based approaches to explore much larger search spaces that have not been\ninvestigated before.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 16:31:25 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 08:59:51 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 04:22:46 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 04:19:28 GMT"}, {"version": "v5", "created": "Mon, 4 May 2020 10:19:18 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bi", "Kaifeng", ""], ["Hu", "Changping", ""], ["Xie", "Lingxi", ""], ["Chen", "Xin", ""], ["Wei", "Longhui", ""], ["Tian", "Qi", ""]]}, {"id": "1910.11843", "submitter": "Yang Zhou", "authors": "Yangxin Lin, Ping Wang, Yang Zhou, Fan Ding, Chen Wang, Huachun Tan", "title": "Platoon trajectories generation: A unidirectional interconnected\n  LSTM-based car following model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Car following models have been widely applied and made remarkable\nachievements in traffic engineering. However, the traffic micro-simulation\naccuracy of car following models in a platoon level, especially during traffic\noscillations, still needs to be enhanced. Rather than using traditional\nindividual car following models, we proposed a new trajectory generation\napproach to generate platoon level trajectories given the first leading\nvehicle's trajectory. In this paper, we discussed the temporal and spatial\nerror propagation issue for the traditional approach by a car following block\ndiagram representation. Based on the analysis, we pointed out that error comes\nfrom the training method and the model structure. In order to fix that, we\nadopt two improvements on the basis of the traditional LSTM based car following\nmodel. We utilized a scheduled sampling technique during the training process\nto solve the error propagation in the temporal dimension. Furthermore, we\ndeveloped a unidirectional interconnected LSTM model structure to extract\ntrajectories features from the perspective of the platoon. As indicated by the\nsystematic empirical experiments, the proposed novel structure could\nefficiently reduce the temporal and spatial error propagation. Compared with\nthe traditional LSTM based car following model, the proposed model has almost\n40% less error. The findings will benefit the design and analysis of\nmicro-simulation for platoon level car following models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 16:58:00 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Lin", "Yangxin", ""], ["Wang", "Ping", ""], ["Zhou", "Yang", ""], ["Ding", "Fan", ""], ["Wang", "Chen", ""], ["Tan", "Huachun", ""]]}, {"id": "1910.11853", "submitter": "Bin Sun", "authors": "Bin Sun, Jun Li, Ming Shao, Yun Fu", "title": "LPRNet: Lightweight Deep Network by Low-rank Pointwise Residual\n  Convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become popular in recent years primarily due to the\npowerful computing device such as GPUs. However, deploying these deep models to\nend-user devices, smart phones, or embedded systems with limited resources is\nchallenging. To reduce the computation and memory costs, we propose a novel\nlightweight deep learning module by low-rank pointwise residual (LPR)\nconvolution, called LPRNet. Essentially, LPR aims at using low-rank\napproximation in pointwise convolution to further reduce the module size, while\nkeeping depthwise convolutions as the residual module to rectify the LPR\nmodule. This is critical when the low-rankness undermines the convolution\nprocess. We embody our design by replacing modules of identical input-output\ndimension in MobileNet and ShuffleNetv2. Experiments on visual recognition\ntasks including image classification and face alignment on popular benchmarks\nshow that our LPRNet achieves competitive performance but with significant\nreduction of Flops and memory cost compared to the state-of-the-art deep models\nfocusing on model compression.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 17:23:05 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 18:08:55 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 22:44:48 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Sun", "Bin", ""], ["Li", "Jun", ""], ["Shao", "Ming", ""], ["Fu", "Yun", ""]]}, {"id": "1910.11856", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Sebastian Ruder, Dani Yogatama", "title": "On the Cross-lingual Transferability of Monolingual Representations", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art unsupervised multilingual models (e.g., multilingual BERT)\nhave been shown to generalize in a zero-shot cross-lingual setting. This\ngeneralization ability has been attributed to the use of a shared subword\nvocabulary and joint training across multiple languages giving rise to deep\nmultilingual abstractions. We evaluate this hypothesis by designing an\nalternative approach that transfers a monolingual model to new languages at the\nlexical level. More concretely, we first train a transformer-based masked\nlanguage model on one language, and transfer it to a new language by learning a\nnew embedding matrix with the same masked language modeling objective, freezing\nparameters of all other layers. This approach does not rely on a shared\nvocabulary or joint training. However, we show that it is competitive with\nmultilingual BERT on standard cross-lingual classification benchmarks and on a\nnew Cross-lingual Question Answering Dataset (XQuAD). Our results contradict\ncommon beliefs of the basis of the generalization ability of multilingual\nmodels and suggest that deep monolingual models learn some abstractions that\ngeneralize across languages. We also release XQuAD as a more comprehensive\ncross-lingual benchmark, which comprises 240 paragraphs and 1190\nquestion-answer pairs from SQuAD v1.1 translated into ten languages by\nprofessional translators.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 17:30:20 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 16:55:33 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 22:45:22 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Artetxe", "Mikel", ""], ["Ruder", "Sebastian", ""], ["Yogatama", "Dani", ""]]}, {"id": "1910.11858", "submitter": "Colin White", "authors": "Colin White, Willie Neiswanger, Yash Savani", "title": "BANANAS: Bayesian Optimization with Neural Architectures for Neural\n  Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past half-decade, many methods have been considered for neural\narchitecture search (NAS). Bayesian optimization (BO), which has long had\nsuccess in hyperparameter optimization, has recently emerged as a very\npromising strategy for NAS when it is coupled with a neural predictor. Recent\nwork has proposed different instantiations of this framework, for example,\nusing Bayesian neural networks or graph convolutional networks as the\npredictive model within BO. However, the analyses in these papers often focus\non the full-fledged NAS algorithm, so it is difficult to tell which individual\ncomponents of the framework lead to the best performance.\n  In this work, we give a thorough analysis of the \"BO + neural predictor\"\nframework by identifying five main components: the architecture encoding,\nneural predictor, uncertainty calibration method, acquisition function, and\nacquisition optimization strategy. We test several different methods for each\ncomponent and also develop a novel path-based encoding scheme for neural\narchitectures, which we show theoretically and empirically scales better than\nother encodings. Using all of our analyses, we develop a final algorithm called\nBANANAS, which achieves state-of-the-art performance on NAS search spaces. We\nadhere to the NAS research checklist (Lindauer and Hutter 2019) to facilitate\nbest practices, and our code is available at\nhttps://github.com/naszilla/naszilla.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 17:35:49 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 08:39:44 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 15:28:47 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["White", "Colin", ""], ["Neiswanger", "Willie", ""], ["Savani", "Yash", ""]]}, {"id": "1910.11868", "submitter": "Yakup Ceki Papo", "authors": "Yakup Ceki Papo", "title": "Bias-Variance Tradeoff in a Sliding Window Implementation of the\n  Stochastic Gradient Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a framework to analyze stochastic gradient algorithms in\na mean squared error (MSE) sense using the asymptotic normality result of the\nstochastic gradient descent (SGD) iterates. We perform this analysis by taking\nthe asymptotic normality result and applying it to the finite iteration case.\nSpecifically, we look at problems where the gradient estimators are biased and\nhave reduced variance and compare the iterates generated by these gradient\nestimators to the iterates generated by the SGD algorithm. We use the work of\nFabian to characterize the mean and the variance of the distribution of the\niterates in terms of the bias and the covariance matrix of the gradient\nestimators. We introduce the sliding window SGD (SW-SGD) algorithm, with its\nproof of convergence, which incurs a lower MSE than the SGD algorithm on\nquadratic and convex problems. Lastly, we present some numerical results to\nshow the effectiveness of this framework and the superiority of SW-SGD\nalgorithm over the SGD algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 18:38:41 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Papo", "Yakup Ceki", ""]]}, {"id": "1910.11901", "submitter": "Xinwei Chen", "authors": "Xinwei Chen, Marlin W. Ulmer, Barrett W. Thomas", "title": "Deep Q-Learning for Same-Day Delivery with Vehicles and Drones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider same-day delivery with vehicles and drones.\nCustomers make delivery requests over the course of the day, and the dispatcher\ndynamically dispatches vehicles and drones to deliver the goods to customers\nbefore their delivery deadline. Vehicles can deliver multiple packages in one\nroute but travel relatively slowly due to the urban traffic. Drones travel\nfaster, but they have limited capacity and require charging or battery swaps.\nTo exploit the different strengths of the fleets, we propose a deep Q-learning\napproach. Our method learns the value of assigning a new customer to either\ndrones or vehicles as well as the option to not offer service at all. In a\nsystematic computational analysis, we show the superiority of our policy\ncompared to benchmark policies and the effectiveness of our deep Q-learning\napproach. We also show that our policy can maintain effectiveness when the\nfleet size changes moderately. Experiments on data drawn from varied\nspatial/temporal distributions demonstrate that our trained policies can cope\nwith changes in the input data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 18:46:24 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 01:08:46 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Chen", "Xinwei", ""], ["Ulmer", "Marlin W.", ""], ["Thomas", "Barrett W.", ""]]}, {"id": "1910.11910", "submitter": "Felix De Chaumont Quitry", "authors": "F\\'elix de Chaumont Quitry, Marco Tagliasacchi, Dominik Roblek", "title": "Learning audio representations via phase prediction", "comments": "Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We learn audio representations by solving a novel self-supervised learning\ntask, which consists of predicting the phase of the short-time Fourier\ntransform from its magnitude. A convolutional encoder is used to map the\nmagnitude spectrum of the input waveform to a lower dimensional embedding. A\nconvolutional decoder is then used to predict the instantaneous frequency\n(i.e., the temporal rate of change of the phase) from such embedding. To\nevaluate the quality of the learned representations, we evaluate how they\ntransfer to a wide variety of downstream audio tasks. Our experiments reveal\nthat the phase prediction task leads to representations that generalize across\ndifferent tasks, partially bridging the gap with fully-supervised models. In\naddition, we show that the predicted phase can be used as initialization of the\nGriffin-Lim algorithm, thus reducing the number of iterations needed to\nreconstruct the waveform in the time domain.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 19:36:09 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Quitry", "F\u00e9lix de Chaumont", ""], ["Tagliasacchi", "Marco", ""], ["Roblek", "Dominik", ""]]}, {"id": "1910.11914", "submitter": "Lea Marion Trenkwalder", "authors": "Walter L. Boyajian and Jens Clausen and Lea M. Trenkwalder and Vedran\n  Dunjko and Hans J. Briegel", "title": "On the convergence of projective-simulation-based reinforcement learning\n  in Markov decision processes", "comments": "20 pages, 2 figures, v3: a few minor updates to match journal\n  version. Order of authors changed", "journal-ref": "Quantum Mach. Intell. 2, 13 (2020)", "doi": "10.1007/s42484-020-00023-9", "report-no": null, "categories": "cs.LG cs.AI quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the interest in leveraging quantum effects for enhancing\nmachine learning tasks has significantly increased. Many algorithms speeding up\nsupervised and unsupervised learning were established. The first framework in\nwhich ways to exploit quantum resources specifically for the broader context of\nreinforcement learning were found is projective simulation. Projective\nsimulation presents an agent-based reinforcement learning approach designed in\na manner which may support quantum walk-based speed-ups. Although classical\nvariants of projective simulation have been benchmarked against common\nreinforcement learning algorithms, very few formal theoretical analyses have\nbeen provided for its performance in standard learning scenarios. In this\npaper, we provide a detailed formal discussion of the properties of this model.\nSpecifically, we prove that one version of the projective simulation model,\nunderstood as a reinforcement learning approach, converges to optimal behavior\nin a large class of Markov decision processes. This proof shows that a\nphysically-inspired approach to reinforcement learning can guarantee to\nconverge.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 19:46:04 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 17:31:01 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 15:49:08 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Boyajian", "Walter L.", ""], ["Clausen", "Jens", ""], ["Trenkwalder", "Lea M.", ""], ["Dunjko", "Vedran", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1910.11923", "submitter": "Eran Malach", "authors": "Eran Malach, Shai Shalev-Shwartz", "title": "Learning Boolean Circuits with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While on some natural distributions, neural-networks are trained efficiently\nusing gradient-based algorithms, it is known that learning them is\ncomputationally hard in the worst-case. To separate hard from easy to learn\ndistributions, we observe the property of local correlation: correlation\nbetween local patterns of the input and the target label. We focus on learning\ndeep neural-networks using a gradient-based algorithm, when the target function\nis a tree-structured Boolean circuit. We show that in this case, the existence\nof correlation between the gates of the circuit and the target label determines\nwhether the optimization succeeds or fails. Using this result, we show that\nneural-networks can learn the (log n)-parity problem for most product\ndistributions. These results hint that local correlation may play an important\nrole in separating easy/hard to learn distributions. We also obtain a novel\ndepth separation result, in which we show that a shallow network cannot express\nsome functions, while there exists an efficient gradient-based algorithm that\ncan learn the very same functions using a deep network. The negative\nexpressivity result for shallow networks is obtained by a reduction from\nresults in communication complexity, that may be of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 20:26:13 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 11:51:02 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Malach", "Eran", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "1910.11933", "submitter": "Alexandros Kastanos", "authors": "Alexandros Kastanos, Anton Ragni, Mark Gales", "title": "Confidence Estimation for Black Box Automatic Speech Recognition Systems\n  Using Lattice Recurrent Neural Networks", "comments": "5 pages, 8 figures, ICASSP submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been growth in providers of speech transcription services\nenabling others to leverage technology they would not normally be able to use.\nAs a result, speech-enabled solutions have become commonplace. Their success\ncritically relies on the quality, accuracy, and reliability of the underlying\nspeech transcription systems. Those black box systems, however, offer limited\nmeans for quality control as only word sequences are typically available. This\npaper examines this limited resource scenario for confidence estimation, a\nmeasure commonly used to assess transcription reliability. In particular, it\nexplores what other sources of word and sub-word level information available in\nthe transcription process could be used to improve confidence scores. To encode\nall such information this paper extends lattice recurrent neural networks to\nhandle sub-words. Experimental results using the IARPA OpenKWS 2016 evaluation\nsystem show that the use of additional information yields significant gains in\nconfidence estimation accuracy. The implementation for this model can be found\nonline.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 21:01:40 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 15:15:39 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Kastanos", "Alexandros", ""], ["Ragni", "Anton", ""], ["Gales", "Mark", ""]]}, {"id": "1910.11945", "submitter": "Guangtao Wang", "authors": "Guangtao Wang and Rex Ying and Jing Huang and Jure Leskovec", "title": "Improving Graph Attention Networks with Large Margin-based Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Attention Networks (GATs) are the state-of-the-art neural architecture\nfor representation learning with graphs. GATs learn attention functions that\nassign weights to nodes so that different nodes have different influences in\nthe feature aggregation steps. In practice, however, induced attention\nfunctions are prone to over-fitting due to the increasing number of parameters\nand the lack of direct supervision on attention weights. GATs also suffer from\nover-smoothing at the decision boundary of nodes. Here we propose a framework\nto address their weaknesses via margin-based constraints on attention during\ntraining. We first theoretically demonstrate the over-smoothing behavior of\nGATs and then develop an approach using constraint on the attention weights\naccording to the class boundary and feature aggregation pattern. Furthermore,\nto alleviate the over-fitting problem, we propose additional constraints on the\ngraph structure. Extensive experiments and ablation studies on common benchmark\ndatasets demonstrate the effectiveness of our method, which leads to\nsignificant improvements over the previous state-of-the-art graph attention\nmethods on all datasets.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 21:24:00 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wang", "Guangtao", ""], ["Ying", "Rex", ""], ["Huang", "Jing", ""], ["Leskovec", "Jure", ""]]}, {"id": "1910.11950", "submitter": "Andreas Munk", "authors": "Andreas Munk, Adam \\'Scibior, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Andrew\n  Stewart, Goran Fernlund, Anoush Poursartip, Frank Wood", "title": "Deep Probabilistic Surrogate Networks for Universal Simulator\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for automatically structuring and training fast,\napproximate, deep neural surrogates of existing stochastic simulators. Unlike\ntraditional approaches to surrogate modeling, our surrogates retain the\ninterpretable structure of the reference simulators. The particular way we\nachieve this allows us to replace the reference simulator with the surrogate\nwhen undertaking amortized inference in the probabilistic programming sense.\nThe fidelity and speed of our surrogates allow for not only faster \"forward\"\nstochastic simulation but also for accurate and substantially faster inference.\nWe support these claims via experiments that involve a commercial\ncomposite-materials curing simulator. Employing our surrogate modeling\ntechnique makes inference an order of magnitude faster, opening up the\npossibility of doing simulator-based, non-invasive, just-in-time parts quality\ntesting; in this case inferring safety-critical latent internal temperature\nprofiles of composite materials undergoing curing from surface temperature\nprofile measurements.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 21:55:22 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Munk", "Andreas", ""], ["\u015acibior", "Adam", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Stewart", "Andrew", ""], ["Fernlund", "Goran", ""], ["Poursartip", "Anoush", ""], ["Wood", "Frank", ""]]}, {"id": "1910.11956", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta, Vikash Kumar, Corey Lynch, Sergey Levine, Karol\n  Hausman", "title": "Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and\n  Reinforcement Learning", "comments": "Published at CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present relay policy learning, a method for imitation and reinforcement\nlearning that can solve multi-stage, long-horizon robotic tasks. This general\nand universally-applicable, two-phase approach consists of an imitation\nlearning stage that produces goal-conditioned hierarchical policies, and a\nreinforcement learning phase that finetunes these policies for task\nperformance. Our method, while not necessarily perfect at imitation learning,\nis very amenable to further improvement via environment interaction, allowing\nit to scale to challenging long-horizon tasks. We simplify the long-horizon\npolicy learning problem by using a novel data-relabeling algorithm for learning\ngoal-conditioned hierarchical policies, where the low-level only acts for a\nfixed number of steps, regardless of the goal achieved. While we rely on\ndemonstration data to bootstrap policy learning, we do not assume access to\ndemonstrations of every specific tasks that is being solved, and instead\nleverage unstructured and unsegmented demonstrations of semantically meaningful\nbehaviors that are not only less burdensome to provide, but also can greatly\nfacilitate further improvement using reinforcement learning. We demonstrate the\neffectiveness of our method on a number of multi-stage, long-horizon\nmanipulation tasks in a challenging kitchen simulation environment. Videos are\navailable at https://relay-policy-learning.github.io/\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 23:01:43 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Gupta", "Abhishek", ""], ["Kumar", "Vikash", ""], ["Lynch", "Corey", ""], ["Levine", "Sergey", ""], ["Hausman", "Karol", ""]]}, {"id": "1910.11958", "submitter": "Matt Whitehill", "authors": "Matt Whitehill, Shuang Ma, Daniel McDuff, Yale Song", "title": "Multi-Reference Neural TTS Stylization with Adversarial Cycle\n  Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current multi-reference style transfer models for Text-to-Speech (TTS)\nperform sub-optimally on disjoints datasets, where one dataset contains only a\nsingle style class for one of the style dimensions. These models generally fail\nto produce style transfer for the dimension that is underrepresented in the\ndataset. In this paper, we propose an adversarial cycle consistency training\nscheme with paired and unpaired triplets to ensure the use of information from\nall style dimensions. During training, we incorporate unpaired triplets with\nrandomly selected reference audio samples and encourage the synthesized speech\nto preserve the appropriate styles using adversarial cycle consistency. We use\nthis method to transfer emotion from a dataset containing four emotions to a\ndataset with only a single emotion. This results in a 78% improvement in style\ntransfer (based on emotion classification) with minimal reduction in fidelity\nand naturalness. In subjective evaluations our method was consistently rated as\ncloser to the reference style than the baseline. Synthesized speech samples are\navailable at: https://sites.google.com/view/adv-cycle-consistent-tts\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 23:11:27 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Whitehill", "Matt", ""], ["Ma", "Shuang", ""], ["McDuff", "Daniel", ""], ["Song", "Yale", ""]]}, {"id": "1910.11961", "submitter": "Andreas Munk", "authors": "William Harvey, Andreas Munk, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin,\n  Alexander Bergholm, Frank Wood", "title": "Attention for Inference Compilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to automatic amortized inference in universal\nprobabilistic programs which improves performance compared to current methods.\nOur approach is a variation of inference compilation (IC) which leverages deep\nneural networks to approximate a posterior distribution over latent variables\nin a probabilistic program. A challenge with existing IC network architectures\nis that they can fail to model long-range dependencies between latent\nvariables. To address this, we introduce an attention mechanism that attends to\nthe most salient variables previously sampled in the execution of a\nprobabilistic program. We demonstrate that the addition of attention allows the\nproposal distributions to better match the true posterior, enhancing inference\nabout latent variables in simulators.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 23:21:37 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Harvey", "William", ""], ["Munk", "Andreas", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Bergholm", "Alexander", ""], ["Wood", "Frank", ""]]}, {"id": "1910.11971", "submitter": "Xundong Wu", "authors": "Zhilin Yu, Chao Wang, Xin Wang, Qing Wu, Yong Zhao, Xundong Wu", "title": "Cross-Channel Intragroup Sparsity Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural networks rely on overparameterization to achieve\nstate-of-the-art generalization. But overparameterized models are\ncomputationally expensive. Network pruning is often employed to obtain less\ndemanding models for deployment. Fine-grained pruning removes individual\nweights in parameter tensors and can achieve a high model compression ratio\nwith little accuracy degradation. However, it introduces irregularity into the\ncomputing dataflow and often does not yield improved model inference efficiency\nin practice. Coarse-grained model pruning, while realizing satisfactory\ninference speedup through removal of network weights in groups, e.g. an entire\nfilter, often lead to significant accuracy degradation. This work introduces\nthe cross-channel intragroup (CCI) sparsity structure, which can prevent the\ninference inefficiency of fine-grained pruning while maintaining outstanding\nmodel performance. We then present a novel training algorithm designed to\nperform well under the constraint imposed by the CCI-Sparsity. Through a series\nof comparative experiments we show that our proposed CCI-Sparsity structure and\nthe corresponding pruning algorithm outperform prior art in inference\nefficiency by a substantial margin given suited hardware acceleration in the\nfuture.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 01:03:01 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 05:29:47 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Yu", "Zhilin", ""], ["Wang", "Chao", ""], ["Wang", "Xin", ""], ["Wu", "Qing", ""], ["Zhao", "Yong", ""], ["Wu", "Xundong", ""]]}, {"id": "1910.11997", "submitter": "Rafael Valle", "authors": "Rafael Valle, Jason Li, Ryan Prenger, Bryan Catanzaro", "title": "Mellotron: Multispeaker expressive voice synthesis by conditioning on\n  rhythm, pitch and global style tokens", "comments": "5 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mellotron is a multispeaker voice synthesis model based on Tacotron 2 GST\nthat can make a voice emote and sing without emotive or singing training data.\nBy explicitly conditioning on rhythm and continuous pitch contours from an\naudio signal or music score, Mellotron is able to generate speech in a variety\nof styles ranging from read speech to expressive speech, from slow drawls to\nrap and from monotonous voice to singing voice. Unlike other methods, we train\nMellotron using only read speech data without alignments between text and\naudio. We evaluate our models using the LJSpeech and LibriTTS datasets. We\nprovide F0 Frame Errors and synthesized samples that include style transfer\nfrom other speakers, singers and styles not seen during training, procedural\nmanipulation of rhythm and pitch and choir synthesis.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 04:28:49 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Valle", "Rafael", ""], ["Li", "Jason", ""], ["Prenger", "Ryan", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "1910.11998", "submitter": "Haibin Yu", "authors": "Haibin Yu, Yizhou Chen, Zhongxiang Dai, Kian Hsiang Low, Patrick\n  Jaillet", "title": "Implicit Posterior Variational Inference for Deep Gaussian Processes", "comments": "33rd Annual Conference on Neural Information Processing Systems\n  (NeurIPS-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multi-layer deep Gaussian process (DGP) model is a hierarchical composition\nof GP models with a greater expressive power. Exact DGP inference is\nintractable, which has motivated the recent development of deterministic and\nstochastic approximation methods. Unfortunately, the deterministic\napproximation methods yield a biased posterior belief while the stochastic one\nis computationally costly. This paper presents an implicit posterior\nvariational inference (IPVI) framework for DGPs that can ideally recover an\nunbiased posterior belief and still preserve time efficiency. Inspired by\ngenerative adversarial networks, our IPVI framework achieves this by casting\nthe DGP inference problem as a two-player game in which a Nash equilibrium,\ninterestingly, coincides with an unbiased posterior belief. This consequently\ninspires us to devise a best-response dynamics algorithm to search for a Nash\nequilibrium (i.e., an unbiased posterior belief). Empirical evaluation shows\nthat IPVI outperforms the state-of-the-art approximation methods for DGPs.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 05:07:01 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Yu", "Haibin", ""], ["Chen", "Yizhou", ""], ["Dai", "Zhongxiang", ""], ["Low", "Kian Hsiang", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1910.12001", "submitter": "Faisal Almutairi", "authors": "Faisal M. Almutairi, Charilaos I. Kanatsoulis, and Nicholas D.\n  Sidiropoulos", "title": "PREMA: Principled Tensor Data Recovery from Multiple Aggregated Views", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional data have become ubiquitous and are frequently encountered\nin situations where the information is aggregated over multiple data atoms. The\naggregation can be over time or other features, such as geographical location.\nWe often have access to multiple aggregated views of the same data, each\naggregated in one or more dimensions, especially when data are collected or\nmeasured by different agencies. For instance, item sales can be aggregated\ntemporally, and over groups of stores based on their location or affiliation.\nHowever, data mining and machine learning models benefit from detailed data for\npersonalized analysis and prediction. Thus, data disaggregation algorithms are\nbecoming increasingly important in various domains. The goal of this paper is\nto reconstruct finer-scale data from multiple coarse views, aggregated over\ndifferent (subsets of) dimensions. The proposed method, called PREMA, leverages\nlow-rank tensor factorization tools to fuse the multiple views and provide\nrecovery guarantees under certain conditions. PREMA can tackle challenging\nscenarios, such as missing or partially observed data, double aggregation, and\neven blind disaggregation (without knowledge of the aggregation patterns) using\na variant of PREMA called B-PREMA. To showcase the effectiveness of PREMA, the\npaper includes extensive experiments using real data from different domains:\nretail sales, crime counts, and weather observations.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 05:37:30 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 18:38:31 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Almutairi", "Faisal M.", ""], ["Kanatsoulis", "Charilaos I.", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1910.12004", "submitter": "Eduardo Fonseca", "authors": "Eduardo Fonseca, Frederic Font, Xavier Serra", "title": "Model-agnostic Approaches to Handling Noisy Labels When Training Sound\n  Event Classifiers", "comments": "WASPAA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Label noise is emerging as a pressing issue in sound event classification.\nThis arises as we move towards larger datasets that are difficult to annotate\nmanually, but it is even more severe if datasets are collected automatically\nfrom online repositories, where labels are inferred through automated\nheuristics applied to the audio content or metadata. While learning from noisy\nlabels has been an active area of research in computer vision, it has received\nlittle attention in sound event classification. Most recent computer vision\napproaches against label noise are relatively complex, requiring complex\nnetworks or extra data resources. In this work, we evaluate simple and\nefficient model-agnostic approaches to handling noisy labels when training\nsound event classifiers, namely label smoothing regularization, mixup and\nnoise-robust loss functions. The main advantage of these methods is that they\ncan be easily incorporated to existing deep learning pipelines without need for\nnetwork modifications or extra resources. We report results from experiments\nconducted with the FSDnoisy18k dataset. We show that these simple methods can\nbe effective in mitigating the effect of label noise, providing up to 2.5\\% of\naccuracy boost when incorporated to two different CNNs, while requiring minimal\nintervention and computational overhead.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 05:53:01 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Fonseca", "Eduardo", ""], ["Font", "Frederic", ""], ["Serra", "Xavier", ""]]}, {"id": "1910.12008", "submitter": "Kristy Choi", "authors": "Kristy Choi, Aditya Grover, Trisha Singh, Rui Shu, Stefano Ermon", "title": "Fair Generative Modeling via Weak Supervision", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world datasets are often biased with respect to key demographic factors\nsuch as race and gender. Due to the latent nature of the underlying factors,\ndetecting and mitigating bias is especially challenging for unsupervised\nmachine learning. We present a weakly supervised algorithm for overcoming\ndataset bias for deep generative models. Our approach requires access to an\nadditional small, unlabeled reference dataset as the supervision signal, thus\nsidestepping the need for explicit labels on the underlying bias factors. Using\nthis supplementary dataset, we detect the bias in existing datasets via a\ndensity ratio technique and learn generative models which efficiently achieve\nthe twin goals of: 1) data efficiency by using training examples from both\nbiased and reference datasets for learning; and 2) data generation close in\ndistribution to the reference dataset at test time. Empirically, we demonstrate\nthe efficacy of our approach which reduces bias w.r.t. latent factors by an\naverage of up to 34.6% over baselines for comparable image generation using\ngenerative adversarial networks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 06:40:03 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 11:11:27 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Choi", "Kristy", ""], ["Grover", "Aditya", ""], ["Singh", "Trisha", ""], ["Shu", "Rui", ""], ["Ermon", "Stefano", ""]]}, {"id": "1910.12016", "submitter": "Hao Kong", "authors": "Hao Kong, Canyi Lu, Zhouchen Lin", "title": "Tensor Q-Rank: New Data Dependent Definition of Tensor Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the \\textit{Tensor Nuclear Norm~(TNN)} regularization based on\nt-SVD has been widely used in various low tubal-rank tensor recovery tasks.\nHowever, these models usually require smooth change of data along the third\ndimension to ensure their low rank structures. In this paper, we propose a new\ndefinition of data dependent tensor rank named \\textit{tensor Q-rank} by a\nlearnable orthogonal matrix $\\mathbf{Q}$, and further introduce a unified data\ndependent low rank tensor recovery model. According to the low rank hypothesis,\nwe introduce two explainable selection method of $\\mathbf{Q}$, under which the\ndata tensor may have a more significant low tensor Q-rank structure than that\nof low tubal-rank structure. Specifically, maximizing the variance of singular\nvalue distribution leads to Variance Maximization Tensor Q-Nuclear\nnorm~(VMTQN), while minimizing the value of nuclear norm through manifold\noptimization leads to Manifold Optimization Tensor Q-Nuclear norm~(MOTQN).\nMoreover, we apply these two models to the low rank tensor completion problem,\nand then give an effective algorithm and briefly analyze why our method works\nbetter than TNN based methods in the case of complex data with low sampling\nrate. Finally, experimental results on real-world datasets demonstrate the\nsuperiority of our proposed model in the tensor completion problem with respect\nto other tensor rank regularization models.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 07:53:21 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 18:39:21 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 05:30:41 GMT"}, {"version": "v4", "created": "Tue, 15 Jun 2021 08:50:52 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kong", "Hao", ""], ["Lu", "Canyi", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1910.12019", "submitter": "Huanhou Xiao", "authors": "Huanhou Xiao and Jinglun Shi", "title": "Diverse Video Captioning Through Latent Variable Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically describing video content with text description is challenging\nbut important task, which has been attracting a lot of attention in computer\nvision community. Previous works mainly strive for the accuracy of the\ngenerated sentences, while ignoring the sentences diversity, which is\ninconsistent with human behavior. In this paper, we aim to caption each video\nwith multiple descriptions and propose a novel framework. Concretely, for a\ngiven video, the intermediate latent variables of conventional encode-decode\nprocess are utilized as input to the conditional generative adversarial network\n(CGAN) with the purpose of generating diverse sentences. We adopt different\nConvolutional Neural Networks (CNNs) as our generator that produces\ndescriptions conditioned on latent variables and discriminator that assesses\nthe quality of generated sentences. Simultaneously, a novel DCE metric is\ndesigned to assess the diverse captions. We evaluate our method on the\nbenchmark datasets, where it demonstrates its ability to generate diverse\ndescriptions and achieves superior results against other state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 08:34:20 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 02:26:11 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 01:28:08 GMT"}, {"version": "v4", "created": "Thu, 5 Mar 2020 16:58:51 GMT"}, {"version": "v5", "created": "Thu, 25 Mar 2021 15:12:08 GMT"}, {"version": "v6", "created": "Tue, 15 Jun 2021 14:50:14 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Xiao", "Huanhou", ""], ["Shi", "Jinglun", ""]]}, {"id": "1910.12024", "submitter": "Saiprasad Ravishankar", "authors": "Zhipeng Li, Siqi Ye, Yong Long, and Saiprasad Ravishankar", "title": "SUPER Learning: A Supervised-Unsupervised Framework for Low-Dose CT\n  Image Reconstruction", "comments": "Accepted to International Conference on Computer Vision (ICCV) -\n  Learning for Computational Imaging (LCI) Workshop, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed growing interest in machine learning-based models\nand techniques for low-dose X-ray CT (LDCT) imaging tasks. The methods can\ntypically be categorized into supervised learning methods and unsupervised or\nmodel-based learning methods. Supervised learning methods have recently shown\nsuccess in image restoration tasks. However, they often rely on large training\nsets. Model-based learning methods such as dictionary or transform learning do\nnot require large or paired training sets and often have good generalization\nproperties, since they learn general properties of CT image sets. Recent works\nhave shown the promising reconstruction performance of methods such as\nPWLS-ULTRA that rely on clustering the underlying (reconstructed) image patches\ninto a learned union of transforms. In this paper, we propose a new\nSupervised-UnsuPERvised (SUPER) reconstruction framework for LDCT image\nreconstruction that combines the benefits of supervised learning methods and\n(unsupervised) transform learning-based methods such as PWLS-ULTRA that involve\nhighly image-adaptive clustering. The SUPER model consists of several layers,\neach of which includes a deep network learned in a supervised manner and an\nunsupervised iterative method that involves image-adaptive components. The\nSUPER reconstruction algorithms are learned in a greedy manner from training\ndata. The proposed SUPER learning methods dramatically outperform both the\nconstituent supervised learning-based networks and iterative algorithms for\nLDCT, and use much fewer iterations in the iterative reconstruction modules.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 09:04:45 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Li", "Zhipeng", ""], ["Ye", "Siqi", ""], ["Long", "Yong", ""], ["Ravishankar", "Saiprasad", ""]]}, {"id": "1910.12027", "submitter": "Han Zhang", "authors": "Han Zhang, Zizhao Zhang, Augustus Odena, Honglak Lee", "title": "Consistency Regularization for Generative Adversarial Networks", "comments": "ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are known to be difficult to train,\ndespite considerable research effort. Several regularization techniques for\nstabilizing training have been proposed, but they introduce non-trivial\ncomputational overheads and interact poorly with existing techniques like\nspectral normalization. In this work, we propose a simple, effective training\nstabilizer based on the notion of consistency regularization---a popular\ntechnique in the semi-supervised learning literature. In particular, we augment\ndata passing into the GAN discriminator and penalize the sensitivity of the\ndiscriminator to these augmentations. We conduct a series of experiments to\ndemonstrate that consistency regularization works effectively with spectral\nnormalization and various GAN architectures, loss functions and optimizer\nsettings. Our method achieves the best FID scores for unconditional image\ngeneration compared to other regularization methods on CIFAR-10 and CelebA.\nMoreover, Our consistency regularized GAN (CR-GAN) improves state-of-the-art\nFID scores for conditional generation from 14.73 to 11.48 on CIFAR-10 and from\n8.73 to 6.66 on ImageNet-2012.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 09:06:03 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 21:43:54 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhang", "Han", ""], ["Zhang", "Zizhao", ""], ["Odena", "Augustus", ""], ["Lee", "Honglak", ""]]}, {"id": "1910.12028", "submitter": "Kundan Kumar", "authors": "Debojyoti Mallick, Kundan Kumar, Sumanshu Agarwal", "title": "Blood Vessel Detection using Modified Multiscale MF-FDOG Filters for\n  Diabetic Retinopathy", "comments": "5 Pages, 7 Figures, ICAML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blindness in diabetic patients caused by retinopathy (characterized by an\nincrease in the diameter and new branches of the blood vessels inside the\nretina) is a grave concern. Many efforts have been made for the early detection\nof the disease using various image processing techniques on retinal images.\nHowever, most of the methods are plagued with the false detection of the blood\nvessel pixels. Given that, here, we propose a modified matched filter with the\nfirst derivative of Gaussian. The method uses the top-hat transform and\ncontrast limited histogram equalization. Further, we segment the modified\nmultiscale matched filter response by using a binary threshold obtained from\nthe first derivative of Gaussian. The method was assessed on a publicly\navailable database (DRIVE database). As anticipated, the proposed method\nprovides a higher accuracy compared to the literature. Moreover, a lesser false\ndetection from the existing matched filters and its variants have been\nobserved.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 09:17:10 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mallick", "Debojyoti", ""], ["Kumar", "Kundan", ""], ["Agarwal", "Sumanshu", ""]]}, {"id": "1910.12031", "submitter": "Jinn-Liang Liu", "authors": "Der-Hau Lee, Kuan-Lin Chen, Kuan-Han Liou, Chang-Lun Liu, Jinn-Liang\n  Liu", "title": "Deep Learning and Control Algorithms of Direct Perception for Autonomous\n  Driving", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the direct perception paradigm of autonomous driving, we investigate\nand modify the CNNs (convolutional neural networks) AlexNet and GoogLeNet that\nmap an input image to few perception indicators (heading angle, distances to\npreceding cars, and distance to road centerline) for estimating driving\naffordances in highway traffic. We also design a controller with these\nindicators and the short-range sensor information of TORCS (the open racing car\nsimulator) for driving simulated cars to avoid collisions. We collect a set of\nimages from a TORCS camera in various driving scenarios, train these CNNs using\nthe dataset, test them in unseen traffics, and find that they perform better\nthan earlier algorithms and controllers in terms of training efficiency and\ndriving stability. Source code and data are available on our website.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 09:24:12 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 05:26:27 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Lee", "Der-Hau", ""], ["Chen", "Kuan-Lin", ""], ["Liou", "Kuan-Han", ""], ["Liu", "Chang-Lun", ""], ["Liu", "Jinn-Liang", ""]]}, {"id": "1910.12043", "submitter": "Shogo Iwazaki", "authors": "Shogo Iwazaki, Yu Inatsu, Ichiro Takeuchi", "title": "Bayesian Experimental Design for Finding Reliable Level Set under Input\n  Uncertainty", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the manufacturing industry, it is often necessary to repeat expensive\noperational testing of machine in order to identify the range of input\nconditions under which the machine operates properly. Since it is often\ndifficult to accurately control the input conditions during the actual usage of\nthe machine, there is a need to guarantee the performance of the machine after\nproperly incorporating the possible variation in input conditions. In this\npaper, we formulate this practical manufacturing scenario as an Input Uncertain\nReliable Level Set Estimation (IU-rLSE) problem, and provide an efficient\nalgorithm for solving it. The goal of IU-rLSE is to identify the input range in\nwhich the outputs smaller/greater than a desired threshold can be obtained with\nhigh probability when the input uncertainty is properly taken into\nconsideration. We propose an active learning method to solve the IU-rLSE\nproblem efficiently, theoretically analyze its accuracy and convergence, and\nillustrate its empirical performance through numerical experiments on\nartificial and real data.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 10:30:45 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Iwazaki", "Shogo", ""], ["Inatsu", "Yu", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1910.12048", "submitter": "Hoon Lee", "authors": "Hoon Lee, Tony Q. S. Quek, Sang Hyun Lee", "title": "A Deep Learning Approach to Universal Binary Visible Light Communication\n  Transceiver", "comments": "to appear in IEEE Trans. Wireless Commun", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a deep learning (DL) framework for the design of binary\nmodulated visible light communication (VLC) transceiver with universal dimming\nsupport. The dimming control for the optical binary signal boils down to a\ncombinatorial codebook design so that the average Hamming weight of binary\ncodewords matches with arbitrary dimming target. An unsupervised DL technique\nis employed for obtaining a neural network to replace the encoder-decoder pair\nthat recovers the message from the optically transmitted signal. In such a\ntask, a novel stochastic binarization method is developed to generate the set\nof binary codewords from continuous-valued neural network outputs. For\nuniversal support of arbitrary dimming target, the DL-based VLC transceiver is\ntrained with multiple dimming constraints, which turns out to be a constrained\ntraining optimization that is very challenging to handle with existing DL\nmethods. We develop a new training algorithm that addresses the dimming\nconstraints through a dual formulation of the optimization. Based on the\ndeveloped algorithm, the resulting VLC transceiver can be optimized via the\nend-to-end training procedure. Numerical results verify that the proposed\ncodebook outperforms theoretically best constant weight codebooks under various\nVLC setups.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 11:19:01 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Lee", "Hoon", ""], ["Quek", "Tony Q. S.", ""], ["Lee", "Sang Hyun", ""]]}, {"id": "1910.12050", "submitter": "Yunus Esencayi", "authors": "Yunus Esencayi (SUNY at Buffalo), Marco Gaboardi (Boston University),\n  Shi Li (SUNY at Buffalo), Di Wang (SUNY at Buffalo)", "title": "Facility Location Problem in Differential Privacy Model Revisited", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the uncapacitated facility location problem in the\nmodel of differential privacy (DP) with uniform facility cost. Specifically, we\nfirst show that, under the hierarchically well-separated tree (HST) metrics and\nthe super-set output setting that was introduced in Gupta et. al., there is an\n$\\epsilon$-DP algorithm that achieves an $O(\\frac{1}{\\epsilon})$(expected\nmultiplicative) approximation ratio; this implies an $O(\\frac{\\log\nn}{\\epsilon})$ approximation ratio for the general metric case, where $n$ is\nthe size of the input metric. These bounds improve the best-known results given\nby Gupta et. al. In particular, our approximation ratio for HST-metrics is\nindependent of $n$, and the ratio for general metrics is independent of the\naspect ratio of the input metric. On the negative side, we show that the\napproximation ratio of any $\\epsilon$-DP algorithm is lower bounded by\n$\\Omega(\\frac{1}{\\sqrt{\\epsilon}})$, even for instances on HST metrics with\nuniform facility cost, under the super-set output setting. The lower bound\nshows that the dependence of the approximation ratio for HST metrics on\n$\\epsilon$ can not be removed or greatly improved. Our novel methods and\ntechniques for both the upper and lower bound may find additional applications.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 11:29:29 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Esencayi", "Yunus", "", "SUNY at Buffalo"], ["Gaboardi", "Marco", "", "Boston University"], ["Li", "Shi", "", "SUNY at Buffalo"], ["Wang", "Di", "", "SUNY at Buffalo"]]}, {"id": "1910.12061", "submitter": "Ramya Hebbalaguppe", "authors": "Srinidhi Hegde, Ranjitha Prasad, Ramya Hebbalaguppe, Vishwajith Kumar", "title": "Variational Student: Learning Compact and Sparser Networks in Knowledge\n  Distillation Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The holy grail in deep neural network research is porting the memory- and\ncomputation-intensive network models on embedded platforms with a minimal\ncompromise in model accuracy. To this end, we propose a novel approach, termed\nas Variational Student, where we reap the benefits of compressibility of the\nknowledge distillation (KD) framework, and sparsity inducing abilities of\nvariational inference (VI) techniques. Essentially, we build a sparse student\nnetwork, whose sparsity is induced by the variational parameters found via\noptimizing a loss function based on VI, leveraging the knowledge learnt by an\naccurate but complex pre-trained teacher network. Further, for sparsity\nenhancement, we also employ a Block Sparse Regularizer on a concatenated tensor\nof teacher and student network weights. We demonstrate that the marriage of KD\nand the VI techniques inherits compression properties from the KD framework,\nand enhances levels of sparsity from the VI approach, with minimal compromise\nin the model accuracy. We benchmark our results on LeNet MLP and VGGNet (CNN)\nand illustrate a memory footprint reduction of 64x and 213x on these MLP and\nCNN variants, respectively, without a need to retrain the teacher network.\nFurthermore, in the low data regime, we observed that our method outperforms\nstate-of-the-art Bayesian techniques in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 13:18:54 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Hegde", "Srinidhi", ""], ["Prasad", "Ranjitha", ""], ["Hebbalaguppe", "Ramya", ""], ["Kumar", "Vishwajith", ""]]}, {"id": "1910.12073", "submitter": "Jillian Tompkins", "authors": "Jillian Tompkins", "title": "Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past couple of years, the topic of \"fake news\" and its influence\nover people's opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to \"go viral.\" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 14:29:37 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Tompkins", "Jillian", ""]]}, {"id": "1910.12074", "submitter": "Aditya Pandey", "authors": "Aditya Pandey, Abhishek Sinha and Aishwarya PS", "title": "Intrusion Detection using Sequential Hybrid Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large amount of work has been done on the KDD 99 dataset, most of which\nincludes the use of a hybrid anomaly and misuse detection model done in\nparallel with each other. In order to further classify the intrusions, our\napproach to network intrusion detection includes use of two different anomaly\ndetection models followed by misuse detection applied on the combined output\nobtained from the previous step. The end goal of this is to verify the\nanomalies detected by the anomaly detection algorithm and clarify whether they\nare actually intrusions or random outliers from the trained normal (and thus to\ntry and reduce the number of false positives). We aim to detect a pattern in\nthis novel intrusion technique itself, and not the handling of such intrusions.\nThe intrusions were detected to a very high degree of accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 14:37:10 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 04:43:40 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Pandey", "Aditya", ""], ["Sinha", "Abhishek", ""], ["PS", "Aishwarya", ""]]}, {"id": "1910.12084", "submitter": "Alessandro Lameiras Koerich", "authors": "Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich", "title": "Detection of Adversarial Attacks and Characterization of Adversarial\n  Subspace", "comments": "Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks have always been a serious threat for any data-driven\nmodel. In this paper, we explore subspaces of adversarial examples in unitary\nvector domain, and we propose a novel detector for defending our models trained\nfor environmental sound classification. We measure chordal distance between\nlegitimate and malicious representation of sounds in unitary space of\ngeneralized Schur decomposition and show that their manifolds lie far from each\nother. Our front-end detector is a regularized logistic regression which\ndiscriminates eigenvalues of legitimate and adversarial spectrograms. The\nexperimental results on three benchmarking datasets of environmental sounds\nrepresented by spectrograms reveal high detection rate of the proposed detector\nfor eight types of adversarial attacks and outperforms other detection\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 15:14:51 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Esmaeilpour", "Mohammad", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "1910.12086", "submitter": "Miguel A. Roman", "authors": "Miguel A. Rom\\'an, Antonio Pertusa, Jorge Calvo-Zaragoza", "title": "A holistic approach to polyphonic music transcription with neural\n  networks", "comments": "Source code available at https://github.com/mangelroman/audio2score", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a framework based on neural networks to extract music scores\ndirectly from polyphonic audio in an end-to-end fashion. Most previous\nAutomatic Music Transcription (AMT) methods seek a piano-roll representation of\nthe pitches, that can be further transformed into a score by incorporating\ntempo estimation, beat tracking, key estimation or rhythm quantization. Unlike\nthese methods, our approach generates music notation directly from the input\naudio in a single stage. For this, we use a Convolutional Recurrent Neural\nNetwork (CRNN) with Connectionist Temporal Classification (CTC) loss function\nwhich does not require annotated alignments of audio frames with the score\nrhythmic information. We trained our model using as input Haydn, Mozart, and\nBeethoven string quartets and Bach chorales synthesized with different tempos\nand expressive performances. The output is a textual representation of\nfour-voice music scores based on **kern format. Although the proposed approach\nis evaluated in a simplified scenario, results show that this model can learn\nto transcribe scores directly from audio signals, opening a promising avenue\ntowards complete AMT.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 15:19:11 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Rom\u00e1n", "Miguel A.", ""], ["Pertusa", "Antonio", ""], ["Calvo-Zaragoza", "Jorge", ""]]}, {"id": "1910.12091", "submitter": "Evgeny Burnaev", "authors": "Sergei Ivanov and Sergei Sviridov and Evgeny Burnaev", "title": "Understanding Isomorphism Bias in Graph Data Sets", "comments": "19 pages, 5 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a rapid increase in classification methods on\ngraph structured data. Both in graph kernels and graph neural networks, one of\nthe implicit assumptions of successful state-of-the-art models was that\nincorporating graph isomorphism features into the architecture leads to better\nempirical performance. However, as we discover in this work, commonly used data\nsets for graph classification have repeating instances which cause the problem\nof isomorphism bias, i.e. artificially increasing the accuracy of the models by\nmemorizing target information from the training set. This prevents fair\ncompetition of the algorithms and raises a question of the validity of the\nobtained results. We analyze 54 data sets, previously extensively used for\ngraph-related tasks, on the existence of isomorphism bias, give a set of\nrecommendations to machine learning practitioners to properly set up their\nmodels, and open source new data sets for the future experiments.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 15:52:42 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 16:14:17 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Ivanov", "Sergei", ""], ["Sviridov", "Sergei", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1910.12132", "submitter": "Florence Regol", "authors": "Soumyasundar Pal, Florence Regol, Mark Coates", "title": "Bayesian Graph Convolutional Neural Networks Using Non-Parametric Graph\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCNN) have been successfully applied to\nmany different graph based learning tasks including node and graph\nclassification, matrix completion, and learning of node embeddings. Despite\ntheir impressive performance, the techniques have a limited capability to\nincorporate the uncertainty in the underlined graph structure. In order to\naddress this issue, a Bayesian GCNN (BGCN) framework was recently proposed. In\nthis framework, the observed graph is considered to be a random realization\nfrom a parametric random graph model and the joint Bayesian inference of the\ngraph and GCNN weights is performed. In this paper, we propose a non-parametric\ngenerative model for graphs and incorporate it within the BGCN framework. In\naddition to the observed graph, our approach effectively uses the node features\nand training labels in the posterior inference of graphs and attains superior\nor comparable performance in benchmark node classification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 20:27:16 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Pal", "Soumyasundar", ""], ["Regol", "Florence", ""], ["Coates", "Mark", ""]]}, {"id": "1910.12134", "submitter": "Shengyi Huang", "authors": "Shengyi Huang, Santiago Onta\\~n\\'on", "title": "Comparing Observation and Action Representations for Deep Reinforcement\n  Learning in $\\mu$RTS", "comments": "Presented in the AIIDE 2019 Workshop on Artificial Intelligence for\n  Strategy Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a preliminary study comparing different observation and\naction space representations for Deep Reinforcement Learning (DRL) in the\ncontext of Real-time Strategy (RTS) games. Specifically, we compare two\nrepresentations: (1) a global representation where the observation represents\nthe whole game state, and the RL agent needs to choose which unit to issue\nactions to, and which actions to execute; and (2) a local representation where\nthe observation is represented from the point of view of an individual unit,\nand the RL agent picks actions for each unit independently. We evaluate these\nrepresentations in $\\mu$RTS showing that the local representation seems to\noutperform the global representation when training agents with the task of\nharvesting resources.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 20:30:36 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 03:03:22 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 22:43:13 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Huang", "Shengyi", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "1910.12143", "submitter": "Ayon Biswas", "authors": "Ayon Biswas, Jess McIver and Ashish Mahabal", "title": "New methods to assess and improve LIGO detector duty cycle", "comments": null, "journal-ref": "Classical and Quantum Gravity (2020), 37(17), p.175008", "doi": "10.1088/1361-6382/ab8650", "report-no": null, "categories": "astro-ph.IM cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A network of three or more gravitational wave detectors simultaneously taking\ndata is required to generate a well-localized sky map for gravitational wave\nsources, such as GW170817. Local seismic disturbances often cause the LIGO and\nVirgo detectors to lose light resonance in one or more of their component optic\ncavities, and the affected detector is unable to take data until resonance is\nrecovered. In this paper, we use machine learning techniques to gain insight\ninto the predictive behavior of the LIGO detector optic cavities during the\nsecond LIGO-Virgo observing run. We identify a minimal set of optic cavity\ncontrol signals and data features which capture interferometer behavior leading\nto a loss of light resonance, or lockloss. We use these channels to accurately\ndistinguish between lockloss events and quiet interferometer operating times\nvia both supervised and unsupervised machine learning methods. This analysis\nyields new insights into how components of the LIGO detectors contribute to\nlockloss events, which could inform detector commissioning efforts to mitigate\nthe associated loss of uptime. Particularly, we find that the state of the\ncomponent optical cavities is a better predictor of loss of lock than ground\nmotion trends. We report prediction accuracies of 98% for times just prior to\nlock loss, and 90% for times up to 30 seconds prior to lockloss, which shows\npromise for this method to be applied in near-real time to trigger preventative\ndetector state changes. This method can be extended to target other auxiliary\nsubsystems or times of interest, such as transient noise or loss in detector\nsensitivity. Application of these techniques during the third LIGO-Virgo\nobserving run and beyond would maximize the potential of the global detector\nnetwork for multi-messenger astronomy with gravitational waves.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 20:55:56 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 00:30:36 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Biswas", "Ayon", ""], ["McIver", "Jess", ""], ["Mahabal", "Ashish", ""]]}, {"id": "1910.12154", "submitter": "Daniel Seita", "authors": "Daniel Seita, David Chan, Roshan Rao, Chen Tang, Mandi Zhao, John\n  Canny", "title": "ZPD Teaching Strategies for Deep Reinforcement Learning from\n  Demonstrations", "comments": "Deep Reinforcement Learning Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstrations is a popular tool for accelerating and reducing\nthe exploration requirements of reinforcement learning. When providing expert\ndemonstrations to human students, we know that the demonstrations must fall\nwithin a particular range of difficulties called the \"Zone of Proximal\nDevelopment (ZPD)\". If they are too easy the student learns nothing, but if\nthey are too difficult the student is unable to follow along. This raises the\nquestion: Given a set of potential demonstrators, which among them is best\nsuited for teaching any particular learner? Prior work, such as the popular\nDeep Q-learning from Demonstrations (DQfD) algorithm has generally focused on\nsingle demonstrators. In this work we consider the problem of choosing among\nmultiple demonstrators of varying skill levels. Our results align with\nintuition from human learners: it is not always the best policy to draw\ndemonstrations from the best performing demonstrator (in terms of reward). We\nshow that careful selection of teaching strategies can result in sample\nefficiency gains in the learner's environment across nine Atari games\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 23:05:43 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Seita", "Daniel", ""], ["Chan", "David", ""], ["Rao", "Roshan", ""], ["Tang", "Chen", ""], ["Zhao", "Mandi", ""], ["Canny", "John", ""]]}, {"id": "1910.12156", "submitter": "Ming Yu", "authors": "Ming Yu, Zhuoran Yang, Mladen Kolar, Zhaoran Wang", "title": "Convergent Policy Optimization for Safe Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the safe reinforcement learning problem with nonlinear function\napproximation, where policy optimization is formulated as a constrained\noptimization problem with both the objective and the constraint being nonconvex\nfunctions. For such a problem, we construct a sequence of surrogate convex\nconstrained optimization problems by replacing the nonconvex functions locally\nwith convex quadratic functions obtained from policy gradient estimators. We\nprove that the solutions to these surrogate problems converge to a stationary\npoint of the original nonconvex problem. Furthermore, to extend our theoretical\nresults, we apply our algorithm to examples of optimal control and multi-agent\nreinforcement learning with safety constraints.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 23:40:46 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Yu", "Ming", ""], ["Yang", "Zhuoran", ""], ["Kolar", "Mladen", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1910.12159", "submitter": "Mahdieh Shabanian", "authors": "Mahdieh Shabanian, Eugene C. Eckstein, Hao Chen, John P. DeVincenzo", "title": "Classification of Neurodevelopmental Age in Normal Infants Using 3D-CNN\n  based on Brain MRI", "comments": "6 pages, 11 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human brain development is rapid during infancy and early childhood. Many\ndisease processes impair this development. Therefore, brain developmental age\nestimation (BDAE) is essential for all diseases affecting cognitive\ndevelopment. Brain magnetic resonance imaging (MRI) of infants shows brain\ngrowth and morphologic patterns during childhood. Therefore, we can estimate\nthe developmental age from brain images. However, MRI analysis is\ntime-consuming because each scan contains millions of data points (voxels). We\ninvestigated the three-dimensional convolutional neural network (3D CNN), a\ndeep learning algorithm, to rapidly classify neurodevelopmental age with high\naccuracy based on MRIs. MRIs from normal newborns were obtained from the\nNational Institute of Mental Health (NIMH) Data Archive. Age categories of\npediatric MRIs were 3 wks + 1 wk, 1 yr + 2 wks, and 3 yrs + 4 wks. We trained a\nBDAE method using T1, T2, and proton density (PD) images from MRI scans of 112\nindividuals using 3D CNN. Compared with the known age, our method has a\nsensitivity of 99% and specificity of 98.3%. Moreover, our 3D CNN model has\nbetter performance in neurodevelopmental age estimation than does 2D CNN.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 00:08:55 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 01:26:19 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shabanian", "Mahdieh", ""], ["Eckstein", "Eugene C.", ""], ["Chen", "Hao", ""], ["DeVincenzo", "John P.", ""]]}, {"id": "1910.12162", "submitter": "Jong Chul Ye", "authors": "Mathews Jacob, Merry P. Mani, and Jong Chul Ye", "title": "Structured Low-Rank Algorithms: Theory, MR Applications, and Links to\n  Machine Learning", "comments": "Accepted for IEEE Signal Processing Magazine", "journal-ref": null, "doi": "10.1109/MSP.2019.2950432", "report-no": null, "categories": "cs.CV cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey, we provide a detailed review of recent advances in the\nrecovery of continuous domain multidimensional signals from their few\nnon-uniform (multichannel) measurements using structured low-rank matrix\ncompletion formulation. This framework is centered on the fundamental duality\nbetween the compactness (e.g., sparsity) of the continuous signal and the rank\nof a structured matrix, whose entries are functions of the signal. This\nproperty enables the reformulation of the signal recovery as a low-rank\nstructured matrix completion, which comes with performance guarantees. We will\nalso review fast algorithms that are comparable in complexity to current\ncompressed sensing methods, which enables the application of the framework to\nlarge-scale magnetic resonance (MR) recovery problems. The remarkable\nflexibility of the formulation can be used to exploit signal properties that\nare difficult to capture by current sparse and low-rank optimization\nstrategies. We demonstrate the utility of the framework in a wide range of MR\nimaging (MRI) applications, including highly accelerated imaging,\ncalibration-free acquisition, MR artifact correction, and ungated dynamic MRI.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 01:46:02 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Jacob", "Mathews", ""], ["Mani", "Merry P.", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1910.12163", "submitter": "Xupeng Shi", "authors": "Xupeng Shi, A. Adam Ding", "title": "Understanding and Quantifying Adversarial Examples Existence in Linear\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-art deep neural networks (DNN) are vulnerable to attacks by\nadversarial examples: a carefully designed small perturbation to the input,\nthat is imperceptible to human, can mislead DNN. To understand the root cause\nof adversarial examples, we quantify the probability of adversarial example\nexistence for linear classifiers. Previous mathematical definition of\nadversarial examples only involves the overall perturbation amount, and we\npropose a more practical relevant definition of strong adversarial examples\nthat separately limits the perturbation along the signal direction also. We\nshow that linear classifiers can be made robust to strong adversarial examples\nattack in cases where no adversarial robust linear classifiers exist under the\nprevious definition. The quantitative formulas are confirmed by numerical\nexperiments using a linear support vector machine (SVM) classifier. The results\nsuggest that designing general strong-adversarial-robust learning systems is\nfeasible but only through incorporating human knowledge of the underlying\nclassification problem.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 01:57:16 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Shi", "Xupeng", ""], ["Ding", "A. Adam", ""]]}, {"id": "1910.12164", "submitter": "Shu-Qian Shen", "authors": "Jin-Min Liang, Shu-Qian Shen, Ming Li, Lei Li", "title": "Variational Quantum Algorithms for Dimensionality Reduction and\n  Classification", "comments": "Some modifications have been made", "journal-ref": "Phys. Rev. A 101, 032323 (2020)", "doi": "10.1103/PhysRevA.101.032323", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a quantum neighborhood preserving embedding and a\nquantum local discriminant embedding for dimensionality reduction and\nclassification. We demonstrate that these two algorithms have an exponential\nspeedup over their respectively classical counterparts. Along the way, we\npropose a variational quantum generalized eigenvalue solver that finds the\ngeneralized eigenvalues and eigenstates of a matrix pencil\n$(\\mathcal{G},\\mathcal{S})$. As a proof-of-principle, we implement our\nalgorithm to solve $2^5\\times2^5$ generalized eigenvalue problems. Finally, our\nresults offer two optional outputs with quantum or classical form, which can be\ndirectly applied in another quantum or classical machine learning process.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 02:08:19 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 03:17:27 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Liang", "Jin-Min", ""], ["Shen", "Shu-Qian", ""], ["Li", "Ming", ""], ["Li", "Lei", ""]]}, {"id": "1910.12165", "submitter": "Yiming Li", "authors": "Jia Xu, Yiming Li, Yong Jiang, Shu-Tao Xia", "title": "Adversarial Defense via Local Flatness Regularization", "comments": "Accepted by the ICIP 2020. The first two authors contributed equally\n  to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial defense is a popular and important research area. Due to its\nintrinsic mechanism, one of the most straightforward and effective ways of\ndefending attacks is to analyze the property of loss surface in the input\nspace. In this paper, we define the local flatness of the loss surface as the\nmaximum value of the chosen norm of the gradient regarding to the input within\na neighborhood centered on the benign sample, and discuss the relationship\nbetween the local flatness and adversarial vulnerability. Based on the\nanalysis, we propose a novel defense approach via regularizing the local\nflatness, dubbed local flatness regularization (LFR). We also demonstrate the\neffectiveness of the proposed method from other perspectives, such as human\nvisual mechanism, and analyze the relationship between LFR and other related\nmethods theoretically. Experiments are conducted to verify our theory and\ndemonstrate the superiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 02:12:20 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 06:53:06 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 11:49:26 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 07:19:03 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Xu", "Jia", ""], ["Li", "Yiming", ""], ["Jiang", "Yong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "1910.12166", "submitter": "Kaiyi Ji", "authors": "Kaiyi Ji, Zhe Wang, Yi Zhou and Yingbin Liang", "title": "Improved Zeroth-Order Variance Reduced Algorithms and Analysis for\n  Nonconvex Optimization", "comments": "Published in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two types of zeroth-order stochastic algorithms have recently been designed\nfor nonconvex optimization respectively based on the first-order techniques\nSVRG and SARAH/SPIDER. This paper addresses several important issues that are\nstill open in these methods. First, all existing SVRG-type zeroth-order\nalgorithms suffer from worse function query complexities than either\nzeroth-order gradient descent (ZO-GD) or stochastic gradient descent (ZO-SGD).\nIn this paper, we propose a new algorithm ZO-SVRG-Coord-Rand and develop a new\nanalysis for an existing ZO-SVRG-Coord algorithm proposed in Liu et al. 2018b,\nand show that both ZO-SVRG-Coord-Rand and ZO-SVRG-Coord (under our new\nanalysis) outperform other exiting SVRG-type zeroth-order methods as well as\nZO-GD and ZO-SGD. Second, the existing SPIDER-type algorithm SPIDER-SZO (Fang\net al. 2018) has superior theoretical performance, but suffers from the\ngeneration of a large number of Gaussian random variables as well as a\n$\\sqrt{\\epsilon}$-level stepsize in practice. In this paper, we develop a new\nalgorithm ZO-SPIDER-Coord, which is free from Gaussian variable generation and\nallows a large constant stepsize while maintaining the same convergence rate\nand query complexity, and we further show that ZO-SPIDER-Coord automatically\nachieves a linear convergence rate as the iterate enters into a local PL region\nwithout restart and algorithmic modification.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 02:48:03 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ji", "Kaiyi", ""], ["Wang", "Zhe", ""], ["Zhou", "Yi", ""], ["Liang", "Yingbin", ""]]}, {"id": "1910.12179", "submitter": "Che Wang", "authors": "Xinyue Chen, Zijian Zhou, Zheng Wang, Che Wang, Yanqiu Wu, Keith Ross", "title": "BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement\n  Learning", "comments": "27 pages(15 pages for appendix); Published in 34th Conference on\n  Neural Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been a surge in research in batch Deep Reinforcement\nLearning (DRL), which aims for learning a high-performing policy from a given\ndataset without additional interactions with the environment. We propose a new\nalgorithm, Best-Action Imitation Learning (BAIL), which strives for both\nsimplicity and performance. BAIL learns a V function, uses the V function to\nselect actions it believes to be high-performing, and then uses those actions\nto train a policy network using imitation learning. For the MuJoCo benchmark,\nwe provide a comprehensive experimental study of BAIL, comparing its\nperformance to four other batch Q-learning and imitation-learning schemes for a\nlarge variety of batch datasets. Our experiments show that BAIL's performance\nis much higher than the other schemes, and is also computationally much faster\nthan the batch Q-learning schemes.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 04:43:19 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 11:26:19 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 05:28:24 GMT"}, {"version": "v4", "created": "Mon, 2 Nov 2020 07:11:07 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Chen", "Xinyue", ""], ["Zhou", "Zijian", ""], ["Wang", "Zheng", ""], ["Wang", "Che", ""], ["Wu", "Yanqiu", ""], ["Ross", "Keith", ""]]}, {"id": "1910.12180", "submitter": "Saeid Hosseini", "authors": "Saeed Najafipour, Saeid Hosseini, Wen Hua, Mohammad Reza Kangavari,\n  Xiaofang Zhou", "title": "SoulMate: Short-text author linking through Multi-aspect\n  temporal-textual embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linking authors of short-text contents has important usages in many\napplications, including Named Entity Recognition (NER) and human community\ndetection. However, certain challenges lie ahead. Firstly, the input short-text\ncontents are noisy, ambiguous, and do not follow the grammatical rules.\nSecondly, traditional text mining methods fail to effectively extract concepts\nthrough words and phrases. Thirdly, the textual contents are temporally skewed,\nwhich can affect the semantic understanding by multiple time facets. Finally,\nusing the complementary knowledge-bases makes the results biased to the content\nof the external database and deviates the understanding and interpretation away\nfrom the real nature of the given short text corpus. To overcome these\nchallenges, we devise a neural network-based temporal-textual framework that\ngenerates the tightly connected author subgraphs from microblog short-text\ncontents. Our approach, on the one hand, computes the relevance score (edge\nweight) between the authors through considering a portmanteau of contents and\nconcepts, and on the other hand, employs a stack-wise graph cutting algorithm\nto extract the communities of the related authors. Experimental results show\nthat compared to other knowledge-centered competitors, our multi-aspect vector\nspace model can achieve a higher performance in linking short-text authors.\nAdditionally, given the author linking task, the more comprehensive the dataset\nis, the higher the significance of the extracted concepts will be.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 04:53:35 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Najafipour", "Saeed", ""], ["Hosseini", "Saeid", ""], ["Hua", "Wen", ""], ["Kangavari", "Mohammad Reza", ""], ["Zhou", "Xiaofang", ""]]}, {"id": "1910.12181", "submitter": "Sicheng Zhao", "authors": "Sicheng Zhao, Bo Li, Xiangyu Yue, Yang Gu, Pengfei Xu, Runbo Hu, Hua\n  Chai, Kurt Keutzer", "title": "Multi-source Domain Adaptation for Semantic Segmentation", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation-to-real domain adaptation for semantic segmentation has been\nactively studied for various applications such as autonomous driving. Existing\nmethods mainly focus on a single-source setting, which cannot easily handle a\nmore practical scenario of multiple sources with different distributions. In\nthis paper, we propose to investigate multi-source domain adaptation for\nsemantic segmentation. Specifically, we design a novel framework, termed\nMulti-source Adversarial Domain Aggregation Network (MADAN), which can be\ntrained in an end-to-end manner. First, we generate an adapted domain for each\nsource with dynamic semantic consistency while aligning at the pixel-level\ncycle-consistently towards the target. Second, we propose sub-domain\naggregation discriminator and cross-domain cycle discriminator to make\ndifferent adapted domains more closely aggregated. Finally, feature-level\nalignment is performed between the aggregated domain and target domain while\ntraining the segmentation network. Extensive experiments from synthetic GTA and\nSYNTHIA to real Cityscapes and BDDS datasets demonstrate that the proposed\nMADAN model outperforms state-of-the-art approaches. Our source code is\nreleased at: https://github.com/Luodian/MADAN.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 05:04:25 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhao", "Sicheng", ""], ["Li", "Bo", ""], ["Yue", "Xiangyu", ""], ["Gu", "Yang", ""], ["Xu", "Pengfei", ""], ["Hu", "Runbo", ""], ["Chai", "Hua", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1910.12191", "submitter": "Sabri Boughorbel", "authors": "Sabri Boughorbel, Fethi Jarray, Neethu Venugopal, Shabir Moosa,\n  Haithum Elhadi, Michel Makhlouf", "title": "Federated Uncertainty-Aware Learning for Distributed Hospital EHR Data", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that applying Machine Learning to Electronic Health\nRecords (EHR) can strongly accelerate precision medicine. This requires\ndeveloping models based on diverse EHR sources. Federated Learning (FL) has\nenabled predictive modeling using distributed training which lifted the need of\nsharing data and compromising privacy. Since models are distributed in FL, it\nis attractive to devise ensembles of Deep Neural Networks that also assess\nmodel uncertainty. We propose a new FL model called Federated Uncertainty-Aware\nLearning Algorithm (FUALA) that improves on Federated Averaging (FedAvg) in the\ncontext of EHR. FUALA embeds uncertainty information in two ways: It reduces\nthe contribution of models with high uncertainty in the aggregated model. It\nalso introduces model ensembling at prediction time by keeping the last layers\nof each hospital from the final round. In FUALA, the Federator (central node)\nsends at each round the average model to all hospitals as well as a randomly\nassigned hospital model update to estimate its generalization on that hospital\nown data. Each hospital sends back its model update as well a generalization\nestimation of the assigned model. At prediction time, the model outputs C\npredictions for each sample where C is the number of hospital models. The\nexperimental analysis conducted on a cohort of 87K deliveries for the task of\npreterm-birth prediction showed that the proposed approach outperforms FedAvg\nwhen evaluated on out-of-distribution data. We illustrated how uncertainty\ncould be measured using the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 06:33:34 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Boughorbel", "Sabri", ""], ["Jarray", "Fethi", ""], ["Venugopal", "Neethu", ""], ["Moosa", "Shabir", ""], ["Elhadi", "Haithum", ""], ["Makhlouf", "Michel", ""]]}, {"id": "1910.12194", "submitter": "Rita Fioresi", "authors": "R. Fioresi, P. Chaudhari, S. Soatto", "title": "A geometric interpretation of stochastic gradient descent using\n  diffusion metrics", "comments": null, "journal-ref": null, "doi": "10.3390/e22010101", "report-no": null, "categories": "cs.LG gr-qc math.DG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is a key ingredient in the training of deep\nneural networks and yet its geometrical significance appears elusive. We study\na deterministic model in which the trajectories of our dynamical systems are\ndescribed via geodesics of a family of metrics arising from the diffusion\nmatrix. These metrics encode information about the highly non-isotropic\ngradient noise in SGD. We establish a parallel with General Relativity models,\nwhere the role of the electromagnetic field is played by the gradient of the\nloss function. We compute an example of a two layer network.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 06:47:16 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Fioresi", "R.", ""], ["Chaudhari", "P.", ""], ["Soatto", "S.", ""]]}, {"id": "1910.12196", "submitter": "Fanchao Qi", "authors": "Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang, Qun\n  Liu, Maosong Sun", "title": "Word-level Textual Adversarial Attacking as Combinatorial Optimization", "comments": "Accepted at ACL 2020 as a long paper (a typo is corrected as compared\n  with the official conference camera-ready version). 16 pages, 3 figures", "journal-ref": null, "doi": "10.18653/v1/2020.acl-main.540", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks are carried out to reveal the vulnerability of deep\nneural networks. Textual adversarial attacking is challenging because text is\ndiscrete and a small perturbation can bring significant change to the original\ninput. Word-level attacking, which can be regarded as a combinatorial\noptimization problem, is a well-studied class of textual attack methods.\nHowever, existing word-level attack models are far from perfect, largely\nbecause unsuitable search space reduction methods and inefficient optimization\nalgorithms are employed. In this paper, we propose a novel attack model, which\nincorporates the sememe-based word substitution method and particle swarm\noptimization-based search algorithm to solve the two problems separately. We\nconduct exhaustive experiments to evaluate our attack model by attacking BiLSTM\nand BERT on three benchmark datasets. Experimental results demonstrate that our\nmodel consistently achieves much higher attack success rates and crafts more\nhigh-quality adversarial examples as compared to baseline methods. Also,\nfurther experiments show our model has higher transferability and can bring\nmore robustness enhancement to victim models by adversarial training. All the\ncode and data of this paper can be obtained on\nhttps://github.com/thunlp/SememePSO-Attack.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 06:54:27 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 11:20:10 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 09:54:31 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 09:38:21 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Zang", "Yuan", ""], ["Qi", "Fanchao", ""], ["Yang", "Chenghao", ""], ["Liu", "Zhiyuan", ""], ["Zhang", "Meng", ""], ["Liu", "Qun", ""], ["Sun", "Maosong", ""]]}, {"id": "1910.12197", "submitter": "Forough Arabshahi", "authors": "Zhichu Lu, Forough Arabshahi, Igor Labutov, Tom Mitchell", "title": "Look-up and Adapt: A One-shot Semantic Parser", "comments": "2019 Conference on Empirical Methods in Natural Language Processing\n  (EMNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing devices have recently become capable of interacting with their end\nusers via natural language. However, they can only operate within a limited\n\"supported\" domain of discourse and fail drastically when faced with an\nout-of-domain utterance, mainly due to the limitations of their semantic\nparser. In this paper, we propose a semantic parser that generalizes to\nout-of-domain examples by learning a general strategy for parsing an unseen\nutterance through adapting the logical forms of seen utterances, instead of\nlearning to generate a logical form from scratch. Our parser maintains a memory\nconsisting of a representative subset of the seen utterances paired with their\nlogical forms. Given an unseen utterance, our parser works by looking up a\nsimilar utterance from the memory and adapting its logical form until it fits\nthe unseen utterance. Moreover, we present a data generation strategy for\nconstructing utterance-logical form pairs from different domains. Our results\nshow an improvement of up to 68.8% on one-shot parsing under two different\nevaluation settings compared to the baselines.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 06:56:43 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Lu", "Zhichu", ""], ["Arabshahi", "Forough", ""], ["Labutov", "Igor", ""], ["Mitchell", "Tom", ""]]}, {"id": "1910.12203", "submitter": "Vaibhav Vaibhav", "authors": "Vaibhav Vaibhav, Raghuram Mandyam Annasamy, Eduard Hovy", "title": "Do Sentence Interactions Matter? Leveraging Sentence Level\n  Representations for Fake News Classification", "comments": "Accepted at TextGraphs - EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rising growth of fake news and misleading information through online\nmedia outlets demands an automatic method for detecting such news articles. Of\nthe few limited works which differentiate between trusted vs other types of\nnews article (satire, propaganda, hoax), none of them model sentence\ninteractions within a document. We observe an interesting pattern in the way\nsentences interact with each other across different kind of news articles. To\ncapture this kind of information for long news articles, we propose a graph\nneural network-based model which does away with the need of feature engineering\nfor fine grained fake news classification. Through experiments, we show that\nour proposed method beats strong neural baselines and achieves state-of-the-art\naccuracy on existing datasets. Moreover, we establish the generalizability of\nour model by evaluating its performance in out-of-domain scenarios. Code is\navailable at https://github.com/MysteryVaibhav/fake_news_semantics\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 07:44:33 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Vaibhav", "Vaibhav", ""], ["Annasamy", "Raghuram Mandyam", ""], ["Hovy", "Eduard", ""]]}, {"id": "1910.12204", "submitter": "Yotam Gigi", "authors": "Yotam Gigi, Ami Wiesel, Sella Nevo, Gal Elidan, Avinatan Hassidim,\n  Yossi Matias", "title": "Spectral Algorithm for Low-rank Multitask Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning, i.e. taking advantage of the relatedness of individual\ntasks in order to improve performance on all of them, is a core challenge in\nthe field of machine learning. We focus on matrix regression tasks where the\nrank of the weight matrix is constrained to reduce sample complexity. We\nintroduce the common mechanism regression (CMR) model which assumes a shared\nleft low-rank component across all tasks, but allows an individual per-task\nright low-rank component. This dramatically reduces the number of samples\nneeded for accurate estimation. The problem of jointly recovering the common\nand the local components has a non-convex bi-linear structure. We overcome this\nhurdle and provide a provably beneficial non-iterative spectral algorithm.\nAppealingly, the solution has favorable behavior as a function of the number of\nrelated tasks and the small number of samples available for each one. We\ndemonstrate the efficacy of our approach for the challenging task of remote\nriver discharge estimation across multiple river sites, where data for each\ntask is naturally scarce. In this scenario sharing a low-rank component between\nthe tasks translates to a shared spectral reflection of the water, which is a\ntrue underlying physical model. We also show the benefit of the approach on the\nmarkedly different setting of image classification where the common component\ncan be interpreted as the shared convolution filters.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 08:00:17 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Gigi", "Yotam", ""], ["Wiesel", "Ami", ""], ["Nevo", "Sella", ""], ["Elidan", "Gal", ""], ["Hassidim", "Avinatan", ""], ["Matias", "Yossi", ""]]}, {"id": "1910.12207", "submitter": "Jialin Lu", "authors": "Jialin Lu, Martin Ester", "title": "An Active Approach for Model Interpretation", "comments": "NeurIPS 2019 workshop on Human-Centric Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model interpretation, or explanation of a machine learning classifier, aims\nto extract generalizable knowledge from a trained classifier into a\nhuman-understandable format, for various purposes such as model assessment,\ndebugging and trust. From a computaional viewpoint, it is formulated as\napproximating the target classifier using a simpler interpretable model, such\nas rule models like a decision set/list/tree. Often, this approximation is\nhandled as standard supervised learning and the only difference is that the\nlabels are provided by the target classifier instead of ground truth. This\nparadigm is particularly popular because there exists a variety of well-studied\nsupervised algorithms for learning an interpretable classifier. However, we\nargue that this paradigm is suboptimal for it does not utilize the unique\nproperty of the model interpretation problem, that is, the ability to generate\nsynthetic instances and query the target classifier for their labels. We call\nthis the active-query property, suggesting that we should consider model\ninterpretation from an active learning perspective. Following this insight, we\nargue that the active-query property should be employed when designing a model\ninterpretation algorithm, and that the generation of synthetic instances should\nbe integrated seamlessly with the algorithm that learns the model\ninterpretation. In this paper, we demonstrate that by doing so, it is possible\nto achieve more faithful interpretation with simpler model complexity. As a\ntechnical contribution, we present an active algorithm Active Decision Set\nInduction (ADS) to learn a decision set, a set of if-else rules, for model\ninterpretation. ADS performs a local search over the space of all decision\nsets. In every iteration, ADS computes confidence intervals for the value of\nthe objective function of all local actions and utilizes active-query to\ndetermine the best one.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 08:37:38 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Lu", "Jialin", ""], ["Ester", "Martin", ""]]}, {"id": "1910.12223", "submitter": "Jing Zhang", "authors": "Jing Zhang and Zhe Chen and Dacheng Tao", "title": "Human Keypoint Detection by Progressive Context Refinement", "comments": "Technical Report for \"Joint COCO and MapillaryWorkshop at ICCV 2019:\n  COCO Keypoint Detection Challenge Track\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human keypoint detection from a single image is very challenging due to\nocclusion, blur, illumination and scale variance of person instances. In this\npaper, we find that context information plays an important role in addressing\nthese issues, and propose a novel method named progressive context refinement\n(PCR) for human keypoint detection. First, we devise a simple but effective\ncontext-aware module (CAM) that can efficiently integrate spatial and channel\ncontext information to aid feature learning for locating hard keypoints. Then,\nwe construct the PCR model by stacking several CAMs sequentially with shortcuts\nand employ multi-task learning to progressively refine the context information\nand predictions. Besides, to maximize PCR's potential for the aforementioned\nhard case inference, we propose a hard-negative person detection mining\nstrategy together with a joint-training strategy by exploiting the unlabeled\ncoco dataset and external dataset. Extensive experiments on the COCO keypoint\ndetection benchmark demonstrate the superiority of PCR over representative\nstate-of-the-art (SOTA) methods. Our single model achieves comparable\nperformance with the winner of the 2018 COCO Keypoint Detection Challenge. The\nfinal ensemble model sets a new SOTA on this benchmark.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 09:57:08 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhang", "Jing", ""], ["Chen", "Zhe", ""], ["Tao", "Dacheng", ""]]}, {"id": "1910.12227", "submitter": "Ali Shahin Shamsabadi", "authors": "Ali Shahin Shamsabadi, Changjae Oh, Andrea Cavallaro", "title": "EdgeFool: An Adversarial Image Enhancement Filter", "comments": null, "journal-ref": "Proceedings of the 45th IEEE International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP)2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are intentionally perturbed images that mislead\nclassifiers. These images can, however, be easily detected using denoising\nalgorithms, when high-frequency spatial perturbations are used, or can be\nnoticed by humans, when perturbations are large. In this paper, we propose\nEdgeFool, an adversarial image enhancement filter that learns structure-aware\nadversarial perturbations. EdgeFool generates adversarial images with\nperturbations that enhance image details via training a fully convolutional\nneural network end-to-end with a multi-task loss function. This loss function\naccounts for both image detail enhancement and class misleading objectives. We\nevaluate EdgeFool on three classifiers (ResNet-50, ResNet-18 and AlexNet) using\ntwo datasets (ImageNet and Private-Places365) and compare it with six\nadversarial methods (DeepFool, SparseFool, Carlini-Wagner, SemanticAdv,\nNon-targeted and Private Fast Gradient Sign Methods). Code is available at\nhttps://github.com/smartcameras/EdgeFool.git.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 10:16:26 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 10:08:19 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Shamsabadi", "Ali Shahin", ""], ["Oh", "Changjae", ""], ["Cavallaro", "Andrea", ""]]}, {"id": "1910.12232", "submitter": "Guy Jacob", "authors": "Neta Zmora, Guy Jacob, Lev Zlotnik, Bar Elharar, Gal Novik", "title": "Neural Network Distiller: A Python Package For DNN Compression Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper presents the philosophy, design and feature-set of Neural Network\nDistiller, an open-source Python package for DNN compression research.\nDistiller is a library of DNN compression algorithms implementations, with\ntools, tutorials and sample applications for various learning tasks. Its target\nusers are both engineers and researchers, and the rich content is complemented\nby a design-for-extensibility to facilitate new research. Distiller is\nopen-source and is available on Github at\nhttps://github.com/NervanaSystems/distiller.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 10:42:15 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zmora", "Neta", ""], ["Jacob", "Guy", ""], ["Zlotnik", "Lev", ""], ["Elharar", "Bar", ""], ["Novik", "Gal", ""]]}, {"id": "1910.12240", "submitter": "Yue Wang", "authors": "Yue Wang and Justin M. Solomon", "title": "PRNet: Self-Supervised Learning for Partial-to-Partial Registration", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present a simple, flexible, and general framework titled Partial\nRegistration Network (PRNet), for partial-to-partial point cloud registration.\nInspired by recently-proposed learning-based methods for registration, we use\ndeep networks to tackle non-convexity of the alignment and partial\ncorrespondence problems. While previous learning-based methods assume the\nentire shape is visible, PRNet is suitable for partial-to-partial registration,\noutperforming PointNetLK, DCP, and non-learning methods on synthetic data.\nPRNet is self-supervised, jointly learning an appropriate geometric\nrepresentation, a keypoint detector that finds points in common between partial\nviews, and keypoint-to-keypoint correspondences. We show PRNet predicts\nkeypoints and correspondences consistently across views and objects.\nFurthermore, the learned representation is transferable to classification.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 11:26:16 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 15:58:14 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Wang", "Yue", ""], ["Solomon", "Justin M.", ""]]}, {"id": "1910.12241", "submitter": "Danhao Zhu", "authors": "Danhao Zhu, Xin-yu Dai, Jiajun Chen", "title": "Pre-train and Learn: Preserve Global Information for Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have shown great power in learning on attributed\ngraphs. However, it is still a challenge for GNNs to utilize information\nfaraway from the source node. Moreover, general GNNs require graph attributes\nas input, so they cannot be appled to plain graphs. In the paper, we propose\nnew models named G-GNNs (Global information for GNNs) to address the above\nlimitations. First, the global structure and attribute features for each node\nare obtained via unsupervised pre-training, which preserve the global\ninformation associated to the node. Then, using the global features and the raw\nnetwork attributes, we propose a parallel framework of GNNs to learn different\naspects from these features. The proposed learning methods can be applied to\nboth plain graphs and attributed graphs. Extensive experiments have shown that\nG-GNNs can outperform other state-of-the-art models on three standard\nevaluation graphs. Specially, our methods establish new benchmark records on\nCora (84.31\\%) and Pubmed (80.95\\%) when learning on attributed graphs.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 11:27:14 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhu", "Danhao", ""], ["Dai", "Xin-yu", ""], ["Chen", "Jiajun", ""]]}, {"id": "1910.12243", "submitter": "Zhengxuan Ling", "authors": "Zhengxuan Ling, Xinyu Tao, Yu Zhang, Xi Chen", "title": "Solving Optimization Problems through Fully Convolutional Networks: an\n  Application to the Travelling Salesman Problem", "comments": "25pages,7figures,research article", "journal-ref": null, "doi": "10.1186/s11671-018-2831-8", "report-no": null, "categories": "cs.LG cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the new wave of artificial intelligence, deep learning is impacting\nvarious industries. As a closely related area, optimization algorithms greatly\ncontribute to the development of deep learning. But the reverse applications\nare still insufficient. Is there any efficient way to solve certain\noptimization problem through deep learning? The key is to convert the\noptimization to a representation suitable for deep learning. In this paper, a\ntraveling salesman problem (TSP) is studied. Considering that deep learning is\ngood at image processing, an image representation method is proposed to\ntransfer a TSP to an image. Based on samples of a 10 city TSP, a fully\nconvolutional network (FCN) is used to learn the mapping from a feasible region\nto an optimal solution. The training process is analyzed and interpreted\nthrough stages. A visualization method is presented to show how a FCN can\nunderstand the training task of a TSP. Once the training is completed, no\nsignificant effort is required to solve a new TSP and the prediction is\nobtained on the scale of milliseconds. The results show good performance in\nfinding the global optimal solution. Moreover, the developed FCN model has been\ndemonstrated on TSP's with different city numbers, proving excellent\ngeneralization performance.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 11:32:39 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Ling", "Zhengxuan", ""], ["Tao", "Xinyu", ""], ["Zhang", "Yu", ""], ["Chen", "Xi", ""]]}, {"id": "1910.12249", "submitter": "Jianbang Ding", "authors": "Jianbang Ding, Xuancheng Ren, Ruixuan Luo, Xu Sun", "title": "An Adaptive and Momental Bound Method for Stochastic Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks requires intricate initialization and careful\nselection of learning rates. The emergence of stochastic gradient optimization\nmethods that use adaptive learning rates based on squared past gradients, e.g.,\nAdaGrad, AdaDelta, and Adam, eases the job slightly. However, such methods have\nalso been proven problematic in recent studies with their own pitfalls\nincluding non-convergence issues and so on. Alternative variants have been\nproposed for enhancement, such as AMSGrad, AdaShift and AdaBound. In this work,\nwe identify a new problem of adaptive learning rate methods that exhibits at\nthe beginning of learning where Adam produces extremely large learning rates\nthat inhibit the start of learning. We propose the Adaptive and Momental Bound\n(AdaMod) method to restrict the adaptive learning rates with adaptive and\nmomental upper bounds. The dynamic learning rate bounds are based on the\nexponential moving averages of the adaptive learning rates themselves, which\nsmooth out unexpected large learning rates and stabilize the training of deep\nneural networks. Our experiments verify that AdaMod eliminates the extremely\nlarge learning rates throughout the training and brings significant\nimprovements especially on complex networks such as DenseNet and Transformer,\ncompared to Adam. Our implementation is available at:\nhttps://github.com/lancopku/AdaMod\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 12:22:08 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ding", "Jianbang", ""], ["Ren", "Xuancheng", ""], ["Luo", "Ruixuan", ""], ["Sun", "Xu", ""]]}, {"id": "1910.12252", "submitter": "Jen Ning Lim", "authors": "Jen Ning Lim, Makoto Yamada, Bernhard Sch\\\"olkopf, Wittawat Jitkrittum", "title": "Kernel Stein Tests for Multiple Model Comparison", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of non-parametric multiple model comparison: given $l$\ncandidate models, decide whether each candidate is as good as the best one(s)\nor worse than it. We propose two statistical tests, each controlling a\ndifferent notion of decision errors. The first test, building on the post\nselection inference framework, provably controls the number of best models that\nare wrongly declared worse (false positive rate). The second test is based on\nmultiple correction, and controls the proportion of the models declared worse\nbut are in fact as good as the best (false discovery rate). We prove that under\nappropriate conditions the first test can yield a higher true positive rate\nthan the second. Experimental results on toy and real (CelebA, Chicago Crime\ndata) problems show that the two tests have high true positive rates with\nwell-controlled error rates. By contrast, the naive approach of choosing the\nmodel with the lowest score without correction leads to more false positives.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 12:45:03 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Lim", "Jen Ning", ""], ["Yamada", "Makoto", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Jitkrittum", "Wittawat", ""]]}, {"id": "1910.12258", "submitter": "Rodrigo de Lamare", "authors": "Q. Jiang, S. Li, Z. Zhu, H. Bai, X. He and R. C. de Lamare", "title": "Compressed Sensing with Probability-based Prior Information", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the design of a sensing matrix along with a sparse\nrecovery algorithm by utilizing the probability-based prior information for\ncompressed sensing system. With the knowledge of the probability for each atom\nof the dictionary being used, a diagonal weighted matrix is obtained and then\nthe sensing matrix is designed by minimizing a weighted function such that the\nGram of the equivalent dictionary is as close to the Gram of dictionary as\npossible. An analytical solution for the corresponding sensing matrix is\nderived which leads to low computational complexity. We also exploit this prior\ninformation through the sparse recovery stage and propose a probability-driven\northogonal matching pursuit algorithm that improves the accuracy of the\nrecovery. Simulations for synthetic data and application scenarios of\nsurveillance video are carried out to compare the performance of the proposed\nmethods with some existing algorithms. The results reveal that the proposed CS\nsystem outperforms existing CS systems.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 13:12:34 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Jiang", "Q.", ""], ["Li", "S.", ""], ["Zhu", "Z.", ""], ["Bai", "H.", ""], ["He", "X.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "1910.12259", "submitter": "Peter M. Roth", "authors": "Mina Basirat, Peter M. Roth", "title": "L*ReLU: Piece-wise Linear Activation Functions for Deep Fine-grained\n  Visual Categorization", "comments": "Accepted: Winter Conference on Applications of Computer Vision (WACV)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks paved the way for significant improvements in image\nvisual categorization during the last years. However, even though the tasks are\nhighly varying, differing in complexity and difficulty, existing solutions\nmostly build on the same architectural decisions. This also applies to the\nselection of activation functions (AFs), where most approaches build on\nRectified Linear Units (ReLUs). In this paper, however, we show that the choice\nof a proper AF has a significant impact on the classification accuracy, in\nparticular, if fine, subtle details are of relevance. Therefore, we propose to\nmodel the degree of absence and the presence of features via the AF by using\npiece-wise linear functions, which we refer to as L*ReLU. In this way, we can\nensure the required properties, while still inheriting the benefits in terms of\ncomputational efficiency from ReLUs. We demonstrate our approach for the task\nof Fine-grained Visual Categorization (FGVC), running experiments on seven\ndifferent benchmark datasets. The results do not only demonstrate superior\nresults but also that for different tasks, having different characteristics,\ndifferent AFs are selected.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 13:15:32 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Basirat", "Mina", ""], ["Roth", "Peter M.", ""]]}, {"id": "1910.12263", "submitter": "Tomasz Ku\\'smierczyk", "authors": "Eliezer de Souza da Silva, Tomasz Ku\\'smierczyk, Marcelo Hartmann,\n  Arto Klami", "title": "Prior specification via prior predictive matching: Poisson matrix\n  factorization and beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization for machine learning models is typically carried\nout by some sort of cross-validation procedure or global optimization, both of\nwhich require running the learning algorithm numerous times. We show that for\nBayesian hierarchical models there is an appealing alternative that allows\nselecting good hyperparameters without learning the model parameters during the\nprocess at all, facilitated by the prior predictive distribution that\nmarginalizes out the model parameters. We propose an approach that matches\nsuitable statistics of the prior predictive distribution with ones provided by\nan expert and apply the general concept for matrix factorization models. For\nsome Poisson matrix factorization models we can analytically obtain exact\nhyperparameters, including the number of factors, and for more complex models\nwe propose a model-independent optimization procedure.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 13:56:30 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["da Silva", "Eliezer de Souza", ""], ["Ku\u015bmierczyk", "Tomasz", ""], ["Hartmann", "Marcelo", ""], ["Klami", "Arto", ""]]}, {"id": "1910.12281", "submitter": "Vladimir Puzyrev", "authors": "Vladimir Puzyrev", "title": "Deep convolutional autoencoder for cryptocurrency market analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study attempts to analyze patterns in cryptocurrency markets using a\nspecial type of deep neural networks, namely a convolutional autoencoder. The\nmethod extracts the dominant features of market behavior and classifies the 40\nstudied cryptocurrencies into several classes for twelve 6-month periods\nstarting from 15th May 2013. Transitions from one class to another with time\nare related to the maturement of cryptocurrencies. In speculative\ncryptocurrency markets, these findings have potential implications for\ninvestment and trading strategies.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 15:14:14 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Puzyrev", "Vladimir", ""]]}, {"id": "1910.12288", "submitter": "Axel Brando Guillaumes", "authors": "Axel Brando, Jose A. Rodr\\'iguez-Serrano, Jordi Vitri\\`a, Alberto\n  Rubio", "title": "Modelling heterogeneous distributions with an Uncountable Mixture of\n  Asymmetric Laplacians", "comments": "12 pages, 4 figures, Paper accepted as poster at the 33rd Conference\n  on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression tasks, aleatoric uncertainty is commonly addressed by\nconsidering a parametric distribution of the output variable, which is based on\nstrong assumptions such as symmetry, unimodality or by supposing a restricted\nshape. These assumptions are too limited in scenarios where complex shapes,\nstrong skews or multiple modes are present. In this paper, we propose a generic\ndeep learning framework that learns an Uncountable Mixture of Asymmetric\nLaplacians (UMAL), which will allow us to estimate heterogeneous distributions\nof the output variable and shows its connections to quantile regression.\nDespite having a fixed number of parameters, the model can be interpreted as an\ninfinite mixture of components, which yields a flexible approximation for\nheterogeneous distributions. Apart from synthetic cases, we apply this model to\nroom price forecasting and to predict financial operations in personal bank\naccounts. We demonstrate that UMAL produces proper distributions, which allows\nus to extract richer insights and to sharpen decision-making.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 15:50:08 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 11:15:25 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Brando", "Axel", ""], ["Rodr\u00edguez-Serrano", "Jose A.", ""], ["Vitri\u00e0", "Jordi", ""], ["Rubio", "Alberto", ""]]}, {"id": "1910.12306", "submitter": "Vinoj Yasanga Jayasundara Magalle Hewa Mr.", "authors": "Vinoj Jayasundara, Nghi Duy Quoc Bui, Lingxiao Jiang, David Lo", "title": "TreeCaps: Tree-Structured Capsule Networks for Program Source Code\n  Processing", "comments": "in NeurIPS Workshop on ML for Systems, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program comprehension is a fundamental task in software development and\nmaintenance processes. Software developers often need to understand a large\namount of existing code before they can develop new features or fix bugs in\nexisting programs. Being able to process programming language code\nautomatically and provide summaries of code functionality accurately can\nsignificantly help developers to reduce time spent in code navigation and\nunderstanding, and thus increase productivity. Different from natural language\narticles, source code in programming languages often follows rigid syntactical\nstructures and there can exist dependencies among code elements that are\nlocated far away from each other through complex control flows and data flows.\nExisting studies on tree-based convolutional neural networks (TBCNN) and gated\ngraph neural networks (GGNN) are not able to capture essential semantic\ndependencies among code elements accurately. In this paper, we propose novel\ntree-based capsule networks (TreeCaps) and relevant techniques for processing\nprogram code in an automated way that encodes code syntactical structures and\ncaptures code dependencies more accurately. Based on evaluation on programs\nwritten in different programming languages, we show that our TreeCaps-based\napproach can outperform other approaches in classifying the functionalities of\nmany programs.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 17:28:00 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Jayasundara", "Vinoj", ""], ["Bui", "Nghi Duy Quoc", ""], ["Jiang", "Lingxiao", ""], ["Lo", "David", ""]]}, {"id": "1910.12308", "submitter": "Giorgi Nadiradze", "authors": "Giorgi Nadiradze, Amirmojtaba Sabour, Peter Davies, Ilia Markov,\n  Shigang Li, Dan Alistarh", "title": "Decentralized SGD with Asynchronous, Local and Quantized Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to scale distributed optimization to large node counts has been\none of the main enablers of recent progress in machine learning. To this end,\nseveral techniques have been explored, such as asynchronous, decentralized, or\nquantized communication--which significantly reduce the cost of\nsynchronization, and the ability for nodes to perform several local model\nupdates before communicating--which reduces the frequency of synchronization.\n  In this paper, we show that these techniques, which have so far been\nconsidered independently, can be jointly leveraged to minimize distribution\ncost for training neural network models via stochastic gradient descent (SGD).\nWe consider a setting with minimal coordination: we have a large number of\nnodes on a communication graph, each with a local subset of data, performing\nindependent SGD updates onto their local models. After some number of local\nupdates, each node chooses an interaction partner uniformly at random from its\nneighbors, and averages a possibly quantized version of its local model with\nthe neighbor's model. Our first contribution is in proving that, even under\nsuch a relaxed setting, SGD can still be guaranteed to converge under standard\nassumptions. The proof is based on a new connection with parallel\nload-balancing processes, and improves existing techniques by jointly handling\ndecentralization, asynchrony, quantization, and local updates, and by bounding\ntheir impact. On the practical side, we implement variants of our algorithm and\ndeploy them onto distributed environments, and show that they can successfully\nconverge and scale for large-scale image classification and translation tasks,\nmatching or even slightly improving the accuracy of previous methods.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 17:40:26 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 14:24:00 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 18:32:01 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Nadiradze", "Giorgi", ""], ["Sabour", "Amirmojtaba", ""], ["Davies", "Peter", ""], ["Markov", "Ilia", ""], ["Li", "Shigang", ""], ["Alistarh", "Dan", ""]]}, {"id": "1910.12316", "submitter": "Georgios Detorakis", "authors": "Georgios Detorakis, Sourav Dutta, Abhishek Khanna, Matthew Jerry,\n  Suman Datta, Emre Neftci", "title": "Inherent Weight Normalization in Stochastic Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplicative stochasticity such as Dropout improves the robustness and\ngeneralizability of deep neural networks. Here, we further demonstrate that\nalways-on multiplicative stochasticity combined with simple threshold neurons\nare sufficient operations for deep neural networks. We call such models Neural\nSampling Machines (NSM). We find that the probability of activation of the NSM\nexhibits a self-normalizing property that mirrors Weight Normalization, a\npreviously studied mechanism that fulfills many of the features of Batch\nNormalization in an online fashion. The normalization of activities during\ntraining speeds up convergence by preventing internal covariate shift caused by\nchanges in the input distribution. The always-on stochasticity of the NSM\nconfers the following advantages: the network is identical in the inference and\nlearning phases, making the NSM suitable for online learning, it can exploit\nstochasticity inherent to a physical substrate such as analog non-volatile\nmemories for in-memory computing, and it is suitable for Monte Carlo sampling,\nwhile requiring almost exclusively addition and comparison operations. We\ndemonstrate NSMs on standard classification benchmarks (MNIST and CIFAR) and\nevent-based classification benchmarks (N-MNIST and DVS Gestures). Our results\nshow that NSMs perform comparably or better than conventional artificial neural\nnetworks with the same architecture.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 18:21:26 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Detorakis", "Georgios", ""], ["Dutta", "Sourav", ""], ["Khanna", "Abhishek", ""], ["Jerry", "Matthew", ""], ["Datta", "Suman", ""], ["Neftci", "Emre", ""]]}, {"id": "1910.12322", "submitter": "Arda Efe Okay", "authors": "Arda Efe Okay, Manal AlGhamdi, Robert Westendorp and Mohamed\n  Abdel-Mottaleb", "title": "Multi-Resolution Overlapping Stripes Network for Person\n  Re-Identification", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the person re-identification (PReID) problem by\ncombining global and local information at multiple feature resolutions with\ndifferent loss functions. Many previous studies address this problem using\neither part-based features or global features. In case of part-based\nrepresentation, the spatial correlation between these parts is not considered,\nwhile global-based representation are not sensitive to spatial variations. This\npaper presents a part-based model with a multi-resolution network that uses\ndifferent level of features. The output of the last two conv blocks is then\npartitioned horizontally and processed in pairs with overlapping stripes to\ncover the important information that might lie between parts. We use different\nloss functions to combine local and global information for classification.\nExperimental results on a benchmark dataset demonstrate that the presented\nmethod outperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 18:38:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Okay", "Arda Efe", ""], ["AlGhamdi", "Manal", ""], ["Westendorp", "Robert", ""], ["Abdel-Mottaleb", "Mohamed", ""]]}, {"id": "1910.12326", "submitter": "Alireza Chamanzar", "authors": "Alireza Chamanzar, Yao Nie", "title": "Weakly Supervised Multi-Task Learning for Cell Detection and\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell detection and segmentation is fundamental for all downstream analysis of\ndigital pathology images. However, obtaining the pixel-level ground truth for\nsingle cell segmentation is extremely labor intensive. To overcome this\nchallenge, we developed an end-to-end deep learning algorithm to perform both\nsingle cell detection and segmentation using only point labels. This is\nachieved through the combination of different task orientated point label\nencoding methods and a multi-task scheduler for training. We apply and validate\nour algorithm on PMS2 stained colon rectal cancer and tonsil tissue images.\nCompared to the state-of-the-art, our algorithm shows significant improvement\nin cell detection and segmentation without increasing the annotation efforts.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 19:11:39 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Chamanzar", "Alireza", ""], ["Nie", "Yao", ""]]}, {"id": "1910.12329", "submitter": "Aicha BenTaieb", "authors": "A\\\"icha BenTaieb, Ghassan Hamarneh", "title": "Deep Learning Models for Digital Pathology", "comments": "Technical report, Survey, 58 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histopathology images; microscopy images of stained tissue biopsies contain\nfundamental prognostic information that forms the foundation of pathological\nanalysis and diagnostic medicine. However, diagnostics from histopathology\nimages generally rely on a visual cognitive assessment of tissue slides which\nimplies an inherent element of interpretation and hence subjectivity. Access to\ndigitized histopathology images enabled the development of computational\nsystems aiming at reducing manual intervention and automating parts of\npathologists' workflow. Specifically, applications of deep learning to\nhistopathology image analysis now offer opportunities for better quantitative\nmodeling of disease appearance and hence possibly improved prediction of\ndisease aggressiveness and patient outcome. However digitized histopathology\ntissue slides are unique in a variety of ways and come with their own set of\ncomputational challenges. In this survey, we summarize the different challenges\nfacing computational systems for digital pathology and provide a review of\nstate-of-the-art works that developed deep learning-based solutions for the\npredictive modeling of histopathology images from a detection, stain\nnormalization, segmentation, and tissue classification perspective. We then\ndiscuss the challenges facing the validation and integration of such deep\nlearning-based computational systems in clinical workflow and reflect on future\nopportunities for histopathology derived image measurements and better\npredictive modeling.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 19:38:58 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 01:35:20 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["BenTaieb", "A\u00efcha", ""], ["Hamarneh", "Ghassan", ""]]}, {"id": "1910.12336", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Walter Karlen", "title": "CXPlain: Causal Explanations for Model Interpretation under Uncertainty", "comments": "To appear in Advances in Neural Information Processing Systems 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature importance estimates that inform users about the degree to which\ngiven inputs influence the output of a predictive model are crucial for\nunderstanding, validating, and interpreting machine-learning models. However,\nproviding fast and accurate estimates of feature importance for\nhigh-dimensional data, and quantifying the uncertainty of such estimates remain\nopen challenges. Here, we frame the task of providing explanations for the\ndecisions of machine-learning models as a causal learning task, and train\ncausal explanation (CXPlain) models that learn to estimate to what degree\ncertain inputs cause outputs in another machine-learning model. CXPlain can,\nonce trained, be used to explain the target model in little time, and enables\nthe quantification of the uncertainty associated with its feature importance\nestimates via bootstrap ensembling. We present experiments that demonstrate\nthat CXPlain is significantly more accurate and faster than existing\nmodel-agnostic methods for estimating feature importance. In addition, we\nconfirm that the uncertainty estimates provided by CXPlain ensembles are\nstrongly correlated with their ability to accurately estimate feature\nimportance on held-out data.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 19:59:18 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Schwab", "Patrick", ""], ["Karlen", "Walter", ""]]}, {"id": "1910.12354", "submitter": "Vladislav Kurenkov", "authors": "Vladislav Kurenkov, Bulat Maksudov, Adil Khan", "title": "Task-Oriented Language Grounding for Language Input with Multiple\n  Sub-Goals of Non-Linear Order", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we analyze the performance of general deep reinforcement\nlearning algorithms for a task-oriented language grounding problem, where\nlanguage input contains multiple sub-goals and their order of execution is\nnon-linear.\n  We generate a simple instructional language for the GridWorld environment,\nthat is built around three language elements (order connectors) defining the\norder of execution: one linear - \"comma\" and two non-linear - \"but first\", \"but\nbefore\". We apply one of the deep reinforcement learning baselines - Double DQN\nwith frame stacking and ablate several extensions such as Prioritized\nExperience Replay and Gated-Attention architecture.\n  Our results show that the introduction of non-linear order connectors\nimproves the success rate on instructions with a higher number of sub-goals in\n2-3 times, but it still does not exceed 20%. Also, we observe that the usage of\nGated-Attention provides no competitive advantage against concatenation in this\nsetting. Source code and experiments' results are available at\nhttps://github.com/vkurenkov/language-grounding-multigoal\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 21:11:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kurenkov", "Vladislav", ""], ["Maksudov", "Bulat", ""], ["Khan", "Adil", ""]]}, {"id": "1910.12358", "submitter": "Krikamol Muandet", "authors": "Krikamol Muandet, Arash Mehrjou, Si Kai Lee, Anant Raj", "title": "Dual Instrumental Variable Regression", "comments": "Advances in Neural Information Processing Systems 33 (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithm for non-linear instrumental variable (IV)\nregression, DualIV, which simplifies traditional two-stage methods via a dual\nformulation. Inspired by problems in stochastic programming, we show that\ntwo-stage procedures for non-linear IV regression can be reformulated as a\nconvex-concave saddle-point problem. Our formulation enables us to circumvent\nthe first-stage regression which is a potential bottleneck in real-world\napplications. We develop a simple kernel-based algorithm with an analytic\nsolution based on this formulation. Empirical results show that we are\ncompetitive to existing, more complicated algorithms for non-linear\ninstrumental variable regression.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 21:36:26 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 20:43:18 GMT"}, {"version": "v3", "created": "Sat, 24 Oct 2020 14:24:17 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Muandet", "Krikamol", ""], ["Mehrjou", "Arash", ""], ["Lee", "Si Kai", ""], ["Raj", "Anant", ""]]}, {"id": "1910.12359", "submitter": "Melih Yesilli", "authors": "Melih C. Yesilli, Sarah Tymochko, Firas A. Khasawneh, Elizabeth Munch", "title": "Chatter Diagnosis in Milling Using Supervised Learning and Topological\n  Features Vector", "comments": null, "journal-ref": null, "doi": "10.1109/ICMLA.2019.00200", "report-no": null, "categories": "eess.SP cs.CG cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatter detection has become a prominent subject of interest due to its\neffect on cutting tool life, surface finish and spindle of machine tool. Most\nof the existing methods in chatter detection literature are based on signal\nprocessing and signal decomposition. In this study, we use topological features\nof data simulating cutting tool vibrations, combined with four supervised\nmachine learning algorithms to diagnose chatter in the milling process.\nPersistence diagrams, a method of representing topological features, are not\neasily used in the context of machine learning, so they must be transformed\ninto a form that is more amenable. Specifically, we will focus on two different\nmethods for featurizing persistence diagrams, Carlsson coordinates and template\nfunctions. In this paper, we provide classification results for simulated data\nfrom various cutting configurations, including upmilling and downmilling, in\naddition to the same data with some added noise. Our results show that Carlsson\nCoordinates and Template Functions yield accuracies as high as 96% and 95%,\nrespectively. We also provide evidence that these topological methods are noise\nrobust descriptors for chatter detection.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 21:39:27 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Yesilli", "Melih C.", ""], ["Tymochko", "Sarah", ""], ["Khasawneh", "Firas A.", ""], ["Munch", "Elizabeth", ""]]}, {"id": "1910.12360", "submitter": "Zheng Wang", "authors": "Zheng Wang, Shandian Zhe", "title": "Conditional Expectation Propagation", "comments": "10 pages, 5 figures, UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectation propagation (EP) is a powerful approximate inference algorithm.\nHowever, a critical barrier in applying EP is that the moment matching in\nmessage updates can be intractable. Handcrafting approximations is usually\ntricky, and lacks generalizability. Importance sampling is very expensive.\nWhile Laplace propagation provides a good solution, it has to run numerical\noptimizations to find Laplace approximations in every update, which is still\nquite inefficient. To overcome these practical barriers, we propose conditional\nexpectation propagation (CEP) that performs conditional moment matching given\nthe variables outside each message, and then takes expectation w.r.t the\napproximate posterior of these variables. The conditional moments are often\nanalytical and much easier to derive. In the most general case, we can use\n(fully) factorized messages to represent the conditional moments by quadrature\nformulas. We then compute the expectation of the conditional moments via Taylor\napproximations when necessary. In this way, our algorithm can always conduct\nefficient, analytical fixed point iterations. Experiments on several popular\nmodels for which standard EP is available or unavailable demonstrate the\nadvantages of CEP in both inference quality and computational efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 21:41:19 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 16:44:13 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Wang", "Zheng", ""], ["Zhe", "Shandian", ""]]}, {"id": "1910.12362", "submitter": "David Cortes", "authors": "David Cortes", "title": "Distance approximation using Isolation Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work briefly explores the possibility of approximating spatial distance\n(alternatively, similarity) between data points using the Isolation Forest\nmethod envisioned for outlier detection. The logic is similar to that of\nisolation: the more similar or closer two points are, the more random splits it\nwill take to separate them. The separation depth between two points can be\nstandardized in the same way as the isolation depth, transforming it into a\ndistance metric that is limited in range, centered, and in compliance with the\naxioms of distance. This metric presents some desirable properties such as\nbeing invariant to the scales of variables or being able to account for\nnon-linear relationships between variables, which other metrics such as\nEuclidean or Mahalanobis distance do not. Extensions to the Isolation Forest\nmethod are also proposed for handling categorical variables and missing values,\nresulting in a more generalizable and robust metric.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 21:47:32 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 15:17:32 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Cortes", "David", ""]]}, {"id": "1910.12363", "submitter": "Dan Oneata", "authors": "Dan Oneata, Cosmin George Alexandru, Marius Stanescu, Octavian Pascu,\n  Alexandru Magan, Adrian Postelnicu, Horia Cucu", "title": "The Quo Vadis submission at Traffic4cast 2019", "comments": "Extended abstract for the Traffic4cast competition from NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe the submission of the Quo Vadis team to the Traffic4cast\ncompetition, which was organized as part of the NeurIPS 2019 series of\nchallenges. Our system consists of a temporal regression module, implemented as\n$1\\times1$ 2d convolutions, augmented with spatio-temporal biases. We have\nfound that using biases is a straightforward and efficient way to include\nseasonal patterns and to improve the performance of the temporal regression\nmodel. Our implementation obtains a mean squared error of $9.47\\times 10^{-3}$\non the test data, placing us on the eight place team-wise. We also present our\nattempts at incorporating spatial correlations into the model; however,\ncontrary to our expectations, adding this type of auxiliary information did not\nbenefit the main system. Our code is available at\nhttps://github.com/danoneata/traffic4cast.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 21:50:30 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Oneata", "Dan", ""], ["Alexandru", "Cosmin George", ""], ["Stanescu", "Marius", ""], ["Pascu", "Octavian", ""], ["Magan", "Alexandru", ""], ["Postelnicu", "Adrian", ""], ["Cucu", "Horia", ""]]}, {"id": "1910.12366", "submitter": "Kalpesh Krishna", "authors": "Kalpesh Krishna, Gaurav Singh Tomar, Ankur P. Parikh, Nicolas\n  Papernot, Mohit Iyyer", "title": "Thieves on Sesame Street! Model Extraction of BERT-based APIs", "comments": "ICLR 2020 Camera Ready (19 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of model extraction in natural language processing, in\nwhich an adversary with only query access to a victim model attempts to\nreconstruct a local copy of that model. Assuming that both the adversary and\nvictim model fine-tune a large pretrained language model such as BERT (Devlin\net al. 2019), we show that the adversary does not need any real training data\nto successfully mount the attack. In fact, the attacker need not even use\ngrammatical or semantically meaningful queries: we show that random sequences\nof words coupled with task-specific heuristics form effective queries for model\nextraction on a diverse set of NLP tasks, including natural language inference\nand question answering. Our work thus highlights an exploit only made feasible\nby the shift towards transfer learning methods within the NLP community: for a\nquery budget of a few hundred dollars, an attacker can extract a model that\nperforms only slightly worse than the victim model. Finally, we study two\ndefense strategies against model extraction---membership classification and API\nwatermarking---which while successful against naive adversaries, are\nineffective against more sophisticated ones.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 22:09:13 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 03:20:52 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 12:14:05 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Krishna", "Kalpesh", ""], ["Tomar", "Gaurav Singh", ""], ["Parikh", "Ankur P.", ""], ["Papernot", "Nicolas", ""], ["Iyyer", "Mohit", ""]]}, {"id": "1910.12367", "submitter": "Abdelrahman Mohamed", "authors": "Kritika Singh, Dmytro Okhonko, Jun Liu, Yongqiang Wang, Frank Zhang,\n  Ross Girshick, Sergey Edunov, Fuchun Peng, Yatharth Saraf, Geoffrey Zweig,\n  Abdelrahman Mohamed", "title": "Training ASR models by Generation of Contextual Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised ASR models have reached unprecedented levels of accuracy, thanks\nin part to ever-increasing amounts of labelled training data. However, in many\napplications and locales, only moderate amounts of data are available, which\nhas led to a surge in semi- and weakly-supervised learning research. In this\npaper, we conduct a large-scale study evaluating the effectiveness of\nweakly-supervised learning for speech recognition by using loosely related\ncontextual information as a surrogate for ground-truth labels. For weakly\nsupervised training, we use 50k hours of public English social media videos\nalong with their respective titles and post text to train an encoder-decoder\ntransformer model. Our best encoder-decoder models achieve an average of 20.8%\nWER reduction over a 1000 hours supervised baseline, and an average of 13.4%\nWER reduction when using only the weakly supervised encoder for CTC\nfine-tuning. Our results show that our setup for weak supervision improved both\nthe encoder acoustic representations as well as the decoder language generation\nabilities.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 22:13:09 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 21:59:25 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Singh", "Kritika", ""], ["Okhonko", "Dmytro", ""], ["Liu", "Jun", ""], ["Wang", "Yongqiang", ""], ["Zhang", "Frank", ""], ["Girshick", "Ross", ""], ["Edunov", "Sergey", ""], ["Peng", "Fuchun", ""], ["Saraf", "Yatharth", ""], ["Zweig", "Geoffrey", ""], ["Mohamed", "Abdelrahman", ""]]}, {"id": "1910.12369", "submitter": "Tito Spadini", "authors": "Tito Spadini, Dimitri Leandro de Oliveira Silva, Ricardo Suyama", "title": "Sound Event Recognition in a Smart City Surveillance Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Due to the growing demand for improving surveillance capabilities in smart\ncities, systems need to be developed to provide better monitoring capabilities\nto competent authorities, agencies responsible for strategic resource\nmanagement, and emergency call centers. This work assumes that, as a\ncomplementary monitoring solution, the use of a system capable of detecting the\noccurrence of sound events, performing the Sound Events Recognition (SER) task,\nis highly convenient. In order to contribute to the classification of such\nevents, this paper explored several classifiers over the SESA dataset, composed\nof audios of three hazard classes (gunshots, explosions, and sirens) and a\nclass of casual sounds that could be misinterpreted as some of the other\nsounds. The best result was obtained by SGD, with an accuracy of 72.13% with\n6.81 ms classification time, reinforcing the viability of such an approach.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 22:17:26 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 20:36:20 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Spadini", "Tito", ""], ["Silva", "Dimitri Leandro de Oliveira", ""], ["Suyama", "Ricardo", ""]]}, {"id": "1910.12370", "submitter": "Aya Abdelsalam Ismail", "authors": "Aya Abdelsalam Ismail, Mohamed Gunady, Luiz Pessoa, H\\'ector Corrada\n  Bravo and Soheil Feizi", "title": "Input-Cell Attention Reduces Vanishing Saliency of Recurrent Neural\n  Networks", "comments": null, "journal-ref": "Neurips 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts to improve the interpretability of deep neural networks use\nsaliency to characterize the importance of input features to predictions made\nby models. Work on interpretability using saliency-based methods on Recurrent\nNeural Networks (RNNs) has mostly targeted language tasks, and their\napplicability to time series data is less understood. In this work we analyze\nsaliency-based methods for RNNs, both classical and gated cell architectures.\nWe show that RNN saliency vanishes over time, biasing detection of salient\nfeatures only to later time steps and are, therefore, incapable of reliably\ndetecting important features at arbitrary time intervals. To address this\nvanishing saliency problem, we propose a novel RNN cell structure (input-cell\nattention), which can extend any RNN cell architecture. At each time step,\ninstead of only looking at the current input vector, input-cell attention uses\na fixed-size matrix embedding, each row of the matrix attending to different\ninputs from current or previous time steps. Using synthetic data, we show that\nthe saliency map produced by the input-cell attention RNN is able to faithfully\ndetect important features regardless of their occurrence in time. We also apply\nthe input-cell attention RNN on a neuroscience task analyzing functional\nMagnetic Resonance Imaging (fMRI) data for human subjects performing a variety\nof tasks. In this case, we use saliency to characterize brain regions (input\nfeatures) for which activity is important to distinguish between tasks. We show\nthat standard RNN architectures are only capable of detecting important brain\nregions in the last few time steps of the fMRI data, while the input-cell\nattention model is able to detect important brain region activity across time\nwithout latter time step biases.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 22:31:29 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ismail", "Aya Abdelsalam", ""], ["Gunady", "Mohamed", ""], ["Pessoa", "Luiz", ""], ["Bravo", "H\u00e9ctor Corrada", ""], ["Feizi", "Soheil", ""]]}, {"id": "1910.12378", "submitter": "Chi Wu", "authors": "Chi Wu, Xinping Yi, Wenjin Wang, Li You, Qing Huang, Xiqi Gao", "title": "Learning to Localize: A 3D CNN Approach to User Positioning in Massive\n  MIMO-OFDM Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the user positioning problem in the massive\nmultiple-input multiple-output (MIMO) orthogonal frequency-division\nmultiplexing (OFDM) system with a uniform planner antenna (UPA) array. Taking\nadvantage of the UPA array geometry and wide bandwidth, we advocate the use of\nthe angle-delay channel power matrix (ADCPM) as a new type of fingerprint to\nreplace the traditional ones. The ADCPM embeds the stable and stationary\nmultipath characteristics, e.g. delay, power, and angle in the vertical and\nhorizontal directions, which are beneficial to positioning. Taking ADCPM\nfingerprints as the inputs, we propose a novel three-dimensional (3D)\nconvolution neural network (CNN) enabled learning method to localize users' 3D\npositions. In particular, such a 3D CNN model consists of a convolution\nrefinement module to refine the elementary feature maps from the ADCPM\nfingerprints, three extended Inception modules to extract the advanced feature\nmaps, and a regression module to estimate the 3D positions. By intensive\nsimulations, the proposed 3D CNN-enabled positioning method is demonstrated to\nachieve higher positioning accuracy than the traditional searching-based ones,\nwith reduced computational complexity and storage overhead, and the ADCPM\nfingerprints are more robust to noise contamination.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 23:16:30 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 13:54:45 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Wu", "Chi", ""], ["Yi", "Xinping", ""], ["Wang", "Wenjin", ""], ["You", "Li", ""], ["Huang", "Qing", ""], ["Gao", "Xiqi", ""]]}, {"id": "1910.12379", "submitter": "Yuxin Chen", "authors": "Nikhil Ghosh, Yuxin Chen, Yisong Yue", "title": "Landmark Ordinal Embedding", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to learn a low-dimensional Euclidean representation\nfrom a set of constraints of the form \"item j is closer to item i than item k\".\nExisting approaches for this \"ordinal embedding\" problem require expensive\noptimization procedures, which cannot scale to handle increasingly larger\ndatasets. To address this issue, we propose a landmark-based strategy, which we\ncall Landmark Ordinal Embedding (LOE). Our approach trades off statistical\nefficiency for computational efficiency by exploiting the low-dimensionality of\nthe latent embedding. We derive bounds establishing the statistical consistency\nof LOE under the popular Bradley-Terry-Luce noise model. Through a rigorous\nanalysis of the computational complexity, we show that LOE is significantly\nmore efficient than conventional ordinal embedding approaches as the number of\nitems grows. We validate these characterizations empirically on both synthetic\nand real datasets. We also present a practical approach that achieves the \"best\nof both worlds\", by using LOE to warm-start existing methods that are more\nstatistically efficient but computationally expensive.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 23:26:32 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ghosh", "Nikhil", ""], ["Chen", "Yuxin", ""], ["Yue", "Yisong", ""]]}, {"id": "1910.12385", "submitter": "Ruizhe Zhao", "authors": "Ruizhe Zhao, Brian Vogel, Tanvir Ahmed", "title": "Adaptive Loss Scaling for Mixed Precision Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed precision training (MPT) is becoming a practical technique to improve\nthe speed and energy efficiency of training deep neural networks by leveraging\nthe fast hardware support for IEEE half-precision floating point that is\navailable in existing GPUs. MPT is typically used in combination with a\ntechnique called loss scaling, that works by scaling up the loss value up\nbefore the start of backpropagation in order to minimize the impact of\nnumerical underflow on training. Unfortunately, existing methods make this loss\nscale value a hyperparameter that needs to be tuned per-model, and a single\nscale cannot be adapted to different layers at different training stages. We\nintroduce a loss scaling-based training method called adaptive loss scaling\nthat makes MPT easier and more practical to use, by removing the need to tune a\nmodel-specific loss scale hyperparameter. We achieve this by introducing\nlayer-wise loss scale values which are automatically computed during training\nto deal with underflow more effectively than existing methods. We present\nexperimental results on a variety of networks and tasks that show our approach\ncan shorten the time to convergence and improve accuracy compared to the\nexisting state-of-the-art MPT and single-precision floating point\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 00:13:08 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhao", "Ruizhe", ""], ["Vogel", "Brian", ""], ["Ahmed", "Tanvir", ""]]}, {"id": "1910.12387", "submitter": "Alexander Jung", "authors": "Alexander Jung", "title": "Components of Machine Learning: Binding Bits and FLOPS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems and methods are combinations of three\ncomponents: data, hypothesis space and loss function. Different machine\nlearning methods are obtained as combinations of different choices for the\nrepresentation of data, hypothesis space and loss function. After reviewing the\nmathematical structure of these three components, we discuss intrinsic\ntrade-offs between statistical and computational properties of machine learning\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 17:33:33 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 07:59:02 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Jung", "Alexander", ""]]}, {"id": "1910.12388", "submitter": "Sneha Aenugu", "authors": "Sneha Aenugu", "title": "A memory enhanced LSTM for modeling complex temporal dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Gamma-LSTM, an enhanced long short term memory\n(LSTM) unit, to enable learning of hierarchical representations through\nmultiple stages of temporal abstractions. Gamma memory, a hierarchical memory\nunit, forms the central memory of Gamma-LSTM with gates to regulate the\ninformation flow into various levels of hierarchy, thus providing the unit with\na control to pick the appropriate level of hierarchy to process the input at a\ngiven instant of time. We demonstrate better performance of Gamma-LSTM model\nregular and stacked LSTMs in two settings (pixel-by-pixel MNIST digit\nclassification and natural language inference) placing emphasis on the ability\nto generalize over long sequences.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 17:09:16 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Aenugu", "Sneha", ""]]}, {"id": "1910.12389", "submitter": "Jian Ma", "authors": "Jian Ma", "title": "Variable Selection with Copula Entropy", "comments": "To appear at Chinese Journal of Applied Probability and Statistics.\n  Code is available on GitHub at https://github.com/majianthu/aps2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection is of significant importance for classification and\nregression tasks in machine learning and statistical applications where both\npredictability and explainability are needed. In this paper, a Copula Entropy\n(CE) based method for variable selection which use CE based ranks to select\nvariables is proposed. The method is both model-free and tuning-free.\nComparison experiments between the proposed method and traditional variable\nselection methods, such as Distance Correlation, Hilbert-Schmidt Independence\nCriterion, Stepwise Selection, regularized generalized linear models and\nAdaptive LASSO, were conducted on the UCI heart disease data. Experimental\nresults show that CE based method can select the `right' variables out more\neffectively and derive better interpretable results than traditional methods do\nwithout sacrificing accuracy performance. It is believed that CE based variable\nselection can help to build more explainable models.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 00:47:00 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 11:22:53 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Ma", "Jian", ""]]}, {"id": "1910.12392", "submitter": "Ehsan Nowroozi", "authors": "Mauro Barni, Ehsan Nowroozi, Benedetta Tondi, Bowen Zhang", "title": "Effectiveness of random deep feature selection for securing image\n  manipulation detectors against adversarial examples", "comments": "Submitted to the ICASSP conference to be held in 2020, Barcelona,\n  Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate if the random feature selection approach proposed in [1] to\nimprove the robustness of forensic detectors to targeted attacks, can be\nextended to detectors based on deep learning features. In particular, we study\nthe transferability of adversarial examples targeting an original CNN image\nmanipulation detector to other detectors (a fully connected neural network and\na linear SVM) that rely on a random subset of the features extracted from the\nflatten layer of the original network. The results we got by considering three\nimage manipulation detection tasks (resizing, median filtering and adaptive\nhistogram equalization), two original network architectures and three classes\nof attacks, show that feature randomization helps to hinder attack\ntransferability, even if, in some cases, simply changing the architecture of\nthe detector, or even retraining the detector is enough to prevent the\ntransferability of the attacks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 10:33:32 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 11:37:28 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Barni", "Mauro", ""], ["Nowroozi", "Ehsan", ""], ["Tondi", "Benedetta", ""], ["Zhang", "Bowen", ""]]}, {"id": "1910.12396", "submitter": "Guy Katz", "authors": "Sumathi Gokulanathan, Alexander Feldsher, Adi Malca, Clark Barrett,\n  Guy Katz", "title": "Simplifying Neural Networks using Formal Verification", "comments": "This paper appeared at NFM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) verification is an emerging field, with diverse\nverification engines quickly becoming available. Demonstrating the\neffectiveness of these engines on real-world DNNs is an important step towards\ntheir wider adoption. We present a tool that can leverage existing verification\nengines in performing a novel application: neural network simplification,\nthrough the reduction of the size of a DNN without harming its accuracy. We\nreport on the work-flow of the simplification process, and demonstrate its\npotential significance and applicability on a family of real-world DNNs for\naircraft collision avoidance, whose sizes we were able to reduce by as much as\n10%.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 17:29:53 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 12:00:56 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gokulanathan", "Sumathi", ""], ["Feldsher", "Alexander", ""], ["Malca", "Adi", ""], ["Barrett", "Clark", ""], ["Katz", "Guy", ""]]}, {"id": "1910.12406", "submitter": "Shubhanshu Shekhar", "authors": "Shubhanshu Shekhar, Tara Javidi, Mohammad Ghavamzadeh", "title": "Adaptive Sampling for Estimating Multiple Probability Distributions", "comments": "40 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of allocating samples to a finite set of discrete\ndistributions in order to learn them uniformly well in terms of four common\ndistance measures: $\\ell_2^2$, $\\ell_1$, $f$-divergence, and separation\ndistance. To present a unified treatment of these distances, we first propose a\ngeneral optimistic tracking algorithm and analyze its sample allocation\nperformance w.r.t.~an oracle. We then instantiate this algorithm for the four\ndistance measures and derive bounds on the regret of their resulting allocation\nschemes. We verify our theoretical findings through some experiments. Finally,\nwe show that the techniques developed in the paper can be easily extended to\nthe related setting of minimizing the average error (in terms of the four\ndistances) in learning a set of distributions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 02:18:40 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 01:32:56 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Shekhar", "Shubhanshu", ""], ["Javidi", "Tara", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "1910.12414", "submitter": "Lin Chen", "authors": "Lin Chen, Hossein Esfandiari, Thomas Fu, Vahab S. Mirrokni", "title": "Locality-Sensitive Hashing for f-Divergences: Mutual Information Loss\n  and Beyond", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing approximate nearest neighbors in high dimensional spaces is a\ncentral problem in large-scale data mining with a wide range of applications in\nmachine learning and data science. A popular and effective technique in\ncomputing nearest neighbors approximately is the locality-sensitive hashing\n(LSH) scheme. In this paper, we aim to develop LSH schemes for distance\nfunctions that measure the distance between two probability distributions,\nparticularly for f-divergences as well as a generalization to capture mutual\ninformation loss. First, we provide a general framework to design LHS schemes\nfor f-divergence distance functions and develop LSH schemes for the generalized\nJensen-Shannon divergence and triangular discrimination in this framework. We\nshow a two-sided approximation result for approximation of the generalized\nJensen-Shannon divergence by the Hellinger distance, which may be of\nindependent interest. Next, we show a general method of reducing the problem of\ndesigning an LSH scheme for a Krein kernel (which can be expressed as the\ndifference of two positive definite kernels) to the problem of maximum inner\nproduct search. We exemplify this method by applying it to the mutual\ninformation loss, due to its several important applications such as model\ncompression.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 03:07:29 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Chen", "Lin", ""], ["Esfandiari", "Hossein", ""], ["Fu", "Thomas", ""], ["Mirrokni", "Vahab S.", ""]]}, {"id": "1910.12417", "submitter": "Raha Moraffah", "authors": "Raha Moraffah, Kai Shu, Adrienne Raglin, Huan Liu", "title": "Deep causal representation learning for unsupervised domain adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies show that the representations learned by deep neural networks can be\ntransferred to similar prediction tasks in other domains for which we do not\nhave enough labeled data. However, as we transition to higher layers in the\nmodel, the representations become more task-specific and less generalizable.\nRecent research on deep domain adaptation proposed to mitigate this problem by\nforcing the deep model to learn more transferable feature representations\nacross domains. This is achieved by incorporating domain adaptation methods\ninto deep learning pipeline. The majority of existing models learn the\ntransferable feature representations which are highly correlated with the\noutcome. However, correlations are not always transferable. In this paper, we\npropose a novel deep causal representation learning framework for unsupervised\ndomain adaptation, in which we propose to learn domain-invariant causal\nrepresentations of the input from the source domain. We simulate a virtual\ntarget domain using reweighted samples from the source domain and estimate the\ncausal effect of features on the outcomes. The extensive comparative study\ndemonstrates the strengths of the proposed model for unsupervised domain\nadaptation via causal representations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 03:16:01 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Moraffah", "Raha", ""], ["Shu", "Kai", ""], ["Raglin", "Adrienne", ""], ["Liu", "Huan", ""]]}, {"id": "1910.12424", "submitter": "Mingrui Zhang", "authors": "Mingrui Zhang, Lin Chen, Hamed Hassani, Amin Karbasi", "title": "Online Continuous Submodular Maximization: From Full-Information to\n  Bandit Feedback", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose three online algorithms for submodular\nmaximisation. The first one, Mono-Frank-Wolfe, reduces the number of\nper-function gradient evaluations from $T^{1/2}$ [Chen2018Online] and $T^{3/2}$\n[chen2018projection] to 1, and achieves a $(1-1/e)$-regret bound of\n$O(T^{4/5})$. The second one, Bandit-Frank-Wolfe, is the first bandit algorithm\nfor continuous DR-submodular maximization, which achieves a $(1-1/e)$-regret\nbound of $O(T^{8/9})$. Finally, we extend Bandit-Frank-Wolfe to a bandit\nalgorithm for discrete submodular maximization, Responsive-Frank-Wolfe, which\nattains a $(1-1/e)$-regret bound of $O(T^{8/9})$ in the responsive bandit\nsetting.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 03:24:12 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhang", "Mingrui", ""], ["Chen", "Lin", ""], ["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""]]}, {"id": "1910.12428", "submitter": "Jingbo Liu", "authors": "Jingbo Liu and Philippe Rigollet", "title": "Power analysis of knockoff filters for correlated designs", "comments": "Accepted to Neurips 2019. The conference version includes the\n  contents of this version excluding the appendices. v3 on arXiv corrected some\n  typos in v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The knockoff filter introduced by Barber and Cand\\`es 2016 is an elegant\nframework for controlling the false discovery rate in variable selection. While\nempirical results indicate that this methodology is not too conservative, there\nis no conclusive theoretical result on its power. When the predictors are\ni.i.d. Gaussian, it is known that as the signal to noise ratio tend to\ninfinity, the knockoff filter is consistent in the sense that one can make FDR\ngo to 0 and power go to 1 simultaneously. In this work we study the case where\nthe predictors have a general covariance matrix $\\Sigma$. We introduce a simple\nfunctional called effective signal deficiency (ESD) of the covariance matrix\n$\\Sigma$ that predicts consistency of various variable selection methods. In\nparticular, ESD reveals that the structure of the precision matrix\n$\\Sigma^{-1}$ plays a central role in consistency and therefore, so does the\nconditional independence structure of the predictors. To leverage this\nconnection, we introduce Conditional Independence knockoff, a simple procedure\nthat is able to compete with the more sophisticated knockoff filters and that\nis defined when the predictors obey a Gaussian tree graphical models (or when\nthe graph is sufficiently sparse). Our theoretical results are supported by\nnumerical evidence on synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 03:48:42 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 12:40:50 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 21:12:13 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Liu", "Jingbo", ""], ["Rigollet", "Philippe", ""]]}, {"id": "1910.12430", "submitter": "Akshay Agrawal", "authors": "Akshay Agrawal, Brandon Amos, Shane Barratt, Stephen Boyd, Steven\n  Diamond, Zico Kolter", "title": "Differentiable Convex Optimization Layers", "comments": "In NeurIPS 2019. Code available at\n  https://www.github.com/cvxgrp/cvxpylayers. Authors in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown how to embed differentiable optimization problems (that\nis, problems whose solutions can be backpropagated through) as layers within\ndeep learning architectures. This method provides a useful inductive bias for\ncertain problems, but existing software for differentiable optimization layers\nis rigid and difficult to apply to new settings. In this paper, we propose an\napproach to differentiating through disciplined convex programs, a subclass of\nconvex optimization problems used by domain-specific languages (DSLs) for\nconvex optimization. We introduce disciplined parametrized programming, a\nsubset of disciplined convex programming, and we show that every disciplined\nparametrized program can be represented as the composition of an affine map\nfrom parameters to problem data, a solver, and an affine map from the solver's\nsolution to a solution of the original problem (a new form we refer to as\naffine-solver-affine form). We then demonstrate how to efficiently\ndifferentiate through each of these components, allowing for end-to-end\nanalytical differentiation through the entire convex program. We implement our\nmethodology in version 1.1 of CVXPY, a popular Python-embedded DSL for convex\noptimization, and additionally implement differentiable layers for disciplined\nconvex programs in PyTorch and TensorFlow 2.0. Our implementation significantly\nlowers the barrier to using convex optimization problems in differentiable\nprograms. We present applications in linear machine learning models and in\nstochastic control, and we show that our layer is competitive (in execution\ntime) compared to specialized differentiable solvers from past work.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 04:08:18 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Agrawal", "Akshay", ""], ["Amos", "Brandon", ""], ["Barratt", "Shane", ""], ["Boyd", "Stephen", ""], ["Diamond", "Steven", ""], ["Kolter", "Zico", ""]]}, {"id": "1910.12435", "submitter": "Marcel Keller", "authors": "Anders Dalskov and Daniel Escudero and Marcel Keller", "title": "Secure Evaluation of Quantized Neural Networks", "comments": "22 pages", "journal-ref": "Proceedings on Privacy Enhancing Technologies 4 (2020): 355-375", "doi": "10.2478/popets-2020-0077", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We investigate two questions in this paper: First, we ask to what extent \"MPC\nfriendly\" models are already supported by major Machine Learning frameworks\nsuch as TensorFlow or PyTorch. Prior works provide protocols that only work on\nfixed-point integers and specialized activation functions, two aspects that are\nnot supported by popular Machine Learning frameworks, and the need for these\nspecialized model representations means that it is hard, and often impossible,\nto use e.g., TensorFlow to design, train and test models that later have to be\nevaluated securely. Second, we ask to what extent the functionality for\nevaluating Neural Networks already exists in general-purpose MPC frameworks.\nThese frameworks have received more scrutiny, are better documented and\nsupported on more platforms. Furthermore, they are typically flexible in terms\nof the threat model they support. In contrast, most secure evaluation protocols\nin the literature are targeted to a specific threat model and their\nimplementations are only a \"proof-of-concept\", making it very hard for their\nadoption in practice. We answer both of the above questions in a positive way:\nWe observe that the quantization techniques supported by both TensorFlow,\nPyTorch and MXNet can provide models in a representation that can be evaluated\nsecurely; and moreover, that this evaluation can be performed by a general\npurpose MPC framework. We perform extensive benchmarks to understand the exact\ntrade-offs between different corruption models, network sizes and efficiency.\nThese experiments provide an interesting insight into cost between active and\npassive security, as well as honest and dishonest majority. Our work shows then\nthat the separating line between existing ML frameworks and existing MPC\nprotocols may be narrower than implicitly suggested by previous works.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 04:17:33 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 04:22:07 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Dalskov", "Anders", ""], ["Escudero", "Daniel", ""], ["Keller", "Marcel", ""]]}, {"id": "1910.12450", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Chun Kai Ling and Fei Fang and Tuomas Sandholm", "title": "Efficient Regret Minimization Algorithm for Extensive-Form Correlated\n  Equilibrium", "comments": "Full version of NeurIPS 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-play methods based on regret minimization have become the state of the\nart for computing Nash equilibria in large two-players zero-sum extensive-form\ngames. These methods fundamentally rely on the hierarchical structure of the\nplayers' sequential strategy spaces to construct a regret minimizer that\nrecursively minimizes regret at each decision point in the game tree. In this\npaper, we introduce the first efficient regret minimization algorithm for\ncomputing extensive-form correlated equilibria in large two-player general-sum\ngames with no chance moves. Designing such an algorithm is significantly more\nchallenging than designing one for the Nash equilibrium counterpart, as the\nconstraints that define the space of correlation plans lack the hierarchical\nstructure and might even form cycles. We show that some of the constraints are\nredundant and can be excluded from consideration, and present an efficient\nalgorithm that generates the space of extensive-form correlation plans\nincrementally from the remaining constraints. This structural decomposition is\nachieved via a special convexity-preserving operation that we coin scaled\nextension. We show that a regret minimizer can be designed for a scaled\nextension of any two convex sets, and that from the decomposition we then\nobtain a global regret minimizer. Our algorithm produces feasible iterates.\nExperiments show that it significantly outperforms prior approaches and for\nlarger problems it is the only viable option.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 05:28:23 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Farina", "Gabriele", ""], ["Ling", "Chun Kai", ""], ["Fang", "Fei", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1910.12453", "submitter": "Yunzhi Zhang", "authors": "Yunzhi Zhang, Ignasi Clavera, Boren Tsai, Pieter Abbeel", "title": "Asynchronous Methods for Model-Based Reinforcement Learning", "comments": "10 pages, CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant progress has been made in the area of model-based reinforcement\nlearning. State-of-the-art algorithms are now able to match the asymptotic\nperformance of model-free methods while being significantly more data\nefficient. However, this success has come at a price: state-of-the-art\nmodel-based methods require significant computation interleaved with data\ncollection, resulting in run times that take days, even if the amount of agent\ninteraction might be just hours or even minutes. When considering the goal of\nlearning in real-time on real robots, this means these state-of-the-art\nmodel-based algorithms still remain impractical. In this work, we propose an\nasynchronous framework for model-based reinforcement learning methods that\nbrings down the run time of these algorithms to be just the data collection\ntime. We evaluate our asynchronous framework on a range of standard MuJoCo\nbenchmarks. We also evaluate our asynchronous framework on three real-world\nrobotic manipulation tasks. We show how asynchronous learning not only speeds\nup learning w.r.t wall-clock time through parallelization, but also further\nreduces the sample complexity of model-based approaches by means of improving\nthe exploration and by means of effectively avoiding the policy overfitting to\nthe deficiencies of learned dynamics models.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 05:45:39 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhang", "Yunzhi", ""], ["Clavera", "Ignasi", ""], ["Tsai", "Boren", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1910.12454", "submitter": "Alexander Potapov", "authors": "Alexander Potapov, Ian Colbert, Ken Kreutz-Delgado, Alexander\n  Cloninger, and Srinjoy Das", "title": "PT-MMD: A Novel Statistical Framework for the Evaluation of Generative\n  Systems", "comments": "Will be presented at the Asilomar Conference on Signals, Systems, and\n  Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic-sampling-based Generative Neural Networks, such as Restricted\nBoltzmann Machines and Generative Adversarial Networks, are now used for\napplications such as denoising, image occlusion removal, pattern completion,\nand motion synthesis. In scenarios which involve performing such inference\ntasks with these models, it is critical to determine metrics that allow for\nmodel selection and/or maintenance of requisite generative performance under\npre-specified implementation constraints. In this paper, we propose a new\nmetric for evaluating generative model performance based on $p$-values derived\nfrom the combined use of Maximum Mean Discrepancy (MMD) and permutation-based\n(PT-based) resampling, which we refer to as PT-MMD. We demonstrate the\neffectiveness of this metric for two cases: (1) Selection of bitwidth and\nactivation function complexity to achieve minimum power-at-performance for\nRestricted Boltzmann Machines; (2) Quantitative comparison of images generated\nby two types of Generative Adversarial Networks (PGAN and WGAN) to facilitate\nmodel selection in order to maximize the fidelity of generated images. For\nthese applications, our results are shown using Euclidean and Haar-based\nkernels for the PT-MMD two sample hypothesis test. This demonstrates the\ncritical role of distance functions in comparing generated images against their\ncorresponding ground truth counterparts as what would be perceived by human\nusers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 05:50:08 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Potapov", "Alexander", ""], ["Colbert", "Ian", ""], ["Kreutz-Delgado", "Ken", ""], ["Cloninger", "Alexander", ""], ["Das", "Srinjoy", ""]]}, {"id": "1910.12460", "submitter": "Kyle Xiao", "authors": "Kyle Xiao, Houdong Hu, Yan Wang", "title": "Applications of Generative Adversarial Models in Visual Search\n  Reformulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query reformulation is the process by which a input search query is refined\nby the user to match documents outside the original top-n results. On average,\nroughly 50% of text search queries involve some form of reformulation, and term\nsuggestion tools are used 35% of the time when offered to users. As prevalent\nas text search queries are, however, such a feature has yet to be explored at\nscale for visual search. This is because reformulation for images presents a\nnovel challenge to seamlessly transform visual features to match user intent\nwithin the context of a typical user session. In this paper, we present methods\nof semantically transforming visual queries, such as utilizing operations in\nthe latent space of a generative adversarial model for the scenarios of fashion\nand product search.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 06:27:38 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Xiao", "Kyle", ""], ["Hu", "Houdong", ""], ["Wang", "Yan", ""]]}, {"id": "1910.12462", "submitter": "Ankur Goswami", "authors": "Ankur Goswami, Joshua McGrath, Shanan Peters, Theodoros Rekatsinas", "title": "Fine-Grained Object Detection over Scientific Document Images with\n  Region Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We study the problem of object detection over scanned images of scientific\ndocuments. We consider images that contain objects of varying aspect ratios and\nsizes and range from coarse elements such as tables and figures to fine\nelements such as equations and section headers. We find that current object\ndetectors fail to produce properly localized region proposals over such page\nobjects. We revisit the original R-CNN model and present a method for\ngenerating fine-grained proposals over document elements. We also present a\nregion embedding model that uses the convolutional maps of a proposal's\nneighbors as context to produce an embedding for each proposal. This region\nembedding is able to capture the semantic relationships between a target region\nand its surrounding context. Our end-to-end model produces an embedding for\neach proposal, then classifies each proposal by using a multi-head attention\nmodel that attends to the most important neighbors of a proposal. To evaluate\nour model, we collect and annotate a dataset of publications from heterogeneous\njournals. We show that our model, referred to as Attentive-RCNN, yields a 17%\nmAP improvement compared to standard object detection models.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 06:39:02 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 17:25:24 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Goswami", "Ankur", ""], ["McGrath", "Joshua", ""], ["Peters", "Shanan", ""], ["Rekatsinas", "Theodoros", ""]]}, {"id": "1910.12465", "submitter": "Trevon Badloe", "authors": "Trevon Badloe, Inki Kim, and Junsuk Rho", "title": "Biomimetic Ultra-Broadband Perfect Absorbers Optimised with\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1039/C9CP05621A", "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By learning the optimal policy with a double deep Q-learning network, we\ndesign ultra-broadband, biomimetic, perfect absorbers with various materials,\nbased the structure of a moths eye. All absorbers achieve over 90% average\nabsorption from 400 to 1,600 nm. By training a DDQN with motheye structures\nmade up of chromium, we transfer the learned knowledge to other, similar\nmaterials to quickly and efficiently find the optimal parameters from the\naround 1 billion possible options. The knowledge learned from previous\noptimisations helps the network to find the best solution for a new material in\nfewer steps, dramatically increasing the efficiency of finding designs with\nultra-broadband absorption.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 06:58:58 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Badloe", "Trevon", ""], ["Kim", "Inki", ""], ["Rho", "Junsuk", ""]]}, {"id": "1910.12469", "submitter": "Qitian Wu", "authors": "Qitian Wu, Zixuan Zhang, Xiaofeng Gao, Junchi Yan, Guihai Chen", "title": "Learning Latent Process from High-Dimensional Event Sequences via\n  Efficient Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We target modeling latent dynamics in high-dimension marked event sequences\nwithout any prior knowledge about marker relations. Such problem has been\nrarely studied by previous works which would have fundamental difficulty to\nhandle the arisen challenges: 1) the high-dimensional markers and unknown\nrelation network among them pose intractable obstacles for modeling the latent\ndynamic process; 2) one observed event sequence may concurrently contain\nseveral different chains of interdependent events; 3) it is hard to well define\nthe distance between two high-dimension event sequences. To these ends, in this\npaper, we propose a seminal adversarial imitation learning framework for\nhigh-dimension event sequence generation which could be decomposed into: 1) a\nlatent structural intensity model that estimates the adjacent nodes without\nexplicit networks and learns to capture the temporal dynamics in the latent\nspace of markers over observed sequence; 2) an efficient random walk based\ngeneration model that aims at imitating the generation process of\nhigh-dimension event sequences from a bottom-up view; 3) a discriminator\nspecified as a seq2seq network optimizing the rewards to help the generator\noutput event sequences as real as possible. Experimental results on both\nsynthetic and real-world datasets demonstrate that the proposed method could\neffectively detect the hidden network among markers and make decent prediction\nfor future marked events, even when the number of markers scales to million\nlevel.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 07:11:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wu", "Qitian", ""], ["Zhang", "Zixuan", ""], ["Gao", "Xiaofeng", ""], ["Yan", "Junchi", ""], ["Chen", "Guihai", ""]]}, {"id": "1910.12478", "submitter": "Greg Yang", "authors": "Greg Yang", "title": "Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any\n  Architecture are Gaussian Processes", "comments": "Appearing in NeurIPS 2019; 10 pages of main text; 12 figures, 11\n  programs; 73 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide neural networks with random weights and biases are Gaussian processes,\nas originally observed by Neal (1995) and more recently by Lee et al. (2018)\nand Matthews et al. (2018) for deep fully-connected networks, as well as by\nNovak et al. (2019) and Garriga-Alonso et al. (2019) for deep convolutional\nnetworks. We show that this Neural Network-Gaussian Process correspondence\nsurprisingly extends to all modern feedforward or recurrent neural networks\ncomposed of multilayer perceptron, RNNs (e.g. LSTMs, GRUs), (nD or graph)\nconvolution, pooling, skip connection, attention, batch normalization, and/or\nlayer normalization. More generally, we introduce a language for expressing\nneural network computations, and our result encompasses all such expressible\nneural networks. This work serves as a tutorial on the *tensor programs*\ntechnique formulated in Yang (2019) and elucidates the Gaussian Process results\nobtained there. We provide open-source implementations of the Gaussian Process\nkernels of simple RNN, GRU, transformer, and batchnorm+ReLU network at\ngithub.com/thegregyang/GP4A.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 07:31:59 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 08:48:14 GMT"}, {"version": "v3", "created": "Sat, 8 May 2021 12:45:18 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yang", "Greg", ""]]}, {"id": "1910.12481", "submitter": "Justin Cosentino", "authors": "Justin Cosentino, Jun Zhu", "title": "Generative Well-intentioned Networks", "comments": "17 pages, 9 figures, 8 tables, to appear in the proceedings of\n  Advances in Neural Information Processing Systems (NeurIPS), Vancouver,\n  Canada, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Generative Well-intentioned Networks (GWINs), a novel framework\nfor increasing the accuracy of certainty-based, closed-world classifiers. A\nconditional generative network recovers the distribution of observations that\nthe classifier labels correctly with high certainty. We introduce a reject\noption to the classifier during inference, allowing the classifier to reject an\nobservation instance rather than predict an uncertain label. These rejected\nobservations are translated by the generative network to high-certainty\nrepresentations, which are then relabeled by the classifier. This architecture\nallows for any certainty-based classifier or rejection function and is not\nlimited to multilayer perceptrons. The capability of this framework is assessed\nusing benchmark classification datasets and shows that GWINs significantly\nimprove the accuracy of uncertain observations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 07:40:41 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Cosentino", "Justin", ""], ["Zhu", "Jun", ""]]}, {"id": "1910.12490", "submitter": "Wasim Huleihel", "authors": "Wasim Huleihel, Arya Mazumdar, Muriel M\\'edard, and Soumyabrata Pal", "title": "Same-Cluster Querying for Overlapping Clusters", "comments": "43 pages, accepted at NeurIPS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overlapping clusters are common in models of many practical data-segmentation\napplications. Suppose we are given $n$ elements to be clustered into $k$\npossibly overlapping clusters, and an oracle that can interactively answer\nqueries of the form \"do elements $u$ and $v$ belong to the same cluster?\" The\ngoal is to recover the clusters with minimum number of such queries. This\nproblem has been of recent interest for the case of disjoint clusters. In this\npaper, we look at the more practical scenario of overlapping clusters, and\nprovide upper bounds (with algorithms) on the sufficient number of queries. We\nprovide algorithmic results under both arbitrary (worst-case) and statistical\nmodeling assumptions. Our algorithms are parameter free, efficient, and work in\nthe presence of random noise. We also derive information-theoretic lower bounds\non the number of queries needed, proving that our algorithms are order optimal.\nFinally, we test our algorithms over both synthetic and real-world data,\nshowing their practicality and effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 08:06:20 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Huleihel", "Wasim", ""], ["Mazumdar", "Arya", ""], ["M\u00e9dard", "Muriel", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "1910.12511", "submitter": "Sebastian Curi", "authors": "Sebastian Curi, Kfir. Y. Levy, Stefanie Jegelka, Andreas Krause", "title": "Adaptive Sampling for Stochastic Risk-Averse Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high-stakes machine learning applications, it is crucial to not only\nperform well on average, but also when restricted to difficult examples. To\naddress this, we consider the problem of training models in a risk-averse\nmanner. We propose an adaptive sampling algorithm for stochastically optimizing\nthe Conditional Value-at-Risk (CVaR) of a loss distribution, which measures its\nperformance on the $\\alpha$ fraction of most difficult examples. We use a\ndistributionally robust formulation of the CVaR to phrase the problem as a\nzero-sum game between two players, and solve it efficiently using regret\nminimization. Our approach relies on sampling from structured Determinantal\nPoint Processes (DPPs), which enables scaling it to large data sets. Finally,\nwe empirically demonstrate its effectiveness on large-scale convex and\nnon-convex learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 09:12:36 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 16:26:40 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 13:02:17 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Curi", "Sebastian", ""], ["Levy", "Kfir. Y.", ""], ["Jegelka", "Stefanie", ""], ["Krause", "Andreas", ""]]}, {"id": "1910.12514", "submitter": "Jiexiang Wang", "authors": "Jiexiang Wang, Hongyu Huang, Chaoqi Chen, Wenao Ma, Yue Huang, Xinghao\n  Ding", "title": "Multi-sequence Cardiac MR Segmentation with Adversarial Domain\n  Adaptation Network", "comments": "10th Workshop on Statistical Atlases and Computational Modelling of\n  the Heart (MICCAI2019 Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic and accurate segmentation of the ventricles and myocardium from\nmulti-sequence cardiac MRI (CMR) is crucial for the diagnosis and treatment\nmanagement for patients suffering from myocardial infarction (MI). However, due\nto the existence of domain shift among different modalities of datasets, the\nperformance of deep neural networks drops significantly when the training and\ntesting datasets are distinct. In this paper, we propose an unsupervised domain\nalignment method to explicitly alleviate the domain shifts among different\nmodalities of CMR sequences, \\emph{e.g.,} bSSFP, LGE, and T2-weighted. Our\nsegmentation network is attention U-Net with pyramid pooling module, where\nmulti-level feature space and output space adversarial learning are proposed to\ntransfer discriminative domain knowledge across different datasets. Moreover,\nwe further introduce a group-wise feature recalibration module to enforce the\nfine-grained semantic-level feature alignment that matching features from\ndifferent networks but with the same class label. We evaluate our method on the\nmulti-sequence cardiac MR Segmentation Challenge 2019 datasets, which contain\nthree different modalities of MRI sequences. Extensive experimental results\nshow that the proposed methods can obtain significant segmentation improvements\ncompared with the baseline models.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 09:20:23 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wang", "Jiexiang", ""], ["Huang", "Hongyu", ""], ["Chen", "Chaoqi", ""], ["Ma", "Wenao", ""], ["Huang", "Yue", ""], ["Ding", "Xinghao", ""]]}, {"id": "1910.12521", "submitter": "Belhal Karimi", "authors": "Belhal Karimi, Hoi-To Wai, Eric Moulines, Marc Lavielle", "title": "On the Global Convergence of (Fast) Incremental Expectation Maximization\n  Methods", "comments": "25 pages, Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EM algorithm is one of the most popular algorithm for inference in latent\ndata models. The original formulation of the EM algorithm does not scale to\nlarge data set, because the whole data set is required at each iteration of the\nalgorithm. To alleviate this problem, Neal and Hinton have proposed an\nincremental version of the EM (iEM) in which at each iteration the conditional\nexpectation of the latent data (E-step) is updated only for a mini-batch of\nobservations. Another approach has been proposed by Capp\\'e and Moulines in\nwhich the E-step is replaced by a stochastic approximation step, closely\nrelated to stochastic gradient. In this paper, we analyze incremental and\nstochastic version of the EM algorithm as well as the variance reduced-version\nof Chen et. al. in a common unifying framework. We also introduce a new version\nincremental version, inspired by the SAGA algorithm by Defazio et. al. We\nestablish non-asymptotic convergence bounds for global convergence. Numerical\napplications are presented in this article to illustrate our findings.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 09:51:14 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Karimi", "Belhal", ""], ["Wai", "Hoi-To", ""], ["Moulines", "Eric", ""], ["Lavielle", "Marc", ""]]}, {"id": "1910.12548", "submitter": "Alexander Hepburn", "authors": "Alexander Hepburn, Valero Laparra, Jes\\'us Malo, Ryan McConville, Raul\n  Santos-Rodriguez", "title": "PerceptNet: A Human Visual System Inspired Neural Network for Estimating\n  Perceptual Distance", "comments": null, "journal-ref": "2020 IEEE International Conference on Image Processing (ICIP), Abu\n  Dhabi, United Arab Emirates, 2020, pp. 121-125", "doi": "10.1109/ICIP40778.2020.9190691", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, the vision community has devised algorithms to estimate the\ndistance between an original image and images that have been subject to\nperturbations. Inspiration was usually taken from the human visual perceptual\nsystem and how the system processes different perturbations in order to\nreplicate to what extent it determines our ability to judge image quality.\nWhile recent works have presented deep neural networks trained to predict human\nperceptual quality, very few borrow any intuitions from the human visual\nsystem. To address this, we present PerceptNet, a convolutional neural network\nwhere the architecture has been chosen to reflect the structure and various\nstages in the human visual system. We evaluate PerceptNet on various\ntraditional perception datasets and note strong performance on a number of them\nas compared with traditional image quality metrics. We also show that including\na nonlinearity inspired by the human visual system in classical deep neural\nnetworks architectures can increase their ability to judge perceptual\nsimilarity. Compared to similar deep learning methods, the performance is\nsimilar, although our network has a number of parameters that is several orders\nof magnitude less.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 10:48:30 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 10:33:43 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hepburn", "Alexander", ""], ["Laparra", "Valero", ""], ["Malo", "Jes\u00fas", ""], ["McConville", "Ryan", ""], ["Santos-Rodriguez", "Raul", ""]]}, {"id": "1910.12551", "submitter": "Furkan Yesiler", "authors": "Furkan Yesiler, Joan Serr\\`a, Emilia G\\'omez", "title": "Accurate and Scalable Version Identification Using Musically-Motivated\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The version identification (VI) task deals with the automatic detection of\nrecordings that correspond to the same underlying musical piece. Despite many\nefforts, VI is still an open problem, with much room for improvement, specially\nwith regard to combining accuracy and scalability. In this paper, we present\nMOVE, a musically-motivated method for accurate and scalable version\nidentification. MOVE achieves state-of-the-art performance on two\npublicly-available benchmark sets by learning scalable embeddings in an\nEuclidean distance space, using a triplet loss and a hard triplet mining\nstrategy. It improves over previous work by employing an alternative input\nrepresentation, and introducing a novel technique for temporal content\nsummarization, a standardized latent space, and a data augmentation strategy\nspecifically designed for VI. In addition to the main results, we perform an\nablation study to highlight the importance of our design choices, and study the\nrelation between embedding dimensionality and model performance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 10:54:53 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 12:40:10 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Yesiler", "Furkan", ""], ["Serr\u00e0", "Joan", ""], ["G\u00f3mez", "Emilia", ""]]}, {"id": "1910.12554", "submitter": "Yingbo Gao", "authors": "Yingbo Gao, Christian Herold, Weiyue Wang, Hermann Ney", "title": "Exploring Kernel Functions in the Softmax Layer for Contextual Word\n  Classification", "comments": "IWSLT2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prominently used in support vector machines and logistic regressions, kernel\nfunctions (kernels) can implicitly map data points into high dimensional spaces\nand make it easier to learn complex decision boundaries. In this work, by\nreplacing the inner product function in the softmax layer, we explore the use\nof kernels for contextual word classification. In order to compare the\nindividual kernels, experiments are conducted on standard language modeling and\nmachine translation tasks. We observe a wide range of performances across\ndifferent kernel settings. Extending the results, we look at the gradient\nproperties, investigate various mixture strategies and examine the\ndisambiguation abilities.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 11:06:21 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Gao", "Yingbo", ""], ["Herold", "Christian", ""], ["Wang", "Weiyue", ""], ["Ney", "Hermann", ""]]}, {"id": "1910.12574", "submitter": "Marzieh Mozafari", "authors": "Marzieh Mozafari, Reza Farahbakhsh, Noel Crespi", "title": "A BERT-Based Transfer Learning Approach for Hate Speech Detection in\n  Online Social Media", "comments": "This paper has been accepted in The 8th International Conference on\n  Complex Networks and their Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generated hateful and toxic content by a portion of users in social media is\na rising phenomenon that motivated researchers to dedicate substantial efforts\nto the challenging direction of hateful content identification. We not only\nneed an efficient automatic hate speech detection model based on advanced\nmachine learning and natural language processing, but also a sufficiently large\namount of annotated data to train a model. The lack of a sufficient amount of\nlabelled hate speech data, along with the existing biases, has been the main\nissue in this domain of research. To address these needs, in this study we\nintroduce a novel transfer learning approach based on an existing pre-trained\nlanguage model called BERT (Bidirectional Encoder Representations from\nTransformers). More specifically, we investigate the ability of BERT at\ncapturing hateful context within social media content by using new fine-tuning\nmethods based on transfer learning. To evaluate our proposed approach, we use\ntwo publicly available datasets that have been annotated for racism, sexism,\nhate, or offensive content on Twitter. The results show that our solution\nobtains considerable performance on these datasets in terms of precision and\nrecall in comparison to existing approaches. Consequently, our model can\ncapture some biases in data annotation and collection process and can\npotentially lead us to a more accurate model.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 12:13:38 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mozafari", "Marzieh", ""], ["Farahbakhsh", "Reza", ""], ["Crespi", "Noel", ""]]}, {"id": "1910.12577", "submitter": "Chunxi Tan", "authors": "Ruijian Han, Kani Chen and Chunxi Tan", "title": "Curiosity-Driven Recommendation Strategy for Adaptive Learning via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of recommendations strategies in the adaptive learning system\nfocuses on utilizing currently available information to provide\nindividual-specific learning instructions for learners. As a critical motivate\nfor human behaviors, curiosity is essentially the drive to explore knowledge\nand seek information. In a psychologically inspired view, we aim to incorporate\nthe element of curiosity for guiding learners to study spontaneously. In this\npaper, a curiosity-driven recommendation policy is proposed under the\nreinforcement learning framework, allowing for a both efficient and enjoyable\npersonalized learning mode. Given intrinsic rewards from a well-designed\npredictive model, we apply the actor-critic method to approximate the policy\ndirectly through neural networks. Numeric analyses with a large continuous\nknowledge state space and concrete learning scenarios are used to further\ndemonstrate the power of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 02:59:16 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Han", "Ruijian", ""], ["Chen", "Kani", ""], ["Tan", "Chunxi", ""]]}, {"id": "1910.12586", "submitter": "Yongkai Wu", "authors": "Yongkai Wu, Lu Zhang, Xintao Wu, Hanghang Tong", "title": "PC-Fairness: A Unified Framework for Measuring Causality-based Fairness", "comments": "Accepted as a poster to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent trend of fair machine learning is to define fairness as\ncausality-based notions which concern the causal connection between protected\nattributes and decisions. However, one common challenge of all causality-based\nfairness notions is identifiability, i.e., whether they can be uniquely\nmeasured from observational data, which is a critical barrier to applying these\nnotions to real-world situations. In this paper, we develop a framework for\nmeasuring different causality-based fairness. We propose a unified definition\nthat covers most of previous causality-based fairness notions, namely the\npath-specific counterfactual fairness (PC fairness). Based on that, we propose\na general method in the form of a constrained optimization problem for bounding\nthe path-specific counterfactual fairness under all unidentifiable situations.\nExperiments on synthetic and real-world datasets show the correctness and\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 23:00:53 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wu", "Yongkai", ""], ["Zhang", "Lu", ""], ["Wu", "Xintao", ""], ["Tong", "Hanghang", ""]]}, {"id": "1910.12587", "submitter": "Tyler Lee", "authors": "Tyler Lee, Ting Gong, Suchismita Padhy, Andrew Rouditchenko, Anthony\n  Ndirango", "title": "Label-efficient audio classification through multitask learning and\n  self-supervision", "comments": "Presented at ICLR 2019 Limited Labeled Data (LLD) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has been incredibly successful in modeling tasks with\nlarge, carefully curated labeled datasets, its application to problems with\nlimited labeled data remains a challenge. The aim of the present work is to\nimprove the label efficiency of large neural networks operating on audio data\nthrough a combination of multitask learning and self-supervised learning on\nunlabeled data. We trained an end-to-end audio feature extractor based on\nWaveNet that feeds into simple, yet versatile task-specific neural networks. We\ndescribe several easily implemented self-supervised learning tasks that can\noperate on any large, unlabeled audio corpus. We demonstrate that, in scenarios\nwith limited labeled training data, one can significantly improve the\nperformance of three different supervised classification tasks individually by\nup to 6% through simultaneous training with these additional self-supervised\ntasks. We also show that incorporating data augmentation into our multitask\nsetting leads to even further gains in performance.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 00:58:30 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Lee", "Tyler", ""], ["Gong", "Ting", ""], ["Padhy", "Suchismita", ""], ["Rouditchenko", "Andrew", ""], ["Ndirango", "Anthony", ""]]}, {"id": "1910.12589", "submitter": "Ramya Akula", "authors": "Ramya Akula, Zachary Wieselthier, Laura Martin, Ivan Garibay", "title": "Forecasting the Success of Television Series using Machine Learning", "comments": "9 Pages, 10 Figures and 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Television is an ever-evolving multi billion dollar industry. The success of\na television show in an increasingly technological society is a vast\nmulti-variable formula. The art of success is not just something that happens,\nbut is studied, replicated, and applied. Hollywood can be unpredictable\nregarding success, as many movies and sitcoms that are hyped up and promise to\nbe a hit end up being box office failures and complete disappointments. In\ncurrent studies, linguistic exploration is being performed on the relationship\nbetween Television series and target community of viewers. Having a decision\nsupport system that can display sound and predictable results would be needed\nto build confidence in the investment of a new TV series. The models presented\nin this study use data to study and determine what makes a sitcom successful.\nIn this paper, we use descriptive and predictive modeling techniques to assess\nthe continuing success of television comedies: The Office, Big Bang Theory,\nArrested Development, Scrubs, and South Park. The factors that are tested for\nstatistical significance on episode ratings are character presence, director,\nand writer. These statistics show that while characters are indeed crucial to\nthe shows themselves, the creation and direction of the shows pose implication\nupon the ratings and therefore the success of the shows. We use machine\nlearning based forecasting models to accurately predict the success of shows.\nThe models represent a baseline to understanding the success of a television\nshow and how producers can increase the success of current television shows or\nutilize this data in the creation of future shows. Due to the many factors that\ngo into a series, the empirical analysis in this work shows that there is no\none-fits-all model to forecast the rating or success of a television show.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 01:46:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Akula", "Ramya", ""], ["Wieselthier", "Zachary", ""], ["Martin", "Laura", ""], ["Garibay", "Ivan", ""]]}, {"id": "1910.12590", "submitter": "Tedd Kourkounakis", "authors": "Tedd Kourkounakis, Amirhossein Hajavi, Ali Etemad", "title": "Detecting Multiple Speech Disfluencies using a Deep Residual Network\n  with Bidirectional Long Short-Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stuttering is a speech impediment affecting tens of millions of people on an\neveryday basis. Even with its commonality, there is minimal data and research\non the identification and classification of stuttered speech. This paper\ntackles the problem of detection and classification of different forms of\nstutter. As opposed to most existing works that identify stutters with language\nmodels, our work proposes a model that relies solely on acoustic features,\nallowing for identification of several variations of stutter disfluencies\nwithout the need for speech recognition. Our model uses a deep residual network\nand bidirectional long short-term memory layers to classify different types of\nstutters and achieves an average miss rate of 10.03%, outperforming the\nstate-of-the-art by almost 27%\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 21:32:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kourkounakis", "Tedd", ""], ["Hajavi", "Amirhossein", ""], ["Etemad", "Ali", ""]]}, {"id": "1910.12597", "submitter": "Richard Scruggs", "authors": "Richard Scruggs, Ryan S. Baker, Bruce M. McLaren", "title": "Extending Deep Knowledge Tracing: Inferring Interpretable Knowledge and\n  Predicting Post-System Performance", "comments": "8 pages, accepted to the International Conference on Computers in\n  Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent student knowledge modeling algorithms such as Deep Knowledge Tracing\n(DKT) and Dynamic Key-Value Memory Networks (DKVMN) have been shown to produce\naccurate predictions of problem correctness within the same learning system.\nHowever, these algorithms do not attempt to directly infer student knowledge.\nIn this paper we present an extension to these algorithms to also infer\nknowledge. We apply this extension to DKT and DKVMN, resulting in knowledge\nestimates that correlate better with a posttest than knowledge estimates from\nBayesian Knowledge Tracing (BKT), an algorithm designed to infer knowledge, and\nanother classic algorithm, Performance Factors Analysis (PFA). We also apply\nour extension to correctness predictions from BKT and PFA, finding that\nknowledge estimates produced with it correlate better with the posttest than\nBKT and PFA's standard knowledge estimates. These findings are significant\nsince the primary aim of education is to prepare students for later experiences\noutside of the immediate learning activity.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 14:21:20 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 19:33:54 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Scruggs", "Richard", ""], ["Baker", "Ryan S.", ""], ["McLaren", "Bruce M.", ""]]}, {"id": "1910.12601", "submitter": "Meixin Zhu", "authors": "Meixin Zhu, Jingyun Hu, Hao (Frank) Yang, Ziyuan Pu, and Yinhai Wang", "title": "Personalized Context-Aware Multi-Modal Transportation Recommendation", "comments": "KDD cup 2019 regular machine track solution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes to find the most appropriate transport modes with\nawareness of user preferences (e.g., costs, times) and trip characteristics\n(e.g., purpose, distance). The work was based on real-life trips obtained from\na map application. Several methods including gradient boosting tree, learning\nto rank, multinomial logit model, automated machine learning, random forest,\nand shallow neural network have been tried. For some methods, feature selection\nand over-sampling techniques were also tried. The results show that the best\nperforming method is a gradient boosting tree model with synthetic minority\nover-sampling technique (SMOTE). Also, results of the multinomial logit model\nshow that (1) an increase in travel cost would decrease the utility of all the\ntransportation modes; (2) people are less sensitive to the travel distance for\nthe metro mode or a multi-modal option that containing metro, i.e., compared to\nother modes, people would be more willing to tolerate long-distance metro\ntrips. This indicates that metro lines might be a good candidate for large\ncities.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 20:16:13 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhu", "Meixin", "", "Frank"], ["Hu", "Jingyun", "", "Frank"], ["Hao", "", "", "Frank"], ["Yang", "", ""], ["Pu", "Ziyuan", ""], ["Wang", "Yinhai", ""]]}, {"id": "1910.12603", "submitter": "Jonathan Passerat-Palmbach", "authors": "Jonathan Passerat-Palmbach and Tyler Farnan and Robert Miller and\n  Marielle S. Gross and Heather Leigh Flannery and Bill Gleim", "title": "A blockchain-orchestrated Federated Learning architecture for healthcare\n  consortia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a novel architecture for federated learning within healthcare\nconsortia. At the heart of the solution is a unique integration of privacy\npreserving technologies, built upon native enterprise blockchain components\navailable in the Ethereum ecosystem. We show how the specific characteristics\nand challenges of healthcare consortia informed our design choices, notably the\nconception of a new Secure Aggregation protocol assembled with a protected\nhardware component and an encryption toolkit native to Ethereum. Our\narchitecture also brings in a privacy preserving audit trail that logs events\nin the network without revealing identities.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 16:44:05 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Passerat-Palmbach", "Jonathan", ""], ["Farnan", "Tyler", ""], ["Miller", "Robert", ""], ["Gross", "Marielle S.", ""], ["Flannery", "Heather Leigh", ""], ["Gleim", "Bill", ""]]}, {"id": "1910.12607", "submitter": "Yu-An Chung", "authors": "Yu-An Chung, James Glass", "title": "Generative Pre-Training for Speech with Autoregressive Predictive Coding", "comments": "Accepted to ICASSP 2020. Code and pre-trained models are available at\n  https://github.com/iamyuanchung/Autoregressive-Predictive-Coding", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning meaningful and general representations from unannotated speech that\nare applicable to a wide range of tasks remains challenging. In this paper we\npropose to use autoregressive predictive coding (APC), a recently proposed\nself-supervised objective, as a generative pre-training approach for learning\nmeaningful, non-specific, and transferable speech representations. We pre-train\nAPC on large-scale unlabeled data and conduct transfer learning experiments on\nthree speech applications that require different information about speech\ncharacteristics to perform well: speech recognition, speech translation, and\nspeaker identification. Extensive experiments show that APC not only\noutperforms surface features (e.g., log Mel spectrograms) and other popular\nrepresentation learning methods on all three tasks, but is also effective at\nreducing downstream labeled data size and model parameters. We also investigate\nthe use of Transformers for modeling APC and find it superior to RNNs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:28:51 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 09:36:23 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chung", "Yu-An", ""], ["Glass", "James", ""]]}, {"id": "1910.12611", "submitter": "Shaoxiong Ji", "authors": "Shaoxiong Ji and Shirui Pan and Xue Li and Erik Cambria and Guodong\n  Long and Zi Huang", "title": "Suicidal Ideation Detection: A Review of Machine Learning Methods and\n  Applications", "comments": "IEEE Transactions on Computational Social Systems", "journal-ref": "IEEE Transactions on Computational Social Systems, 8(1), 2021, pp.\n  214-226", "doi": "10.1109/TCSS.2020.3021467", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suicide is a critical issue in modern society. Early detection and prevention\nof suicide attempts should be addressed to save people's life. Current suicidal\nideation detection methods include clinical methods based on the interaction\nbetween social workers or experts and the targeted individuals and machine\nlearning techniques with feature engineering or deep learning for automatic\ndetection based on online social contents. This paper is the first survey that\ncomprehensively introduces and discusses the methods from these categories.\nDomain-specific applications of suicidal ideation detection are reviewed\naccording to their data sources, i.e., questionnaires, electronic health\nrecords, suicide notes, and online user content. Several specific tasks and\ndatasets are introduced and summarized to facilitate further research. Finally,\nwe summarize the limitations of current work and provide an outlook of further\nresearch directions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 02:10:42 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 11:04:42 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 09:49:48 GMT"}, {"version": "v4", "created": "Sun, 6 Sep 2020 06:12:03 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ji", "Shaoxiong", ""], ["Pan", "Shirui", ""], ["Li", "Xue", ""], ["Cambria", "Erik", ""], ["Long", "Guodong", ""], ["Huang", "Zi", ""]]}, {"id": "1910.12612", "submitter": "Duc Le", "authors": "Duc Le, Thilo Koehler, Christian Fuegen, Michael L. Seltzer", "title": "G2G: TTS-Driven Pronunciation Learning for Graphemic Hybrid ASR", "comments": "To appear at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grapheme-based acoustic modeling has recently been shown to outperform\nphoneme-based approaches in both hybrid and end-to-end automatic speech\nrecognition (ASR), even on non-phonemic languages like English. However,\ngraphemic ASR still has problems with rare long-tail words that do not follow\nthe standard spelling conventions seen in training, such as entity names. In\nthis work, we present a novel method to train a statistical\ngrapheme-to-grapheme (G2G) model on text-to-speech data that can rewrite an\narbitrary character sequence into more phonetically consistent forms. We show\nthat using G2G to provide alternative pronunciations during decoding reduces\nWord Error Rate by 3% to 11% relative over a strong graphemic baseline and\nbridges the gap on rare name recognition with an equivalent phonetic setup.\nUnlike many previously proposed methods, our method does not require any change\nto the acoustic model training procedure. This work reaffirms the efficacy of\ngrapheme-based modeling and shows that specialized linguistic knowledge, when\navailable, can be leveraged to improve graphemic ASR.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 21:49:50 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 21:24:48 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Le", "Duc", ""], ["Koehler", "Thilo", ""], ["Fuegen", "Christian", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "1910.12614", "submitter": "Nicolas Obin", "authors": "Rafael Ferro, Nicolas Obin, Axel Roebel", "title": "CycleGAN Voice Conversion of Spectral Envelopes using Adversarial\n  Weights", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles GAN optimization and stability issues in the context of\nvoice conversion. First, to simplify the conversion task, we propose to use\nspectral envelopes as inputs. Second we propose two adversarial weight training\nparadigms, the generalized weighted GAN and the generator impact GAN, both aim\nat reducing the impact of the generator on the discriminator, so both can learn\nmore gradually and efficiently during training. Applying an energy constraint\nto the cycleGAN paradigm considerably improved conversion quality. A subjective\nexperiment conducted on a voice conversion task on the voice conversion\nchallenge 2018 dataset shows first that despite a significantly reduced network\ncomplexity, the proposed method achieves state-of-the-art results, and second\nthat the proposed weighted GAN methods outperform a previously proposed one.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 12:18:18 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 14:43:03 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Ferro", "Rafael", ""], ["Obin", "Nicolas", ""], ["Roebel", "Axel", ""]]}, {"id": "1910.12618", "submitter": "David Obst", "authors": "David Obst and Badih Ghattas and Sandra Claudel and Jairo Cugliari and\n  Yannig Goude and Georges Oppenheim", "title": "Textual Data for Time Series Forecasting", "comments": "-Added e-mail addresses of authors. -Added author who didn't appear\n  on the paper's arXiv page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While ubiquitous, textual sources of information such as company reports,\nsocial media posts, etc. are hardly included in prediction algorithms for time\nseries, despite the relevant information they may contain. In this work, openly\naccessible daily weather reports from France and the United-Kingdom are\nleveraged to predict time series of national electricity consumption, average\ntemperature and wind-speed with a single pipeline. Two methods of numerical\nrepresentation of text are considered, namely traditional Term Frequency -\nInverse Document Frequency (TF-IDF) as well as our own neural word embedding.\nUsing exclusively text, we are able to predict the aforementioned time series\nwith sufficient accuracy to be used to replace missing data. Furthermore the\nproposed word embeddings display geometric properties relating to the behavior\nof the time series and context similarity between words.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 07:47:56 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 09:39:06 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Obst", "David", ""], ["Ghattas", "Badih", ""], ["Claudel", "Sandra", ""], ["Cugliari", "Jairo", ""], ["Goude", "Yannig", ""], ["Oppenheim", "Georges", ""]]}, {"id": "1910.12620", "submitter": "Sherif Abdulatif", "authors": "Sherif Abdulatif, Karim Armanious, Karim Guirguis, Jayasankar T.\n  Sajeev, Bin Yang", "title": "AeGAN: Time-Frequency Speech Denoising via Generative Adversarial\n  Networks", "comments": "5 pages, 4 figures and 2 Tables. Accepted in EUSIPCO 2020", "journal-ref": null, "doi": "10.23919/Eusipco47968.2020.9287606", "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) systems are of vital importance nowadays\nin commonplace tasks such as speech-to-text processing and language\ntranslation. This created the need for an ASR system that can operate in\nrealistic crowded environments. Thus, speech enhancement is a valuable building\nblock in ASR systems and other applications such as hearing aids, smartphones\nand teleconferencing systems. In this paper, a generative adversarial network\n(GAN) based framework is investigated for the task of speech enhancement, more\nspecifically speech denoising of audio tracks. A new architecture based on\nCasNet generator and an additional feature-based loss are incorporated to get\nrealistically denoised speech phonetics. Finally, the proposed framework is\nshown to outperform other learning and traditional model-based speech\nenhancement approaches.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:27:22 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 19:55:22 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 00:10:35 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Abdulatif", "Sherif", ""], ["Armanious", "Karim", ""], ["Guirguis", "Karim", ""], ["Sajeev", "Jayasankar T.", ""], ["Yang", "Bin", ""]]}, {"id": "1910.12621", "submitter": "Ethan Manilow", "authors": "Ethan Manilow, Prem Seetharaman, Bryan Pardo", "title": "Simultaneous Separation and Transcription of Mixtures with Multiple\n  Polyphonic and Percussive Instruments", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a single deep learning architecture that can both separate an\naudio recording of a musical mixture into constituent single-instrument\nrecordings and transcribe these instruments into a human-readable format at the\nsame time, learning a shared musical representation for both tasks. This novel\narchitecture, which we call Cerberus, builds on the Chimera network for source\nseparation by adding a third \"head\" for transcription. By training each head\nwith different losses, we are able to jointly learn how to separate and\ntranscribe up to 5 instruments in our experiments with a single network. We\nshow that the two tasks are highly complementary with one another and when\nlearned jointly, lead to Cerberus networks that are better at both separation\nand transcription and generalize better to unseen mixtures.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 04:46:34 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 22:14:54 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Manilow", "Ethan", ""], ["Seetharaman", "Prem", ""], ["Pardo", "Bryan", ""]]}, {"id": "1910.12625", "submitter": "Erwei Wang", "authors": "Erwei Wang, James J. Davis, Peter Y. K. Cheung, George A.\n  Constantinides", "title": "LUTNet: Learning FPGA Configurations for Highly Efficient Neural Network\n  Inference", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.00938.\n  Accepted manuscript uploaded 02/03/20. DOA 01/03/20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research has shown that deep neural networks contain significant redundancy,\nand thus that high classification accuracy can be achieved even when weights\nand activations are quantized down to binary values. Network binarization on\nFPGAs greatly increases area efficiency by replacing resource-hungry\nmultipliers with lightweight XNOR gates. However, an FPGA's fundamental\nbuilding block, the K-LUT, is capable of implementing far more than an XNOR: it\ncan perform any K-input Boolean operation. Inspired by this observation, we\npropose LUTNet, an end-to-end hardware-software framework for the construction\nof area-efficient FPGA-based neural network accelerators using the native LUTs\nas inference operators. We describe the realization of both unrolled and tiled\nLUTNet architectures, with the latter facilitating smaller, less power-hungry\ndeployment over the former while sacrificing area and energy efficiency along\nwith throughput. For both varieties, we demonstrate that the exploitation of\nLUT flexibility allows for far heavier pruning than possible in prior works,\nresulting in significant area savings while achieving comparable accuracy.\nAgainst the state-of-the-art binarized neural network implementation, we\nachieve up to twice the area efficiency for several standard network models\nwhen inferencing popular datasets. We also demonstrate that even greater energy\nefficiency improvements are obtainable.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 00:04:56 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 23:26:43 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Wang", "Erwei", ""], ["Davis", "James J.", ""], ["Cheung", "Peter Y. K.", ""], ["Constantinides", "George A.", ""]]}, {"id": "1910.12626", "submitter": "Alisa Liu", "authors": "Alisa Liu, Prem Seetharaman, Bryan Pardo", "title": "Model selection for deep audio source separation via clustering analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio source separation is the process of separating a mixture (e.g. a pop\nband recording) into isolated sounds from individual sources (e.g. just the\nlead vocals). Deep learning models are the state-of-the-art in source\nseparation, given that the mixture to be separated is similar to the mixtures\nthe deep model was trained on. This requires the end user to know enough about\neach model's training to select the correct model for a given audio mixture. In\nthis work, we automate selection of the appropriate model for an audio mixture.\nWe present a confidence measure that does not require ground truth to estimate\nseparation quality, given a deep model and audio mixture. We use this\nconfidence measure to automatically select the model output with the best\npredicted separation quality. We compare our confidence-based ensemble approach\nto using individual models with no selection, to an oracle that always selects\nthe best model and to a random model selector. Results show our\nconfidence-based ensemble significantly outperforms the random ensemble over\ngeneral mixtures and approaches oracle performance for music mixtures.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 18:09:31 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 19:28:28 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Liu", "Alisa", ""], ["Seetharaman", "Prem", ""], ["Pardo", "Bryan", ""]]}, {"id": "1910.12638", "submitter": "Andy T. Liu", "authors": "Andy T. Liu, Shu-wen Yang, Po-Han Chi, Po-chun Hsu, Hung-yi Lee", "title": "Mockingjay: Unsupervised Speech Representation Learning with Deep\n  Bidirectional Transformer Encoders", "comments": "Accepted by ICASSP 2020, Lecture Session", "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP40776.2020.9054458", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Mockingjay as a new speech representation learning approach, where\nbidirectional Transformer encoders are pre-trained on a large amount of\nunlabeled speech. Previous speech representation methods learn through\nconditioning on past frames and predicting information about future frames.\nWhereas Mockingjay is designed to predict the current frame through jointly\nconditioning on both past and future contexts. The Mockingjay representation\nimproves performance for a wide range of downstream tasks, including phoneme\nclassification, speaker recognition, and sentiment classification on spoken\ncontent, while outperforming other approaches. Mockingjay is empirically\npowerful and can be fine-tuned with downstream models, with only 2 epochs we\nfurther improve performance dramatically. In a low resource setting with only\n0.1% of labeled data, we outperform the result of Mel-features that uses all\n100% labeled data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 01:55:12 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 15:08:39 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Liu", "Andy T.", ""], ["Yang", "Shu-wen", ""], ["Chi", "Po-Han", ""], ["Hsu", "Po-chun", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1910.12647", "submitter": "Mehrad Moradshahi", "authors": "Mehrad Moradshahi, Hamid Palangi, Monica S. Lam, Paul Smolensky,\n  Jianfeng Gao", "title": "HUBERT Untangles BERT to Improve Transfer across NLP Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce HUBERT which combines the structured-representational power of\nTensor-Product Representations (TPRs) and BERT, a pre-trained bidirectional\nTransformer language model. We show that there is shared structure between\ndifferent NLP datasets that HUBERT, but not BERT, is able to learn and\nleverage. We validate the effectiveness of our model on the GLUE benchmark and\nHANS dataset. Our experiment results show that untangling data-specific\nsemantics from general language structure is key for better transfer among NLP\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 06:25:25 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 23:42:01 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Moradshahi", "Mehrad", ""], ["Palangi", "Hamid", ""], ["Lam", "Monica S.", ""], ["Smolensky", "Paul", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1910.12656", "submitter": "Telmo Silva Filho", "authors": "Meelis Kull, Miquel Perello-Nieto, Markus K\\\"angsepp, Telmo Silva\n  Filho, Hao Song, Peter Flach", "title": "Beyond temperature scaling: Obtaining well-calibrated multiclass\n  probabilities with Dirichlet calibration", "comments": "Accepted for presentation at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Class probabilities predicted by most multiclass classifiers are\nuncalibrated, often tending towards over-confidence. With neural networks,\ncalibration can be improved by temperature scaling, a method to learn a single\ncorrective multiplicative factor for inputs to the last softmax layer. On\nnon-neural models the existing methods apply binary calibration in a pairwise\nor one-vs-rest fashion.\n  We propose a natively multiclass calibration method applicable to classifiers\nfrom any model class, derived from Dirichlet distributions and generalising the\nbeta calibration method from binary classification. It is easily implemented\nwith neural nets since it is equivalent to log-transforming the uncalibrated\nprobabilities, followed by one linear layer and softmax. Experiments\ndemonstrate improved probabilistic predictions according to multiple measures\n(confidence-ECE, classwise-ECE, log-loss, Brier score) across a wide range of\ndatasets and classifiers. Parameters of the learned Dirichlet calibration map\nprovide insights to the biases in the uncalibrated model.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 13:23:09 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kull", "Meelis", ""], ["Perello-Nieto", "Miquel", ""], ["K\u00e4ngsepp", "Markus", ""], ["Filho", "Telmo Silva", ""], ["Song", "Hao", ""], ["Flach", "Peter", ""]]}, {"id": "1910.12674", "submitter": "Anderson De Andrade", "authors": "Anderson de Andrade", "title": "A Comparison of Neural Network Training Methods for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the impact of neural networks in text classification. Our focus is\non training deep neural networks with proper weight initialization and greedy\nlayer-wise pretraining. Results are compared with 1-layer neural networks and\nSupport Vector Machines. We work with a dataset of labeled messages from the\nTwitter microblogging service and aim to predict weather conditions. A feature\nextraction procedure specific for the task is proposed, which applies\ndimensionality reduction using Latent Semantic Analysis. Our results show that\nneural networks outperform Support Vector Machines with Gaussian kernels,\nnoticing performance gains from introducing additional hidden layers with\nnonlinearities. The impact of using Nesterov's Accelerated Gradient in\nbackpropagation is also studied. We conclude that deep neural networks are a\nreasonable approach for text classification and propose further ideas to\nimprove performance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 13:46:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["de Andrade", "Anderson", ""]]}, {"id": "1910.12680", "submitter": "Martin Tak\\'a\\v{c}", "authors": "Nur Sila Gulgec, Zheng Shi, Neil Deshmukh, Shamim Pakzad, and Martin\n  Tak\\'a\\v{c}", "title": "FD-Net with Auxiliary Time Steps: Fast Prediction of PDEs using\n  Hessian-Free Trust-Region Methods", "comments": "Paper accepted to NeurIPS workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the underlying physical behavior of complex systems is a crucial,\nbut less well-understood topic in many engineering disciplines. This study\nproposes a finite-difference inspired convolutional neural network framework to\nlearn hidden partial differential equations from given data and iteratively\nestimate future dynamical behavior. The methodology designs the filter sizes\nsuch that they mimic the finite difference between the neighboring points. By\nlearning the governing equation, the network predicts the future evolution of\nthe solution by using only a few trainable parameters. In this paper, we\nprovide numerical results to compare the efficiency of the second-order\nTrust-Region Conjugate Gradient (TRCG) method with the first-order ADAM\noptimizer.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 13:50:57 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 01:55:23 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Gulgec", "Nur Sila", ""], ["Shi", "Zheng", ""], ["Deshmukh", "Neil", ""], ["Pakzad", "Shamim", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1910.12686", "submitter": "Daria Fokina", "authors": "Daria Fokina and Ivan Oseledets", "title": "Growing axons: greedy learning of neural networks with application to\n  function approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for learning deep neural network models that is based\non a greedy learning approach: we add one basis function at a time, and a new\nbasis function is generated as a non-linear activation function applied to a\nlinear combination of the previous basis functions. Such a method (growing deep\nneural network by one neuron at a time) allows us to compute much more accurate\napproximants for several model problems in function approximation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:00:04 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 20:48:09 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Fokina", "Daria", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1910.12697", "submitter": "Aditya Deshmukh", "authors": "Aditya Deshmukh, Srikrishna Bhashyam, Venugopal V. Veeravalli", "title": "Sequential Controlled Sensing for Composite Multihypothesis Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of multi-hypothesis testing with controlled sensing of\nobservations is considered. The distribution of observations collected under\neach control is assumed to follow a single-parameter exponential family\ndistribution. The goal is to design a policy to find the true hypothesis with\nminimum expected delay while ensuring that the probability of error is below a\ngiven constraint. The decision-maker can control the delay by intelligently\nchoosing the control for observation collection in each time slot. We derive a\npolicy that satisfies the given constraint on the error probability. We also\nshow that the policy is asymptotically optimal in the sense that it\nasymptotically achieves an information-theoretic lower bound on the expected\ndelay.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 22:21:26 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Deshmukh", "Aditya", ""], ["Bhashyam", "Srikrishna", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1910.12702", "submitter": "Nasser Zalmout", "authors": "Nasser Zalmout and Nizar Habash", "title": "Adversarial Multitask Learning for Joint Multi-Feature and Multi-Dialect\n  Morphological Modeling", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morphological tagging is challenging for morphologically rich languages due\nto the large target space and the need for more training data to minimize model\nsparsity. Dialectal variants of morphologically rich languages suffer more as\nthey tend to be more noisy and have less resources. In this paper we explore\nthe use of multitask learning and adversarial training to address morphological\nrichness and dialectal variations in the context of full morphological tagging.\nWe use multitask learning for joint morphological modeling for the features\nwithin two dialects, and as a knowledge-transfer scheme for cross-dialectal\nmodeling. We use adversarial training to learn dialect invariant features that\ncan help the knowledge-transfer scheme from the high to low-resource variants.\nWe work with two dialectal variants: Modern Standard Arabic (high-resource\n\"dialect\") and Egyptian Arabic (low-resource dialect) as a case study. Our\nmodels achieve state-of-the-art results for both. Furthermore, adversarial\ntraining provides more significant improvement when using smaller training\ndatasets in particular.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:22:56 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zalmout", "Nasser", ""], ["Habash", "Nizar", ""]]}, {"id": "1910.12703", "submitter": "Mikolaj Jankowski", "authors": "Mikolaj Jankowski, Deniz Gunduz, Krystian Mikolajczyk", "title": "Deep Joint Source-Channel Coding for Wireless Image Retrieval", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054078", "report-no": null, "categories": "cs.IT cs.LG eess.IV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by surveillance applications with wireless cameras or drones, we\nconsider the problem of image retrieval over a wireless channel. Conventional\nsystems apply lossy compression on query images to reduce the data that must be\ntransmitted over the bandwidth and power limited wireless link. We first note\nthat reconstructing the original image is not needed for retrieval tasks;\nhence, we introduce a deep neutral network (DNN) based compression scheme\ntargeting the retrieval task. Then, we completely remove the compression step,\nand propose another DNN-based communication scheme that directly maps the\nfeature vectors to channel inputs. This joint source-channel coding (JSCC)\napproach not only improves the end-to-end accuracy, but also simplifies and\nspeeds up the encoding operation which is highly beneficial for power and\nlatency constrained IoT applications.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:23:54 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Jankowski", "Mikolaj", ""], ["Gunduz", "Deniz", ""], ["Mikolajczyk", "Krystian", ""]]}, {"id": "1910.12706", "submitter": "Gene-Ping Yang", "authors": "Gene-Ping Yang, Szu-Lin Wu, Yao-Wen Mao, Hung-yi Lee, Lin-shan Lee", "title": "Interrupted and cascaded permutation invariant training for speech\n  separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permutation Invariant Training (PIT) has long been a stepping stone method\nfor training speech separation model in handling the label ambiguity problem.\nWith PIT selecting the minimum cost label assignments dynamically, very few\nstudies considered the separation problem to be optimizing both the model\nparameters and the label assignments, but focused on searching for good model\narchitecture and parameters. In this paper, we investigate instead for a given\nmodel architecture the various flexible label assignment strategies for\ntraining the model, rather than directly using PIT. Surprisingly, we discover a\nsignificant performance boost compared to PIT is possible if the model is\ntrained with fixed label assignments and a good set of labels is chosen. With\nfixed label training cascaded between two sections of PIT, we achieved the\nstate-of-the-art performance on WSJ0-2mix without changing the model\narchitecture at all.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:28:12 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Yang", "Gene-Ping", ""], ["Wu", "Szu-Lin", ""], ["Mao", "Yao-Wen", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1910.12708", "submitter": "Shrey Desai", "authors": "Shrey Desai, Hongyuan Zhan, Ahmed Aly", "title": "Evaluating Lottery Tickets Under Distributional Shifts", "comments": "Accepted to EMNLP 2019 Workshop on Deep Learning for Low-Resource NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lottery Ticket Hypothesis suggests large, over-parameterized neural\nnetworks consist of small, sparse subnetworks that can be trained in isolation\nto reach a similar (or better) test accuracy. However, the initialization and\ngeneralizability of the obtained sparse subnetworks have been recently called\ninto question. Our work focuses on evaluating the initialization of sparse\nsubnetworks under distributional shifts. Specifically, we investigate the\nextent to which a sparse subnetwork obtained in a source domain can be\nre-trained in isolation in a dissimilar, target domain. In addition, we examine\nthe effects of different initialization strategies at transfer-time. Our\nexperiments show that sparse subnetworks obtained through lottery ticket\ntraining do not simply overfit to particular domains, but rather reflect an\ninductive bias of deep neural networks that can be exploited in multiple\ndomains.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:29:28 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Desai", "Shrey", ""], ["Zhan", "Hongyuan", ""], ["Aly", "Ahmed", ""]]}, {"id": "1910.12713", "submitter": "Ting-Chun Wang", "authors": "Ting-Chun Wang, Ming-Yu Liu, Andrew Tao, Guilin Liu, Jan Kautz, Bryan\n  Catanzaro", "title": "Few-shot Video-to-Video Synthesis", "comments": "In NeurIPS, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video-to-video synthesis (vid2vid) aims at converting an input semantic\nvideo, such as videos of human poses or segmentation masks, to an output\nphotorealistic video. While the state-of-the-art of vid2vid has advanced\nsignificantly, existing approaches share two major limitations. First, they are\ndata-hungry. Numerous images of a target human subject or a scene are required\nfor training. Second, a learned model has limited generalization capability. A\npose-to-human vid2vid model can only synthesize poses of the single person in\nthe training set. It does not generalize to other humans that are not in the\ntraining set. To address the limitations, we propose a few-shot vid2vid\nframework, which learns to synthesize videos of previously unseen subjects or\nscenes by leveraging few example images of the target at test time. Our model\nachieves this few-shot generalization capability via a novel network weight\ngeneration module utilizing an attention mechanism. We conduct extensive\nexperimental validations with comparisons to strong baselines using several\nlarge-scale video datasets including human-dancing videos, talking-head videos,\nand street-scene videos. The experimental results verify the effectiveness of\nthe proposed framework in addressing the two limitations of existing vid2vid\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:33:09 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wang", "Ting-Chun", ""], ["Liu", "Ming-Yu", ""], ["Tao", "Andrew", ""], ["Liu", "Guilin", ""], ["Kautz", "Jan", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "1910.12717", "submitter": "Christian Soize", "authors": "Christian Soize and Roger Ghanem", "title": "Sampling of Bayesian posteriors with a non-Gaussian probabilistic\n  learning on manifolds from a small dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the challenge presented by small-data to the task of\nBayesian inference. A novel methodology, based on manifold learning and\nmanifold sampling, is proposed for solving this computational statistics\nproblem under the following assumptions: 1) neither the prior model nor the\nlikelihood function are Gaussian and neither can be approximated by a Gaussian\nmeasure; 2) the number of functional input (system parameters) and functional\noutput (quantity of interest) can be large; 3) the number of available\nrealizations of the prior model is small, leading to the small-data challenge\ntypically associated with expensive numerical simulations; the number of\nexperimental realizations is also small; 4) the number of the posterior\nrealizations required for decision is much larger than the available initial\ndataset. The method and its mathematical aspects are detailed. Three\napplications are presented for validation: The first two involve mathematical\nconstructions aimed to develop intuition around the method and to explore its\nperformance. The third example aims to demonstrate the operational value of the\nmethod using a more complex application related to the statistical inverse\nidentification of the non-Gaussian matrix-valued random elasticity field of a\ndamaged biological tissue (osteoporosis in a cortical bone) using ultrasonic\nwaves.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:37:08 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Soize", "Christian", ""], ["Ghanem", "Roger", ""]]}, {"id": "1910.12727", "submitter": "Weiwei Zhang", "authors": "Weiwei Zhang, Changsheng chen, Xuechun Wu, Jialin Gao, Di Bao, Jiwei\n  Li, Xi Zhou", "title": "Layer Pruning for Accelerating Very Deep Neural Networks", "comments": "v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an adaptive pruning method. This method can cut off\nthe channel and layer adaptively. The proportion of the layer and the channel\nto be cut is learned adaptively. The pruning method proposed in this paper can\nreduce half of the parameters, and the accuracy will not decrease or even be\nhigher than baseline.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:49:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhang", "Weiwei", ""], ["chen", "Changsheng", ""], ["Wu", "Xuechun", ""], ["Gao", "Jialin", ""], ["Bao", "Di", ""], ["Li", "Jiwei", ""], ["Zhou", "Xi", ""]]}, {"id": "1910.12735", "submitter": "Wenlin Wang", "authors": "Wenlin Wang, Hongteng Xu, Ruiyi Zhang, Wenqi Wang, Piyush Rai,\n  Lawrence Carin", "title": "Learning to Recommend from Sparse Data via Generative User Feedback", "comments": "To appear in AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional collaborative filtering (CF) based recommender systems tend to\nperform poorly when the user-item interactions/ratings are highly scarce. To\naddress this, we propose a learning framework that improves collaborative\nfiltering with a synthetic feedback loop (CF-SFL) to simulate the user\nfeedback. The proposed framework consists of a \"recommender\" and a \"virtual\nuser\". The \"recommender\" is formulated as a CF model, recommending items\naccording to observed user preference. The \"virtual user\" estimates rewards\nfrom the recommended items and generates a \\emph{feedback} in addition to the\nobserved user preference. The \"recommender\" connected with the \"virtual user\"\nconstructs a closed loop, that recommends users with items and imitates the\n\\emph{unobserved} feedback of the users to the recommended items. The synthetic\nfeedback is used to augment the observed user preference and improve\nrecommendation results. Theoretically, such model design can be interpreted as\ninverse reinforcement learning, which can be learned effectively via rollout\n(simulation). Experimental results show that the proposed framework is able to\nenrich the learning of user preference and boost the performance of existing\ncollaborative filtering methods on multiple datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 01:31:07 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 03:17:42 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Wang", "Wenlin", ""], ["Xu", "Hongteng", ""], ["Zhang", "Ruiyi", ""], ["Wang", "Wenqi", ""], ["Rai", "Piyush", ""], ["Carin", "Lawrence", ""]]}, {"id": "1910.12744", "submitter": "Saeed Saremi", "authors": "Saeed Saremi", "title": "On approximating $\\nabla f$ with neural networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a feedforward neural network $\\psi: \\mathbb{R}^d\\rightarrow\n\\mathbb{R}^d$ such that $\\psi\\approx \\nabla f$, where $f:\\mathbb{R}^d\n\\rightarrow \\mathbb{R}$ is a smooth function, therefore $\\psi$ must satisfy\n$\\partial_j \\psi_i = \\partial_i \\psi_j$ pointwise. We prove a theorem that a\n$\\psi$ network with more than one hidden layer can only represent one feature\nin its first hidden layer; this is a dramatic departure from the well-known\nresults for one hidden layer. The proof of the theorem is straightforward,\nwhere two backward paths and a weight-tying matrix play the key roles. We then\npresent the alternative, the implicit parametrization, where the neural network\nis $\\phi: \\mathbb{R}^d \\rightarrow \\mathbb{R}$ and $\\nabla \\phi \\approx \\nabla\nf$; in addition, a \"soft analysis\" of $\\nabla \\phi$ gives a dual perspective on\nthe theorem. Throughout, we come back to recent probabilistic models that are\nformulated as $\\nabla \\phi \\approx \\nabla f$, and conclude with a critique of\ndenoising autoencoders.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 15:12:42 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 12:41:30 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Saremi", "Saeed", ""]]}, {"id": "1910.12748", "submitter": "Cheol Young Park", "authors": "Seung Joon Nam, Han Min Kim, Thomas Kang, Cheol Young Park", "title": "A Study of Machine Learning Models in Predicting the Intention of\n  Adolescents to Smoke Cigarettes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of electronic cigarette (e-cigarette) is increasing among\nadolescents. This is problematic since consuming nicotine at an early age can\ncause harmful effects in developing teenager's brain and health. Additionally,\nthe use of e-cigarette has a possibility of leading to the use of cigarettes,\nwhich is more severe. There were many researches about e-cigarette and\ncigarette that mostly focused on finding and analyzing causes of smoking using\nconventional statistics. However, there is a lack of research on developing\nprediction models, which is more applicable to anti-smoking campaign, about\ne-cigarette and cigarette. In this paper, we research the prediction models\nthat can be used to predict an individual e-cigarette user's (including\nnon-e-cigarette users) intention to smoke cigarettes, so that one can be early\ninformed about the risk of going down the path of smoking cigarettes. To\nconstruct the prediction models, five machine learning (ML) algorithms are\nexploited and tested for their accuracy in predicting the intention to smoke\ncigarettes among never smokers using data from the 2018 National Youth Tobacco\nSurvey (NYTS). In our investigation, the Gradient Boosting Classifier, one of\nthe prediction models, shows the highest accuracy out of all the other models.\nAlso, with the best prediction model, we made a public website that enables\nusers to input information to predict their intentions of smoking cigarettes.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 15:17:24 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 12:48:51 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Nam", "Seung Joon", ""], ["Kim", "Han Min", ""], ["Kang", "Thomas", ""], ["Park", "Cheol Young", ""]]}, {"id": "1910.12749", "submitter": "Rafael Rego Drumond", "authors": "Rafael Rego Drumond, Lukas Brinkmeyer, Josif Grabocka, Lars\n  Schmidt-Thieme", "title": "HIDRA: Head Initialization across Dynamic targets for Robust\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of gradient-based optimization strategies depends heavily on\nthe initial weights of the parametric model. Recent works show that there exist\nweight initializations from which optimization procedures can find the\ntask-specific parameters faster than from uniformly random initializations and\nthat such a weight initialization can be learned by optimizing a specific model\narchitecture across similar tasks via MAML (Model-Agnostic Meta-Learning).\nCurrent methods are limited to populations of classification tasks that share\nthe same number of classes due to the static model architectures used during\nmeta-learning. In this paper, we present HIDRA, a meta-learning approach that\nenables training and evaluating across tasks with any number of target\nvariables. We show that Model-Agnostic Meta-Learning trains a distribution for\nall the neurons in the output layer and a specific weight initialization for\nthe ones in the hidden layers. HIDRA explores this by learning one master\nneuron, which is used to initialize any number of output neurons for a new\ntask. Extensive experiments on the Miniimagenet and Omniglot data sets\ndemonstrate that HIDRA improves over standard approaches while generalizing to\ntasks with any number of target variables. Moreover, our approach is shown to\nrobustify low-capacity models in learning across complex tasks with a high\nnumber of classes for which regular MAML fails to learn any feasible\ninitialization.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 15:18:19 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 17:14:15 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Drumond", "Rafael Rego", ""], ["Brinkmeyer", "Lukas", ""], ["Grabocka", "Josif", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1910.12752", "submitter": "Shang-Chun Lin", "authors": "Shang-Chun Lin, Georg Martius, Martin Oettel", "title": "Analytical classical density functionals from an equation learning\n  network", "comments": "Update figures and SI. Some explanations and clarifications are added", "journal-ref": "J. Chem. Phys. 152, 021102 (2020)", "doi": "10.1063/1.5135919", "report-no": null, "categories": "cond-mat.soft cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the feasibility of using machine learning methods to obtain an\nanalytic form of the classical free energy functional for two model fluids,\nhard rods and Lennard--Jones, in one dimension . The Equation Learning Network\nproposed in Ref. 1 is suitably modified to construct free energy densities\nwhich are functions of a set of weighted densities and which are built from a\nsmall number of basis functions with flexible combination rules. This setup\nconsiderably enlarges the functional space used in the machine learning\noptimization as compared to previous work 2 where the functional is limited to\na simple polynomial form. As a result, we find a good approximation for the\nexact hard rod functional and its direct correlation function. For the\nLennard--Jones fluid, we let the network learn (i) the full excess free energy\nfunctional and (ii) the excess free energy functional related to interparticle\nattractions. Both functionals show a good agreement with simulated density\nprofiles for thermodynamic parameters inside and outside the training region.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 15:28:06 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 20:06:30 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Lin", "Shang-Chun", ""], ["Martius", "Georg", ""], ["Oettel", "Martin", ""]]}, {"id": "1910.12756", "submitter": "Nikita Zhivotovskiy", "authors": "Olivier Bousquet, Nikita Zhivotovskiy", "title": "Fast classification rates without standard margin assumptions", "comments": "29 pages, 1 figure; presentation changed according to referees\n  suggestion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical problem of learning rates for classes with finite\nVC dimension. It is well known that fast learning rates up to\n$O\\left(\\frac{d}{n}\\right)$ are achievable by the empirical risk minimization\nalgorithm (ERM) if low noise or margin assumptions are satisfied. These usually\nrequire the optimal Bayes classifier to be in the class, and it has been shown\nthat when this is not the case, the fast rates cannot be achieved even in the\nnoise free case. In this paper, we further investigate the question of the fast\nrates under the misspecification, when the Bayes classifier is not in the class\n(also called the agnostic setting).\n  First, we consider classification with a reject option, namely Chow's reject\noption model, and show that by slightly lowering the impact of hard instances,\na learning rate of order $O\\left(\\frac{d}{n}\\log \\frac{n}{d}\\right)$ is always\nachievable in the agnostic setting by a specific learning algorithm. Similar\nresults were only known under special versions of margin assumptions. We also\nshow that the performance of the proposed algorithm is never worse than the\nperformance of ERM.\n  Based on those results, we derive the necessary and sufficient conditions for\nclassification (without a reject option) with fast rates in the agnostic\nsetting achievable by improper learners. This simultaneously extends the work\nof Massart and N\\'{e}d\\'{e}lec (Ann. of Statistics, 2006), which studied this\nquestion in the case where the Bayesian optimal rule belongs to the class, and\nthe work of Ben-David and Urner (COLT, 2014), which allows the misspecification\nbut is limited to the no noise setting. Our result also provides the first\ngeneral setup in statistical learning theory in which an improper learning\nalgorithm may significantly improve the learning rate for non-convex losses.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 15:34:57 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 17:24:20 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Bousquet", "Olivier", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "1910.12757", "submitter": "Aditya Mantha", "authors": "Aditya Mantha, Yokila Arora, Shubham Gupta, Praveenkumar Kanumala,\n  Zhiwei Liu, Stephen Guo, Kannan Achan", "title": "A Large-Scale Deep Architecture for Personalized Grocery Basket\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With growing consumer adoption of online grocery shopping through platforms\nsuch as Amazon Fresh, Instacart, and Walmart Grocery, there is a pressing\nbusiness need to provide relevant recommendations throughout the customer\njourney. In this paper, we introduce a production within-basket grocery\nrecommendation system, RTT2Vec, which generates real-time personalized product\nrecommendations to supplement the user's current grocery basket. We conduct\nextensive offline evaluation of our system and demonstrate a 9.4% uplift in\nprediction metrics over baseline state-of-the-art within-basket recommendation\nmodels. We also propose an approximate inference technique 11.6x times faster\nthan exact inference approaches. In production, our system has resulted in an\nincrease in average basket size, improved product discovery, and enabled faster\nuser check-out\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 06:54:55 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 18:24:28 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 02:03:18 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Mantha", "Aditya", ""], ["Arora", "Yokila", ""], ["Gupta", "Shubham", ""], ["Kanumala", "Praveenkumar", ""], ["Liu", "Zhiwei", ""], ["Guo", "Stephen", ""], ["Achan", "Kannan", ""]]}, {"id": "1910.12760", "submitter": "Sofiene Jerbi", "authors": "Sofiene Jerbi, Lea M. Trenkwalder, Hendrik Poulsen Nautrup, Hans J.\n  Briegel, Vedran Dunjko", "title": "Quantum enhancements for deep reinforcement learning in large spaces", "comments": "Significant number of new analyses and results", "journal-ref": "PRX Quantum 2, 010328 (2021)", "doi": "10.1103/PRXQuantum.2.010328", "report-no": null, "categories": "quant-ph cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, the field of quantum machine learning has drawn\nsignificant attention due to the prospect of bringing genuine computational\nadvantages to now widespread algorithmic methods. However, not all domains of\nmachine learning have benefited equally from quantum enhancements. Notably,\ndeep learning and reinforcement learning, despite their tremendous success in\nthe classical domain, both individually and combined, remain relatively\nunaddressed by the quantum community. Arguably, one reason behind this is the\nsystematic use in these domains of models and methods without prominent\ncomputational bottlenecks, leaving little room for quantum improvements. In\nthis work, we study the state-of-the-art neural-network approaches for\nreinforcement learning with quantum enhancements in mind. We demonstrate the\nsubstantial learning advantage that models with a sampling bottleneck can\nprovide over conventional neural network architectures in complex learning\nenvironments. These so-called energy-based models, like deep energy-based\nreinforcement learning, and deep projective simulation that we also introduce\nin this work, effectively allow to trade off learning performance for\nefficiency of computation. To alleviate the additional computational costs, we\npropose to leverage future and near-term quantum algorithms, resulting in\noverall more advantageous learning algorithms. This is achieved using\ncutting-edge and new quantum computing machinery to speed-up classical sampling\nmethods and by employing generalized models to gain an additional quantum\nadvantage.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 15:41:19 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 17:32:44 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Jerbi", "Sofiene", ""], ["Trenkwalder", "Lea M.", ""], ["Nautrup", "Hendrik Poulsen", ""], ["Briegel", "Hans J.", ""], ["Dunjko", "Vedran", ""]]}, {"id": "1910.12774", "submitter": "George Chen", "authors": "Wei Ma, George H. Chen", "title": "Missing Not at Random in Matrix Completion: The Effectiveness of\n  Estimating Missingness Probabilities Under a Low Nuclear Norm Assumption", "comments": "Advances in Neural Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is often applied to data with entries missing not at random\n(MNAR). For example, consider a recommendation system where users tend to only\nreveal ratings for items they like. In this case, a matrix completion method\nthat relies on entries being revealed at uniformly sampled row and column\nindices can yield overly optimistic predictions of unseen user ratings.\nRecently, various papers have shown that we can reduce this bias in MNAR matrix\ncompletion if we know the probabilities of different matrix entries being\nmissing. These probabilities are typically modeled using logistic regression or\nnaive Bayes, which make strong assumptions and lack guarantees on the accuracy\nof the estimated probabilities. In this paper, we suggest a simple approach to\nestimating these probabilities that avoids these shortcomings. Our approach\nfollows from the observation that missingness patterns in real data often\nexhibit low nuclear norm structure. We can then estimate the missingness\nprobabilities by feeding the (always fully-observed) binary matrix specifying\nwhich entries are revealed or missing to an existing nuclear-norm-constrained\nmatrix completion algorithm by Davenport et al. [2014]. Thus, we tackle MNAR\nmatrix completion by solving a different matrix completion problem first that\nrecovers missingness probabilities. We establish finite-sample error bounds for\nhow accurate these probability estimates are and how well these estimates\ndebias standard matrix completion losses for the original matrix to be\ncompleted. Our experiments show that the proposed debiasing strategy can\nimprove a variety of existing matrix completion algorithms, and achieves\ndownstream matrix completion accuracy at least as good as logistic regression\nand naive Bayes debiasing baselines that require additional auxiliary\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:01:47 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 12:25:33 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Ma", "Wei", ""], ["Chen", "George H.", ""]]}, {"id": "1910.12778", "submitter": "Jiajin Li", "authors": "Jiajin Li, Sen Huang, Anthony Man-Cho So", "title": "A First-Order Algorithmic Framework for Wasserstein Distributionally\n  Robust Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein distance-based distributionally robust optimization (DRO) has\nreceived much attention lately due to its ability to provide a robustness\ninterpretation of various learning models. Moreover, many of the DRO problems\nthat arise in the learning context admits exact convex reformulations and hence\ncan be tackled by off-the-shelf solvers. Nevertheless, the use of such solvers\nseverely limits the applicability of DRO in large-scale learning problems, as\nthey often rely on general purpose interior-point algorithms. On the other\nhand, there are very few works that attempt to develop fast iterative methods\nto solve these DRO problems, which typically possess complicated structures. In\nthis paper, we take a first step towards resolving the above difficulty by\ndeveloping a first-order algorithmic framework for tackling a class of\nWasserstein distance-based distributionally robust logistic regression (DRLR)\nproblem. Specifically, we propose a novel linearized proximal ADMM to solve the\nDRLR problem, whose objective is convex but consists of a smooth term plus two\nnon-separable non-smooth terms. We prove that our method enjoys a sublinear\nconvergence rate. Furthermore, we conduct three different experiments to show\nits superb performance on both synthetic and real-world datasets. In\nparticular, our method can achieve the same accuracy up to 800+ times faster\nthan the standard off-the-shelf solver.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:03:00 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Li", "Jiajin", ""], ["Huang", "Sen", ""], ["So", "Anthony Man-Cho", ""]]}, {"id": "1910.12781", "submitter": "Malte Ludewig", "authors": "Malte Ludewig, Noemi Mauro, Sara Latifi, Dietmar Jannach", "title": "Empirical Analysis of Session-Based Recommendation Algorithms", "comments": null, "journal-ref": null, "doi": "10.1007/s11257-020-09277-1", "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are tools that support online users by pointing them to\npotential items of interest in situations of information overload. In recent\nyears, the class of session-based recommendation algorithms received more\nattention in the research literature. These algorithms base their\nrecommendations solely on the observed interactions with the user in an ongoing\nsession and do not require the existence of long-term preference profiles. Most\nrecently, a number of deep learning based (\"neural\") approaches to\nsession-based recommendations were proposed. However, previous research\nindicates that today's complex neural recommendation methods are not always\nbetter than comparably simple algorithms in terms of prediction accuracy.\n  With this work, our goal is to shed light on the state-of-the-art in the area\nof session-based recommendation and on the progress that is made with neural\napproaches. For this purpose, we compare twelve algorithmic approaches, among\nthem six recent neural methods, under identical conditions on various datasets.\nWe find that the progress in terms of prediction accuracy that is achieved with\nneural methods is still limited. In most cases, our experiments show that\nsimple heuristic methods based on nearest-neighbors schemes are preferable over\nconceptually and computationally more complex methods. Observations from a user\nstudy furthermore indicate that recommendations based on heuristic methods were\nalso well accepted by the study participants. To support future progress and\nreproducibility in this area, we publicly share the session-rec evaluation\nframework that was used in our research.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:08:58 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 15:36:15 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ludewig", "Malte", ""], ["Mauro", "Noemi", ""], ["Latifi", "Sara", ""], ["Jannach", "Dietmar", ""]]}, {"id": "1910.12783", "submitter": "Lingzhou Hong", "authors": "Lingzhou Hong, Alfredo Garcia, and Ceyhun Eksin", "title": "Distributed Networked Learning with Correlated Data", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider a distributed estimation method in a setting with heterogeneous\nstreams of correlated data distributed across nodes in a network. In the\nconsidered approach, linear models are estimated locally (i.e., with only local\ndata) subject to a network regularization term that penalizes a local model\nthat differs from neighboring models. We analyze computation dynamics\n(associated with stochastic gradient updates) and information exchange\n(associated with exchanging current models with neighboring nodes). We provide\na finite-time characterization of convergence of the weighted ensemble average\nestimate and compare this result to federated learning, an alternative approach\nto estimation wherein a single model is updated by locally generated gradient\nupdates. This comparison highlights the trade-off between speed vs precision:\nwhile model updates take place at a faster rate in federated learning, the\nproposed networked approach to estimation enables the identification of models\nwith higher precision. We illustrate the method's general applicability in two\nexamples: estimating a Markov random field using wireless sensor networks and\nmodeling prey escape behavior of flocking birds based on a publicly available\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:14:02 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 23:38:45 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Hong", "Lingzhou", ""], ["Garcia", "Alfredo", ""], ["Eksin", "Ceyhun", ""]]}, {"id": "1910.12794", "submitter": "Dilin Wang", "authors": "Dilin Wang, Ziyang Tang, Chandrajit Bajaj, Qiang Liu", "title": "Stein Variational Gradient Descent With Matrix-Valued Kernels", "comments": "Neural Information Processing Systems 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein variational gradient descent (SVGD) is a particle-based inference\nalgorithm that leverages gradient information for efficient approximate\ninference. In this work, we enhance SVGD by leveraging preconditioning\nmatrices, such as the Hessian and Fisher information matrix, to incorporate\ngeometric information into SVGD updates. We achieve this by presenting a\ngeneralization of SVGD that replaces the scalar-valued kernels in vanilla SVGD\nwith more general matrix-valued kernels. This yields a significant extension of\nSVGD, and more importantly, allows us to flexibly incorporate various\npreconditioning matrices to accelerate the exploration in the probability\nlandscape. Empirical results show that our method outperforms vanilla SVGD and\na variety of baseline approaches over a range of real-world Bayesian inference\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:43:48 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:54:26 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Wang", "Dilin", ""], ["Tang", "Ziyang", ""], ["Bajaj", "Chandrajit", ""], ["Liu", "Qiang", ""]]}, {"id": "1910.12795", "submitter": "Zhiting Hu", "authors": "Zhiting Hu, Bowen Tan, Ruslan Salakhutdinov, Tom Mitchell, Eric P.\n  Xing", "title": "Learning Data Manipulation for Augmentation and Weighting", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulating data, such as weighting data examples or augmenting with new\ninstances, has been increasingly used to improve model training. Previous work\nhas studied various rule- or learning-based approaches designed for specific\ntypes of data manipulation. In this work, we propose a new method that supports\nlearning different manipulation schemes with the same gradient-based algorithm.\nOur approach builds upon a recent connection of supervised learning and\nreinforcement learning (RL), and adapts an off-the-shelf reward learning\nalgorithm from RL for joint data manipulation learning and model training.\nDifferent parameterization of the \"data reward\" function instantiates different\nmanipulation schemes. We showcase data augmentation that learns a text\ntransformation network, and data weighting that dynamically adapts the data\nsample importance. Experiments show the resulting algorithms significantly\nimprove the image and text classification performance in low data regime and\nclass-imbalance problems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:46:24 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Hu", "Zhiting", ""], ["Tan", "Bowen", ""], ["Salakhutdinov", "Ruslan", ""], ["Mitchell", "Tom", ""], ["Xing", "Eric P.", ""]]}, {"id": "1910.12799", "submitter": "Taiji Suzuki", "authors": "Taiji Suzuki and Atsushi Nitanda", "title": "Deep learning is adaptive to intrinsic dimensionality of model\n  smoothness in anisotropic Besov space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has exhibited superior performance for various tasks,\nespecially for high-dimensional datasets, such as images. To understand this\nproperty, we investigate the approximation and estimation ability of deep\nlearning on {\\it anisotropic Besov spaces}. The anisotropic Besov space is\ncharacterized by direction-dependent smoothness and includes several function\nclasses that have been investigated thus far. We demonstrate that the\napproximation error and estimation error of deep learning only depend on the\naverage value of the smoothness parameters in all directions. Consequently, the\ncurse of dimensionality can be avoided if the smoothness of the target function\nis highly anisotropic. Unlike existing studies, our analysis does not require a\nlow-dimensional structure of the input data. We also investigate the minimax\noptimality of deep learning and compare its performance with that of the kernel\nmethod (more generally, linear estimators). The results show that deep learning\nhas better dependence on the input dimensionality if the target function\npossesses anisotropic smoothness, and it achieves an adaptive rate for\nfunctions with spatially inhomogeneous smoothness.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:52:25 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Suzuki", "Taiji", ""], ["Nitanda", "Atsushi", ""]]}, {"id": "1910.12800", "submitter": "Xing Zhao", "authors": "Xing Zhao, Ping Lu, Yanyan Zhang, Jianxiong Chen, and Xiaoyang Li", "title": "Attenuating Random Noise in Seismic Data by a Deep Learning Approach", "comments": "33 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the geophysical field, seismic noise attenuation has been considered as a\ncritical and long-standing problem, especially for the pre-stack data\nprocessing. Here, we propose a model to leverage the deep-learning model for\nthis task. Rather than directly applying an existing de-noising model from\nordinary images to the seismic data, we have designed a particular\ndeep-learning model, based on residual neural networks. It is named as\nN2N-Seismic, which has a strong ability to recover the seismic signals back to\nintact condition with the preservation of primary signals. The proposed model,\nachieving with great success in attenuating noise, has been tested on two\ndifferent seismic datasets. Several metrics show that our method outperforms\nconventional approaches in terms of Signal-to-Noise-Ratio, Mean-Squared-Error,\nPhase Spectrum, etc. Moreover, robust tests in terms of effectively removing\nrandom noise from any dataset with strong and weak noises have been extensively\nscrutinized in making sure that the proposed model is able to maintain a good\nlevel of adaptation while dealing with large variations of noise\ncharacteristics and intensities.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:53:26 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhao", "Xing", ""], ["Lu", "Ping", ""], ["Zhang", "Yanyan", ""], ["Chen", "Jianxiong", ""], ["Li", "Xiaoyang", ""]]}, {"id": "1910.12802", "submitter": "Mathieu Lauri\\`ere", "authors": "Ren\\'e Carmona and Mathieu Lauri\\`ere and Zongjun Tan", "title": "Model-Free Mean-Field Reinforcement Learning: Mean-Field MDP and\n  Mean-Field Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general reinforcement learning framework for mean field control\n(MFC) problems. Such problems arise for instance as the limit of collaborative\nmulti-agent control problems when the number of agents is very large. The\nasymptotic problem can be phrased as the optimal control of a non-linear\ndynamics. This can also be viewed as a Markov decision process (MDP) but the\nkey difference with the usual RL setup is that the dynamics and the reward now\ndepend on the state's probability distribution itself. Alternatively, it can be\nrecast as a MDP on the Wasserstein space of measures. In this work, we\nintroduce generic model-free algorithms based on the state-action value\nfunction at the mean field level and we prove convergence for a prototypical\nQ-learning method. We then implement an actor-critic method and report\nnumerical results on two archetypal problems: a finite space model motivated by\na cyber security application and a continuous space model motivated by an\napplication to swarm motion.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:56:46 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Carmona", "Ren\u00e9", ""], ["Lauri\u00e8re", "Mathieu", ""], ["Tan", "Zongjun", ""]]}, {"id": "1910.12806", "submitter": "Jinoh Kim", "authors": "Makiya Nakashima, Alex Sim, Youngsoo Kim, Jonghyun Kim, Jinoh Kim", "title": "An Ensemble Approach toward Automated Variable Selection for Network\n  Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While variable selection is essential to optimize the learning complexity by\nprioritizing features, automating the selection process is preferred since it\nrequires laborious efforts with intensive analysis otherwise. However, it is\nnot an easy task to enable the automation due to several reasons. First,\nselection techniques often need a condition to terminate the reduction process,\nfor example, by using a threshold or the number of features to stop, and\nsearching an adequate stopping condition is highly challenging. Second, it is\nuncertain that the reduced variable set would work well; our preliminary\nexperimental result shows that well-known selection techniques produce\ndifferent sets of variables as a result of reduction (even with the same\ntermination condition), and it is hard to estimate which of them would work the\nbest in future testing. In this paper, we demonstrate the potential power of\nour approach to the automation of selection process that incorporates\nwell-known selection methods identifying important variables. Our experimental\nresults with two public network traffic data (UNSW-NB15 and IDS2017) show that\nour proposed method identifies a small number of core variables, with which it\nis possible to approximate the performance to the one with the entire\nvariables.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:03:02 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Nakashima", "Makiya", ""], ["Sim", "Alex", ""], ["Kim", "Youngsoo", ""], ["Kim", "Jonghyun", ""], ["Kim", "Jinoh", ""]]}, {"id": "1910.12807", "submitter": "Kamil Ciosek", "authors": "Kamil Ciosek, Quan Vuong, Robert Loftin, Katja Hofmann", "title": "Better Exploration with Optimistic Actor-Critic", "comments": "20 pages (including supplement)", "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actor-critic methods, a type of model-free Reinforcement Learning, have been\nsuccessfully applied to challenging tasks in continuous control, often\nachieving state-of-the art performance. However, wide-scale adoption of these\nmethods in real-world domains is made difficult by their poor sample\nefficiency. We address this problem both theoretically and empirically. On the\ntheoretical side, we identify two phenomena preventing efficient exploration in\nexisting state-of-the-art algorithms such as Soft Actor Critic. First,\ncombining a greedy actor update with a pessimistic estimate of the critic leads\nto the avoidance of actions that the agent does not know about, a phenomenon we\ncall pessimistic underexploration. Second, current algorithms are directionally\nuninformed, sampling actions with equal probability in opposite directions from\nthe current mean. This is wasteful, since we typically need actions taken along\ncertain directions much more than others. To address both of these phenomena,\nwe introduce a new algorithm, Optimistic Actor Critic, which approximates a\nlower and upper confidence bound on the state-action value function. This\nallows us to apply the principle of optimism in the face of uncertainty to\nperform directed exploration using the upper bound while still using the lower\nbound to avoid overestimation. We evaluate OAC in several challenging\ncontinuous control tasks, achieving state-of the art sample efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:06:40 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ciosek", "Kamil", ""], ["Vuong", "Quan", ""], ["Loftin", "Robert", ""], ["Hofmann", "Katja", ""]]}, {"id": "1910.12809", "submitter": "Masatoshi Uehara", "authors": "Masatoshi Uehara, Jiawei Huang, Nan Jiang", "title": "Minimax Weight and Q-Function Learning for Off-Policy Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide theoretical investigations into off-policy evaluation in\nreinforcement learning using function approximators for (marginalized)\nimportance weights and value functions. Our contributions include: (1) A new\nestimator, MWL, that directly estimates importance ratios over the state-action\ndistributions, removing the reliance on knowledge of the behavior policy as in\nprior work (Liu et al., 2018). (2) Another new estimator, MQL, obtained by\nswapping the roles of importance weights and value-functions in MWL. MQL has an\nintuitive interpretation of minimizing average Bellman errors and can be\ncombined with MWL in a doubly robust manner. (3) Several additional results\nthat offer further insights into these methods, including the sample complexity\nanalyses of MWL and MQL, their asymptotic optimality in the tabular setting,\nhow the learned importance weights depend the choice of the discriminator\nclass, and how our methods provide a unified view of some old and new\nalgorithms in RL.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:08:25 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 21:21:33 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 01:49:19 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 23:04:03 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Uehara", "Masatoshi", ""], ["Huang", "Jiawei", ""], ["Jiang", "Nan", ""]]}, {"id": "1910.12819", "submitter": "Ehsan Hajiramezanali", "authors": "Ehsan Hajiramezanali, Arman Hasanzadeh, Nick Duffield, Krishna\n  Narayanan, Mingyuan Zhou, Xiaoning Qian", "title": "Semi-Implicit Stochastic Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic recurrent neural networks with latent random variables of complex\ndependency structures have shown to be more successful in modeling sequential\ndata than deterministic deep models. However, the majority of existing methods\nhave limited expressive power due to the Gaussian assumption of latent\nvariables. In this paper, we advocate learning implicit latent representations\nusing semi-implicit variational inference to further increase model\nflexibility. Semi-implicit stochastic recurrent neural network(SIS-RNN) is\ndeveloped to enrich inferred model posteriors that may have no analytic density\nfunctions, as long as independent random samples can be generated via\nreparameterization. Extensive experiments in different tasks on real-world\ndatasets show that SIS-RNN outperforms the existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:24:41 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 03:02:25 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Hajiramezanali", "Ehsan", ""], ["Hasanzadeh", "Arman", ""], ["Duffield", "Nick", ""], ["Narayanan", "Krishna", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1910.12820", "submitter": "Paul Burchard", "authors": "Paul Burchard, Anthony Daoud, Dominic Dotterrer", "title": "Empirical Differential Privacy", "comments": "more precise definitions and theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to achieve differential privacy with no or reduced added noise,\nbased on the empirical noise in the data itself. Unlike previous works on\nnoiseless privacy, the empirical viewpoint avoids making any explicit\nassumptions about the random process generating the data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:26:18 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 19:49:10 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 15:12:31 GMT"}, {"version": "v4", "created": "Fri, 23 Apr 2021 00:00:10 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Burchard", "Paul", ""], ["Daoud", "Anthony", ""], ["Dotterrer", "Dominic", ""]]}, {"id": "1910.12824", "submitter": "J\\\"org Franke", "authors": "J\\\"org K.H. Franke, Gregor K\\\"ohler, Noor Awad, Frank Hutter", "title": "Neural Architecture Evolution in Deep Reinforcement Learning for\n  Continuous Control", "comments": "NeurIPS 2019 MetaLearn Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current Deep Reinforcement Learning algorithms still heavily rely on\nhandcrafted neural network architectures. We propose a novel approach to\nautomatically find strong topologies for continuous control tasks while only\nadding a minor overhead in terms of interactions in the environment. To achieve\nthis, we combine Neuroevolution techniques with off-policy training and propose\na novel architecture mutation operator. Experiments on five continuous control\nbenchmarks show that the proposed Actor-Critic Neuroevolution algorithm often\noutperforms the strong Actor-Critic baseline and is capable of automatically\nfinding topologies in a sample-efficient manner which would otherwise have to\nbe found by expensive architecture search.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:33:26 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 21:38:04 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 11:54:44 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Franke", "J\u00f6rg K. H.", ""], ["K\u00f6hler", "Gregor", ""], ["Awad", "Noor", ""], ["Hutter", "Frank", ""]]}, {"id": "1910.12827", "submitter": "Michael Chang", "authors": "Rishi Veerapaneni, John D. Co-Reyes, Michael Chang, Michael Janner,\n  Chelsea Finn, Jiajun Wu, Joshua B. Tenenbaum, Sergey Levine", "title": "Entity Abstraction in Visual Model-Based Reinforcement Learning", "comments": "Accepted at CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tests the hypothesis that modeling a scene in terms of entities\nand their local interactions, as opposed to modeling the scene globally,\nprovides a significant benefit in generalizing to physical tasks in a\ncombinatorial space the learner has not encountered before. We present\nobject-centric perception, prediction, and planning (OP3), which to the best of\nour knowledge is the first fully probabilistic entity-centric dynamic latent\nvariable framework for model-based reinforcement learning that acquires entity\nrepresentations from raw visual observations without supervision and uses them\nto predict and plan. OP3 enforces entity-abstraction -- symmetric processing of\neach entity representation with the same locally-scoped function -- which\nenables it to scale to model different numbers and configurations of objects\nfrom those in training. Our approach to solving the key technical challenge of\ngrounding these entity representations to actual objects in the environment is\nto frame this variable binding problem as an inference problem, and we develop\nan interactive inference algorithm that uses temporal continuity and\ninteractive feedback to bind information about object properties to the entity\nvariables. On block-stacking tasks, OP3 generalizes to novel block\nconfigurations and more objects than observed during training, outperforming an\noracle model that assumes access to object supervision and achieving two to\nthree times better accuracy than a state-of-the-art video prediction model that\ndoes not exhibit entity abstraction.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:37:46 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 12:57:33 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 23:16:31 GMT"}, {"version": "v4", "created": "Sat, 11 Apr 2020 19:50:41 GMT"}, {"version": "v5", "created": "Wed, 6 May 2020 14:51:15 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Veerapaneni", "Rishi", ""], ["Co-Reyes", "John D.", ""], ["Chang", "Michael", ""], ["Janner", "Michael", ""], ["Finn", "Chelsea", ""], ["Wu", "Jiajun", ""], ["Tenenbaum", "Joshua B.", ""], ["Levine", "Sergey", ""]]}, {"id": "1910.12832", "submitter": "Kanthi Sarpatwar", "authors": "Kanthi Sarpatwar and Karthikeyan Shanmugam and Venkata\n  Sitaramagiridharganesh Ganapavarapu and Ashish Jagmohan and Roman Vaculin", "title": "Differentially Private Distributed Data Summarization under Covariate\n  Shift", "comments": "To appear in the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We envision AI marketplaces to be platforms where consumers, with very less\ndata for a target task, can obtain a relevant model by accessing many private\ndata sources with vast number of data samples. One of the key challenges is to\nconstruct a training dataset that matches a target task without compromising on\nprivacy of the data sources. To this end, we consider the following distributed\ndata summarizataion problem. Given K private source datasets denoted by\n$[D_i]_{i\\in [K]}$ and a small target validation set $D_v$, which may involve a\nconsiderable covariate shift with respect to the sources, compute a summary\ndataset $D_s\\subseteq \\bigcup_{i\\in [K]} D_i$ such that its statistical\ndistance from the validation dataset $D_v$ is minimized. We use the popular\nMaximum Mean Discrepancy as the measure of statistical distance. The\nnon-private problem has received considerable attention in prior art, for\nexample in prototype selection (Kim et al., NIPS 2016). Our work is the first\nto obtain strong differential privacy guarantees while ensuring the quality\nguarantees of the non-private version. We study this problem in a Parsimonious\nCurator Privacy Model, where a trusted curator coordinates the summarization\nprocess while minimizing the amount of private information accessed. Our\ncentral result is a novel protocol that (a) ensures the curator accesses at\nmost $O(K^{\\frac{1}{3}}|D_s| + |D_v|)$ points (b) has formal privacy guarantees\non the leakage of information between the data owners and (c) closely matches\nthe best known non-private greedy algorithm. Our protocol uses two hash\nfunctions, one inspired by the Rahimi-Recht random features method and the\nsecond leverages state of the art differential privacy mechanisms. We introduce\na novel \"noiseless\" differentially private auctioning protocol for winner\nnotification and demonstrate the efficacy of our protocol using real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:45:12 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 15:47:05 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Sarpatwar", "Kanthi", ""], ["Shanmugam", "Karthikeyan", ""], ["Ganapavarapu", "Venkata Sitaramagiridharganesh", ""], ["Jagmohan", "Ashish", ""], ["Vaculin", "Roman", ""]]}, {"id": "1910.12837", "submitter": "Yan Shuo Tan", "authors": "Yan Shuo Tan, Roman Vershynin", "title": "Online Stochastic Gradient Descent with Arbitrary Initialization Solves\n  Non-smooth, Non-convex Phase Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG cs.NA math.IT math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent literature, a general two step procedure has been formulated for\nsolving the problem of phase retrieval. First, a spectral technique is used to\nobtain a constant-error initial estimate, following which, the estimate is\nrefined to arbitrary precision by first-order optimization of a non-convex loss\nfunction. Numerical experiments, however, seem to suggest that simply running\nthe iterative schemes from a random initialization may also lead to\nconvergence, albeit at the cost of slightly higher sample complexity. In this\npaper, we prove that, in fact, constant step size online stochastic gradient\ndescent (SGD) converges from arbitrary initializations for the non-smooth,\nnon-convex amplitude squared loss objective. In this setting, online SGD is\nalso equivalent to the randomized Kaczmarz algorithm from numerical analysis.\nOur analysis can easily be generalized to other single index models. It also\nmakes use of new ideas from stochastic process theory, including the notion of\na summary state space, which we believe will be of use for the broader field of\nnon-convex optimization.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:46:49 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Tan", "Yan Shuo", ""], ["Vershynin", "Roman", ""]]}, {"id": "1910.12853", "submitter": "Shiyu Chang", "authors": "Shiyu Chang, Yang Zhang, Mo Yu, Tommi S. Jaakkola", "title": "A Game Theoretic Approach to Class-wise Selective Rationalization", "comments": "Accepted by Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selection of input features such as relevant pieces of text has become a\ncommon technique of highlighting how complex neural predictors operate. The\nselection can be optimized post-hoc for trained models or incorporated directly\ninto the method itself (self-explaining). However, an overall selection does\nnot properly capture the multi-faceted nature of useful rationales such as pros\nand cons for decisions. To this end, we propose a new game theoretic approach\nto class-dependent rationalization, where the method is specifically trained to\nhighlight evidence supporting alternative conclusions. Each class involves\nthree players set up competitively to find evidence for factual and\ncounterfactual scenarios. We show theoretically in a simplified scenario how\nthe game drives the solution towards meaningful class-dependent rationales. We\nevaluate the method in single- and multi-aspect sentiment classification tasks\nand demonstrate that the proposed method is able to identify both factual\n(justifying the ground truth label) and counterfactual (countering the ground\ntruth label) rationales consistent with human rationalization. The code for our\nmethod is publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:59:02 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Chang", "Shiyu", ""], ["Zhang", "Yang", ""], ["Yu", "Mo", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1910.12854", "submitter": "Keith Burghardt", "authors": "Yuzi He and Keith Burghardt and Kristina Lerman", "title": "Learning Fair and Interpretable Representations via Linear\n  Orthogonalization", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce human error and prejudice, many high-stakes decisions have been\nturned over to machine algorithms. However, recent research suggests that this\ndoes not remove discrimination, and can perpetuate harmful stereotypes. While\nalgorithms have been developed to improve fairness, they typically face at\nleast one of three shortcomings: they are not interpretable, their prediction\nquality deteriorates quickly compared to unbiased equivalents, and they are not\neasily transferable across models. To address these shortcomings, we propose a\ngeometric method that removes correlations between data and any number of\nprotected variables. Further, we can control the strength of debiasing through\nan adjustable parameter to address the trade-off between prediction quality and\nfairness. The resulting features are interpretable and can be used with many\npopular models, such as linear regression, random forest, and multilayer\nperceptrons. The resulting predictions are found to be more accurate and fair\ncompared to several state-of-the-art fair AI algorithms across a variety of\nbenchmark datasets. Our work shows that debiasing data is a simple and\neffective solution toward improving fairness.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:59:31 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 18:59:13 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["He", "Yuzi", ""], ["Burghardt", "Keith", ""], ["Lerman", "Kristina", ""]]}, {"id": "1910.12892", "submitter": "Douwe Kiela", "authors": "Qi Liu, Maximilian Nickel, Douwe Kiela", "title": "Hyperbolic Graph Neural Networks", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from graph-structured data is an important task in machine learning\nand artificial intelligence, for which Graph Neural Networks (GNNs) have shown\ngreat promise. Motivated by recent advances in geometric representation\nlearning, we propose a novel GNN architecture for learning representations on\nRiemannian manifolds with differentiable exponential and logarithmic maps. We\ndevelop a scalable algorithm for modeling the structural properties of graphs,\ncomparing Euclidean and hyperbolic geometry. In our experiments, we show that\nhyperbolic GNNs can lead to substantial improvements on various benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:01:10 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Liu", "Qi", ""], ["Nickel", "Maximilian", ""], ["Kiela", "Douwe", ""]]}, {"id": "1910.12903", "submitter": "Xiaoyu Cao", "authors": "Xiaoyu Cao, Jinyuan Jia and Neil Zhenqiang Gong", "title": "IPGuard: Protecting Intellectual Property of Deep Neural Networks via\n  Fingerprinting the Classification Boundary", "comments": "Accepted by AsiaCCS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep neural network (DNN) classifier represents a model owner's\nintellectual property as training a DNN classifier often requires lots of\nresource. Watermarking was recently proposed to protect the intellectual\nproperty of DNN classifiers. However, watermarking suffers from a key\nlimitation: it sacrifices the utility/accuracy of the model owner's classifier\nbecause it tampers the classifier's training or fine-tuning process. In this\nwork, we propose IPGuard, the first method to protect intellectual property of\nDNN classifiers that provably incurs no accuracy loss for the classifiers. Our\nkey observation is that a DNN classifier can be uniquely represented by its\nclassification boundary. Based on this observation, IPGuard extracts some data\npoints near the classification boundary of the model owner's classifier and\nuses them to fingerprint the classifier. A DNN classifier is said to be a\npirated version of the model owner's classifier if they predict the same labels\nfor most fingerprinting data points. IPGuard is qualitatively different from\nwatermarking. Specifically, IPGuard extracts fingerprinting data points near\nthe classification boundary of a classifier that is already trained, while\nwatermarking embeds watermarks into a classifier during its training or\nfine-tuning process. We extensively evaluate IPGuard on CIFAR-10, CIFAR-100,\nand ImageNet datasets. Our results show that IPGuard can robustly identify\npost-processed versions of the model owner's classifier as pirated versions of\nthe classifier, and IPGuard can identify classifiers, which are not the model\nowner's classifier nor its post-processed versions, as non-pirated versions of\nthe classifier.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:39:49 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 15:54:57 GMT"}, {"version": "v3", "created": "Sat, 11 Apr 2020 17:19:58 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 19:27:24 GMT"}, {"version": "v5", "created": "Sat, 31 Oct 2020 15:19:17 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Cao", "Xiaoyu", ""], ["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1910.12908", "submitter": "Bj\\\"orn L\\\"utjens", "authors": "Bj\\\"orn L\\\"utjens, Michael Everett, Jonathan P. How", "title": "Certified Adversarial Robustness for Deep Reinforcement Learning", "comments": "Published at Conference on Robot Learning (CoRL) 2019; (v2) contains\n  minor updates to related works; (v3) acknowledged AWS", "journal-ref": "Proceedings of Machine Learning Research (PMLR) Vol. 100, 2019", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network-based systems are now the state-of-the-art in many\nrobotics tasks, but their application in safety-critical domains remains\ndangerous without formal guarantees on network robustness. Small perturbations\nto sensor inputs (from noise or adversarial examples) are often enough to\nchange network-based decisions, which was already shown to cause an autonomous\nvehicle to swerve into oncoming traffic. In light of these dangers, numerous\nalgorithms have been developed as defensive mechanisms from these adversarial\ninputs, some of which provide formal robustness guarantees or certificates.\nThis work leverages research on certified adversarial robustness to develop an\nonline certified defense for deep reinforcement learning algorithms. The\nproposed defense computes guaranteed lower bounds on state-action values during\nexecution to identify and choose the optimal action under a worst-case\ndeviation in input space due to possible adversaries or noise. The approach is\ndemonstrated on a Deep Q-Network policy and is shown to increase robustness to\nnoise and adversaries in pedestrian collision avoidance scenarios and a classic\ncontrol task.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:45:38 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 00:29:33 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 19:20:21 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["L\u00fctjens", "Bj\u00f6rn", ""], ["Everett", "Michael", ""], ["How", "Jonathan P.", ""]]}, {"id": "1910.12911", "submitter": "Maximilian Igl", "authors": "Maximilian Igl, Kamil Ciosek, Yingzhen Li, Sebastian Tschiatschek,\n  Cheng Zhang, Sam Devlin, Katja Hofmann", "title": "Generalization in Reinforcement Learning with Selective Noise Injection\n  and Information Bottleneck", "comments": "Published at Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability for policies to generalize to new environments is key to the\nbroad application of RL agents. A promising approach to prevent an agent's\npolicy from overfitting to a limited set of training environments is to apply\nregularization techniques originally developed for supervised learning.\nHowever, there are stark differences between supervised learning and RL. We\ndiscuss those differences and propose modifications to existing regularization\ntechniques in order to better adapt them to RL. In particular, we focus on\nregularization techniques relying on the injection of noise into the learned\nfunction, a family that includes some of the most widely used approaches such\nas Dropout and Batch Normalization. To adapt them to RL, we propose Selective\nNoise Injection (SNI), which maintains the regularizing effect the injected\nnoise has, while mitigating the adverse effects it has on the gradient quality.\nFurthermore, we demonstrate that the Information Bottleneck (IB) is a\nparticularly well suited regularization technique for RL as it is effective in\nthe low-data regime encountered early on in training RL agents. Combining the\nIB with SNI, we significantly outperform current state of the art results,\nincluding on the recently proposed generalization benchmark Coinrun.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:51:54 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Igl", "Maximilian", ""], ["Ciosek", "Kamil", ""], ["Li", "Yingzhen", ""], ["Tschiatschek", "Sebastian", ""], ["Zhang", "Cheng", ""], ["Devlin", "Sam", ""], ["Hofmann", "Katja", ""]]}, {"id": "1910.12913", "submitter": "Hafiz Imtiaz", "authors": "Hafiz Imtiaz, Jafar Mohammadi, Rogers Silva, Bradley Baker, Sergey M.\n  Plis, Anand D. Sarwate, Vince Calhoun", "title": "Improved Differentially Private Decentralized Source Separation for fMRI\n  Data", "comments": "\\c{opyright} 2020 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works. arXiv admin note: text overlap with\n  arXiv:1904.10059", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind source separation algorithms such as independent component analysis\n(ICA) are widely used in the analysis of neuroimaging data. In order to\nleverage larger sample sizes, different data holders/sites may wish to\ncollaboratively learn feature representations. However, such datasets are often\nprivacy-sensitive, precluding centralized analyses that pool the data at a\nsingle site. In this work, we propose a differentially private algorithm for\nperforming ICA in a decentralized data setting. Conventional approaches to\ndecentralized differentially private algorithms may introduce too much noise\ndue to the typically small sample sizes at each site. We propose a novel\nprotocol that uses correlated noise to remedy this problem. We show that our\nalgorithm outperforms existing approaches on synthetic and real neuroimaging\ndatasets and demonstrate that it can sometimes reach the same level of utility\nas the corresponding non-private algorithm. This indicates that it is possible\nto have meaningful utility while preserving privacy.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:57:57 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 02:55:54 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Imtiaz", "Hafiz", ""], ["Mohammadi", "Jafar", ""], ["Silva", "Rogers", ""], ["Baker", "Bradley", ""], ["Plis", "Sergey M.", ""], ["Sarwate", "Anand D.", ""], ["Calhoun", "Vince", ""]]}, {"id": "1910.12933", "submitter": "Rex Ying", "authors": "Ines Chami, Rex Ying, Christopher R\\'e, Jure Leskovec", "title": "Hyperbolic Graph Convolutional Neural Networks", "comments": "Published at Conference NeurIPS 2019. First 2 authors have equal\n  contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCNs) embed nodes in a graph into\nEuclidean space, which has been shown to incur a large distortion when\nembedding real-world graphs with scale-free or hierarchical structure.\nHyperbolic geometry offers an exciting alternative, as it enables embeddings\nwith much smaller distortion. However, extending GCNs to hyperbolic geometry\npresents several unique challenges because it is not clear how to define neural\nnetwork operations, such as feature transformation and aggregation, in\nhyperbolic space. Furthermore, since input features are often Euclidean, it is\nunclear how to transform the features into hyperbolic embeddings with the right\namount of curvature. Here we propose Hyperbolic Graph Convolutional Neural\nNetwork (HGCN), the first inductive hyperbolic GCN that leverages both the\nexpressiveness of GCNs and hyperbolic geometry to learn inductive node\nrepresentations for hierarchical and scale-free graphs. We derive GCN\noperations in the hyperboloid model of hyperbolic space and map Euclidean input\nfeatures to embeddings in hyperbolic spaces with different trainable curvature\nat each layer. Experiments demonstrate that HGCN learns embeddings that\npreserve hierarchical structure, and leads to improved performance when\ncompared to Euclidean analogs, even with very low dimensional embeddings:\ncompared to state-of-the-art GCNs, HGCN achieves an error reduction of up to\n63.1% in ROC AUC for link prediction and of up to 47.5% in F1 score for node\nclassification, also improving state-of-the art on the Pubmed dataset.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 19:41:56 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Chami", "Ines", ""], ["Ying", "Rex", ""], ["R\u00e9", "Christopher", ""], ["Leskovec", "Jure", ""]]}, {"id": "1910.12939", "submitter": "Monisha Yuvaraj", "authors": "Umar Islambekov, Monisha Yuvaraj and Yulia R. Gel", "title": "Harnessing the power of Topological Data Analysis to detect change\n  points in time series", "comments": "11 pages, 3 Figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel geometry-oriented methodology, based on the emerging\ntools of topological data analysis, into the change point detection framework.\nThe key rationale is that change points are likely to be associated with\nchanges in geometry behind the data generating process. While the applications\nof topological data analysis to change point detection are potentially very\nbroad, in this paper we primarily focus on integrating topological concepts\nwith the existing nonparametric methods for change point detection. In\nparticular, the proposed new geometry-oriented approach aims to enhance\ndetection accuracy of distributional regime shift locations. Our simulation\nstudies suggest that integration of topological data analysis with some\nexisting algorithms for change point detection leads to consistently more\naccurate detection results. We illustrate our new methodology in application to\nthe two closely related environmental time series datasets -ice phenology of\nthe Lake Baikal and the North Atlantic Oscillation indices, in a research query\nfor a possible association between their estimated regime shift locations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 19:52:23 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Islambekov", "Umar", ""], ["Yuvaraj", "Monisha", ""], ["Gel", "Yulia R.", ""]]}, {"id": "1910.12944", "submitter": "Justin Leo", "authors": "Justin Leo, Jugal Kalita", "title": "Moving Towards Open Set Incremental Learning: Readily Discovering New\n  Authors", "comments": "Accepted to Future of Information and Communication Conference (FICC)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of textual data often yields important information. Most\nclassifiers work in a closed world setting where the classifier is trained on a\nknown corpus, and then it is tested on unseen examples that belong to one of\nthe classes seen during training. Despite the usefulness of this design, often\nthere is a need to classify unseen examples that do not belong to any of the\nclasses on which the classifier was trained. This paper describes the open set\nscenario where unseen examples from previously unseen classes are handled while\ntesting. This further examines a process of enhanced open set classification\nwith a deep neural network that discovers new classes by clustering the\nexamples identified as belonging to unknown classes, followed by a process of\nretraining the classifier with newly recognized classes. Through this process\nthe model moves to an incremental learning model where it continuously finds\nand learns from novel classes of data that have been identified automatically.\nThis paper also develops a new metric that measures multiple attributes of\nclustering open set data. Multiple experiments across two author attribution\ndata sets demonstrate the creation an incremental model that produces excellent\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 20:01:54 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Leo", "Justin", ""], ["Kalita", "Jugal", ""]]}, {"id": "1910.12947", "submitter": "Minshuo Chen", "authors": "Minshuo Chen, Xingguo Li, Tuo Zhao", "title": "On Generalization Bounds of a Family of Recurrent Neural Networks", "comments": "30 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) have been widely applied to sequential data\nanalysis. Due to their complicated modeling structures, however, the theory\nbehind is still largely missing. To connect theory and practice, we study the\ngeneralization properties of vanilla RNNs as well as their variants, including\nMinimal Gated Unit (MGU), Long Short Term Memory (LSTM), and Convolutional\n(Conv) RNNs. Specifically, our theory is established under the PAC-Learning\nframework. The generalization bound is presented in terms of the spectral norms\nof the weight matrices and the total number of parameters. We also establish\nrefined generalization bounds with additional norm assumptions, and draw a\ncomparison among these bounds. We remark: (1) Our generalization bound for\nvanilla RNNs is significantly tighter than the best of existing results; (2) We\nare not aware of any other generalization bounds for MGU, LSTM, and Conv RNNs\nin the exiting literature; (3) We demonstrate the advantages of these variants\nin generalization.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 20:12:16 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 03:15:14 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Chen", "Minshuo", ""], ["Li", "Xingguo", ""], ["Zhao", "Tuo", ""]]}, {"id": "1910.12948", "submitter": "Gilles Vandewiele", "authors": "Gilles Vandewiele and Femke Ongenae and Filip De Turck", "title": "GENDIS: GENetic DIscovery of Shapelets", "comments": null, "journal-ref": null, "doi": "10.3390/s21041059", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the time series classification domain, shapelets are small time series\nthat are discriminative for a certain class. It has been shown that classifiers\nare able to achieve state-of-the-art results on a plethora of datasets by\ntaking as input distances from the input time series to different\ndiscriminative shapelets. Additionally, these shapelets can easily be\nvisualized and thus possess an interpretable characteristic, making them very\nappealing in critical domains, such as the health care domain, where\nlongitudinal data is ubiquitous. In this study, a new paradigm for shapelet\ndiscovery is proposed, which is based upon evolutionary computation. The\nadvantages of the proposed approach are that (i) it is gradient-free, which\ncould allow to escape from local optima more easily and to find suited\ncandidates more easily and supports non-differentiable objectives, (ii) no\nbrute-force search is required, which drastically reduces the computational\ncomplexity by several orders of magnitude, (iii) the total amount of shapelets\nand length of each of these shapelets are evolved jointly with the shapelets\nthemselves, alleviating the need to specify this beforehand, (iv) entire sets\nare evaluated at once as opposed to single shapelets, which results in smaller\nfinal sets with less similar shapelets that result in similar predictive\nperformances, and (v) discovered shapelets do not need to be a subsequence of\nthe input time series. We present the results of experiments which validate the\nenumerated advantages.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 08:51:35 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 12:23:35 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Vandewiele", "Gilles", ""], ["Ongenae", "Femke", ""], ["De Turck", "Filip", ""]]}, {"id": "1910.12954", "submitter": "Abram Magner", "authors": "Abram Magner and Mayank Baranwal and Alfred O. Hero III", "title": "Fundamental Limits of Deep Graph Convolutional Networks", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) are a widely used method for graph\nrepresentation learning. To elucidate the capabilities and limitations of GCNs,\nwe investigate their power, as a function of their number of layers, to\ndistinguish between different random graph models (corresponding to different\nclass-conditional distributions in a classification problem) on the basis of\nthe embeddings of their sample graphs. In particular, the graph models that we\nconsider arise from graphons, which are the most general possible\nparameterizations of infinite exchangeable graph models and which are the\ncentral objects of study in the theory of dense graph limits. We give a precise\ncharacterization of the set of pairs of graphons that are indistinguishable by\na GCN with nonlinear activation functions coming from a certain broad class if\nits depth is at least logarithmic in the size of the sample graph. This\ncharacterization is in terms of a degree profile closeness property. Outside\nthis class, a very simple GCN architecture suffices for distinguishability. We\nthen exhibit a concrete, infinite class of graphons arising from stochastic\nblock models that are well-separated in terms of cut distance and are\nindistinguishable by a GCN. These results theoretically match empirical\nobservations of several prior works. To prove our results, we exploit a\nconnection to random walks on graphs. Finally, we give empirical results on\nsynthetic and real graph classification datasets, indicating that\nindistinguishable graph distributions arise in practice.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 20:28:59 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 18:17:33 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Magner", "Abram", ""], ["Baranwal", "Mayank", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1910.12956", "submitter": "Vaibhav Jain", "authors": "Vaibhav Jain, Ruchika Malhotra, Sanskar Jain and Nishant Tanwar", "title": "Cross-Domain Ambiguity Detection using Linear Transformation of Word\n  Embedding Spaces", "comments": "Published as part of the proceedings of the 3rd Workshop on Natural\n  Language Processing for Requirements Engineering in CEUR-WS Vol-2584", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The requirements engineering process is a crucial stage of the software\ndevelopment life cycle. It involves various stakeholders from different\nprofessional backgrounds, particularly in the requirements elicitation phase.\nEach stakeholder carries distinct domain knowledge, causing them to differently\ninterpret certain words, leading to cross-domain ambiguity. This can result in\nmisunderstanding amongst them and jeopardize the entire project. This paper\nproposes a natural language processing approach to find potentially ambiguous\nwords for a given set of domains. The idea is to apply linear transformations\non word embedding models trained on different domain corpora, to bring them\ninto a unified embedding space. The approach then finds words with divergent\nembeddings as they signify a variation in the meaning across the domains. It\ncan help a requirements analyst in preventing misunderstandings during\nelicitation interviews and meetings by defining a set of potentially ambiguous\nterms in advance. The paper also discusses certain problems with the existing\napproaches and discusses how the proposed approach resolves them.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 20:32:56 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 05:51:41 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 19:10:42 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Jain", "Vaibhav", ""], ["Malhotra", "Ruchika", ""], ["Jain", "Sanskar", ""], ["Tanwar", "Nishant", ""]]}, {"id": "1910.12958", "submitter": "Gabriel Peyr\\'e", "authors": "Thibault S\\'ejourn\\'e, Jean Feydy, Fran\\c{c}ois-Xavier Vialard, Alain\n  Trouv\\'e, Gabriel Peyr\\'e", "title": "Sinkhorn Divergences for Unbalanced Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport induces the Earth Mover's (Wasserstein) distance between\nprobability distributions, a geometric divergence that is relevant to a wide\nrange of problems. Over the last decade, two relaxations of optimal transport\nhave been studied in depth: unbalanced transport, which is robust to the\npresence of outliers and can be used when distributions don't have the same\ntotal mass; entropy-regularized transport, which is robust to sampling noise\nand lends itself to fast computations using the Sinkhorn algorithm. This paper\ncombines both lines of work to put robust optimal transport on solid ground.\nOur main contribution is a generalization of the Sinkhorn algorithm to\nunbalanced transport: our method alternates between the standard Sinkhorn\nupdates and the pointwise application of a contractive function. This implies\nthat entropic transport solvers on grid images, point clouds and sampled\ndistributions can all be modified easily to support unbalanced transport, with\na proof of linear convergence that holds in all settings. We then show how to\nuse this method to define pseudo-distances on the full space of positive\nmeasures that satisfy key geometric axioms: (unbalanced) Sinkhorn divergences\nare differentiable, positive, definite, convex, statistically robust and avoid\nany \"entropic bias\" towards a shrinkage of the measures' supports.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 20:40:37 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 08:02:09 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["S\u00e9journ\u00e9", "Thibault", ""], ["Feydy", "Jean", ""], ["Vialard", "Fran\u00e7ois-Xavier", ""], ["Trouv\u00e9", "Alain", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "1910.12960", "submitter": "Yuanhao Lai", "authors": "Yuanhao Lai and Ian McLeod", "title": "Ensemble Quantile Classifier", "comments": null, "journal-ref": "Computational Statistics and Data Analysis (2019) 106849", "doi": "10.1016/j.csda.2019.106849", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both the median-based classifier and the quantile-based classifier are useful\nfor discriminating high-dimensional data with heavy-tailed or skewed inputs.\nBut these methods are restricted as they assign equal weight to each variable\nin an unregularized way. The ensemble quantile classifier is a more flexible\nregularized classifier that provides better performance with high-dimensional\ndata, asymmetric data or when there are many irrelevant extraneous inputs. The\nimproved performance is demonstrated by a simulation study as well as an\napplication to text categorization. It is proven that the estimated parameters\nof the ensemble quantile classifier consistently estimate the minimal\npopulation loss under suitable general model assumptions. It is also shown that\nthe ensemble quantile classifier is Bayes optimal under suitable assumptions\nwith asymmetric Laplace distribution inputs.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 20:41:49 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Lai", "Yuanhao", ""], ["McLeod", "Ian", ""]]}, {"id": "1910.12969", "submitter": "Qin Lin", "authors": "Qin Lin, Wenshuo Wang, Yihuan Zhang, John Dolan", "title": "Measuring Similarity of Interactive Driving Behaviors Using Matrix\n  Profile", "comments": "ACC final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding multi-vehicle interactive behaviors with temporal sequential\nobservations is crucial for autonomous vehicles to make appropriate decisions\nin an uncertain traffic environment. On-demand similarity measures are\nsignificant for autonomous vehicles to deal with massive interactive driving\nbehaviors by clustering and classifying diverse scenarios. This paper proposes\na general approach for measuring spatiotemporal similarity of interactive\nbehaviors using a multivariate matrix profile technique. The key attractive\nfeatures of the approach are its superior space and time complexity, real-time\nonline computing for streaming traffic data, and possible capability of\nleveraging hardware for parallel computation. The proposed approach is\nvalidated through automatically discovering similar interactive driving\nbehaviors at intersections from sequential data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 20:58:43 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 15:20:43 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 21:46:05 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Lin", "Qin", ""], ["Wang", "Wenshuo", ""], ["Zhang", "Yihuan", ""], ["Dolan", "John", ""]]}, {"id": "1910.12976", "submitter": "Wanyu Lin", "authors": "Wanyu Lin, Zhaolin Gao, Baochun Li", "title": "Shoestring: Graph-Based Semi-Supervised Learning with Severely Limited\n  Labeled Data", "comments": "9 pages, 5 tables, 3 figures, accepted at CVPR2020, source code will\n  be released soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based semi-supervised learning has been shown to be one of the most\neffective approaches for classification tasks from a wide range of domains,\nsuch as image classification and text classification, as they can exploit the\nconnectivity patterns between labeled and unlabeled samples to improve learning\nperformance. In this work, we advance this effective learning paradigm towards\na scenario where labeled data are severely limited. More specifically, we\naddress the problem of graph-based semi-supervised learning in the presence of\nseverely limited labeled samples, and propose a new framework, called {\\em\nShoestring}, that improves the learning performance through semantic transfer\nfrom these very few labeled samples to large numbers of unlabeled samples.\n  In particular, our framework learns a metric space in which classification\ncan be performed by computing the similarity to centroid embedding of each\nclass. {\\em Shoestring} is trained in an end-to-end fashion to learn to\nleverage the semantic knowledge of limited labeled samples as well as their\nconnectivity patterns with large numbers of unlabeled samples simultaneously.\nBy combining {\\em Shoestring} with graph convolutional networks, label\npropagation and their recent label-efficient variations (IGCN and GLP), we are\nable to achieve state-of-the-art node classification performance in the\npresence of very few labeled samples. In addition, we demonstrate the\neffectiveness of our framework on image classification tasks in the few-shot\nlearning regime, with significant gains on miniImageNet ($2.57\\%\\sim3.59\\%$)\nand tieredImageNet ($1.05\\%\\sim2.70\\%$).\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 21:23:01 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 14:34:18 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Lin", "Wanyu", ""], ["Gao", "Zhaolin", ""], ["Li", "Baochun", ""]]}, {"id": "1910.12980", "submitter": "Hanjun Dai", "authors": "Hanjun Dai, Yujia Li, Chenglong Wang, Rishabh Singh, Po-Sen Huang,\n  Pushmeet Kohli", "title": "Learning Transferable Graph Exploration", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of efficient exploration of unseen\nenvironments, a key challenge in AI. We propose a `learning to explore'\nframework where we learn a policy from a distribution of environments. At test\ntime, presented with an unseen environment from the same distribution, the\npolicy aims to generalize the exploration strategy to visit the maximum number\nof unique states in a limited number of steps. We particularly focus on\nenvironments with graph-structured state-spaces that are encountered in many\nimportant real-world applications like software testing and map building. We\nformulate this task as a reinforcement learning problem where the `exploration'\nagent is rewarded for transitioning to previously unseen environment states and\nemploy a graph-structured memory to encode the agent's past trajectory.\nExperimental results demonstrate that our approach is extremely effective for\nexploration of spatial maps; and when applied on the challenging problems of\ncoverage-guided software-testing of domain-specific programs and real-world\nmobile applications, it outperforms methods that have been hand-engineered by\nhuman experts.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 21:43:22 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Dai", "Hanjun", ""], ["Li", "Yujia", ""], ["Wang", "Chenglong", ""], ["Singh", "Rishabh", ""], ["Huang", "Po-Sen", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1910.12991", "submitter": "Aaron Schein", "authors": "Aaron Schein, Scott W. Linderman, Mingyuan Zhou, David M. Blei, and\n  Hanna Wallach", "title": "Poisson-Randomized Gamma Dynamical Systems", "comments": "To appear in the Proceedings of the 32nd Advances in Neural\n  Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Poisson-randomized gamma dynamical system (PRGDS), a\nmodel for sequentially observed count tensors that encodes a strong inductive\nbias toward sparsity and burstiness. The PRGDS is based on a new motif in\nBayesian latent variable modeling, an alternating chain of discrete Poisson and\ncontinuous gamma latent states that is analytically convenient and\ncomputationally tractable. This motif yields closed-form complete conditionals\nfor all variables by way of the Bessel distribution and a novel discrete\ndistribution that we call the shifted confluent hypergeometric distribution. We\ndraw connections to closely related models and compare the PRGDS to these\nmodels in studies of real-world count data sets of text, international events,\nand neural spike trains. We find that a sparse variant of the PRGDS, which\nallows the continuous gamma latent states to take values of exactly zero, often\nobtains better predictive performance than other models and is uniquely capable\nof inferring latent structures that are highly localized in time.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 22:26:29 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Schein", "Aaron", ""], ["Linderman", "Scott W.", ""], ["Zhou", "Mingyuan", ""], ["Blei", "David M.", ""], ["Wallach", "Hanna", ""]]}, {"id": "1910.12993", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami, Alan Yang, Negar Kiyavash, Kun Zhang", "title": "Characterizing Distribution Equivalence and Structure Learning for\n  Cyclic and Acyclic Directed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main approach to defining equivalence among acyclic directed causal\ngraphical models is based on the conditional independence relationships in the\ndistributions that the causal models can generate, in terms of the Markov\nequivalence. However, it is known that when cycles are allowed in the causal\nstructure, conditional independence may not be a suitable notion for\nequivalence of two structures, as it does not reflect all the information in\nthe distribution that is useful for identification of the underlying structure.\nIn this paper, we present a general, unified notion of equivalence for linear\nGaussian causal directed graphical models, whether they are cyclic or acyclic.\nIn our proposed definition of equivalence, two structures are equivalent if\nthey can generate the same set of data distributions. We also propose a weaker\nnotion of equivalence called quasi-equivalence, which we show is the extent of\nidentifiability from observational data. We propose analytic as well as\ngraphical methods for characterizing the equivalence of two structures.\nAdditionally, we propose a score-based method for learning the structure from\nobservational data, which successfully deals with both acyclic and cyclic\nstructures.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 22:30:53 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 18:23:42 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 14:21:59 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Yang", "Alan", ""], ["Kiyavash", "Negar", ""], ["Zhang", "Kun", ""]]}, {"id": "1910.12995", "submitter": "Tuan Manh Lai", "authors": "Tuan Manh Lai, Quan Hung Tran, Trung Bui, Daisuke Kihara", "title": "A Simple but Effective BERT Model for Dialog State Tracking on\n  Resource-Limited Systems", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a task-oriented dialog system, the goal of dialog state tracking (DST) is\nto monitor the state of the conversation from the dialog history. Recently,\nmany deep learning based methods have been proposed for the task. Despite their\nimpressive performance, current neural architectures for DST are typically\nheavily-engineered and conceptually complex, making it difficult to implement,\ndebug, and maintain them in a production setting. In this work, we propose a\nsimple but effective DST model based on BERT. In addition to its simplicity,\nour approach also has a number of other advantages: (a) the number of\nparameters does not grow with the ontology size (b) the model can operate in\nsituations where the domain ontology may change dynamically. Experimental\nresults demonstrate that our BERT-based model outperforms previous methods by a\nlarge margin, achieving new state-of-the-art results on the standard WoZ 2.0\ndataset. Finally, to make the model small and fast enough for\nresource-restricted systems, we apply the knowledge distillation method to\ncompress our model. The final compressed model achieves comparable results with\nthe original model while being 8x smaller and 7x faster.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 22:41:55 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 18:02:09 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 04:35:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lai", "Tuan Manh", ""], ["Tran", "Quan Hung", ""], ["Bui", "Trung", ""], ["Kihara", "Daisuke", ""]]}, {"id": "1910.12999", "submitter": "Mingrui Liu", "authors": "Mingrui Liu, Wei Zhang, Youssef Mroueh, Xiaodong Cui, Jerret Ross,\n  Tianbao Yang, Payel Das", "title": "A Decentralized Parallel Algorithm for Training Generative Adversarial\n  Nets", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a powerful class of generative\nmodels in the deep learning community. Current practice on large-scale GAN\ntraining utilizes large models and distributed large-batch training strategies,\nand is implemented on deep learning frameworks (e.g., TensorFlow, PyTorch,\netc.) designed in a centralized manner. In the centralized network topology,\nevery worker needs to either directly communicate with the central node or\nindirectly communicate with all other workers in every iteration. However, when\nthe network bandwidth is low or network latency is high, the performance would\nbe significantly degraded. Despite recent progress on decentralized algorithms\nfor training deep neural networks, it remains unclear whether it is possible to\ntrain GANs in a decentralized manner. The main difficulty lies at handling the\nnonconvex-nonconcave min-max optimization and the decentralized communication\nsimultaneously. In this paper, we address this difficulty by designing the\n\\textbf{first gradient-based decentralized parallel algorithm} which allows\nworkers to have multiple rounds of communications in one iteration and to\nupdate the discriminator and generator simultaneously, and this design makes it\namenable for the convergence analysis of the proposed decentralized algorithm.\nTheoretically, our proposed decentralized algorithm is able to solve a class of\nnon-convex non-concave min-max problems with provable non-asymptotic\nconvergence to first-order stationary point. Experimental results on GANs\ndemonstrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 22:51:45 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 20:38:02 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 08:12:30 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 03:00:10 GMT"}, {"version": "v5", "created": "Fri, 26 Jun 2020 06:34:49 GMT"}, {"version": "v6", "created": "Mon, 19 Oct 2020 20:51:45 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Liu", "Mingrui", ""], ["Zhang", "Wei", ""], ["Mroueh", "Youssef", ""], ["Cui", "Xiaodong", ""], ["Ross", "Jerret", ""], ["Yang", "Tianbao", ""], ["Das", "Payel", ""]]}, {"id": "1910.13003", "submitter": "Weiyang Liu", "authors": "Weiyang Liu, Zhen Liu, James M. Rehg, Le Song", "title": "Neural Similarity Learning", "comments": "NeurIPS 2019 (v3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inner product-based convolution has been the founding stone of convolutional\nneural networks (CNNs), enabling end-to-end learning of visual representation.\nBy generalizing inner product with a bilinear matrix, we propose the neural\nsimilarity which serves as a learnable parametric similarity measure for CNNs.\nNeural similarity naturally generalizes the convolution and enhances\nflexibility. Further, we consider the neural similarity learning (NSL) in order\nto learn the neural similarity adaptively from training data. Specifically, we\npropose two different ways of learning the neural similarity: static NSL and\ndynamic NSL. Interestingly, dynamic neural similarity makes the CNN become a\ndynamic inference network. By regularizing the bilinear matrix, NSL can be\nviewed as learning the shape of kernel and the similarity measure\nsimultaneously. We further justify the effectiveness of NSL with a theoretical\nviewpoint. Most importantly, NSL shows promising performance in visual\nrecognition and few-shot learning, validating the superiority of NSL over the\ninner product-based convolution counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 23:06:56 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 16:59:32 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 10:39:39 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Liu", "Weiyang", ""], ["Liu", "Zhen", ""], ["Rehg", "James M.", ""], ["Song", "Le", ""]]}, {"id": "1910.13010", "submitter": "Emmanouil Vasileios Vlatakis Gkaragkounis", "authors": "Lampros Flokas, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Georgios\n  Piliouras", "title": "Poincar\\'e Recurrence, Cycles and Spurious Equilibria in\n  Gradient-Descent-Ascent for Non-Convex Non-Concave Zero-Sum Games", "comments": "To appear in NeurIPS 2019 (Spotlight talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a wide class of non-convex non-concave min-max games that\ngeneralizes over standard bilinear zero-sum games. In this class, players\ncontrol the inputs of a smooth function whose output is being applied to a\nbilinear zero-sum game. This class of games is motivated by the indirect nature\nof the competition in Generative Adversarial Networks, where players control\nthe parameters of a neural network while the actual competition happens between\nthe distributions that the generator and discriminator capture. We establish\ntheoretically, that depending on the specific instance of the problem\ngradient-descent-ascent dynamics can exhibit a variety of behaviors\nantithetical to convergence to the game theoretically meaningful min-max\nsolution. Specifically, different forms of recurrent behavior (including\nperiodicity and Poincar\\'e recurrence) are possible as well as convergence to\nspurious (non-min-max) equilibria for a positive measure of initial conditions.\nAt the technical level, our analysis combines tools from optimization theory,\ngame theory and dynamical systems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 23:59:25 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Flokas", "Lampros", ""], ["Vlatakis-Gkaragkounis", "Emmanouil-Vasileios", ""], ["Piliouras", "Georgios", ""]]}, {"id": "1910.13016", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Alexander Hepburn and Raul Santos-Rodriguez and Peter\n  Flach", "title": "bLIMEy: Surrogate Prediction Explanations Beyond LIME", "comments": "2019 Workshop on Human-Centric Machine Learning (HCML 2019); 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surrogate explainers of black-box machine learning predictions are of\nparamount importance in the field of eXplainable Artificial Intelligence since\nthey can be applied to any type of data (images, text and tabular), are\nmodel-agnostic and are post-hoc (i.e., can be retrofitted). The Local\nInterpretable Model-agnostic Explanations (LIME) algorithm is often mistakenly\nunified with a more general framework of surrogate explainers, which may lead\nto a belief that it is the solution to surrogate explainability. In this paper\nwe empower the community to \"build LIME yourself\" (bLIMEy) by proposing a\nprincipled algorithmic framework for building custom local surrogate explainers\nof black-box model predictions, including LIME itself. To this end, we\ndemonstrate how to decompose the surrogate explainers family into\nalgorithmically independent and interoperable modules and discuss the influence\nof these component choices on the functional capabilities of the resulting\nexplainer, using the example of LIME.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 00:21:31 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Sokol", "Kacper", ""], ["Hepburn", "Alexander", ""], ["Santos-Rodriguez", "Raul", ""], ["Flach", "Peter", ""]]}, {"id": "1910.13018", "submitter": "Marmar Orooji", "authors": "Marmar Orooji, Jianhua Chen", "title": "Predicting Louisiana Public High School Dropout through Imbalanced\n  Learning Techniques", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study is motivated by the magnitude of the problem of Louisiana high\nschool dropout and its negative impacts on individual and public well-being.\nOur goal is to predict students who are at risk of high school dropout, by\nexamining Louisiana administrative dataset. Due to the imbalanced nature of the\ndataset, imbalanced learning techniques including resampling, case weighting,\nand cost-sensitive learning have been applied to enhance the prediction\nperformance on the rare class. Performance metrics used in this study are\nF-measure, recall and precision of the rare class. We compare the performance\nof several machine learning algorithms such as neural networks, decision trees\nand bagging trees in combination with the imbalanced learning approaches using\nan administrative dataset of size of 366k+ from Louisiana Department of\nEducation. Experiments show that application of imbalanced learning methods\nproduces good results on recall but decreases precision, whereas base\nclassifiers without regard of imbalanced data handling gives better precision\nbut poor recall. Overall application of imbalanced learning techniques is\nbeneficial, yet more studies are desired to improve precision.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 00:30:33 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Orooji", "Marmar", ""], ["Chen", "Jianhua", ""]]}, {"id": "1910.13021", "submitter": "Emmanouil Vasileios Vlatakis Gkaragkounis", "authors": "Lampros Flokas, Emmanouil-Vasileios Vlatakis-Gkaragkounis and Georgios\n  Piliouras", "title": "Efficiently avoiding saddle points with zero order methods: No gradients\n  required", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the case of derivative-free algorithms for non-convex\noptimization, also known as zero order algorithms, that use only function\nevaluations rather than gradients. For a wide variety of gradient approximators\nbased on finite differences, we establish asymptotic convergence to second\norder stationary points using a carefully tailored application of the Stable\nManifold Theorem. Regarding efficiency, we introduce a noisy zero-order method\nthat converges to second order stationary points, i.e avoids saddle points. Our\nalgorithm uses only $\\tilde{\\mathcal{O}}(1 / \\epsilon^2)$ approximate gradient\ncalculations and, thus, it matches the converge rate guarantees of their exact\ngradient counterparts up to constants. In contrast to previous work, our\nconvergence rate analysis avoids imposing additional dimension dependent\nslowdowns in the number of iterations required for non-convex zero order\noptimization.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 00:45:45 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Flokas", "Lampros", ""], ["Vlatakis-Gkaragkounis", "Emmanouil-Vasileios", ""], ["Piliouras", "Georgios", ""]]}, {"id": "1910.13025", "submitter": "Chunfeng Cui", "authors": "Chunfeng Cui, Kaiqi Zhang, Talgat Daulbaev, Julia Gusak, Ivan\n  Oseledets, Zheng Zhang", "title": "Active Subspace of Neural Networks: Structural Analysis and Universal\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active subspace is a model reduction method widely used in the uncertainty\nquantification community. In this paper, we propose analyzing the internal\nstructure and vulnerability and deep neural networks using active subspace.\nFirstly, we employ the active subspace to measure the number of \"active\nneurons\" at each intermediate layer and reduce the number of neurons from\nseveral thousands to several dozens. This motivates us to change the network\nstructure and to develop a new and more compact network, referred to as\n{ASNet}, that has significantly fewer model parameters. Secondly, we propose\nanalyzing the vulnerability of a neural network using active subspace and\nfinding an additive universal adversarial attack vector that can misclassify a\ndataset with a high probability. Our experiments on CIFAR-10 show that ASNet\ncan achieve 23.98$\\times$ parameter and 7.30$\\times$ flops reduction. The\nuniversal active subspace attack vector can achieve around 20% higher attack\nratio compared with the existing approach in all of our numerical experiments.\nThe PyTorch codes for this paper are available online.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 01:03:23 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 12:25:32 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Cui", "Chunfeng", ""], ["Zhang", "Kaiqi", ""], ["Daulbaev", "Talgat", ""], ["Gusak", "Julia", ""], ["Oseledets", "Ivan", ""], ["Zhang", "Zheng", ""]]}, {"id": "1910.13029", "submitter": "Anderson de Andrade", "authors": "Anderson de Andrade", "title": "Best Practices for Convolutional Neural Networks Applied to Object\n  Recognition in Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research project studies the impact of convolutional neural networks\n(CNN) in image classification tasks. We explore different architectures and\ntraining configurations with the use of ReLUs, Nesterov's accelerated gradient,\ndropout and maxout networks. We work with the CIFAR-10 dataset as part of a\nKaggle competition to identify objects in images. Initial results show that\nCNNs outperform our baseline by acting as invariant feature detectors.\nComparisons between different preprocessing procedures show better results for\nglobal contrast normalization and ZCA whitening. ReLUs are much faster than\ntanh units and outperform sigmoids. We provide extensive details about our\ntraining hyperparameters, providing intuition for their selection that could\nhelp enhance learning in similar situations. We design 4 models of\nconvolutional neural networks that explore characteristics such as depth,\nnumber of feature maps, size and overlap of kernels, pooling regions, and\ndifferent subsampling techniques. Results favor models of moderate depth that\nuse an extensive number of parameters in both convolutional and dense layers.\nMaxout networks are able to outperform rectifiers on some models but introduce\ntoo much noise as the complexity of the fully-connected layers increases. The\nfinal discussion explains our results and provides additional techniques that\ncould improve performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 01:18:15 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["de Andrade", "Anderson", ""]]}, {"id": "1910.13034", "submitter": "Lala Li", "authors": "Lala Li, William Chan", "title": "Big Bidirectional Insertion Representations for Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Insertion Transformer is well suited for long form text generation due to\nits parallel generation capabilities, requiring $O(\\log_2 n)$ generation steps\nto generate $n$ tokens. However, modeling long sequences is difficult, as there\nis more ambiguity captured in the attention mechanism. This work proposes the\nBig Bidirectional Insertion Representations for Documents (Big BIRD), an\ninsertion-based model for document-level translation tasks. We scale up the\ninsertion-based models to long form documents. Our key contribution is\nintroducing sentence alignment via sentence-positional embeddings between the\nsource and target document. We show an improvement of +4.3 BLEU on the WMT'19\nEnglish$\\rightarrow$German document-level translation task compared with the\nInsertion Transformer baseline.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 01:38:24 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Li", "Lala", ""], ["Chan", "William", ""]]}, {"id": "1910.13038", "submitter": "David Ha", "authors": "C. Daniel Freeman, Luke Metz, David Ha", "title": "Learning to Predict Without Looking Ahead: World Models Without Forward\n  Prediction", "comments": "To appear at the Thirty-third Conference on Neural Information\n  Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much of model-based reinforcement learning involves learning a model of an\nagent's world, and training an agent to leverage this model to perform a task\nmore efficiently. While these models are demonstrably useful for agents, every\nnaturally occurring model of the world of which we are aware---e.g., a\nbrain---arose as the byproduct of competing evolutionary pressures for\nsurvival, not minimization of a supervised forward-predictive loss via gradient\ndescent. That useful models can arise out of the messy and slow optimization\nprocess of evolution suggests that forward-predictive modeling can arise as a\nside-effect of optimization under the right circumstances. Crucially, this\noptimization process need not explicitly be a forward-predictive loss. In this\nwork, we introduce a modification to traditional reinforcement learning which\nwe call observational dropout, whereby we limit the agents ability to observe\nthe real environment at each timestep. In doing so, we can coerce an agent into\nlearning a world model to fill in the observation gaps during reinforcement\nlearning. We show that the emerged world model, while not explicitly trained to\npredict the future, can help the agent learn key skills required to perform\nwell in its environment. Videos of our results available at\nhttps://learningtopredict.github.io/\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 02:17:27 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 00:30:18 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Freeman", "C. Daniel", ""], ["Metz", "Luke", ""], ["Ha", "David", ""]]}, {"id": "1910.13051", "submitter": "Angus Dempster", "authors": "Angus Dempster, Fran\\c{c}ois Petitjean, Geoffrey I. Webb", "title": "ROCKET: Exceptionally fast and accurate time series classification using\n  random convolutional kernels", "comments": "27 pages, 23 figures", "journal-ref": null, "doi": "10.1007/s10618-020-00701-z", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most methods for time series classification that attain state-of-the-art\naccuracy have high computational complexity, requiring significant training\ntime even for smaller datasets, and are intractable for larger datasets.\nAdditionally, many existing methods focus on a single type of feature such as\nshape or frequency. Building on the recent success of convolutional neural\nnetworks for time series classification, we show that simple linear classifiers\nusing random convolutional kernels achieve state-of-the-art accuracy with a\nfraction of the computational expense of existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 02:48:56 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Dempster", "Angus", ""], ["Petitjean", "Fran\u00e7ois", ""], ["Webb", "Geoffrey I.", ""]]}, {"id": "1910.13052", "submitter": "Feng Zhou", "authors": "Feng Zhou, Zhidong Li, Xuhui Fan, Yang Wang, Arcot Sowmya, Fang Chen", "title": "Scalable Inference for Nonparametric Hawkes Process Using\n  P\\'{o}lya-Gamma Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the sigmoid Gaussian Hawkes process model: the\nbaseline intensity and triggering kernel of Hawkes process are both modeled as\nthe sigmoid transformation of random trajectories drawn from Gaussian processes\n(GP). By introducing auxiliary latent random variables (branching structure,\nP\\'{o}lya-Gamma random variables and latent marked Poisson processes), the\nlikelihood is converted to two decoupled components with a Gaussian form which\nallows for an efficient conjugate analytical inference. Using the augmented\nlikelihood, we derive an expectation-maximization (EM) algorithm to obtain the\nmaximum a posteriori (MAP) estimate. Furthermore, we extend the EM algorithm to\nan efficient approximate Bayesian inference algorithm: mean-field variational\ninference. We demonstrate the performance of two algorithms on simulated\nfictitious data. Experiments on real data show that our proposed inference\nalgorithms can recover well the underlying prompting characteristics\nefficiently.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 02:49:19 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Zhou", "Feng", ""], ["Li", "Zhidong", ""], ["Fan", "Xuhui", ""], ["Wang", "Yang", ""], ["Sowmya", "Arcot", ""], ["Chen", "Fang", ""]]}, {"id": "1910.13055", "submitter": "Rui Fan", "authors": "Rui Fan, Yuan Wang, Lei Qiao, Ruiwen Yao, Peng Han, Weidong Zhang,\n  Ioannis Pitas, Ming Liu", "title": "PT-ResNet: Perspective Transformation-Based Residual Network for\n  Semantic Road Image Segmentation", "comments": "5 pages, 5 figures, accepted by 2019 IEEE International Conference on\n  Imaging Systems and Techniques (IST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic road region segmentation is a high-level task, which paves the way\ntowards road scene understanding. This paper presents a residual network\ntrained for semantic road segmentation. Firstly, we represent the projections\nof road disparities in the v-disparity map as a linear model, which can be\nestimated by optimizing the v-disparity map using dynamic programming. This\nlinear model is then utilized to reduce the redundant information in the left\nand right road images. The right image is also transformed into the left\nperspective view, which greatly enhances the road surface similarity between\nthe two images. Finally, the processed stereo images and their disparity maps\nare concatenated to create a set of 3D images, which are then utilized to train\nour neural network. The experimental results illustrate that our network\nachieves a maximum F1-measure of approximately 91.19% when analyzing the images\nfrom the KITTI road dataset.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 02:53:46 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Fan", "Rui", ""], ["Wang", "Yuan", ""], ["Qiao", "Lei", ""], ["Yao", "Ruiwen", ""], ["Han", "Peng", ""], ["Zhang", "Weidong", ""], ["Pitas", "Ioannis", ""], ["Liu", "Ming", ""]]}, {"id": "1910.13062", "submitter": "Ziye Zhang", "authors": "Ziye Zhang, Li Sun, Zhilin Zheng and Qingli Li", "title": "Disentangling the Spatial Structure and Style in Conditional VAE", "comments": "5 pages, 3 figures", "journal-ref": "Published on ICIP 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to disentangle the latent space in cVAE into the spatial\nstructure and the style code, which are complementary to each other, with one\nof them $z_s$ being label relevant and the other $z_u$ irrelevant. The\ngenerator is built by a connected encoder-decoder and a label condition mapping\nnetwork. Depending on whether the label is related with the spatial structure,\nthe output $z_s$ from the condition mapping network is used either as a style\ncode or a spatial structure code. The encoder provides the label irrelevant\nposterior from which $z_u$ is sampled. The decoder employs $z_s$ and $z_u$ in\neach layer by adaptive normalization like SPADE or AdaIN. Extensive experiments\non two datasets with different types of labels show the effectiveness of our\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 03:14:13 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 09:02:56 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Zhang", "Ziye", ""], ["Sun", "Li", ""], ["Zheng", "Zhilin", ""], ["Li", "Qingli", ""]]}, {"id": "1910.13067", "submitter": "The Canh Dinh", "authors": "Canh T. Dinh, Nguyen H. Tran, Minh N. H. Nguyen, Choong Seon Hong, Wei\n  Bao, Albert Y. Zomaya, Vincent Gramoli", "title": "Federated Learning over Wireless Networks: Convergence Analysis and\n  Resource Allocation", "comments": null, "journal-ref": null, "doi": "10.1109/TNET.2020.3035770", "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is an increasing interest in a fast-growing machine learning technique\ncalled Federated Learning, in which the model training is distributed over\nmobile user equipments (UEs), exploiting UEs' local computation and training\ndata. Despite its advantages in data privacy-preserving, Federated Learning\n(FL) still has challenges in heterogeneity across UEs' data and physical\nresources. We first propose a FL algorithm which can handle the heterogeneous\nUEs' data challenge without further assumptions except strongly convex and\nsmooth loss functions. We provide the convergence rate characterizing the\ntrade-off between local computation rounds of UE to update its local model and\nglobal communication rounds to update the FL global model. We then employ the\nproposed FL algorithm in wireless networks as a resource allocation\noptimization problem that captures the trade-off between the FL convergence\nwall clock time and energy consumption of UEs with heterogeneous computing and\npower resources. Even though the wireless resource allocation problem of FL is\nnon-convex, we exploit this problem's structure to decompose it into three\nsub-problems and analyze their closed-form solutions as well as insights to\nproblem design. Finally, we illustrate the theoretical analysis for the new\nalgorithm with Tensorflow experiments and extensive numerical results for the\nwireless resource allocation sub-problems. The experiment results not only\nverify the theoretical convergence but also show that our proposed algorithm\noutperforms the vanilla FedAvg algorithm in terms of convergence rate and\ntesting accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 03:31:28 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 03:31:59 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 00:16:29 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 03:09:33 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Dinh", "Canh T.", ""], ["Tran", "Nguyen H.", ""], ["Nguyen", "Minh N. H.", ""], ["Hong", "Choong Seon", ""], ["Bao", "Wei", ""], ["Zomaya", "Albert Y.", ""], ["Gramoli", "Vincent", ""]]}, {"id": "1910.13076", "submitter": "Alceu Emanuel Bissoto", "authors": "Alceu Bissoto, Eduardo Valle, Sandra Avila", "title": "The Six Fronts of the Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks fostered a newfound interest in generative\nmodels, resulting in a swelling wave of new works that new-coming researchers\nmay find formidable to surf. In this paper, we intend to help those\nresearchers, by splitting that incoming wave into six \"fronts\": Architectural\nContributions, Conditional Techniques, Normalization and Constraint\nContributions, Loss Functions, Image-to-image Translations, and Validation\nMetrics. The division in fronts organizes literature into approachable blocks,\nultimately communicating to the reader how the area is evolving. Previous\nsurveys in the area, which this works also tabulates, focus on a few of those\nfronts, leaving a gap that we propose to fill with a more integrated,\ncomprehensive overview. Here, instead of an exhaustive survey, we opt for a\nstraightforward review: our target is to be an entry point to this vast\nliterature, and also to be able to update experienced researchers to the newest\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 04:07:00 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Bissoto", "Alceu", ""], ["Valle", "Eduardo", ""], ["Avila", "Sandra", ""]]}, {"id": "1910.13089", "submitter": "Md Mahfuzur Rahman", "authors": "Md Mahfuzur Rahman, Daniel Pimentel-Alarcon", "title": "GLIMPS: A Greedy Mixed Integer Approach for Super Robust Matched\n  Subspace Detection", "comments": "8 pages, 5 figures, 57th Allerton Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Due to diverse nature of data acquisition and modern applications, many\ncontemporary problems involve high dimensional datum $\\x \\in \\R^\\d$ whose\nentries often lie in a union of subspaces and the goal is to find out which\nentries of $\\x$ match with a particular subspace $\\sU$, classically called\n\\emph {matched subspace detection}. Consequently, entries that match with one\nsubspace are considered as inliers w.r.t the subspace while all other entries\nare considered as outliers. Proportion of outliers relative to each subspace\nvaries based on the degree of coordinates from subspaces. This problem is a\ncombinatorial NP-hard in nature and has been immensely studied in recent years.\nExisting approaches can solve the problem when outliers are sparse. However, if\noutliers are abundant or in other words if $\\x$ contains coordinates from a\nfair amount of subspaces, this problem can't be solved with acceptable accuracy\nor within a reasonable amount of time. This paper proposes a two-stage approach\ncalled \\emph{Greedy Linear Integer Mixed Programmed Selector} (GLIMPS) for this\nabundant-outliers setting, which combines a greedy algorithm and mixed integer\nformulation and can tolerate over 80\\% outliers, outperforming the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 05:15:40 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Rahman", "Md Mahfuzur", ""], ["Pimentel-Alarcon", "Daniel", ""]]}, {"id": "1910.13090", "submitter": "Wenzhuo Song", "authors": "Wenzhuo Song, Hongxu Chen, Xueyan Liu, Hongzhe Jiang, Shengsheng Wang", "title": "Hyperbolic Node Embedding for Signed Networks", "comments": "32 pages", "journal-ref": null, "doi": "10.1016/j.neucom.2020.10.008", "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signed network embedding methods aim to learn vector representations of nodes\nin signed networks. However, existing algorithms only managed to embed networks\ninto low-dimensional Euclidean spaces whereas many intrinsic features of signed\nnetworks are reported more suitable for non-Euclidean spaces. For instance,\nprevious works did not consider the hierarchical structures of networks, which\nis widely witnessed in real-world networks. In this work, we answer an open\nquestion that whether the hyperbolic space is a better choice to accommodate\nsigned networks and learn embeddings that can preserve the corresponding\nspecial characteristics. We also propose a non-Euclidean signed network\nembedding method based on structural balance theory and Riemannian\noptimization, which embeds signed networks into a Poincar\\'e ball in a\nhyperbolic space. This space enables our approach to capture underlying\nhierarchy of nodes in signed networks because it can be seen as a continuous\ntree. We empirically compare our method against six Euclidean-based baselines\nin three tasks on seven real-world datasets, and the results show the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 05:17:00 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 06:01:26 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Song", "Wenzhuo", ""], ["Chen", "Hongxu", ""], ["Liu", "Xueyan", ""], ["Jiang", "Hongzhe", ""], ["Wang", "Shengsheng", ""]]}, {"id": "1910.13092", "submitter": "Huong Ha", "authors": "Huong Ha, Santu Rana, Sunil Gupta, Thanh Nguyen, Hung Tran-The, Svetha\n  Venkatesh", "title": "Bayesian Optimization with Unknown Search Space", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Bayesian optimization in problems wherein the search space is\nunknown is challenging. To address this problem, we propose a systematic volume\nexpansion strategy for the Bayesian optimization. We devise a strategy to\nguarantee that in iterative expansions of the search space, our method can find\na point whose function value within epsilon of the objective function maximum.\nWithout the need to specify any parameters, our algorithm automatically\ntriggers a minimal expansion required iteratively. We derive analytic\nexpressions for when to trigger the expansion and by how much to expand. We\nalso provide theoretical analysis to show that our method achieves\nepsilon-accuracy after a finite number of iterations. We demonstrate our method\non both benchmark test functions and machine learning hyper-parameter tuning\ntasks and demonstrate that our method outperforms baselines.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 05:31:24 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Ha", "Huong", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Nguyen", "Thanh", ""], ["Tran-The", "Hung", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1910.13101", "submitter": "Shuangfei Zhai", "authors": "Shuangfei Zhai, Walter Talbott, Carlos Guestrin, Joshua M. Susskind", "title": "Adversarial Fisher Vectors for Unsupervised Representation Learning", "comments": "Accepted as spotlight presentation to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine Generative Adversarial Networks (GANs) through the lens of deep\nEnergy Based Models (EBMs), with the goal of exploiting the density model that\nfollows from this formulation. In contrast to a traditional view where the\ndiscriminator learns a constant function when reaching convergence, here we\nshow that it can provide useful information for downstream tasks, e.g., feature\nextraction for classification. To be concrete, in the EBM formulation, the\ndiscriminator learns an unnormalized density function (i.e., the negative\nenergy term) that characterizes the data manifold. We propose to evaluate both\nthe generator and the discriminator by deriving corresponding Fisher Score and\nFisher Information from the EBM. We show that by assuming that the generated\nexamples form an estimate of the learned density, both the Fisher Information\nand the normalized Fisher Vectors are easy to compute. We also show that we are\nable to derive a distance metric between examples and between sets of examples.\nWe conduct experiments showing that the GAN-induced Fisher Vectors demonstrate\ncompetitive performance as unsupervised feature extractors for classification\nand perceptual similarity tasks. Code is available at\n\\url{https://github.com/apple/ml-afv}.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 06:10:48 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Zhai", "Shuangfei", ""], ["Talbott", "Walter", ""], ["Guestrin", "Carlos", ""], ["Susskind", "Joshua M.", ""]]}, {"id": "1910.13111", "submitter": "Lingchen Zhao", "authors": "Lingchen Zhao, Shengshan Hu, Qian Wang, Jianlin Jiang, Chao Shen,\n  Xiangyang Luo, Pengfei Hu", "title": "Shielding Collaborative Learning: Mitigating Poisoning Attacks through\n  Client-Side Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative learning allows multiple clients to train a joint model without\nsharing their data with each other. Each client performs training locally and\nthen submits the model updates to a central server for aggregation. Since the\nserver has no visibility into the process of generating the updates,\ncollaborative learning is vulnerable to poisoning attacks where a malicious\nclient can generate a poisoned update to introduce backdoor functionality to\nthe joint model. The existing solutions for detecting poisoned updates,\nhowever, fail to defend against the recently proposed attacks, especially in\nthe non-IID setting. In this paper, we present a novel defense scheme to detect\nanomalous updates in both IID and non-IID settings. Our key idea is to realize\nclient-side cross-validation, where each update is evaluated over other\nclients' local data. The server will adjust the weights of the updates based on\nthe evaluation results when performing aggregation. To adapt to the unbalanced\ndistribution of data in the non-IID setting, a dynamic client allocation\nmechanism is designed to assign detection tasks to the most suitable clients.\nDuring the detection process, we also protect the client-level privacy to\nprevent malicious clients from stealing the training data of other clients, by\nintegrating differential privacy with our design without degrading the\ndetection performance. Our experimental evaluations on two real-world datasets\nshow that our scheme is significantly robust to two representative poisoning\nattacks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 06:49:22 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 03:17:16 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Zhao", "Lingchen", ""], ["Hu", "Shengshan", ""], ["Wang", "Qian", ""], ["Jiang", "Jianlin", ""], ["Shen", "Chao", ""], ["Luo", "Xiangyang", ""], ["Hu", "Pengfei", ""]]}, {"id": "1910.13113", "submitter": "Kazuhiro Fukui", "authors": "Kazuhiro Fukui, Naoya Sogi, Takumi Kobayashi, Jing-Hao Xue, Atsuto\n  Maki", "title": "Discriminant analysis based on projection onto generalized difference\n  subspace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses a new type of discriminant analysis based on the\northogonal projection of data onto a generalized difference subspace (GDS). In\nour previous work, we have demonstrated that GDS projection works as the\nquasi-orthogonalization of class subspaces, which is an effective feature\nextraction for subspace based classifiers. Interestingly, GDS projection also\nworks as a discriminant feature extraction through a similar mechanism to the\nFisher discriminant analysis (FDA). A direct proof of the connection between\nGDS projection and FDA is difficult due to the significant difference in their\nformulations. To avoid the difficulty, we first introduce geometrical Fisher\ndiscriminant analysis (gFDA) based on a simplified Fisher criterion. Our\nsimplified Fisher criterion is derived from a heuristic yet practically\nplausible principle: the direction of the sample mean vector of a class is in\nmost cases almost equal to that of the first principal component vector of the\nclass, under the condition that the principal component vectors are calculated\nby applying the principal component analysis (PCA) without data centering. gFDA\ncan work stably even under few samples, bypassing the small sample size (SSS)\nproblem of FDA. Next, we prove that gFDA is equivalent to GDS projection with a\nsmall correction term. This equivalence ensures GDS projection to inherit the\ndiscriminant ability from FDA via gFDA. Furthermore, to enhance the\nperformances of gFDA and GDS projection, we normalize the projected vectors on\nthe discriminant spaces. Extensive experiments using the extended Yale B+\ndatabase and the CMU face database show that gFDA and GDS projection have\nequivalent or better performance than the original FDA and its extensions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 06:56:17 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 03:19:56 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Fukui", "Kazuhiro", ""], ["Sogi", "Naoya", ""], ["Kobayashi", "Takumi", ""], ["Xue", "Jing-Hao", ""], ["Maki", "Atsuto", ""]]}, {"id": "1910.13122", "submitter": "Araz Taeihagh", "authors": "Hazel Si Min Lim, and Araz Taeihagh", "title": "Algorithmic decision-making in AVs: Understanding ethical and technical\n  concerns for smart cities", "comments": null, "journal-ref": "Sustainability, 2019, 11(20), 5791", "doi": "10.3390/su11205791", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous Vehicles (AVs) are increasingly embraced around the world to\nadvance smart mobility and more broadly, smart, and sustainable cities.\nAlgorithms form the basis of decision-making in AVs, allowing them to perform\ndriving tasks autonomously, efficiently, and more safely than human drivers and\noffering various economic, social, and environmental benefits. However,\nalgorithmic decision-making in AVs can also introduce new issues that create\nnew safety risks and perpetuate discrimination. We identify bias, ethics, and\nperverse incentives as key ethical issues in the AV algorithms' decision-making\nthat can create new safety risks and discriminatory outcomes. Technical issues\nin the AVs' perception, decision-making and control algorithms, limitations of\nexisting AV testing and verification methods, and cybersecurity vulnerabilities\ncan also undermine the performance of the AV system. This article investigates\nthe ethical and technical concerns surrounding algorithmic decision-making in\nAVs by exploring how driving decisions can perpetuate discrimination and create\nnew safety risks for the public. We discuss steps taken to address these\nissues, highlight the existing research gaps and the need to mitigate these\nissues through the design of AV's algorithms and of policies and regulations to\nfully realise AVs' benefits for smart and sustainable cities.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 07:50:02 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Lim", "Hazel Si Min", ""], ["Taeihagh", "Araz", ""]]}, {"id": "1910.13124", "submitter": "Guillaume Godin", "authors": "Fabio Capela, Vincent Nouchi, Ruud Van Deursen, Igor V. Tetko and\n  Guillaume Godin", "title": "Multitask Learning On Graph Neural Networks Applied To Molecular\n  Property Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Prediction of molecular properties, including physico-chemical properties, is\na challenging task in chemistry. Herein we present a new state-of-the-art\nmultitask prediction method based on existing graph neural network models. We\nhave used different architectures for our models and the results clearly\ndemonstrate that multitask learning can improve model performance.\nAdditionally, a significant reduction of variance in the models has been\nobserved. Most importantly, datasets with a small amount of data points reach\nbetter results without the need of augmentation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 07:53:50 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 12:40:24 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Capela", "Fabio", ""], ["Nouchi", "Vincent", ""], ["Van Deursen", "Ruud", ""], ["Tetko", "Igor V.", ""], ["Godin", "Guillaume", ""]]}, {"id": "1910.13140", "submitter": "Neo Christopher Chung <", "authors": "Lennart Brocki, Neo Christopher Chung", "title": "Concept Saliency Maps to Visualize Relevant Features in Deep Generative\n  Models", "comments": "18th IEEE International Conference on Machine Learning and\n  Applications (ICMLA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating, explaining, and visualizing high-level concepts in generative\nmodels, such as variational autoencoders (VAEs), is challenging in part due to\na lack of known prediction classes that are required to generate saliency maps\nin supervised learning. While saliency maps may help identify relevant features\n(e.g., pixels) in the input for classification tasks of deep neural networks,\nsimilar frameworks are understudied in unsupervised learning. Therefore, we\nintroduce a new method of obtaining saliency maps for latent representations of\nknown or novel high-level concepts, often called concept vectors in generative\nmodels. Concept scores, analogous to class scores in classification tasks, are\ndefined as dot products between concept vectors and encoded input data, which\ncan be readily used to compute the gradients. The resulting concept saliency\nmaps are shown to highlight input features deemed important for high-level\nconcepts. Our method is applied to the VAE's latent space of CelebA dataset in\nwhich known attributes such as \"smiles\" and \"hats\" are used to elucidate\nrelevant facial features. Furthermore, our application to spatial\ntranscriptomic (ST) data of a mouse olfactory bulb demonstrates the potential\nof latent representations of morphological layers and molecular features in\nadvancing our understanding of complex biological systems. By extending the\npopular method of saliency maps to generative models, the proposed concept\nsaliency maps help improve interpretability of latent variable models in deep\nlearning.\n  Codes to reproduce and to implement concept saliency maps:\nhttps://github.com/lenbrocki/concept-saliency-maps\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 09:15:25 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Brocki", "Lennart", ""], ["Chung", "Neo Christopher", ""]]}, {"id": "1910.13141", "submitter": "Atsushi Yaguchi", "authors": "Atsushi Yaguchi, Taiji Suzuki, Shuhei Nitta, Yukinobu Sakata, Akiyuki\n  Tanizawa", "title": "Decomposable-Net: Scalable Low-Rank Compression for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressing deep neural networks (DNNs) is important for real-world\napplications operating on resource-constrained devices. However, it is not\nstraightforward to change the model size (i.e., computational complexity) once\ntraining and compression are completed, calling for retraining to construct\nmodels suitable for different devices. In this paper, we propose a novel\nmethod, Decomposable-Net (the network decomposable in any size), which allows\nflexible changes to model size without retraining. We decompose weight matrices\nin the DNNs via singular value decomposition and adjust ranks according to the\ntarget model size. Unlike the existing methods, (1) we propose a learning\nmethod that explicitly minimizes losses for both of full-rank and low-rank\nnetworks, which is designed not only to maintain the performance of a full-rank\nnetwork but also to improve multiple low-rank networks in a single model. (2)\nWe also provide a mathematical analysis for the scalability of the\napproximation error with respect to the rank in each layer. Moreover, on the\nbasis of the analysis, (3) we introduce a simple criterion for rank selection\nthat effectively suppresses approximation error. In experiments on\nimage-classification tasks on CIFAR-10/100 and ImageNet datasets,\nDecomposable-Net yields favorable performance in a broader range of compressed\nmodels. In particular, Decomposable-Net achieves the top-1 accuracy of $73.2\\%$\nwith $0.27\\times$MACs on the ImageNet classification task with ResNet-50,\ncompared to low-rank tensor (Tucker) decomposition ($67.4\\% / 0.30\\times$) and\nuniversally slimmable networks ($70.6\\% / 0.26\\times$).\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 09:15:40 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 07:32:42 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Yaguchi", "Atsushi", ""], ["Suzuki", "Taiji", ""], ["Nitta", "Shuhei", ""], ["Sakata", "Yukinobu", ""], ["Tanizawa", "Akiyuki", ""]]}, {"id": "1910.13148", "submitter": "Maxim Kuznetsov", "authors": "Maksim Kuznetsov and Daniil Polykovskiy and Dmitry Vetrov and\n  Alexander Zhebrak", "title": "A Prior of a Googol Gaussians: a Tensor Ring Induced Prior for\n  Generative Models", "comments": "NeurIPS 2019; GitHub: https://github.com/insilicomedicine/TRIP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models produce realistic objects in many domains, including text,\nimage, video, and audio synthesis. Most popular models---Generative Adversarial\nNetworks (GANs) and Variational Autoencoders (VAEs)---usually employ a standard\nGaussian distribution as a prior. Previous works show that the richer family of\nprior distributions may help to avoid the mode collapse problem in GANs and to\nimprove the evidence lower bound in VAEs. We propose a new family of prior\ndistributions---Tensor Ring Induced Prior (TRIP)---that packs an exponential\nnumber of Gaussians into a high-dimensional lattice with a relatively small\nnumber of parameters. We show that these priors improve Fr\\'echet Inception\nDistance for GANs and Evidence Lower Bound for VAEs. We also study generative\nmodels with TRIP in the conditional generation setup with missing conditions.\nAltogether, we propose a novel plug-and-play framework for generative models\nthat can be utilized in any GAN and VAE-like architectures.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 09:33:09 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Kuznetsov", "Maksim", ""], ["Polykovskiy", "Daniil", ""], ["Vetrov", "Dmitry", ""], ["Zhebrak", "Alexander", ""]]}, {"id": "1910.13153", "submitter": "Garrett Bernstein", "authors": "Garrett Bernstein and Daniel Sheldon", "title": "Differentially Private Bayesian Linear Regression", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear regression is an important tool across many fields that work with\nsensitive human-sourced data. Significant prior work has focused on producing\ndifferentially private point estimates, which provide a privacy guarantee to\nindividuals while still allowing modelers to draw insights from data by\nestimating regression coefficients. We investigate the problem of Bayesian\nlinear regression, with the goal of computing posterior distributions that\ncorrectly quantify uncertainty given privately released statistics. We show\nthat a naive approach that ignores the noise injected by the privacy mechanism\ndoes a poor job in realistic data settings. We then develop noise-aware methods\nthat perform inference over the privacy mechanism and produce correct\nposteriors across a wide range of scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 09:47:23 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Bernstein", "Garrett", ""], ["Sheldon", "Daniel", ""]]}, {"id": "1910.13157", "submitter": "Eran Treister", "authors": "Jonathan Ephrath, Moshe Eliasof, Lars Ruthotto, Eldad Haber and Eran\n  Treister", "title": "LeanConvNets: Low-cost Yet Effective Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2020.2972775", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have become indispensable for solving\nmachine learning tasks in speech recognition, computer vision, and other areas\nthat involve high-dimensional data. A CNN filters the input feature using a\nnetwork containing spatial convolution operators with compactly supported\nstencils. In practice, the input data and the hidden features consist of a\nlarge number of channels, which in most CNNs are fully coupled by the\nconvolution operators. This coupling leads to immense computational cost in the\ntraining and prediction phase. In this paper, we introduce LeanConvNets that\nare derived by sparsifying fully-coupled operators in existing CNNs. Our goal\nis to improve the efficiency of CNNs by reducing the number of weights,\nfloating point operations and latency times, with minimal loss of accuracy. Our\nlean convolution operators involve tuning parameters that controls the\ntrade-off between the network's accuracy and computational costs. These\nconvolutions can be used in a wide range of existing networks, and we exemplify\ntheir use in residual networks (ResNets). Using a range of benchmark problems\nfrom image classification and semantic segmentation, we demonstrate that the\nresulting LeanConvNet's accuracy is close to state-of-the-art networks while\nbeing computationally less expensive. In our tests, the lean versions of ResNet\nin most cases outperform comparable reduced architectures such as MobileNets\nand ShuffleNets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 09:51:10 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 10:50:12 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Ephrath", "Jonathan", ""], ["Eliasof", "Moshe", ""], ["Ruthotto", "Lars", ""], ["Haber", "Eldad", ""], ["Treister", "Eran", ""]]}, {"id": "1910.13162", "submitter": "Hoang Nhat Suong", "authors": "Suong N. Hoang, Linh V. Nguyen, Tai Huynh and Vuong T. Pham", "title": "An Efficient Model for Sentiment Analysis of Electronic Product Reviews\n  in Vietnamese", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the past few years, the growth of e-commerce and digital marketing in\nVietnam has generated a huge volume of opinionated data. Analyzing those data\nwould provide enterprises with insight for better business decisions. In this\nwork, as part of the Advosights project, we study sentiment analysis of product\nreviews in Vietnamese. The final solution is based on Self-attention neural\nnetworks, a flexible architecture for text classification task with about\n90.16% of accuracy in 0.0124 second, a very fast inference time.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 10:06:56 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Hoang", "Suong N.", ""], ["Nguyen", "Linh V.", ""], ["Huynh", "Tai", ""], ["Pham", "Vuong T.", ""]]}, {"id": "1910.13181", "submitter": "Talip Ucar", "authors": "Talip Ucar", "title": "Bridging the ELBO and MMD", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in training generative models such as the variational\nauto encoder (VAE) is avoiding posterior collapse. When the generator has too\nmuch capacity, it is prone to ignoring latent code. This problem is exacerbated\nwhen the dataset is small, and the latent dimension is high. The root of the\nproblem is the ELBO objective, specifically the Kullback-Leibler (KL)\ndivergence term in objective function \\citep{zhao2019infovae}. This paper\nproposes a new objective function to replace the KL term with one that emulates\nthe maximum mean discrepancy (MMD) objective. It also introduces a new\ntechnique, named latent clipping, that is used to control distance between\nsamples in latent space. A probabilistic autoencoder model, named $\\mu$-VAE, is\ndesigned and trained on MNIST and MNIST Fashion datasets, using the new\nobjective function and is shown to outperform models trained with ELBO and\n$\\beta$-VAE objective. The $\\mu$-VAE is less prone to posterior collapse, and\ncan generate reconstructions and new samples in good quality. Latent\nrepresentations learned by $\\mu$-VAE are shown to be good and can be used for\ndownstream tasks such as classification.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 10:32:40 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Ucar", "Talip", ""]]}, {"id": "1910.13188", "submitter": "Kuen-Han Tsai", "authors": "Kuen-Han Tsai and Hsuan-Tien Lin", "title": "Learning from Label Proportions with Consistency Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning from label proportions (LLP) involves training\nclassifiers with weak labels on bags of instances, rather than strong labels on\nindividual instances. The weak labels only contain the label proportion of each\nbag. The LLP problem is important for many practical applications that only\nallow label proportions to be collected because of data privacy or annotation\ncost, and has recently received lots of research attention. Most existing works\nfocus on extending supervised learning models to solve the LLP problem, but the\nweak learning nature makes it hard to further improve LLP performance with a\nsupervised angle. In this paper, we take a different angle from semi-supervised\nlearning. In particular, we propose a novel model inspired by consistency\nregularization, a popular concept in semi-supervised learning that encourages\nthe model to produce a decision boundary that better describes the data\nmanifold. With the introduction of consistency regularization, we further\nextend our study to non-uniform bag-generation and validation-based\nparameter-selection procedures that better match practical needs. Experiments\nnot only justify that LLP with consistency regularization achieves superior\nperformance, but also demonstrate the practical usability of the proposed\nprocedures.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 10:46:15 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Tsai", "Kuen-Han", ""], ["Lin", "Hsuan-Tien", ""]]}, {"id": "1910.13196", "submitter": "Florian K\\\"opf", "authors": "Florian K\\\"opf, Samuel Tesfazgi, Michael Flad, S\\\"oren Hohmann", "title": "Deep Decentralized Reinforcement Learning for Cooperative Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to collaborate efficiently with unknown partners in cooperative\ncontrol settings, adaptation of the partners based on online experience is\nrequired. The rather general and widely applicable control setting, where each\ncooperation partner might strive for individual goals while the control laws\nand objectives of the partners are unknown, entails various challenges such as\nthe non-stationarity of the environment, the multi-agent credit assignment\nproblem, the alter-exploration problem and the coordination problem. We propose\nnew, modular deep decentralized Multi-Agent Reinforcement Learning mechanisms\nto account for these challenges. Therefore, our method uses a time-dependent\nprioritization of samples, incorporates a model of the system dynamics and\nutilizes variable, accountability-driven learning rates and simulated,\nartificial experiences in order to guide the learning process. The\neffectiveness of our method is demonstrated by means of a simulated, nonlinear\ncooperative control task.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:06:56 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["K\u00f6pf", "Florian", ""], ["Tesfazgi", "Samuel", ""], ["Flad", "Michael", ""], ["Hohmann", "S\u00f6ren", ""]]}, {"id": "1910.13197", "submitter": "Ghodai Abdelrahman", "authors": "Ghodai Abdelrahman and Qing Wang", "title": "Knowledge Tracing with Sequential Key-Value Memory Networks", "comments": null, "journal-ref": "Proceedings of the 42Nd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (2019)", "doi": "10.1145/3331184.3331195", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can machines trace human knowledge like humans? Knowledge tracing (KT) is a\nfundamental task in a wide range of applications in education, such as massive\nopen online courses (MOOCs), intelligent tutoring systems, educational games,\nand learning management systems. It models dynamics in a student's knowledge\nstates in relation to different learning concepts through their interactions\nwith learning activities. Recently, several attempts have been made to use deep\nlearning models for tackling the KT problem. Although these deep learning\nmodels have shown promising results, they have limitations: either lack the\nability to go deeper to trace how specific concepts in a knowledge state are\nmastered by a student, or fail to capture long-term dependencies in an exercise\nsequence. In this paper, we address these limitations by proposing a novel deep\nlearning model for knowledge tracing, namely Sequential Key-Value Memory\nNetworks (SKVMN). This model unifies the strengths of recurrent modelling\ncapacity and memory capacity of the existing deep learning KT models for\nmodelling student learning. We have extensively evaluated our proposed model on\nfive benchmark datasets. The experimental results show that (1) SKVMN\noutperforms the state-of-the-art KT models on all datasets, (2) SKVMN can\nbetter discover the correlation between latent concepts and questions, and (3)\nSKVMN can trace the knowledge state of students dynamics, and a leverage\nsequential dependencies in an exercise sequence for improved predication\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:10:50 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Abdelrahman", "Ghodai", ""], ["Wang", "Qing", ""]]}, {"id": "1910.13204", "submitter": "Bulat Ibragimov", "authors": "Bulat Ibragimov and Gleb Gusev", "title": "Minimal Variance Sampling in Stochastic Gradient Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Boosting (SGB) is a widely used approach to\nregularization of boosting models based on decision trees. It was shown that,\nin many cases, random sampling at each iteration can lead to better\ngeneralization performance of the model and can also decrease the learning\ntime. Different sampling approaches were proposed, where probabilities are not\nuniform, and it is not currently clear which approach is the most effective. In\nthis paper, we formulate the problem of randomization in SGB in terms of\noptimization of sampling probabilities to maximize the estimation accuracy of\nsplit scoring used to train decision trees. This optimization problem has a\nclosed-form nearly optimal solution, and it leads to a new sampling technique,\nwhich we call Minimal Variance Sampling (MVS). The method both decreases the\nnumber of examples needed for each iteration of boosting and increases the\nquality of the model significantly as compared to the state-of-the art sampling\nmethods. The superiority of the algorithm was confirmed by introducing MVS as a\nnew default option for subsampling in CatBoost, a gradient boosting library\nachieving state-of-the-art quality on various machine learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:26:24 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Ibragimov", "Bulat", ""], ["Gusev", "Gleb", ""]]}, {"id": "1910.13212", "submitter": "Mimansa Jaiswal", "authors": "Mimansa Jaiswal, Emily Mower Provost", "title": "Privacy Enhanced Multimodal Neural Representations for Emotion\n  Recognition", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mobile applications and virtual conversational agents now aim to\nrecognize and adapt to emotions. To enable this, data are transmitted from\nusers' devices and stored on central servers. Yet, these data contain sensitive\ninformation that could be used by mobile applications without user's consent\nor, maliciously, by an eavesdropping adversary. In this work, we show how\nmultimodal representations trained for a primary task, here emotion\nrecognition, can unintentionally leak demographic information, which could\noverride a selected opt-out option by the user. We analyze how this leakage\ndiffers in representations obtained from textual, acoustic, and multimodal\ndata. We use an adversarial learning paradigm to unlearn the private\ninformation present in a representation and investigate the effect of varying\nthe strength of the adversarial component on the primary task and on the\nprivacy metric, defined here as the inability of an attacker to predict\nspecific demographic information. We evaluate this paradigm on multiple\ndatasets and show that we can improve the privacy metric while not\nsignificantly impacting the performance on the primary task. To the best of our\nknowledge, this is the first work to analyze how the privacy metric differs\nacross modalities and how multiple privacy concerns can be tackled while still\nmaintaining performance on emotion recognition.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:49:30 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Jaiswal", "Mimansa", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1910.13213", "submitter": "Yat Long Lo", "authors": "Yat Long Lo and Sina Ghiassian", "title": "Overcoming Catastrophic Interference in Online Reinforcement Learning\n  with Dynamic Self-Organizing Maps", "comments": "9 Pages, 7 Figures, NeurIPS Workshop on Biological and Artificial\n  Reinforcement Learning, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using neural networks in the reinforcement learning (RL) framework has\nachieved notable successes. Yet, neural networks tend to forget what they\nlearned in the past, especially when they learn online and fully incrementally,\na setting in which the weights are updated after each sample is received and\nthe sample is then discarded. Under this setting, an update can lead to overly\nglobal generalization by changing too many weights. The global generalization\ninterferes with what was previously learned and deteriorates performance, a\nphenomenon known as catastrophic interference. Many previous works use\nmechanisms such as experience replay (ER) buffers to mitigate interference by\nperforming minibatch updates, ensuring the data distribution is approximately\nindependent-and-identically-distributed (i.i.d.). But using ER would become\ninfeasible in terms of memory as problem complexity increases. Thus, it is\ncrucial to look for more memory-efficient alternatives. Interference can be\naverted if we replace global updates with more local ones, so only weights\nresponsible for the observed data sample are updated. In this work, we propose\nthe use of dynamic self-organizing map (DSOM) with neural networks to induce\nsuch locality in the updates without ER buffers. Our method learns a DSOM to\nproduce a mask to reweigh each hidden unit's output, modulating its degree of\nuse. It prevents interference by replacing global updates with local ones,\nconditioned on the agent's state. We validate our method on standard RL\nbenchmarks including Mountain Car and Lunar Lander, where existing methods\noften fail to learn without ER. Empirically, we show that our online and fully\nincremental method is on par with and in some cases, better than\nstate-of-the-art in terms of final performance and learning speed. We provide\nvisualizations and quantitative measures to show that our method indeed\nmitigates interference.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:50:39 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Lo", "Yat Long", ""], ["Ghiassian", "Sina", ""]]}, {"id": "1910.13233", "submitter": "George Papamakarios", "authors": "George Papamakarios", "title": "Neural Density Estimation and Likelihood-free Inference", "comments": "PhD thesis submitted to the University of Edinburgh in April 2019.\n  Includes in full the following articles: arXiv:1605.06376, arXiv:1705.07057,\n  arXiv:1805.07226", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I consider two problems in machine learning and statistics: the problem of\nestimating the joint probability density of a collection of random variables,\nknown as density estimation, and the problem of inferring model parameters when\ntheir likelihood is intractable, known as likelihood-free inference. The\ncontribution of the thesis is a set of new methods for addressing these\nproblems that are based on recent advances in neural networks and deep\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 12:52:33 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Papamakarios", "George", ""]]}, {"id": "1910.13249", "submitter": "Florian Golemo", "authors": "Martin Weiss, Simon Chamorro, Roger Girgis, Margaux Luck, Samira E.\n  Kahou, Joseph P. Cohen, Derek Nowrouzezahrai, Doina Precup, Florian Golemo,\n  Chris Pal", "title": "Navigation Agents for the Visually Impaired: A Sidewalk Simulator and\n  Experiments", "comments": "Accepted at CoRL2019. Code & video available at\n  https://mweiss17.github.io/SEVN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of blind and visually-impaired (BVI) people navigate urban\nenvironments every day, using smartphones for high-level path-planning and\nwhite canes or guide dogs for local information. However, many BVI people still\nstruggle to travel to new places. In our endeavor to create a navigation\nassistant for the BVI, we found that existing Reinforcement Learning (RL)\nenvironments were unsuitable for the task. This work introduces SEVN, a\nsidewalk simulation environment and a neural network-based approach to creating\na navigation agent. SEVN contains panoramic images with labels for house\nnumbers, doors, and street name signs, and formulations for several navigation\ntasks. We study the performance of an RL algorithm (PPO) in this setting. Our\npolicy model fuses multi-modal observations in the form of variable resolution\nimages, visible text, and simulated GPS data to navigate to a goal door. We\nhope that this dataset, simulator, and experimental results will provide a\nfoundation for further research into the creation of agents that can assist\nmembers of the BVI community with outdoor navigation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 13:23:02 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Weiss", "Martin", ""], ["Chamorro", "Simon", ""], ["Girgis", "Roger", ""], ["Luck", "Margaux", ""], ["Kahou", "Samira E.", ""], ["Cohen", "Joseph P.", ""], ["Nowrouzezahrai", "Derek", ""], ["Precup", "Doina", ""], ["Golemo", "Florian", ""], ["Pal", "Chris", ""]]}, {"id": "1910.13253", "submitter": "Jun Wang", "authors": "Max W. Y. Lam, Jun Wang, Dan Su, Dong Yu", "title": "Mixup-breakdown: a consistency training method for improving\n  generalization of speech separation models", "comments": "Accepted in a Lesson session in ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-learning based speech separation models confront poor generalization\nproblem that even the state-of-the-art models could abruptly fail when\nevaluating them in mismatch conditions. To address this problem, we propose an\neasy-to-implement yet effective consistency based semi-supervised learning\n(SSL) approach, namely Mixup-Breakdown training (MBT). It learns a teacher\nmodel to \"breakdown\" unlabeled inputs, and the estimated separations are\ninterpolated to produce more useful pseudo \"mixup\" input-output pairs, on which\nthe consistency regularization could apply for learning a student model. In our\nexperiment, we evaluate MBT under various conditions with ascending degrees of\nmismatch, including unseen interfering speech, noise, and music, and compare\nMBT's generalization capability against state-of-the-art supervised learning\nand SSL approaches. The result indicates that MBT significantly outperforms\nseveral strong baselines with up to 13.77% relative SI-SNRi improvement.\nMoreover, MBT only adds negligible computational overhead to standard training\nschemes.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 03:34:42 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 11:34:34 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 10:00:06 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Lam", "Max W. Y.", ""], ["Wang", "Jun", ""], ["Su", "Dan", ""], ["Yu", "Dong", ""]]}, {"id": "1910.13255", "submitter": "Yosi Shrem", "authors": "Yosi Shrem, Matthew Goldrick, Joseph Keshet", "title": "Dr.VOT : Measuring Positive and Negative Voice Onset Time in the Wild", "comments": "interspeech 2019", "journal-ref": "interspeech 2019", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice Onset Time (VOT), a key measurement of speech for basic research and\napplied medical studies, is the time between the onset of a stop burst and the\nonset of voicing. When the voicing onset precedes burst onset the VOT is\nnegative; if voicing onset follows the burst, it is positive. In this work, we\npresent a deep-learning model for accurate and reliable measurement of VOT in\nnaturalistic speech. The proposed system addresses two critical issues: it can\nmeasure positive and negative VOT equally well, and it is trained to be robust\nto variation across annotations. Our approach is based on the structured\nprediction framework, where the feature functions are defined to be RNNs. These\nlearn to capture segmental variation in the signal. Results suggest that our\nmethod substantially improves over the current state-of-the-art. In contrast to\nprevious work, our Deep and Robust VOT annotator, Dr.VOT, can successfully\nestimate negative VOTs while maintaining state-of-the-art performance on\npositive VOTs. This high level of performance generalizes to new corpora\nwithout further retraining. Index Terms: structured prediction, multi-task\nlearning, adversarial training, recurrent neural networks, sequence\nsegmentation.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 12:42:52 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Shrem", "Yosi", ""], ["Goldrick", "Matthew", ""], ["Keshet", "Joseph", ""]]}, {"id": "1910.13257", "submitter": "Diogo R. Ferreira", "authors": "Diogo R. Ferreira, Pedro J. Carvalho, Hor\\'acio Fernandes (JET\n  Contributors)", "title": "Deep Learning for Plasma Tomography and Disruption Prediction from\n  Bolometer Data", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.00333", "journal-ref": "IEEE Transactions on Plasma Science, 2019", "doi": "10.1109/TPS.2019.2947304", "report-no": null, "categories": "physics.plasm-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep learning is facilitating a wide range of data processing\ntasks in many areas. The analysis of fusion data is no exception, since there\nis a need to process large amounts of data collected from the diagnostic\nsystems attached to a fusion device. Fusion data involves images and time\nseries, and are a natural candidate for the use of convolutional and recurrent\nneural networks. In this work, we describe how CNNs can be used to reconstruct\nthe plasma radiation profile, and we discuss the potential of using RNNs for\ndisruption prediction based on the same input data. Both approaches have been\napplied at JET using data from a multi-channel diagnostic system. Similar\napproaches can be applied to other fusion devices and diagnostics.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 11:37:24 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Ferreira", "Diogo R.", "", "JET\n  Contributors"], ["Carvalho", "Pedro J.", "", "JET\n  Contributors"], ["Fernandes", "Hor\u00e1cio", "", "JET\n  Contributors"]]}, {"id": "1910.13272", "submitter": "Tyler Westenbroek", "authors": "Tyler Westenbroek, David Fridovich-Keil, Eric Mazumdar, Shreyas Arora,\n  Valmik Prabhu, S. Shankar Sastry, and Claire J. Tomlin", "title": "Feedback Linearization for Unknown Systems via Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel approach to control design for nonlinear systems which\nleverages model-free policy optimization techniques to learn a linearizing\ncontroller for a physical plant with unknown dynamics. Feedback linearization\nis a technique from nonlinear control which renders the input-output dynamics\nof a nonlinear plant \\emph{linear} under application of an appropriate feedback\ncontroller. Once a linearizing controller has been constructed, desired output\ntrajectories for the nonlinear plant can be tracked using a variety of linear\ncontrol techniques. However, the calculation of a linearizing controller\nrequires a precise dynamics model for the system. As a result, model-based\napproaches for learning exact linearizing controllers generally require a\nsimple, highly structured model of the system with easily identifiable\nparameters. In contrast, the model-free approach presented in this paper is\nable to approximate the linearizing controller for the plant using general\nfunction approximation architectures. Specifically, we formulate a\ncontinuous-time optimization problem over the parameters of a learned\nlinearizing controller whose optima are the set of parameters which best\nlinearize the plant. We derive conditions under which the learning problem is\n(strongly) convex and provide guarantees which ensure the true linearizing\ncontroller for the plant is recovered. We then discuss how model-free policy\noptimization algorithms can be used to solve a discrete-time approximation to\nthe problem using data collected from the real-world plant. The utility of the\nframework is demonstrated in simulation and on a real-world robotic platform.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 13:52:04 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 22:34:56 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Westenbroek", "Tyler", ""], ["Fridovich-Keil", "David", ""], ["Mazumdar", "Eric", ""], ["Arora", "Shreyas", ""], ["Prabhu", "Valmik", ""], ["Sastry", "S. Shankar", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "1910.13282", "submitter": "Zhao You", "authors": "Zhao You, Dan Su, Jie Chen, Chao Weng, Dong Yu", "title": "DFSMN-SAN with Persistent Memory Model for Automatic Speech Recognition", "comments": "5 pages, 2 figures, subbmitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention networks (SAN) have been introduced into automatic speech\nrecognition (ASR) and achieved state-of-the-art performance owing to its\nsuperior ability in capturing long term dependency. One of the key ingredients\nis the self-attention mechanism which can be effectively performed on the whole\nutterance level. In this paper, we try to investigate whether even more\ninformation beyond the whole utterance level can be exploited and beneficial.\nWe propose to apply self-attention layer with augmented memory to ASR.\nSpecifically, we first propose a variant model architecture which combines deep\nfeed-forward sequential memory network (DFSMN) with self-attention layers to\nform a better baseline model compared with a purely self-attention network.\nThen, we propose and compare two kinds of additional memory structures added\ninto self-attention layers. Experiments on large-scale LVCSR tasks show that on\nfour individual test sets, the DFSMN-SAN architecture outperforms vanilla SAN\nencoder by 5% relatively in character error rate (CER). More importantly, the\nadditional memory structure provides further 5% to 11% relative improvement in\nCER.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 04:58:23 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["You", "Zhao", ""], ["Su", "Dan", ""], ["Chen", "Jie", ""], ["Weng", "Chao", ""], ["Yu", "Dong", ""]]}, {"id": "1910.13288", "submitter": "Lantian Li Mr.", "authors": "Haoran Sun and Yunqi Cai and Lantian Li and Dong Wang", "title": "On Investigation of Unsupervised Speech Factorization Based on\n  Normalization Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech signals are complex composites of various information, including\nphonetic content, speaker traits, channel effect, etc. Decomposing this\ncomplicated mixture into independent factors, i.e., speech factorization, is\nfundamentally important and plays the central role in many important algorithms\nof modern speech processing tasks. In this paper, we present a preliminary\ninvestigation on unsupervised speech factorization based on the normalization\nflow model. This model constructs a complex invertible transform, by which we\ncan project speech segments into a latent code space where the distribution is\na simple diagonal Gaussian. Our preliminary investigation on the TIMIT database\nshows that this code space exhibits favorable properties such as denseness and\npseudo linearity, and perceptually important factors such as phonetic content\nand speaker trait can be represented as particular directions within the code\nspace.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 14:26:22 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Sun", "Haoran", ""], ["Cai", "Yunqi", ""], ["Li", "Lantian", ""], ["Wang", "Dong", ""]]}, {"id": "1910.13291", "submitter": "Ekaterina Artemova", "authors": "Dmitry Popov and Alexander Pugachev and Polina Svyatokum and Elizaveta\n  Svitanko and Ekaterina Artemova", "title": "Sentence Embeddings for Russian NLU", "comments": "to appear in AIST2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the performance of sentence embeddings models on several tasks\nfor the Russian language. In our comparison, we include such tasks as multiple\nchoice question answering, next sentence prediction, and paraphrase\nidentification. We employ FastText embeddings as a baseline and compare it to\nELMo and BERT embeddings. We conduct two series of experiments, using both\nunsupervised (i.e., based on similarity measure only) and supervised approaches\nfor the tasks. Finally, we present datasets for multiple choice question\nanswering and next sentence prediction in Russian.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 14:28:34 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Popov", "Dmitry", ""], ["Pugachev", "Alexander", ""], ["Svyatokum", "Polina", ""], ["Svitanko", "Elizaveta", ""], ["Artemova", "Ekaterina", ""]]}, {"id": "1910.13292", "submitter": "Luis Miralles PHD", "authors": "Luis Miralles, M. Atif Qureshi, Brian Mac Namee", "title": "Real-time Bidding campaigns optimization using attribute selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-Time Bidding is nowadays one of the most promising systems in the online\nadvertising ecosystem. In the presented study, the performance of RTB campaigns\nis improved by optimising the parameters of the users' profiles and the\npublishers' websites. Most studies about optimising RTB campaigns are focused\non the bidding strategy. In contrast, the objective of our research consists of\noptimising RTB campaigns by finding out configurations that maximise both the\nnumber of impressions and their average profitability. The experiments\ndemonstrate that, when the number of required visits by advertisers is low, it\nis easy to find configurations with high average profitability, but as the\nrequired number of visits increases, the average profitability tends to go\ndown. Additionally, configuration optimisation has been combined with other\ninteresting strategies to increase, even more, the campaigns' profitability.\nAlong with parameter configuration the study considers the following\ncomplementary strategies to increase profitability: i) selecting multiple\nconfigurations with a small number of visits instead of a unique configuration\nwith a large number, ii) discarding visits according to the thresholds of cost\nand profitability, iii) analysing a reduced space of the dataset and\nextrapolating the solution, and iv) increasing the search space by including\nsolutions below the required number of visits. The developed campaign\noptimisation methodology could be offered by RTB platforms to advertisers to\nmake their campaigns more profitable.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 14:30:15 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Miralles", "Luis", ""], ["Qureshi", "M. Atif", ""], ["Mac Namee", "Brian", ""]]}, {"id": "1910.13294", "submitter": "Mo Yu", "authors": "Mo Yu, Shiyu Chang, Yang Zhang, Tommi S. Jaakkola", "title": "Rethinking Cooperative Rationalization: Introspective Extraction and\n  Complement Control", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective rationalization has become a common mechanism to ensure that\npredictive models reveal how they use any available features. The selection may\nbe soft or hard, and identifies a subset of input features relevant for\nprediction. The setup can be viewed as a co-operate game between the selector\n(aka rationale generator) and the predictor making use of only the selected\nfeatures. The co-operative setting may, however, be compromised for two\nreasons. First, the generator typically has no direct access to the outcome it\naims to justify, resulting in poor performance. Second, there's typically no\ncontrol exerted on the information left outside the selection. We revise the\noverall co-operative framework to address these challenges. We introduce an\nintrospective model which explicitly predicts and incorporates the outcome into\nthe selection process. Moreover, we explicitly control the rationale complement\nvia an adversary so as not to leave any useful information out of the\nselection. We show that the two complementary mechanisms maintain both high\npredictive accuracy and lead to comprehensive rationales.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 14:32:54 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 21:21:15 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Yu", "Mo", ""], ["Chang", "Shiyu", ""], ["Zhang", "Yang", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1910.13295", "submitter": "Pedro Herruzo", "authors": "Pedro Herruzo and Josep L. Larriba-Pey", "title": "Recurrent Autoencoder with Skip Connections and Exogenous Variables for\n  Traffic Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The increasing complexity of mobility plus the growing population in cities,\ntogether with the importance of privacy when sharing data from vehicles or any\ndevice, makes traffic forecasting that uses data from infrastructure and\ncitizens an open and challenging task. In this paper, we introduce a novel\napproach to deal with predictions of speed, volume, and main traffic direction,\nin a new aggregated way of traffic data presented as videos. The approach\nleverages the continuity in a sequence of frames and its dynamics, learning to\npredict changing areas in a low dimensional space and then, recovering static\nfeatures when reconstructing the original space. Exogenous variables like\nweather, time and calendar are also added in the model. Furthermore, we\nintroduce a novel sampling approach for sequences that ensures diversity when\ncreating batches, running in parallel to the optimization process.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:04:56 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Herruzo", "Pedro", ""], ["Larriba-Pey", "Josep L.", ""]]}, {"id": "1910.13296", "submitter": "Thai Son Nguyen", "authors": "Thai-Son Nguyen, Sebastian Stueker, Jan Niehues, Alex Waibel", "title": "Improving sequence-to-sequence speech recognition training with\n  on-the-fly data augmentation", "comments": "To appear in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-Sequence (S2S) models recently started to show state-of-the-art\nperformance for automatic speech recognition (ASR). With these large and deep\nmodels overfitting remains the largest problem, outweighing performance\nimprovements that can be obtained from better architectures. One solution to\nthe overfitting problem is increasing the amount of available training data and\nthe variety exhibited by the training data with the help of data augmentation.\nIn this paper we examine the influence of three data augmentation methods on\nthe performance of two S2S model architectures. One of the data augmentation\nmethod comes from literature, while two other methods are our own development -\na time perturbation in the frequency domain and sub-sequence sampling. Our\nexperiments on Switchboard and Fisher data show state-of-the-art performance\nfor S2S models that are trained solely on the speech training data and do not\nuse additional text data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 14:38:22 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 08:12:31 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Nguyen", "Thai-Son", ""], ["Stueker", "Sebastian", ""], ["Niehues", "Jan", ""], ["Waibel", "Alex", ""]]}, {"id": "1910.13314", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Blaz \\v{S}krlj, Jan Kralj, Nada Lavra\\v{c}", "title": "Symbolic Graph Embedding using Frequent Pattern Mining", "comments": "Published at DS2019 conference as a full paper", "journal-ref": null, "doi": "10.1007/978-3-030-33778-0_21", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational data mining is becoming ubiquitous in many fields of study. It\noffers insights into behaviour of complex, real-world systems which cannot be\nmodeled directly using propositional learning. We propose Symbolic Graph\nEmbedding (SGE), an algorithm aimed to learn symbolic node representations.\nBuilt on the ideas from the field of inductive logic programming, SGE first\nsamples a given node's neighborhood and interprets it as a transaction\ndatabase, which is used for frequent pattern mining to identify logical\nconjuncts of items that co-occur frequently in a given context. Such patterns\nare in this work used as features to represent individual nodes, yielding\ninterpretable, symbolic node embeddings. The proposed SGE approach on a venue\nclassification task outperforms shallow node embedding methods such as\nDeepWalk, and performs similarly to metapath2vec, a black-box representation\nlearner that can exploit node and edge types in a given graph. The proposed SGE\napproach performs especially well when small amounts of data are used for\nlearning, scales to graphs with millions of nodes and edges, and can be run on\nan of-the-shelf laptop.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:13:18 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["\u0160krlj", "Blaz", ""], ["Kralj", "Jan", ""], ["Lavra\u010d", "Nada", ""]]}, {"id": "1910.13315", "submitter": "Kemal Davaslioglu", "authors": "Kemal Davaslioglu, Sohraab Soltani, Tugba Erpek, Yalin E. Sagduyu", "title": "DeepWiFi: Cognitive WiFi with Deep Learning", "comments": "Accepted to IEEE Transactions on Mobile Computing, 17 pages\n  (including the Appendix), 23 figures, and 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the DeepWiFi protocol, which hardens the baseline WiFi (IEEE\n802.11ac) with deep learning and sustains high throughput by mitigating\nout-of-network interference. DeepWiFi is interoperable with baseline WiFi and\nbuilds upon the existing WiFi's PHY transceiver chain without changing the MAC\nframe format. Users run DeepWiFi for i) RF front end processing; ii) spectrum\nsensing and signal classification; iii) signal authentication; iv) channel\nselection and access; v) power control; vi) modulation and coding scheme (MCS)\nadaptation; and vii) routing. DeepWiFi mitigates the effects of probabilistic,\nsensing-based, and adaptive jammers. RF front end processing applies a deep\nlearning-based autoencoder to extract spectrum-representative features. Then a\ndeep neural network is trained to classify waveforms reliably as idle, WiFi, or\njammer. Utilizing channel labels, users effectively access idle or jammed\nchannels, while avoiding interference with legitimate WiFi transmissions\n(authenticated by machine learning-based RF fingerprinting) resulting in higher\nthroughput. Users optimize their transmit power for low probability of\nintercept/detection and their MCS to maximize link rates used by backpressure\nalgorithm for routing. Supported by embedded platform implementation, DeepWiFi\nprovides major throughput gains compared to baseline WiFi and another\njamming-resistant protocol, especially when channels are likely to be jammed\nand the signal-to-interference-plus-noise-ratio is low.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:14:11 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Davaslioglu", "Kemal", ""], ["Soltani", "Sohraab", ""], ["Erpek", "Tugba", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "1910.13321", "submitter": "Tobias Hinz", "authors": "Tobias Hinz, Stefan Heinrich, Stefan Wermter", "title": "Semantic Object Accuracy for Generative Text-to-Image Synthesis", "comments": "Added a user study to verify results. Code available at\n  https://github.com/tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis", "journal-ref": "TPAMI (Early Access), 2020", "doi": "10.1109/TPAMI.2020.3021209", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks conditioned on textual image descriptions are\ncapable of generating realistic-looking images. However, current methods still\nstruggle to generate images based on complex image captions from a\nheterogeneous domain. Furthermore, quantitatively evaluating these\ntext-to-image models is challenging, as most evaluation metrics only judge\nimage quality but not the conformity between the image and its caption. To\naddress these challenges we introduce a new model that explicitly models\nindividual objects within an image and a new evaluation metric called Semantic\nObject Accuracy (SOA) that specifically evaluates images given an image\ncaption. The SOA uses a pre-trained object detector to evaluate if a generated\nimage contains objects that are mentioned in the image caption, e.g. whether an\nimage generated from \"a car driving down the street\" contains a car. We perform\na user study comparing several text-to-image models and show that our SOA\nmetric ranks the models the same way as humans, whereas other metrics such as\nthe Inception Score do not. Our evaluation also shows that models which\nexplicitly model objects outperform models which only model global image\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:35:52 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 12:25:16 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Hinz", "Tobias", ""], ["Heinrich", "Stefan", ""], ["Wermter", "Stefan", ""]]}, {"id": "1910.13324", "submitter": "Yuan Zhou", "authors": "Yuan Zhou, Hongseok Yang, Yee Whye Teh and Tom Rainforth", "title": "Divide, Conquer, and Combine: a New Inference Strategy for Probabilistic\n  Programs with Stochastic Support", "comments": "Published at the 37th International Conference on Machine Learning\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal probabilistic programming systems (PPSs) provide a powerful\nframework for specifying rich probabilistic models. They further attempt to\nautomate the process of drawing inferences from these models, but doing this\nsuccessfully is severely hampered by the wide range of non--standard models\nthey can express. As a result, although one can specify complex models in a\nuniversal PPS, the provided inference engines often fall far short of what is\nrequired. In particular, we show that they produce surprisingly unsatisfactory\nperformance for models where the support varies between executions, often doing\nno better than importance sampling from the prior. To address this, we\nintroduce a new inference framework: Divide, Conquer, and Combine, which\nremains efficient for such models, and show how it can be implemented as an\nautomated and generic PPS inference engine. We empirically demonstrate\nsubstantial performance improvements over existing approaches on three\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:36:56 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 23:21:21 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 17:26:12 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Zhou", "Yuan", ""], ["Yang", "Hongseok", ""], ["Teh", "Yee Whye", ""], ["Rainforth", "Tom", ""]]}, {"id": "1910.13325", "submitter": "Leszek Spalek Dr", "authors": "John Armitage, Leszek J. Spalek, Malgorzata Nguyen, Mark Nikolka, Ian\n  E. Jacobs, Lorena Mara\\~n\\'on, Iyad Nasrallah, Guillaume Schweicher, Ivan\n  Dimov, Dimitrios Simatos, Iain McCulloch, Christian B. Nielsen, Gareth\n  Conduit and Henning Sirringhaus", "title": "Fragment Graphical Variational AutoEncoding for Screening Molecules with\n  Small Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cond-mat.mtrl-sci cs.LG physics.app-ph physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the majority of molecular optimization tasks, predictive machine learning\n(ML) models are limited due to the unavailability and cost of generating big\nexperimental datasets on the specific task. To circumvent this limitation, ML\nmodels are trained on big theoretical datasets or experimental indicators of\nmolecular suitability that are either publicly available or inexpensive to\nacquire. These approaches produce a set of candidate molecules which have to be\nranked using limited experimental data or expert knowledge. Under the\nassumption that structure is related to functionality, here we use a molecular\nfragment-based graphical autoencoder to generate unique structural fingerprints\nto efficiently search through the candidate set. We demonstrate that\nfragment-based graphical autoencoding reduces the error in predicting physical\ncharacteristics such as the solubility and partition coefficient in the small\ndata regime compared to other extended circular fingerprints and string based\napproaches. We further demonstrate that this approach is capable of providing\ninsight into real world molecular optimization problems, such as searching for\nstabilization additives in organic semiconductors by accurately predicting 92%\nof test molecules given 69 training examples. This task is a model example of\nblack box molecular optimization as there is minimal theoretical and\nexperimental knowledge to accurately predict the suitability of the additives.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:35:13 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 17:18:31 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Armitage", "John", ""], ["Spalek", "Leszek J.", ""], ["Nguyen", "Malgorzata", ""], ["Nikolka", "Mark", ""], ["Jacobs", "Ian E.", ""], ["Mara\u00f1\u00f3n", "Lorena", ""], ["Nasrallah", "Iyad", ""], ["Schweicher", "Guillaume", ""], ["Dimov", "Ivan", ""], ["Simatos", "Dimitrios", ""], ["McCulloch", "Iain", ""], ["Nielsen", "Christian B.", ""], ["Conduit", "Gareth", ""], ["Sirringhaus", "Henning", ""]]}, {"id": "1910.13327", "submitter": "Michael Riegler", "authors": "Steven A. Hicks and Jorunn M. Andersen and Oliwia Witczak and Vajira\n  Thambawita and P{\\aa}ll Halvorsen and Hugo L. Hammer and Trine B. Haugen and\n  Michael A. Riegler", "title": "Machine Learning-Based Analysis of Sperm Videos and Participant Data for\n  Male Fertility Prediction", "comments": "Preprint, accepted by Nature Scientific Reports for publication\n  24.10.2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for automatic analysis of clinical data are usually targeted towards\na specific modality and do not make use of all relevant data available. In the\nfield of male human reproduction, clinical and biological data are not used to\nits fullest potential. Manual evaluation of a semen sample using a microscope\nis time-consuming and requires extensive training. Furthermore, the validity of\nmanual semen analysis has been questioned due to limited reproducibility, and\noften high inter-personnel variation. The existing computer-aided sperm\nanalyzer systems are not recommended for routine clinical use due to\nmethodological challenges caused by the consistency of the semen sample. Thus,\nthere is a need for an improved methodology. We use modern and classical\nmachine learning techniques together with a dataset consisting of 85 videos of\nhuman semen samples and related participant data to automatically predict sperm\nmotility. Used techniques include simple linear regression and more\nsophisticated methods using convolutional neural networks. Our results indicate\nthat sperm motility prediction based on deep learning using sperm motility\nvideos is rapid to perform and consistent. The algorithms performed worse when\nparticipant data was added. In conclusion, machine learning-based automatic\nanalysis may become a valuable tool in male infertility investigation and\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:38:47 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Hicks", "Steven A.", ""], ["Andersen", "Jorunn M.", ""], ["Witczak", "Oliwia", ""], ["Thambawita", "Vajira", ""], ["Halvorsen", "P\u00e5ll", ""], ["Hammer", "Hugo L.", ""], ["Haugen", "Trine B.", ""], ["Riegler", "Michael A.", ""]]}, {"id": "1910.13328", "submitter": "Jingwen Wang", "authors": "Jingwen Wang, Richard J. Chen, Ming Y. Lu, Alexander Baras, Faisal\n  Mahmood", "title": "Weakly Supervised Prostate TMA Classification via Graph Convolutional\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histology-based grade classification is clinically important for many cancer\ntypes in stratifying patients distinct treatment groups. In prostate cancer,\nthe Gleason score is a grading system used to measure the aggressiveness of\nprostate cancer from the spatial organization of cells and the distribution of\nglands. However, the subjective interpretation of Gleason score often suffers\nfrom large interobserver and intraobserver variability. Previous work in deep\nlearning-based objective Gleason grading requires manual pixel-level\nannotation. In this work, we propose a weakly-supervised approach for grade\nclassification in tissue micro-arrays (TMA) using graph convolutional networks\n(GCNs), in which we model the spatial organization of cells as a graph to\nbetter capture the proliferation and community structure of tumor cells. As\nnode-level features in our graph representation, we learn the morphometry of\neach cell using a contrastive predictive coding (CPC)-based self-supervised\napproach. We demonstrate that on a five-fold cross validation our method can\nachieve $0.9659\\pm0.0096$ AUC using only TMA-level labels. Our method\ndemonstrates a 39.80\\% improvement over standard GCNs with texture features and\na 29.27% improvement over GCNs with VGG19 features. Our proposed pipeline can\nbe used to objectively stratify low and high risk cases, reducing inter- and\nintra-observer variability and pathologist workload.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:44:20 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 14:24:35 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Wang", "Jingwen", ""], ["Chen", "Richard J.", ""], ["Lu", "Ming Y.", ""], ["Baras", "Alexander", ""], ["Mahmood", "Faisal", ""]]}, {"id": "1910.13332", "submitter": "Matthias Freiberger", "authors": "Matthias Freiberger, Peter Bienstman and Joni Dambre", "title": "Towards Deep Physical Reservoir Computing Through Automatic Task\n  Decomposition And Mapping", "comments": "Submitted to the IEEE International Conference on Rebooting Computing\n  2019; accepted as a poster, will not be presented though", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photonic reservoir computing is a promising candidate for low-energy\ncomputing at high bandwidths. Despite recent successes, there are bounds to\nwhat one can achieve simply by making photonic reservoirs larger. Therefore, a\nswitch from single-reservoir computing to multi-reservoir and even deep\nphysical reservoir computing is desirable. Given that backpropagation can not\nbe used directly to train multi-reservoir systems in our targeted setting, we\npropose an alternative approach that still uses its power to derive\nintermediate targets. In this work we report our findings on a conducted\nexperiment to evaluate the general feasibility of our approach by training a\nnetwork of 3 Echo State Networks to perform the well-known NARMA-10 task using\ntargets derived through backpropagation. Our results indicate that our proposed\nmethod is well-suited to train multi-reservoir systems in a efficient way.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 09:46:54 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Freiberger", "Matthias", ""], ["Bienstman", "Peter", ""], ["Dambre", "Joni", ""]]}, {"id": "1910.13339", "submitter": "Alon Jacovi", "authors": "Alon Jacovi, Gang Niu, Yoav Goldberg, Masashi Sugiyama", "title": "Scalable Evaluation and Improvement of Document Set Expansion via Neural\n  Positive-Unlabeled Learning", "comments": "Accepted as a long paper to EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the situation in which a user has collected a small set of\ndocuments on a cohesive topic, and they want to retrieve additional documents\non this topic from a large collection. Information Retrieval (IR) solutions\ntreat the document set as a query, and look for similar documents in the\ncollection. We propose to extend the IR approach by treating the problem as an\ninstance of positive-unlabeled (PU) learning -- i.e., learning binary\nclassifiers from only positive and unlabeled data, where the positive data\ncorresponds to the query documents, and the unlabeled data is the results\nreturned by the IR engine. Utilizing PU learning for text with big neural\nnetworks is a largely unexplored field. We discuss various challenges in\napplying PU learning to the setting, including an unknown class prior,\nextremely imbalanced data and large-scale accurate evaluation of models, and we\npropose solutions and empirically validate them. We demonstrate the\neffectiveness of the method using a series of experiments of retrieving PubMed\nabstracts adhering to fine-grained topics. We demonstrate improvements over the\nbase IR solution and other baselines.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:56:33 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 20:48:36 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Jacovi", "Alon", ""], ["Niu", "Gang", ""], ["Goldberg", "Yoav", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1910.13349", "submitter": "Yue Wang", "authors": "Yue Wang, Ziyu Jiang, Xiaohan Chen, Pengfei Xu, Yang Zhao, Yingyan\n  Lin, Zhangyang Wang", "title": "E2-Train: Training State-of-the-art CNNs with Over 80% Energy Savings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have been increasingly deployed to edge\ndevices. Hence, many efforts have been made towards efficient CNN inference in\nresource-constrained platforms. This paper attempts to explore an orthogonal\ndirection: how to conduct more energy-efficient training of CNNs, so as to\nenable on-device training. We strive to reduce the energy cost during training,\nby dropping unnecessary computations from three complementary levels:\nstochastic mini-batch dropping on the data level; selective layer update on the\nmodel level; and sign prediction for low-cost, low-precision back-propagation,\non the algorithm level. Extensive simulations and ablation studies, with real\nenergy measurements from an FPGA board, confirm the superiority of our proposed\nstrategies and demonstrate remarkable energy savings for training. For example,\nwhen training ResNet-74 on CIFAR-10, we achieve aggressive energy savings of\n>90% and >60%, while incurring a top-1 accuracy loss of only about 2% and 1.2%,\nrespectively. When training ResNet-110 on CIFAR-100, an over 84% training\nenergy saving is achieved without degrading inference accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 16:07:42 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 00:51:06 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 23:03:56 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2019 00:40:00 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Wang", "Yue", ""], ["Jiang", "Ziyu", ""], ["Chen", "Xiaohan", ""], ["Xu", "Pengfei", ""], ["Zhao", "Yang", ""], ["Lin", "Yingyan", ""], ["Wang", "Zhangyang", ""]]}, {"id": "1910.13351", "submitter": "Donald Wunsch", "authors": "Donald C. Wunsch", "title": "Admiring the Great Mountain: A Celebration Special Issue in Honor of\n  Stephen Grossbergs 80th Birthday", "comments": "Editorial for Special Issue of Neural Networks in honor of\n  Grossberg's 80th birthday", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This editorial summarizes selected key contributions of Prof. Stephen\nGrossberg and describes the papers in this 80th birthday special issue in his\nhonor. His productivity, creativity, and vision would each be enough to mark a\nscientist of the first caliber. In combination, they have resulted in\ncontributions that have changed the entire discipline of neural networks.\nGrossberg has been tremendously influential in engineering, dynamical systems,\nand artificial intelligence as well. Indeed, he has been one of the most\nimportant mentors and role models in my career, and has done so with\nextraordinary generosity and encouragement. All authors in this special issue\nhave taken great pleasure in hereby commemorating his extraordinary career and\ncontributions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 09:17:01 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Wunsch", "Donald C.", ""]]}, {"id": "1910.13369", "submitter": "Andrea Bajcsy", "authors": "Somil Bansal, Andrea Bajcsy, Ellis Ratner, Anca D. Dragan, Claire J.\n  Tomlin", "title": "A Hamilton-Jacobi Reachability-Based Framework for Predicting and\n  Analyzing Human Motion for Safe Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world autonomous systems often employ probabilistic predictive models of\nhuman behavior during planning to reason about their future motion. Since\naccurately modeling human behavior a priori is challenging, such models are\noften parameterized, enabling the robot to adapt predictions based on\nobservations by maintaining a distribution over the model parameters. Although\nthis enables data and priors to improve the human model, observation models are\ndifficult to specify and priors may be incorrect, leading to erroneous state\npredictions that can degrade the safety of the robot motion plan. In this work,\nwe seek to design a predictor which is more robust to misspecified models and\npriors, but can still leverage human behavioral data online to reduce\nconservatism in a safe way. To do this, we cast human motion prediction as a\nHamilton-Jacobi reachability problem in the joint state space of the human and\nthe belief over the model parameters. We construct a new continuous-time\ndynamical system, where the inputs are the observations of human behavior, and\nthe dynamics include how the belief over the model parameters change. The\nresults of this reachability computation enable us to both analyze the effect\nof incorrect priors on future predictions in continuous state and time, as well\nas to make predictions of the human state in the future. We compare our\napproach to the worst-case forward reachable set and a stochastic predictor\nwhich uses Bayesian inference and produces full future state distributions. Our\ncomparisons in simulation and in hardware demonstrate how our framework can\nenable robust planning while not being overly conservative, even when the human\nmodel is inaccurate.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 16:34:00 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 21:10:25 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Bansal", "Somil", ""], ["Bajcsy", "Andrea", ""], ["Ratner", "Ellis", ""], ["Dragan", "Anca D.", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "1910.13372", "submitter": "Pieter Robberechts", "authors": "Pieter Robberechts, Rud Derie, Pieter Van den Berghe, Joeri Gerlo,\n  Dirk De Clercq, Veerle Segers, Jesse Davis", "title": "Predicting gait events from tibial acceleration in rearfoot running: a\n  structured machine learning approach", "comments": null, "journal-ref": "Gait & Posture, Volume 84, 2021, Pages 87-92", "doi": "10.1016/j.gaitpost.2020.10.035", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gait event detection of the initial contact and toe off is essential for\nrunning gait analysis, allowing the derivation of parameters such as stance\ntime. Heuristic-based methods exist to estimate these key gait events from\ntibial accelerometry. However, these methods are tailored to very specific\nacceleration profiles, which may offer complications when dealing with larger\ndata sets and inherent biological variability. Therefore, this paper\ninvestigates whether a structured machine learning approach can achieve a more\naccurate prediction of running gait event timings from tibial accelerometry.\nForce-based event detection acted as the criterion measure in order to assess\nthe accuracy, repeatability and sensitivity of the predicted gait events. A\nheuristic method and two structured machine learning methods were employed to\nderive initial contact, toe off and stance time from tibial acceleration\nsignals. Both a structured perceptron model (median absolute error of stance\ntime estimation: 10.00 $\\pm$ 8.73 ms) and a structured recurrent neural network\nmodel (median absolute error of stance time estimation: 6.50 $\\pm$ 5.74 ms)\nsignificantly outperformed the existing heuristic approach (median absolute\nerror of stance time estimation: 11.25 $\\pm$ 9.52 ms) on data from 93 rearfoot\nrunners. Thus, results indicate that a structured recurrent neural network\nmachine learning model offers the most accurate and consistent estimation of\nthe gait events and its derived stance time during level overground running.\nThe machine learning methods seem less affected by intra- and inter-subject\nvariation within the data, allowing for accurate and efficient automated data\noutput during rearfoot overground running. Furthermore offering possibilities\nfor real-time monitoring and biofeedback during prolonged measurements, even\noutside the laboratory.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 16:36:04 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 15:17:18 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 12:20:51 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Robberechts", "Pieter", ""], ["Derie", "Rud", ""], ["Berghe", "Pieter Van den", ""], ["Gerlo", "Joeri", ""], ["De Clercq", "Dirk", ""], ["Segers", "Veerle", ""], ["Davis", "Jesse", ""]]}, {"id": "1910.13376", "submitter": "Gero Szepannek", "authors": "Gero Szepannek", "title": "How Much Can We See? A Note on Quantifying Explainability of Machine\n  Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most popular approaches to understanding feature effects of modern\nblack box machine learning models are partial dependence plots (PDP). These\nplots are easy to understand but only able to visualize low order dependencies.\nThe paper is about the question 'How much can we see?': A framework is\ndeveloped to quantify the explainability of arbitrary machine learning models,\ni.e. up to what degree the visualization as given by a PDP is able to explain\nthe predictions of the model. The result allows for a judgement whether an\nattempt to explain a black box model is sufficient or not.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 16:39:35 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 08:20:40 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Szepannek", "Gero", ""]]}, {"id": "1910.13389", "submitter": "Jacky Zhang", "authors": "Jacky Y. Zhang, Rajiv Khanna, Anastasios Kyrillidis, Oluwasanmi Koyejo", "title": "Learning Sparse Distributions using Iterative Hard Thresholding", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative hard thresholding (IHT) is a projected gradient descent algorithm,\nknown to achieve state of the art performance for a wide range of structured\nestimation problems, such as sparse inference. In this work, we consider IHT as\na solution to the problem of learning sparse discrete distributions. We study\nthe hardness of using IHT on the space of measures. As a practical alternative,\nwe propose a greedy approximate projection which simultaneously captures\nappropriate notions of sparsity in distributions, while satisfying the simplex\nconstraint, and investigate the convergence behavior of the resulting procedure\nin various settings. Our results show, both in theory and practice, that IHT\ncan achieve state of the art results for learning sparse distributions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 16:53:47 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 05:05:11 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 00:10:10 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Zhang", "Jacky Y.", ""], ["Khanna", "Rajiv", ""], ["Kyrillidis", "Anastasios", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "1910.13393", "submitter": "Santiago Paternain Mr", "authors": "Santiago Paternain, Luiz F.O. Chamon, Miguel Calvo-Fullana, Alejandro\n  Ribeiro", "title": "Constrained Reinforcement Learning Has Zero Duality Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents must often deal with conflicting requirements, such as\ncompleting tasks using the least amount of time/energy, learning multiple\ntasks, or dealing with multiple opponents. In the context of reinforcement\nlearning~(RL), these problems are addressed by (i)~designing a reward function\nthat simultaneously describes all requirements or (ii)~combining modular value\nfunctions that encode them individually. Though effective, these methods have\ncritical downsides. Designing good reward functions that balance different\nobjectives is challenging, especially as the number of objectives grows.\nMoreover, implicit interference between goals may lead to performance plateaus\nas they compete for resources, particularly when training on-policy. Similarly,\nselecting parameters to combine value functions is at least as hard as\ndesigning an all-encompassing reward, given that the effect of their values on\nthe overall policy is not straightforward. The later is generally addressed by\nformulating the conflicting requirements as a constrained RL problem and solved\nusing Primal-Dual methods. These algorithms are in general not guaranteed to\nconverge to the optimal solution since the problem is not convex. This work\nprovides theoretical support to these approaches by establishing that despite\nits non-convexity, this problem has zero duality gap, i.e., it can be solved\nexactly in the dual domain, where it becomes convex. Finally, we show this\nresult basically holds if the policy is described by a good\nparametrization~(e.g., neural networks) and we connect this result with\nprimal-dual algorithms present in the literature and we establish the\nconvergence to the optimal solution.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 16:56:21 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Paternain", "Santiago", ""], ["Chamon", "Luiz F. O.", ""], ["Calvo-Fullana", "Miguel", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1910.13395", "submitter": "Kuan Fang", "authors": "Kuan Fang, Yuke Zhu, Animesh Garg, Silvio Savarese, Li Fei-Fei", "title": "Dynamics Learning with Cascaded Variational Inference for Multi-Step\n  Manipulation", "comments": "CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental challenge of planning for multi-step manipulation is to find\neffective and plausible action sequences that lead to the task goal. We present\nCascaded Variational Inference (CAVIN) Planner, a model-based method that\nhierarchically generates plans by sampling from latent spaces. To facilitate\nplanning over long time horizons, our method learns latent representations that\ndecouple the prediction of high-level effects from the generation of low-level\nmotions through cascaded variational inference. This enables us to model\ndynamics at two different levels of temporal resolutions for hierarchical\nplanning. We evaluate our approach in three multi-step robotic manipulation\ntasks in cluttered tabletop environments given high-dimensional observations.\nEmpirical results demonstrate that the proposed method outperforms\nstate-of-the-art model-based methods by strategically interacting with multiple\nobjects.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 16:58:25 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 08:55:05 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Fang", "Kuan", ""], ["Zhu", "Yuke", ""], ["Garg", "Animesh", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1910.13398", "submitter": "Wu Lin", "authors": "Wu Lin, Mohammad Emtiyaz Khan, Mark Schmidt", "title": "Stein's Lemma for the Reparameterization Trick with Exponential Family\n  Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein's method (Stein, 1973; 1981) is a powerful tool for statistical\napplications, and has had a significant impact in machine learning. Stein's\nlemma plays an essential role in Stein's method. Previous applications of\nStein's lemma either required strong technical assumptions or were limited to\nGaussian distributions with restricted covariance structures. In this work, we\nextend Stein's lemma to exponential-family mixture distributions including\nGaussian distributions with full covariance structures. Our generalization\nenables us to establish a connection between Stein's lemma and the\nreparamterization trick to derive gradients of expectations of a large class of\nfunctions under weak assumptions. Using this connection, we can derive many new\nreparameterizable gradient-identities that goes beyond the reach of existing\nworks. For example, we give gradient identities when expectation is taken with\nrespect to Student's t-distribution, skew Gaussian, exponentially modified\nGaussian, and normal inverse Gaussian.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 16:59:22 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Lin", "Wu", ""], ["Khan", "Mohammad Emtiyaz", ""], ["Schmidt", "Mark", ""]]}, {"id": "1910.13399", "submitter": "Matteo Turchetta", "authors": "Matteo Turchetta, Andreas Krause, Sebastian Trimpe", "title": "Robust Model-free Reinforcement Learning with Multi-objective Bayesian\n  Optimization", "comments": "Submitted to IEEE Conference on Robotics and Automation 2020 (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), an autonomous agent learns to perform complex\ntasks by maximizing an exogenous reward signal while interacting with its\nenvironment. In real-world applications, test conditions may differ\nsubstantially from the training scenario and, therefore, focusing on pure\nreward maximization during training may lead to poor results at test time. In\nthese cases, it is important to trade-off between performance and robustness\nwhile learning a policy. While several results exist for robust, model-based\nRL, the model-free case has not been widely investigated. In this paper, we\ncast the robust, model-free RL problem as a multi-objective optimization\nproblem. To quantify the robustness of a policy, we use delay margin and gain\nmargin, two robustness indicators that are common in control theory. We show\nhow these metrics can be estimated from data in the model-free setting. We use\nmulti-objective Bayesian optimization (MOBO) to solve efficiently this\nexpensive-to-evaluate, multi-objective optimization problem. We show the\nbenefits of our robust formulation both in sim-to-real and pure hardware\nexperiments to balance a Furuta pendulum.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:00:05 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Turchetta", "Matteo", ""], ["Krause", "Andreas", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1910.13401", "submitter": "Diyan Teng", "authors": "Diyan Teng, Rashmi Kulkarni, Justin McGloin", "title": "Model enhancement and personalization using weakly supervised learning\n  for multi-modal mobile sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Always-on sensing of mobile device user's contextual information is critical\nto many intelligent use cases nowadays such as healthcare, drive assistance,\nvoice UI. State-of-the-art approaches for predicting user context have proved\nthe value to leverage multiple sensing modalities for better accuracy. However,\nthose context inference algorithms that run on application processor nowadays\ntend to drain heavy amount of power, making them not suitable for an always-on\nimplementation. We claim that not every sensing modality is suitable to be\nactivated all the time and it remains challenging to build an inference engine\nusing power friendly sensing modalities. Meanwhile, due to the diverse\npopulation, we find it challenging to learn a context inference model that\ngeneralizes well, with limited training data, especially when only using\nalways-on low power sensors. In this work, we propose an approach to leverage\nthe opportunistically-on counterparts in device to improve the always-on\nprediction model, leading to a personalized solution. We model this problem\nusing a weakly supervised learning framework and provide both theoretical and\nexperimental results to validate our design. The proposed framework achieves\nsatisfying result in the IMU based activity recognition application we\nconsidered.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:00:48 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Teng", "Diyan", ""], ["Kulkarni", "Rashmi", ""], ["McGloin", "Justin", ""]]}, {"id": "1910.13406", "submitter": "Meire Fortunato", "authors": "Meire Fortunato, Melissa Tan, Ryan Faulkner, Steven Hansen, Adri\\`a\n  Puigdom\\`enech Badia, Gavin Buttimore, Charlie Deck, Joel Z Leibo, Charles\n  Blundell", "title": "Generalization of Reinforcement Learners with Working and Episodic\n  Memory", "comments": "NeurIPS 2019. Equal contribution of first 4 authors", "journal-ref": "33rd Conference on Neural Information Processing Systems (Neurips\n  2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory is an important aspect of intelligence and plays a role in many deep\nreinforcement learning models. However, little progress has been made in\nunderstanding when specific memory systems help more than others and how well\nthey generalize. The field also has yet to see a prevalent consistent and\nrigorous approach for evaluating agent performance on holdout data. In this\npaper, we aim to develop a comprehensive methodology to test different kinds of\nmemory in an agent and assess how well the agent can apply what it learns in\ntraining to a holdout set that differs from the training set along dimensions\nthat we suggest are relevant for evaluating memory-specific generalization. To\nthat end, we first construct a diverse set of memory tasks that allow us to\nevaluate test-time generalization across multiple dimensions. Second, we\ndevelop and perform multiple ablations on an agent architecture that combines\nmultiple memory systems, observe its baseline models, and investigate its\nperformance against the task suite.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:07:53 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 01:08:38 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Fortunato", "Meire", ""], ["Tan", "Melissa", ""], ["Faulkner", "Ryan", ""], ["Hansen", "Steven", ""], ["Badia", "Adri\u00e0 Puigdom\u00e8nech", ""], ["Buttimore", "Gavin", ""], ["Deck", "Charlie", ""], ["Leibo", "Joel Z", ""], ["Blundell", "Charles", ""]]}, {"id": "1910.13408", "submitter": "Kate Duffy", "authors": "Kate Duffy, Thomas Vandal, Weile Wang, Ramakrishna Nemani and Auroop\n  R. Ganguly", "title": "Deep Learning Emulation of Multi-Angle Implementation of Atmospheric\n  Correction (MAIAC)", "comments": "10 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New generation geostationary satellites make solar reflectance observations\navailable at a continental scale with unprecedented spatiotemporal resolution\nand spectral range. Generating quality land monitoring products requires\ncorrection of the effects of atmospheric scattering and absorption, which vary\nin time and space according to geometry and atmospheric composition. Many\natmospheric radiative transfer models, including that of Multi-Angle\nImplementation of Atmospheric Correction (MAIAC), are too computationally\ncomplex to be run in real time, and rely on precomputed look-up tables.\nAdditionally, uncertainty in measurements and models for remote sensing\nreceives insufficient attention, in part due to the difficulty of obtaining\nsufficient ground measurements. In this paper, we present an adaptation of\nBayesian Deep Learning (BDL) to emulation of the MAIAC atmospheric correction\nalgorithm. Emulation approaches learn a statistical model as an efficient\napproximation of a physical model, while machine learning methods have\ndemonstrated performance in extracting spatial features and learning complex,\nnonlinear mappings. We demonstrate stable surface reflectance retrieval by\nemulation (R2 between MAIAC and emulator SR are 0.63, 0.75, 0.86, 0.84, 0.95,\nand 0.91 for Blue, Green, Red, NIR, SWIR1, and SWIR2 bands, respectively),\naccurate cloud detection (86\\%), and well-calibrated, geolocated uncertainty\nestimates. Our results support BDL-based emulation as an accurate and efficient\n(up to 6x speedup) method for approximation atmospheric correction, where\nbuilt-in uncertainty estimates stand to open new opportunities for model\nassessment and support informed use of SR-derived quantities in multiple\ndomains.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:11:50 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Duffy", "Kate", ""], ["Vandal", "Thomas", ""], ["Wang", "Weile", ""], ["Nemani", "Ramakrishna", ""], ["Ganguly", "Auroop R.", ""]]}, {"id": "1910.13413", "submitter": "Dominik Janzing", "authors": "Dominik Janzing, Lenon Minorics, and Patrick Bl\\\"obaum", "title": "Feature relevance quantification in explainable AI: A causal problem", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss promising recent contributions on quantifying feature relevance\nusing Shapley values, where we observed some confusion on which probability\ndistribution is the right one for dropped features. We argue that the confusion\nis based on not carefully distinguishing between observational and\ninterventional conditional probabilities and try a clarification based on\nPearl's seminal work on causality. We conclude that unconditional rather than\nconditional expectations provide the right notion of dropping features in\ncontradiction to the theoretical justification of the software package SHAP.\nParts of SHAP are unaffected because unconditional expectations (which we argue\nto be conceptually right) are used as approximation for the conditional ones,\nwhich encouraged others to `improve' SHAP in a way that we believe to be\nflawed.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:18:39 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 09:40:41 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Janzing", "Dominik", ""], ["Minorics", "Lenon", ""], ["Bl\u00f6baum", "Patrick", ""]]}, {"id": "1910.13425", "submitter": "Pratik Kayal", "authors": "Pratik Kayal, Mayank Singh, Pawan Goyal", "title": "Weakly-Supervised Deep Learning for Domain Invariant Sentiment\n  Classification", "comments": "5 Pages, 3 tables", "journal-ref": null, "doi": "10.1145/3371158.3371194", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of learning a sentiment classification model that adapts well to any\ntarget domain, different from the source domain, is a challenging problem.\nMajority of the existing approaches focus on learning a common representation\nby leveraging both source and target data during training. In this paper, we\nintroduce a two-stage training procedure that leverages weakly supervised\ndatasets for developing simple lift-and-shift-based predictive models without\nbeing exposed to the target domain during the training phase. Experimental\nresults show that transfer with weak supervision from a source domain to\nvarious target domains provides performance very close to that obtained via\nsupervised training on the target domain itself.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:43:37 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 06:59:48 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Kayal", "Pratik", ""], ["Singh", "Mayank", ""], ["Goyal", "Pawan", ""]]}, {"id": "1910.13427", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini, \\'Ulfar Erlingsson, Nicolas Papernot", "title": "Distribution Density, Tails, and Outliers in Machine Learning: Metrics\n  and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop techniques to quantify the degree to which a given (training or\ntesting) example is an outlier in the underlying distribution. We evaluate five\nmethods to score examples in a dataset by how well-represented the examples\nare, for different plausible definitions of \"well-represented\", and apply these\nto four common datasets: MNIST, Fashion-MNIST, CIFAR-10, and ImageNet. Despite\nbeing independent approaches, we find all five are highly correlated,\nsuggesting that the notion of being well-represented can be quantified. Among\nother uses, we find these methods can be combined to identify (a) prototypical\nexamples (that match human expectations); (b) memorized training examples; and,\n(c) uncommon submodes of the dataset. Further, we show how we can utilize our\nmetrics to determine an improved ordering for curriculum learning, and impact\nadversarial robustness. We release all metric values on training and test sets\nwe studied.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:44:35 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Carlini", "Nicholas", ""], ["Erlingsson", "\u00dalfar", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1910.13437", "submitter": "William Chan", "authors": "William Chan, Mitchell Stern, Jamie Kiros, Jakob Uszkoreit", "title": "An Empirical Study of Generation Order for Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an empirical study of generation order for machine\ntranslation. Building on recent advances in insertion-based modeling, we first\nintroduce a soft order-reward framework that enables us to train models to\nfollow arbitrary oracle generation policies. We then make use of this framework\nto explore a large variety of generation orders, including uninformed orders,\nlocation-based orders, frequency-based orders, content-based orders, and\nmodel-based orders. Curiously, we find that for the WMT'14 English $\\to$ German\ntranslation task, order does not have a substantial impact on output quality,\nwith unintuitive orderings such as alphabetical and shortest-first matching the\nperformance of a standard Transformer. This demonstrates that traditional\nleft-to-right generation is not strictly necessary to achieve high performance.\nOn the other hand, results on the WMT'18 English $\\to$ Chinese task tend to\nvary more widely, suggesting that translation for less well-aligned language\npairs may be more sensitive to generation order.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:54:36 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Chan", "William", ""], ["Stern", "Mitchell", ""], ["Kiros", "Jamie", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1910.13439", "submitter": "Lerrel Pinto", "authors": "Yilin Wu, Wilson Yan, Thanard Kurutach, Lerrel Pinto, Pieter Abbeel", "title": "Learning to Manipulate Deformable Objects without Demonstrations", "comments": "Project website:\n  https://sites.google.com/view/alternating-pick-and-place", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we tackle the problem of deformable object manipulation through\nmodel-free visual reinforcement learning (RL). In order to circumvent the\nsample inefficiency of RL, we propose two key ideas that accelerate learning.\nFirst, we propose an iterative pick-place action space that encodes the\nconditional relationship between picking and placing on deformable objects. The\nexplicit structural encoding enables faster learning under complex object\ndynamics. Second, instead of jointly learning both the pick and the place\nlocations, we only explicitly learn the placing policy conditioned on random\npick points. Then, by selecting the pick point that has Maximal Value under\nPlacing (MVP), we obtain our picking policy. This provides us with an informed\npicking policy during testing, while using only random pick points during\ntraining. Experimentally, this learning framework obtains an order of magnitude\nfaster learning compared to independent action-spaces on our suite of\ndeformable object manipulation tasks with visual RGB observations. Finally,\nusing domain randomization, we transfer our policies to a real PR2 robot for\nchallenging cloth and rope coverage tasks, and demonstrate significant\nimprovements over standard RL techniques on average coverage.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:56:56 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 21:45:54 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Wu", "Yilin", ""], ["Yan", "Wilson", ""], ["Kurutach", "Thanard", ""], ["Pinto", "Lerrel", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1910.13444", "submitter": "David Barajas-Solano", "authors": "Liu Yang and Sean Treichler and Thorsten Kurth and Keno Fischer and\n  David Barajas-Solano and Josh Romero and Valentin Churavy and Alexandre\n  Tartakovsky and Michael Houston and Prabhat and George Karniadakis", "title": "Highly-scalable, physics-informed GANs for learning solutions of\n  stochastic PDEs", "comments": "3rd Deep Learning on Supercomputers Workshop (DLS) at SC19", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification for forward and inverse problems is a central\nchallenge across physical and biomedical disciplines. We address this challenge\nfor the problem of modeling subsurface flow at the Hanford Site by combining\nstochastic computational models with observational data using physics-informed\nGAN models. The geographic extent, spatial heterogeneity, and multiple\ncorrelation length scales of the Hanford Site require training a\ncomputationally intensive GAN model to thousands of dimensions. We develop a\nhierarchical scheme for exploiting domain parallelism, map discriminators and\ngenerators to multiple GPUs, and employ efficient communication schemes to\nensure training stability and convergence. We developed a highly optimized\nimplementation of this scheme that scales to 27,500 NVIDIA Volta GPUs and 4584\nnodes on the Summit supercomputer with a 93.1% scaling efficiency, achieving\npeak and sustained half-precision rates of 1228 PF/s and 1207 PF/s.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 03:47:19 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Yang", "Liu", ""], ["Treichler", "Sean", ""], ["Kurth", "Thorsten", ""], ["Fischer", "Keno", ""], ["Barajas-Solano", "David", ""], ["Romero", "Josh", ""], ["Churavy", "Valentin", ""], ["Tartakovsky", "Alexandre", ""], ["Houston", "Michael", ""], ["Prabhat", "", ""], ["Karniadakis", "George", ""]]}, {"id": "1910.13445", "submitter": "Jiaxuan You", "authors": "Jiaxuan You, Haoze Wu, Clark Barrett, Raghuram Ramanujan, Jure\n  Leskovec", "title": "G2SAT: Learning to Generate SAT Formulas", "comments": "Accepted by NeurIPS 2019. Equal contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Boolean Satisfiability (SAT) problem is the canonical NP-complete problem\nand is fundamental to computer science, with a wide array of applications in\nplanning, verification, and theorem proving. Developing and evaluating\npractical SAT solvers relies on extensive empirical testing on a set of\nreal-world benchmark formulas. However, the availability of such real-world SAT\nformulas is limited. While these benchmark formulas can be augmented with\nsynthetically generated ones, existing approaches for doing so are heavily\nhand-crafted and fail to simultaneously capture a wide range of characteristics\nexhibited by real-world SAT instances. In this work, we present G2SAT, the\nfirst deep generative framework that learns to generate SAT formulas from a\ngiven set of input formulas. Our key insight is that SAT formulas can be\ntransformed into latent bipartite graph representations which we model using a\nspecialized deep generative neural network. We show that G2SAT can generate SAT\nformulas that closely resemble given real-world SAT instances, as measured by\nboth graph metrics and SAT solver behavior. Further, we show that our synthetic\nSAT formulas could be used to improve SAT solver performance on real-world\nbenchmarks, which opens up new opportunities for the continued development of\nSAT solvers and a deeper understanding of their performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 07:48:50 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["You", "Jiaxuan", ""], ["Wu", "Haoze", ""], ["Barrett", "Clark", ""], ["Ramanujan", "Raghuram", ""], ["Leskovec", "Jure", ""]]}, {"id": "1910.13446", "submitter": "Chengjian Sun", "authors": "Jiajun Wu, Chengjian Sun, Chenyang Yang", "title": "Proactive Optimization with Machine Learning: Femto-caching with Future\n  Content Popularity", "comments": "6 pages, 3 figures, submitted to IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing resource allocation with predicted information has shown promising\ngain in boosting network performance and improving user experience. Earlier\nresearch efforts focus on optimizing proactive policies under the assumption of\nknowing the future information. Recently, various techniques have been proposed\nto predict the required information, and the prediction results were then\ntreated as the true value in the optimization, i.e.,\n\"first-predict-then-optimize\". In this paper, we introduce a proactive\noptimization framework for anticipatory resource allocation, where the future\ninformation is implicitly predicted under the same objective with the policy\noptimization in a single step. An optimization problem is formulated to\nintegrate the implicit prediction and the policy optimization, based on the\nconditional distribution of the future information given the historical\nobservations. To solve such a problem, we transform it equivalently to a\nproblem depending on the joint distribution of future and historical\ninformation. Then, we resort to unsupervised learning with neural networks to\nlearn the proactive policy as a function of the past observations via\nstochastic optimization. We take proactive caching and bandwidth allocation at\nbase stations as a concrete example, where the objective function is the\nconditional expectation of successful offloading probability taken over the\nfuture popularity given the historically observed popularity. We use simulation\nto validate the proposed framework and compare it with the\n\"first-predict-then-optimize\" strategy and a heuristic \"end-to-end\"\noptimization strategy with supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 08:38:26 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 05:14:39 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 05:54:26 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wu", "Jiajun", ""], ["Sun", "Chengjian", ""], ["Yang", "Chenyang", ""]]}, {"id": "1910.13461", "submitter": "Marjan Ghazvininejad", "authors": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman\n  Mohamed, Omer Levy, Ves Stoyanov, Luke Zettlemoyer", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language\n  Generation, Translation, and Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BART, a denoising autoencoder for pretraining sequence-to-sequence\nmodels. BART is trained by (1) corrupting text with an arbitrary noising\nfunction, and (2) learning a model to reconstruct the original text. It uses a\nstandard Tranformer-based neural machine translation architecture which,\ndespite its simplicity, can be seen as generalizing BERT (due to the\nbidirectional encoder), GPT (with the left-to-right decoder), and many other\nmore recent pretraining schemes. We evaluate a number of noising approaches,\nfinding the best performance by both randomly shuffling the order of the\noriginal sentences and using a novel in-filling scheme, where spans of text are\nreplaced with a single mask token. BART is particularly effective when fine\ntuned for text generation but also works well for comprehension tasks. It\nmatches the performance of RoBERTa with comparable training resources on GLUE\nand SQuAD, achieves new state-of-the-art results on a range of abstractive\ndialogue, question answering, and summarization tasks, with gains of up to 6\nROUGE. BART also provides a 1.1 BLEU increase over a back-translation system\nfor machine translation, with only target language pretraining. We also report\nablation experiments that replicate other pretraining schemes within the BART\nframework, to better measure which factors most influence end-task performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 18:01:00 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lewis", "Mike", ""], ["Liu", "Yinhan", ""], ["Goyal", "Naman", ""], ["Ghazvininejad", "Marjan", ""], ["Mohamed", "Abdelrahman", ""], ["Levy", "Omer", ""], ["Stoyanov", "Ves", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1910.13466", "submitter": "Yikang Shen", "authors": "Yikang Shen, Shawn Tan, Arian Hosseini, Zhouhan Lin, Alessandro\n  Sordoni, Aaron Courville", "title": "Ordered Memory", "comments": "Published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stack-augmented recurrent neural networks (RNNs) have been of interest to the\ndeep learning community for some time. However, the difficulty of training\nmemory models remains a problem obstructing the widespread use of such models.\nIn this paper, we propose the Ordered Memory architecture. Inspired by Ordered\nNeurons (Shen et al., 2018), we introduce a new attention-based mechanism and\nuse its cumulative probability to control the writing and erasing operation of\nthe memory. We also introduce a new Gated Recursive Cell to compose lower-level\nrepresentations into higher-level representation. We demonstrate that our model\nachieves strong performance on the logical inference task (Bowman et al.,\n2015)and the ListOps (Nangia and Bowman, 2018) task. We can also interpret the\nmodel to retrieve the induced tree structure, and find that these induced\nstructures align with the ground truth. Finally, we evaluate our model on the\nStanford SentimentTreebank tasks (Socher et al., 2013), and find that it\nperforms comparatively with the state-of-the-art methods in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 18:14:14 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 18:10:34 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Shen", "Yikang", ""], ["Tan", "Shawn", ""], ["Hosseini", "Arian", ""], ["Lin", "Zhouhan", ""], ["Sordoni", "Alessandro", ""], ["Courville", "Aaron", ""]]}, {"id": "1910.13476", "submitter": "Nicolas Garcia Trillos", "authors": "Jeff Calder and Nicolas Garcia Trillos", "title": "Improved spectral convergence rates for graph Laplacians on\n  epsilon-graphs and k-NN graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we improve the spectral convergence rates for graph-based\napproximations of Laplace-Beltrami operators constructed from random data. We\nutilize regularity of the continuum eigenfunctions and strong pointwise\nconsistency results to prove that spectral convergence rates are the same as\nthe pointwise consistency rates for graph Laplacians. In particular, for an\noptimal choice of the graph connectivity $\\varepsilon$, our results show that\nthe eigenvalues and eigenvectors of the graph Laplacian converge to those of\nthe Laplace-Beltrami operator at a rate of $O(n^{-1/(m+4)})$, up to log\nfactors, where $m$ is the manifold dimension and $n$ is the number of vertices\nin the graph. Our approach is general and allows us to analyze a large variety\nof graph constructions that include $\\varepsilon$-graphs and $k$-NN graphs.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 18:49:15 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 11:36:52 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Calder", "Jeff", ""], ["Trillos", "Nicolas Garcia", ""]]}, {"id": "1910.13496", "submitter": "Kim Andrea Nicoli", "authors": "Kim A. Nicoli, Shinichi Nakajima, Nils Strodthoff, Wojciech Samek,\n  Klaus-Robert M\u007f\\\"uller, Pan Kessel", "title": "Asymptotically unbiased estimation of physical observables with neural\n  samplers", "comments": "5 figures", "journal-ref": "Phys. Rev. E 101, 023304 (2020)", "doi": "10.1103/PhysRevE.101.023304", "report-no": null, "categories": "cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for the estimation of observables with\ngenerative neural samplers focusing on modern deep generative neural networks\nthat provide an exact sampling probability. In this framework, we present\nasymptotically unbiased estimators for generic observables, including those\nthat explicitly depend on the partition function such as free energy or\nentropy, and derive corresponding variance estimators. We demonstrate their\npractical applicability by numerical experiments for the 2d Ising model which\nhighlight the superiority over existing methods. Our approach greatly enhances\nthe applicability of generative neural samplers to real-world physical systems.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 19:40:08 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 16:55:06 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Nicoli", "Kim A.", ""], ["Nakajima", "Shinichi", ""], ["Strodthoff", "Nils", ""], ["Samek", "Wojciech", ""], ["M\u007f\u00fcller", "Klaus-Robert", ""], ["Kessel", "Pan", ""]]}, {"id": "1910.13503", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis, Hal Daum\\'e III, Jennifer Wortman Vaughan, Hanna\n  Wallach", "title": "Weight of Evidence as a Basis for Human-Oriented Explanations", "comments": "Human-Centric Machine Learning (HCML) Workshop @ NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability is an elusive but highly sought-after characteristic of\nmodern machine learning methods. Recent work has focused on interpretability\nvia $\\textit{explanations}$, which justify individual model predictions. In\nthis work, we take a step towards reconciling machine explanations with those\nthat humans produce and prefer by taking inspiration from the study of\nexplanation in philosophy, cognitive science, and the social sciences. We\nidentify key aspects in which these human explanations differ from current\nmachine explanations, distill them into a list of desiderata, and formalize\nthem into a framework via the notion of $\\textit{weight of evidence}$ from\ninformation theory. Finally, we instantiate this framework in two simple\napplications and show it produces intuitive and comprehensible explanations.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 19:53:23 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Daum\u00e9", "Hal", "III"], ["Vaughan", "Jennifer Wortman", ""], ["Wallach", "Hanna", ""]]}, {"id": "1910.13509", "submitter": "Mengge Chen", "authors": "Mengge Chen, Jonathan Li", "title": "Deep convolutional neural network application on rooftop detection for\n  aerial image", "comments": "4 pages, two figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the most destructive disasters in the world, earthquake causes\ndeath, injuries, destruction and enormous damage to the affected area. It is\nsignificant to detect buildings after an earthquake in response to\nreconstruction and damage evaluation. In this research, we proposed an\nautomatic rooftop detection method based on the convolutional neural network\n(CNN) to extract buildings in the city of Christchurch and tuned\nhyperparameters to detect small detached houses from the aerial image. The\nexperiment result shows that our approach can effectively and accurately detect\nand segment buildings and has competitive performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 20:04:02 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Chen", "Mengge", ""], ["Li", "Jonathan", ""]]}, {"id": "1910.13511", "submitter": "Erdem Koyuncu", "authors": "Samuele Battaglino and Erdem Koyuncu", "title": "A Generalization of Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional principal component analysis (PCA) finds a principal vector that\nmaximizes the sum of second powers of principal components. We consider a\ngeneralized PCA that aims at maximizing the sum of an arbitrary convex function\nof principal components. We present a gradient ascent algorithm to solve the\nproblem. For the kernel version of generalized PCA, we show that the solutions\ncan be obtained as fixed points of a simple single-layer recurrent neural\nnetwork. We also evaluate our algorithms on different datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 20:07:22 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 22:13:44 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Battaglino", "Samuele", ""], ["Koyuncu", "Erdem", ""]]}, {"id": "1910.13520", "submitter": "Dattaraj Rao", "authors": "Dattaraj Jagdish Rao, Shraddha Mane", "title": "Digital Twin approach to Clinical DSS with Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a digital twin approach to improve healthcare decision support\nsystems with a combination of domain knowledge and data. Domain knowledge helps\nbuild decision thresholds that doctors can use to determine a risk or recommend\na treatment or test based on the specific patient condition. However, these\nassessments tend to be highly subjective and differ from doctor to doctor and\nfrom patient to patient. We propose a system where we collate this subjective\nrisk by compiling data from different doctors treating different patients and\nbuild a machine learning model that learns from this knowledge. Then using\nstate-of-the-art explainability concepts we derive explanations from this\nmodel. These explanations give us a summary of different doctor domain\nknowledge applied in different cases to give a more generic perspective. Also\nthese explanations are specific to a particular patient and are customized for\ntheir condition. This is a form of a digital twin for the patient that can now\nbe used to enhance decision boundaries for earlier defined decision tables that\nhelp in diagnosis. We will show an example of running this analysis for a liver\ndisease risk diagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 11:19:25 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Rao", "Dattaraj Jagdish", ""], ["Mane", "Shraddha", ""]]}, {"id": "1910.13521", "submitter": "Sajjad Azami", "authors": "Hamid Shayestehmanesh, Sajjad Azami, Nishant A. Mehta", "title": "Dying Experts: Efficient Algorithms with Optimal Regret Bounds", "comments": "18 Pages, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of decision-theoretic online learning in which the set of\nexperts that are available to Learner can shrink over time. This is a\nrestricted version of the well-studied sleeping experts problem, itself a\ngeneralization of the fundamental game of prediction with expert advice.\nSimilar to many works in this direction, our benchmark is the ranking regret.\nVarious results suggest that achieving optimal regret in the fully adversarial\nsleeping experts problem is computationally hard. This motivates our relaxation\nwhere any expert that goes to sleep will never again wake up. We call this\nsetting \"dying experts\" and study it in two different cases: the case where the\nlearner knows the order in which the experts will die and the case where the\nlearner does not. In both cases, we provide matching upper and lower bounds on\nthe ranking regret in the fully adversarial setting. Furthermore, we present\nnew, computationally efficient algorithms that obtain our optimal upper bounds.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 20:28:53 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Shayestehmanesh", "Hamid", ""], ["Azami", "Sajjad", ""], ["Mehta", "Nishant A.", ""]]}, {"id": "1910.13524", "submitter": "Andrew Zammit-Mangion", "authors": "Andrew Zammit-Mangion and Christopher K. Wikle", "title": "Deep Integro-Difference Equation Models for Spatio-Temporal Forecasting", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": "10.1016/j.spasta.2020.100408", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integro-difference equation (IDE) models describe the conditional dependence\nbetween the spatial process at a future time point and the process at the\npresent time point through an integral operator. Nonlinearity or temporal\ndependence in the dynamics is often captured by allowing the operator\nparameters to vary temporally, or by re-fitting a model with a\ntemporally-invariant linear operator in a sliding window. Both procedures tend\nto be excellent for prediction purposes over small time horizons, but are\ngenerally time-consuming and, crucially, do not provide a global prior model\nfor the temporally-varying dynamics that is realistic. Here, we tackle these\ntwo issues by using a deep convolution neural network (CNN) in a hierarchical\nstatistical IDE framework, where the CNN is designed to extract process\ndynamics from the process' most recent behaviour. Once the CNN is fitted,\nprobabilistic forecasting can be done extremely quickly online using an\nensemble Kalman filter with no requirement for repeated parameter estimation.\nWe conduct an experiment where we train the model using 13 years of daily\nsea-surface temperature data in the North Atlantic Ocean. Forecasts are seen to\nbe accurate and calibrated. A key advantage of our approach is that the CNN\nprovides a global prior model for the dynamics that is realistic,\ninterpretable, and computationally efficient. We show the versatility of the\napproach by successfully producing 10-minute nowcasts of weather radar\nreflectivities in Sydney using the same model that was trained on daily\nsea-surface temperature data in the North Atlantic Ocean.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 20:49:25 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 21:21:49 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 23:24:41 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Zammit-Mangion", "Andrew", ""], ["Wikle", "Christopher K.", ""]]}, {"id": "1910.13526", "submitter": "Qin Lin", "authors": "Qin Lin, Sicco Verwer, John Dolan", "title": "Learning a Safety Verifiable Adaptive Cruise Controller from Human\n  Driving Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning provides a way to automatically construct a controller by\nmimicking human behavior from data. For safety-critical systems such as\nautonomous vehicles, it can be problematic to use controllers learned from data\nbecause they cannot be guaranteed to be collision-free. Recently, a method has\nbeen proposed for learning a multi-mode hybrid automaton cruise controller\n(MOHA). Besides being accurate, the logical nature of this model makes it\nsuitable for formal verification. In this paper, we demonstrate this capability\nusing the SpaceEx hybrid model checker as follows. After learning, we translate\nthe automaton model into constraints and equations required by SpaceEx. We then\nverify that a pure MOHA controller is not collision-free. By adding a safety\nstate based on headway in time, a rule that human drivers should follow anyway,\nwe do obtain a provably safe cruise control. Moreover, the safe controller\nremains more human-like than existing cruise controllers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 20:51:13 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lin", "Qin", ""], ["Verwer", "Sicco", ""], ["Dolan", "John", ""]]}, {"id": "1910.13527", "submitter": "Yujia Zheng", "authors": "Yujia Zheng, Siyi Liu, Zailei Zhou", "title": "Balancing Multi-level Interactions for Session-based Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting user actions based on anonymous sessions is a challenge to general\nrecommendation systems because the lack of user profiles heavily limits\ndata-driven models. Recently, session-based recommendation methods have\nachieved remarkable results in dealing with this task. However, the upper bound\nof performance can still be boosted through the innovative exploration of\nlimited data. In this paper, we propose a novel method, namely Intra-and\nInter-session Interaction-aware Graph-enhanced Network, to take inter-session\nitem-level interactions into account. Different from existing intra-session\nitem-level interactions and session-level collaborative information, our\nintroduced data represents complex item-level interactions between different\nsessions. For mining the new data without breaking the equilibrium of the model\nbetween different interactions, we construct an intra-session graph and an\ninter-session graph for the current session. The former focuses on item-level\ninteractions within a single session and the latter models those between items\namong neighborhood sessions. Then different approaches are employed to encode\nthe information of two graphs according to different structures, and the\ngenerated latent vectors are combined to balance the model across different\nscopes. Experiments on real-world datasets verify that our method outperforms\nother state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 20:51:19 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Zheng", "Yujia", ""], ["Liu", "Siyi", ""], ["Zhou", "Zailei", ""]]}, {"id": "1910.13540", "submitter": "Augustus Odena", "authors": "Samarth Sinha, Han Zhang, Anirudh Goyal, Yoshua Bengio, Hugo\n  Larochelle, Augustus Odena", "title": "Small-GAN: Speeding Up GAN Training Using Core-sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work by Brock et al. (2018) suggests that Generative Adversarial\nNetworks (GANs) benefit disproportionately from large mini-batch sizes.\nUnfortunately, using large batches is slow and expensive on conventional\nhardware. Thus, it would be nice if we could generate batches that were\neffectively large though actually small. In this work, we propose a method to\ndo this, inspired by the use of Coreset-selection in active learning. When\ntraining a GAN, we draw a large batch of samples from the prior and then\ncompress that batch using Coreset-selection. To create effectively large\nbatches of 'real' images, we create a cached dataset of Inception activations\nof each training image, randomly project them down to a smaller dimension, and\nthen use Coreset-selection on those projected activations at training time. We\nconduct experiments showing that this technique substantially reduces training\ntime and memory usage for modern GAN variants, that it reduces the fraction of\ndropped modes in a synthetic dataset, and that it allows GANs to reach a new\nstate of the art in anomaly detection.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 21:26:05 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Sinha", "Samarth", ""], ["Zhang", "Han", ""], ["Goyal", "Anirudh", ""], ["Bengio", "Yoshua", ""], ["Larochelle", "Hugo", ""], ["Odena", "Augustus", ""]]}, {"id": "1910.13556", "submitter": "Jonathan Gordon", "authors": "Jonathan Gordon, Wessel P. Bruinsma, Andrew Y. K. Foong, James\n  Requeima, Yann Dubois, Richard E. Turner", "title": "Convolutional Conditional Neural Processes", "comments": "Accepted at International Conference on Learning Representations 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Convolutional Conditional Neural Process (ConvCNP), a new\nmember of the Neural Process family that models translation equivariance in the\ndata. Translation equivariance is an important inductive bias for many learning\nproblems including time series modelling, spatial data, and images. The model\nembeds data sets into an infinite-dimensional function space as opposed to a\nfinite-dimensional vector space. To formalize this notion, we extend the theory\nof neural representations of sets to include functional representations, and\ndemonstrate that any translation-equivariant embedding can be represented using\na convolutional deep set. We evaluate ConvCNPs in several settings,\ndemonstrating that they achieve state-of-the-art performance compared to\nexisting NPs. We demonstrate that building in translation equivariance enables\nzero-shot generalization to challenging, out-of-domain tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 21:56:00 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 14:26:44 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 13:23:19 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 13:07:49 GMT"}, {"version": "v5", "created": "Thu, 25 Jun 2020 13:20:06 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Gordon", "Jonathan", ""], ["Bruinsma", "Wessel P.", ""], ["Foong", "Andrew Y. K.", ""], ["Requeima", "James", ""], ["Dubois", "Yann", ""], ["Turner", "Richard E.", ""]]}, {"id": "1910.13561", "submitter": "Mohamed Medhat Gaber", "authors": "Safwan Shatnawi, Mohamed Medhat Gaber, Mihaela Cocea", "title": "A Heuristically Modified FP-Tree for Ontology Learning with Applications\n  in Education", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a heuristically modified FP-Tree for ontology learning from text.\nUnlike previous research, for concept extraction, we use a regular expression\nparser approach widely adopted in compiler construction, i.e., deterministic\nfinite automata (DFA). Thus, the concepts are extracted from unstructured\ndocuments. For ontology learning, we use a frequent pattern mining approach and\nemploy a rule mining heuristic function to enhance its quality. This process\ndoes not rely on predefined lexico-syntactic patterns, thus, it is applicable\nfor different subjects. We employ the ontology in a question-answering system\nfor students' content-related questions. For validation, we used textbook\nquestions/answers and questions from online course forums. Subject experts\nrated the quality of the system's answers on a subset of questions and their\nratings were used to identify the most appropriate automatic semantic text\nsimilarity metric to use as a validation metric for all answers. The Latent\nSemantic Analysis was identified as the closest to the experts' ratings. We\ncompared the use of our ontology with the use of Text2Onto for the\nquestion-answering system and found that with our ontology 80% of the questions\nwere answered, while with Text2Onto only 28.4% were answered, thanks to the\nfiner grained hierarchy our approach is able to produce.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 22:12:44 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Shatnawi", "Safwan", ""], ["Gaber", "Mohamed Medhat", ""], ["Cocea", "Mihaela", ""]]}, {"id": "1910.13565", "submitter": "Andrew Wilson", "authors": "Gregory W. Benton, Wesley J. Maddox, Jayson P. Salkey, Julio Albinati,\n  Andrew Gordon Wilson", "title": "Function-Space Distributions over Kernels", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are flexible function approximators, with inductive biases\ncontrolled by a covariance kernel. Learning the kernel is the key to\nrepresentation learning and strong predictive performance. In this paper, we\ndevelop functional kernel learning (FKL) to directly infer functional\nposteriors over kernels. In particular, we place a transformed Gaussian process\nover a spectral density, to induce a non-parametric distribution over kernel\nfunctions. The resulting approach enables learning of rich representations,\nwith support for any stationary kernel, uncertainty over the values of the\nkernel, and an interpretable specification of a prior directly over kernels,\nwithout requiring sophisticated initialization or manual intervention. We\nperform inference through elliptical slice sampling, which is especially well\nsuited to marginalizing posteriors with the strongly correlated priors typical\nto function space modelling. We develop our approach for non-uniform,\nlarge-scale, multi-task, and multidimensional data, and show promising\nperformance in a wide range of settings, including interpolation,\nextrapolation, and kernel recovery experiments.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 22:26:38 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Benton", "Gregory W.", ""], ["Maddox", "Wesley J.", ""], ["Salkey", "Jayson P.", ""], ["Albinati", "Julio", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1910.13573", "submitter": "Neil Deshmukh", "authors": "Neil Deshmukh, Selin Gumustop, Romane Gauriau, Varun Buch, Bradley\n  Wright, Christopher Bridge, Ram Naidu, Katherine Andriole, and Bernardo Bizzo", "title": "Semi-Supervised Natural Language Approach for Fine-Grained\n  Classification of Medical Reports", "comments": "Accepted for IEEE publication & presented at MIT URTC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although machine learning has become a powerful tool to augment doctors in\nclinical analysis, the immense amount of labeled data that is necessary to\ntrain supervised learning approaches burdens each development task as time and\nresource intensive. The vast majority of dense clinical information is stored\nin written reports, detailing pertinent patient information. The challenge with\nutilizing natural language data for standard model development is due to the\ncomplex nature of the modality. In this research, a model pipeline was\ndeveloped to utilize an unsupervised approach to train an encoder-language\nmodel, a recurrent network, to generate document encodings; which then can be\nused as features passed into a decoder-classifier model that requires\nmagnitudes less labeled data than previous approaches to differentiate between\nfine-grained disease classes accurately. The language model was trained on\nunlabeled radiology reports from the Massachusetts General Hospital Radiology\nDepartment (n=218,159) and terminated with a loss of 1.62. The classification\nmodels were trained on three labeled datasets of head CT studies of reported\npatients, presenting large vessel occlusion (n=1403), acute ischemic strokes\n(n=331), and intracranial hemorrhage (n=4350), to identify a variety of\ndifferent findings directly from the radiology report data; resulting in AUCs\nof 0.98, 0.95, and 0.99, respectively, for the large vessel occlusion, acute\nischemic stroke, and intracranial hemorrhage datasets. The output encodings are\nable to be used in conjunction with imaging data, to create models that can\nprocess a multitude of different modalities. The ability to automatically\nextract relevant features from textual data allows for faster model development\nand integration of textual modality, overall, allowing clinical reports to\nbecome a more viable input for more encompassing and accurate deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 23:25:59 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 03:18:19 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Deshmukh", "Neil", ""], ["Gumustop", "Selin", ""], ["Gauriau", "Romane", ""], ["Buch", "Varun", ""], ["Wright", "Bradley", ""], ["Bridge", "Christopher", ""], ["Naidu", "Ram", ""], ["Andriole", "Katherine", ""], ["Bizzo", "Bernardo", ""]]}, {"id": "1910.13574", "submitter": "Amir Mosavi Prof", "authors": "Sanaz Mojrian, Gergo Pinter, Javad Hassannataj Joloudari, Imre Felde,\n  Narjes Nabipour, Laszlo Nadai, Amir Mosavi", "title": "Hybrid Machine Learning Model of Extreme Learning Machine Radial basis\n  function for Breast Cancer Detection and Diagnosis; a Multilayer Fuzzy Expert\n  System", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mammography is often used as the most common laboratory method for the\ndetection of breast cancer, yet associated with the high cost and many side\neffects. Machine learning prediction as an alternative method has shown\npromising results. This paper presents a method based on a multilayer fuzzy\nexpert system for the detection of breast cancer using an extreme learning\nmachine (ELM) classification model integrated with radial basis function (RBF)\nkernel called ELM-RBF, considering the Wisconsin dataset. The performance of\nthe proposed model is further compared with a linear-SVM model. The proposed\nmodel outperforms the linear-SVM model with RMSE, R2, MAPE equal to 0.1719,\n0.9374 and 0.0539, respectively. Furthermore, both models are studied in terms\nof criteria of accuracy, precision, sensitivity, specificity, validation, true\npositive rate (TPR), and false-negative rate (FNR). The ELM-RBF model for these\ncriteria presents better performance compared to the SVM model.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 23:33:23 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Mojrian", "Sanaz", ""], ["Pinter", "Gergo", ""], ["Joloudari", "Javad Hassannataj", ""], ["Felde", "Imre", ""], ["Nabipour", "Narjes", ""], ["Nadai", "Laszlo", ""], ["Mosavi", "Amir", ""]]}, {"id": "1910.13593", "submitter": "Tyler Lee", "authors": "Tyler Lee and Anthony Ndirango", "title": "Generalization in multitask deep neural classifiers: a statistical\n  physics approach", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A proper understanding of the striking generalization abilities of deep\nneural networks presents an enduring puzzle. Recently, there has been a growing\nbody of numerically-grounded theoretical work that has contributed important\ninsights to the theory of learning in deep neural nets. There has also been a\nrecent interest in extending these analyses to understanding how multitask\nlearning can further improve the generalization capacity of deep neural nets.\nThese studies deal almost exclusively with regression tasks which are amenable\nto existing analytical techniques. We develop an analytic theory of the\nnonlinear dynamics of generalization of deep neural networks trained to solve\nclassification tasks using softmax outputs and cross-entropy loss, addressing\nboth single task and multitask settings. We do so by adapting techniques from\nthe statistical physics of disordered systems, accounting for both finite size\ndatasets and correlated outputs induced by the training dynamics. We discuss\nthe validity of our theoretical results in comparison to a comprehensive suite\nof numerical experiments. Our analysis provides theoretical support for the\nintuition that the performance of multitask learning is determined by the\nnoisiness of the tasks and how well their input features align with each other.\nHighly related, clean tasks benefit each other, whereas unrelated, clean tasks\ncan be detrimental to individual task performance.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 00:25:04 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lee", "Tyler", ""], ["Ndirango", "Anthony", ""]]}, {"id": "1910.13598", "submitter": "Farzin Haddadpour", "authors": "Farzin Haddadpour, Mohammad Mahdi Kamani, Mehrdad Mahdavi, Viveck R.\n  Cadambe", "title": "Local SGD with Periodic Averaging: Tighter Analysis and Adaptive\n  Synchronization", "comments": "Paper accepted to NeurIPS 2019 - We fixed a flaw in the earlier\n  version regarding the dependency on constants but this change does not affect\n  the communication complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication overhead is one of the key challenges that hinders the\nscalability of distributed optimization algorithms. In this paper, we study\nlocal distributed SGD, where data is partitioned among computation nodes, and\nthe computation nodes perform local updates with periodically exchanging the\nmodel among the workers to perform averaging. While local SGD is empirically\nshown to provide promising results, a theoretical understanding of its\nperformance remains open. We strengthen convergence analysis for local SGD, and\nshow that local SGD can be far less expensive and applied far more generally\nthan current theory suggests. Specifically, we show that for loss functions\nthat satisfy the Polyak-{\\L}ojasiewicz condition, $O((pT)^{1/3})$ rounds of\ncommunication suffice to achieve a linear speed up, that is, an error of\n$O(1/pT)$, where $T$ is the total number of model updates at each worker. This\nis in contrast with previous work which required higher number of communication\nrounds, as well as was limited to strongly convex loss functions, for a similar\nasymptotic performance. We also develop an adaptive synchronization scheme that\nprovides a general condition for linear speed up. Finally, we validate the\ntheory with experimental results, running over AWS EC2 clouds and an internal\nGPU cluster.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 00:35:38 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 16:04:26 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Haddadpour", "Farzin", ""], ["Kamani", "Mohammad Mahdi", ""], ["Mahdavi", "Mehrdad", ""], ["Cadambe", "Viveck R.", ""]]}, {"id": "1910.13601", "submitter": "Guansong Pang", "authors": "Guansong Pang, Chunhua Shen, Huidong Jin, Anton van den Hengel", "title": "Deep Weakly-supervised Anomaly Detection", "comments": "Theoretical results are refined and extended. Significant more\n  empirical results are added, including results on detecting previously\n  unknown anomalies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is typically posited as an unsupervised learning task in\nthe literature due to the prohibitive cost and difficulty to obtain large-scale\nlabeled anomaly data, but this ignores the fact that a very small number\n(e.g.,, a few dozens) of labeled anomalies can often be made available with\nsmall/trivial cost in many real-world anomaly detection applications. To\nleverage such labeled anomaly data, we study an important anomaly detection\nproblem termed weakly-supervised anomaly detection, in which, in addition to a\nlarge amount of unlabeled data, a limited number of labeled anomalies are\navailable during modeling. Learning with the small labeled anomaly data enables\nanomaly-informed modeling, which helps identify anomalies of interest and\naddress the notorious high false positives in unsupervised anomaly detection.\nHowever, the problem is especially challenging, since (i) the limited amount of\nlabeled anomaly data often, if not always, cannot cover all types of anomalies\nand (ii) the unlabeled data is often dominated by normal instances but has\nanomaly contamination. We address the problem by formulating it as a pairwise\nrelation prediction task. Particularly, our approach defines a two-stream\nordinal regression neural network to learn the relation of randomly sampled\ninstance pairs, i.e., whether the instance pair contains two labeled anomalies,\none labeled anomaly, or just unlabeled data instances. The resulting model\neffectively leverages both the labeled and unlabeled data to substantially\naugment the training data and learn well-generalized representations of\nnormality and abnormality. Comprehensive empirical results on 40 real-world\ndatasets show that our approach (i) significantly outperforms four\nstate-of-the-art methods in detecting both of the known and previously unseen\nanomalies and (ii) is substantially more data-efficient.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 00:40:25 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 04:59:36 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2020 05:21:03 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Pang", "Guansong", ""], ["Shen", "Chunhua", ""], ["Jin", "Huidong", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1910.13603", "submitter": "S\\'ebastien Arnold", "authors": "S\\'ebastien M.R. Arnold, Shariq Iqbal, Fei Sha", "title": "When MAML Can Adapt Fast and How to Assist When It Cannot", "comments": "Accepted at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-Agnostic Meta-Learning (MAML) and its variants have achieved success in\nmeta-learning tasks on many datasets and settings. On the other hand, we have\njust started to understand and analyze how they are able to adapt fast to new\ntasks. For example, one popular hypothesis is that the algorithms learn good\nrepresentations for transfer, as in multi-task learning. In this work, we\ncontribute by providing a series of empirical and theoretical studies, and\ndiscover several interesting yet previously unknown properties of the\nalgorithm. We find MAML adapts better with a deep architecture even if the\ntasks need only a shallow one (and thus, no representation learning is needed).\nWhile echoing previous findings by others that the bottom layers in deep\narchitectures enable representation learning, we also find that upper layers\nenable fast adaptation by being meta-learned to perform adaptive gradient\nupdate when generalizing to new tasks. Motivated by these findings, we study\nseveral meta-optimization approaches and propose a new one for learning to\noptimize adaptively. Those approaches attain stronger performance in\nmeta-learning both shallower and deeper architectures than MAML.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 00:50:42 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 04:39:00 GMT"}, {"version": "v3", "created": "Sun, 24 Jan 2021 23:55:14 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Arnold", "S\u00e9bastien M. R.", ""], ["Iqbal", "Shariq", ""], ["Sha", "Fei", ""]]}, {"id": "1910.13607", "submitter": "Atoosa Kasirzadeh", "authors": "Atoosa Kasirzadeh", "title": "Mathematical decisions and non-causal elements of explainable AI", "comments": "A shorter version of this paper was presented at the NeurIPS 2019,\n  Human-Centric Machine Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The social implications of algorithmic decision-making in sensitive contexts\nhave generated lively debates among multiple stakeholders, such as moral and\npolitical philosophers, computer scientists, and the public. Yet, the lack of a\ncommon language and a conceptual framework for an appropriate bridging of the\nmoral, technical, and political aspects of the debate prevents the discussion\nto be as effective as it can be. Social scientists and psychologists are\ncontributing to this debate by gathering a wealth of empirical data, yet a\nphilosophical analysis of the social implications of algorithmic\ndecision-making remains comparatively impoverished. In attempting to address\nthis lacuna, this paper argues that a hierarchy of different types of\nexplanations for why and how an algorithmic decision outcome is achieved can\nestablish the relevant connection between the moral and technical aspects of\nalgorithmic decision-making. In particular, I offer a multi-faceted conceptual\nframework for the explanations and the interpretations of algorithmic\ndecisions, and I claim that this framework can lay the groundwork for a focused\ndiscussion among multiple stakeholders about the social implications of\nalgorithmic decision-making, as well as AI governance and ethics more\ngenerally.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 00:58:44 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 07:08:33 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Kasirzadeh", "Atoosa", ""]]}, {"id": "1910.13613", "submitter": "Yuxiao Liu", "authors": "Yuxiao Liu, Bolun Xu, Audun Botterud, Ning Zhang, and Chongqing Kang", "title": "Bounding Regression Errors in Data-driven Power Grid Steady-state Models", "comments": "11 pages, 10 fugures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven models analyze power grids under incomplete physical information,\nand their accuracy has been mostly validated empirically using certain training\nand testing datasets. This paper explores error bounds for data-driven models\nunder all possible training and testing scenarios, and proposes an evaluation\nimplementation based on Rademacher complexity theory. We answer key questions\nfor data-driven models: how much training data is required to guarantee a\ncertain error bound, and how partial physical knowledge can be utilized to\nreduce the required amount of data. Our results are crucial for the evaluation\nand application of data-driven models in power grid analysis. We demonstrate\nthe proposed method by finding generalization error bounds for two\napplications, i.e. branch flow linearization and external network equivalent\nunder different degrees of physical knowledge. Results identify how the bounds\ndecrease with additional power grid physical knowledge or more training data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 01:20:10 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 14:39:58 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Liu", "Yuxiao", ""], ["Xu", "Bolun", ""], ["Botterud", "Audun", ""], ["Zhang", "Ning", ""], ["Kang", "Chongqing", ""]]}, {"id": "1910.13614", "submitter": "Ruosong Wang", "authors": "Simon S. Du, Ruosong Wang, Mengdi Wang, Lin F. Yang", "title": "Continuous Control with Contexts, Provably", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in artificial intelligence is to build an agent that\ngeneralizes and adapts to unseen environments. A common strategy is to build a\ndecoder that takes the context of the unseen new environment as input and\ngenerates a policy accordingly. The current paper studies how to build a\ndecoder for the fundamental continuous control task, linear quadratic regulator\n(LQR), which can model a wide range of real-world physical environments. We\npresent a simple algorithm for this problem, which uses upper confidence bound\n(UCB) to refine the estimate of the decoder and balance the\nexploration-exploitation trade-off. Theoretically, our algorithm enjoys a\n$\\widetilde{O}\\left(\\sqrt{T}\\right)$ regret bound in the online setting where\n$T$ is the number of environments the agent played. This also implies after\nplaying $\\widetilde{O}\\left(1/\\epsilon^2\\right)$ environments, the agent is\nable to transfer the learned knowledge to obtain an $\\epsilon$-suboptimal\npolicy for an unseen environment. To our knowledge, this is first provably\nefficient algorithm to build a decoder in the continuous control setting. While\nour main focus is theoretical, we also present experiments that demonstrate the\neffectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 01:20:58 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Du", "Simon S.", ""], ["Wang", "Ruosong", ""], ["Wang", "Mengdi", ""], ["Yang", "Lin F.", ""]]}, {"id": "1910.13616", "submitter": "Risto Vuorio", "authors": "Risto Vuorio, Shao-Hua Sun, Hexiang Hu, and Joseph J. Lim", "title": "Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-agnostic meta-learners aim to acquire meta-learned parameters from\nsimilar tasks to adapt to novel tasks from the same distribution with few\ngradient updates. With the flexibility in the choice of models, those\nframeworks demonstrate appealing performance on a variety of domains such as\nfew-shot image classification and reinforcement learning. However, one\nimportant limitation of such frameworks is that they seek a common\ninitialization shared across the entire task distribution, substantially\nlimiting the diversity of the task distributions that they are able to learn\nfrom. In this paper, we augment MAML with the capability to identify the mode\nof tasks sampled from a multimodal task distribution and adapt quickly through\ngradient updates. Specifically, we propose a multimodal MAML (MMAML) framework,\nwhich is able to modulate its meta-learned prior parameters according to the\nidentified mode, allowing more efficient fast adaptation. We evaluate the\nproposed model on a diverse set of few-shot learning tasks, including\nregression, image classification, and reinforcement learning. The results not\nonly demonstrate the effectiveness of our model in modulating the meta-learned\nprior in response to the characteristics of tasks but also show that training\non a multimodal distribution can produce an improvement over unimodal training.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 01:35:19 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Vuorio", "Risto", ""], ["Sun", "Shao-Hua", ""], ["Hu", "Hexiang", ""], ["Lim", "Joseph J.", ""]]}, {"id": "1910.13618", "submitter": "Chen Dan", "authors": "Chen Dan, Hong Wang, Hongyang Zhang, Yuchen Zhou, Pradeep Ravikumar", "title": "Optimal Analysis of Subset-Selection Based L_p Low Rank Approximation", "comments": "20 pages, accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the low rank approximation problem of any given matrix $A$ over\n$\\mathbb{R}^{n\\times m}$ and $\\mathbb{C}^{n\\times m}$ in entry-wise $\\ell_p$\nloss, that is, finding a rank-$k$ matrix $X$ such that $\\|A-X\\|_p$ is\nminimized. Unlike the traditional $\\ell_2$ setting, this particular variant is\nNP-Hard. We show that the algorithm of column subset selection, which was an\nalgorithmic foundation of many existing algorithms, enjoys approximation ratio\n$(k+1)^{1/p}$ for $1\\le p\\le 2$ and $(k+1)^{1-1/p}$ for $p\\ge 2$. This improves\nupon the previous $O(k+1)$ bound for $p\\ge 1$\n\\cite{chierichetti2017algorithms}. We complement our analysis with lower\nbounds; these bounds match our upper bounds up to constant $1$ when $p\\geq 2$.\nAt the core of our techniques is an application of \\emph{Riesz-Thorin\ninterpolation theorem} from harmonic analysis, which might be of independent\ninterest to other algorithmic designs and analysis more broadly.\n  As a consequence of our analysis, we provide better approximation guarantees\nfor several other algorithms with various time complexity. For example, to make\nthe algorithm of column subset selection computationally efficient, we analyze\na polynomial time bi-criteria algorithm which selects $O(k\\log m)$ columns. We\nshow that this algorithm has an approximation ratio of $O((k+1)^{1/p})$ for\n$1\\le p\\le 2$ and $O((k+1)^{1-1/p})$ for $p\\ge 2$. This improves over the\nbest-known bound with an $O(k+1)$ approximation ratio. Our bi-criteria\nalgorithm also implies an exact-rank method in polynomial time with a slightly\nlarger approximation ratio.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 01:42:20 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Dan", "Chen", ""], ["Wang", "Hong", ""], ["Zhang", "Hongyang", ""], ["Zhou", "Yuchen", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1910.13631", "submitter": "Yijun Bian", "authors": "Yijun Bian, Huanhuan Chen", "title": "When does Diversity Help Generalization in Classification Ensembles?", "comments": "Accepted by the IEEE Transactions on Cybernetics", "journal-ref": null, "doi": "10.1109/TCYB.2021.3053165", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles, as a widely used and effective technique in the machine learning\ncommunity, succeed within a key element -- \"diversity.\" The relationship\nbetween diversity and generalization, unfortunately, is not entirely understood\nand remains an open research issue. To reveal the effect of diversity on the\ngeneralization of classification ensembles, we investigate three issues on\ndiversity, i.e., the measurement of diversity, the relationship between the\nproposed diversity and the generalization error, and the utilization of this\nrelationship for ensemble pruning. In the diversity measurement, we measure\ndiversity by error decomposition inspired by regression ensembles, which\ndecomposes the error of classification ensembles into accuracy and diversity.\nThen we formulate the relationship between the measured diversity and ensemble\nperformance through the theorem of margin and generalization and observe that\nthe generalization error is reduced effectively only when the measured\ndiversity is increased in a few specific ranges, while in other ranges larger\ndiversity is less beneficial to increasing the generalization of an ensemble.\nBesides, we propose two pruning methods based on diversity management to\nutilize this relationship, which could increase diversity appropriately and\nshrink the size of the ensemble without much-decreasing performance. Empirical\nresults validate the reasonableness of the proposed relationship between\ndiversity and ensemble generalization error and the effectiveness of the\nproposed pruning methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 02:39:08 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 05:25:10 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Bian", "Yijun", ""], ["Chen", "Huanhuan", ""]]}, {"id": "1910.13634", "submitter": "HaiLiang Li", "authors": "Hailiang Li, Adele Y.C. Wang, Yang Liu, Du Tang, Zhibin Lei, Wenye Li", "title": "An Augmented Transformer Architecture for Natural Language Generation\n  Tasks", "comments": "This paper will be appeared in the conference workshop ICDM MLCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Transformer based neural networks have been showing significant\nadvantages on most evaluations of various natural language processing and other\nsequence-to-sequence tasks due to its inherent architecture based\nsuperiorities. Although the main architecture of the Transformer has been\ncontinuously being explored, little attention was paid to the positional\nencoding module. In this paper, we enhance the sinusoidal positional encoding\nalgorithm by maximizing the variances between encoded consecutive positions to\nobtain additional promotion. Furthermore, we propose an augmented Transformer\narchitecture encoded with additional linguistic knowledge, such as the\nPart-of-Speech (POS) tagging, to boost the performance on some natural language\ngeneration tasks, e.g., the automatic translation and summarization tasks.\nExperiments show that the proposed architecture attains constantly superior\nresults compared to the vanilla Transformer.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 02:46:04 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Li", "Hailiang", ""], ["Wang", "Adele Y. C.", ""], ["Liu", "Yang", ""], ["Tang", "Du", ""], ["Lei", "Zhibin", ""], ["Li", "Wenye", ""]]}, {"id": "1910.13645", "submitter": "Xin Qin", "authors": "Xin Qin, Nikos Ar\\'echiga, Andrew Best, Jyotirmoy Deshmukh", "title": "Automatic Testing With Reusable Adversarial Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems such as self-driving cars and general-purpose robots are\nsafety-critical systems that operate in highly uncertain and dynamic\nenvironments. We propose an interactive multi-agent framework where the\nsystem-under-design is modeled as an ego agent and its environment is modeled\nby a number of adversarial (ado) agents. For example, a self-driving car is an\nego agent whose behavior is influenced by ado agents such as pedestrians,\nbicyclists, traffic lights, road geometry etc. Given a logical specification of\nthe correct behavior of the ego agent, and a set of constraints that encode\nreasonable adversarial behavior, our framework reduces the adversarial testing\nproblem to the problem of synthesizing controllers for (constrained) ado agents\nthat cause the ego agent to violate its specifications. Specifically, we\nexplore the use of tabular and deep reinforcement learning approaches for\nsynthesizing adversarial agents. We show that ado agents trained in this\nfashion are better than traditional falsification or testing techniques because\nthey can generalize to ego agents and environments that differ from the\noriginal ego agent. We demonstrate the efficacy of our technique on two\nreal-world case studies from the domain of self-driving cars.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 03:18:10 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 07:46:56 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 22:27:14 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Qin", "Xin", ""], ["Ar\u00e9chiga", "Nikos", ""], ["Best", "Andrew", ""], ["Deshmukh", "Jyotirmoy", ""]]}, {"id": "1910.13659", "submitter": "Quanquan Gu", "authors": "Lingxiao Wang and Bargav Jayaraman and David Evans and Quanquan Gu", "title": "Efficient Privacy-Preserving Stochastic Nonconvex Optimization", "comments": "28 pages, 5 figures, 6 tables. This version improves the algorithm\n  and the presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many solutions for privacy-preserving convex empirical risk\nminimization (ERM) have been developed, privacy-preserving nonconvex ERM\nremains a challenge. We study nonconvex ERM, which takes the form of minimizing\na finite-sum of nonconvex loss functions over a training set. We propose a new\ndifferentially private stochastic gradient descent algorithm for nonconvex ERM\nthat achieves strong privacy guarantees efficiently, and provide a tight\nanalysis of its privacy and utility guarantees, as well as its gradient\ncomplexity. Our algorithm substantially reduces gradient complexity while\nmatching the best previous utility guarantee given by Wang et al. (2017). We\nextend our algorithm to the distributed setting using secure multi-party\ncomputation, and show it is possible for a distributed algorithm to match the\nprivacy and utility guarantees of a centralized algorithm in this setting. Our\nexperiments on benchmark nonconvex ERM problems demonstrate superior\nperformance in terms of both training cost and utility gains compared with\nprevious differentially private methods using the same privacy budgets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 04:32:56 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 17:43:19 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Wang", "Lingxiao", ""], ["Jayaraman", "Bargav", ""], ["Evans", "David", ""], ["Gu", "Quanquan", ""]]}, {"id": "1910.13672", "submitter": "Mojtaba Sahraee Ardakan", "authors": "M. Emami, M. Sahraee-Ardakan, S. Rangan, A. K. Fletcher", "title": "Input-Output Equivalence of Unitary and Contractive RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unitary recurrent neural networks (URNNs) have been proposed as a method to\novercome the vanishing and exploding gradient problem in modeling data with\nlong-term dependencies. A basic question is how restrictive is the unitary\nconstraint on the possible input-output mappings of such a network? This work\nshows that for any contractive RNN with ReLU activations, there is a URNN with\nat most twice the number of hidden states and the identical input-output\nmapping. Hence, with ReLU activations, URNNs are as expressive as general RNNs.\nIn contrast, for certain smooth activations, it is shown that the input-output\nmapping of an RNN cannot be matched with a URNN, even with an arbitrary number\nof states. The theoretical results are supported by experiments on modeling of\nslowly-varying dynamical systems.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 05:02:44 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Emami", "M.", ""], ["Sahraee-Ardakan", "M.", ""], ["Rangan", "S.", ""], ["Fletcher", "A. K.", ""]]}, {"id": "1910.13673", "submitter": "Mingyuan Zhou", "authors": "Zhendong Wang and Mingyuan Zhou", "title": "Thompson Sampling via Local Uncertainty", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson sampling is an efficient algorithm for sequential decision making,\nwhich exploits the posterior uncertainty to address the\nexploration-exploitation dilemma. There has been significant recent interest in\nintegrating Bayesian neural networks into Thompson sampling. Most of these\nmethods rely on global variable uncertainty for exploration. In this paper, we\npropose a new probabilistic modeling framework for Thompson sampling, where\nlocal latent variable uncertainty is used to sample the mean reward.\nVariational inference is used to approximate the posterior of the local\nvariable, and semi-implicit structure is further introduced to enhance its\nexpressiveness. Our experimental results on eight contextual bandit benchmark\ndatasets show that Thompson sampling guided by local uncertainty achieves\nstate-of-the-art performance while having low computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 05:05:30 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 05:38:02 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 22:18:02 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Wang", "Zhendong", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1910.13675", "submitter": "Kevin Zakka", "authors": "Kevin Zakka, Andy Zeng, Johnny Lee, Shuran Song", "title": "Form2Fit: Learning Shape Priors for Generalizable Assembly from\n  Disassembly", "comments": "Code, videos, and supplemental material are available at\n  https://form2fit.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it possible to learn policies for robotic assembly that can generalize to\nnew objects? We explore this idea in the context of the kit assembly task.\nSince classic methods rely heavily on object pose estimation, they often\nstruggle to generalize to new objects without 3D CAD models or task-specific\ntraining data. In this work, we propose to formulate the kit assembly task as a\nshape matching problem, where the goal is to learn a shape descriptor that\nestablishes geometric correspondences between object surfaces and their target\nplacement locations from visual input. This formulation enables the model to\nacquire a broader understanding of how shapes and surfaces fit together for\nassembly -- allowing it to generalize to new objects and kits. To obtain\ntraining data for our model, we present a self-supervised data-collection\npipeline that obtains ground truth object-to-placement correspondences by\ndisassembling complete kits. Our resulting real-world system, Form2Fit, learns\neffective pick and place strategies for assembling objects into a variety of\nkits -- achieving $90\\%$ average success rates under different initial\nconditions (e.g. varying object and kit poses), $94\\%$ success under new\nconfigurations of multiple kits, and over $86\\%$ success with completely new\nobjects and kits.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 05:11:53 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 23:20:28 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zakka", "Kevin", ""], ["Zeng", "Andy", ""], ["Lee", "Johnny", ""], ["Song", "Shuran", ""]]}, {"id": "1910.13717", "submitter": "Daniel Rodriguez", "authors": "Daniel Rodriguez and Javier Dolado and Javier Tuya and Dietmar Pfahl", "title": "Software defect prediction with zero-inflated Poisson models", "comments": "4 pages, 2 figures, presented at MadSESE'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we apply several Poisson and zero-inflated models for software\ndefect prediction. We apply different functions from several R packages such as\npscl, MASS, R2Jags and the recent glmmTMB. We test the functions using the\nEquinox dataset. The results show that Zero-inflated models, fitted with either\nmaximum likelihood estimation or with Bayesian approach, are slightly better\nthan other models, using the AIC as selection criterion.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 08:36:39 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Rodriguez", "Daniel", ""], ["Dolado", "Javier", ""], ["Tuya", "Javier", ""], ["Pfahl", "Dietmar", ""]]}, {"id": "1910.13724", "submitter": "Kazuki Shimada", "authors": "Kazuki Shimada, Yuichiro Koyama, Akira Inoue", "title": "Metric Learning with Background Noise Class for Few-shot Detection of\n  Rare Sound Events", "comments": "5 pages, 5 figures, accepted for publication in IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning systems for sound event recognition have gained interests\nsince they require only a few examples to adapt to new target classes without\nfine-tuning. However, such systems have only been applied to chunks of sounds\nfor classification or verification. In this paper, we aim to achieve few-shot\ndetection of rare sound events, from query sequence that contain not only the\ntarget events but also the other events and background noise. Therefore, it is\nrequired to prevent false positive reactions to both the other events and\nbackground noise. We propose metric learning with background noise class for\nthe few-shot detection. The contribution is to present the explicit inclusion\nof background noise as an independent class, a suitable loss function that\nemphasizes this additional class, and a corresponding sampling strategy that\nassists training. It provides a feature space where the event classes and the\nbackground noise class are sufficiently separated. Evaluations on few-shot\ndetection tasks, using DCASE 2017 task2 and ESC-50, show that our proposed\nmethod outperforms metric learning without considering the background noise\nclass. The few-shot detection performance is also comparable to that of the\nDCASE 2017 task2 baseline system, which requires huge amount of annotated audio\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 09:00:59 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 11:24:49 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Shimada", "Kazuki", ""], ["Koyama", "Yuichiro", ""], ["Inoue", "Akira", ""]]}, {"id": "1910.13726", "submitter": "Matteo Turchetta", "authors": "Matteo Turchetta, Felix Berkenkamp, Andreas Krause", "title": "Safe Exploration for Interactive Machine Learning", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Interactive Machine Learning (IML), we iteratively make decisions and\nobtain noisy observations of an unknown function. While IML methods, e.g.,\nBayesian optimization and active learning, have been successful in\napplications, on real-world systems they must provably avoid unsafe decisions.\nTo this end, safe IML algorithms must carefully learn about a priori unknown\nconstraints without making unsafe decisions. Existing algorithms for this\nproblem learn about the safety of all decisions to ensure convergence. This is\nsample-inefficient, as it explores decisions that are not relevant for the\noriginal IML objective. In this paper, we introduce a novel framework that\nrenders any existing unsafe IML algorithm safe. Our method works as an add-on\nthat takes suggested decisions as input and exploits regularity assumptions in\nterms of a Gaussian process prior in order to efficiently learn about their\nsafety. As a result, we only explore the safe set when necessary for the IML\nproblem. We apply our framework to safe Bayesian optimization and to safe\nexploration in deterministic Markov Decision Processes (MDP), which have been\nanalyzed separately before. Our method outperforms other algorithms\nempirically.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 09:12:48 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Turchetta", "Matteo", ""], ["Berkenkamp", "Felix", ""], ["Krause", "Andreas", ""]]}, {"id": "1910.13728", "submitter": "Jia Guo", "authors": "Jia Guo and Chenyang Yang", "title": "Structure of Deep Neural Networks with a Priori Information in Wireless\n  Tasks", "comments": "6 pages, 2 figures, Submitted to ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been employed for designing wireless\nnetworks in many aspects, such as transceiver optimization, resource\nallocation, and information prediction. Existing works either use\nfully-connected DNN or the DNNs with specific structures that are designed in\nother domains. In this paper, we show that a priori information widely existed\nin wireless tasks is permutation invariant. For these tasks, we propose a DNN\nwith special structure, where the weight matrices between layers of the DNN\nonly consist of two smaller sub-matrices. By such way of parameter sharing, the\nnumber of model parameters reduces, giving rise to low sample and computational\ncomplexity for training a DNN. We take predictive resource allocation as an\nexample to show how the designed DNN can be applied for learning the optimal\npolicy with unsupervised learning. Simulations results validate our analysis\nand show dramatic gain of the proposed structure in terms of reducing training\ncomplexity.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 09:15:38 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 07:08:13 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Guo", "Jia", ""], ["Yang", "Chenyang", ""]]}, {"id": "1910.13742", "submitter": "Joon Kwon", "authors": "Anatoli Juditsky, Joon Kwon, \\'Eric Moulines", "title": "Unifying mirror descent and dual averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and analyze a new family of algorithms which generalizes and\nunifies both the mirror descent and the dual averaging algorithms. In the\nframework of this family, we define a new algorithm for constrained\noptimization with the aim of combining the advantages of mirror descent and\ndual averaging. In practice, this new algorithm converges as fast as mirror\ndescent and dual averaging, and in some situations greatly outperforms them.\nBesides, we demonstrate how our algorithms can also be applied to solving\nvariational inequalities.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 09:55:25 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 14:21:56 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Juditsky", "Anatoli", ""], ["Kwon", "Joon", ""], ["Moulines", "\u00c9ric", ""]]}, {"id": "1910.13795", "submitter": "Saeid Haghighatshoar", "authors": "Yi Song, Mahdi Barzegar Khalilsarai, Saeid Haghighatshoar, and\n  Giuseppe Caire", "title": "Machine Learning for Geometrically-Consistent Angular Spread Function\n  Estimation in Massive MIMO", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the spatial channel models used in multi-antenna wireless communications,\nthe propagation from a single-antenna transmitter (e.g., a user) to an\nM-antenna receiver (e.g., a Base Station) occurs through scattering clusters\nlocated in the far field of the receiving antenna array. The Angular Spread\nFunction (ASF) of the corresponding M-dim channel vector describes the angular\ndensity of the received signal power at the array. The modern literature on\nmassive MIMO has recognized that the knowledge of covariance matrix of user\nchannel vectors is very useful for various applications such as hybrid digital\nanalog beamforming, pilot decontamination, etc. Therefore, most literature has\nfocused on the estimation of such channel covariance matrices. However, in some\napplications such as uplink-downlink covariance transformation (for FDD massive\nMIMO precoding) and channel sounding some form of ASF estimation is required\neither implicitly or explicitly. It turns out that while covariance estimation\nis well-known and well-conditioned, the ASF estimation is a much harder problem\nand is in general ill-posed. In this paper, we show that under additional\ngeometrically-consistent group-sparsity structure on the ASF, which is\nprevalent in almost all wireless propagation scenarios, one is able to estimate\nASF properly. We propose sparse dictionary-based algorithms that promote this\ngroup-sparsity structure via suitable regularizations. Since generally it is\ndifficult to capture the notion of group-sparsity through proper\nregularization, we propose another algorithm based on Deep Neural Networks\n(DNNs) that learns this structure. We provide numerical simulations to assess\nthe performance of our proposed algorithms. We also compare the results with\nthat of other methods in the literature, where we re-frame those methods in the\ncontext of ASF estimation in massive MIMO.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 12:18:51 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Song", "Yi", ""], ["Khalilsarai", "Mahdi Barzegar", ""], ["Haghighatshoar", "Saeid", ""], ["Caire", "Giuseppe", ""]]}, {"id": "1910.13796", "submitter": "Niall O' Mahony", "authors": "Niall O' Mahony, Sean Campbell, Anderson Carvalho, Suman\n  Harapanahalli, Gustavo Velasco-Hernandez, Lenka Krpalkova, Daniel Riordan,\n  Joseph Walsh", "title": "Deep Learning vs. Traditional Computer Vision", "comments": null, "journal-ref": "in Advances in Computer Vision Proceedings of the 2019 Computer\n  Vision Conference (CVC). Springer Nature Switzerland AG, pp. 128-144", "doi": "10.1007/978-3-030-17795-9", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has pushed the limits of what was possible in the domain of\nDigital Image Processing. However, that is not to say that the traditional\ncomputer vision techniques which had been undergoing progressive development in\nyears prior to the rise of DL have become obsolete. This paper will analyse the\nbenefits and drawbacks of each approach. The aim of this paper is to promote a\ndiscussion on whether knowledge of classical computer vision techniques should\nbe maintained. The paper will also explore how the two sides of computer vision\ncan be combined. Several recent hybrid methodologies are reviewed which have\ndemonstrated the ability to improve computer vision performance and to tackle\nproblems not suited to Deep Learning. For example, combining traditional\ncomputer vision techniques with Deep Learning has been popular in emerging\ndomains such as Panoramic Vision and 3D vision for which Deep Learning models\nhave not yet been fully optimised\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 12:25:10 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Mahony", "Niall O'", ""], ["Campbell", "Sean", ""], ["Carvalho", "Anderson", ""], ["Harapanahalli", "Suman", ""], ["Velasco-Hernandez", "Gustavo", ""], ["Krpalkova", "Lenka", ""], ["Riordan", "Daniel", ""], ["Walsh", "Joseph", ""]]}, {"id": "1910.13799", "submitter": "Zitao Liu", "authors": "Hang Li, Yu Kang, Wenbiao Ding, Song Yang, Songfan Yang, Gale Yan\n  Huang, Zitao Liu", "title": "Multimodal Learning For Classroom Activity Detection", "comments": "The 45th International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classroom activity detection (CAD) focuses on accurately classifying whether\nthe teacher or student is speaking and recording both the length of individual\nutterances during a class. A CAD solution helps teachers get instant feedback\non their pedagogical instructions. This greatly improves educators' teaching\nskills and hence leads to students' achievement. However, CAD is very\nchallenging because (1) the CAD model needs to be generalized well enough for\ndifferent teachers and students; (2) data from both vocal and language\nmodalities has to be wisely fused so that they can be complementary; and (3)\nthe solution shouldn't heavily rely on additional recording device. In this\npaper, we address the above challenges by using a novel attention based neural\nframework. Our framework not only extracts both speech and language\ninformation, but utilizes attention mechanism to capture long-term semantic\ndependence. Our framework is device-free and is able to take any classroom\nrecording as input. The proposed CAD learning framework is evaluated in two\nreal-world education applications. The experimental results demonstrate the\nbenefits of our approach on learning attention based neural network from\nclassroom data with different modalities, and show our approach is able to\noutperform state-of-the-art baselines in terms of various evaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 12:14:07 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 15:38:58 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 23:12:27 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Li", "Hang", ""], ["Kang", "Yu", ""], ["Ding", "Wenbiao", ""], ["Yang", "Song", ""], ["Yang", "Songfan", ""], ["Huang", "Gale Yan", ""], ["Liu", "Zitao", ""]]}, {"id": "1910.13800", "submitter": "Abhishek Ghose", "authors": "Abhishek Ghose", "title": "Rational Kernels: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many kinds of data are naturally amenable to being treated as sequences. An\nexample is text data, where a text may be seen as a sequence of words. Another\nexample is clickstream data, where a data instance is a sequence of clicks made\nby a visitor to a website. This is also common for data originating in the\ndomains of speech processing and computational biology. Using such data with\nstatistical learning techniques can often prove to be cumbersome since most of\nthem only allow fixed-length feature vectors as input. In casting the data to\nfixed-length feature vectors to suit these techniques, we lose the convenience,\nand possibly information, a good sequence-based representation can offer. The\nframework of rational kernels partly addresses this problem by providing an\nelegant representation for sequences, for algorithms that use kernel functions.\nIn this report, we take a comprehensive look at this framework, its various\nextensions and applications. We start with an overview of the core ideas, where\nwe look at the characterization of rational kernels, and then extend our\ndiscussion to extensions, applications and use at scale. Rational kernels\nrepresent a family of kernels, and thus, learning an appropriate rational\nkernel instead of picking one, suggests a convenient way to use them; we\nexplore this idea in our concluding section. Rational kernels are not as\npopular as the many other learning techniques in use today; however, we hope\nthat this summary effectively shows that not only is their theory\nwell-developed, but also that various practical aspects have been carefully\nstudied over time.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 19:16:44 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Ghose", "Abhishek", ""]]}, {"id": "1910.13804", "submitter": "Thomas Adler", "authors": "Thomas Adler, Manuel Erhard, Mario Krenn, Johannes Brandstetter,\n  Johannes Kofler, Sepp Hochreiter", "title": "Quantum Optical Experiments Modeled by Long Short-Term Memory", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how machine learning is able to model experiments in quantum\nphysics. Quantum entanglement is a cornerstone for upcoming quantum\ntechnologies such as quantum computation and quantum cryptography. Of\nparticular interest are complex quantum states with more than two particles and\na large number of entangled quantum levels. Given such a multiparticle\nhigh-dimensional quantum state, it is usually impossible to reconstruct an\nexperimental setup that produces it. To search for interesting experiments, one\nthus has to randomly create millions of setups on a computer and calculate the\nrespective output states. In this work, we show that machine learning models\ncan provide significant improvement over random search. We demonstrate that a\nlong short-term memory (LSTM) neural network can successfully learn to model\nquantum experiments by correctly predicting output state characteristics for\ngiven setups without the necessity of computing the states themselves. This\napproach not only allows for faster search but is also an essential step\ntowards automated design of multiparticle high-dimensional quantum experiments\nusing generative machine learning models.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 12:35:46 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Adler", "Thomas", ""], ["Erhard", "Manuel", ""], ["Krenn", "Mario", ""], ["Brandstetter", "Johannes", ""], ["Kofler", "Johannes", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "1910.13806", "submitter": "Zheng Lian", "authors": "Zheng Lian, Jianhua Tao, Bin Liu, Jian Huang", "title": "Unsupervised Representation Learning with Future Observation Prediction\n  for Speech Emotion Recognition", "comments": null, "journal-ref": "Proc. Interspeech 2019, 3840-3844", "doi": "10.21437/Interspeech.2019-1582", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior works on speech emotion recognition utilize various unsupervised\nlearning approaches to deal with low-resource samples. However, these methods\npay less attention to modeling the long-term dynamic dependency, which is\nimportant for speech emotion recognition. To deal with this problem, this paper\ncombines the unsupervised representation learning strategy -- Future\nObservation Prediction (FOP), with transfer learning approaches (such as\nFine-tuning and Hypercolumns). To verify the effectiveness of the proposed\nmethod, we conduct experiments on the IEMOCAP database. Experimental results\ndemonstrate that our method is superior to currently advanced unsupervised\nlearning strategies.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 16:29:16 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lian", "Zheng", ""], ["Tao", "Jianhua", ""], ["Liu", "Bin", ""], ["Huang", "Jian", ""]]}, {"id": "1910.13807", "submitter": "Zheng Lian", "authors": "Zheng Lian, Jianhua Tao, Bin Liu, Jian Huang", "title": "Domain adversarial learning for emotion recognition", "comments": "submitted to ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical applications for emotion recognition, users do not always exist\nin the training corpus. The mismatch between training speakers and testing\nspeakers affects the performance of the trained model. To deal with this\nproblem, we need our model to focus on emotion-related information, while\nignoring the difference between speaker identities. In this paper, we look into\nthe use of the domain adversarial neural network (DANN) to extract a common\nrepresentation between different speakers. The primary task is to predict\nemotion labels. The secondary task is to learn a common representation where\nspeaker identities can not be distinguished. By using the gradient reversal\nlayer, the gradients coming from the secondary task are used to bring the\nrepresentations for different speakers closer. To verify the effectiveness of\nthe proposed method, we conduct experiments on the IEMOCAP database.\nExperimental results demonstrate that the proposed framework shows an absolute\nimprovement of 3.48% over state-of-the-art strategies.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 16:33:48 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lian", "Zheng", ""], ["Tao", "Jianhua", ""], ["Liu", "Bin", ""], ["Huang", "Jian", ""]]}, {"id": "1910.13817", "submitter": "Jeffrey Hokanson", "authors": "Ibrohim Nosirov and Jeffrey M. Hokanson (Mentor)", "title": "A Numerical Investigation of the Minimum Width of a Neural Network", "comments": "Draft manuscript to be submitted to SIAM Undergrad Research Online", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network width and depth are fundamental aspects of network topology.\nUniversal approximation theorems provide that with increasing width or depth,\nthere exists a neural network that approximates a function arbitrarily well.\nThese theorems assume requirements, such as infinite data, that must be\ndiscretized in practice. Through numerical experiments, we seek to test the\nlower bounds established by Hanin in 2017.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 22:45:43 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Nosirov", "Ibrohim", "", "Mentor"], ["Hokanson", "Jeffrey M.", "", "Mentor"]]}, {"id": "1910.13819", "submitter": "Caroline Ceribeli", "authors": "Caroline Ceribeli, Henrique F. de Arruda, Luciano da F. Costa", "title": "How Coupled are Mass Spectrometry and Capillary Electrophoresis?", "comments": null, "journal-ref": null, "doi": "10.1007/s11192-021-03923-0", "report-no": null, "categories": "cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The understanding of how science works can contribute to making scientific\ndevelopment more effective. In this paper, we report an analysis of the\norganization and interconnection between two important issues in chemistry,\nnamely mass spectrometry (MS) and capillary electrophoresis (CE). For that\npurpose, we employed science of science techniques based on complex networks.\nMore specifically, we considered a citation network in which the nodes and\nconnections represent papers and citations, respectively. Interesting results\nwere found, including a good separation between some clusters of articles\ndevoted to instrumentation techniques and applications. However, the papers\nthat describe CE-MS did not lead to a well-defined cluster. In order to better\nunderstand the organization of the citation network, we considered a\nmulti-scale analysis, in which we used the information regarding sub-clusters.\nFirstly, we analyzed the sub-cluster of the first article devoted to the\ncoupling between CE and MS, which was found to be a good representation of its\nsub-cluster. The second analysis was about the sub-cluster of a seminal paper\nknown to be the first that dealt with proteins by using CE-MS. By considering\nthe proposed methodologies, our paper paves the way for researchers working\nwith both techniques, since it elucidates the knowledge organization and can\ntherefore lead to better literature reviews.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 23:40:27 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ceribeli", "Caroline", ""], ["de Arruda", "Henrique F.", ""], ["Costa", "Luciano da F.", ""]]}, {"id": "1910.13824", "submitter": "Henry Martin", "authors": "Henry Martin, Ye Hong, Dominik Bucher, Christian Rupprecht, Ren\\'e\n  Buffat", "title": "Traffic4cast-Traffic Map Movie Forecasting -- Team MIE-Lab", "comments": null, "journal-ref": null, "doi": "10.3929/ethz-b-000388707", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the IARAI competition traffic4cast was to predict the city-wide\ntraffic status within a 15-minute time window, based on information from the\nprevious hour. The traffic status was given as multi-channel images (one pixel\nroughly corresponds to 100x100 meters), where one channel indicated the traffic\nvolume, another one the average speed of vehicles, and a third one their rough\nheading. As part of our work on the competition, we evaluated many different\nnetwork architectures, analyzed the statistical properties of the given data in\ndetail, and thought about how to transform the problem to be able to take\nadditional spatio-temporal context-information into account, such as the street\nnetwork, the positions of traffic lights, or the weather. This document\nsummarizes our efforts that led to our best submission, and gives some insights\nabout which other approaches we evaluated, and why they did not work as well as\nimagined.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 20:39:14 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 10:10:48 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Martin", "Henry", ""], ["Hong", "Ye", ""], ["Bucher", "Dominik", ""], ["Rupprecht", "Christian", ""], ["Buffat", "Ren\u00e9", ""]]}, {"id": "1910.13827", "submitter": "Nikhil Oswal", "authors": "Nikhil Oswal", "title": "Predicting Rainfall using Machine Learning Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rainfall prediction is one of the challenging and uncertain tasks which has a\nsignificant impact on human society. Timely and accurate predictions can help\nto proactively reduce human and financial loss. This study presents a set of\nexperiments which involve the use of prevalent machine learning techniques to\nbuild models to predict whether it is going to rain tomorrow or not based on\nweather data for that particular day in major cities of Australia. This\ncomparative study is conducted concentrating on three aspects: modeling inputs,\nmodeling methods, and pre-processing techniques. The results provide a\ncomparison of various evaluation metrics of these machine learning techniques\nand their reliability to predict the rainfall by analyzing the weather data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 01:42:15 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Oswal", "Nikhil", ""]]}, {"id": "1910.13830", "submitter": "Tharun Kumar Reddy Medini", "authors": "Tharun Medini, Qixuan Huang, Yiqiu Wang, Vijai Mohan, Anshumali\n  Shrivastava", "title": "Extreme Classification in Log Memory using Count-Min Sketch: A Case\n  Study of Amazon Search with 50M Products", "comments": "Published at NeurIPS 2019. arXiv admin note: text overlap with\n  arXiv:1810.04254", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, it has been shown that many hard AI tasks, especially in\nNLP, can be naturally modeled as extreme classification problems leading to\nimproved precision. However, such models are prohibitively expensive to train\ndue to the memory blow-up in the last layer. For example, a reasonable softmax\nlayer for the dataset of interest in this paper can easily reach well beyond\n100 billion parameters (>400 GB memory). To alleviate this problem, we present\nMerged-Average Classifiers via Hashing (MACH), a generic K-classification\nalgorithm where memory provably scales at O(logK) without any strong assumption\non the classes. MACH is subtly a count-min sketch structure in disguise, which\nuses universal hashing to reduce classification with a large number of classes\nto few embarrassingly parallel and independent classification tasks with a\nsmall (constant) number of classes. MACH naturally provides a technique for\nzero communication model parallelism. We experiment with 6 datasets; some\nmulticlass and some multilabel, and show consistent improvement over respective\nstate-of-the-art baselines. In particular, we train an end-to-end deep\nclassifier on a private product search dataset sampled from Amazon Search\nEngine with 70 million queries and 49.46 million products. MACH outperforms, by\na significant margin,the state-of-the-art extreme classification models\ndeployed on commercial search engines: Parabel and dense embedding models. Our\nlargest model has 6.4 billion parameters and trains in less than 35 hours on a\nsingle p3.16x machine. Our training times are 7-10x faster, and our memory\nfootprints are 2-4x smaller than the best baselines. This training time is also\nsignificantly lower than the one reported by Google's mixture of experts (MoE)\nlanguage model on a comparable model size and hardware.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 19:41:28 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Medini", "Tharun", ""], ["Huang", "Qixuan", ""], ["Wang", "Yiqiu", ""], ["Mohan", "Vijai", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1910.13832", "submitter": "Juri Kuronen", "authors": "Juri Kuronen, Jukka Corander and Johan Pensar", "title": "Learning pairwise Markov network structures using correlation\n  neighborhoods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov networks are widely studied and used throughout multivariate\nstatistics and computer science. In particular, the problem of learning the\nstructure of Markov networks from data without invoking chordality assumptions\nin order to retain expressiveness of the model class has been given a\nconsiderable attention in the recent literature, where numerous\nconstraint-based or score-based methods have been introduced. Here we develop a\nnew search algorithm for the network score-optimization that has several\ncomputational advantages and scales well to high-dimensional data sets. The key\nobservation behind the algorithm is that the neighborhood of a variable can be\nefficiently captured using local penalized likelihood ratio (PLR) tests by\nexploiting an exponential decay of correlations across the neighborhood with an\nincreasing graph-theoretic distance from the focus node. The candidate\nneighborhoods are then processed by a two-stage hill-climbing (HC) algorithm.\nOur approach, termed fully as PLRHC-BIC$_{0.5}$, compares favorably against the\nstate-of-the-art methods in all our experiments spanning both low- and\nhigh-dimensional networks and a wide range of sample sizes. An efficient\nimplementation of PLRHC-BIC$_{0.5}$ is freely available from the URL:\nhttps://github.com/jurikuronen/plrhc.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 13:11:17 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Kuronen", "Juri", ""], ["Corander", "Jukka", ""], ["Pensar", "Johan", ""]]}, {"id": "1910.13850", "submitter": "Fernando Garc\\'ia-Redondo", "authors": "Fernando Garc\\'ia-Redondo, Shidhartha Das, Glen Rosendale", "title": "Training DNN IoT Applications for Deployment On Analog NVM Crossbars", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9206822", "report-no": null, "categories": "cs.LG cs.ET stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A trend towards energy-efficiency, security and privacy has led to a recent\nfocus on deploying DNNs on microcontrollers. However, limits on compute and\nmemory resources restrict the size and the complexity of the ML models\ndeployable in these systems. Computation-In-Memory architectures based on\nresistive nonvolatile memory (NVM) technologies hold great promise of\nsatisfying the compute and memory demands of high-performance and low-power,\ninherent in modern DNNs. Nevertheless, these technologies are still immature\nand suffer from both the intrinsic analog-domain noise problems and the\ninability of representing negative weights in the NVM structures, incurring in\nlarger crossbar sizes with concomitant impact on ADCs and DACs. In this paper,\nwe provide a training framework for addressing these challenges and\nquantitatively evaluate the circuit-level efficiency gains thus accrued. We\nmake two contributions: Firstly, we propose a training algorithm that\neliminates the need for tuning individual layers of a DNN ensuring uniformity\nacross layer weights and activations. This ensures analog-blocks that can be\nreused and peripheral hardware substantially reduced. Secondly, using NAS\nmethods, we propose the use of unipolar-weighted (either all-positive or\nall-negative weights) matrices/sub-matrices. Weight unipolarity obviates the\nneed for doubling crossbar area leading to simplified analog periphery. We\nvalidate our methodology with CIFAR10 and HAR applications by mapping to\ncrossbars using 4-bit and 2-bit devices. We achieve up to 92:91% accuracy (95%\nfloating-point) using 2-bit only-positive weights for HAR. A combination of the\nproposed techniques leads to 80% area improvement and up to 45% energy\nreduction.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 13:49:53 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 16:59:48 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 09:43:17 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Garc\u00eda-Redondo", "Fernando", ""], ["Das", "Shidhartha", ""], ["Rosendale", "Glen", ""]]}, {"id": "1910.13852", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski, Ali H. Sayed", "title": "Linear Speedup in Saddle-Point Escape for Decentralized Non-Convex\n  Optimization", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under appropriate cooperation protocols and parameter choices, fully\ndecentralized solutions for stochastic optimization have been shown to match\nthe performance of centralized solutions and result in linear speedup (in the\nnumber of agents) relative to non-cooperative approaches in the strongly-convex\nsetting. More recently, these results have been extended to the pursuit of\nfirst-order stationary points in non-convex environments. In this work, we\nexamine in detail the dependence of second-order convergence guarantees on the\nspectral properties of the combination policy for non-convex multi agent\noptimization. We establish linear speedup in saddle-point escape time in the\nnumber of agents for symmetric combination policies and study the potential for\nfurther improvement by employing asymmetric combination weights. The results\nimply that a linear speedup can be expected in the pursuit of second-order\nstationary points, which exclude local maxima as well as strict saddle-points\nand correspond to local or even global minima in many important learning\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 13:51:47 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1910.13857", "submitter": "Ali Kavis", "authors": "Ali Kavis, Kfir Y. Levy, Francis Bach, Volkan Cevher", "title": "UniXGrad: A Universal, Adaptive Algorithm with Optimal Guarantees for\n  Constrained Optimization", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adaptive, accelerated algorithm for the stochastic\nconstrained convex optimization setting. Our method, which is inspired by the\nMirror-Prox method, \\emph{simultaneously} achieves the optimal rates for\nsmooth/non-smooth problems with either deterministic/stochastic first-order\noracles. This is done without any prior knowledge of the smoothness nor the\nnoise properties of the problem. To the best of our knowledge, this is the\nfirst adaptive, unified algorithm that achieves the optimal rates in the\nconstrained setting. We demonstrate the practical performance of our framework\nthrough extensive numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:00:59 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Kavis", "Ali", ""], ["Levy", "Kfir Y.", ""], ["Bach", "Francis", ""], ["Cevher", "Volkan", ""]]}, {"id": "1910.13875", "submitter": "Vasisht Duddu", "authors": "Vasisht Duddu, N. Rajesh Pillai, D. Vijay Rao, Valentina E. Balas", "title": "Fault Tolerance of Neural Networks in Adversarial Settings", "comments": null, "journal-ref": "Journal of Intelligent and Fuzzy Systems (JIFS) 2020", "doi": "10.3233/JIFS-179677", "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence systems require a through assessment of different\npillars of trust, namely, fairness, interpretability, data and model privacy,\nreliability (safety) and robustness against against adversarial attacks. While\nthese research problems have been extensively studied in isolation, an\nunderstanding of the trade-off between different pillars of trust is lacking.\nTo this extent, the trade-off between fault tolerance, privacy and adversarial\nrobustness is evaluated for the specific case of Deep Neural Networks, by\nconsidering two adversarial settings under a security and a privacy threat\nmodel. Specifically, this work studies the impact of the fault tolerance of the\nNeural Network on training the model by adding noise to the input (Adversarial\nRobustness) and noise to the gradients (Differential Privacy). While training\nmodels with noise to inputs, gradients or weights enhances fault tolerance, it\nis observed that adversarial robustness and fault tolerance are at odds with\neach other. On the other hand, ($\\epsilon,\\delta$)-Differentially Private\nmodels enhance the fault tolerance, measured using generalisation error,\ntheoretically has an upper bound of $e^{\\epsilon} - 1 + \\delta$. This novel\nstudy of the trade-off between different elements of trust is pivotal for\ntraining a model which satisfies the requirements for different pillars of\ntrust simultaneously.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:22:22 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 16:21:15 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Duddu", "Vasisht", ""], ["Pillai", "N. Rajesh", ""], ["Rao", "D. Vijay", ""], ["Balas", "Valentina E.", ""]]}, {"id": "1910.13886", "submitter": "Juan-Pablo Ortega", "authors": "Lukas Gonon, Lyudmila Grigoryeva, and Juan-Pablo Ortega", "title": "Risk bounds for reservoir computing", "comments": "60 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the practices of reservoir computing in the framework of\nstatistical learning theory. In particular, we derive finite sample upper\nbounds for the generalization error committed by specific families of reservoir\ncomputing systems when processing discrete-time inputs under various hypotheses\non their dependence structure. Non-asymptotic bounds are explicitly written\ndown in terms of the multivariate Rademacher complexities of the reservoir\nsystems and the weak dependence structure of the signals that are being\nhandled. This allows, in particular, to determine the minimal number of\nobservations needed in order to guarantee a prescribed estimation accuracy with\nhigh probability for a given reservoir family. At the same time, the asymptotic\nbehavior of the devised bounds guarantees the consistency of the empirical risk\nminimization procedure for various hypothesis classes of reservoir functionals.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:28:46 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Gonon", "Lukas", ""], ["Grigoryeva", "Lyudmila", ""], ["Ortega", "Juan-Pablo", ""]]}, {"id": "1910.13895", "submitter": "Gail Weiss", "authors": "Gail Weiss, Yoav Goldberg, and Eran Yahav", "title": "Learning Deterministic Weighted Automata with Queries and\n  Counterexamples", "comments": "Presented in NeurIPS 2019. Update: fix email address, add reference\n  to github repo (available at https://github.com/tech-srl/weighted_lstar )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for extraction of a probabilistic deterministic\nfinite automaton (PDFA) from a given black-box language model, such as a\nrecurrent neural network (RNN). The algorithm is a variant of the\nexact-learning algorithm L*, adapted to a probabilistic setting with noise. The\nkey insight is the use of conditional probabilities for observations, and the\nintroduction of a local tolerance when comparing them. When applied to RNNs,\nour algorithm often achieves better word error rate (WER) and normalised\ndistributed cumulative gain (NDCG) than that achieved by spectral extraction of\nweighted finite automata (WFA) from the same networks. PDFAs are substantially\nmore expressive than n-grams, and are guaranteed to be stochastic and\ndeterministic - unlike spectrally extracted WFAs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:37:33 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 10:29:51 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Weiss", "Gail", ""], ["Goldberg", "Yoav", ""], ["Yahav", "Eran", ""]]}, {"id": "1910.13904", "submitter": "Antoine Honor\\'e", "authors": "Antoine Honore, Dong Liu, David Forsberg, Karen Coste, Eric Herlenius,\n  Saikat Chatterjee, Mikael Skoglund", "title": "Hidden Markov Models for sepsis detection in preterm infants", "comments": "Submitted at the 45th International Conference on Acoustics, Speech,\n  and Signal Processing, ICASSP 2020, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of traditional and contemporary hidden Markov models\n(HMMs) for sequential physiological data analysis and sepsis prediction in\npreterm infants. We investigate the use of classical Gaussian mixture model\nbased HMM, and a recently proposed neural network based HMM. To improve the\nneural network based HMM, we propose a discriminative training approach.\nExperimental results show the potential of HMMs over logistic regression,\nsupport vector machine and extreme learning machine.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:49:13 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Honore", "Antoine", ""], ["Liu", "Dong", ""], ["Forsberg", "David", ""], ["Coste", "Karen", ""], ["Herlenius", "Eric", ""], ["Chatterjee", "Saikat", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1910.13921", "submitter": "Mojtaba Bemana", "authors": "Mojtaba Bemana, Karol Myszkowski, Hans-Peter Seidel, Tobias Ritschel", "title": "Neural View-Interpolation for Sparse Light Field Video", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest representing light field (LF) videos as \"one-off\" neural networks\n(NN), i.e., a learned mapping from view-plus-time coordinates to\nhigh-resolution color values, trained on sparse views. Initially, this sounds\nlike a bad idea for three main reasons: First, a NN LF will likely have less\nquality than a same-sized pixel basis representation. Second, only few training\ndata, e.g., 9 exemplars per frame are available for sparse LF videos. Third,\nthere is no generalization across LFs, but across view and time instead.\nConsequently, a network needs to be trained for each LF video. Surprisingly,\nthese problems can turn into substantial advantages: Other than the linear\npixel basis, a NN has to come up with a compact, non-linear i.e., more\nintelligent, explanation of color, conditioned on the sparse view and time\ncoordinates. As observed for many NN however, this representation now is\ninterpolatable: if the image output for sparse view coordinates is plausible,\nit is for all intermediate, continuous coordinates as well. Our specific\nnetwork architecture involves a differentiable occlusion-aware warping step,\nwhich leads to a compact set of trainable parameters and consequently fast\nlearning and fast execution.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 15:18:37 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 16:38:40 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 10:27:50 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Bemana", "Mojtaba", ""], ["Myszkowski", "Karol", ""], ["Seidel", "Hans-Peter", ""], ["Ritschel", "Tobias", ""]]}, {"id": "1910.13923", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Samuel Cahyawijaya, Zhaojiang Lin, Zihan Liu,\n  Pascale Fung", "title": "Lightweight and Efficient End-to-End Speech Recognition Using Low-Rank\n  Transformer", "comments": "The first two authors contributed equally to this work. Accepted as\n  an oral presentation in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly performing deep neural networks come at the cost of computational\ncomplexity that limits their practicality for deployment on portable devices.\nWe propose the low-rank transformer (LRT), a memory-efficient and fast neural\narchitecture that significantly reduces the parameters and boosts the speed of\ntraining and inference for end-to-end speech recognition. Our approach reduces\nthe number of parameters of the network by more than 50% and speeds up the\ninference time by around 1.35x compared to the baseline transformer model. The\nexperiments show that our LRT model generalizes better and yields lower error\nrates on both validation and test sets compared to an uncompressed transformer\nmodel. The LRT model outperforms those from existing works on several datasets\nin an end-to-end setting without using an external language model or acoustic\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 15:20:07 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 19:09:09 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 08:06:33 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Winata", "Genta Indra", ""], ["Cahyawijaya", "Samuel", ""], ["Lin", "Zhaojiang", ""], ["Liu", "Zihan", ""], ["Fung", "Pascale", ""]]}, {"id": "1910.13930", "submitter": "Xilei Zhao", "authors": "Xilei Zhao, Zhengze Zhou, Xiang Yan, Pascal Van Hentenryck", "title": "Distilling Black-Box Travel Mode Choice Model for Behavioral\n  Interpretation", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has proved to be very successful for making predictions in\ntravel behavior modeling. However, most machine-learning models have complex\nmodel structures and offer little or no explanation as to how they arrive at\nthese predictions. Interpretations about travel behavior models are essential\nfor decision makers to understand travelers' preferences and plan policy\ninterventions accordingly. Therefore, this paper proposes to apply and extend\nthe model distillation approach, a model-agnostic machine-learning\ninterpretation method, to explain how a black-box travel mode choice model\nmakes predictions for the entire population and subpopulations of interest.\nModel distillation aims at compressing knowledge from a complex model (teacher)\ninto an understandable and interpretable model (student). In particular, the\npaper integrates model distillation with market segmentation to generate more\ninsights by accounting for heterogeneity. Furthermore, the paper provides a\ncomprehensive comparison of student models with the benchmark model (decision\ntree) and the teacher model (gradient boosting trees) to quantify the fidelity\nand accuracy of the students' interpretations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 15:29:58 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Zhao", "Xilei", ""], ["Zhou", "Zhengze", ""], ["Yan", "Xiang", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1910.13935", "submitter": "Alexander Wagner", "authors": "Alexander Wagner", "title": "Nonembeddability of Persistence Diagrams with $p>2$ Wasserstein Metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG math.AT math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams do not admit an inner product structure compatible with\nany Wasserstein metric. Hence, when applying kernel methods to persistence\ndiagrams, the underlying feature map necessarily causes distortion. We prove\npersistence diagrams with the p-Wasserstein metric do not admit a coarse\nembedding into a Hilbert space when p > 2.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 15:39:37 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Wagner", "Alexander", ""]]}, {"id": "1910.13938", "submitter": "Qiuling Yang", "authors": "Qiuling Yang, Alireza Sadeghi, Gang Wang, Georgios B. Giannakis, Jian\n  Sun", "title": "A Statistical Learning Approach to Reactive Power Control in\n  Distribution Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pronounced variability due to the growth of renewable energy sources,\nflexible loads, and distributed generation is challenging residential\ndistribution systems. This context, motivates well fast, efficient, and robust\nreactive power control. Real-time optimal reactive power control is possible in\ntheory by solving a non-convex optimization problem based on the exact model of\ndistribution flow. However, lack of high-precision instrumentation and reliable\ncommunications, as well as the heavy computational burden of non-convex\noptimization solvers render computing and implementing the optimal control\nchallenging in practice. Taking a statistical learning viewpoint, the\ninput-output relationship between each grid state and the corresponding optimal\nreactive power control is parameterized in the present work by a deep neural\nnetwork, whose unknown weights are learned offline by minimizing the power loss\nover a number of historical and simulated training pairs. In the inference\nphase, one just feeds the real-time state vector into the learned neural\nnetwork to obtain the `optimal' reactive power control with only several\nmatrix-vector multiplications. The merits of this novel statistical learning\napproach are computational efficiency as well as robustness to random input\nperturbations. Numerical tests on a 47-bus distribution network using real data\ncorroborate these practical merits.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 13:38:52 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Yang", "Qiuling", ""], ["Sadeghi", "Alireza", ""], ["Wang", "Gang", ""], ["Giannakis", "Georgios B.", ""], ["Sun", "Jian", ""]]}, {"id": "1910.13951", "submitter": "Pedro Mercado", "authors": "Pedro Mercado, Francesco Tudisco, Matthias Hein", "title": "Generalized Matrix Means for Semi-Supervised Learning with Multilayer\n  Graphs", "comments": "Accepted in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of semi-supervised learning on multilayer graphs by taking\ninto account both labeled and unlabeled observations together with the\ninformation encoded by each individual graph layer. We propose a regularizer\nbased on the generalized matrix mean, which is a one-parameter family of matrix\nmeans that includes the arithmetic, geometric and harmonic means as particular\ncases. We analyze it in expectation under a Multilayer Stochastic Block Model\nand verify numerically that it outperforms state of the art methods. Moreover,\nwe introduce a matrix-free numerical scheme based on contour integral\nquadratures and Krylov subspace solvers that scales to large sparse multilayer\ngraphs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 16:06:35 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Mercado", "Pedro", ""], ["Tudisco", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "1910.13962", "submitter": "Igor Gitman", "authors": "Igor Gitman, Hunter Lang, Pengchuan Zhang, Lin Xiao", "title": "Understanding the Role of Momentum in Stochastic Gradient Methods", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of momentum in stochastic gradient methods has become a widespread\npractice in machine learning. Different variants of momentum, including\nheavy-ball momentum, Nesterov's accelerated gradient (NAG), and\nquasi-hyperbolic momentum (QHM), have demonstrated success on various tasks.\nDespite these empirical successes, there is a lack of clear understanding of\nhow the momentum parameters affect convergence and various performance measures\nof different algorithms. In this paper, we use the general formulation of QHM\nto give a unified analysis of several popular algorithms, covering their\nasymptotic convergence conditions, stability regions, and properties of their\nstationary distributions. In addition, by combining the results on convergence\nrates and stationary distributions, we obtain sometimes counter-intuitive\npractical guidelines for setting the learning rate and momentum parameters.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 16:27:34 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Gitman", "Igor", ""], ["Lang", "Hunter", ""], ["Zhang", "Pengchuan", ""], ["Xiao", "Lin", ""]]}, {"id": "1910.13969", "submitter": "Vittorio Tiozzo", "authors": "Giuseppe Carlo Calafiore, Marisa Hillary Morales, Vittorio Tiozzo,\n  Serge Marquie", "title": "A Classifiers Voting Model for Exit Prediction of Privately Held\n  Companies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the exit (e.g. bankrupt, acquisition, etc.) of privately held\ncompanies is a current and relevant problem for investment firms. The\ndifficulty of the problem stems from the lack of reliable, quantitative and\npublicly available data. In this paper, we contribute to this endeavour by\nconstructing an exit predictor model based on qualitative data, which blends\nthe outcomes of three classifiers, namely, a Logistic Regression model, a\nRandom Forest model, and a Support Vector Machine model. The output of the\ncombined model is selected on the basis of the majority of the output classes\nof the component models. The models are trained using data extracted from the\nThomson Reuters Eikon repository of 54697 US and European companies over the\n1996-2011 time span. Experiments have been conducted for predicting whether the\ncompany eventually either gets acquired or goes public (IPO), against the\ncomplementary event that it remains private or goes bankrupt, in the considered\ntime window. Our model achieves a 63\\% predictive accuracy, which is quite a\nvaluable figure for Private Equity investors, who typically expect very high\nreturns from successful investments.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 16:38:08 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Calafiore", "Giuseppe Carlo", ""], ["Morales", "Marisa Hillary", ""], ["Tiozzo", "Vittorio", ""], ["Marquie", "Serge", ""]]}, {"id": "1910.13983", "submitter": "Michiel Bakker", "authors": "Michiel A. Bakker, Duy Patrick Tu, Humberto River\\'on Vald\\'es,\n  Krishna P. Gummadi, Kush R. Varshney, Adrian Weller, Alex Pentland", "title": "DADI: Dynamic Discovery of Fair Information with Adversarial\n  Reinforcement Learning", "comments": "Accepted at NeurIPS 2019 HCML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for dynamic adversarial discovery of information\n(DADI), motivated by a scenario where information (a feature set) is used by\nthird parties with unknown objectives. We train a reinforcement learning agent\nto sequentially acquire a subset of the information while balancing accuracy\nand fairness of predictors downstream. Based on the set of already acquired\nfeatures, the agent decides dynamically to either collect more information from\nthe set of available features or to stop and predict using the information that\nis currently available. Building on previous work exploring adversarial\nrepresentation learning, we attain group fairness (demographic parity) by\nrewarding the agent with the adversary's loss, computed over the final feature\nset. Importantly, however, the framework provides a more general starting point\nfor fair or private dynamic information discovery. Finally, we demonstrate\nempirically, using two real-world datasets, that we can trade-off fairness and\npredictive performance\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 16:54:22 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Bakker", "Michiel A.", ""], ["Tu", "Duy Patrick", ""], ["Vald\u00e9s", "Humberto River\u00f3n", ""], ["Gummadi", "Krishna P.", ""], ["Varshney", "Kush R.", ""], ["Weller", "Adrian", ""], ["Pentland", "Alex", ""]]}, {"id": "1910.13984", "submitter": "Ali Vakilian", "authors": "Piotr Indyk, Ali Vakilian, Yang Yuan", "title": "Learning-Based Low-Rank Approximations", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a \"learning-based\" algorithm for the low-rank decomposition\nproblem: given an $n \\times d$ matrix $A$, and a parameter $k$, compute a\nrank-$k$ matrix $A'$ that minimizes the approximation loss $\\|A-A'\\|_F$. The\nalgorithm uses a training set of input matrices in order to optimize its\nperformance. Specifically, some of the most efficient approximate algorithms\nfor computing low-rank approximations proceed by computing a projection $SA$,\nwhere $S$ is a sparse random $m \\times n$ \"sketching matrix\", and then\nperforming the singular value decomposition of $SA$. We show how to replace the\nrandom matrix $S$ with a \"learned\" matrix of the same sparsity to reduce the\nerror.\n  Our experiments show that, for multiple types of data sets, a learned sketch\nmatrix can substantially reduce the approximation loss compared to a random\nmatrix $S$, sometimes by one order of magnitude. We also study mixed matrices\nwhere only some of the rows are trained and the remaining ones are random, and\nshow that matrices still offer improved performance while retaining worst-case\nguarantees.\n  Finally, to understand the theoretical aspects of our approach, we study the\nspecial case of $m=1$. In particular, we give an approximation algorithm for\nminimizing the empirical loss, with approximation factor depending on the\nstable rank of matrices in the training set. We also show generalization bounds\nfor the sketch matrix learning problem.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 16:54:50 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Indyk", "Piotr", ""], ["Vakilian", "Ali", ""], ["Yuan", "Yang", ""]]}, {"id": "1910.13988", "submitter": "Roman Goldenberg", "authors": "Dror Simon, Miriam Farber, Roman Goldenberg", "title": "Auto-Annotation Quality Prediction for Semi-Supervised Learning with\n  Ensembles", "comments": "10 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-annotation by ensemble of models is an efficient method of learning on\nunlabeled data. Wrong or inaccurate annotations generated by the ensemble may\nlead to performance degradation of the trained model. To deal with this problem\nwe propose filtering the auto-labeled data using a trained model that predicts\nthe quality of the annotation from the degree of consensus between ensemble\nmodels. Using semantic segmentation as an example, we show the advantage of the\nproposed auto-annotation filtering over training on data contaminated with\ninaccurate labels.\n  Moreover, our experimental results show that in the case of semantic\nsegmentation, the performance of a state-of-the-art model can be achieved by\ntraining it with only a fraction (30$\\%$) of the original manually labeled data\nset, and replacing the rest with the auto-annotated, quality filtered labels.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 17:10:21 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Simon", "Dror", ""], ["Farber", "Miriam", ""], ["Goldenberg", "Roman", ""]]}, {"id": "1910.13993", "submitter": "Litu Rout", "authors": "Litu Rout", "title": "Is Supervised Learning With Adversarial Features Provably Better Than\n  Sole Supervision?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) have shown promising results on a wide\nvariety of complex tasks. Recent experiments show adversarial training provides\nuseful gradients to the generator that helps attain better performance. In this\npaper, we intend to theoretically analyze whether supervised learning with\nadversarial features can outperform sole supervision, or not. First, we show\nthat supervised learning without adversarial features suffer from vanishing\ngradient issue in near optimal region. Second, we analyze how adversarial\nlearning augmented with supervised signal mitigates this vanishing gradient\nissue. Finally, we prove our main result that shows supervised learning with\nadversarial features can be better than sole supervision (under some mild\nassumptions). We support our main result on two fronts (i) expected empirical\nrisk and (ii) rate of convergence.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 17:20:45 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 14:42:18 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Rout", "Litu", ""]]}, {"id": "1910.14002", "submitter": "Vaneet Aggarwal", "authors": "Ashutosh Singh and Abubakr Alabbasi and Vaneet Aggarwal", "title": "A Distributed Model-Free Algorithm for Multi-hop Ride-sharing using Deep\n  Reinforcement Learning", "comments": "This is an extended version of the work presented in NeurIPS Workshop\n  2019. arXiv admin note: text overlap with arXiv:1903.03882", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of autonomous vehicles, ridesharing systems, and self driving\ntechnology will bring a shift in the way ride hailing platforms plan out their\nservices. However, these advances in technology coupled with road congestion,\nenvironmental concerns, fuel usage, vehicles emissions, and the high cost of\nthe vehicle usage have brought more attention to better utilize the use of\nvehicles and their capacities. In this paper, we propose a novel multi-hop\nride-sharing (MHRS) algorithm that uses deep reinforcement learning to learn\noptimal vehicle dispatch and matching decisions by interacting with the\nexternal environment. By allowing customers to transfer between vehicles, i.e.,\nride with one vehicle for sometime and then transfer to another one, MHRS helps\nin attaining 30\\% lower cost and 20\\% more efficient utilization of fleets, as\ncompared to the ride-sharing algorithms. This flexibility of multi-hop feature\ngives a seamless experience to customers and ride-sharing companies, and thus\nimproves ride-sharing services.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 17:40:32 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Singh", "Ashutosh", ""], ["Alabbasi", "Abubakr", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1910.14025", "submitter": "Chen Li", "authors": "Linmei Hu, Chen Li, Chuan Shi, Cheng Yang, Chao Shao", "title": "Graph Neural News Recommendation with Long-term and Short-term Interest\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the information explosion of news articles, personalized news\nrecommendation has become important for users to quickly find news that they\nare interested in. Existing methods on news recommendation mainly include\ncollaborative filtering methods which rely on direct user-item interactions and\ncontent based methods which characterize the content of user reading history.\nAlthough these methods have achieved good performances, they still suffer from\ndata sparse problem, since most of them fail to extensively exploit high-order\nstructure information (similar users tend to read similar news articles) in\nnews recommendation systems. In this paper, we propose to build a heterogeneous\ngraph to explicitly model the interactions among users, news and latent topics.\nThe incorporated topic information would help indicate a user's interest and\nalleviate the sparsity of user-item interactions. Then we take advantage of\ngraph neural networks to learn user and news representations that encode\nhigh-order structure information by propagating embeddings over the graph. The\nlearned user embeddings with complete historic user clicks capture the users'\nlong-term interests. We also consider a user's short-term interest using the\nrecent reading history with an attention based LSTM model. Experimental results\non real-world datasets show that our proposed model significantly outperforms\nstate-of-the-art methods on news recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 08:04:43 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 02:20:03 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Hu", "Linmei", ""], ["Li", "Chen", ""], ["Shi", "Chuan", ""], ["Yang", "Cheng", ""], ["Shao", "Chao", ""]]}, {"id": "1910.14026", "submitter": "Federico Orsini", "authors": "Federico Orsini, Massimiliano Gastaldi, Luca Mantecchini, Riccardo\n  Rossi", "title": "Neural networks trained with WiFi traces to predict airport passenger\n  behavior", "comments": "Post-print of paper presented at the 2019 6th International\n  Conference on Models and Technologies for Intelligent Transportation Systems\n  (MT-ITS)", "journal-ref": "2019 6th International Conference on Models and Technologies for\n  Intelligent Transportation Systems (MT-ITS)", "doi": "10.1109/MTITS.2019.8883365", "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of neural networks to predict airport passenger activity choices\ninside the terminal is presented in this paper. Three network architectures are\nproposed: Feedforward Neural Networks (FNN), Long Short-Term Memory (LSTM)\nnetworks, and a combination of the two. Inputs to these models are both static\n(passenger and trip characteristics) and dynamic (real-time passenger\ntracking). A real-world case study exemplifies the application of these models,\nusing anonymous WiFi traces collected at Bologna Airport to train the networks.\nThe performance of the models were evaluated according to the misclassification\nrate of passenger activity choices. In the LSTM approach, two different\nmulti-step forecasting strategies are tested. According to our findings, the\ndirect LSTM approach provides better results than the FNN, especially when the\nprediction horizon is relatively short (20 minutes or less).\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 08:11:38 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Orsini", "Federico", ""], ["Gastaldi", "Massimiliano", ""], ["Mantecchini", "Luca", ""], ["Rossi", "Riccardo", ""]]}, {"id": "1910.14029", "submitter": "Stefan Engblom", "authors": "Jing Liu and Stefan Engblom and Carl Nettelblad", "title": "Flash X-ray diffraction imaging in 3D: a proposed analysis pipeline", "comments": null, "journal-ref": null, "doi": "10.1364/JOSAA.390384", "report-no": null, "categories": "eess.IV cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Flash X-ray diffraction Imaging (FXI) acquires diffraction signals\nfrom single biomolecules at a high repetition rate from X-ray Free Electron\nLasers (XFELs), easily obtaining millions of 2D diffraction patterns from a\nsingle experiment. Due to the stochastic nature of FXI experiments and the\nmassive volumes of data, retrieving 3D electron densities from raw 2D\ndiffraction patterns is a challenging and time-consuming task.\n  We propose a semi-automatic data analysis pipeline for FXI experiments, which\nincludes four steps: hit finding and preliminary filtering, pattern\nclassification, 3D Fourier reconstruction, and post analysis. We also include a\nrecently developed bootstrap methodology in the post-analysis step for\nuncertainty analysis and quality control. To achieve the best possible\nresolution, we further suggest using background subtraction, signal windowing,\nand convex optimization techniques when retrieving the Fourier phases in the\npost-analysis step.\n  As an application example, we quantified the 3D electron structure of the\nPR772 virus using the proposed data-analysis pipeline. The retrieved structure\nwas above the detector-edge resolution and clearly showed the\npseudo-icosahedral capsid of the PR772.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 13:29:54 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:04:33 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Liu", "Jing", ""], ["Engblom", "Stefan", ""], ["Nettelblad", "Carl", ""]]}, {"id": "1910.14033", "submitter": "Coline Devin", "authors": "Coline Devin, Daniel Geng, Pieter Abbeel, Trevor Darrell, Sergey\n  Levine", "title": "Plan Arithmetic: Compositional Plan Vectors for Multi-Task Control", "comments": "In NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents situated in real-world environments must be able to master\nlarge repertoires of skills. While a single short skill can be learned quickly,\nit would be impractical to learn every task independently. Instead, the agent\nshould share knowledge across behaviors such that each task can be learned\nefficiently, and such that the resulting model can generalize to new tasks,\nespecially ones that are compositions or subsets of tasks seen previously. A\npolicy conditioned on a goal or demonstration has the potential to share\nknowledge between tasks if it sees enough diversity of inputs. However, these\nmethods may not generalize to a more complex task at test time. We introduce\ncompositional plan vectors (CPVs) to enable a policy to perform compositions of\ntasks without additional supervision. CPVs represent trajectories as the sum of\nthe subtasks within them. We show that CPVs can be learned within a one-shot\nimitation learning framework without any additional supervision or information\nabout task hierarchy, and enable a demonstration-conditioned policy to\ngeneralize to tasks that sequence twice as many skills as the tasks seen during\ntraining.\n  Analogously to embeddings such as word2vec in NLP, CPVs can also support\nsimple arithmetic operations -- for example, we can add the CPVs for two\ndifferent tasks to command an agent to compose both tasks, without any\nadditional training.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 17:50:42 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 01:00:16 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Devin", "Coline", ""], ["Geng", "Daniel", ""], ["Abbeel", "Pieter", ""], ["Darrell", "Trevor", ""], ["Levine", "Sergey", ""]]}, {"id": "1910.14055", "submitter": "Hao Sun", "authors": "Hao Sun, Zhizhong Li, Xiaotong Liu, Dahua Lin, Bolei Zhou", "title": "Policy Continuation with Hindsight Inverse Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Solving goal-oriented tasks is an important but challenging problem in\nreinforcement learning (RL). For such tasks, the rewards are often sparse,\nmaking it difficult to learn a policy effectively. To tackle this difficulty,\nwe propose a new approach called Policy Continuation with Hindsight Inverse\nDynamics (PCHID). This approach learns from Hindsight Inverse Dynamics based on\nHindsight Experience Replay, enabling the learning process in a self-imitated\nmanner and thus can be trained with supervised learning. This work also extends\nit to multi-step settings with Policy Continuation. The proposed method is\ngeneral, which can work in isolation or be combined with other on-policy and\noff-policy algorithms. On two multi-goal tasks GridWorld and FetchReach, PCHID\nsignificantly improves the sample efficiency as well as the final performance.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 18:00:21 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 04:18:43 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sun", "Hao", ""], ["Li", "Zhizhong", ""], ["Liu", "Xiaotong", ""], ["Lin", "Dahua", ""], ["Zhou", "Bolei", ""]]}, {"id": "1910.14056", "submitter": "Hao Sun", "authors": "Hao Sun, Jiadong Guo, Edward J. Kim, Robert J. Brunner", "title": "Unsupervised Star Galaxy Classification with Cascade Variational\n  Auto-Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing amount of data in astronomy provides great challenges for\nmachine learning research. Previously, supervised learning methods achieved\nsatisfactory recognition accuracy for the star-galaxy classification task,\nbased on manually labeled data set. In this work, we propose a novel\nunsupervised approach for the star-galaxy recognition task, namely Cascade\nVariational Auto-Encoder (CasVAE). Our empirical results show our method\noutperforms the baseline model in both accuracy and stability.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 18:00:23 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Sun", "Hao", ""], ["Guo", "Jiadong", ""], ["Kim", "Edward J.", ""], ["Brunner", "Robert J.", ""]]}, {"id": "1910.14072", "submitter": "Miguel Ib\\'a\\~nez Berganza", "authors": "Miguel Ib\\'a\\~nez-Berganza, Ambra Amico, Gian Luca Lancia, Federico\n  Maggiore, Bernardo Monechi, Vittorio Loreto", "title": "Unsupervised inference approach to facial attractiveness", "comments": "main article (10 pages, 4 figures) + supplementary information (22\n  pages, 10 figures). minor typos corrected. Federico Maggiore added as author", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The perception of facial beauty is a complex phenomenon depending on many,\ndetailed and global facial features influencing each other. In the machine\nlearning community this problem is typically tackled as a problem of supervised\ninference. However, it has been conjectured that this approach does not capture\nthe complexity of the phenomenon. A recent original experiment\n(Ib\\'a\\~nez-Berganza et al., Scientific Reports 9, 8364, 2019) allowed\ndifferent human subjects to navigate the face-space and ``sculpt'' their\npreferred modification of a reference facial portrait. Here we present an\nunsupervised inference study of the set of sculpted facial vectors in that\nexperiment. We first infer minimal, interpretable, and faithful probabilistic\nmodels (through Maximum Entropy and artificial neural networks) of the\npreferred facial variations, that capture the origin of the observed\ninter-subject diversity in the sculpted faces. The application of such\ngenerative models to the supervised classification of the gender of the\nsculpting subjects, reveals an astonishingly high prediction accuracy. This\nresult suggests that much relevant information regarding the subjects may\ninfluence (and be elicited from) her/his facial preference criteria, in\nagreement with the multiple motive theory of attractiveness proposed in\nprevious works.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 18:23:56 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 18:43:45 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 13:58:18 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ib\u00e1\u00f1ez-Berganza", "Miguel", ""], ["Amico", "Ambra", ""], ["Lancia", "Gian Luca", ""], ["Maggiore", "Federico", ""], ["Monechi", "Bernardo", ""], ["Loreto", "Vittorio", ""]]}, {"id": "1910.14080", "submitter": "Yifu Sun", "authors": "Yifu Sun, Haoming Jiang", "title": "Contextual Text Denoising with Masked Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with the help of deep learning models, significant advances have\nbeen made in different Natural Language Processing (NLP) tasks. Unfortunately,\nstate-of-the-art models are vulnerable to noisy texts. We propose a new\ncontextual text denoising algorithm based on the ready-to-use masked language\nmodel. The proposed algorithm does not require retraining of the model and can\nbe integrated into any NLP system without additional training on paired\ncleaning training data. We evaluate our method under synthetic noise and\nnatural noise and show that the proposed algorithm can use context information\nto correct noise text and improve the performance of noisy inputs in several\ndownstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 18:47:37 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Sun", "Yifu", ""], ["Jiang", "Haoming", ""]]}, {"id": "1910.14095", "submitter": "Justin Lovelace", "authors": "Justin R. Lovelace, Nathan C. Hurley, Adrian D. Haimovich, and Bobak\n  J. Mortazavi", "title": "Explainable Prediction of Adverse Outcomes Using Clinical Notes", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Clinical notes contain a large amount of clinically valuable information that\nis ignored in many clinical decision support systems due to the difficulty that\ncomes with mining that information. Recent work has found success leveraging\ndeep learning models for the prediction of clinical outcomes using clinical\nnotes. However, these models fail to provide clinically relevant and\ninterpretable information that clinicians can utilize for informed clinical\ncare. In this work, we augment a popular convolutional model with an attention\nmechanism and apply it to unstructured clinical notes for the prediction of ICU\nreadmission and mortality. We find that the addition of the attention mechanism\nleads to competitive performance while allowing for the straightforward\ninterpretation of predictions. We develop clear visualizations to present\nimportant spans of text for both individual predictions and high-risk cohorts.\nWe then conduct a qualitative analysis and demonstrate that our model is\nconsistently attending to clinically meaningful portions of the narrative for\nall of the outcomes that we explore.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 19:30:14 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 16:14:39 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Lovelace", "Justin R.", ""], ["Hurley", "Nathan C.", ""], ["Haimovich", "Adrian D.", ""], ["Mortazavi", "Bobak J.", ""]]}, {"id": "1910.14096", "submitter": "Usama Muneeb", "authors": "Usama Muneeb, Erdem Koyuncu, Yasaman Keshtkarjahromi, Hulya Seferoglu,\n  Mehmet Fatih Erden, Ahmet Enis Cetin", "title": "Robust and Computationally-Efficient Anomaly Detection using\n  Powers-of-Two Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust and computationally efficient anomaly detection in videos is a problem\nin video surveillance systems. We propose a technique to increase robustness\nand reduce computational complexity in a Convolutional Neural Network (CNN)\nbased anomaly detector that utilizes the optical flow information of video\ndata. We reduce the complexity of the network by denoising the intermediate\nlayer outputs of the CNN and by using powers-of-two weights, which replaces the\ncomputationally expensive multiplication operations with bit-shift operations.\nDenoising operation during inference forces small valued intermediate layer\noutputs to zero. The number of zeros in the network significantly increases as\na result of denoising, we can implement the CNN about 10% faster than a\ncomparable network while detecting all the anomalies in the testing set. It\nturns out that denoising operation also provides robustness because the\ncontribution of small intermediate values to the final result is negligible.\nDuring training we also generate motion vector images by a Generative\nAdversarial Network (GAN) to improve the robustness of the overall system. We\nexperimentally observe that the resulting system is robust to background\nmotion.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 19:30:24 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Muneeb", "Usama", ""], ["Koyuncu", "Erdem", ""], ["Keshtkarjahromi", "Yasaman", ""], ["Seferoglu", "Hulya", ""], ["Erden", "Mehmet Fatih", ""], ["Cetin", "Ahmet Enis", ""]]}, {"id": "1910.14098", "submitter": "Sahar Hojjatinia", "authors": "Sahar Hojjatinia, Constantino M. Lagoa", "title": "Comparison of Different Spike Sorting Subtechniques Based on Rat Brain\n  Basolateral Amygdala Neuronal Activity", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing electrophysiological recordings of brain neuronal activity and\ntheir analysis provide a basis for exploring the structure of brain function\nand nervous system investigation. The recorded signals are typically a\ncombination of spikes and noise. High amounts of background noise and\npossibility of electric signaling recording from several neurons adjacent to\nthe recording site have led scientists to develop neuronal signal processing\ntools such as spike sorting to facilitate brain data analysis. Spike sorting\nplays a pivotal role in understanding the electrophysiological activity of\nneuronal networks. This process prepares recorded data for interpretations of\nneurons interactions and understanding the overall structure of brain\nfunctions. Spike sorting consists of three steps: spike detection, feature\nextraction, and spike clustering. There are several methods to implement each\nof spike sorting steps. This paper provides a systematic comparison of various\nspike sorting sub-techniques applied to real extracellularly recorded data from\na rat brain basolateral amygdala. An efficient sorted data resulted from\ncareful choice of spike sorting sub-methods leads to better interpretation of\nthe brain structures connectivity under different conditions, which is a very\nsensitive concept in diagnosis and treatment of neurological disorders. Here,\nspike detection is performed by appropriate choice of threshold level via three\ndifferent approaches. Feature extraction is done through PCA and Kernel PCA\nmethods, which Kernel PCA outperforms. We have applied four different\nalgorithms for spike clustering including K-means, Fuzzy C-means, Bayesian and\nFuzzy maximum likelihood estimation. As one requirement of most clustering\nalgorithms, optimal number of clusters is achieved through validity indices for\neach method. Finally, the sorting results are evaluated using inter-spike\ninterval histograms.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 00:44:24 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Hojjatinia", "Sahar", ""], ["Lagoa", "Constantino M.", ""]]}, {"id": "1910.14104", "submitter": "Yi Luo", "authors": "Yi Luo, Zhuo Chen, Nima Mesgarani, Takuya Yoshioka", "title": "End-to-end Microphone Permutation and Number Invariant Multi-channel\n  Speech Separation", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An important problem in ad-hoc microphone speech separation is how to\nguarantee the robustness of a system with respect to the locations and numbers\nof microphones. The former requires the system to be invariant to different\nindexing of the microphones with the same locations, while the latter requires\nthe system to be able to process inputs with varying dimensions. Conventional\noptimization-based beamforming techniques satisfy these requirements by\ndefinition, while for deep learning-based end-to-end systems those constraints\nare not fully addressed. In this paper, we propose\ntransform-average-concatenate (TAC), a simple design paradigm for channel\npermutation and number invariant multi-channel speech separation. Based on the\nfilter-and-sum network (FaSNet), a recently proposed end-to-end time-domain\nbeamforming system, we show how TAC significantly improves the separation\nperformance across various numbers of microphones in noisy reverberant\nseparation tasks with ad-hoc arrays. Moreover, we show that TAC also\nsignificantly improves the separation performance with fixed geometry array\nconfiguration, further proving the effectiveness of the proposed paradigm in\nthe general problem of multi-microphone speech separation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 19:45:34 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 20:48:49 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 10:12:19 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Luo", "Yi", ""], ["Chen", "Zhuo", ""], ["Mesgarani", "Nima", ""], ["Yoshioka", "Takuya", ""]]}, {"id": "1910.14106", "submitter": "Soumyabrata Pal", "authors": "Akshay Krishnamurthy, Arya Mazumdar, Andrew McGregor, Soumyabrata Pal", "title": "Sample Complexity of Learning Mixtures of Sparse Linear Regressions", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of learning mixtures of linear regressions, the goal is to\nlearn a collection of signal vectors from a sequence of (possibly noisy) linear\nmeasurements, where each measurement is evaluated on an unknown signal drawn\nuniformly from this collection. This setting is quite expressive and has been\nstudied both in terms of practical applications and for the sake of\nestablishing theoretical guarantees. In this paper, we consider the case where\nthe signal vectors are sparse; this generalizes the popular compressed sensing\nparadigm. We improve upon the state-of-the-art results as follows: In the noisy\ncase, we resolve an open question of Yin et al. (IEEE Transactions on\nInformation Theory, 2019) by showing how to handle collections of more than two\nvectors and present the first robust reconstruction algorithm, i.e., if the\nsignals are not perfectly sparse, we still learn a good sparse approximation of\nthe signals. In the noiseless case, as well as in the noisy case, we show how\nto circumvent the need for a restrictive assumption required in the previous\nwork. Our techniques are quite different from those in the previous work: for\nthe noiseless case, we rely on a property of sparse polynomials and for the\nnoisy case, we provide new connections to learning Gaussian mixtures and use\nideas from the theory of error-correcting codes.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 19:53:49 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Krishnamurthy", "Akshay", ""], ["Mazumdar", "Arya", ""], ["McGregor", "Andrew", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "1910.14107", "submitter": "Rana Abou Khamis", "authors": "Rana Abou Khamis, Omair Shafiq, Ashraf Matrawy", "title": "Investigating Resistance of Deep Learning-based IDS against Adversaries\n  using min-max Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of adversarial attacks against machine learning models,\nseveral concerns have emerged about potential vulnerabilities in designing deep\nneural network-based intrusion detection systems (IDS). In this paper, we study\nthe resilience of deep learning-based intrusion detection systems against\nadversarial attacks. We apply the min-max (or saddle-point) approach to train\nintrusion detection systems against adversarial attack samples in NSW-NB 15\ndataset. We have the max approach for generating adversarial samples that\nachieves maximum loss and attack deep neural networks. On the other side, we\nutilize the existing min approach [2] [9] as a defense strategy to optimize\nintrusion detection systems that minimize the loss of the incorporated\nadversarial samples during the adversarial training. We study and measure the\neffectiveness of the adversarial attack methods as well as the resistance of\nthe adversarially trained models against such attacks. We find that the\nadversarial attack methods that were designed in binary domains can be used in\ncontinuous domains and exhibit different misclassification levels. We finally\nshow that principal component analysis (PCA) based feature reduction can boost\nthe robustness in intrusion detection system (IDS) using a deep neural network\n(DNN).\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 19:55:26 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Khamis", "Rana Abou", ""], ["Shafiq", "Omair", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "1910.14120", "submitter": "Ananth Balashankar", "authors": "Ananth Balashankar, Alyssa Lees, Chris Welty, Lakshminarayanan\n  Subramanian", "title": "What is Fair? Exploring Pareto-Efficiency for Fairness Constrained\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential for learned models to amplify existing societal biases has been\nbroadly recognized. Fairness-aware classifier constraints, which apply equality\nmetrics of performance across subgroups defined on sensitive attributes such as\nrace and gender, seek to rectify inequity but can yield non-uniform degradation\nin performance for skewed datasets. In certain domains, imbalanced degradation\nof performance can yield another form of unintentional bias. In the spirit of\nconstructing fairness-aware algorithms as societal imperative, we explore an\nalternative: Pareto-Efficient Fairness (PEF). Theoretically, we prove that PEF\nidentifies the operating point on the Pareto curve of subgroup performances\nclosest to the fairness hyperplane, maximizing multiple subgroup accuracy.\nEmpirically we demonstrate that PEF outperforms by achieving Pareto levels in\naccuracy for all subgroups compared to strict fairness constraints in several\nUCI datasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 20:32:01 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Balashankar", "Ananth", ""], ["Lees", "Alyssa", ""], ["Welty", "Chris", ""], ["Subramanian", "Lakshminarayanan", ""]]}, {"id": "1910.14124", "submitter": "Sam Witty", "authors": "Sam Witty, Alexander Lew, David Jensen, Vikash Mansinghka", "title": "Bayesian causal inference via probabilistic program synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal inference can be formalized as Bayesian inference that combines a\nprior distribution over causal models and likelihoods that account for both\nobservations and interventions. We show that it is possible to implement this\napproach using a sufficiently expressive probabilistic programming language.\nPriors are represented using probabilistic programs that generate source code\nin a domain specific language. Interventions are represented using\nprobabilistic programs that edit this source code to modify the original\ngenerative process. This approach makes it straightforward to incorporate data\nfrom atomic interventions, as well as shift interventions, variance-scaling\ninterventions, and other interventions that modify causal structure. This\napproach also enables the use of general-purpose inference machinery for\nprobabilistic programs to infer probable causal structures and parameters from\ndata. This abstract describes a prototype of this approach in the Gen\nprobabilistic programming language.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 20:46:43 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Witty", "Sam", ""], ["Lew", "Alexander", ""], ["Jensen", "David", ""], ["Mansinghka", "Vikash", ""]]}, {"id": "1910.14134", "submitter": "Yibo Jiang", "authors": "Yibo Jiang, Nakul Verma", "title": "Meta-Learning to Cluster", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is one of the most fundamental and wide-spread techniques in\nexploratory data analysis. Yet, the basic approach to clustering has not really\nchanged: a practitioner hand-picks a task-specific clustering loss to optimize\nand fit the given data to reveal the underlying cluster structure. Some types\nof losses---such as k-means, or its non-linear version: kernelized k-means\n(centroid based), and DBSCAN (density based)---are popular choices due to their\ngood empirical performance on a range of applications. Although every so often\nthe clustering output using these standard losses fails to reveal the\nunderlying structure, and the practitioner has to custom-design their own\nvariation. In this work we take an intrinsically different approach to\nclustering: rather than fitting a dataset to a specific clustering loss, we\ntrain a recurrent model that learns how to cluster. The model uses as training\npairs examples of datasets (as input) and its corresponding cluster identities\n(as output). By providing multiple types of training datasets as inputs, our\nmodel has the ability to generalize well on unseen datasets (new clustering\ntasks). Our experiments reveal that by training on simple synthetically\ngenerated datasets or on existing real datasets, we can achieve better\nclustering performance on unseen real-world datasets when compared with\nstandard benchmark clustering techniques. Our meta clustering model works well\neven for small datasets where the usual deep learning models tend to perform\nworse.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 21:06:15 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Jiang", "Yibo", ""], ["Verma", "Nakul", ""]]}, {"id": "1910.14137", "submitter": "Ben Adlam", "authors": "Ben Adlam, Charles Weill, and Amol Kapoor", "title": "Investigating Under and Overfitting in Wasserstein Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate under and overfitting in Generative Adversarial Networks\n(GANs), using discriminators unseen by the generator to measure generalization.\nWe find that the model capacity of the discriminator has a significant effect\non the generator's model quality, and that the generator's poor performance\ncoincides with the discriminator underfitting. Contrary to our expectations, we\nfind that generators with large model capacities relative to the discriminator\ndo not show evidence of overfitting on CIFAR10, CIFAR100, and CelebA.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 21:10:36 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Adlam", "Ben", ""], ["Weill", "Charles", ""], ["Kapoor", "Amol", ""]]}, {"id": "1910.14147", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Si Si, Xiaojin Zhu, Yang Li, Cho-Jui Hsieh", "title": "A Unified Framework for Data Poisoning Attack to Graph-based\n  Semi-supervised Learning", "comments": "NeurIPS 2019 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a general framework for data poisoning attacks to\ngraph-based semi-supervised learning (G-SSL). In this framework, we first unify\ndifferent tasks, goals, and constraints into a single formula for data\npoisoning attack in G-SSL, then we propose two specialized algorithms to\nefficiently solve two important cases --- poisoning regression tasks under\n$\\ell_2$-norm constraint and classification tasks under $\\ell_0$-norm\nconstraint. In the former case, we transform it into a non-convex trust region\nproblem and show that our gradient-based algorithm with delicate initialization\nand update scheme finds the (globally) optimal perturbation. For the latter\ncase, although it is an NP-hard integer programming problem, we propose a\nprobabilistic solver that works much better than the classical greedy method.\nLastly, we test our framework on real datasets and evaluate the robustness of\nG-SSL algorithms. For instance, on the MNIST binary classification problem\n(50000 training data with 50 labeled), flipping two labeled data is enough to\nmake the model perform like random guess (around 50\\% error).\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 21:30:12 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Liu", "Xuanqing", ""], ["Si", "Si", ""], ["Zhu", "Xiaojin", ""], ["Li", "Yang", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1910.14162", "submitter": "Beidi Chen", "authors": "Beidi Chen, Yingchen Xu, Anshumali Shrivastava", "title": "Lsh-sampling Breaks the Computation Chicken-and-egg Loop in Adaptive\n  Stochastic Gradient Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent or SGD is the most popular optimization algorithm\nfor large-scale problems. SGD estimates the gradient by uniform sampling with\nsample size one. There have been several other works that suggest faster\nepoch-wise convergence by using weighted non-uniform sampling for better\ngradient estimates. Unfortunately, the per-iteration cost of maintaining this\nadaptive distribution for gradient estimation is more than calculating the full\ngradient itself, which we call the chicken-and-the-egg loop. As a result, the\nfalse impression of faster convergence in iterations, in reality, leads to\nslower convergence in time. In this paper, we break this barrier by providing\nthe first demonstration of a scheme, Locality sensitive hashing (LSH) sampled\nStochastic Gradient Descent (LGD), which leads to superior gradient estimation\nwhile keeping the sampling cost per iteration similar to that of the uniform\nsampling. Such an algorithm is possible due to the sampling view of LSH, which\ncame to light recently. As a consequence of superior and fast estimation, we\nreduce the running time of all existing gradient descent algorithms, that\nrelies on gradient estimates including Adam, Ada-grad, etc. We demonstrate the\neffectiveness of our proposal with experiments on linear models as well as the\nnon-linear BERT, which is a recent popular deep learning based language\nrepresentation model.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 22:28:54 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Chen", "Beidi", ""], ["Xu", "Yingchen", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1910.14166", "submitter": "Charlie Dickens", "authors": "Graham Cormode, Charlie Dickens", "title": "Iterative Hessian Sketch in Input Sparsity Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable algorithms to solve optimization and regression tasks even\napproximately, are needed to work with large datasets. In this paper we study\nefficient techniques from matrix sketching to solve a variety of convex\nconstrained regression problems. We adopt \"Iterative Hessian Sketching\" (IHS)\nand show that the fast CountSketch and sparse Johnson-Lindenstrauss Transforms\nyield state-of-the-art accuracy guarantees under IHS, while drastically\nimproving the time cost. As a result, we obtain significantly faster algorithms\nfor constrained regression, for both sparse and dense inputs. Our empirical\nresults show that we can summarize data roughly 100x faster for sparse data,\nand, surprisingly, 10x faster on dense data! Consequently, solutions accurate\nto within machine precision of the optimal solution can be found much faster\nthan the previous state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 22:40:07 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Cormode", "Graham", ""], ["Dickens", "Charlie", ""]]}, {"id": "1910.14175", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Bindya Venkatesh and Deepta Rajan", "title": "Learn-By-Calibrating: Using Calibration as a Training Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibration error is commonly adopted for evaluating the quality of\nuncertainty estimators in deep neural networks. In this paper, we argue that\nsuch a metric is highly beneficial for training predictive models, even when we\ndo not explicitly measure the uncertainties. This is conceptually similar to\nheteroscedastic neural networks that produce variance estimates for each\nprediction, with the key difference that we do not place a Gaussian prior on\nthe predictions. We propose a novel algorithm that performs simultaneous\ninterval estimation for different calibration levels and effectively leverages\nthe intervals to refine the mean estimates. Our results show that, our approach\nis consistently superior to existing regularization strategies in deep\nregression models. Finally, we propose to augment partial dependence plots, a\nmodel-agnostic interpretability tool, with expected prediction intervals to\nreveal interesting dependencies between data and the target.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 23:13:40 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Venkatesh", "Bindya", ""], ["Rajan", "Deepta", ""]]}, {"id": "1910.14179", "submitter": "Jayaraman J. Thiagarajan", "authors": "Bindya Venkatesh and Jayaraman J. Thiagarajan", "title": "Heteroscedastic Calibration of Uncertainty Estimators in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of uncertainty quantification (UQ) in deep learning has become\ncrucial with growing use of predictive models in high-risk applications. Though\na large class of methods exists for measuring deep uncertainties, in practice,\nthe resulting estimates are found to be poorly calibrated, thus making it\nchallenging to translate them into actionable insights. A common workaround is\nto utilize a separate recalibration step, which adjusts the estimates to\ncompensate for the miscalibration. Instead, we propose to repurpose the\nheteroscedastic regression objective as a surrogate for calibration and enable\nany existing uncertainty estimator to be inherently calibrated. In addition to\neliminating the need for recalibration, this also regularizes the training\nprocess. Using regression experiments, we demonstrate the effectiveness of the\nproposed heteroscedastic calibration with two popular uncertainty estimators.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 23:22:39 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Venkatesh", "Bindya", ""], ["Thiagarajan", "Jayaraman J.", ""]]}, {"id": "1910.14186", "submitter": "Ambar Pal", "authors": "Ambar Pal, Connor Lane, Ren\\'e Vidal, Benjamin D. Haeffele", "title": "On the Regularization Properties of Structured Dropout", "comments": "Accepted at Computer Vision and Pattern Recognition (CVPR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout and its extensions (eg. DropBlock and DropConnect) are popular\nheuristics for training neural networks, which have been shown to improve\ngeneralization performance in practice. However, a theoretical understanding of\ntheir optimization and regularization properties remains elusive. Recent work\nshows that in the case of single hidden-layer linear networks, Dropout is a\nstochastic gradient descent method for minimizing a regularized loss, and that\nthe regularizer induces solutions that are low-rank and balanced. In this work\nwe show that for single hidden-layer linear networks, DropBlock induces\nspectral k-support norm regularization, and promotes solutions that are\nlow-rank and have factors with equal norm. We also show that the global\nminimizer for DropBlock can be computed in closed form, and that DropConnect is\nequivalent to Dropout. We then show that some of these results can be extended\nto a general class of Dropout-strategies, and, with some assumptions, to deep\nnon-linear networks when Dropout is applied to the last layer. We verify our\ntheoretical claims and assumptions experimentally with commonly used network\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 23:58:34 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 11:25:47 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Pal", "Ambar", ""], ["Lane", "Connor", ""], ["Vidal", "Ren\u00e9", ""], ["Haeffele", "Benjamin D.", ""]]}, {"id": "1910.14194", "submitter": "Alisha Sharma", "authors": "Kamal Viswanath, Alisha Sharma, Saketh Gabbita, Jason Geder, Ravi\n  Ramamurti, and Marius Pruessner", "title": "Evaluation of Surrogate Models for Multi-fin Flapping Propulsion Systems", "comments": "Presented at IEEE/MTS OCEANS 2019 (Seattle)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG cs.RO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The aim of this study is to develop surrogate models for quick, accurate\nprediction of thrust forces generated through flapping fin propulsion for given\noperating conditions and fin geometries. Different network architectures and\nconfigurations are explored to model the training data separately for the lead\nfin and rear fin of a tandem fin setup. We progressively improve the data\nrepresentation of the input parameter space for model predictions. The models\nare tested on three unseen fin geometries and the predictions validated with\ncomputational fluid dynamics (CFD) data. Finally, the orders of magnitude gains\nin computational performance of these surrogate models, compared to\nexperimental and CFD runs, vs their tradeoff with accuracy is discussed within\nthe context of this tandem fin configuration.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 00:34:41 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Viswanath", "Kamal", ""], ["Sharma", "Alisha", ""], ["Gabbita", "Saketh", ""], ["Geder", "Jason", ""], ["Ramamurti", "Ravi", ""], ["Pruessner", "Marius", ""]]}, {"id": "1910.14207", "submitter": "Anastasiia Razdaibiedina", "authors": "Anastasia Razdaibiedina, Jeevaa Velayutham, Miti Modi", "title": "Multi-defect microscopy image restoration under limited data conditions", "comments": "NeurIPS 2019 Medical Imaging workhop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are becoming widely used for restoration of defects\nassociated with fluorescence microscopy imaging. One of the major challenges in\napplication of such methods is the availability of training data. In this work,\nwe propose a unified method for reconstruction of multi-defect fluorescence\nmicroscopy images when training data is limited. Our approach consists of two\nstages: first, we perform data augmentation using Generative Adversarial\nNetwork (GAN) with conditional instance normalization (CIN); second, we train a\nconditional GAN (cGAN) on paired ground-truth and defected images to perform\nrestoration. The experiments on three common types of imaging defects with\ndifferent amounts of training data show that the proposed method gives\ncomparable results or outperforms CARE, deblurGAN and CycleGAN in restored\nimage quality when available data is limited.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 01:55:01 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 20:14:19 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Razdaibiedina", "Anastasia", ""], ["Velayutham", "Jeevaa", ""], ["Modi", "Miti", ""]]}, {"id": "1910.14209", "submitter": "Liyao Lyu", "authors": "Liyao Lyu, Zhiwen Zhang, Jingrun Chen", "title": "A QMC-deep learning method for diffusivity estimation in random domains", "comments": null, "journal-ref": null, "doi": "10.4208/nmtma.OA-2020-0032", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exciton diffusion plays a vital role in the function of many organic\nsemiconducting opto-electronic devices, where an accurate description requires\nprecise control of heterojunctions. This poses a challenging problem because\nthe parameterization of heterojunctions in high-dimensional random space is far\nbeyond the capability of classical simulation tools. Here, we develop a novel\nmethod based on quasi-Monte Carlo sampling to generate the training data set\nand deep neural network to extract a function for exciton diffusion length on\nsurface roughness with high accuracy and unprecedented efficiency, yielding an\nabundance of information over the entire parameter space. Our method provides a\nnew strategy to analyze the impact of interfacial ordering on exciton diffusion\nand is expected to assist experimental design with tailored opto-electronic\nfunctionalities.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 02:00:25 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 16:51:06 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Lyu", "Liyao", ""], ["Zhang", "Zhiwen", ""], ["Chen", "Jingrun", ""]]}, {"id": "1910.14210", "submitter": "Samuel Deng", "authors": "Samuel Deng and Achille Varzi", "title": "Methodological Blind Spots in Machine Learning Fairness: Lessons from\n  the Philosophy of Science and Computer Science", "comments": "Accepted for submission in: Workshop on Human-Centric Machine\n  Learning at the 33rd Conference on Neural Information ProcessingSystems\n  (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the ML fairness literature, there have been few investigations through the\nviewpoint of philosophy, a lens that encourages the critical evaluation of\nbasic assumptions. The purpose of this paper is to use three ideas from the\nphilosophy of science and computer science to tease out blind spots in the\nassumptions that underlie ML fairness: abstraction, induction, and measurement.\nThrough this investigation, we hope to warn of these methodological blind spots\nand encourage further interdisciplinary investigation in fair-ML through the\nframework of philosophy.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 02:02:31 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Deng", "Samuel", ""], ["Varzi", "Achille", ""]]}, {"id": "1910.14212", "submitter": "Youssef Mroueh", "authors": "Youssef Mroueh, Tom Sercu, Mattia Rigotti, Inkit Padhi, Cicero Dos\n  Santos", "title": "Sobolev Independence Criterion", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Sobolev Independence Criterion (SIC), an interpretable\ndependency measure between a high dimensional random variable X and a response\nvariable Y . SIC decomposes to the sum of feature importance scores and hence\ncan be used for nonlinear feature selection. SIC can be seen as a gradient\nregularized Integral Probability Metric (IPM) between the joint distribution of\nthe two random variables and the product of their marginals. We use sparsity\ninducing gradient penalties to promote input sparsity of the critic of the IPM.\nIn the kernel version we show that SIC can be cast as a convex optimization\nproblem by introducing auxiliary variables that play an important role in\nfeature selection as they are normalized feature importance scores. We then\npresent a neural version of SIC where the critic is parameterized as a\nhomogeneous neural network, improving its representation power as well as its\ninterpretability. We conduct experiments validating SIC for feature selection\nin synthetic and real-world experiments. We show that SIC enables reliable and\ninterpretable discoveries, when used in conjunction with the holdout\nrandomization test and knockoffs to control the False Discovery Rate. Code is\navailable at http://github.com/ibm/sic.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 02:17:28 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Mroueh", "Youssef", ""], ["Sercu", "Tom", ""], ["Rigotti", "Mattia", ""], ["Padhi", "Inkit", ""], ["Santos", "Cicero Dos", ""]]}, {"id": "1910.14215", "submitter": "Rebecca Russell", "authors": "Rebecca L. Russell and Christopher Reale", "title": "Multivariate Uncertainty in Deep Learning", "comments": "To be published in IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has the potential to dramatically impact navigation and\ntracking state estimation problems critical to autonomous vehicles and\nrobotics. Measurement uncertainties in state estimation systems based on Kalman\nand other Bayes filters are typically assumed to be a fixed covariance matrix.\nThis assumption is risky, particularly for \"black box\" deep learning models, in\nwhich uncertainty can vary dramatically and unexpectedly. Accurate\nquantification of multivariate uncertainty will allow for the full potential of\ndeep learning to be used more safely and reliably in these applications. We\nshow how to model multivariate uncertainty for regression problems with neural\nnetworks, incorporating both aleatoric and epistemic sources of heteroscedastic\nuncertainty. We train a deep uncertainty covariance matrix model in two ways:\ndirectly using a multivariate Gaussian density loss function, and indirectly\nusing end-to-end training through a Kalman filter. We experimentally show in a\nvisual tracking problem the large impact that accurate multivariate uncertainty\nquantification can have on Kalman filter performance for both in-domain and\nout-of-domain evaluation data. We additionally show in a challenging visual\nodometry problem how end-to-end filter training can allow uncertainty\npredictions to compensate for filter weaknesses.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 02:25:16 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 22:54:51 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Russell", "Rebecca L.", ""], ["Reale", "Christopher", ""]]}, {"id": "1910.14238", "submitter": "Jianxin Ma", "authors": "Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, Wenwu Zhu", "title": "Learning Disentangled Representations for Recommendation", "comments": "To appear in the Proceedings of the Thirty-third Conference on Neural\n  Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User behavior data in recommender systems are driven by the complex\ninteractions of many latent factors behind the users' decision making\nprocesses. The factors are highly entangled, and may range from high-level ones\nthat govern user intentions, to low-level ones that characterize a user's\npreference when executing an intention. Learning representations that uncover\nand disentangle these latent factors can bring enhanced robustness,\ninterpretability, and controllability. However, learning such disentangled\nrepresentations from user behavior is challenging, and remains largely\nneglected by the existing literature. In this paper, we present the MACRo-mIcro\nDisentangled Variational Auto-Encoder (MacridVAE) for learning disentangled\nrepresentations from user behavior. Our approach achieves macro disentanglement\nby inferring the high-level concepts associated with user intentions (e.g., to\nbuy a shirt or a cellphone), while capturing the preference of a user regarding\nthe different concepts separately. A micro-disentanglement regularizer,\nstemming from an information-theoretic interpretation of VAEs, then forces each\ndimension of the representations to independently reflect an isolated low-level\nfactor (e.g., the size or the color of a shirt). Empirical results show that\nour approach can achieve substantial improvement over the state-of-the-art\nbaselines. We further demonstrate that the learned representations are\ninterpretable and controllable, which can potentially lead to a new paradigm\nfor recommendation where users are given fine-grained control over targeted\naspects of the recommendation lists.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 03:31:56 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Ma", "Jianxin", ""], ["Zhou", "Chang", ""], ["Cui", "Peng", ""], ["Yang", "Hongxia", ""], ["Zhu", "Wenwu", ""]]}, {"id": "1910.14241", "submitter": "Avinash Kori", "authors": "Avinash Kori, Manik Sharma", "title": "Dynamic Regularizer with an Informative Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Regularization methods, specifically those which directly alter weights like\n$L_1$ and $L_2$, are an integral part of many learning algorithms. Both the\nregularizers mentioned above are formulated by assuming certain priors in the\nparameter space and these assumptions, in some cases, induce sparsity in the\nparameter space. Regularizers help in transferring beliefs one has on the\ndataset or the parameter space by introducing adequate terms in the loss\nfunction. Any kind of formulation represents a specific set of beliefs: $L_1$\nregularization conveys that the parameter space should be sparse whereas $L_2$\nregularization conveys that the parameter space should be bounded and\ncontinuous. These regularizers in turn leverage certain priors to express these\ninherent beliefs. A better understanding of how the prior affects the behavior\nof the parameters and how the priors can be updated based on the dataset can\ncontribute greatly in improving the generalization capabilities of a function\nestimator. In this work, we introduce a weakly informative prior and then\nfurther extend it to an informative prior in order to formulate a\nregularization penalty, which shows better results in terms of inducing\nsparsity experimentally, when compared to regularizers based only on Gaussian\nand Laplacian priors. Experimentally, we verify that a regularizer based on an\nadapted prior improves the generalization capabilities of any network. We\nillustrate the performance of the proposed method on the MNIST and CIFAR-10\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 03:40:03 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Kori", "Avinash", ""], ["Sharma", "Manik", ""]]}, {"id": "1910.14243", "submitter": "Chiyu Zhang", "authors": "Muhammad Abdul-Mageed, Chiyu Zhang, AbdelRahim Elmadany, Arun\n  Rajendran and Lyle Ungar", "title": "DiaNet: BERT and Hierarchical Attention Multi-Task Learning of\n  Fine-Grained Dialect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction of language varieties and dialects is an important language\nprocessing task, with a wide range of applications. For Arabic, the native\ntongue of ~ 300 million people, most varieties remain unsupported. To ease this\nbottleneck, we present a very large scale dataset covering 319 cities from all\n21 Arab countries. We introduce a hierarchical attention multi-task learning\n(HA-MTL) approach for dialect identification exploiting our data at the city,\nstate, and country levels. We also evaluate use of BERT on the three tasks,\ncomparing it to the MTL approach. We benchmark and release our data and models.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 03:56:32 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Abdul-Mageed", "Muhammad", ""], ["Zhang", "Chiyu", ""], ["Elmadany", "AbdelRahim", ""], ["Rajendran", "Arun", ""], ["Ungar", "Lyle", ""]]}, {"id": "1910.14258", "submitter": "Khoi-Nguyen Tran", "authors": "Nebula Alam, Khoi-Nguyen Tran, Sue Ann Chen, John Wagner, Josh Andres,\n  Mukesh Mohania", "title": "Towards a Predictive Patent Analytics and Evaluation Platform", "comments": "ECML-PKDD 2019 - Demo Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of patents is well recognised across many regions of the\nworld. Many patent mining systems have been proposed, but with limited\npredictive capabilities. In this demo, we showcase how predictive algorithms\nleveraging the state-of-the-art machine learning and deep learning techniques\ncan be used to improve understanding of patents for inventors, patent\nevaluators, and business analysts alike. Our demo video is available at\nhttp://ibm.biz/ecml2019-demo-patent-analytics\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 04:54:38 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Alam", "Nebula", ""], ["Tran", "Khoi-Nguyen", ""], ["Chen", "Sue Ann", ""], ["Wagner", "John", ""], ["Andres", "Josh", ""], ["Mohania", "Mukesh", ""]]}, {"id": "1910.14265", "submitter": "George Tucker", "authors": "Dieterich Lawson, George Tucker, Bo Dai, Rajesh Ranganath", "title": "Energy-Inspired Models: Learning with Sampler-Induced Distributions", "comments": "Presented at the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-based models (EBMs) are powerful probabilistic models, but suffer from\nintractable sampling and density evaluation due to the partition function. As a\nresult, inference in EBMs relies on approximate sampling algorithms, leading to\na mismatch between the model and inference. Motivated by this, we consider the\nsampler-induced distribution as the model of interest and maximize the\nlikelihood of this model. This yields a class of energy-inspired models (EIMs)\nthat incorporate learned energy functions while still providing exact samples\nand tractable log-likelihood lower bounds. We describe and evaluate three\ninstantiations of such models based on truncated rejection sampling,\nself-normalized importance sampling, and Hamiltonian importance sampling. These\nmodels outperform or perform comparably to the recently proposed Learned\nAccept/Reject Sampling algorithm and provide new insights on ranking Noise\nContrastive Estimation and Contrastive Predictive Coding. Moreover, EIMs allow\nus to generalize a recent connection between multi-sample variational lower\nbounds and auxiliary variable variational inference. We show how recent\nvariational bounds can be unified with EIMs as the variational family.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 05:31:18 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 18:10:38 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Lawson", "Dieterich", ""], ["Tucker", "George", ""], ["Dai", "Bo", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1910.14268", "submitter": "Tianhao Wang", "authors": "Tianhao Wang, Florian Kerschbaum", "title": "RIGA: Covert and Robust White-Box Watermarking of Deep Neural Networks", "comments": "WebConf'21 (Full Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Watermarking of deep neural networks (DNN) can enable their tracing once\nreleased by a data owner. In this paper, we generalize white-box watermarking\nalgorithms for DNNs, where the data owner needs white-box access to the model\nto extract the watermark. White-box watermarking algorithms have the advantage\nthat they do not impact the accuracy of the watermarked model. We propose\nRobust whIte-box GAn watermarking (RIGA), a novel white-box watermarking\nalgorithm that uses adversarial training. Our extensive experiments demonstrate\nthat the proposed watermarking algorithm not only does not impact accuracy, but\nalso significantly improves the covertness and robustness over the current\nstate-of-art.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 05:51:45 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 02:33:54 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 23:42:09 GMT"}, {"version": "v4", "created": "Sun, 14 Feb 2021 02:57:33 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Wang", "Tianhao", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "1910.14270", "submitter": "Xu Zhao", "authors": "Xu Zhao", "title": "Parameter Sharing Decoder Pair for Auto Composing", "comments": "The author information of the old version of this paper is wrong.\n  Removed it. Please use this version if need to cite", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto Composing is an active and appealing research area in the past few\nyears, and lots of efforts have been put into inventing more robust models to\nsolve this problem. With the fast evolution of deep learning techniques, some\ndeep neural network-based language models are becoming dominant. Notably, the\ntransformer structure has been proven to be very efficient and promising in\nmodeling texts. However, the transformer-based language models usually contain\nhuge number of parameters and the size of the model is usually too large to put\nin production for some storage limited applications. In this paper, we propose\na parameter sharing decoder pair (PSDP), which reduces the number of parameters\ndramatically and at the same time maintains the capability of generating\nunderstandable and reasonable compositions. Works created by the proposed model\nare presented to demonstrate the effectiveness of the model.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 06:06:56 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 00:25:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhao", "Xu", ""]]}, {"id": "1910.14273", "submitter": "Xiaoxue Li", "authors": "Xiaoxue Li, Yanan Cao, Yanmin Shang, Yangxi Li, Yanbing Liu, Jianlong\n  Tan", "title": "RLINK: Deep Reinforcement Learning for User Identity Linkage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User identity linkage is a task of recognizing the identities of the same\nuser across different social networks (SN). Previous works tackle this problem\nvia estimating the pairwise similarity between identities from different SN,\npredicting the label of identity pairs or selecting the most relevant identity\npair based on the similarity scores. However, most of these methods ignore the\nresults of previously matched identities, which could contribute to the linkage\nin following matching steps. To address this problem, we convert user identity\nlinkage into a sequence decision problem and propose a reinforcement learning\nmodel to optimize the linkage strategy from the global perspective. Our method\nmakes full use of both the social network structure and the history matched\nidentities, and explores the long-term influence of current matching on\nsubsequent decisions. We conduct experiments on different types of datasets,\nthe results show that our method achieves better performance than other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 06:21:33 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Li", "Xiaoxue", ""], ["Cao", "Yanan", ""], ["Shang", "Yanmin", ""], ["Li", "Yangxi", ""], ["Liu", "Yanbing", ""], ["Tan", "Jianlong", ""]]}, {"id": "1910.14280", "submitter": "Navjot Singh", "authors": "Navjot Singh, Deepesh Data, Jemin George, Suhas Diggavi", "title": "SPARQ-SGD: Event-Triggered and Compressed Communication in Decentralized\n  Stochastic Optimization", "comments": "41 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and analyze SPARQ-SGD, which is an event-triggered\nand compressed algorithm for decentralized training of large-scale machine\nlearning models. Each node can locally compute a condition (event) which\ntriggers a communication where quantized and sparsified local model parameters\nare sent. In SPARQ-SGD each node takes at least a fixed number ($H$) of local\ngradient steps and then checks if the model parameters have significantly\nchanged compared to its last update; it communicates further compressed model\nparameters only when there is a significant change, as specified by a (design)\ncriterion. We prove that the SPARQ-SGD converges as $O(\\frac{1}{nT})$ and\n$O(\\frac{1}{\\sqrt{nT}})$ in the strongly-convex and non-convex settings,\nrespectively, demonstrating that such aggressive compression, including\nevent-triggered communication, model sparsification and quantization does not\naffect the overall convergence rate as compared to uncompressed decentralized\ntraining; thereby theoretically yielding communication efficiency for \"free\".\nWe evaluate SPARQ-SGD over real datasets to demonstrate significant amount of\nsavings in communication over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 06:58:38 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 23:23:41 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Singh", "Navjot", ""], ["Data", "Deepesh", ""], ["George", "Jemin", ""], ["Diggavi", "Suhas", ""]]}, {"id": "1910.14296", "submitter": "Junru Zhou", "authors": "Junru Zhou, Zhuosheng Zhang, Hai Zhao, Shuailiang Zhang", "title": "LIMIT-BERT : Linguistic Informed Multi-Task BERT", "comments": "EMNLP 2020, ACL Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a Linguistic Informed Multi-Task BERT (LIMIT-BERT)\nfor learning language representations across multiple linguistic tasks by\nMulti-Task Learning (MTL). LIMIT-BERT includes five key linguistic syntax and\nsemantics tasks: Part-Of-Speech (POS) tags, constituent and dependency\nsyntactic parsing, span and dependency semantic role labeling (SRL). Besides,\nLIMIT-BERT adopts linguistics mask strategy: Syntactic and Semantic Phrase\nMasking which mask all of the tokens corresponding to a syntactic/semantic\nphrase. Different from recent Multi-Task Deep Neural Networks (MT-DNN) (Liu et\nal., 2019), our LIMIT-BERT is linguistically motivated and learning in a\nsemi-supervised method which provides large amounts of linguistic-task data as\nsame as BERT learning corpus. As a result, LIMIT-BERT not only improves\nlinguistic tasks performance but also benefits from a regularization effect and\nlinguistic information that leads to more general representations to help adapt\nto new tasks and domains. LIMIT-BERT obtains new state-of-the-art or\ncompetitive results on both span and dependency semantic parsing on Propbank\nbenchmarks and both dependency and constituent syntactic parsing on Penn\nTreebank.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 08:14:51 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 03:11:55 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Zhou", "Junru", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""], ["Zhang", "Shuailiang", ""]]}, {"id": "1910.14315", "submitter": "Jiawei Shao", "authors": "Jiawei Shao, Jun Zhang", "title": "BottleNet++: An End-to-End Approach for Feature Compression in\n  Device-Edge Co-Inference Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of various intelligent mobile applications demands the\ndeployment of powerful deep learning models at resource-constrained mobile\ndevices. The device-edge co-inference framework provides a promising solution\nby splitting a neural network at a mobile device and an edge computing server.\nIn order to balance the on-device computation and the communication overhead,\nthe splitting point needs to be carefully picked, while the intermediate\nfeature needs to be compressed before transmission. Existing studies decoupled\nthe design of model splitting, feature compression, and communication, which\nmay lead to excessive resource consumption of the mobile device. In this paper,\nwe introduce an end-to-end architecture, named BottleNet++, that consists of an\nencoder, a non-trainable channel layer, and a decoder for more efficient\nfeature compression and transmission. The encoder and decoder essentially\nimplement joint source-channel coding via convolutional neural networks (CNNs),\nwhile explicitly considering the effect of channel noise. By exploiting the\nstrong sparsity and the fault-tolerant property of the intermediate feature in\na deep neural network (DNN), BottleNet++ achieves a much higher compression\nratio than existing methods. Furthermore, by providing the channel condition to\nthe encoder as an input, our method enjoys a strong generalization ability in\ndifferent channel conditions. Compared with merely transmitting intermediate\ndata without feature compression, BottleNet++ achieves up to 64x bandwidth\nreduction over the additive white Gaussian noise channel and up to 256x bit\ncompression ratio in the binary erasure channel, with less than 2% reduction in\naccuracy. With a higher compression ratio, BottleNet++ enables splitting a DNN\nat earlier layers, which leads to up to 3x reduction in on-device computation\ncompared with other compression methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 08:58:44 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 01:47:15 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 01:43:10 GMT"}, {"version": "v4", "created": "Sat, 18 Jan 2020 08:15:19 GMT"}, {"version": "v5", "created": "Fri, 5 Jun 2020 07:16:49 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Shao", "Jiawei", ""], ["Zhang", "Jun", ""]]}, {"id": "1910.14322", "submitter": "Zhilin Lu", "authors": "Zhilin Lu, Jintao Wang, Jian Song", "title": "Multi-resolution CSI Feedback with deep learning in Massive MIMO System", "comments": "6 pages, 5 figures, 4 tables. This work has been accepted by ICC2020.\n  Note that the flops complexity is fixed in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In massive multiple-input multiple-output (MIMO) system, user equipment (UE)\nneeds to send downlink channel state information (CSI) back to base station\n(BS). However, the feedback becomes expensive with the growing complexity of\nCSI in massive MIMO system. Recently, deep learning (DL) approaches are used to\nimprove the reconstruction efficiency of CSI feedback. In this paper, a novel\nfeedback network named CRNet is proposed to achieve better performance via\nextracting CSI features on multiple resolutions. An advanced training scheme\nthat further boosts the network performance is also introduced. Simulation\nresults show that the proposed CRNet outperforms the state-of-the-art CsiNet\nunder the same computational complexity without any extra information. The open\nsource codes are available at https://github.com/Kylin9511/CRNet\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 09:13:30 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 12:30:29 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Lu", "Zhilin", ""], ["Wang", "Jintao", ""], ["Song", "Jian", ""]]}, {"id": "1910.14351", "submitter": "Haitao Xu", "authors": "Haitao Xu, Brendan McCane, Lech Szymanski", "title": "VASE: Variational Assorted Surprise Exploration for Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in environments with continuous control and sparse rewards\nremains a key challenge in reinforcement learning (RL). Recently, surprise has\nbeen used as an intrinsic reward that encourages systematic and efficient\nexploration. We introduce a new definition of surprise and its RL\nimplementation named Variational Assorted Surprise Exploration (VASE). VASE\nuses a Bayesian neural network as a model of the environment dynamics and is\ntrained using variational inference, alternately updating the accuracy of the\nagent's model and policy. Our experiments show that in continuous control\nsparse reward environments VASE outperforms other surprise-based exploration\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 10:26:40 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Xu", "Haitao", ""], ["McCane", "Brendan", ""], ["Szymanski", "Lech", ""]]}, {"id": "1910.14353", "submitter": "Valeriya Slovikovskaya", "authors": "Valeriya Slovikovskaya", "title": "Transfer Learning from Transformers to Fake News Challenge Stance\n  Detection (FNC-1) Task", "comments": "12 pages, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report improved results of the Fake News Challenge Stage 1\n(FNC-1) stance detection task. This gain in performance is due to the\ngeneralization power of large language models based on Transformer\narchitecture, invented, trained and publicly released over the last two years.\nSpecifically (1) we improved the FNC-1 best performing model adding BERT\nsentence embedding of input sequences as a model feature, (2) we fine-tuned\nBERT, XLNet, and RoBERTa transformers on FNC-1 extended dataset and obtained\nstate-of-the-art results on FNC-1 task.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 10:32:43 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Slovikovskaya", "Valeriya", ""]]}, {"id": "1910.14354", "submitter": "Ciara Pike-Burke", "authors": "Ciara Pike-Burke and Steffen Gr\\\"unew\\\"alder", "title": "Recovering Bandits", "comments": "accepted to neurips 2019 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the recovering bandits problem, a variant of the stochastic\nmulti-armed bandit problem where the expected reward of each arm varies\naccording to some unknown function of the time since the arm was last played.\nWhile being a natural extension of the classical bandit problem that arises in\nmany real-world settings, this variation is accompanied by significant\ndifficulties. In particular, methods need to plan ahead and estimate many more\nquantities than in the classical bandit setting. In this work, we explore the\nuse of Gaussian processes to tackle the estimation and planing problem. We also\ndiscuss different regret definitions that let us quantify the performance of\nthe methods. To improve computational efficiency of the methods, we provide an\noptimistic planning approximation. We complement these discussions with regret\nbounds and empirical studies.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 10:34:37 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Pike-Burke", "Ciara", ""], ["Gr\u00fcnew\u00e4lder", "Steffen", ""]]}, {"id": "1910.14356", "submitter": "Aleksandar Bojchevski", "authors": "Aleksandar Bojchevski, Stephan G\\\"unnemann", "title": "Certifiable Robustness to Graph Perturbations", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the exploding interest in graph neural networks there has been little\neffort to verify and improve their robustness. This is even more alarming given\nrecent findings showing that they are extremely vulnerable to adversarial\nattacks on both the graph structure and the node attributes. We propose the\nfirst method for verifying certifiable (non-)robustness to graph perturbations\nfor a general class of models that includes graph neural networks and\nlabel/feature propagation. By exploiting connections to PageRank and Markov\ndecision processes our certificates can be efficiently (and under many threat\nmodels exactly) computed. Furthermore, we investigate robust training\nprocedures that increase the number of certifiably robust nodes while\nmaintaining or improving the clean predictive accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 10:42:58 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 11:51:15 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Bojchevski", "Aleksandar", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1910.14361", "submitter": "Victor Bapst", "authors": "Victor Bapst, Alvaro Sanchez-Gonzalez, Omar Shams, Kimberly\n  Stachenfeld, Peter W. Battaglia, Satinder Singh, Jessica B. Hamrick", "title": "Object-oriented state editing for HRL", "comments": "8 pages; accepted to the Perception as Generative Reasoning workshop\n  of the 33rd Conference on Neural InformationProcessing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce agents that use object-oriented reasoning to consider alternate\nstates of the world in order to more quickly find solutions to problems.\nSpecifically, a hierarchical controller directs a low-level agent to behave as\nif objects in the scene were added, deleted, or modified. The actions taken by\nthe controller are defined over a graph-based representation of the scene, with\nactions corresponding to adding, deleting, or editing the nodes of a graph. We\npresent preliminary results on three environments, demonstrating that our\napproach can achieve similar levels of reward as non-hierarchical agents, but\nwith better data efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 10:48:45 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Bapst", "Victor", ""], ["Sanchez-Gonzalez", "Alvaro", ""], ["Shams", "Omar", ""], ["Stachenfeld", "Kimberly", ""], ["Battaglia", "Peter W.", ""], ["Singh", "Satinder", ""], ["Hamrick", "Jessica B.", ""]]}, {"id": "1910.14375", "submitter": "Aravind Illa", "authors": "Abhayjeet Singh, Aravind Illa, Prasanta Kumar Ghosh", "title": "A comparative study of estimating articulatory movements from phoneme\n  sequences and acoustic features", "comments": "5 pages, 5 figures, accepted in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike phoneme sequences, movements of speech articulators (lips, tongue,\njaw, velum) and the resultant acoustic signal are known to encode not only the\nlinguistic message but also carry para-linguistic information. While several\nworks exist for estimating articulatory movement from acoustic signals, little\nis known to what extent articulatory movements can be predicted only from\nlinguistic information, i.e., phoneme sequence. In this work, we estimate\narticulatory movements from three different input representations: R1) acoustic\nsignal, R2) phoneme sequence, R3) phoneme sequence with timing information.\nWhile an attention network is used for estimating articulatory movement in the\ncase of R2, BLSTM network is used for R1 and R3. Experiments with ten subjects'\nacoustic-articulatory data reveal that the estimation techniques achieve an\naverage correlation coefficient of 0.85, 0.81, and 0.81 in the case of R1, R2,\nand R3 respectively. This indicates that attention network, although uses only\nphoneme sequence (R2) without any timing information, results in an estimation\nperformance similar to that using rich acoustic signal (R1), suggesting that\narticulatory motion is primarily driven by the linguistic message. The\ncorrelation coefficient is further improved to 0.88 when R1 and R3 are used\ntogether for estimating articulatory movements.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 11:13:44 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 13:26:08 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Singh", "Abhayjeet", ""], ["Illa", "Aravind", ""], ["Ghosh", "Prasanta Kumar", ""]]}, {"id": "1910.14380", "submitter": "Sarath Pattathil", "authors": "Weijie Liu, Aryan Mokhtari, Asuman Ozdaglar, Sarath Pattathil, Zebang\n  Shen, Nenggan Zheng", "title": "A Decentralized Proximal Point-type Method for Saddle Point Problems", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on solving a class of constrained non-convex\nnon-concave saddle point problems in a decentralized manner by a group of nodes\nin a network. Specifically, we assume that each node has access to a summand of\na global objective function and nodes are allowed to exchange information only\nwith their neighboring nodes. We propose a decentralized variant of the\nproximal point method for solving this problem. We show that when the objective\nfunction is $\\rho$-weakly convex-weakly concave the iterates converge to\napproximate stationarity with a rate of $\\mathcal{O}(1/\\sqrt{T})$ where the\napproximation error depends linearly on $\\sqrt{\\rho}$. We further show that\nwhen the objective function satisfies the Minty VI condition (which generalizes\nthe convex-concave case) we obtain convergence to stationarity with a rate of\n$\\mathcal{O}(1/\\sqrt{T})$. To the best of our knowledge, our proposed method is\nthe first decentralized algorithm with theoretical guarantees for solving a\nnon-convex non-concave decentralized saddle point problem. Our numerical\nresults for training a general adversarial network (GAN) in a decentralized\nmanner match our theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 11:24:21 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Liu", "Weijie", ""], ["Mokhtari", "Aryan", ""], ["Ozdaglar", "Asuman", ""], ["Pattathil", "Sarath", ""], ["Shen", "Zebang", ""], ["Zheng", "Nenggan", ""]]}, {"id": "1910.14388", "submitter": "Davide Belli", "authors": "Davide Belli and Thomas Kipf", "title": "Image-Conditioned Graph Generation for Road Network Extraction", "comments": "Presented at NeurIPS 2019 Workshop on Graph Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models for graphs have shown great promise in the area of\ndrug design, but have so far found little application beyond generating\ngraph-structured molecules. In this work, we demonstrate a proof of concept for\nthe challenging task of road network extraction from image data. This task can\nbe framed as image-conditioned graph generation, for which we develop the\nGenerative Graph Transformer (GGT), a deep autoregressive model that makes use\nof attention mechanisms for image conditioning and the recurrent generation of\ngraphs. We benchmark GGT on the application of road network extraction from\nsemantic segmentation data. For this, we introduce the Toulouse Road Network\ndataset, based on real-world publicly-available data. We further propose the\nStreetMover distance: a metric based on the Sinkhorn distance for effectively\nevaluating the quality of road network generation. The code and dataset are\npublicly available.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 11:38:13 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Belli", "Davide", ""], ["Kipf", "Thomas", ""]]}, {"id": "1910.14409", "submitter": "Vasisht Duddu", "authors": "Vasisht Duddu, D. Vijay Rao", "title": "Quantifying (Hyper) Parameter Leakage in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning models, extensively used for various multimedia\napplications, are offered to users as a blackbox service on the Cloud on a\npay-per-query basis. Such blackbox models are commercially valuable to\nadversaries, making them vulnerable to extraction attacks to reverse engineer\nthe proprietary model thereby violating the model privacy and Intellectual\nProperty. Here, the adversary first extracts the model architecture or\nhyperparameters through side channel leakage, followed by stealing the\nfunctionality of the target model by training the reconstructed architecture on\na synthetic dataset. While the attacks proposed in literature are empirical,\nthere is a need for a theoretical framework to measure the information leaked\nunder such extraction attacks. To this extent, in this work, we propose a novel\nprobabilistic framework, Airavata, to estimate the information leakage in such\nmodel extraction attacks. This framework captures the fact that extracting the\nexact target model is difficult due to experimental uncertainty while inferring\nmodel hyperparameters and stochastic nature of training to steal the target\nmodel functionality. Specifically, we use Bayesian Networks to capture\nuncertainty in estimating the target model under various extraction attacks\nbased on the subjective notion of probability. We validate the proposed\nframework under different adversary assumptions commonly adopted in literature\nto reason about the attack efficacy. This provides a practical tool to infer\nactionable details about extracting blackbox models and help identify the best\nattack combination which maximises the knowledge extracted (or information\nleaked) from the target model.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 12:05:00 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 06:57:41 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Duddu", "Vasisht", ""], ["Rao", "D. Vijay", ""]]}, {"id": "1910.14421", "submitter": "Amir Hossein Akhavan Rahnama", "authors": "Amir Hossein Akhavan Rahnama, Henrik Bostr\\\"om", "title": "A study of data and label shift in the LIME framework", "comments": "Accepted at the Neurip 2019 Workshop \"Human-Centric Machine Learning\"\n  (poster + spotlight talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LIME is a popular approach for explaining a black-box prediction through an\ninterpretable model that is trained on instances in the vicinity of the\npredicted instance. To generate these instances, LIME randomly selects a subset\nof the non-zero features of the predicted instance. After that, the perturbed\ninstances are fed into the black-box model to obtain labels for these, which\nare then used for training the interpretable model. In this study, we present a\nsystematic evaluation of the interpretable models that are output by LIME on\nthe two use-cases that were considered in the original paper introducing the\napproach; text classification and object detection. The investigation shows\nthat the perturbation and labeling phases result in both data and label shift.\nIn addition, we study the correlation between the shift and the fidelity of the\ninterpretable model and show that in certain cases the shift negatively\ncorrelates with the fidelity. Based on these findings, it is argued that there\nis a need for a new sampling approach that mitigates the shift in the LIME's\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 12:39:03 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Rahnama", "Amir Hossein Akhavan", ""], ["Bostr\u00f6m", "Henrik", ""]]}, {"id": "1910.14424", "submitter": "Rodrigo Nogueira", "authors": "Rodrigo Nogueira, Wei Yang, Kyunghyun Cho, Jimmy Lin", "title": "Multi-Stage Document Ranking with BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of deep neural networks pre-trained via language modeling tasks\nhas spurred a number of successful applications in natural language processing.\nThis work explores one such popular model, BERT, in the context of document\nranking. We propose two variants, called monoBERT and duoBERT, that formulate\nthe ranking problem as pointwise and pairwise classification, respectively.\nThese two models are arranged in a multi-stage ranking architecture to form an\nend-to-end search system. One major advantage of this design is the ability to\ntrade off quality against latency by controlling the admission of candidates\ninto each pipeline stage, and by doing so, we are able to find operating points\nthat offer a good balance between these two competing metrics. On two\nlarge-scale datasets, MS MARCO and TREC CAR, experiments show that our model\nproduces results that are either at or comparable to the state of the art.\nAblation studies show the contributions of each component and characterize the\nlatency/quality tradeoff space.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 12:45:40 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Nogueira", "Rodrigo", ""], ["Yang", "Wei", ""], ["Cho", "Kyunghyun", ""], ["Lin", "Jimmy", ""]]}, {"id": "1910.14425", "submitter": "Farzin Haddadpour", "authors": "Farzin Haddadpour, Mehrdad Mahdavi", "title": "On the Convergence of Local Descent Methods in Federated Learning", "comments": "47 pages, \"Updates from v1: A technical error in Lemma B3 is\n  corrected\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In federated distributed learning, the goal is to optimize a global training\nobjective defined over distributed devices, where the data shard at each device\nis sampled from a possibly different distribution (a.k.a., heterogeneous or non\ni.i.d. data samples). In this paper, we generalize the local stochastic and\nfull gradient descent with periodic averaging-- originally designed for\nhomogeneous distributed optimization, to solve nonconvex optimization problems\nin federated learning. Although scant research is available on the\neffectiveness of local SGD in reducing the number of communication rounds in\nhomogeneous setting, its convergence and communication complexity in\nheterogeneous setting is mostly demonstrated empirically and lacks through\ntheoretical understating. To bridge this gap, we demonstrate that by properly\nanalyzing the effect of unbiased gradients and sampling schema in federated\nsetting, under mild assumptions, the implicit variance reduction feature of\nlocal distributed methods generalize to heterogeneous data shards and exhibits\nthe best known convergence rates of homogeneous setting both in general\nnonconvex and under {\\pl}~ condition (generalization of strong-convexity). Our\ntheoretical results complement the recent empirical studies that demonstrate\nthe applicability of local GD/SGD to federated learning. We also specialize the\nproposed local method for networked distributed optimization. To the best of\nour knowledge, the obtained convergence rates are the sharpest known to date on\nthe convergence of local decant methods with periodic averaging for solving\nnonconvex federated optimization in both centralized and networked distributed\noptimization.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 12:52:55 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 21:16:41 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Haddadpour", "Farzin", ""], ["Mahdavi", "Mehrdad", ""]]}, {"id": "1910.14428", "submitter": "Arash Mehrjou", "authors": "Arash Mehrjou, Wittawat Jitkrittum, Krikamol Muandet, Bernhard\n  Sch\\\"olkopf", "title": "Kernel-Guided Training of Implicit Generative Models with Stability\n  Guarantees", "comments": "There was a misunderstanding in how an article should be updated on\n  arXiv. We have withdrawn this article from this link. The same article can be\n  found at arXiv:1901.09206", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern implicit generative models such as generative adversarial networks\n(GANs) are generally known to suffer from issues such as instability,\nuninterpretability, and difficulty in assessing their performance. If we see\nthese implicit models as dynamical systems, some of these issues are caused by\nbeing unable to control their behavior in a meaningful way during the course of\ntraining. In this work, we propose a theoretically grounded method to guide the\ntraining trajectories of GANs by augmenting the GAN loss function with a\nkernel-based regularization term that controls local and global discrepancies\nbetween the model and true distributions. This control signal allows us to\ninject prior knowledge into the model. We provide theoretical guarantees on the\nstability of the resulting dynamical system and demonstrate different aspects\nof it via a wide range of experiments.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 21:02:32 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 17:06:14 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Mehrjou", "Arash", ""], ["Jitkrittum", "Wittawat", ""], ["Muandet", "Krikamol", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1910.14436", "submitter": "Djallel Bouneffouf", "authors": "Charu Aggarwal, Djallel Bouneffouf, Horst Samulowitz, Beat Buesser,\n  Thanh Hoang, Udayan Khurana, Sijia Liu, Tejaswini Pedapati, Parikshit Ram,\n  Ambrish Rawat, Martin Wistuba and Alexander Gray", "title": "How can AI Automate End-to-End Data Science?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data science is labor-intensive and human experts are scarce but heavily\ninvolved in every aspect of it. This makes data science time consuming and\nrestricted to experts with the resulting quality heavily dependent on their\nexperience and skills. To make data science more accessible and scalable, we\nneed its democratization. Automated Data Science (AutoDS) is aimed towards that\ngoal and is emerging as an important research and business topic. We introduce\nand define the AutoDS challenge, followed by a proposal of a general AutoDS\nframework that covers existing approaches but also provides guidance for the\ndevelopment of new methods. We categorize and review the existing literature\nfrom multiple aspects of the problem setup and employed techniques. Then we\nprovide several views on how AI could succeed in automating end-to-end AutoDS.\nWe hope this survey can serve as insightful guideline for the AutoDS field and\nprovide inspiration for future research.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 12:54:48 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Aggarwal", "Charu", ""], ["Bouneffouf", "Djallel", ""], ["Samulowitz", "Horst", ""], ["Buesser", "Beat", ""], ["Hoang", "Thanh", ""], ["Khurana", "Udayan", ""], ["Liu", "Sijia", ""], ["Pedapati", "Tejaswini", ""], ["Ram", "Parikshit", ""], ["Rawat", "Ambrish", ""], ["Wistuba", "Martin", ""], ["Gray", "Alexander", ""]]}, {"id": "1910.14442", "submitter": "Fei Xia", "authors": "Fei Xia, William B. Shen, Chengshu Li, Priya Kasimbeg, Micael Tchapmi,\n  Alexander Toshev, Li Fei-Fei, Roberto Mart\\'in-Mart\\'in, Silvio Savarese", "title": "Interactive Gibson Benchmark: A Benchmark for Interactive Navigation in\n  Cluttered Environments", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Interactive Gibson Benchmark, the first comprehensive benchmark\nfor training and evaluating Interactive Navigation: robot navigation strategies\nwhere physical interaction with objects is allowed and even encouraged to\naccomplish a task. For example, the robot can move objects if needed in order\nto clear a path leading to the goal location. Our benchmark comprises two novel\nelements: 1) a new experimental setup, the Interactive Gibson Environment,\nwhich simulates high fidelity visuals of indoor scenes, and high fidelity\nphysical dynamics of the robot and common objects found in these scenes; 2) a\nset of Interactive Navigation metrics which allows one to study the interplay\nbetween navigation and physical interaction. We present and evaluate multiple\nlearning-based baselines in Interactive Gibson, and provide insights into\nregimes of navigation with different trade-offs between navigation path\nefficiency and disturbance of surrounding objects. We make our benchmark\npublicly available(https://sites.google.com/view/interactivegibsonenv) and\nencourage researchers from all disciplines in robotics (e.g. planning,\nlearning, control) to propose, evaluate, and compare their Interactive\nNavigation solutions in Interactive Gibson.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 01:04:37 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 07:08:01 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Xia", "Fei", ""], ["Shen", "William B.", ""], ["Li", "Chengshu", ""], ["Kasimbeg", "Priya", ""], ["Tchapmi", "Micael", ""], ["Toshev", "Alexander", ""], ["Fei-Fei", "Li", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Savarese", "Silvio", ""]]}, {"id": "1910.14443", "submitter": "Joanna Rownicka", "authors": "Joanna Rownicka, Peter Bell, Steve Renals", "title": "Multi-scale Octave Convolutions for Robust Speech Recognition", "comments": "submitted to ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-scale octave convolution layer to learn robust speech\nrepresentations efficiently. Octave convolutions were introduced by Chen et al\n[1] in the computer vision field to reduce the spatial redundancy of the\nfeature maps by decomposing the output of a convolutional layer into feature\nmaps at two different spatial resolutions, one octave apart. This approach\nimproved the efficiency as well as the accuracy of the CNN models. The accuracy\ngain was attributed to the enlargement of the receptive field in the original\ninput space. We argue that octave convolutions likewise improve the robustness\nof learned representations due to the use of average pooling in the lower\nresolution group, acting as a low-pass filter. We test this hypothesis by\nevaluating on two noisy speech corpora - Aurora-4 and AMI. We extend the octave\nconvolution concept to multiple resolution groups and multiple octaves. To\nevaluate the robustness of the inferred representations, we report the\nsimilarity between clean and noisy encodings using an affine projection loss as\na proxy robustness measure. The results show that proposed method reduces the\nWER by up to 6.6% relative for Aurora-4 and 3.6% for AMI, while improving the\ncomputational efficiency of the CNN acoustic models.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 13:15:24 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Rownicka", "Joanna", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "1910.14448", "submitter": "Xiang Pan", "authors": "Xiang Pan, Tianyu Zhao, Minghua Chen, and Shengyu Zhang", "title": "DeepOPF: A Deep Neural Network Approach for Security-Constrained DC\n  Optimal Power Flow", "comments": "14 pages, 6 figures, accepted for publication in IEEE Transactions on\n  Power Systems. (Conference version in IEEE SmartGridComm 2019.) arXiv admin\n  note: text overlap with arXiv:1905.04479", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop DeepOPF as a Deep Neural Network (DNN) approach for solving\nsecurity-constrained direct current optimal power flow (SC-DCOPF) problems,\nwhich are critical for reliable and cost-effective power system\noperation.DeepOPF is inspired by the observation that solving SC-DCOPF problems\nfor a given power network is equivalent to depicting a high-dimensional mapping\nfrom the load inputs to the generation and phase angle outputs. We first train\na DNN to learn the mapping and predict the generations from the load inputs. We\nthen directly reconstruct the phase angles from the generations and loads by\nusing the power flow equations. Such a predict-and-reconstruct approach reduces\nthe dimension of the mapping to learn, subsequently cutting down the size of\nthe DNN and the amount of training data needed. We further derive a condition\nfor tuning the size of the DNN according to the desired approximation accuracy\nof the load-generation mapping. We develop a post-processing procedure based on\n$\\ell_1$-projection to ensure the feasibility of the obtained solution, which\ncan be of independent interest. Simulation results for IEEE test cases show\nthat DeepOPF generates feasible solutions with less than 0.2% optimality loss,\nwhile speeding up the computation time by up to two orders of magnitude as\ncompared to a state-of-the-art solver.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 07:15:32 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 08:25:53 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 16:20:57 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Pan", "Xiang", ""], ["Zhao", "Tianyu", ""], ["Chen", "Minghua", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1910.14458", "submitter": "Edouard Pauwels", "authors": "Mai Trang Vu, Fran\\c{c}ois Bachoc, Edouard Pauwels", "title": "Rate of convergence for geometric inference based on the empirical\n  Christoffel function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the support of a measure from a finite,\nindependent, sample. The estimators which are considered are constructed based\non the empirical Christoffel function. Such estimators have been proposed for\nthe problem of set estimation with heuristic justifications. We carry out a\ndetailed finite sample analysis, that allows us to select the threshold and\ndegree parameters as a function of the sample size. We provide a convergence\nrate analysis of the resulting support estimation procedure. Our analysis\nestablishes that we may obtain finite sample bounds which are comparable to\nexisting rates for different set estimation procedures. Our results rely on\nconcentration inequalities for the empirical Christoffel function and on\nestimates of the supremum of the Christoffel-Darboux kernel on sets with smooth\nboundaries, that can be considered of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 13:32:00 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 09:21:26 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Vu", "Mai Trang", ""], ["Bachoc", "Fran\u00e7ois", ""], ["Pauwels", "Edouard", ""]]}, {"id": "1910.14460", "submitter": "Javier Cabrera", "authors": "J. Cabrera, D. Amaratunga, W. Kostis and J Kostis", "title": "Precision disease networks (PDN)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a method for building patient-based networks that we call\nPrecision disease networks, and its uses for predicting medical outcomes. Our\nmethodology consists of building networks, one for each patient or case, that\ndescribes the dis-ease evolution of the patient (PDN) and store the networks as\na set of features in a data set of PDN's, one per observation. We cluster the\nPDN data and study the within and between cluster variability. In addition, we\ndevelop data visualization technics in order to display, compare and summarize\nthe network data. Finally, we analyze a dataset of heart diseases patients from\na New Jersey statewide data-base MIDAS (Myocardial Infarction Data Acquisition\nSystem, in order to show that the network data improve on the prediction of\nimportant patient outcomes such as death or cardiovascular death, when compared\nwith the standard statistical analysis.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 15:22:04 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Cabrera", "J.", ""], ["Amaratunga", "D.", ""], ["Kostis", "W.", ""], ["Kostis", "J", ""]]}, {"id": "1910.14464", "submitter": "Jordan Boyd-Graber", "authors": "Jordan Boyd-Graber, Benjamin B\\\"orschinger", "title": "What Question Answering can Learn from Trivia Nerds", "comments": null, "journal-ref": "ACL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to the traditional task of getting machines to answer questions,\na major research question in question answering is to create interesting,\nchallenging questions that can help systems learn how to answer questions and\nalso reveal which systems are the best at answering questions. We argue that\ncreating a question answering dataset -- and the ubiquitous leaderboard that\ngoes with it -- closely resembles running a trivia tournament: you write\nquestions, have agents (either humans or machines) answer the questions, and\ndeclare a winner. However, the research community has ignored the decades of\nhard-learned lessons from decades of the trivia community creating vibrant,\nfair, and effective question answering competitions. After detailing problems\nwith existing QA datasets, we outline the key lessons -- removing ambiguity,\ndiscriminating skill, and adjudicating disputes -- that can transfer to QA\nresearch and how they might be implemented for the QA community.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 13:38:01 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 15:27:05 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 12:41:05 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Boyd-Graber", "Jordan", ""], ["B\u00f6rschinger", "Benjamin", ""]]}, {"id": "1910.14472", "submitter": "Zongqing Lu", "authors": "Jiechuan Jiang and Zongqing Lu", "title": "Learning Fairness in Multi-Agent Systems", "comments": "NeurIPS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is essential for human society, contributing to stability and\nproductivity. Similarly, fairness is also the key for many multi-agent systems.\nTaking fairness into multi-agent learning could help multi-agent systems become\nboth efficient and stable. However, learning efficiency and fairness\nsimultaneously is a complex, multi-objective, joint-policy optimization. To\ntackle these difficulties, we propose FEN, a novel hierarchical reinforcement\nlearning model. We first decompose fairness for each agent and propose\nfair-efficient reward that each agent learns its own policy to optimize. To\navoid multi-objective conflict, we design a hierarchy consisting of a\ncontroller and several sub-policies, where the controller maximizes the\nfair-efficient reward by switching among the sub-policies that provides diverse\nbehaviors to interact with the environment. FEN can be trained in a fully\ndecentralized way, making it easy to be deployed in real-world applications.\nEmpirically, we show that FEN easily learns both fairness and efficiency and\nsignificantly outperforms baselines in a variety of multi-agent scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 13:59:37 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Jiang", "Jiechuan", ""], ["Lu", "Zongqing", ""]]}, {"id": "1910.14479", "submitter": "Hui Guan", "authors": "Hui Guan, Lin Ning, Zhen Lin, Xipeng Shen, Huiyang Zhou, Seung-Hwan\n  Lim", "title": "In-Place Zero-Space Memory Protection for CNN", "comments": "Accepted in NeurIPS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) are being actively explored for\nsafety-critical applications such as autonomous vehicles and aerospace, where\nit is essential to ensure the reliability of inference results in the presence\nof possible memory faults. Traditional methods such as error correction codes\n(ECC) and Triple Modular Redundancy (TMR) are CNN-oblivious and incur\nsubstantial memory overhead and energy cost. This paper introduces in-place\nzero-space ECC assisted with a new training scheme weight distribution-oriented\ntraining. The new method provides the first known zero space cost memory\nprotection for CNNs without compromising the reliability offered by traditional\nECC.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 14:15:11 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Guan", "Hui", ""], ["Ning", "Lin", ""], ["Lin", "Zhen", ""], ["Shen", "Xipeng", ""], ["Zhou", "Huiyang", ""], ["Lim", "Seung-Hwan", ""]]}, {"id": "1910.14481", "submitter": "Dushyant Rao", "authors": "Dushyant Rao, Francesco Visin, Andrei A. Rusu, Yee Whye Teh, Razvan\n  Pascanu, Raia Hadsell", "title": "Continual Unsupervised Representation Learning", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning aims to improve the ability of modern learning systems to\ndeal with non-stationary distributions, typically by attempting to learn a\nseries of tasks sequentially. Prior art in the field has largely considered\nsupervised or reinforcement learning tasks, and often assumes full knowledge of\ntask labels and boundaries. In this work, we propose an approach (CURL) to\ntackle a more general problem that we will refer to as unsupervised continual\nlearning. The focus is on learning representations without any knowledge about\ntask identity, and we explore scenarios when there are abrupt changes between\ntasks, smooth transitions from one task to another, or even when the data is\nshuffled. The proposed approach performs task inference directly within the\nmodel, is able to dynamically expand to capture new concepts over its lifetime,\nand incorporates additional rehearsal-based techniques to deal with\ncatastrophic forgetting. We demonstrate the efficacy of CURL in an unsupervised\nlearning setting with MNIST and Omniglot, where the lack of labels ensures no\ninformation is leaked about the task. Further, we demonstrate strong\nperformance compared to prior art in an i.i.d setting, or when adapting the\ntechnique to supervised tasks such as incremental class learning.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 14:18:45 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Rao", "Dushyant", ""], ["Visin", "Francesco", ""], ["Rusu", "Andrei A.", ""], ["Teh", "Yee Whye", ""], ["Pascanu", "Razvan", ""], ["Hadsell", "Raia", ""]]}, {"id": "1910.14488", "submitter": "Mingkui Tan", "authors": "Yong Guo, Yin Zheng, Mingkui Tan, Qi Chen, Jian Chen, Peilin Zhao,\n  Junzhou Huang", "title": "NAT: Neural Architecture Transformer for Accurate and Compact\n  Architectures", "comments": "This paper is accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing effective architectures is one of the key factors behind the\nsuccess of deep neural networks. Existing deep architectures are either\nmanually designed or automatically searched by some Neural Architecture Search\n(NAS) methods. However, even a well-searched architecture may still contain\nmany non-significant or redundant modules or operations (e.g., convolution or\npooling), which may not only incur substantial memory consumption and\ncomputation cost but also deteriorate the performance. Thus, it is necessary to\noptimize the operations inside an architecture to improve the performance\nwithout introducing extra computation cost. Unfortunately, such a constrained\noptimization problem is NP-hard. To make the problem feasible, we cast the\noptimization problem into a Markov decision process (MDP) and seek to learn a\nNeural Architecture Transformer (NAT) to replace the redundant operations with\nthe more computationally efficient ones (e.g., skip connection or directly\nremoving the connection). Based on MDP, we learn NAT by exploiting\nreinforcement learning to obtain the optimization policies w.r.t. different\narchitectures. To verify the effectiveness of the proposed strategies, we apply\nNAT on both hand-crafted architectures and NAS based architectures. Extensive\nexperiments on two benchmark datasets, i.e., CIFAR-10 and ImageNet, demonstrate\nthat the transformed architecture by NAT significantly outperforms both its\noriginal form and those architectures optimized by existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 14:29:09 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 05:26:39 GMT"}, {"version": "v3", "created": "Tue, 24 Dec 2019 16:00:44 GMT"}, {"version": "v4", "created": "Thu, 2 Jan 2020 11:24:12 GMT"}, {"version": "v5", "created": "Mon, 13 Jan 2020 13:39:25 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Guo", "Yong", ""], ["Zheng", "Yin", ""], ["Tan", "Mingkui", ""], ["Chen", "Qi", ""], ["Chen", "Jian", ""], ["Zhao", "Peilin", ""], ["Huang", "Junzhou", ""]]}, {"id": "1910.14491", "submitter": "Zaiqiao Meng", "authors": "Zaiqiao Meng, Shangsong Liang, Jinyuan Fang, Teng Xiao", "title": "Semi-supervisedly Co-embedding Attributed Networks", "comments": "Published at NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models (DGMs) have achieved remarkable advances.\nSemi-supervised variational auto-encoders (SVAE) as a classical DGM offer a\nprincipled framework to effectively generalize from small labelled data to\nlarge unlabelled ones, but it is difficult to incorporate rich unstructured\nrelationships within the multiple heterogeneous entities. In this paper, to\ndeal with the problem, we present a semi-supervised co-embedding model for\nattributed networks (SCAN) based on the generalized SVAE for heterogeneous\ndata, which collaboratively learns low-dimensional vector representations of\nboth nodes and attributes for partially labelled attributed networks\nsemi-supervisedly. The node and attribute embeddings obtained in a unified\nmanner by our SCAN can benefit for capturing not only the proximities between\nnodes but also the affinities between nodes and attributes. Moreover, our model\nalso trains a discriminative network to learn the label predictive distribution\nof nodes. Experimental results on real-world networks demonstrate that our\nmodel yields excellent performance in a number of applications such as\nattribute inference, user profiling and node classification compared to the\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 14:30:06 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Meng", "Zaiqiao", ""], ["Liang", "Shangsong", ""], ["Fang", "Jinyuan", ""], ["Xiao", "Teng", ""]]}, {"id": "1910.14497", "submitter": "Hailey James", "authors": "Hailey James and David Alvarez-Melis", "title": "Probabilistic Bias Mitigation in Word Embeddings", "comments": "4 pages, 4 figures, Workshop on Human-Centric Machine Learning at\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that word embeddings derived from large corpora tend to\nincorporate biases present in their training data. Various methods for\nmitigating these biases have been proposed, but recent work has demonstrated\nthat these methods hide but fail to truly remove the biases, which can still be\nobserved in word nearest-neighbor statistics. In this work we propose a\nprobabilistic view of word embedding bias. We leverage this framework to\npresent a novel method for mitigating bias which relies on probabilistic\nobservations to yield a more robust bias mitigation algorithm. We demonstrate\nthat this method effectively reduces bias according to three separate measures\nof bias while maintaining embedding quality across various popular benchmark\nsemantic tasks\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 14:34:14 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 23:17:22 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["James", "Hailey", ""], ["Alvarez-Melis", "David", ""]]}, {"id": "1910.14499", "submitter": "Andrei Osiptsov", "authors": "A.D. Morozov, D.O. Popkov, V.M. Duplyakov, R.F. Mutalova, A.A.\n  Osiptsov, A.L. Vainshtein, E.V. Burnaev, E.V. Shel, G.V. Paderin", "title": "Data-driven model for hydraulic fracturing design optimization: focus on\n  building digital database and production forecast", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Growing amount of hydraulic fracturing (HF) jobs in the recent two decades\nresulted in a significant amount of measured data available for development of\npredictive models via machine learning (ML). In multistage fractured\ncompletions, post-fracturing production analysis reveals that different stages\nproduce very non-uniformly due to a combination of geomechanics and fracturing\ndesign factors. Hence, there is a significant room for improvement of current\ndesign practices. The workflow is essentially split into two stages. As a\nresult of the first stage, the present paper summarizes the efforts into the\ncreation of a digital database of field data from several thousands of\nmultistage HF jobs on wells from circa 20 different oilfields in Western\nSiberia, Russia. In terms of the number of points (fracturing jobs), the\npresent database is a rare case of a representative dataset of about 5000 data\npoints. Each point in the data base contains the vector of 92 input variables\n(the reservoir, well and the frac design parameters) and the vector of\nproduction data, which is characterized by 16 parameters, including the target,\ncumulative oil production. Data preparation has been done using various ML\ntechniques: the problem of missing values in the database is solved with\ncollaborative filtering for data imputation; outliers are removed using\nvisualisation of cluster data structure by t-SNE algorithm. The production\nforecast problem is solved via CatBoost algorithm. Prediction capability of the\nmodel is measured with the coefficient of determination (R^2) and reached\n0.815. The inverse problem (selecting an optimum set of fracturing design\nparameters to maximize production) will be considered in the second part of the\nstudy to be published in another paper, along with a recommendation system for\nadvising DESC and production stimulation engineers on an optimized fracturing\ndesign.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 12:17:13 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 13:35:30 GMT"}, {"version": "v3", "created": "Sat, 18 Jul 2020 06:22:53 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Morozov", "A. D.", ""], ["Popkov", "D. O.", ""], ["Duplyakov", "V. M.", ""], ["Mutalova", "R. F.", ""], ["Osiptsov", "A. A.", ""], ["Vainshtein", "A. L.", ""], ["Burnaev", "E. V.", ""], ["Shel", "E. V.", ""], ["Paderin", "G. V.", ""]]}, {"id": "1910.14502", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef", "title": "Assessment of Multiple-Biomarker Classifiers: fundamental principles and\n  a proposed strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multiple-biomarker classifier problem and its assessment are reviewed\nagainst the background of some fundamental principles from the field of\nstatistical pattern recognition, machine learning, or the recently so-called\n\"data science\". A narrow reading of that literature has led many authors to\nneglect the contribution to the total uncertainty of performance assessment\nfrom the finite training sample. Yet the latter is a fundamental indicator of\nthe stability of a classifier; thus its neglect may be contributing to the\nproblematic status of many studies. A three-level strategy is proposed for\nmoving forward in this field. The lowest level is that of construction, where\ncandidate features are selected and the choice of classifier architecture is\nmade. At that point, the effective dimensionality of the classifier is\nestimated and used to size the next level of analysis, a pilot study on\npreviously unseen cases. The total (training and testing) uncertainty resulting\nfrom the pilot study is, in turn, used to size the highest level of analysis, a\npivotal study with a target level of uncertainty. Some resources available in\nthe literature for implementing this approach are reviewed. Although the\nconcepts explained in the present article may be fundamental and\nstraightforward for many researchers in the machine learning community they are\nsubtle for many practitioners, for whom we provided a general advice for the\nbest practice in \\cite{Shi2010MAQCII} and elaborate here in the present paper.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 17:45:09 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Yousef", "Waleed A.", ""]]}, {"id": "1910.14543", "submitter": "Dong Dong", "authors": "Wojciech Czaja, Dong Dong, Pierre-Emmanuel Jabin, Franck Olivier\n  Ndjakou Njeunje", "title": "Transport Model for Feature Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new feature extraction method for complex and large datasets,\nbased on the concept of transport operators on graphs. The proposed approach\ngeneralizes and extends the many existing data representation methodologies\nbuilt upon diffusion processes, to a new domain where dynamical systems play a\nkey role. The main advantage of this approach comes from the ability to exploit\ndifferent relationships than those arising in the context of e.g., Graph\nLaplacians. Fundamental properties of the transport operators are proved. We\ndemonstrate the flexibility of the method by introducing several diverse\nexamples of transformations. We close the paper with a series of computational\nexperiments and applications to the problem of classification of hyperspectral\nsatellite imagery, to illustrate the practical implications of our algorithm\nand its ability to quantify new aspects of relationships within complicated\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 15:45:07 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Czaja", "Wojciech", ""], ["Dong", "Dong", ""], ["Jabin", "Pierre-Emmanuel", ""], ["Njeunje", "Franck Olivier Ndjakou", ""]]}, {"id": "1910.14544", "submitter": "Aur\\'elien Decelle", "authors": "Aur\\'elien Decelle and Cyril Furtlehner", "title": "Gaussian-Spherical Restricted Boltzmann Machines", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": "10.1088/1751-8121/ab79f3", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a special type of Restricted Boltzmann machine (RBM), namely a\nGaussian-spherical RBM where the visible units have Gaussian priors while the\nvector of hidden variables is constrained to stay on an ${\\mathbbm L}_2$\nsphere. The spherical constraint having the advantage to admit exact asymptotic\ntreatments, various scaling regimes are explicitly identified based solely on\nthe spectral properties of the coupling matrix (also called weight matrix of\nthe RBM). Incidentally these happen to be formally related to similar scaling\nbehaviours obtained in a different context dealing with spatial condensation of\nzero range processes. More specifically, when the spectrum of the coupling\nmatrix is doubly degenerated an exact treatment can be proposed to deal with\nfinite size effects. Interestingly the known parallel between the ferromagnetic\ntransition of the spherical model and the Bose-Einstein condensation can be\nmade explicit in that case. More importantly this gives us the ability to\nextract all needed response functions with arbitrary precision for the training\nalgorithm of the RBM. This allows us then to numerically integrate the dynamics\nof the spectrum of the weight matrix during learning in a precise way. This\ndynamics reveals in particular a sequential emergence of modes from the\nMarchenko-Pastur bulk of singular vectors of the coupling matrix.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 15:46:08 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Decelle", "Aur\u00e9lien", ""], ["Furtlehner", "Cyril", ""]]}, {"id": "1910.14549", "submitter": "Sang Sang Tan", "authors": "Sang-Sang Tan (1), Jin-Cheon Na (1) ((1) Nanyang Technological\n  University, Singapore)", "title": "Positional Attention-based Frame Identification with BERT: A Deep\n  Learning Approach to Target Disambiguation and Semantic Frame Selection", "comments": "19 pages, 7 figures, uses basic.sty", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is the task of transforming sentences from natural language\ninto formal representations of predicate-argument structures. Under this\nresearch area, frame-semantic parsing has attracted much interest. This parsing\napproach leverages the lexical information defined in FrameNet to associate\nmarked predicates or targets with semantic frames, thereby assigning semantic\nroles to sentence components based on pre-specified frame elements in FrameNet.\nIn this paper, a deep neural network architecture known as Positional\nAttention-based Frame Identification with BERT (PAFIBERT) is presented as a\nsolution to the frame identification subtask in frame-semantic parsing.\nAlthough the importance of this subtask is well-established, prior research has\nyet to find a robust solution that works satisfactorily for both in-domain and\nout-of-domain data. This study thus set out to improve frame identification in\nlight of recent advancements of language modeling and transfer learning in\nnatural language processing. The proposed method is partially empowered by\nBERT, a pre-trained language model that excels at capturing contextual\ninformation in texts. By combining the language representation power of BERT\nwith a position-based attention mechanism, PAFIBERT is able to attend to\ntarget-specific contexts in sentences for disambiguating targets and\nassociating them with the most suitable semantic frames. Under various\nexperimental settings, PAFIBERT outperformed existing solutions by a\nsignificant margin, achieving new state-of-the-art results for both in-domain\nand out-of-domain benchmark test sets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 15:51:04 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Tan", "Sang-Sang", ""], ["Na", "Jin-Cheon", ""]]}, {"id": "1910.14563", "submitter": "Pandarasamy Arjunan", "authors": "Pandarasamy Arjunan, Kameshwar Poolla, Clayton Miller", "title": "EnergyStar++: Towards more accurate and explanatory building energy\n  benchmarking", "comments": null, "journal-ref": "Applied Energy, Volume 276, 15 October 2020, 115413", "doi": "10.1016/j.apenergy.2020.115413", "report-no": null, "categories": "stat.AP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building energy performance benchmarking has been adopted widely in the USA\nand Canada through the Energy Star Portfolio Manager platform. Building\noperations and energy management professionals have long used a simple 1-100\nscore to understand how their building compares to its peers. This single\nnumber is easy to use, but is created by inaccurate linear regression (MLR)\nmodels. This paper proposes a methodology that enhances the existing Energy\nStar calculation method by increasing accuracy and providing additional model\noutput processing to help explain why a building is achieving a certain score.\nWe propose and test two new prediction models: multiple linear regression with\nfeature interactions (MLRi) and gradient boosted trees (GBT). Both models have\nbetter average accuracy than the baseline Energy Star models. The third order\nMLRi and GBT models achieve 4.9% and 24.9% increase in adjusted R2,\nrespectively, and 7.0% and 13.7% decrease in normalized root mean squared error\n(NRMSE), respectively, on average than MLR models for six building types. Even\nmore importantly, a set of techniques is developed to help determine which\nfactors most influence the score using SHAP values. The SHAP force\nvisualization in particular offers an accessible overview of the aspects of the\nbuilding that influence the score that non-technical users can readily\ninterpret. This methodology is tested on the 2012 Commercial Building Energy\nConsumption Survey (CBECS)(1,812 buildings) and public data sets from the\nenergy disclosure programs of New York City (11,131 buildings) and Seattle\n(2,073 buildings).\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 07:04:56 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 08:39:40 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Arjunan", "Pandarasamy", ""], ["Poolla", "Kameshwar", ""], ["Miller", "Clayton", ""]]}, {"id": "1910.14565", "submitter": "Mehul S. Raval", "authors": "Hiren Galiyawala, Mehul S Raval, Shivansh Dave", "title": "Visual Appearance Based Person Retrieval in Unconstrained Environment\n  Videos", "comments": "11 pages", "journal-ref": "Image and Vision Computing, 2019", "doi": "10.1016/j.imavis.2019.10.002", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual appearance-based person retrieval is a challenging problem in\nsurveillance. It uses attributes like height, cloth color, cloth type and\ngender to describe a human. Such attributes are known as soft biometrics. This\npaper proposes person retrieval from surveillance video using height, torso\ncloth type, torso cloth color and gender. The approach introduces an adaptive\ntorso patch extraction and bounding box regression to improve the retrieval.\nThe algorithm uses fine-tuned Mask R-CNN and DenseNet-169 for person detection\nand attribute classification respectively. The performance is analyzed on AVSS\n2018 challenge II dataset and it achieves 11.35% improvement over\nstate-of-the-art based on average Intersection over Union measure.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:20:33 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Galiyawala", "Hiren", ""], ["Raval", "Mehul S", ""], ["Dave", "Shivansh", ""]]}, {"id": "1910.14567", "submitter": "Jevgenij Gamper", "authors": "Michael Zotov, Jevgenij Gamper", "title": "Conditional Denoising of Remote Sensing Imagery Using Cycle-Consistent\n  Deep Generative Models", "comments": "Accepted NeurIPS AI for Social Good, 14 December 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential of using remote sensing imagery for environmental modelling and\nfor providing real time support to humanitarian operations such as hurricane\nrelief efforts is well established. These applications are substantially\naffected by missing data due to non-structural noise such as clouds, shadows\nand other atmospheric effects. In this work we probe the potential of applying\na cycle-consistent latent variable deep generative model (DGM) for denoising\ncloudy Sentinel-2 observations conditioned on the information in cloud\npenetrating bands. We adapt the recently proposed Fr\\'{e}chet Distance metric\nto remote sensing images for evaluating performance of the generator,\ndemonstrate the potential of DGMs for conditional denoising, and discuss future\ndirections as well as the limitations of DGMs in Earth science and humanitarian\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:24:30 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Zotov", "Michael", ""], ["Gamper", "Jevgenij", ""]]}, {"id": "1910.14574", "submitter": "Guy Katz", "authors": "Yizhak Yisrael Elboher, Justin Gottschlich, Guy Katz", "title": "An Abstraction-Based Framework for Neural Network Verification", "comments": "This paper appeared at CAV 2020", "journal-ref": null, "doi": "10.1007/978-3-030-53288-8_3", "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are increasingly being used as controllers for\nsafety-critical systems. Because neural networks are opaque, certifying their\ncorrectness is a significant challenge. To address this issue, several neural\nnetwork verification approaches have recently been proposed. However, these\napproaches afford limited scalability, and applying them to large networks can\nbe challenging. In this paper, we propose a framework that can enhance neural\nnetwork verification techniques by using over-approximation to reduce the size\nof the network - thus making it more amenable to verification. We perform the\napproximation such that if the property holds for the smaller (abstract)\nnetwork, it holds for the original as well. The over-approximation may be too\ncoarse, in which case the underlying verification tool might return a spurious\ncounterexample. Under such conditions, we perform counterexample-guided\nrefinement to adjust the approximation, and then repeat the process. Our\napproach is orthogonal to, and can be integrated with, many existing\nverification techniques. For evaluation purposes, we integrate it with the\nrecently proposed Marabou framework, and observe a significant improvement in\nMarabou's performance. Our experiments demonstrate the great potential of our\napproach for verifying larger neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:27:42 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 06:49:23 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Elboher", "Yizhak Yisrael", ""], ["Gottschlich", "Justin", ""], ["Katz", "Guy", ""]]}, {"id": "1910.14576", "submitter": "Raimon Fabregat", "authors": "Raimon Fabregat, Nelly Pustelnik, Paulo Gon\\c{c}alves and Pierre\n  Borgnat", "title": "Solving NMF with smoothness and sparsity constraints using PALM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization is a problem of dimensionality reduction\nand source separation of data that has been widely used in many fields since it\nwas studied in depth in 1999 by Lee and Seung, including in compression of\ndata, document clustering, processing of audio spectrograms and astronomy. In\nthis work we have adapted a minimization scheme for convex functions with\nnon-differentiable constraints called PALM to solve the NMF problem with\nsolutions that can be smooth and/or sparse, two properties frequently desired.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:29:59 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 09:04:43 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Fabregat", "Raimon", ""], ["Pustelnik", "Nelly", ""], ["Gon\u00e7alves", "Paulo", ""], ["Borgnat", "Pierre", ""]]}, {"id": "1910.14578", "submitter": "Minh-Tan Pham", "authors": "Minh-Tan Pham, S\\'ebastien Lef\\`evre", "title": "Very high resolution Airborne PolSAR Image Classification using\n  Convolutional Neural Networks", "comments": "5 pages, accepted in EUSAR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we exploit convolutional neural networks (CNNs) for the\nclassification of very high resolution (VHR) polarimetric SAR (PolSAR) data.\nDue to the significant appearance of heterogeneous textures within these data,\nnot only polarimetric features but also structural tensors are exploited to\nfeed CNN models. For deep networks, we use the SegNet model for semantic\nsegmentation, which corresponds to pixelwise classification in remote sensing.\nOur experiments on the airborne F-SAR data show that for VHR PolSAR images,\nSegNet could provide high accuracy for the classification task; and introducing\nstructural tensors together with polarimetric features as inputs could help the\nnetwork to focus more on geometrical information to significantly improve the\nclassification performance.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:32:10 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 21:13:23 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Pham", "Minh-Tan", ""], ["Lef\u00e8vre", "S\u00e9bastien", ""]]}, {"id": "1910.14594", "submitter": "Vladimir Golkov", "authors": "Luca Della Libera, Vladimir Golkov, Yue Zhu, Arman Mielke, Daniel\n  Cremers", "title": "Deep Learning for 2D and 3D Rotatable Data: An Overview of Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the reasons for the success of convolutional networks is their\nequivariance/invariance under translations. However, rotatable data such as\nmolecules, living cells, everyday objects, or galaxies require processing with\nequivariance/invariance under rotations in cases where the rotation of the\ncoordinate system does not affect the meaning of the data (e.g. object\nclassification). On the other hand, estimation/processing of rotations is\nnecessary in cases where rotations are important (e.g. motion estimation).\nThere has been recent progress in methods and theory in all these regards. Here\nwe provide an overview of existing methods, both for 2D and 3D rotations (and\ntranslations), and identify commonalities and links between them, in the hope\nthat our insights will be useful for choosing and perfecting the methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:47:46 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Della Libera", "Luca", ""], ["Golkov", "Vladimir", ""], ["Zhu", "Yue", ""], ["Mielke", "Arman", ""], ["Cremers", "Daniel", ""]]}, {"id": "1910.14599", "submitter": "Douwe Kiela", "authors": "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston,\n  Douwe Kiela", "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new large-scale NLI benchmark dataset, collected via an\niterative, adversarial human-and-model-in-the-loop procedure. We show that\ntraining models on this new dataset leads to state-of-the-art performance on a\nvariety of popular NLI benchmarks, while posing a more difficult challenge with\nits new test set. Our analysis sheds light on the shortcomings of current\nstate-of-the-art models, and shows that non-expert annotators are successful at\nfinding their weaknesses. The data collection method can be applied in a\nnever-ending learning scenario, becoming a moving target for NLU, rather than a\nstatic benchmark that will quickly saturate.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:50:43 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:01:56 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Nie", "Yixin", ""], ["Williams", "Adina", ""], ["Dinan", "Emily", ""], ["Bansal", "Mohit", ""], ["Weston", "Jason", ""], ["Kiela", "Douwe", ""]]}, {"id": "1910.14609", "submitter": "Jean-Benoit Delbrouck", "authors": "Jean-Benoit Delbrouck and Bastien Vanderplaetse and St\\'ephane Dupont", "title": "Can adversarial training learn image captioning ?", "comments": "Accepted to NeurIPS 2019 ViGiL workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, generative adversarial networks (GAN) have gathered a lot of\ninterest. Their efficiency in generating unseen samples of high quality,\nespecially images, has improved over the years. In the field of Natural\nLanguage Generation (NLG), the use of the adversarial setting to generate\nmeaningful sentences has shown to be difficult for two reasons: the lack of\nexisting architectures to produce realistic sentences and the lack of\nevaluation tools. In this paper, we propose an adversarial architecture related\nto the conditional GAN (cGAN) that generates sentences according to a given\nimage (also called image captioning). This attempt is the first that uses no\npre-training or reinforcement methods. We also explain why our experiment\nsettings can be safely evaluated and interpreted for further works.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:59:14 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Delbrouck", "Jean-Benoit", ""], ["Vanderplaetse", "Bastien", ""], ["Dupont", "St\u00e9phane", ""]]}, {"id": "1910.14613", "submitter": "Sharan Narang", "authors": "Arvind Neelakantan, Semih Yavuz, Sharan Narang, Vishaal Prasad, Ben\n  Goodrich, Daniel Duckworth, Chinnadhurai Sankar, Xifeng Yan", "title": "Neural Assistant: Joint Action Prediction, Response Generation, and\n  Latent Knowledge Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialog presents a difficult challenge encompassing multiple\nproblems including multi-turn language understanding and generation, knowledge\nretrieval and reasoning, and action prediction. Modern dialog systems typically\nbegin by converting conversation history to a symbolic object referred to as\nbelief state by using supervised learning. The belief state is then used to\nreason on an external knowledge source whose result along with the conversation\nhistory is used in action prediction and response generation tasks\nindependently. Such a pipeline of individually optimized components not only\nmakes the development process cumbersome but also makes it non-trivial to\nleverage session-level user reinforcement signals. In this paper, we develop\nNeural Assistant: a single neural network model that takes conversation history\nand an external knowledge source as input and jointly produces both text\nresponse and action to be taken by the system as output. The model learns to\nreason on the provided knowledge source with weak supervision signal coming\nfrom the text generation and the action prediction tasks, hence removing the\nneed for belief state annotations. In the MultiWOZ dataset, we study the effect\nof distant supervision, and the size of knowledge base on model performance. We\nfind that the Neural Assistant without belief states is able to incorporate\nexternal knowledge information achieving higher factual accuracy scores\ncompared to Transformer. In settings comparable to reported baseline systems,\nNeural Assistant when provided with oracle belief state significantly improves\nlanguage generation performance.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:01:24 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Neelakantan", "Arvind", ""], ["Yavuz", "Semih", ""], ["Narang", "Sharan", ""], ["Prasad", "Vishaal", ""], ["Goodrich", "Ben", ""], ["Duckworth", "Daniel", ""], ["Sankar", "Chinnadhurai", ""], ["Yan", "Xifeng", ""]]}, {"id": "1910.14616", "submitter": "Peiyuan Zhang", "authors": "Peiyuan Zhang, Hadi Daneshmand, Thomas Hofmann", "title": "Mixing of Stochastic Accelerated Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the mixing properties for stochastic accelerated gradient descent\n(SAGD) on least-squares regression. First, we show that stochastic gradient\ndescent (SGD) and SAGD are simulating the same invariant distribution.\nMotivated by this, we then establish mixing rate for SAGD-iterates and compare\nit with those of SGD-iterates. Theoretically, we prove that the chain of SAGD\niterates is geometrically ergodic --using a proper choice of parameters and\nunder regularity assumptions on the input distribution. More specifically, we\nderive an explicit mixing rate depending on the first 4 moments of the data\ndistribution. By means of illustrative examples, we prove that SAGD-iterate\nchain mixes faster than the chain of iterates obtained by SGD. Furthermore, we\nhighlight applications of the established mixing rate in the convergence\nanalysis of SAGD on realizable objectives. The proposed analysis is based on a\nnovel non-asymptotic analysis of products of random matrices. This theoretical\nresult is substantiated and validated by experiments.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:03:30 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Zhang", "Peiyuan", ""], ["Daneshmand", "Hadi", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1910.14634", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel and Mahdi Soltanolkotabi", "title": "Denoising and Regularization via Exploiting the Structural Bias of\n  Convolutional Generators", "comments": "final ICRL version; simplifications in the proof", "journal-ref": "International Conference on Learning Representations (ICLR) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have emerged as highly successful tools\nfor image generation, recovery, and restoration. A major contributing factor to\nthis success is that convolutional networks impose strong prior assumptions\nabout natural images. A surprising experiment that highlights this\narchitectural bias towards natural images is that one can remove noise and\ncorruptions from a natural image without using any training data, by simply\nfitting (via gradient descent) a randomly initialized, over-parameterized\nconvolutional generator to the corrupted image. While this over-parameterized\nnetwork can fit the corrupted image perfectly, surprisingly after a few\niterations of gradient descent it generates an almost uncorrupted image. This\nintriguing phenomenon enables state-of-the-art CNN-based denoising and\nregularization of other inverse problems. In this paper, we attribute this\neffect to a particular architectural choice of convolutional networks, namely\nconvolutions with fixed interpolating filters. We then formally characterize\nthe dynamics of fitting a two-layer convolutional generator to a noisy signal\nand prove that early-stopped gradient descent denoises/regularizes. Our proof\nrelies on showing that convolutional generators fit the structured part of an\nimage significantly faster than the corrupted portion.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:22:00 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 01:49:25 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Heckel", "Reinhard", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "1910.14655", "submitter": "Huan Zhang", "authors": "Huan Zhang, Minhao Cheng, Cho-Jui Hsieh", "title": "Enhancing Certifiable Robustness via a Deep Model Ensemble", "comments": "This is an extended version of ICLR 2019 Safe Machine Learning\n  Workshop (SafeML) paper, \"RobBoost: A provable approach to boost the\n  robustness of deep model ensemble\". May 6, 2019, New Orleans, LA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm to enhance certified robustness of a deep model\nensemble by optimally weighting each base model. Unlike previous works on using\nensembles to empirically improve robustness, our algorithm is based on\noptimizing a guaranteed robustness certificate of neural networks. Our proposed\nensemble framework with certified robustness, RobBoost, formulates the optimal\nmodel selection and weighting task as an optimization problem on a lower bound\nof classification margin, which can be efficiently solved using coordinate\ndescent. Experiments show that our algorithm can form a more robust ensemble\nthan naively averaging all available models using robustly trained MNIST or\nCIFAR base models. Additionally, our ensemble typically has better accuracy on\nclean (unperturbed) data. RobBoost allows us to further improve certified\nrobustness and clean accuracy by creating an ensemble of already certified\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:48:33 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Zhang", "Huan", ""], ["Cheng", "Minhao", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1910.14659", "submitter": "Julian Salazar", "authors": "Julian Salazar, Davis Liang, Toan Q. Nguyen, Katrin Kirchhoff", "title": "Masked Language Model Scoring", "comments": "ACL 2020 camera-ready (presented July 2020)", "journal-ref": "Proceedings of the 58th Annual Meeting of the Association for\n  Computational Linguistics (2020), 2699-2712", "doi": "10.18653/v1/2020.acl-main.240", "report-no": null, "categories": "cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained masked language models (MLMs) require finetuning for most NLP\ntasks. Instead, we evaluate MLMs out of the box via their pseudo-log-likelihood\nscores (PLLs), which are computed by masking tokens one by one. We show that\nPLLs outperform scores from autoregressive language models like GPT-2 in a\nvariety of tasks. By rescoring ASR and NMT hypotheses, RoBERTa reduces an\nend-to-end LibriSpeech model's WER by 30% relative and adds up to +1.7 BLEU on\nstate-of-the-art baselines for low-resource translation pairs, with further\ngains from domain adaptation. We attribute this success to PLL's unsupervised\nexpression of linguistic acceptability without a left-to-right bias, greatly\nimproving on scores from GPT-2 (+10 points on island effects, NPI licensing in\nBLiMP). One can finetune MLMs to give scores without masking, enabling\ncomputation in a single inference pass. In all, PLLs and their associated\npseudo-perplexities (PPPLs) enable plug-and-play use of the growing number of\npretrained MLMs; e.g., we use a single cross-lingual model to rescore\ntranslations in multiple languages. We release our library for language model\nscoring at https://github.com/awslabs/mlm-scoring.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:51:21 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 17:55:10 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 00:00:14 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Salazar", "Julian", ""], ["Liang", "Davis", ""], ["Nguyen", "Toan Q.", ""], ["Kirchhoff", "Katrin", ""]]}, {"id": "1910.14667", "submitter": "Zuxuan Wu", "authors": "Zuxuan Wu, Ser-Nam Lim, Larry Davis, Tom Goldstein", "title": "Making an Invisibility Cloak: Real World Adversarial Attacks on Object\n  Detectors", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a systematic study of adversarial attacks on state-of-the-art\nobject detection frameworks. Using standard detection datasets, we train\npatterns that suppress the objectness scores produced by a range of commonly\nused detectors, and ensembles of detectors. Through extensive experiments, we\nbenchmark the effectiveness of adversarially trained patches under both\nwhite-box and black-box settings, and quantify transferability of attacks\nbetween datasets, object classes, and detector models. Finally, we present a\ndetailed study of physical world attacks using printed posters and wearable\nclothes, and rigorously quantify the performance of such attacks with different\nmetrics.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:56:29 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 17:59:49 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Wu", "Zuxuan", ""], ["Lim", "Ser-Nam", ""], ["Davis", "Larry", ""], ["Goldstein", "Tom", ""]]}, {"id": "1910.14670", "submitter": "Colin Graber", "authors": "Colin Graber, Alexander Schwing", "title": "Graph Structured Prediction Energy Networks", "comments": "Appearing in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For joint inference over multiple variables, a variety of structured\nprediction techniques have been developed to model correlations among variables\nand thereby improve predictions. However, many classical approaches suffer from\none of two primary drawbacks: they either lack the ability to model high-order\ncorrelations among variables while maintaining computationally tractable\ninference, or they do not allow to explicitly model known correlations. To\naddress this shortcoming, we introduce `Graph Structured Prediction Energy\nNetworks,' for which we develop inference techniques that allow to both model\nexplicit local and implicit higher-order correlations while maintaining\ntractability of inference. We apply the proposed method to tasks from the\nnatural language processing and computer vision domain and demonstrate its\ngeneral utility.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:59:57 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 17:52:18 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Graber", "Colin", ""], ["Schwing", "Alexander", ""]]}, {"id": "1910.14671", "submitter": "Jingxiang Lin", "authors": "Jingxiang Lin, Unnat Jain, Alexander G. Schwing", "title": "TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning\n  Baselines", "comments": "Accepted to NeurIPS 2019. Project page:\n  https://deanplayerljx.github.io/tabvcr", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reasoning is an important ability that we learn from a very early age. Yet,\nreasoning is extremely hard for algorithms. Despite impressive recent progress\nthat has been reported on tasks that necessitate reasoning, such as visual\nquestion answering and visual dialog, models often exploit biases in datasets.\nTo develop models with better reasoning abilities, recently, the new visual\ncommonsense reasoning (VCR) task has been introduced. Not only do models have\nto answer questions, but also do they have to provide a reason for the given\nanswer. The proposed baseline achieved compelling results, leveraging a\nmeticulously designed model composed of LSTM modules and attention nets. Here\nwe show that a much simpler model obtained by ablating and pruning the existing\nintricate baseline can perform better with half the number of trainable\nparameters. By associating visual features with attribute information and\nbetter text to image grounding, we obtain further improvements for our simpler\n& effective baseline, TAB-VCR. We show that this approach results in a 5.3%,\n4.4% and 6.5% absolute improvement over the previous state-of-the-art on\nquestion answering, answer justification and holistic VCR.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:59:57 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 15:55:26 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Lin", "Jingxiang", ""], ["Jain", "Unnat", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "1910.14673", "submitter": "Tiantian Fang", "authors": "Tiantian Fang and Alexander G. Schwing", "title": "Co-Generation with GANs using AIS based HMC", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inferring the most likely configuration for a subset of variables of a joint\ndistribution given the remaining ones - which we refer to as co-generation - is\nan important challenge that is computationally demanding for all but the\nsimplest settings. This task has received a considerable amount of attention,\nparticularly for classical ways of modeling distributions like structured\nprediction. In contrast, almost nothing is known about this task when\nconsidering recently proposed techniques for modeling high-dimensional\ndistributions, particularly generative adversarial nets (GANs). Therefore, in\nthis paper, we study the occurring challenges for co-generation with GANs. To\naddress those challenges we develop an annealed importance sampling based\nHamiltonian Monte Carlo co-generation algorithm. The presented approach\nsignificantly outperforms classical gradient based methods on a synthetic and\non the CelebA and LSUN datasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:59:59 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Fang", "Tiantian", ""], ["Schwing", "Alexander G.", ""]]}]