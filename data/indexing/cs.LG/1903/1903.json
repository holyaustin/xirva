[{"id": "1903.00001", "submitter": "Heyi Li", "authors": "Heyi Li, Dongdong Chen, William H. Nailon, Mike E. Davies and Dave\n  Laurenson", "title": "A Deep DUAL-PATH Network for Improved Mammogram Image Processing", "comments": "To Appear in ICCASP 2019 May", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present, for the first time, a novel deep neural network architecture\ncalled \\dcn with a dual-path connection between the input image and output\nclass label for mammogram image processing. This architecture is built upon\nU-Net, which non-linearly maps the input data into a deep latent space. One\npath of the \\dcnn, the locality preserving learner, is devoted to\nhierarchically extracting and exploiting intrinsic features of the input, while\nthe other path, called the conditional graph learner, focuses on modeling the\ninput-mask correlations. The learned mask is further used to improve\nclassification results, and the two learning paths complement each other. By\nintegrating the two learners our new architecture provides a simple but\neffective way to jointly learn the segmentation and predict the class label.\nBenefiting from the powerful expressive capacity of deep neural networks a more\ndiscriminative representation can be learned, in which both the semantics and\nstructure are well preserved. Experimental results show that \\dcn achieves the\nbest mammography segmentation and classification simultaneously, outperforming\nrecent state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 11:51:47 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Li", "Heyi", ""], ["Chen", "Dongdong", ""], ["Nailon", "William H.", ""], ["Davies", "Mike E.", ""], ["Laurenson", "Dave", ""]]}, {"id": "1903.00027", "submitter": "Sergey Kolesnikov", "authors": "Sergey Kolesnikov, Oleksii Hrinchuk", "title": "Catalyst.RL: A Distributed Framework for Reproducible RL Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent progress in deep reinforcement learning field (RL), and,\narguably because of it, a large body of work remains to be done in reproducing\nand carefully comparing different RL algorithms. We present catalyst.RL, an\nopen source framework for RL research with a focus on reproducibility and\nflexibility. Main features of our library include large-scale asynchronous\ndistributed training, easy-to-use configuration files with the complete list of\nhyperparameters for the particular experiments, efficient implementations of\nvarious RL algorithms and auxiliary tricks, such as frame stacking, n-step\nreturns, value distributions, etc. To vindicate the usefulness of our\nframework, we evaluate it on a range of benchmarks in a continuous control, as\nwell as on the task of developing a controller to enable a\nphysiologically-based human model with a prosthetic leg to walk and run. The\nlatter task was introduced at NeurIPS 2018 AI for Prosthetics Challenge, where\nour team took the 3rd place, capitalizing on the ability of catalyst.RL to\ntrain high-quality and sample-efficient RL agents.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 19:06:00 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Kolesnikov", "Sergey", ""], ["Hrinchuk", "Oleksii", ""]]}, {"id": "1903.00035", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Lin Yang, Hao Zheng, Peixian Liang, Colleen Mangold,\n  Raquel G. Loreto, David P. Hughes, Danny Z. Chen", "title": "SPDA: Superpixel-based Data Augmentation for Biomedical Image\n  Segmentation", "comments": "To appear in MIDL2019 and PMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised training a deep neural network aims to \"teach\" the network to\nmimic human visual perception that is represented by image-and-label pairs in\nthe training data. Superpixelized (SP) images are visually perceivable to\nhumans, but a conventionally trained deep learning model often performs poorly\nwhen working on SP images. To better mimic human visual perception, we think it\nis desirable for the deep learning model to be able to perceive not only raw\nimages but also SP images. In this paper, we propose a new superpixel-based\ndata augmentation (SPDA) method for training deep learning models for\nbiomedical image segmentation. Our method applies a superpixel generation\nscheme to all the original training images to generate superpixelized images.\nThe SP images thus obtained are then jointly used with the original training\nimages to train a deep learning model. Our experiments of SPDA on four\nbiomedical image datasets show that SPDA is effective and can consistently\nimprove the performance of state-of-the-art fully convolutional networks for\nbiomedical image segmentation in 2D and 3D images. Additional studies also\ndemonstrate that SPDA can practically reduce the generalization gap.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 19:17:51 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Zhang", "Yizhe", ""], ["Yang", "Lin", ""], ["Zheng", "Hao", ""], ["Liang", "Peixian", ""], ["Mangold", "Colleen", ""], ["Loreto", "Raquel G.", ""], ["Hughes", "David P.", ""], ["Chen", "Danny Z.", ""]]}, {"id": "1903.00045", "submitter": "Tian Guo", "authors": "Shijian Li and Robert J. Walls and Lijie Xu and Tian Guo", "title": "Speeding up Deep Learning with Transient Servers", "comments": "Accepted to ICAC'19. 11 pages, 8 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed training frameworks, like TensorFlow, have been proposed as a\nmeans to reduce the training time of deep learning models by using a cluster of\nGPU servers. While such speedups are often desirable---e.g., for rapidly\nevaluating new model designs---they often come with significantly higher\nmonetary costs due to sublinear scalability. In this paper, we investigate the\nfeasibility of using training clusters composed of cheaper transient GPU\nservers to get the benefits of distributed training without the high costs.\n  We conduct the first large-scale empirical analysis, launching more than a\nthousand GPU servers of various capacities, aimed at understanding the\ncharacteristics of transient GPU servers and their impact on distributed\ntraining performance. Our study demonstrates the potential of transient servers\nwith a speedup of 7.7X with more than 62.9% monetary savings for some cluster\nconfigurations. We also identify a number of important challenges and\nopportunities for redesigning distributed training frameworks to be\ntransient-aware. For example, the dynamic cost and availability characteristics\nof transient servers suggest the need for frameworks to dynamically change\ncluster configurations to best take advantage of current conditions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 19:47:59 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 07:20:37 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Li", "Shijian", ""], ["Walls", "Robert J.", ""], ["Xu", "Lijie", ""], ["Guo", "Tian", ""]]}, {"id": "1903.00049", "submitter": "Maciej  Skorski", "authors": "Maciej Skorski", "title": "Bounds on Bayes Factors for Binomial A/B Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayes factors, in many cases, have been proven to bridge the classic -value\nbased significance testing and bayesian analysis of posterior odds. This paper\ndiscusses this phenomena within the binomial A/B testing setup (applicable for\nexample to conversion testing). It is shown that the bayes factor is controlled\nby the \\emph{Jensen-Shannon divergence} of success ratios in two tested groups,\nwhich can be further bounded by the Welch statistic. As a result, bayesian\nsample bounds almost match frequentionist's sample bounds. The link between\nJensen-Shannon divergence and Welch's test as well as the derivation are an\nelegant application of tools from information geometry.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 20:06:02 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "1903.00058", "submitter": "Ankur Bapna", "authors": "Ankur Bapna and Orhan Firat", "title": "Non-Parametric Adaptation for Neural Machine Translation", "comments": "Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks trained with gradient descent are known to be susceptible to\ncatastrophic forgetting caused by parameter shift during the training process.\nIn the context of Neural Machine Translation (NMT) this results in poor\nperformance on heterogeneous datasets and on sub-tasks like rare phrase\ntranslation. On the other hand, non-parametric approaches are immune to\nforgetting, perfectly complementing the generalization ability of NMT. However,\nattempts to combine non-parametric or retrieval based approaches with NMT have\nonly been successful on narrow domains, possibly due to over-reliance on\nsentence level retrieval. We propose a novel n-gram level retrieval approach\nthat relies on local phrase level similarities, allowing us to retrieve\nneighbors that are useful for translation even when overall sentence similarity\nis low. We complement this with an expressive neural network, allowing our\nmodel to extract information from the noisy retrieved context. We evaluate our\nsemi-parametric NMT approach on a heterogeneous dataset composed of WMT, IWSLT,\nJRC-Acquis and OpenSubtitles, and demonstrate gains on all 4 evaluation sets.\nThe semi-parametric nature of our approach opens the door for non-parametric\ndomain adaptation, demonstrating strong inference-time adaptation performance\non new domains without the need for any parameter updates.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 20:33:00 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 18:57:37 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Bapna", "Ankur", ""], ["Firat", "Orhan", ""]]}, {"id": "1903.00066", "submitter": "Ting Bai", "authors": "Ting Bai and Pan Du and Wayne Xin Zhao and Ji-Rong Wen and Jian-Yun\n  Nie", "title": "A Long-Short Demands-Aware Model for Next-Item Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommending the right products is the central problem in recommender\nsystems, but the right products should also be recommended at the right time to\nmeet the demands of users, so as to maximize their values. Users' demands,\nimplying strong purchase intents, can be the most useful way to promote\nproducts sales if well utilized. Previous recommendation models mainly focused\non user's general interests to find the right products. However, the aspect of\nmeeting users' demands at the right time has been much less explored. To\naddress this problem, we propose a novel Long-Short Demands-aware Model (LSDM),\nin which both user's interests towards items and user's demands over time are\nincorporated. We summarize two aspects: termed as long-time demands (e.g.,\npurchasing the same product repetitively showing a long-time persistent\ninterest) and short-time demands (e.g., co-purchase like buying paintbrushes\nafter pigments). To utilize such long-short demands of users, we create\ndifferent clusters to group the successive product purchases together according\nto different time spans, and use recurrent neural networks to model each\nsequence of clusters at a time scale. The long-short purchase demands with\nmulti-time scales are finally aggregated by joint learning strategies.\nExperimental results on three real-world commerce datasets demonstrate the\neffectiveness of our model for next-item recommendation, showing the usefulness\nof modeling users' long-short purchase demands of items with multi-time scales.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 07:41:56 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Bai", "Ting", ""], ["Du", "Pan", ""], ["Zhao", "Wayne Xin", ""], ["Wen", "Ji-Rong", ""], ["Nie", "Jian-Yun", ""]]}, {"id": "1903.00068", "submitter": "Xinyun Zou", "authors": "Xinyun Zou, Soheil Kolouri, Praveen K. Pilly, Jeffrey L. Krichmar", "title": "Neuromodulated Goal-Driven Perception in Uncertain Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In uncertain domains, the goals are often unknown and need to be predicted by\nthe organism or system. In this paper, contrastive excitation backprop (c-EB)\nwas used in a goal-driven perception task with pairs of noisy MNIST digits,\nwhere the system had to increase attention to one of the two digits\ncorresponding to a goal (i.e., even, odd, low value, or high value) and\ndecrease attention to the distractor digit or noisy background pixels. Because\nthe valid goal was unknown, an online learning model based on the cholinergic\nand noradrenergic neuromodulatory systems was used to predict a noisy goal\n(expected uncertainty) and re-adapt when the goal changed (unexpected\nuncertainty). This neurobiologically plausible model demonstrates how\nneuromodulatory systems can predict goals in uncertain domains and how\nattentional mechanisms can enhance the perception of that goal.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 19:46:09 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Zou", "Xinyun", ""], ["Kolouri", "Soheil", ""], ["Pilly", "Praveen K.", ""], ["Krichmar", "Jeffrey L.", ""]]}, {"id": "1903.00070", "submitter": "Binghong Chen", "authors": "Binghong Chen, Bo Dai, Qinjie Lin, Guo Ye, Han Liu, Le Song", "title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation\n  Trees", "comments": "26 pages, 74 figures, ICLR 2020 spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a meta path planning algorithm named \\emph{Neural\nExploration-Exploitation Trees~(NEXT)} for learning from prior experience for\nsolving new path planning problems in high dimensional continuous state and\naction spaces. Compared to more classical sampling-based methods like RRT, our\napproach achieves much better sample efficiency in high-dimensions and can\nbenefit from prior experience of planning in similar environments. More\nspecifically, NEXT exploits a novel neural architecture which can learn\npromising search directions from problem structures. The learned prior is then\nintegrated into a UCB-type algorithm to achieve an online balance between\n\\emph{exploration} and \\emph{exploitation} when solving a new problem. We\nconduct thorough experiments to show that NEXT accomplishes new planning\nproblems with more compact search trees and significantly outperforms\nstate-of-the-art methods on several benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 20:53:13 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 18:48:51 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 21:59:45 GMT"}, {"version": "v4", "created": "Sun, 23 Feb 2020 08:49:42 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Chen", "Binghong", ""], ["Dai", "Bo", ""], ["Lin", "Qinjie", ""], ["Ye", "Guo", ""], ["Liu", "Han", ""], ["Song", "Le", ""]]}, {"id": "1903.00073", "submitter": "Yash Sharma", "authors": "Yash Sharma, Gavin Weiguang Ding, Marcus Brubaker", "title": "On the Effectiveness of Low Frequency Perturbations", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carefully crafted, often imperceptible, adversarial perturbations have been\nshown to cause state-of-the-art models to yield extremely inaccurate outputs,\nrendering them unsuitable for safety-critical application domains. In addition,\nrecent work has shown that constraining the attack space to a low frequency\nregime is particularly effective. Yet, it remains unclear whether this is due\nto generally constraining the attack search space or specifically removing high\nfrequency components from consideration. By systematically controlling the\nfrequency components of the perturbation, evaluating against the top-placing\ndefense submissions in the NeurIPS 2017 competition, we empirically show that\nperformance improvements in both the white-box and black-box transfer settings\nare yielded only when low frequency components are preserved. In fact, the\ndefended models based on adversarial training are roughly as vulnerable to low\nfrequency perturbations as undefended models, suggesting that the purported\nrobustness of state-of-the-art ImageNet defenses is reliant upon adversarial\nperturbations being high frequency in nature. We do find that under\n$\\ell_\\infty$ $\\epsilon=16/255$, the competition distortion bound, low\nfrequency perturbations are indeed perceptible. This questions the use of the\n$\\ell_\\infty$-norm, in particular, as a distortion metric, and, in turn,\nsuggests that explicitly considering the frequency space is promising for\nlearning robust models which better align with human perception.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 21:25:45 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 00:36:16 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Sharma", "Yash", ""], ["Ding", "Gavin Weiguang", ""], ["Brubaker", "Marcus", ""]]}, {"id": "1903.00091", "submitter": "Prakash Mohan", "authors": "Prakash Mohan, Marc T. Henry de Frahan, Ryan King, Ray W. Grout", "title": "A block-random algorithm for learning on distributed, heterogeneous data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep learning models are based on deep neural networks with multiple\nlayers between input and output. The parameters defining these layers are\ninitialized using random values and are \"learned\" from data, typically using\nstochastic gradient descent based algorithms. These algorithms rely on data\nbeing randomly shuffled before optimization. The randomization of the data\nprior to processing in batches that is formally required for stochastic\ngradient descent algorithm to effectively derive a useful deep learning model\nis expected to be prohibitively expensive for in situ model training because of\nthe resulting data communications across the processor nodes. We show that the\nstochastic gradient descent (SGD) algorithm can still make useful progress if\nthe batches are defined on a per-processor basis and processed in random order\neven though (i) the batches are constructed from data samples from a single\nclass or specific flow region, and (ii) the overall data samples are\nheterogeneous. We present block-random gradient descent, a new algorithm that\nworks on distributed, heterogeneous data without having to pre-shuffle. This\nalgorithm enables in situ learning for exascale simulations. The performance of\nthis algorithm is demonstrated on a set of benchmark classification models and\nthe construction of a subgrid scale large eddy simulations (LES) model for\nturbulent channel flow using a data model similar to that which will be\nencountered in exascale simulation.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 22:28:37 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Mohan", "Prakash", ""], ["de Frahan", "Marc T. Henry", ""], ["King", "Ryan", ""], ["Grout", "Ray W.", ""]]}, {"id": "1903.00092", "submitter": "Rohan Kodialam", "authors": "Rohan Kodialam", "title": "Optimal Algorithms for Ski Rental with Soft Machine-Learned Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the classic Ski Rental online algorithm with\napplications to machine learning. In our variant, we allow the skier access to\na black-box machine-learning algorithm that provides an estimate of the\nprobability that there will be at most a threshold number of ski-days. We\nderive a class of optimal randomized algorithms to determine the strategy that\nminimizes the worst-case expected competitive ratio for the skier given a\nprediction from the machine learning algorithm,and analyze the performance and\nrobustness of these algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 22:34:46 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 20:29:57 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kodialam", "Rohan", ""]]}, {"id": "1903.00095", "submitter": "Sebastiano Barbieri", "authors": "Sebastiano Barbieri, Oliver J. Gurney-Champion, Remy Klaassen, Harriet\n  C. Thoeny", "title": "Deep Learning How to Fit an Intravoxel Incoherent Motion Model to\n  Diffusion-Weighted MRI", "comments": null, "journal-ref": "Magnetic Resonance in Medicine 2019", "doi": "10.1002/mrm.27910", "report-no": null, "categories": "q-bio.QM cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: This prospective clinical study assesses the feasibility of training\na deep neural network (DNN) for intravoxel incoherent motion (IVIM) model\nfitting to diffusion-weighted magnetic resonance imaging (DW-MRI) data and\nevaluates its performance. Methods: In May 2011, ten male volunteers (age\nrange: 29 to 53 years, mean: 37 years) underwent DW-MRI of the upper abdomen on\n1.5T and 3.0T magnetic resonance scanners. Regions of interest in the left and\nright liver lobe, pancreas, spleen, renal cortex, and renal medulla were\ndelineated independently by two readers. DNNs were trained for IVIM model\nfitting using these data; results were compared to least-squares and Bayesian\napproaches to IVIM fitting. Intraclass Correlation Coefficients (ICC) were used\nto assess consistency of measurements between readers. Intersubject variability\nwas evaluated using Coefficients of Variation (CV). The fitting error was\ncalculated based on simulated data and the average fitting time of each method\nwas recorded. Results: DNNs were trained successfully for IVIM parameter\nestimation. This approach was associated with high consistency between the two\nreaders (ICCs between 50 and 97%), low intersubject variability of estimated\nparameter values (CVs between 9.2 and 28.4), and the lowest error when compared\nwith least-squares and Bayesian approaches. Fitting by DNNs was several orders\nof magnitude quicker than the other methods but the networks may need to be\nre-trained for different acquisition protocols or imaged anatomical regions.\nConclusion: DNNs are recommended for accurate and robust IVIM model fitting to\nDW-MRI data. Suitable software is available at (1).\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 22:42:02 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 08:17:04 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Barbieri", "Sebastiano", ""], ["Gurney-Champion", "Oliver J.", ""], ["Klaassen", "Remy", ""], ["Thoeny", "Harriet C.", ""]]}, {"id": "1903.00099", "submitter": "Peng Jiang", "authors": "Peng Jiang and Yingrui Yang (co-first authors), Gann Bierner, Fengjie\n  Alex Li, Ruhan Wang, Azadeh Moghtaderi", "title": "Ranking in Genealogy: Search Results Fusion at Ancestry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Genealogy research is the study of family history using available resources\nsuch as historical records. Ancestry provides its customers with one of the\nworld's largest online genealogical index with billions of records from a wide\nrange of sources, including vital records such as birth and death certificates,\ncensus records, court and probate records among many others. Search at Ancestry\naims to return relevant records from various record types, allowing our\nsubscribers to build their family trees, research their family history, and\nmake meaningful discoveries about their ancestors from diverse perspectives. In\na modern search engine designed for genealogical study, the appropriate ranking\nof search results to provide highly relevant information represents a daunting\nchallenge. In particular, the disparity in historical records makes it\ninherently difficult to score records in an equitable fashion. Herein, we\nprovide an overview of our solutions to overcome such record disparity problems\nin the Ancestry search engine. Specifically, we introduce customized coordinate\nascent (customized CA) to speed up ranking within a specific record type. We\nthen propose stochastic search (SS) that linearly combines ranked results\nfederated across contents from various record types. Furthermore, we propose a\nnovel information retrieval metric, normalized cumulative entropy (NCE), to\nmeasure the diversity of results. We demonstrate the effectiveness of these two\nalgorithms in terms of relevance (by NDCG) and diversity (by NCE) if applicable\nin the offline experiments using real customer data at Ancestry.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 08:02:33 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Jiang", "Peng", "", "co-first authors"], ["Yang", "Yingrui", "", "co-first authors"], ["Bierner", "Gann", ""], ["Li", "Fengjie Alex", ""], ["Wang", "Ruhan", ""], ["Moghtaderi", "Azadeh", ""]]}, {"id": "1903.00100", "submitter": "Shaojie Xu", "authors": "Shaojie Xu, Anvesha Amaravati, Justin Romberg, Arijit Raychowdhury", "title": "Appearance-based Gesture recognition in the compressed domain", "comments": "arXiv admin note: text overlap with arXiv:1605.08313", "journal-ref": "2017 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), New Orleans, LA, 2017, pp. 1722-1726", "doi": "10.1109/ICASSP.2017.7952451", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel appearance-based gesture recognition algorithm using\ncompressed domain signal processing techniques. Gesture features are extracted\ndirectly from the compressed measurements, which are the block averages and the\ncoded linear combinations of the image sensor's pixel values. We also improve\nboth the computational efficiency and the memory requirement of the previous\nDTW-based K-NN gesture classifiers. Both simulation testing and hardware\nimplementation strongly support the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 06:05:12 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Xu", "Shaojie", ""], ["Amaravati", "Anvesha", ""], ["Romberg", "Justin", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "1903.00102", "submitter": "Raffi Al-Qurran Raffi", "authors": "Ghadeer Al-Bdour, Raffi Al-Qurran, Mahmoud Al-Ayyoub, Ali Shatnawi", "title": "A detailed comparative study of open source deep learning frameworks", "comments": "26 pages, 25 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) is one of the hottest trends in machine learning as DL\napproaches produced results superior to the state-of-the-art in problematic\nareas such as image processing and natural language processing (NLP). To foster\nthe growth of DL, several open source frameworks appeared providing\nimplementations of the most common DL algorithms. These frameworks vary in the\nalgorithms they support and in the quality of their implementations. The\npurpose of this work is to provide a qualitative and quantitative comparison\namong three of the most popular and most comprehensive DL frameworks (namely\nGoogle's TensorFlow, University of Montreal's Theano and Microsoft's CNTK). The\nultimate goal of this work is to help end users make an informed decision about\nthe best DL framework that suits their needs and resources. To ensure that our\nstudy is as comprehensive as possible, we conduct several experiments using\nmultiple benchmark datasets from different fields (image processing, NLP, etc.)\nand measure the performance of the frameworks' implementations of different DL\nalgorithms. For most of our experiments, we find out that CNTK's\nimplementations are superior to the other ones under consideration.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 20:10:54 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 11:57:54 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Al-Bdour", "Ghadeer", ""], ["Al-Qurran", "Raffi", ""], ["Al-Ayyoub", "Mahmoud", ""], ["Shatnawi", "Ali", ""]]}, {"id": "1903.00103", "submitter": "Xiaorui Wu", "authors": "Xiaorui Wu, Hong Xu, Honglin Zhang, Huaming Chen, Jian Wang", "title": "Saec: Similarity-Aware Embedding Compression in Recommendation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Production recommendation systems rely on embedding methods to represent\nvarious features. An impeding challenge in practice is that the large embedding\nmatrix incurs substantial memory footprint in serving as the number of features\ngrows over time. We propose a similarity-aware embedding matrix compression\nmethod called Saec to address this challenge. Saec clusters similar features\nwithin a field to reduce the embedding matrix size. Saec also adopts a fast\nclustering optimization based on feature frequency to drastically improve\nclustering time. We implement and evaluate Saec on Numerous, the production\ndistributed machine learning system in Tencent, with 10-day worth of feature\ndata from QQ mobile browser. Testbed experiments show that Saec reduces the\nnumber of embedding vectors by two orders of magnitude, compresses the\nembedding size by ~27x, and delivers the same AUC and log loss performance.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 05:00:22 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Wu", "Xiaorui", ""], ["Xu", "Hong", ""], ["Zhang", "Honglin", ""], ["Chen", "Huaming", ""], ["Wang", "Jian", ""]]}, {"id": "1903.00114", "submitter": "Clement Lee", "authors": "Clement Lee and Darren J Wilkinson", "title": "A Review of Stochastic Block Models and Extensions for Graph Clustering", "comments": "93 pages, 3 figures, 4 tables", "journal-ref": null, "doi": "10.1007/s41109-019-0232-2", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There have been rapid developments in model-based clustering of graphs, also\nknown as block modelling, over the last ten years or so. We review different\napproaches and extensions proposed for different aspects in this area, such as\nthe type of the graph, the clustering approach, the inference approach, and\nwhether the number of groups is selected or estimated. We also review models\nthat combine block modelling with topic modelling and/or longitudinal\nmodelling, regarding how these models deal with multiple types of data. How\ndifferent approaches cope with various issues will be summarised and compared,\nto facilitate the demand of practitioners for a concise overview of the current\nstatus of these areas of literature.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 00:30:09 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 20:46:20 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Lee", "Clement", ""], ["Wilkinson", "Darren J", ""]]}, {"id": "1903.00142", "submitter": "Steven Spratley", "authors": "Steven Spratley, Daniel Beck, and Trevor Cohn", "title": "A Unified Neural Architecture for Instrumental Audio Tasks", "comments": "To appear in Proc. ICASSP 2019, May 12-17, Brighton, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within Music Information Retrieval (MIR), prominent tasks -- including\npitch-tracking, source-separation, super-resolution, and synthesis -- typically\ncall for specialised methods, despite their similarities. Conditional\nGenerative Adversarial Networks (cGANs) have been shown to be highly versatile\nin learning general image-to-image translations, but have not yet been adapted\nacross MIR. In this work, we present an end-to-end supervisable architecture to\nperform all aforementioned audio tasks, consisting of a WaveNet synthesiser\nconditioned on the output of a jointly-trained cGAN spectrogram translator. In\ndoing so, we demonstrate the potential of such flexible techniques to unify MIR\ntasks, promote efficient transfer learning, and converge research to the\nimprovement of powerful, general methods. Finally, to the best of our\nknowledge, we present the first application of GANs to guided instrument\nsynthesis.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 03:28:54 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Spratley", "Steven", ""], ["Beck", "Daniel", ""], ["Cohn", "Trevor", ""]]}, {"id": "1903.00156", "submitter": "Nazgol Tavabi", "authors": "Nazgol Tavabi, Nathan Bartley, Andr\\'es Abeliuk, Sandeep Soni, Emilio\n  Ferrara, Kristina Lerman", "title": "Characterizing Activity on the Deep and Dark Web", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep and darkweb (d2web) refers to limited access web sites that require\nregistration, authentication, or more complex encryption protocols to access\nthem. These web sites serve as hubs for a variety of illicit activities: to\ntrade drugs, stolen user credentials, hacking tools, and to coordinate attacks\nand manipulation campaigns. Despite its importance to cyber crime, the d2web\nhas not been systematically investigated. In this paper, we study a large\ncorpus of messages posted to 80 d2web forums over a period of more than a year.\nWe identify topics of discussion using LDA and use a non-parametric HMM to\nmodel the evolution of topics across forums. Then, we examine the dynamic\npatterns of discussion and identify forums with similar patterns. We show that\nour approach surfaces hidden similarities across different forums and can help\nidentify anomalous events in this rich, heterogeneous data.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 05:01:04 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Tavabi", "Nazgol", ""], ["Bartley", "Nathan", ""], ["Abeliuk", "Andr\u00e9s", ""], ["Soni", "Sandeep", ""], ["Ferrara", "Emilio", ""], ["Lerman", "Kristina", ""]]}, {"id": "1903.00182", "submitter": "Junhao Hua", "authors": "Junhao Hua, Chunguang Li", "title": "Distributed Variational Bayesian Algorithms for Extended Object Tracking", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the problem of distributed extended object\ntracking, which aims to collaboratively estimate the state and extension of an\nobject by a network of nodes. In traditional tracking applications, most\napproaches consider an object as a point source of measurements due to limited\nsensor resolution capabilities. Recently, some studies consider the extended\nobjects, which are spatially structured, i.e., multiple resolution cells are\noccupied by an object. In this setting, multiple measurements are generated by\neach object per time step. In this paper, we present a Bayesian model for\nextended object tracking problem in a sensor network. In this model, the object\nextension is represented by a symmetric positive definite random matrix, and we\nassume that the measurement noise exists but is unknown. Using this Bayesian\nmodel, we first propose a novel centralized algorithm for extended object\ntracking based on variational Bayesian methods. Then, we extend it to the\ndistributed scenario based on the alternating direction method of multipliers\n(ADMM) technique. The proposed algorithms can simultaneously estimate the\nextended object state (the kinematic state and extension) and the measurement\nnoise covariance. Simulations on both extended object tracking and group target\ntracking are given to verify the effectiveness of the proposed model and\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 07:32:48 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Hua", "Junhao", ""], ["Li", "Chunguang", ""]]}, {"id": "1903.00184", "submitter": "Yu Bai", "authors": "Yu Bai, John Duchi, Song Mei", "title": "Proximal algorithms for constrained composite optimization, with\n  applications to solving low-rank SDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a family of (potentially non-convex) constrained optimization\nproblems with convex composite structure. Through a novel analysis of\nnon-smooth geometry, we show that proximal-type algorithms applied to exact\npenalty formulations of such problems exhibit local linear convergence under a\nquadratic growth condition, which the compositional structure we consider\nensures. The main application of our results is to low-rank semidefinite\noptimization with Burer-Monteiro factorizations. We precisely identify the\nconditions for quadratic growth in the factorized problem via structures in the\nsemidefinite problem, which could be of independent interest for understanding\nmatrix factorization.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 07:37:55 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Bai", "Yu", ""], ["Duchi", "John", ""], ["Mei", "Song", ""]]}, {"id": "1903.00194", "submitter": "Xiang Gu", "authors": "Xiang Gu, Sina Ghiassian, Richard S. Sutton", "title": "Should All Temporal Difference Learning Use Emphasis?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emphatic Temporal Difference (ETD) learning has recently been proposed as a\nconvergent off-policy learning method. ETD was proposed mainly to address\nconvergence issues of conventional Temporal Difference (TD) learning under\noff-policy training but it is different from conventional TD learning even\nunder on-policy training. A simple counterexample provided back in 2017 pointed\nto a potential class of problems where ETD converges but TD diverges. In this\npaper, we empirically show that ETD converges on a few other well-known\non-policy experiments whereas TD either diverges or performs poorly. We also\nshow that ETD outperforms TD on the mountain car prediction problem. Our\nresults, together with a similar pattern observed under off-policy training in\nprior works, suggest that ETD might be a good substitute over conventional TD.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 08:09:18 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Gu", "Xiang", ""], ["Ghiassian", "Sina", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1903.00197", "submitter": "Eryu Xia", "authors": "Eryu Xia, Xin Du, Jing Mei, Wen Sun, Suijun Tong, Zhiqing Kang, Jian\n  Sheng, Jian Li, Changsheng Ma, Jianzeng Dong, Shaochun Li", "title": "Outcome-Driven Clustering of Acute Coronary Syndrome Patients using\n  Multi-Task Neural Network with Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster analysis aims at separating patients into phenotypically heterogenous\ngroups and defining therapeutically homogeneous patient subclasses. It is an\nimportant approach in data-driven disease classification and subtyping. Acute\ncoronary syndrome (ACS) is a syndrome due to sudden decrease of coronary artery\nblood flow, where disease classification would help to inform therapeutic\nstrategies and provide prognostic insights. Here we conducted outcome-driven\ncluster analysis of ACS patients, which jointly considers treatment and patient\noutcome as indicators for patient state. Multi-task neural network with\nattention was used as a modeling framework, including learning of the patient\nstate, cluster analysis, and feature importance profiling. Seven patient\nclusters were discovered. The clusters have different characteristics, as well\nas different risk profiles to the outcome of in-hospital major adverse cardiac\nevents. The results demonstrate cluster analysis using outcome-driven\nmulti-task neural network as promising for patient classification and\nsubtyping.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 08:20:28 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 07:08:04 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Xia", "Eryu", ""], ["Du", "Xin", ""], ["Mei", "Jing", ""], ["Sun", "Wen", ""], ["Tong", "Suijun", ""], ["Kang", "Zhiqing", ""], ["Sheng", "Jian", ""], ["Li", "Jian", ""], ["Ma", "Changsheng", ""], ["Dong", "Jianzeng", ""], ["Li", "Shaochun", ""]]}, {"id": "1903.00201", "submitter": "{\\L}ukasz Maziarka", "authors": "Przemys{\\l}aw Spurek, Aleksandra Nowak, Jacek Tabor, {\\L}ukasz\n  Maziarka, Stanis{\\l}aw Jastrz\\k{e}bski", "title": "Non-linear ICA based on Cramer-Wold metric", "comments": null, "journal-ref": "Neural Information Processing. ICONIP 2020", "doi": "10.1007/978-3-030-63836-8_25", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-linear source separation is a challenging open problem with many\napplications. We extend a recently proposed Adversarial Non-linear ICA (ANICA)\nmodel, and introduce Cramer-Wold ICA (CW-ICA). In contrast to ANICA we use a\nsimple, closed--form optimization target instead of a discriminator--based\nindependence measure. Our results show that CW-ICA achieves comparable results\nto ANICA, while foregoing the need for adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 08:42:16 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Spurek", "Przemys\u0142aw", ""], ["Nowak", "Aleksandra", ""], ["Tabor", "Jacek", ""], ["Maziarka", "\u0141ukasz", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""]]}, {"id": "1903.00216", "submitter": "Egor Lakomkin", "authors": "Egor Lakomkin and Sven Magg and Cornelius Weber and Stefan Wermter", "title": "KT-Speech-Crawler: Automatic Dataset Construction for Speech Recognition\n  from YouTube Videos", "comments": "Accepted at the Conference on Empirical Methods in Natural Language\n  Processing 2018, Brussels, Belgium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe KT-Speech-Crawler: an approach for automatic\ndataset construction for speech recognition by crawling YouTube videos. We\noutline several filtering and post-processing steps, which extract samples that\ncan be used for training end-to-end neural speech recognition systems. In our\nexperiments, we demonstrate that a single-core version of the crawler can\nobtain around 150 hours of transcribed speech within a day, containing an\nestimated 3.5% word error rate in the transcriptions. Automatically collected\nsamples contain reading and spontaneous speech recorded in various conditions\nincluding background noise and music, distant microphone recordings, and a\nvariety of accents and reverberation. When training a deep neural network on\nspeech recognition, we observed around 40\\% word error rate reduction on the\nWall Street Journal dataset by integrating 200 hours of the collected samples\ninto the training set. The demo (http://emnlp-demo.lakomkin.me/) and the\ncrawler code (https://github.com/EgorLakomkin/KTSpeechCrawler) are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 09:14:50 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Lakomkin", "Egor", ""], ["Magg", "Sven", ""], ["Weber", "Cornelius", ""], ["Wermter", "Stefan", ""]]}, {"id": "1903.00252", "submitter": "Ji Liu", "authors": "Ji Liu and Lei Zhang", "title": "Optimal Projection Guided Transfer Hashing for Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, learning to hash has been widely studied for image retrieval thanks\nto the computation and storage efficiency of binary codes. For most existing\nlearning to hash methods, sufficient training images are required and used to\nlearn precise hashing codes. However, in some real-world applications, there\nare not always sufficient training images in the domain of interest. In\naddition, some existing supervised approaches need a amount of labeled data,\nwhich is an expensive process in term of time, label and human expertise. To\nhandle such problems, inspired by transfer learning, we propose a simple yet\neffective unsupervised hashing method named Optimal Projection Guided Transfer\nHashing (GTH) where we borrow the images of other different but related domain\ni.e., source domain to help learn precise hashing codes for the domain of\ninterest i.e., target domain. Besides, we propose to seek for the maximum\nlikelihood estimation (MLE) solution of the hashing functions of target and\nsource domains due to the domain gap. Furthermore,an alternating optimization\nmethod is adopted to obtain the two projections of target and source domains\nsuch that the domain hashing disparity is reduced gradually. Extensive\nexperiments on various benchmark databases verify that our method outperforms\nmany state-of-the-art learning to hash methods. The implementation details are\navailable at https://github.com/liuji93/GTH.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 11:43:31 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Liu", "Ji", ""], ["Zhang", "Lei", ""]]}, {"id": "1903.00271", "submitter": "Hafez Farazi", "authors": "Hafez Farazi and Sven Behnke", "title": "Frequency Domain Transformer Networks for Video Prediction", "comments": "Accepted for European Symposium on Artificial Neural Networks,\n  Computational Intelligence and Machine Learning (ESANN), Bruges, Belgium, to\n  appear April 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of video prediction is forecasting the next frames given some\nprevious frames. Despite much recent progress, this task is still challenging\nmainly due to high nonlinearity in the spatial domain. To address this issue,\nwe propose a novel architecture, Frequency Domain Transformer Network (FDTN),\nwhich is an end-to-end learnable model that estimates and uses the\ntransformations of the signal in the frequency domain. Experimental evaluations\nshow that this approach can outperform some widely used video prediction\nmethods like Video Ladder Network (VLN) and Predictive Gated Pyramids (PGP).\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 12:50:15 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Farazi", "Hafez", ""], ["Behnke", "Sven", ""]]}, {"id": "1903.00278", "submitter": "Cedric Renggli", "authors": "Cedric Renggli, Bojan Karla\\v{s}, Bolin Ding, Feng Liu, Kevin\n  Schawinski, Wentao Wu and Ce Zhang", "title": "Continuous Integration of Machine Learning Models with ease.ml/ci:\n  Towards a Rigorous Yet Practical Treatment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous integration is an indispensable step of modern software\nengineering practices to systematically manage the life cycles of system\ndevelopment. Developing a machine learning model is no difference - it is an\nengineering process with a life cycle, including design, implementation,\ntuning, testing, and deployment. However, most, if not all, existing continuous\nintegration engines do not support machine learning as first-class citizens.\n  In this paper, we present ease.ml/ci, to our best knowledge, the first\ncontinuous integration system for machine learning. The challenge of building\nease.ml/ci is to provide rigorous guarantees, e.g., single accuracy point error\ntolerance with 0.999 reliability, with a practical amount of labeling effort,\ne.g., 2K labels per test. We design a domain specific language that allows\nusers to specify integration conditions with reliability constraints, and\ndevelop simple novel optimizations that can lower the number of labels required\nby up to two orders of magnitude for test conditions popularly used in real\nproduction systems.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 13:15:55 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Renggli", "Cedric", ""], ["Karla\u0161", "Bojan", ""], ["Ding", "Bolin", ""], ["Liu", "Feng", ""], ["Schawinski", "Kevin", ""], ["Wu", "Wentao", ""], ["Zhang", "Ce", ""]]}, {"id": "1903.00317", "submitter": "Erwan Le Merrer", "authors": "Erwan Le Merrer and Gilles Tredan", "title": "TamperNN: Efficient Tampering Detection of Deployed Neural Nets", "comments": "In the 30th International Symposium on Software Reliability\n  Engineering (ISSRE 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are powering the deployment of embedded devices and Internet\nof Things. Applications range from personal assistants to critical ones such as\nself-driving cars. It has been shown recently that models obtained from neural\nnets can be trojaned ; an attacker can then trigger an arbitrary model behavior\nfacing crafted inputs. This has a critical impact on the security and\nreliability of those deployed devices. We introduce novel algorithms to detect\nthe tampering with deployed models, classifiers in particular. In the remote\ninteraction setup we consider, the proposed strategy is to identify markers of\nthe model input space that are likely to change class if the model is attacked,\nallowing a user to detect a possible tampering. This setup makes our proposal\ncompatible with a wide range of scenarios, such as embedded models, or models\nexposed through prediction APIs. We experiment those tampering detection\nalgorithms on the canonical MNIST dataset, over three different types of neural\nnets, and facing five different attacks (trojaning, quantization, fine-tuning,\ncompression and watermarking). We then validate over five large models (VGG16,\nVGG19, ResNet, MobileNet, DenseNet) with a state of the art dataset (VGGFace2),\nand report results demonstrating the possibility of an efficient detection of\nmodel tampering.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 14:32:45 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 11:42:19 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Merrer", "Erwan Le", ""], ["Tredan", "Gilles", ""]]}, {"id": "1903.00321", "submitter": "Luca Magri", "authors": "Hans Yu, Matthew P. Juniper, Luca Magri", "title": "Combined State and Parameter Estimation in Level-Set Methods", "comments": "52 pages, 19 figures; accepted for publication", "journal-ref": "Journal of Computational Physics 2019", "doi": "10.1016/j.jcp.2019.108950", "report-no": null, "categories": "physics.comp-ph cs.LG physics.data-an physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced-order models based on level-set methods are widely used tools to\nqualitatively capture and track the nonlinear dynamics of an interface. The aim\nof this paper is to develop a physics-informed, data-driven, statistically\nrigorous learning algorithm for state and parameter estimation with level-set\nmethods. A Bayesian approach based on data assimilation is introduced. Data\nassimilation is enabled by the ensemble Kalman filter and smoother, which are\nused in their probabilistic formulations. The level-set data assimilation\nframework is verified in onedimensional and two-dimensional test cases, where\nstate estimation, parameter estimation and uncertainty quantification are\nperformed. The statistical performance of the proposed ensemble Kalman filter\nand smoother is quantified by twin experiments. In the twin experiments, the\ncombined state and parameter estimation fully recovers the reference solution,\nwhich validates the proposed algorithm. The level-set data assimilation\nframework is then applied to the prediction of the nonlinear dynamics of a\nforced premixed flame, which exhibits the formation of sharp cusps and\nintricate topological changes, such as pinch-off events. The proposed\nphysics-informed statistical learning algorithm opens up new possibilities for\nmaking reduced-order models of interfaces quantitatively predictive, any time\nthat reference data is available.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 14:39:11 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 17:11:14 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Yu", "Hans", ""], ["Juniper", "Matthew P.", ""], ["Magri", "Luca", ""]]}, {"id": "1903.00342", "submitter": "Yu Li", "authors": "Yu Li, Chao Huang, Lizhong Ding, Zhongxiao Li, Yijie Pan, Xin Gao", "title": "Deep learning in bioinformatics: introduction, application, and\n  perspective in big data era", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, which is especially formidable in handling big data, has\nachieved great success in various fields, including bioinformatics. With the\nadvances of the big data era in biology, it is foreseeable that deep learning\nwill become increasingly important in the field and will be incorporated in\nvast majorities of analysis pipelines. In this review, we provide both the\nexoteric introduction of deep learning, and concrete examples and\nimplementations of its representative applications in bioinformatics. We start\nfrom the recent achievements of deep learning in the bioinformatics field,\npointing out the problems which are suitable to use deep learning. After that,\nwe introduce deep learning in an easy-to-understand fashion, from shallow\nneural networks to legendary convolutional neural networks, legendary recurrent\nneural networks, graph neural networks, generative adversarial networks,\nvariational autoencoder, and the most recent state-of-the-art architectures.\nAfter that, we provide eight examples, covering five bioinformatics research\ndirections and all the four kinds of data type, with the implementation written\nin Tensorflow and Keras. Finally, we discuss the common issues, such as\noverfitting and interpretability, that users will encounter when adopting deep\nlearning methods and provide corresponding suggestions. The implementations are\nfreely available at \\url{https://github.com/lykaust15/Deep_learning_examples}.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 09:51:05 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Li", "Yu", ""], ["Huang", "Chao", ""], ["Ding", "Lizhong", ""], ["Li", "Zhongxiao", ""], ["Pan", "Yijie", ""], ["Gao", "Xin", ""]]}, {"id": "1903.00345", "submitter": "Mikel Elkano", "authors": "Mikel Elkano and Mikel Uriz and Humberto Bustince and Mikel Galar", "title": "On the usage of the probability integral transform to reduce the\n  complexity of multi-way fuzzy decision trees in Big Data classification\n  problems", "comments": "Appeared in 2018 IEEE International Congress on Big Data (BigData\n  Congress). arXiv admin note: text overlap with arXiv:1902.09357", "journal-ref": null, "doi": "10.1109/BigDataCongress.2018.00011", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new distributed fuzzy partitioning method to reduce the\ncomplexity of multi-way fuzzy decision trees in Big Data classification\nproblems. The proposed algorithm builds a fixed number of fuzzy sets for all\nvariables and adjusts their shape and position to the real distribution of\ntraining data. A two-step process is applied : 1) transformation of the\noriginal distribution into a standard uniform distribution by means of the\nprobability integral transform. Since the original distribution is generally\nunknown, the cumulative distribution function is approximated by computing the\nq-quantiles of the training set; 2) construction of a Ruspini strong fuzzy\npartition in the transformed attribute space using a fixed number of equally\ndistributed triangular membership functions. Despite the aforementioned\ntransformation, the definition of every fuzzy set in the original space can be\nrecovered by applying the inverse cumulative distribution function (also known\nas quantile function). The experimental results reveal that the proposed\nmethodology allows the state-of-the-art multi-way fuzzy decision tree (FMDT)\ninduction algorithm to maintain classification accuracy with up to 6 million\nfewer leaves.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 07:48:51 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Elkano", "Mikel", ""], ["Uriz", "Mikel", ""], ["Bustince", "Humberto", ""], ["Galar", "Mikel", ""]]}, {"id": "1903.00359", "submitter": "Minhan Li", "authors": "Hiva Ghanbari, Minhan Li and Katya Scheinberg", "title": "Novel and Efficient Approximations for Zero-One Loss of Linear\n  Classifiers", "comments": "arXiv admin note: text overlap with arXiv:1802.02535", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The predictive quality of machine learning models is typically measured in\nterms of their (approximate) expected prediction accuracy or the so-called Area\nUnder the Curve (AUC). Minimizing the reciprocals of these measures are the\ngoals of supervised learning. However, when the models are constructed by the\nmeans of empirical risk minimization (ERM), surrogate functions such as the\nlogistic loss or hinge loss are optimized instead. In this work, we show that\nin the case of linear predictors, the expected error and the expected ranking\nloss can be effectively approximated by smooth functions whose closed form\nexpressions and those of their first (and second) order derivatives depend on\nthe first and second moments of the data distribution, which can be\nprecomputed. Hence, the complexity of an optimization algorithm applied to\nthese functions does not depend on the size of the training data. These\napproximation functions are derived under the assumption that the output of the\nlinear classifier for a given data set has an approximately normal\ndistribution. We argue that this assumption is significantly weaker than the\nGaussian assumption on the data itself and we support this claim by\ndemonstrating that our new approximation is quite accurate on data sets that\nare not necessarily Gaussian. We present computational results that show that\nour proposed approximations and related optimization algorithms can produce\nlinear classifiers with similar or better test accuracy or AUC, than those\nobtained using state-of-the-art approaches, in a fraction of the time.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:04:51 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Ghanbari", "Hiva", ""], ["Li", "Minhan", ""], ["Scheinberg", "Katya", ""]]}, {"id": "1903.00374", "submitter": "Piotr Mi{\\l}o\\'s", "authors": "Lukasz Kaiser, Mohammad Babaeizadeh, Piotr Milos, Blazej Osinski, Roy\n  H Campbell, Konrad Czechowski, Dumitru Erhan, Chelsea Finn, Piotr Kozakowski,\n  Sergey Levine, Afroz Mohiuddin, Ryan Sepassi, George Tucker, Henryk\n  Michalewski", "title": "Model-Based Reinforcement Learning for Atari", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL) can be used to learn effective\npolicies for complex tasks, such as Atari games, even from image observations.\nHowever, this typically requires very large amounts of interaction --\nsubstantially more, in fact, than a human would need to learn the same games.\nHow can people learn so quickly? Part of the answer may be that people can\nlearn how the game works and predict which actions will lead to desirable\noutcomes. In this paper, we explore how video prediction models can similarly\nenable agents to solve Atari games with fewer interactions than model-free\nmethods. We describe Simulated Policy Learning (SimPLe), a complete model-based\ndeep RL algorithm based on video prediction models and present a comparison of\nseveral model architectures, including a novel architecture that yields the\nbest results in our setting. Our experiments evaluate SimPLe on a range of\nAtari games in low data regime of 100k interactions between the agent and the\nenvironment, which corresponds to two hours of real-time play. In most games\nSimPLe outperforms state-of-the-art model-free algorithms, in some games by\nover an order of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 15:40:19 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 17:22:45 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 12:42:06 GMT"}, {"version": "v4", "created": "Wed, 19 Feb 2020 23:00:23 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kaiser", "Lukasz", ""], ["Babaeizadeh", "Mohammad", ""], ["Milos", "Piotr", ""], ["Osinski", "Blazej", ""], ["Campbell", "Roy H", ""], ["Czechowski", "Konrad", ""], ["Erhan", "Dumitru", ""], ["Finn", "Chelsea", ""], ["Kozakowski", "Piotr", ""], ["Levine", "Sergey", ""], ["Mohiuddin", "Afroz", ""], ["Sepassi", "Ryan", ""], ["Tucker", "George", ""], ["Michalewski", "Henryk", ""]]}, {"id": "1903.00386", "submitter": "Nicola Bulso", "authors": "Nicola Bulso, Matteo Marsili, Yasser Roudi", "title": "On the complexity of logistic regression models", "comments": "29 pages, 6 figures, The supplementary material is an ancillary file\n  and can be downloaded from a link on the right", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the complexity of logistic regression models which is defined\nby counting the number of indistinguishable distributions that the model can\nrepresent (Balasubramanian, 1997). We find that the complexity of logistic\nmodels with binary inputs does not only depend on the number of parameters but\nalso on the distribution of inputs in a non-trivial way which standard\ntreatments of complexity do not address. In particular, we observe that\ncorrelations among inputs induce effective dependencies among parameters thus\nconstraining the model and, consequently, reducing its complexity. We derive\nsimple relations for the upper and lower bounds of the complexity. Furthermore,\nwe show analytically that, defining the model parameters on a finite support\nrather than the entire axis, decreases the complexity in a manner that\ncritically depends on the size of the domain. Based on our findings, we propose\na novel model selection criterion which takes into account the entropy of the\ninput distribution. We test our proposal on the problem of selecting the input\nvariables of a logistic regression model in a Bayesian Model Selection\nframework. In our numerical tests, we find that, while the reconstruction\nerrors of standard model selection approaches (AIC, BIC, $\\ell_1$\nregularization) strongly depend on the sparsity of the ground truth, the\nreconstruction error of our method is always close to the minimum in all\nconditions of sparsity, data size and strength of input correlations. Finally,\nwe observe that, when considering categorical instead of binary inputs, in a\nsimple and mathematically tractable case, the contribution of the alphabet size\nto the complexity is very small compared to that of parameter space dimension.\nWe further explore the issue by analysing the dataset of the \"13 keys to the\nWhite House\" which is a method for forecasting the outcomes of US presidential\nelections.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 16:10:55 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Bulso", "Nicola", ""], ["Marsili", "Matteo", ""], ["Roudi", "Yasser", ""]]}, {"id": "1903.00402", "submitter": "Karla DiazOrdaz", "authors": "Noemi Kreif and Karla DiazOrdaz", "title": "Machine learning in policy evaluation: new tools for causal inference", "comments": "40 pages 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning (ML) methods have received a lot of attention in\nrecent years, these methods are primarily for prediction. Empirical researchers\nconducting policy evaluations are, on the other hand, pre-occupied with causal\nproblems, trying to answer counterfactual questions: what would have happened\nin the absence of a policy? Because these counterfactuals can never be directly\nobserved (described as the \"fundamental problem of causal inference\")\nprediction tools from the ML literature cannot be readily used for causal\ninference. In the last decade, major innovations have taken place incorporating\nsupervised ML tools into estimators for causal parameters such as the average\ntreatment effect (ATE). This holds the promise of attenuating model\nmisspecification issues, and increasing of transparency in model selection. One\nparticularly mature strand of the literature include approaches that\nincorporate supervised ML approaches in the estimation of the ATE of a binary\ntreatment, under the \\textit{unconfoundedness} and positivity assumptions (also\nknown as exchangeability and overlap assumptions).\n  This article reviews popular supervised machine learning algorithms,\nincluding the Super Learner. Then, some specific uses of machine learning for\ntreatment effect estimation are introduced and illustrated, namely (1) to\ncreate balance among treated and control groups, (2) to estimate so-called\nnuisance models (e.g. the propensity score, or conditional expectations of the\noutcome) in semi-parametric estimators that target causal parameters (e.g.\ntargeted maximum likelihood estimation or the double ML estimator), and (3) the\nuse of machine learning for variable selection in situations with a high number\nof covariates.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 16:52:51 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Kreif", "Noemi", ""], ["DiazOrdaz", "Karla", ""]]}, {"id": "1903.00405", "submitter": "Aritra Chowdhury", "authors": "Aritra Chowdhury, Malik Magdon-Ismail, Bulent Yener", "title": "Quantifying contribution and propagation of error from computational\n  steps, algorithms and hyperparameter choices in image classification\n  pipelines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data science relies on pipelines that are organized in the form of\ninterdependent computational steps. Each step consists of various candidate\nalgorithms that maybe used for performing a particular function. Each algorithm\nconsists of several hyperparameters. Algorithms and hyperparameters must be\noptimized as a whole to produce the best performance. Typical machine learning\npipelines consist of complex algorithms in each of the steps. Not only is the\nselection process combinatorial, but it is also important to interpret and\nunderstand the pipelines. We propose a method to quantify the importance of\ndifferent components in the pipeline, by computing an error contribution\nrelative to an agnostic choice of computational steps, algorithms and\nhyperparameters. We also propose a methodology to quantify the propagation of\nerror from individual components of the pipeline with the help of a naive set\nof benchmark algorithms not involved in the pipeline. We demonstrate our\nmethodology on image classification pipelines. The agnostic and naive\nmethodologies quantify the error contribution and propagation respectively from\nthe computational steps, algorithms and hyperparameters in the image\nclassification pipeline. We show that algorithm selection and hyperparameter\noptimization methods like grid search, random search and Bayesian optimization\ncan be used to quantify the error contribution and propagation, and that random\nsearch is able to quantify them more accurately than Bayesian optimization.\nThis methodology can be used by domain experts to understand machine learning\nand data analysis pipelines in terms of their individual components, which can\nhelp in prioritizing different components of the pipeline.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 14:42:52 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Chowdhury", "Aritra", ""], ["Magdon-Ismail", "Malik", ""], ["Yener", "Bulent", ""]]}, {"id": "1903.00410", "submitter": "Rafiq Mohammed", "authors": "Rafiq Ahmed Mohammed, Kok-Wai Wong, Mohd Fairuz Shiratuddin, Xuequn\n  Wang", "title": "Improving fraud prediction with incremental data balancing technique for\n  massive data streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of classification algorithms with a massive and highly\nimbalanced data stream depends upon efficient balancing strategy. Some\ntechniques of balancing strategy have been applied in the past with Batch data\nto resolve the class imbalance problem. This paper proposes a new incremental\ndata balancing framework which can work with massive imbalanced data streams.\nIn this paper, we choose Racing Algorithm as an automated data balancing\ntechnique which optimizes the balancing techniques. We applied Random Forest\nclassification algorithm which can deal with the massive data stream. We\ninvestigated the suitability of Racing Algorithm and Random Forest in the\nproposed framework. Applying new technique in the proposed framework on the\nEuropean Credit Card dataset, provided better results than the Batch mode. The\nproposed framework is more scalable to handle online massive data streams.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 07:08:20 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 04:38:15 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Mohammed", "Rafiq Ahmed", ""], ["Wong", "Kok-Wai", ""], ["Shiratuddin", "Mohd Fairuz", ""], ["Wang", "Xuequn", ""]]}, {"id": "1903.00445", "submitter": "Kevin Chen", "authors": "Kevin Chen, Juan Pablo de Vicente, Gabriel Sepulveda, Fei Xia, Alvaro\n  Soto, Marynel Vazquez, Silvio Savarese", "title": "A Behavioral Approach to Visual Navigation with Graph Localization\n  Networks", "comments": "Video: https://youtu.be/nN3B1F90CFM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by research in psychology, we introduce a behavioral approach for\nvisual navigation using topological maps. Our goal is to enable a robot to\nnavigate from one location to another, relying only on its visual input and the\ntopological map of the environment. We propose using graph neural networks for\nlocalizing the agent in the map, and decompose the action space into primitive\nbehaviors implemented as convolutional or recurrent neural networks. Using the\nGibson simulator, we verify that our approach outperforms relevant baselines\nand is able to navigate in both seen and unseen environments.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 18:16:03 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Chen", "Kevin", ""], ["de Vicente", "Juan Pablo", ""], ["Sepulveda", "Gabriel", ""], ["Xia", "Fei", ""], ["Soto", "Alvaro", ""], ["Vazquez", "Marynel", ""], ["Savarese", "Silvio", ""]]}, {"id": "1903.00450", "submitter": "Klaus Greff", "authors": "Klaus Greff, Rapha\\\"el Lopez Kaufman, Rishabh Kabra, Nick Watters,\n  Chris Burgess, Daniel Zoran, Loic Matthey, Matthew Botvinick, Alexander\n  Lerchner", "title": "Multi-Object Representation Learning with Iterative Variational\n  Inference", "comments": null, "journal-ref": "ICML 2019 (PMLR 97:2424-2433)", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human perception is structured around objects which form the basis for our\nhigher-level cognition and impressive systematic generalization abilities. Yet\nmost work on representation learning focuses on feature learning without even\nconsidering multiple objects, or treats segmentation as an (often supervised)\npreprocessing step. Instead, we argue for the importance of learning to segment\nand represent objects jointly. We demonstrate that, starting from the simple\nassumption that a scene is composed of multiple entities, it is possible to\nlearn to segment images into interpretable objects with disentangled\nrepresentations. Our method learns -- without supervision -- to inpaint\noccluded parts, and extrapolates to scenes with more objects and to unseen\nobjects with novel feature combinations. We also show that, due to the use of\niterative variational inference, our system is able to learn multi-modal\nposteriors for ambiguous inputs and extends naturally to sequences.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 18:21:02 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 23:21:01 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 19:55:14 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Greff", "Klaus", ""], ["Kaufman", "Rapha\u00ebl Lopez", ""], ["Kabra", "Rishabh", ""], ["Watters", "Nick", ""], ["Burgess", "Chris", ""], ["Zoran", "Daniel", ""], ["Matthey", "Loic", ""], ["Botvinick", "Matthew", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1903.00516", "submitter": "Stanislav Borysov S", "authors": "Stanislav S. Borysov, Jeppe Rich", "title": "Introducing Super Pseudo Panels: Application to Transport Preference\n  Dynamics", "comments": "22 pages, 10 figures, 5 tables", "journal-ref": null, "doi": "10.1007/s11116-020-10137-5", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach for constructing synthetic pseudo-panel data from\ncross-sectional data. The pseudo panel and the preferences it intends to\ndescribe is constructed at the individual level and is not affected by\naggregation bias across cohorts. This is accomplished by creating a\nhigh-dimensional probabilistic model representation of the entire data set,\nwhich allows sampling from the probabilistic model in such a way that all of\nthe intrinsic correlation properties of the original data are preserved. The\nkey to this is the use of deep learning algorithms based on the Conditional\nVariational Autoencoder (CVAE) framework. From a modelling perspective, the\nconcept of a model-based resampling creates a number of opportunities in that\ndata can be organized and constructed to serve very specific needs of which the\nforming of heterogeneous pseudo panels represents one. The advantage, in that\nrespect, is the ability to trade a serious aggregation bias (when aggregating\ninto cohorts) for an unsystematic noise disturbance. Moreover, the approach\nmakes it possible to explore high-dimensional sparse preference distributions\nand their linkage to individual specific characteristics, which is not possible\nif applying traditional pseudo-panel methods. We use the presented approach to\nreveal the dynamics of transport preferences for a fixed pseudo panel of\nindividuals based on a large Danish cross-sectional data set covering the\nperiod from 2006 to 2016. The model is also utilized to classify individuals\ninto 'slow' and 'fast' movers with respect to the speed at which their\npreferences change over time. It is found that the prototypical fast mover is a\nyoung woman who lives as a single in a large city whereas the typical slow\nmover is a middle-aged man with high income from a nuclear family who lives in\na detached house outside a city.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 19:58:23 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Borysov", "Stanislav S.", ""], ["Rich", "Jeppe", ""]]}, {"id": "1903.00519", "submitter": "Laura Rieger", "authors": "Laura Rieger and Lars Kai Hansen", "title": "Aggregating explanation methods for stable and robust explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a growing literature on explaining neural networks, no consensus has\nbeen reached on how to explain a neural network decision or how to evaluate an\nexplanation. Our contributions in this paper are twofold. First, we investigate\nschemes to combine explanation methods and reduce model uncertainty to obtain a\nsingle aggregated explanation. We provide evidence that the aggregation is\nbetter at identifying important features, than on individual methods.\nAdversarial attacks on explanations is a recent active research topic. As our\nsecond contribution, we present evidence that aggregate explanations are much\nmore robust to attacks than individual explanation methods.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 20:11:06 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 12:41:00 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 21:41:23 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 12:51:36 GMT"}, {"version": "v5", "created": "Fri, 20 Mar 2020 08:52:24 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Rieger", "Laura", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "1903.00534", "submitter": "Anna Ritz", "authors": "Marika Swanberg, Ira Globus-Harris, Iris Griffith, Anna Ritz, Adam\n  Groce, and Andrew Bray", "title": "Improved Differentially Private Analysis of Variance", "comments": "Proceedings of the 19th Privacy Enhancing Technologies Symposium\n  (PETS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypothesis testing is one of the most common types of data analysis and forms\nthe backbone of scientific research in many disciplines. Analysis of variance\n(ANOVA) in particular is used to detect dependence between a categorical and a\nnumerical variable. Here we show how one can carry out this hypothesis test\nunder the restrictions of differential privacy. We show that the $F$-statistic,\nthe optimal test statistic in the public setting, is no longer optimal in the\nprivate setting, and we develop a new test statistic $F_1$ with much higher\nstatistical power. We show how to rigorously compute a reference distribution\nfor the $F_1$ statistic and give an algorithm that outputs accurate $p$-values.\nWe implement our test and experimentally optimize several parameters. We then\ncompare our test to the only previous work on private ANOVA testing, using the\nsame effect size as that work. We see an order of magnitude improvement, with\nour test requiring only 7% as much data to detect the effect.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 20:39:21 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Swanberg", "Marika", ""], ["Globus-Harris", "Ira", ""], ["Griffith", "Iris", ""], ["Ritz", "Anna", ""], ["Groce", "Adam", ""], ["Bray", "Andrew", ""]]}, {"id": "1903.00543", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha and Aditya Gopalan", "title": "Combinatorial Bandits with Relative Feedback", "comments": "47 pages, 12 fgures", "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider combinatorial online learning with subset choices when only\nrelative feedback information from subsets is available, instead of bandit or\nsemi-bandit feedback which is absolute. Specifically, we study two regret\nminimisation problems over subsets of a finite ground set $[n]$, with\nsubset-wise relative preference information feedback according to the\nMultinomial logit choice model. In the first setting, the learner can play\nsubsets of size bounded by a maximum size and receives top-$m$ rank-ordered\nfeedback, while in the second setting the learner can play subsets of a fixed\nsize $k$ with a full subset ranking observed as feedback. For both settings, we\ndevise instance-dependent and order-optimal regret algorithms with regret\n$O(\\frac{n}{m} \\ln T)$ and $O(\\frac{n}{k} \\ln T)$, respectively. We derive\nfundamental limits on the regret performance of online learning with\nsubset-wise preferences, proving the tightness of our regret guarantees. Our\nresults also show the value of eliciting more general top-$m$ rank-ordered\nfeedback over single winner feedback ($m=1$). Our theoretical results are\ncorroborated with empirical evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 21:25:22 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 21:11:57 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1903.00545", "submitter": "Frank Wang", "authors": "Frank Wang and Danjue Li", "title": "A Nonlinear Model for Time Synchronization", "comments": "7 pages, accepted by 2019 Workshop on Synchronization and Timing\n  Services", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current algorithms are based on linear model, for example, Precision Time\nProtocol (PTP) which requires frequent synchronization in order to handle the\neffects of clock frequency drift. This paper introduces a nonlinear approach to\nclock time synchronize. This approach can accurately model the frequency shift.\nTherefore, the required time interval to synchronize clocks can be longer.\nMeanwhile, it also offers better performance and relaxes the synchronization\nprocess. The idea of the nonlinear algorithm and some numerical examples will\nbe presented in this paper in detail.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 21:32:39 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Wang", "Frank", ""], ["Li", "Danjue", ""]]}, {"id": "1903.00558", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha and Aditya Gopalan", "title": "From PAC to Instance-Optimal Sample Complexity in the Plackett-Luce\n  Model", "comments": "56 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider PAC-learning a good item from $k$-subsetwise feedback information\nsampled from a Plackett-Luce probability model, with instance-dependent sample\ncomplexity performance. In the setting where subsets of a fixed size can be\ntested and top-ranked feedback is made available to the learner, we give an\nalgorithm with optimal instance-dependent sample complexity, for PAC best arm\nidentification, of $O\\bigg(\\frac{\\theta_{[k]}}{k}\\sum_{i =\n2}^n\\max\\Big(1,\\frac{1}{\\Delta_i^2}\\Big) \\ln\\frac{k}{\\delta}\\Big(\\ln\n\\frac{1}{\\Delta_i}\\Big)\\bigg)$, $\\Delta_i$ being the Plackett-Luce parameter\ngap between the best and the $i^{th}$ best item, and $\\theta_{[k]}$ is the sum\nof the \\pl\\, parameters for the top-$k$ items. The algorithm is based on a\nwrapper around a PAC winner-finding algorithm with weaker performance\nguarantees to adapt to the hardness of the input instance. The sample\ncomplexity is also shown to be multiplicatively better depending on the length\nof rank-ordered feedback available in each subset-wise play. We show optimality\nof our algorithms with matching sample complexity lower bounds. We next address\nthe winner-finding problem in Plackett-Luce models in the fixed-budget setting\nwith instance dependent upper and lower bounds on the misidentification\nprobability, of $\\Omega\\left(\\exp(-2 \\tilde \\Delta Q) \\right)$ for a given\nbudget $Q$, where $\\tilde \\Delta$ is an explicit instance-dependent problem\ncomplexity parameter. Numerical performance results are also reported.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 22:12:10 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 23:29:46 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1903.00562", "submitter": "Shubhra Kanti Karmaker Santu", "authors": "Shubhra Kanti Karmaker Santu, Liangda Li, Yi Chang, ChengXiang Zhai", "title": "JIM: Joint Influence Modeling for Collective Search Behavior", "comments": null, "journal-ref": null, "doi": "10.1145/3269206.3271681", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has shown that popular trending events are important external\nfactors which pose significant influence on user search behavior and also\nprovided a way to computationally model this influence. However, their problem\nformulation was based on the strong assumption that each event poses its\ninfluence independently. This assumption is unrealistic as there are many\ncorrelated events in the real world which influence each other and thus, would\npose a joint influence on the user search behavior rather than posing influence\nindependently. In this paper, we study this novel problem of Modeling the Joint\nInfluences posed by multiple correlated events on user search behavior. We\npropose a Joint Influence Model based on the Multivariate Hawkes Process which\ncaptures the inter-dependency among multiple events in terms of their influence\nupon user search behavior. We evaluate the proposed Joint Influence Model using\ntwo months query-log data from https://search.yahoo.com/. Experimental results\nshow that the model can indeed capture the temporal dynamics of the joint\ninfluence over time and also achieves superior performance over different\nbaseline methods when applied to solve various interesting prediction problems\nas well as real-word application scenarios, e.g., query auto-completion.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 22:20:47 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Santu", "Shubhra Kanti Karmaker", ""], ["Li", "Liangda", ""], ["Chang", "Yi", ""], ["Zhai", "ChengXiang", ""]]}, {"id": "1903.00585", "submitter": "Uiwon Hwang", "authors": "Uiwon Hwang, Jaewoo Park, Hyemi Jang, Sungroh Yoon, Nam Ik Cho", "title": "PuVAE: A Variational Autoencoder to Purify Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are widely used and exhibit excellent performance in\nmany areas. However, they are vulnerable to adversarial attacks that compromise\nthe network at the inference time by applying elaborately designed perturbation\nto input data. Although several defense methods have been proposed to address\nspecific attacks, other attack methods can circumvent these defense mechanisms.\nTherefore, we propose Purifying Variational Autoencoder (PuVAE), a method to\npurify adversarial examples. The proposed method eliminates an adversarial\nperturbation by projecting an adversarial example on the manifold of each\nclass, and determines the closest projection as a purified sample. We\nexperimentally illustrate the robustness of PuVAE against various attack\nmethods without any prior knowledge. In our experiments, the proposed method\nexhibits performances competitive with state-of-the-art defense methods, and\nthe inference time is approximately 130 times faster than that of Defense-GAN\nthat is the state-of-the art purifier model.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 00:38:38 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Hwang", "Uiwon", ""], ["Park", "Jaewoo", ""], ["Jang", "Hyemi", ""], ["Yoon", "Sungroh", ""], ["Cho", "Nam Ik", ""]]}, {"id": "1903.00597", "submitter": "Yulun Tian", "authors": "Yulun Tian, Kasra Khosoussi, Jonathan P. How", "title": "Block-Coordinate Minimization for Large SDPs with Block-Diagonal\n  Constraints", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The so-called Burer-Monteiro method is a well-studied technique for solving\nlarge-scale semidefinite programs (SDPs) via low-rank factorization. The main\nidea is to solve rank-restricted, albeit non-convex, surrogates instead of the\nSDP. Recent works have shown that, in an important class of SDPs with elegant\ngeometric structure, one can find globally optimal solutions to the SDP by\nfinding rank-deficient second-order critical points of an unconstrained\nRiemannian optimization problem. Hence, in such problems, the Burer-Monteiro\napproach can provide a scalable and reliable alternative to interior-point\nmethods that scale poorly. Among various Riemannian optimization methods\nproposed, block-coordinate minimization (BCM) is of particular interest due to\nits simplicity. Erdogdu et al. in their recent work proposed BCM for problems\nover the Cartesian product of unit spheres and provided global convergence rate\nestimates for the algorithm. This report extends the BCM algorithm and the\nglobal convergence rate analysis of Erdogdu et al. from problems over the\nCartesian product of unit spheres to the Cartesian product of Stiefel\nmanifolds. The latter more general setting has important applications such as\nsynchronization over the special orthogonal (SO) and special Euclidean (SE)\ngroups.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 01:41:15 GMT"}, {"version": "v2", "created": "Sat, 9 Mar 2019 17:43:37 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 20:50:05 GMT"}, {"version": "v4", "created": "Wed, 28 Aug 2019 03:21:35 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Tian", "Yulun", ""], ["Khosoussi", "Kasra", ""], ["How", "Jonathan P.", ""]]}, {"id": "1903.00614", "submitter": "Azade Nazi", "authors": "Azade Nazi, Will Hang, Anna Goldie, Sujith Ravi, Azalia Mirhoseini", "title": "GAP: Generalizable Approximate Graph Partitioning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph partitioning is the problem of dividing the nodes of a graph into\nbalanced partitions while minimizing the edge cut across the partitions. Due to\nits combinatorial nature, many approximate solutions have been developed,\nincluding variants of multi-level methods and spectral clustering. We propose\nGAP, a Generalizable Approximate Partitioning framework that takes a deep\nlearning approach to graph partitioning. We define a differentiable loss\nfunction that represents the partitioning objective and use backpropagation to\noptimize the network parameters. Unlike baselines that redo the optimization\nper graph, GAP is capable of generalization, allowing us to train models that\nproduce performant partitions at inference time, even on unseen graphs.\nFurthermore, because we learn the representation of the graph while jointly\noptimizing for the partitioning loss function, GAP can be easily tuned for a\nvariety of graph structures. We evaluate the performance of GAP on graphs of\nvarying sizes and structures, including graphs of widely used machine learning\nmodels (e.g., ResNet, VGG, and Inception-V3), scale-free graphs, and random\ngraphs. We show that GAP achieves competitive partitions while being up to 100\ntimes faster than the baseline and generalizes to unseen graphs.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 03:06:00 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Nazi", "Azade", ""], ["Hang", "Will", ""], ["Goldie", "Anna", ""], ["Ravi", "Sujith", ""], ["Mirhoseini", "Azalia", ""]]}, {"id": "1903.00617", "submitter": "Reza Hajargasht", "authors": "Reza Hajargasht", "title": "Approximation Properties of Variational Bayes for Vector Autoregressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayes (VB) is a recent approximate method for Bayesian inference.\nIt has the merit of being a fast and scalable alternative to Markov Chain Monte\nCarlo (MCMC) but its approximation error is often unknown. In this paper, we\nderive the approximation error of VB in terms of mean, mode, variance,\npredictive density and KL divergence for the linear Gaussian multi-equation\nregression. Our results indicate that VB approximates the posterior mean\nperfectly. Factors affecting the magnitude of underestimation in posterior\nvariance and mode are revealed. Importantly, We demonstrate that VB estimates\npredictive densities accurately.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 03:24:16 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Hajargasht", "Reza", ""]]}, {"id": "1903.00637", "submitter": "Menglei Hu", "authors": "Menglei Hu, Songcan Chen", "title": "One-Pass Incomplete Multi-view Clustering", "comments": "9 pages, published in the AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real data are often with multiple modalities or from multiple heterogeneous\nsources, thus forming so-called multi-view data, which receives more and more\nattentions in machine learning. Multi-view clustering (MVC) becomes its\nimportant paradigm. In real-world applications, some views often suffer from\ninstances missing. Clustering on such multi-view datasets is called incomplete\nmulti-view clustering (IMC) and quite challenging. To date, though many\napproaches have been developed, most of them are offline and have high\ncomputational and memory costs especially for large scale datasets. To address\nthis problem, in this paper, we propose an One-Pass Incomplete Multi-view\nClustering framework (OPIMC). With the help of regularized matrix factorization\nand weighted matrix factorization, OPIMC can relatively easily deal with such\nproblem. Different from the existing and sole online IMC method, OPIMC can\ndirectly get clustering results and effectively determine the termination of\niteration process by introducing two global statistics. Finally, extensive\nexperiments conducted on four real datasets demonstrate the efficiency and\neffectiveness of the proposed OPIMC method.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 06:16:40 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Hu", "Menglei", ""], ["Chen", "Songcan", ""]]}, {"id": "1903.00667", "submitter": "Giulia Luise", "authors": "Giulia Luise, Dimitris Stamos, Massimiliano Pontil, Carlo Ciliberto", "title": "Leveraging Low-Rank Relations Between Surrogate Tasks in Structured\n  Prediction", "comments": "42 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the interplay between surrogate methods for structured prediction\nand techniques from multitask learning designed to leverage relationships\nbetween surrogate outputs. We propose an efficient algorithm based on trace\nnorm regularization which, differently from previous methods, does not require\nexplicit knowledge of the coding/decoding functions of the surrogate framework.\nAs a result, our algorithm can be applied to the broad class of problems in\nwhich the surrogate space is large or even infinite dimensional. We study\nexcess risk bounds for trace norm regularized structured prediction, implying\nthe consistency and learning rates for our estimator. We also identify relevant\nregimes in which our approach can enjoy better generalization performance than\nprevious methods. Numerical experiments on ranking problems indicate that\nenforcing low-rank relations among surrogate outputs may indeed provide a\nsignificant advantage in practice.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 09:47:56 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Luise", "Giulia", ""], ["Stamos", "Dimitris", ""], ["Pontil", "Massimiliano", ""], ["Ciliberto", "Carlo", ""]]}, {"id": "1903.00695", "submitter": "Noshaba Cheema", "authors": "Noshaba Cheema, Somayeh Hosseini, Janis Sprenger, Erik Herrmann, Han\n  Du, Klaus Fischer, Philipp Slusallek", "title": "Fine-Grained Semantic Segmentation of Motion Capture Data using Dilated\n  Temporal Fully-Convolutional Networks", "comments": "Eurographics 2019 - Short Papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human motion capture data has been widely used in data-driven character\nanimation. In order to generate realistic, natural-looking motions, most\ndata-driven approaches require considerable efforts of pre-processing,\nincluding motion segmentation and annotation. Existing (semi-) automatic\nsolutions either require hand-crafted features for motion segmentation or do\nnot produce the semantic annotations required for motion synthesis and building\nlarge-scale motion databases. In addition, human labeled annotation data\nsuffers from inter- and intra-labeler inconsistencies by design. We propose a\nsemi-automatic framework for semantic segmentation of motion capture data based\non supervised machine learning techniques. It first transforms a motion capture\nsequence into a ``motion image'' and applies a convolutional neural network for\nimage segmentation. Dilated temporal convolutions enable the extraction of\ntemporal information from a large receptive field. Our model outperforms two\nstate-of-the-art models for action segmentation, as well as a popular network\nfor sequence modeling. Most of all, our method is very robust under noisy and\ninaccurate training labels and thus can handle human errors during the labeling\nprocess.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 12:53:25 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Cheema", "Noshaba", ""], ["Hosseini", "Somayeh", ""], ["Sprenger", "Janis", ""], ["Herrmann", "Erik", ""], ["Du", "Han", ""], ["Fischer", "Klaus", ""], ["Slusallek", "Philipp", ""]]}, {"id": "1903.00702", "submitter": "Fei Wen", "authors": "Fei Wen, Rendong Ying, Peilin Liu, Trieu-Kien Truong", "title": "Matrix Completion via Nonconvex Regularization: Convergence of the\n  Proximal Gradient Algorithm", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion has attracted much interest in the past decade in machine\nlearning and computer vision. For low-rank promotion in matrix completion, the\nnuclear norm penalty is convenient due to its convexity but has a bias problem.\nRecently, various algorithms using nonconvex penalties have been proposed,\namong which the proximal gradient descent (PGD) algorithm is one of the most\nefficient and effective. For the nonconvex PGD algorithm, whether it converges\nto a local minimizer and its convergence rate are still unclear. This work\nprovides a nontrivial analysis on the PGD algorithm in the nonconvex case.\nBesides the convergence to a stationary point for a generalized nonconvex\npenalty, we provide more deep analysis on a popular and important class of\nnonconvex penalties which have discontinuous thresholding functions. For such\npenalties, we establish the finite rank convergence, convergence to restricted\nstrictly local minimizer and eventually linear convergence rate of the PGD\nalgorithm. Meanwhile, convergence to a local minimizer has been proved for the\nhard-thresholding penalty. Our result is the first shows that, nonconvex\nregularized matrix completion only has restricted strictly local minimizers,\nand the PGD algorithm can converge to such minimizers with eventually linear\nrate under certain conditions. Illustration of the PGD algorithm via\nexperiments has also been provided. Code is available at\nhttps://github.com/FWen/nmc.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 13:29:39 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Wen", "Fei", ""], ["Ying", "Rendong", ""], ["Liu", "Peilin", ""], ["Truong", "Trieu-Kien", ""]]}, {"id": "1903.00711", "submitter": "Nirmit Desai", "authors": "Nirmit Desai and Linsong Chu and Raghu K. Ganti and Sebastian Stein\n  and Mudhakar Srivatsa", "title": "neuralRank: Searching and ranking ANN-based model repositories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widespread applications of deep learning have led to a plethora of\npre-trained neural network models for common tasks. Such models are often\nadapted from other models via transfer learning. The models may have varying\ntraining sets, training algorithms, network architectures, and\nhyper-parameters. For a given application, what isthe most suitable model in a\nmodel repository? This is a critical question for practical deployments but it\nhas not received much attention. This paper introduces the novel problem of\nsearching and ranking models based on suitability relative to a target dataset\nand proposes a ranking algorithm called \\textit{neuralRank}. The key idea\nbehind this algorithm is to base model suitability on the discriminating power\nof a model, using a novel metric to measure it. With experimental results on\nthe MNIST, Fashion, and CIFAR10 datasets, we demonstrate that (1) neuralRank is\nindependent of the domain, the training set, or the network architecture and\n(2) that the models ranked highly by neuralRank ranking tend to have higher\nmodel accuracy in practice.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 14:45:41 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Desai", "Nirmit", ""], ["Chu", "Linsong", ""], ["Ganti", "Raghu K.", ""], ["Stein", "Sebastian", ""], ["Srivatsa", "Mudhakar", ""]]}, {"id": "1903.00715", "submitter": "Yang Yu", "authors": "Ruo-Ze Liu, Haifeng Guo, Xiaozhong Ji, Yang Yu, Zhen-Jia Pang, Zitai\n  Xiao, Yuzhou Wu, Tong Lu", "title": "Efficient Reinforcement Learning for StarCraft by Abstract Forward\n  Models and Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Injecting human knowledge is an effective way to accelerate reinforcement\nlearning (RL). However, these methods are underexplored. This paper presents\nour discovery that an abstract forward model (Thought-game (TG)) combined with\ntransfer learning is an effective way. We take StarCraft II as the study\nenvironment. With the help of a designed TG, the agent can learn a 99\\%\nwin-rate on a 64$\\times$64 map against the Level-7 built-in AI, using only 1.08\nhours in a single commercial machine. We also show that the TG method is not as\nrestrictive as it was thought to be. It can work with roughly designed TGs, and\ncan also be useful when the environment changes. Comparing with previous\nmodel-based RL, we show TG is more effective. We also present a TG hypothesis\nthat gives the influence of fidelity levels of TG. For real games that have\nunequal state and action spaces, we proposed a novel XfrNet of which usefulness\nis validated while achieving a 90\\% win-rate against the cheating Level-10 AI.\nWe argue the TG method might shed light on further studies of efficient RL with\nhuman knowledge.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 15:02:03 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 05:30:22 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 19:53:22 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Liu", "Ruo-Ze", ""], ["Guo", "Haifeng", ""], ["Ji", "Xiaozhong", ""], ["Yu", "Yang", ""], ["Pang", "Zhen-Jia", ""], ["Xiao", "Zitai", ""], ["Wu", "Yuzhou", ""], ["Lu", "Tong", ""]]}, {"id": "1903.00719", "submitter": "Lukas Pfannschmidt", "authors": "Lukas Pfannschmidt, Christina G\\\"opfert, Ursula Neumann, Dominik\n  Heider, Barbara Hammer", "title": "FRI -- Feature Relevance Intervals for Interpretable and Interactive\n  Data Exploration", "comments": "Addition of IEEE copyright notice. Accepted for CIBCB 2019\n  (https://cibcb2019.icas.xyz/)", "journal-ref": null, "doi": "10.1109/CIBCB.2019.8791489", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing feature selection methods are insufficient for analytic\npurposes as soon as high dimensional data or redundant sensor signals are dealt\nwith since features can be selected due to spurious effects or correlations\nrather than causal effects. To support the finding of causal features in\nbiomedical experiments, we hereby present FRI, an open source Python library\nthat can be used to identify all-relevant variables in linear classification\nand (ordinal) regression problems. Using the recently proposed feature\nrelevance method, FRI is able to provide the base for further general\nexperimentation or in specific can facilitate the search for alternative\nbiomarkers. It can be used in an interactive context, by providing model\nmanipulation and visualization methods, or in a batch process as a filter\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 15:16:15 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 17:21:03 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 14:41:04 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Pfannschmidt", "Lukas", ""], ["G\u00f6pfert", "Christina", ""], ["Neumann", "Ursula", ""], ["Heider", "Dominik", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.00724", "submitter": "Jean-Samuel Leboeuf", "authors": "Nicolas Garneau, Jean-Samuel Leboeuf and Luc Lamontagne", "title": "Predicting and interpreting embeddings for out of vocabulary words in\n  downstream tasks", "comments": "2 pages, 0 figures, 2 tables", "journal-ref": "Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and\n  Interpreting Neural Networks for NLP", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel way to handle out of vocabulary (OOV) words in downstream\nnatural language processing (NLP) tasks. We implement a network that predicts\nuseful embeddings for OOV words based on their morphology and on the context in\nwhich they appear. Our model also incorporates an attention mechanism\nindicating the focus allocated to the left context words, the right context\nwords or the word's characters, hence making the prediction more interpretable.\nThe model is a ``drop-in'' module that is jointly trained with the downstream\ntask's neural network, thus producing embeddings specialized for the task at\nhand. When the task is mostly syntactical, we observe that our model aims most\nof its attention on surface form characters. On the other hand, for tasks more\nsemantical, the network allocates more attention to the surrounding words. In\nall our tests, the module helps the network to achieve better performances in\ncomparison to the use of simple random embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 15:32:39 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Garneau", "Nicolas", ""], ["Leboeuf", "Jean-Samuel", ""], ["Lamontagne", "Luc", ""]]}, {"id": "1903.00725", "submitter": "Wenhao Yang", "authors": "Xiang Li, Wenhao Yang, Zhihua Zhang", "title": "A Regularized Approach to Sparse Optimal Policy in Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study a general framework for regularized Markov decision\nprocesses (MDPs) where the goal is to find an optimal policy that maximizes the\nexpected discounted total reward plus a policy regularization term. The extant\nentropy-regularized MDPs can be cast into our framework. Moreover, under our\nframework, many regularization terms can bring multi-modality and sparsity,\nwhich are potentially useful in reinforcement learning. In particular, we\npresent sufficient and necessary conditions that induce a sparse optimal\npolicy. We also conduct a full mathematical analysis of the proposed\nregularized MDPs, including the optimality condition, performance error, and\nsparseness control. We provide a generic method to devise regularization forms\nand propose off-policy actor critic algorithms in complex environment settings.\nWe empirically analyze the numerical properties of optimal policies and compare\nthe performance of different sparse regularization forms in discrete and\ncontinuous environments.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 15:34:25 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 03:50:50 GMT"}, {"version": "v3", "created": "Sun, 20 Oct 2019 15:28:06 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Li", "Xiang", ""], ["Yang", "Wenhao", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1903.00739", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Jianguo Yu, Ahmed H Tewfik", "title": "Speech Recognition with no speech or with noisy speech", "comments": "Accepted for ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of automatic speech recognition systems(ASR) degrades in the\npresence of noisy speech. This paper demonstrates that using\nelectroencephalography (EEG) can help automatic speech recognition systems\novercome performance loss in the presence of noise. The paper also shows that\ndistillation training of automatic speech recognition systems using EEG\nfeatures will increase their performance. Finally, we demonstrate the ability\nto recognize words from EEG with no speech signal on a limited English\nvocabulary with high accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 17:53:49 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Yu", "Jianguo", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "1903.00743", "submitter": "Udayan Khurana", "authors": "Udayan Khurana and Horst Samulowitz", "title": "Automating Predictive Modeling Process using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a good predictive model requires an array of activities such as data\nimputation, feature transformations, estimator selection, hyper-parameter\nsearch and ensemble construction. Given the large, complex and heterogenous\nspace of options, off-the-shelf optimization methods are infeasible for\nrealistic response times. In practice, much of the predictive modeling process\nis conducted by experienced data scientists, who selectively make use of\navailable tools. Over time, they develop an understanding of the behavior of\noperators, and perform serial decision making under uncertainty, colloquially\nreferred to as educated guesswork. With an unprecedented demand for application\nof supervised machine learning, there is a call for solutions that\nautomatically search for a good combination of parameters across these tasks to\nminimize the modeling error. We introduce a novel system called APRL\n(Autonomous Predictive modeler via Reinforcement Learning), that uses past\nexperience through reinforcement learning to optimize such sequential decision\nmaking from within a set of diverse actions under a time constraint on a\npreviously unseen predictive learning problem. APRL actions are taken to\noptimize the performance of a final ensemble. This is in contrast to other\nsystems, which maximize individual model accuracy first and create ensembles as\na disconnected post-processing step. As a result, APRL is able to reduce up to\n71\\% of classification error on average over a wide variety of problems.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 18:22:19 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Khurana", "Udayan", ""], ["Samulowitz", "Horst", ""]]}, {"id": "1903.00750", "submitter": "Sainyam Galhotra Mr", "authors": "Sainyam Galhotra, Sandhya Saisubramanian and Shlomo Zilberstein", "title": "Lexicographically Ordered Multi-Objective Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a rich model for multi-objective clustering with lexicographic\nordering over objectives and a slack. The slack denotes the allowed\nmultiplicative deviation from the optimal objective value of the higher\npriority objective to facilitate improvement in lower-priority objectives. We\nthen propose an algorithm called Zeus to solve this class of problems, which is\ncharacterized by a makeshift function. The makeshift fine tunes the clusters\nformed by the processed objectives so as to improve the clustering with respect\nto the unprocessed objectives, given the slack. We present makeshift for\nsolving three different classes of objectives and analyze their solution\nguarantees. Finally, we empirically demonstrate the effectiveness of our\napproach on three applications using real-world data.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 19:32:00 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Galhotra", "Sainyam", ""], ["Saisubramanian", "Sandhya", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "1903.00755", "submitter": "Ziming Zhang", "authors": "Ziming Zhang, Anil Kag, Alan Sullivan, Venkatesh Saligrama", "title": "Equilibrated Recurrent Neural Network: Neuronal Time-Delayed\n  Self-Feedback Improves Accuracy and Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel {\\it Equilibrated Recurrent Neural Network} (ERNN) to\ncombat the issues of inaccuracy and instability in conventional RNNs. Drawing\nupon the concept of autapse in neuroscience, we propose augmenting an RNN with\na time-delayed self-feedback loop. Our sole purpose is to modify the dynamics\nof each internal RNN state and, at any time, enforce it to evolve close to the\nequilibrium point associated with the input signal at that time. We show that\nsuch self-feedback helps stabilize the hidden state transitions leading to fast\nconvergence during training while efficiently learning discriminative latent\nfeatures that result in state-of-the-art results on several benchmark datasets\nat test-time. We propose a novel inexact Newton method to solve fixed-point\nconditions given model parameters for generating the latent features at each\nhidden state. We prove that our inexact Newton method converges locally with\nlinear rate (under mild conditions). We leverage this result for efficient\ntraining of ERNNs based on backpropagation.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 20:01:44 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Zhang", "Ziming", ""], ["Kag", "Anil", ""], ["Sullivan", "Alan", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1903.00757", "submitter": "Zhaocheng Zhu", "authors": "Zhaocheng Zhu, Shizhen Xu, Meng Qu, Jian Tang", "title": "GraphVite: A High-Performance CPU-GPU Hybrid System for Node Embedding", "comments": "accepted at WWW 2019", "journal-ref": null, "doi": "10.1145/3308558.3313508", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning continuous representations of nodes is attracting growing interest\nin both academia and industry recently, due to their simplicity and\neffectiveness in a variety of applications. Most of existing node embedding\nalgorithms and systems are capable of processing networks with hundreds of\nthousands or a few millions of nodes. However, how to scale them to networks\nthat have tens of millions or even hundreds of millions of nodes remains a\nchallenging problem. In this paper, we propose GraphVite, a high-performance\nCPU-GPU hybrid system for training node embeddings, by co-optimizing the\nalgorithm and the system. On the CPU end, augmented edge samples are parallelly\ngenerated by random walks in an online fashion on the network, and serve as the\ntraining data. On the GPU end, a novel parallel negative sampling is proposed\nto leverage multiple GPUs to train node embeddings simultaneously, without much\ndata transfer and synchronization. Moreover, an efficient collaboration\nstrategy is proposed to further reduce the synchronization cost between CPUs\nand GPUs. Experiments on multiple real-world networks show that GraphVite is\nsuper efficient. It takes only about one minute for a network with 1 million\nnodes and 5 million edges on a single machine with 4 GPUs, and takes around 20\nhours for a network with 66 million nodes and 1.8 billion edges. Compared to\nthe current fastest system, GraphVite is about 50 times faster without any\nsacrifice on performance.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 20:06:58 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Zhu", "Zhaocheng", ""], ["Xu", "Shizhen", ""], ["Qu", "Meng", ""], ["Tang", "Jian", ""]]}, {"id": "1903.00760", "submitter": "Ziming Zhang", "authors": "Ziming Zhang, Wenju Xu, Alan Sullivan", "title": "Time-Delay Momentum: A Regularization Perspective on the Convergence and\n  Generalization of Stochastic Momentum for Deep Learning", "comments": "has errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of convergence and generalization error\nbound of stochastic momentum for deep learning from the perspective of\nregularization. To do so, we first interpret momentum as solving an\n$\\ell_2$-regularized minimization problem to learn the offsets between\narbitrary two successive model parameters. We call this {\\em time-delay\nmomentum} because the model parameter is updated after a few iterations towards\nfinding the minimizer. We then propose our learning algorithm, \\ie stochastic\ngradient descent (SGD) with time-delay momentum. We show that our algorithm can\nbe interpreted as solving a sequence of strongly convex optimization problems\nusing SGD. We prove that under mild conditions our algorithm can converge to a\nstationary point with rate of $O(\\frac{1}{\\sqrt{K}})$ and generalization error\nbound of $O(\\frac{1}{\\sqrt{n\\delta}})$ with probability at least $1-\\delta$,\nwhere $K,n$ are the numbers of model updates and training samples,\nrespectively. We demonstrate the empirical superiority of our algorithm in deep\nlearning in comparison with the state-of-the-art deep learning solvers.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 20:21:38 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 23:05:37 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zhang", "Ziming", ""], ["Xu", "Wenju", ""], ["Sullivan", "Alan", ""]]}, {"id": "1903.00780", "submitter": "Alex Beutel", "authors": "Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Li Wei, Yi Wu, Lukasz\n  Heldt, Zhe Zhao, Lichan Hong, Ed H. Chi, Cristos Goodrow", "title": "Fairness in Recommendation Ranking through Pairwise Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are one of the most pervasive applications of machine\nlearning in industry, with many services using them to match users to products\nor information. As such it is important to ask: what are the possible fairness\nrisks, how can we quantify them, and how should we address them? In this paper\nwe offer a set of novel metrics for evaluating algorithmic fairness concerns in\nrecommender systems. In particular we show how measuring fairness based on\npairwise comparisons from randomized experiments provides a tractable means to\nreason about fairness in rankings from recommender systems. Building on this\nmetric, we offer a new regularizer to encourage improving this metric during\nmodel training and thus improve fairness in the resulting rankings. We apply\nthis pairwise regularization to a large-scale, production recommender system\nand show that we are able to significantly improve the system's pairwise\nfairness.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 22:29:42 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Beutel", "Alex", ""], ["Chen", "Jilin", ""], ["Doshi", "Tulsee", ""], ["Qian", "Hai", ""], ["Wei", "Li", ""], ["Wu", "Yi", ""], ["Heldt", "Lukasz", ""], ["Zhao", "Zhe", ""], ["Hong", "Lichan", ""], ["Chi", "Ed H.", ""], ["Goodrow", "Cristos", ""]]}, {"id": "1903.00784", "submitter": "Joseph Suarez", "authors": "Joseph Suarez, Yilun Du, Phillip Isola, Igor Mordatch", "title": "Neural MMO: A Massively Multiagent Game Environment for Training and\n  Evaluating Intelligent Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of complex life on Earth is often attributed to the arms race\nthat ensued from a huge number of organisms all competing for finite resources.\nWe present an artificial intelligence research environment, inspired by the\nhuman game genre of MMORPGs (Massively Multiplayer Online Role-Playing Games,\na.k.a. MMOs), that aims to simulate this setting in microcosm. As with MMORPGs\nand the real world alike, our environment is persistent and supports a large\nand variable number of agents. Our environment is well suited to the study of\nlarge-scale multiagent interaction: it requires that agents learn robust combat\nand navigation policies in the presence of large populations attempting to do\nthe same. Baseline experiments reveal that population size magnifies and\nincentivizes the development of skillful behaviors and results in agents that\noutcompete agents trained in smaller populations. We further show that the\npolicies of agents with unshared weights naturally diverge to fill different\nniches in order to avoid competition.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 22:42:33 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Suarez", "Joseph", ""], ["Du", "Yilun", ""], ["Isola", "Phillip", ""], ["Mordatch", "Igor", ""]]}, {"id": "1903.00788", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Yue Wu, Wael AbdAlmageed, Iacopo Masi, Premkumar\n  Natarajan", "title": "AIRD: Adversarial Learning Framework for Image Repurposing Detection", "comments": "Camera-ready version for the IEEE Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image repurposing is a commonly used method for spreading misinformation on\nsocial media and online forums, which involves publishing untampered images\nwith modified metadata to create rumors and further propaganda. While manual\nverification is possible, given vast amounts of verified knowledge available on\nthe internet, the increasing prevalence and ease of this form of semantic\nmanipulation call for the development of robust automatic ways of assessing the\nsemantic integrity of multimedia data. In this paper, we present a novel method\nfor image repurposing detection that is based on the real-world adversarial\ninterplay between a bad actor who repurposes images with counterfeit metadata\nand a watchdog who verifies the semantic consistency between images and their\naccompanying metadata, where both players have access to a reference dataset of\nverified content, which they can use to achieve their goals. The proposed\nmethod exhibits state-of-the-art performance on location-identity,\nsubject-identity and painting-artist verification, showing its efficacy across\na diverse set of scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 23:14:58 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 16:10:51 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 21:17:49 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Jaiswal", "Ayush", ""], ["Wu", "Yue", ""], ["AbdAlmageed", "Wael", ""], ["Masi", "Iacopo", ""], ["Natarajan", "Premkumar", ""]]}, {"id": "1903.00802", "submitter": "Aviral Kumar", "authors": "Aviral Kumar, Sunita Sarawagi", "title": "Calibration of Encoder Decoder Models for Neural Machine Translation", "comments": "12 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the calibration of several state of the art neural machine\ntranslation(NMT) systems built on attention-based encoder-decoder models. For\nstructured outputs like in NMT, calibration is important not just for reliable\nconfidence with predictions, but also for proper functioning of beam-search\ninference. We show that most modern NMT models are surprisingly miscalibrated\neven when conditioned on the true previous tokens. Our investigation leads to\ntwo main reasons -- severe miscalibration of EOS (end of sequence marker) and\nsuppression of attention uncertainty. We design recalibration methods based on\nthese signals and demonstrate improved accuracy, better sequence-level\ncalibration, and more intuitive results from beam-search.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 01:08:47 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Kumar", "Aviral", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "1903.00816", "submitter": "Martin Pavlovski", "authors": "Nino Arsov, Martin Pavlovski, Ljupco Kocarev", "title": "Stability of decision trees and logistic regression", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees and logistic regression are one of the most popular and\nwell-known machine learning algorithms, frequently used to solve a variety of\nreal-world problems. Stability of learning algorithms is a powerful tool to\nanalyze their performance and sensitivity and subsequently allow researchers to\ndraw reliable conclusions. The stability of these two algorithms has remained\nobscure. To that end, in this paper, we derive two stability notions for\ndecision trees and logistic regression: hypothesis and pointwise hypothesis\nstability. Additionally, we derive these notions for L2-regularized logistic\nregression and confirm existing findings that it is uniformly stable. We show\nthat the stability of decision trees depends on the number of leaves in the\ntree, i.e., its depth, while for logistic regression, it depends on the\nsmallest eigenvalue of the Hessian matrix of the cross-entropy loss. We show\nthat logistic regression is not a stable learning algorithm. We construct the\nupper bounds on the generalization error of all three algorithms. Moreover, we\npresent a novel stability measuring framework that allows one to measure the\naforementioned notions of stability. The measures are equivalent to estimates\nof expected loss differences at an input example and then leverage bootstrap\nsampling to yield statistically reliable estimates. Finally, we apply this\nframework to the three algorithms analyzed in this paper to confirm our\ntheoretical findings and, in addition, we discuss the possibilities of\ndeveloping new training techniques to optimize the stability of logistic\nregression, and hence decrease its generalization error.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 03:38:54 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Arsov", "Nino", ""], ["Pavlovski", "Martin", ""], ["Kocarev", "Ljupco", ""]]}, {"id": "1903.00827", "submitter": "Zhizheng Zhang", "authors": "Zhizheng Zhang, Jiale Chen, Zhibo Chen, Weiping Li", "title": "Asynchronous Episodic Deep Deterministic Policy Gradient: Towards\n  Continuous Control in Computationally Complex Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Deterministic Policy Gradient (DDPG) has been proved to be a successful\nreinforcement learning (RL) algorithm for continuous control tasks. However,\nDDPG still suffers from data insufficiency and training inefficiency,\nespecially in computationally complex environments. In this paper, we propose\nAsynchronous Episodic DDPG (AE-DDPG), as an expansion of DDPG, which can\nachieve more effective learning with less training time required. First, we\ndesign a modified scheme for data collection in an asynchronous fashion.\nGenerally, for asynchronous RL algorithms, sample efficiency or/and training\nstability diminish as the degree of parallelism increases. We consider this\nproblem from the perspectives of both data generation and data utilization. In\ndetail, we re-design experience replay by introducing the idea of episodic\ncontrol so that the agent can latch on good trajectories rapidly. In addition,\nwe also inject a new type of noise in action space to enrich the exploration\nbehaviors. Experiments demonstrate that our AE-DDPG achieves higher rewards and\nrequires less time consuming than most popular RL algorithms in Learning to Run\ntask which has a computationally complex environment. Not limited to the\ncontrol tasks in computationally complex environments, AE-DDPG also achieves\nhigher rewards and 2- to 4-fold improvement in sample efficiency on average\ncompared to other variants of DDPG in MuJoCo environments. Furthermore, we\nverify the effectiveness of each proposed technique component through abundant\nablation study.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 04:26:32 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Zhang", "Zhizheng", ""], ["Chen", "Jiale", ""], ["Chen", "Zhibo", ""], ["Li", "Weiping", ""]]}, {"id": "1903.00830", "submitter": "Vinayak Athavale", "authors": "Vinayak Athavale, Aayush Naik, Rajas Vanjape, Manish Shrivastava", "title": "Predicting Algorithm Classes for Programming Word Problems", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the task of algorithm class prediction for programming word\nproblems. A programming word problem is a problem written in natural language,\nwhich can be solved using an algorithm or a program. We define classes of\nvarious programming word problems which correspond to the class of algorithms\nrequired to solve the problem. We present four new datasets for this task, two\nmulticlass datasets with 550 and 1159 problems each and two multilabel datasets\nhaving 3737 and 3960 problems each. We pose the problem as a text\nclassification problem and train neural network and non-neural network-based\nmodels on this task. Our best performing classifier gets an accuracy of 62.7\npercent for the multiclass case on the five class classification dataset,\nCodeforces Multiclass-5 (CFMC5). We also do some human-level analysis and\ncompare human performance with that of our text classification models. Our best\nclassifier has an accuracy only 9 percent lower than that of a human on this\ntask. To the best of our knowledge, these are the first reported results on\nsuch a task. We make our code and datasets publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 04:39:33 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 17:24:56 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Athavale", "Vinayak", ""], ["Naik", "Aayush", ""], ["Vanjape", "Rajas", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1903.00840", "submitter": "Amir Zadeh", "authors": "Amir Zadeh, Yao-Chong Lim, Paul Pu Liang, Louis-Philippe Morency", "title": "Variational Auto-Decoder: A Method for Neural Generative Modeling from\n  Incomplete Data", "comments": "Link to code and data available from\n  https://github.com/A2Zadeh/Variational-Autodecoder", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a generative model from partial data (data with missingness) is a\nchallenging area of machine learning research. We study a specific\nimplementation of the Auto-Encoding Variational Bayes (AEVB) algorithm, named\nin this paper as a Variational Auto-Decoder (VAD). VAD is a generic framework\nwhich uses Variational Bayes and Markov Chain Monte Carlo (MCMC) methods to\nlearn a generative model from partial data. The main distinction between VAD\nand Variational Auto-Encoder (VAE) is the encoder component, as VAD does not\nhave one. Using a proposed efficient inference method from a multivariate\nGaussian approximate posterior, VAD models allow inference to be performed via\nsimple gradient ascent rather than MCMC sampling from a probabilistic decoder.\nThis technique reduces the inference computational cost, allows for using more\ncomplex optimization techniques during latent space inference (which are shown\nto be crucial due to a high degree of freedom in the VAD latent space), and\nkeeps the framework simple to implement. Through extensive experiments over\nseveral datasets and different missing ratios, we show that encoders cannot\nefficiently marginalize the input volatility caused by imputed missing values.\nWe study multimodal datasets in this paper, which is a particular area of\nimpact for VAD models.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 06:19:55 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 02:47:29 GMT"}, {"version": "v3", "created": "Sun, 24 Mar 2019 00:39:41 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2019 21:04:05 GMT"}, {"version": "v5", "created": "Sun, 26 May 2019 13:45:51 GMT"}, {"version": "v6", "created": "Sun, 3 Jan 2021 08:27:20 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zadeh", "Amir", ""], ["Lim", "Yao-Chong", ""], ["Liang", "Paul Pu", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1903.00843", "submitter": "Xiang Liu", "authors": "Xiang Liu, Ziyang Tang, Huyunting Huang, Tonglin Zhang, Baijian Yang", "title": "Multiple Learning for Regression in big data", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression problems that have closed-form solutions are well understood and\ncan be easily implemented when the dataset is small enough to be all loaded\ninto the RAM. Challenges arise when data is too big to be stored in RAM to\ncompute the closed form solutions. Many techniques were proposed to overcome or\nalleviate the memory barrier problem but the solutions are often local optimal.\nIn addition, most approaches require accessing the raw data again when updating\nthe models. Parallel computing clusters are also expected if multiple models\nneed to be computed simultaneously. We propose multiple learning approaches\nthat utilize an array of sufficient statistics (SS) to address this big data\nchallenge. This memory oblivious approach breaks the memory barrier when\ncomputing regressions with closed-form solutions, including but not limited to\nlinear regression, weighted linear regression, linear regression with Box-Cox\ntransformation (Box-Cox regression) and ridge regression models. The\ncomputation and update of the SS array can be handled at per row level or per\nmini-batch level. And updating a model is as easy as matrix addition and\nsubtraction. Furthermore, multiple SS arrays for different models can be easily\ncomputed simultaneously to obtain multiple models at one pass through the\ndataset. We implemented our approaches on Spark and evaluated over the\nsimulated datasets. Results showed our approaches can achieve closed-form\nsolutions of multiple models at the cost of half training time of the\ntraditional methods for a single model.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 06:34:24 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 00:39:30 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Liu", "Xiang", ""], ["Tang", "Ziyang", ""], ["Huang", "Huyunting", ""], ["Zhang", "Tonglin", ""], ["Yang", "Baijian", ""]]}, {"id": "1903.00847", "submitter": "Wenchao Ding", "authors": "Wenchao Ding and Shaojie Shen", "title": "Online Vehicle Trajectory Prediction using Policy Anticipation Network\n  and Optimization-based Context Reasoning", "comments": "6+n pages. Accepted to International Conference on Robotics and\n  Automation (ICRA) 2019. IEEE copyright", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an online two-level vehicle trajectory prediction\nframework for urban autonomous driving where there are complex contextual\nfactors, such as lane geometries, road constructions, traffic regulations and\nmoving agents. Our method combines high-level policy anticipation with\nlow-level context reasoning. We leverage a long short-term memory (LSTM)\nnetwork to anticipate the vehicle's driving policy (e.g., forward, yield, turn\nleft, turn right, etc.) using its sequential history observations. The policy\nis then used to guide a low-level optimization-based context reasoning process.\nWe show that it is essential to incorporate the prior policy anticipation due\nto the multimodal nature of the future trajectory. Moreover, contrary to\nexisting regression-based trajectory prediction methods, our optimization-based\nreasoning process can cope with complex contextual factors. The final output of\nthe two-level reasoning process is a continuous trajectory that automatically\nadapts to different traffic configurations and accurately predicts future\nvehicle motions. The performance of the proposed framework is analyzed and\nvalidated in an emerging autonomous driving simulation platform (CARLA).\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 06:54:20 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Ding", "Wenchao", ""], ["Shen", "Shaojie", ""]]}, {"id": "1903.00848", "submitter": "Wenchao Ding", "authors": "Wenchao Ding and Jing Chen and Shaojie Shen", "title": "Predicting Vehicle Behaviors Over An Extended Horizon Using Behavior\n  Interaction Network", "comments": "6+n pages. Accepted to International Conference on Robotics and\n  Automation (ICRA) 2019. IEEE copyright", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anticipating possible behaviors of traffic participants is an essential\ncapability of autonomous vehicles. Many behavior detection and maneuver\nrecognition methods only have a very limited prediction horizon that leaves\ninadequate time and space for planning. To avoid unsatisfactory reactive\ndecisions, it is essential to count long-term future rewards in planning, which\nrequires extending the prediction horizon. In this paper, we uncover that clues\nto vehicle behaviors over an extended horizon can be found in vehicle\ninteraction, which makes it possible to anticipate the likelihood of a certain\nbehavior, even in the absence of any clear maneuver pattern. We adopt a\nrecurrent neural network (RNN) for observation encoding, and based on that, we\npropose a novel vehicle behavior interaction network (VBIN) to capture the\nvehicle interaction from the hidden states and connection feature of each\ninteraction pair. The output of our method is a probabilistic likelihood of\nmultiple behavior classes, which matches the multimodal and uncertain nature of\nthe distant future. A systematic comparison of our method against two\nstate-of-the-art methods and another two baseline methods on a publicly\navailable real highway dataset is provided, showing that our method has\nsuperior accuracy and advanced capability for interaction modeling.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 06:54:33 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 07:41:18 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ding", "Wenchao", ""], ["Chen", "Jing", ""], ["Shen", "Shaojie", ""]]}, {"id": "1903.00863", "submitter": "Kelvin Hsu", "authors": "Kelvin Hsu and Fabio Ramos", "title": "Bayesian Learning of Conditional Kernel Mean Embeddings for Automatic\n  Likelihood-Free Inference", "comments": "To appear in the Proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2019, Naha, Okinawa, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In likelihood-free settings where likelihood evaluations are intractable,\napproximate Bayesian computation (ABC) addresses the formidable inference task\nto discover plausible parameters of simulation programs that explain the\nobservations. However, they demand large quantities of simulation calls.\nCritically, hyperparameters that determine measures of simulation discrepancy\ncrucially balance inference accuracy and sample efficiency, yet are difficult\nto tune. In this paper, we present kernel embedding likelihood-free inference\n(KELFI), a holistic framework that automatically learns model hyperparameters\nto improve inference accuracy given limited simulation budget. By leveraging\nlikelihood smoothness with conditional mean embeddings, we nonparametrically\napproximate likelihoods and posteriors as surrogate densities and sample from\nclosed-form posterior mean embeddings, whose hyperparameters are learned under\nits approximate marginal likelihood. Our modular framework demonstrates\nimproved accuracy and efficiency on challenging inference problems in ecology.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 09:02:55 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Hsu", "Kelvin", ""], ["Ramos", "Fabio", ""]]}, {"id": "1903.00904", "submitter": "Xuhong Wang", "authors": "Xuhong Wang, Ying Du, Shijie Lin, Ping Cui, Yuntian Shen and Yupu Yang", "title": "adVAE: A self-adversarial variational autoencoder with Gaussian anomaly\n  prior knowledge for anomaly detection", "comments": "This paper has been accepted by Knowledge-based Systems", "journal-ref": null, "doi": "10.1016/j.knosys.2019.105187", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep generative models have become increasingly popular in\nunsupervised anomaly detection. However, deep generative models aim at\nrecovering the data distribution rather than detecting anomalies. Besides, deep\ngenerative models have the risk of overfitting training samples, which has\ndisastrous effects on anomaly detection performance. To solve the above two\nproblems, we propose a Self-adversarial Variational Autoencoder with a Gaussian\nanomaly prior assumption. We assume that both the anomalous and the normal\nprior distribution are Gaussian and have overlaps in the latent space.\nTherefore, a Gaussian transformer net T is trained to synthesize anomalous but\nnear-normal latent variables. Keeping the original training objective of\nVariational Autoencoder, besides, the generator G tries to distinguish between\nthe normal latent variables and the anomalous ones synthesized by T, and the\nencoder E is trained to discriminate whether the output of G is real. These new\nobjectives we added not only give both G and E the ability to discriminate but\nalso introduce additional regularization to prevent overfitting. Compared with\nthe SOTA baselines, the proposed model achieves significant improvements in\nextensive experiments. Datasets and our model are available at a Github\nrepository.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 13:26:19 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 03:37:40 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 12:20:13 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Wang", "Xuhong", ""], ["Du", "Ying", ""], ["Lin", "Shijie", ""], ["Cui", "Ping", ""], ["Shen", "Yuntian", ""], ["Yang", "Yupu", ""]]}, {"id": "1903.00905", "submitter": "Anirudha Vishvakarma", "authors": "Anirudha Vishvakarma", "title": "MILDNet: A Lightweight Single Scaled Deep Ranking Architecture", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-scale deep CNN architecture [1, 2, 3] successfully captures both fine\nand coarse level image descriptors for visual similarity task, but they come up\nwith expensive memory overhead and latency. In this paper, we propose a\ncompeting novel CNN architecture, called MILDNet, which merits by being vastly\ncompact (about 3 times). Inspired by the fact that successive CNN layers\nrepresent the image with increasing levels of abstraction, we compressed our\ndeep ranking model to a single CNN by coupling activations from multiple\nintermediate layers along with the last layer. Trained on the famous\nStreet2shop dataset [4], we demonstrate that our approach performs as good as\nthe current state-of-the-art models with only one third of the parameters,\nmodel size, training time and significant reduction in inference time. The\nsignificance of intermediate layers on image retrieval task has also been shown\nto be performing on popular datasets Holidays, Oxford, Paris [5]. So even\nthough our experiments are done on ecommerce domain, it is applicable to other\ndomains as well. We further did an ablation study to validate our hypothesis by\nchecking the impact on adding each intermediate layer. With this we also\npresent two more useful variants of MILDNet, a mobile model (12 times smaller)\nfor on-edge devices and a compactly featured model (512-d feature embeddings)\nfor systems with less RAMs and to reduce the ranking cost. Further we present\nan intuitive way to automatically create a tailored in-house triplet training\ndataset, which is very hard to create manually. This solution too can also be\ndeployed as an all-inclusive visual similarity solution. Finally, we present\nour entire production level architecture which currently powers visual\nsimilarity at Fynd.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 13:26:37 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 02:54:09 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Vishvakarma", "Anirudha", ""]]}, {"id": "1903.00906", "submitter": "Bokang Zhu", "authors": "Bokang Zhu, Richong Zhang, Dingkun Long and Yongyi Mao", "title": "Understanding Feature Selection and Feature Memorization in Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a test, called Flagged-1-Bit (F1B) test, to study\nthe intrinsic capability of recurrent neural networks in sequence learning.\nFour different recurrent network models are studied both analytically and\nexperimentally using this test. Our results suggest that in general there\nexists a conflict between feature selection and feature memorization in\nsequence learning. Such a conflict can be resolved either using a gating\nmechanism as in LSTM, or by increasing the state dimension as in Vanilla RNN.\nGated models resolve this conflict by adaptively adjusting their state-update\nequations, whereas Vanilla RNN resolves this conflict by assigning different\ndimensions different tasks. Insights into feature selection and memorization in\nrecurrent networks are given.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 13:29:33 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Zhu", "Bokang", ""], ["Zhang", "Richong", ""], ["Long", "Dingkun", ""], ["Mao", "Yongyi", ""]]}, {"id": "1903.00919", "submitter": "Bing Yu", "authors": "Bing Yu, Mengzhang Li, Jiyong Zhang, Zhanxing Zhu", "title": "3D Graph Convolutional Networks with Temporal Graphs: A Spatial\n  Information Free Framework For Traffic Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal prediction plays an important role in many application areas\nespecially in traffic domain. However, due to complicated spatio-temporal\ndependency and high non-linear dynamics in road networks, traffic prediction\ntask is still challenging. Existing works either exhibit heavy training cost or\nfail to accurately capture the spatio-temporal patterns, also ignore the\ncorrelation between distant roads that share the similar patterns. In this\npaper, we propose a novel deep learning framework to overcome these issues: 3D\nTemporal Graph Convolutional Networks (3D-TGCN). Two novel components of our\nmodel are introduced. (1) Instead of constructing the road graph based on\nspatial information, we learn it by comparing the similarity between time\nseries for each road, thus providing a spatial information free framework. (2)\nWe propose an original 3D graph convolution model to model the spatio-temporal\ndata more accurately. Empirical results show that 3D-TGCN could outperform\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 14:44:07 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Yu", "Bing", ""], ["Li", "Mengzhang", ""], ["Zhang", "Jiyong", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1903.00925", "submitter": "Jasmine Collins", "authors": "Jasmine Collins and Johannes Balle and Jonathon Shlens", "title": "Accelerating Training of Deep Neural Networks with a Standardization\n  Loss", "comments": "Technical report. Results presented at WiML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant advance in accelerating neural network training has been the\ndevelopment of normalization methods, permitting the training of deep models\nboth faster and with better accuracy. These advances come with practical\nchallenges: for instance, batch normalization ties the prediction of individual\nexamples with other examples within a batch, resulting in a network that is\nheavily dependent on batch size. Layer normalization and group normalization\nare data-dependent and thus must be continually used, even at test-time. To\naddress the issues that arise from using explicit normalization techniques, we\npropose to replace existing normalization methods with a simple, secondary\nobjective loss that we term a standardization loss. This formulation is\nflexible and robust across different batch sizes and surprisingly, this\nsecondary objective accelerates learning on the primary training objective.\nBecause it is a training loss, it is simply removed at test-time, and no\nfurther effort is needed to maintain normalized activations. We find that a\nstandardization loss accelerates training on both small- and large-scale image\nclassification experiments, works with a variety of architectures, and is\nlargely robust to training across different batch sizes.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 15:17:06 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Collins", "Jasmine", ""], ["Balle", "Johannes", ""], ["Shlens", "Jonathon", ""]]}, {"id": "1903.00954", "submitter": "Jonas Rothfuss", "authors": "Jonas Rothfuss, Fabio Ferreira, Simon Walther, Maxim Ulrich", "title": "Conditional Density Estimation with Neural Networks: Best Practices and\n  Benchmarks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.CP q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a set of empirical observations, conditional density estimation aims to\ncapture the statistical relationship between a conditional variable\n$\\mathbf{x}$ and a dependent variable $\\mathbf{y}$ by modeling their\nconditional probability $p(\\mathbf{y}|\\mathbf{x})$. The paper develops best\npractices for conditional density estimation for finance applications with\nneural networks, grounded on mathematical insights and empirical evaluations.\nIn particular, we introduce a noise regularization and data normalization\nscheme, alleviating problems with over-fitting, initialization and\nhyper-parameter sensitivity of such estimators. We compare our proposed\nmethodology with popular semi- and non-parametric density estimators, underpin\nits effectiveness in various benchmarks on simulated and Euro Stoxx 50 data and\nshow its superior performance. Our methodology allows to obtain high-quality\nestimators for statistical expectations of higher moments, quantiles and\nnon-linear return transformations, with very little assumptions about the\nreturn dynamic.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 18:15:20 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 11:20:14 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Rothfuss", "Jonas", ""], ["Ferreira", "Fabio", ""], ["Walther", "Simon", ""], ["Ulrich", "Maxim", ""]]}, {"id": "1903.00958", "submitter": "Andrew Perrault", "authors": "Andrew Perrault, Bryan Wilder, Eric Ewing, Aditya Mate, Bistra\n  Dilkina, Milind Tambe", "title": "End-to-End Game-Focused Learning of Adversary Behavior in Security Games", "comments": "Appeared at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stackelberg security games are a critical tool for maximizing the utility of\nlimited defense resources to protect important targets from an intelligent\nadversary. Motivated by green security, where the defender may only observe an\nadversary's response to defense on a limited set of targets, we study the\nproblem of learning a defense that generalizes well to a new set of targets\nwith novel feature values and combinations. Traditionally, this problem has\nbeen addressed via a two-stage approach where an adversary model is trained to\nmaximize predictive accuracy without considering the defender's optimization\nproblem. We develop an end-to-end game-focused approach, where the adversary\nmodel is trained to maximize a surrogate for the defender's expected utility.\nWe show both in theory and experimental results that our game-focused approach\nachieves higher defender expected utility than the two-stage alternative when\nthere is limited data.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 18:43:41 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 18:56:11 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Perrault", "Andrew", ""], ["Wilder", "Bryan", ""], ["Ewing", "Eric", ""], ["Mate", "Aditya", ""], ["Dilkina", "Bistra", ""], ["Tambe", "Milind", ""]]}, {"id": "1903.00974", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky", "title": "Anytime Online-to-Batch Conversions, Optimism, and Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard way to obtain convergence guarantees in stochastic convex\noptimization is to run an online learning algorithm and then output the average\nof its iterates: the actual iterates of the online learning algorithm do not\ncome with individual guarantees. We close this gap by introducing a black-box\nmodification to any online learning algorithm whose iterates converge to the\noptimum in stochastic scenarios. We then consider the case of smooth losses,\nand show that combining our approach with optimistic online learning algorithms\nimmediately yields a fast convergence rate of $O(L/T^{3/2}+\\sigma/\\sqrt{T})$ on\n$L$-smooth problems with $\\sigma^2$ variance in the gradients. Finally, we\nprovide a reduction that converts any adaptive online algorithm into one that\nobtains the optimal accelerated rate of $\\tilde O(L/T^2 + \\sigma/\\sqrt{T})$,\nwhile still maintaining $\\tilde O(1/\\sqrt{T})$ convergence in the non-smooth\nsetting. Importantly, our algorithms adapt to $L$ and $\\sigma$ automatically:\nthey do not need to know either to obtain these rates.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 19:56:32 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Cutkosky", "Ashok", ""]]}, {"id": "1903.00979", "submitter": "Sarthak Chatterjee", "authors": "Sarthak Chatterjee, Orlando Romero, S\\'ergio Pequito", "title": "Analysis of a Generalized Expectation-Maximization Algorithm for\n  Gaussian Mixture Models: A Control Systems Perspective", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization (EM) algorithm is one of the most popular\nmethods used to solve the problem of parametric distribution-based clustering\nin unsupervised learning. In this paper, we propose to analyze a generalized EM\n(GEM) algorithm in the context of Gaussian mixture models, where the\nmaximization step in the EM is replaced by an increasing step. We show that\nthis GEM algorithm can be understood as a linear time-invariant (LTI) system\nwith a feedback nonlinearity. Therefore, we explore some of its convergence\nproperties by leveraging tools from robust control theory. Lastly, we explain\nhow the proposed GEM can be designed, and present a pedagogical example to\nunderstand the advantages of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 20:09:39 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 17:48:29 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 22:37:00 GMT"}, {"version": "v4", "created": "Tue, 18 May 2021 04:46:31 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Chatterjee", "Sarthak", ""], ["Romero", "Orlando", ""], ["Pequito", "S\u00e9rgio", ""]]}, {"id": "1903.00985", "submitter": "Didong Li", "authors": "Didong Li and David B Dunson", "title": "Classification via local manifold approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers label data as belonging to one of a set of groups based on input\nfeatures. It is challenging to obtain accurate classification performance when\nthe feature distributions in the different classes are complex, with nonlinear,\noverlapping and intersecting supports. This is particularly true when training\ndata are limited. To address this problem, this article proposes a new type of\nclassifier based on obtaining a local approximation to the support of the data\nwithin each class in a neighborhood of the feature to be classified, and\nassigning the feature to the class having the closest support. This general\nalgorithm is referred to as LOcal Manifold Approximation (LOMA) classification.\nAs a simple and theoretically supported special case having excellent\nperformance in a broad variety of examples, we use spheres for local\napproximation, obtaining a SPherical Approximation (SPA) classifier. We\nillustrate substantial gains for SPA over competitors on a variety of\nchallenging simulated and real data examples.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 20:54:47 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Li", "Didong", ""], ["Dunson", "David B", ""]]}, {"id": "1903.01000", "submitter": "Vivek Sharma", "authors": "Vivek Sharma, Makarand Tapaswi, M.Saquib Sarfraz, Rainer Stiefelhagen", "title": "Self-Supervised Learning of Face Representations for Video Face\n  Clustering", "comments": "To appear at International Conference on Automatic Face and Gesture\n  Recognition (2019) as an Oral. The datasets and code are available at\n  https://github.com/vivoutlaw/SSIAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analyzing the story behind TV series and movies often requires understanding\nwho the characters are and what they are doing. With improving deep face\nmodels, this may seem like a solved problem. However, as face detectors get\nbetter, clustering/identification needs to be revisited to address increasing\ndiversity in facial appearance. In this paper, we address video face clustering\nusing unsupervised methods. Our emphasis is on distilling the essential\ninformation, identity, from the representations obtained using deep pre-trained\nface networks. We propose a self-supervised Siamese network that can be trained\nwithout the need for video/track based supervision, and thus can also be\napplied to image collections. We evaluate our proposed method on three video\nface clustering datasets. The experiments show that our methods outperform\ncurrent state-of-the-art methods on all datasets. Video face clustering is\nlacking a common benchmark as current works are often evaluated with different\nmetrics and/or different sets of face tracks.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 21:53:15 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Sharma", "Vivek", ""], ["Tapaswi", "Makarand", ""], ["Sarfraz", "M. Saquib", ""], ["Stiefelhagen", "Rainer", ""]]}, {"id": "1903.01003", "submitter": "Mohamed Akrout", "authors": "Ismail Akrout, Amal Feriani, Mohamed Akrout", "title": "Hacking Google reCAPTCHA v3 using Reinforcement Learning", "comments": "Accepted for the Conference on Reinforcement Learning and Decision\n  Making (RLDM) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Reinforcement Learning (RL) methodology to bypass Google\nreCAPTCHA v3. We formulate the problem as a grid world where the agent learns\nhow to move the mouse and click on the reCAPTCHA button to receive a high\nscore. We study the performance of the agent when we vary the cell size of the\ngrid world and show that the performance drops when the agent takes big steps\ntoward the goal. Finally, we used a divide and conquer strategy to defeat the\nreCAPTCHA system for any grid resolution. Our proposed method achieves a\nsuccess rate of 97.4% on a 100x100 grid and 96.7% on a 1000x1000 screen\nresolution.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 22:10:47 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 05:22:08 GMT"}, {"version": "v3", "created": "Thu, 18 Apr 2019 16:22:33 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Akrout", "Ismail", ""], ["Feriani", "Amal", ""], ["Akrout", "Mohamed", ""]]}, {"id": "1903.01004", "submitter": "Edouard Leurent", "authors": "Nicolas Carrara, Edouard Leurent, Romain Laroche, Tanguy Urvoy,\n  Odalric-Ambrym Maillard, Olivier Pietquin", "title": "Budgeted Reinforcement Learning in Continuous State Space", "comments": "N. Carrara and E. Leurent have equally contributed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Budgeted Markov Decision Process (BMDP) is an extension of a Markov\nDecision Process to critical applications requiring safety constraints. It\nrelies on a notion of risk implemented in the shape of a cost signal\nconstrained to lie below an - adjustable - threshold. So far, BMDPs could only\nbe solved in the case of finite state spaces with known dynamics. This work\nextends the state-of-the-art to continuous spaces environments and unknown\ndynamics. We show that the solution to a BMDP is a fixed point of a novel\nBudgeted Bellman Optimality operator. This observation allows us to introduce\nnatural extensions of Deep Reinforcement Learning algorithms to address\nlarge-scale BMDPs. We validate our approach on two simulated applications:\nspoken dialogue and autonomous driving.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 22:24:01 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 17:37:51 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 21:50:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Carrara", "Nicolas", ""], ["Leurent", "Edouard", ""], ["Laroche", "Romain", ""], ["Urvoy", "Tanguy", ""], ["Maillard", "Odalric-Ambrym", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1903.01021", "submitter": "Michael Cohen", "authors": "Michael K. Cohen, Elliot Catt, Marcus Hutter", "title": "A Strongly Asymptotically Optimal Agent in General Environments", "comments": "7 pages, 3 figures", "journal-ref": "Proc.IJCAI (2019) 2179-2186", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning agents are expected to eventually perform well.\nTypically, this takes the form of a guarantee about the asymptotic behavior of\nan algorithm given some assumptions about the environment. We present an\nalgorithm for a policy whose value approaches the optimal value with\nprobability 1 in all computable probabilistic environments, provided the agent\nhas a bounded horizon. This is known as strong asymptotic optimality, and it\nwas previously unknown whether it was possible for a policy to be strongly\nasymptotically optimal in the class of all computable probabilistic\nenvironments. Our agent, Inquisitive Reinforcement Learner (Inq), is more\nlikely to explore the more it expects an exploratory action to reduce its\nuncertainty about which environment it is in, hence the term inquisitive.\nExploring inquisitively is a strategy that can be applied generally; for more\nmanageable environment classes, inquisitiveness is tractable. We conducted\nexperiments in \"grid-worlds\" to compare the Inquisitive Reinforcement Learner\nto other weakly asymptotically optimal agents.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 00:02:58 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 04:30:13 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Cohen", "Michael K.", ""], ["Catt", "Elliot", ""], ["Hutter", "Marcus", ""]]}, {"id": "1903.01026", "submitter": "Hossein Aboutalebi", "authors": "Hossein Aboutalebi, Doina Precup, Tibor Schuster", "title": "Learning Modular Safe Policies in the Bandit Setting with Application to\n  Adaptive Clinical Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic multi-armed bandit problem is a well-known model for studying\nthe exploration-exploitation trade-off. It has significant possible\napplications in adaptive clinical trials, which allow for dynamic changes in\nthe treatment allocation probabilities of patients. However, most bandit\nlearning algorithms are designed with the goal of minimizing the expected\nregret. While this approach is useful in many areas, in clinical trials, it can\nbe sensitive to outlier data, especially when the sample size is small. In this\npaper, we define and study a new robustness criterion for bandit problems.\nSpecifically, we consider optimizing a function of the distribution of returns\nas a regret measure. This provides practitioners more flexibility to define an\nappropriate regret measure. The learning algorithm we propose to solve this\ntype of problem is a modification of the BESA algorithm [Baransi et al., 2014],\nwhich considers a more general version of regret. We present a regret bound for\nour approach and evaluate it empirically both on synthetic problems as well as\non a dataset from the clinical trial literature. Our approach compares\nfavorably to a suite of standard bandit algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 00:42:41 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 17:59:48 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 15:18:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Aboutalebi", "Hossein", ""], ["Precup", "Doina", ""], ["Schuster", "Tibor", ""]]}, {"id": "1903.01032", "submitter": "Fabio Pasqualetti", "authors": "Abed AlRahman Al Makdah, Vaibhav Katewa, and Fabio Pasqualetti", "title": "A Fundamental Performance Limitation for Adversarial Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the widespread use of machine learning algorithms to solve problems\nof technological, economic, and social relevance, provable guarantees on the\nperformance of these data-driven algorithms are critically lacking, especially\nwhen the data originates from unreliable sources and is transmitted over\nunprotected and easily accessible channels. In this paper we take an important\nstep to bridge this gap and formally show that, in a quest to optimize their\naccuracy, binary classification algorithms -- including those based on\nmachine-learning techniques -- inevitably become more sensitive to adversarial\nmanipulation of the data. Further, for a given class of algorithms with the\nsame complexity (i.e., number of classification boundaries), the fundamental\ntradeoff curve between accuracy and sensitivity depends solely on the\nstatistics of the data, and cannot be improved by tuning the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 01:22:40 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 00:25:25 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Makdah", "Abed AlRahman Al", ""], ["Katewa", "Vaibhav", ""], ["Pasqualetti", "Fabio", ""]]}, {"id": "1903.01042", "submitter": "Sanghamitra Dutta", "authors": "Sanghamitra Dutta, Ziqian Bai, Tze Meng Low, Pulkit Grover", "title": "CodeNet: Training Large Scale Neural Networks in Presence of Soft-Errors", "comments": "Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes the first strategy to make distributed training of neural\nnetworks resilient to computing errors, a problem that has remained unsolved\ndespite being first posed in 1956 by von Neumann. He also speculated that the\nefficiency and reliability of the human brain is obtained by allowing for low\npower but error-prone components with redundancy for error-resilience. It is\nsurprising that this problem remains open, even as massive artificial neural\nnetworks are being trained on increasingly low-cost and unreliable processing\nunits. Our coding-theory-inspired strategy, \"CodeNet,\" solves this problem by\naddressing three challenges in the science of reliable computing: (i) Providing\nthe first strategy for error-resilient neural network training by encoding each\nlayer separately; (ii) Keeping the overheads of coding\n(encoding/error-detection/decoding) low by obviating the need to re-encode the\nupdated parameter matrices after each iteration from scratch. (iii) Providing a\ncompletely decentralized implementation with no central node (which is a single\npoint of failure), allowing all primary computational steps to be error-prone.\nWe theoretically demonstrate that CodeNet has higher error tolerance than\nreplication, which we leverage to speed up computation time. Simultaneously,\nCodeNet requires lower redundancy than replication, and equal computational and\ncommunication costs in scaling sense. We first demonstrate the benefits of\nCodeNet in reducing expected computation time over replication when accounting\nfor checkpointing. Our experiments show that CodeNet achieves the best\naccuracy-runtime tradeoff compared to both replication and uncoded strategies.\nCodeNet is a significant step towards biologically plausible neural network\ntraining, that could hold the key to orders of magnitude efficiency\nimprovements.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 01:45:14 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Dutta", "Sanghamitra", ""], ["Bai", "Ziqian", ""], ["Low", "Tze Meng", ""], ["Grover", "Pulkit", ""]]}, {"id": "1903.01045", "submitter": "Hasan Poonawala", "authors": "Baoyang Song, Hasan Poonawala, Laura Wynter, Sebastien Blandin", "title": "Robust commuter movement inference from connected mobile devices", "comments": "International Conference on Data Mining 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The preponderance of connected devices provides unprecedented opportunities\nfor fine-grained monitoring of the public infrastructure. However while\nclassical models expect high quality application-specific data streams, the\npromise of the Internet of Things (IoT) is that of an abundance of disparate\nand noisy datasets from connected devices. In this context, we consider the\nproblem of estimation of the level of service of a city-wide public transport\nnetwork. We first propose a robust unsupervised model for train movement\ninference from wifi traces, via the application of robust clustering methods to\na one dimensional spatio-temporal setting. We then explore the extent to which\nthe demand-supply gap can be estimated from connected devices. We propose a\nclassification model of real-time commuter patterns, including both a batch\ntraining phase and an online learning component. We describe our deployment\narchitecture and assess our system accuracy on a large-scale anonymized dataset\ncomprising more than 10 billion records.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 02:18:31 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Song", "Baoyang", ""], ["Poonawala", "Hasan", ""], ["Wynter", "Laura", ""], ["Blandin", "Sebastien", ""]]}, {"id": "1903.01057", "submitter": "Dong Huang", "authors": "Dong Huang, Chang-Dong Wang, Jian-Sheng Wu, Jian-Huang Lai, Chee-Keong\n  Kwoh", "title": "Ultra-Scalable Spectral Clustering and Ensemble Clustering", "comments": "To appear in IEEE Transactions on Knowledge and Data Engineering,\n  2019", "journal-ref": null, "doi": "10.1109/TKDE.2019.2903410", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on scalability and robustness of spectral clustering for\nextremely large-scale datasets with limited resources. Two novel algorithms are\nproposed, namely, ultra-scalable spectral clustering (U-SPEC) and\nultra-scalable ensemble clustering (U-SENC). In U-SPEC, a hybrid representative\nselection strategy and a fast approximation method for K-nearest\nrepresentatives are proposed for the construction of a sparse affinity\nsub-matrix. By interpreting the sparse sub-matrix as a bipartite graph, the\ntransfer cut is then utilized to efficiently partition the graph and obtain the\nclustering result. In U-SENC, multiple U-SPEC clusterers are further integrated\ninto an ensemble clustering framework to enhance the robustness of U-SPEC while\nmaintaining high efficiency. Based on the ensemble generation via multiple\nU-SEPC's, a new bipartite graph is constructed between objects and base\nclusters and then efficiently partitioned to achieve the consensus clustering\nresult. It is noteworthy that both U-SPEC and U-SENC have nearly linear time\nand space complexity, and are capable of robustly and efficiently partitioning\nten-million-level nonlinearly-separable datasets on a PC with 64GB memory.\nExperiments on various large-scale datasets have demonstrated the scalability\nand robustness of our algorithms. The MATLAB code and experimental data are\navailable at https://www.researchgate.net/publication/330760669.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 03:30:23 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 07:33:18 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Huang", "Dong", ""], ["Wang", "Chang-Dong", ""], ["Wu", "Jian-Sheng", ""], ["Lai", "Jian-Huang", ""], ["Kwoh", "Chee-Keong", ""]]}, {"id": "1903.01061", "submitter": "Zhi-Gang Liu", "authors": "Zhi-Gang Liu and Matthew Mattina", "title": "Learning low-precision neural networks without Straight-Through\n  Estimator(STE)", "comments": "conference version accepted by IJCAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Straight-Through Estimator (STE) is widely used for back-propagating\ngradients through the quantization function, but the STE technique lacks a\ncomplete theoretical understanding. We propose an alternative methodology\ncalled alpha-blending (AB), which quantizes neural networks to low-precision\nusing stochastic gradient descent (SGD). Our method (AB) avoids STE\napproximation by replacing the quantized weight in the loss function by an\naffine combination of the quantized weight w_q and the corresponding\nfull-precision weight w with non-trainable scalar coefficient $\\alpha$ and\n$1-\\alpha$. During training, $\\alpha$ is gradually increased from 0 to 1; the\ngradient updates to the weights are through the full-precision term,\n$(1-\\alpha)w$, of the affine combination; the model is converted from\nfull-precision to low-precision progressively. To evaluate the method, a 1-bit\nBinaryNet on CIFAR10 dataset and 8-bits, 4-bits MobileNet v1, ResNet_50 v1/2 on\nImageNet dataset are trained using the alpha-blending approach, and the\nevaluation indicates that AB improves top-1 accuracy by 0.9%, 0.82% and 2.93%\nrespectively compared to the results of STE based quantization.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 03:47:19 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 19:09:40 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Liu", "Zhi-Gang", ""], ["Mattina", "Matthew", ""]]}, {"id": "1903.01063", "submitter": "Yuxiang Yang", "authors": "Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Jie Tan, Chelsea Finn", "title": "NoRML: No-Reward Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently adapting to new environments and changes in dynamics is critical\nfor agents to successfully operate in the real world. Reinforcement learning\n(RL) based approaches typically rely on external reward feedback for\nadaptation. However, in many scenarios this reward signal might not be readily\navailable for the target task, or the difference between the environments can\nbe implicit and only observable from the dynamics. To this end, we introduce a\nmethod that allows for self-adaptation of learned policies: No-Reward Meta\nLearning (NoRML). NoRML extends Model Agnostic Meta Learning (MAML) for RL and\nuses observable dynamics of the environment instead of an explicit reward\nfunction in MAML's finetune step. Our method has a more expressive update step\nthan MAML, while maintaining MAML's gradient based foundation. Additionally, in\norder to allow more targeted exploration, we implement an extension to MAML\nthat effectively disconnects the meta-policy parameters from the fine-tuned\npolicies' parameters. We first study our method on a number of synthetic\ncontrol problems and then validate our method on common benchmark environments,\nshowing that NoRML outperforms MAML when the dynamics change between tasks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 04:00:38 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Yang", "Yuxiang", ""], ["Caluwaerts", "Ken", ""], ["Iscen", "Atil", ""], ["Tan", "Jie", ""], ["Finn", "Chelsea", ""]]}, {"id": "1903.01069", "submitter": "Michael Mozer", "authors": "Been Kim, Emily Reif, Martin Wattenberg, Samy Bengio, Michael C. Mozer", "title": "Neural Networks Trained on Natural Scenes Exhibit Gestalt Closure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gestalt laws of perceptual organization, which describe how visual\nelements in an image are grouped and interpreted, have traditionally been\nthought of as innate despite their ecological validity. We use deep-learning\nmethods to investigate whether natural scene statistics might be sufficient to\nderive the Gestalt laws. We examine the law of closure, which asserts that\nhuman visual perception tends to \"close the gap\" by assembling elements that\ncan jointly be interpreted as a complete figure or object. We demonstrate that\na state-of-the-art convolutional neural network, trained to classify natural\nimages, exhibits closure on synthetic displays of edge fragments, as assessed\nby similarity of internal representations. This finding provides support for\nthe hypothesis that the human perceptual system is even more elegant than the\nGestaltists imagined: a single law---adaptation to the statistical structure of\nthe environment---might suffice as fundamental.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 04:44:19 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 17:00:13 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 02:36:49 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 23:02:58 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kim", "Been", ""], ["Reif", "Emily", ""], ["Wattenberg", "Martin", ""], ["Bengio", "Samy", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1903.01083", "submitter": "Shuai Li", "authors": "Shuai Li, Wei Chen, Zheng Wen, Kwong-Sak Leung", "title": "Stochastic Online Learning with Probabilistic Graph Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of stochastic online learning with general\nprobabilistic graph feedback, where each directed edge in the feedback graph\nhas probability $p_{ij}$. Two cases are covered. (a) The one-step case, where\nafter playing arm $i$ the learner observes a sample reward feedback of arm $j$\nwith independent probability $p_{ij}$. (b) The cascade case where after playing\narm $i$ the learner observes feedback of all arms $j$ in a probabilistic\ncascade starting from $i$ -- for each $(i,j)$ with probability $p_{ij}$, if arm\n$i$ is played or observed, then a reward sample of arm $j$ would be observed\nwith independent probability $p_{ij}$. Previous works mainly focus on\ndeterministic graphs which corresponds to one-step case with $p_{ij} \\in\n\\{0,1\\}$, an adversarial sequence of graphs with certain topology guarantees,\nor a specific type of random graphs. We analyze the asymptotic lower bounds and\ndesign algorithms in both cases. The regret upper bounds of the algorithms\nmatch the lower bounds with high probability.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 05:56:20 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 08:32:27 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Li", "Shuai", ""], ["Chen", "Wei", ""], ["Wen", "Zheng", ""], ["Leung", "Kwong-Sak", ""]]}, {"id": "1903.01167", "submitter": "Prayag Tiwari Mr.", "authors": "Prayag Tiwari, Massimo Melucci", "title": "Binary Classifier Inspired by Quantum Theory", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) helps us to recognize patterns from raw data. ML is\nused in numerous domains i.e. biomedical, agricultural, food technology, etc.\nDespite recent technological advancements, there is still room for substantial\nimprovement in prediction. Current ML models are based on classical theories of\nprobability and statistics, which can now be replaced by Quantum Theory (QT)\nwith the aim of improving the effectiveness of ML. In this paper, we propose\nthe Binary Classifier Inspired by Quantum Theory (BCIQT) model, which\noutperforms the state of the art classification in terms of recall for every\ncategory.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 10:53:01 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Tiwari", "Prayag", ""], ["Melucci", "Massimo", ""]]}, {"id": "1903.01182", "submitter": "Hao-Yun Chen", "authors": "Hao-Yun Chen, Pei-Hsin Wang, Chun-Hao Liu, Shih-Chieh Chang, Jia-Yu\n  Pan, Yu-Ting Chen, Wei Wei, Da-Cheng Juan", "title": "Complement Objective Training", "comments": "ICLR'19 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with a primary objective, such as softmax cross entropy for\nclassification and sequence generation, has been the norm for training deep\nneural networks for years. Although being a widely-adopted approach, using\ncross entropy as the primary objective exploits mostly the information from the\nground-truth class for maximizing data likelihood, and largely ignores\ninformation from the complement (incorrect) classes. We argue that, in addition\nto the primary objective, training also using a complement objective that\nleverages information from the complement classes can be effective in improving\nmodel performance. This motivates us to study a new training paradigm that\nmaximizes the likelihood of the groundtruth class while neutralizing the\nprobabilities of the complement classes. We conduct extensive experiments on\nmultiple tasks ranging from computer vision to natural language understanding.\nThe experimental results confirm that, compared to the conventional training\nwith just one primary objective, training also with the complement objective\nfurther improves the performance of the state-of-the-art models across all\ntasks. In addition to the accuracy improvement, we also show that models\ntrained with both primary and complement objectives are more robust to\nsingle-step adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 11:35:27 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 18:33:12 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Chen", "Hao-Yun", ""], ["Wang", "Pei-Hsin", ""], ["Liu", "Chun-Hao", ""], ["Chang", "Shih-Chieh", ""], ["Pan", "Jia-Yu", ""], ["Chen", "Yu-Ting", ""], ["Wei", "Wei", ""], ["Juan", "Da-Cheng", ""]]}, {"id": "1903.01240", "submitter": "Aran Sena Mr.", "authors": "Aran Sena, Brendan Michael, Matthew Howard", "title": "Improving Task-Parameterised Movement Learning Generalisation with\n  Frame-Weighted Trajectory Generation", "comments": "8 pages, 6 figures, submitted to 2019 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from Demonstration depends on a robot learner generalising its\nlearned model to unseen conditions, as it is not feasible for a person to\nprovide a demonstration set that accounts for all possible variations in\nnon-trivial tasks. While there are many learning methods that can handle\ninterpolation of observed data effectively, extrapolation from observed data\noffers a much greater challenge. To address this problem of generalisation,\nthis paper proposes a modified Task-Parameterised Gaussian Mixture Regression\nmethod that considers the relevance of task parameters during trajectory\ngeneration, as determined by variance in the data. The benefits of the proposed\nmethod are first explored using a simulated reaching task data set. Here it is\nshown that the proposed method offers far-reaching, low-error extrapolation\nabilities that are different in nature to existing learning methods. Data\ncollected from novice users for a real-world manipulation task is then\nconsidered, where it is shown that the proposed method is able to effectively\nreduce grasping performance errors by ${\\sim30\\%}$ and extrapolate to unseen\ngrasp targets under real-world conditions. These results indicate the proposed\nmethod serves to benefit novice users by placing less reliance on the user to\nprovide high quality demonstration data sets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 13:50:49 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Sena", "Aran", ""], ["Michael", "Brendan", ""], ["Howard", "Matthew", ""]]}, {"id": "1903.01246", "submitter": "Oliver Scheel", "authors": "Oliver Scheel, Naveen Shankar Nagaraja, Loren Schwarz, Nassir Navab,\n  Federico Tombari", "title": "Attention-based Lane Change Prediction", "comments": "To Appear in IEEE International Conference on Robotics and Automation\n  (ICRA) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lane change prediction of surrounding vehicles is a key building block of\npath planning. The focus has been on increasing the accuracy of prediction by\nposing it purely as a function estimation problem at the cost of model\nunderstandability. However, the efficacy of any lane change prediction model\ncan be improved when both corner and failure cases are humanly understandable.\nWe propose an attention-based recurrent model to tackle both understandability\nand prediction quality. We also propose metrics which reflect the discomfort\nfelt by the driver. We show encouraging results on a publicly available dataset\nand proprietary fleet data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 13:56:25 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 13:51:17 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Scheel", "Oliver", ""], ["Nagaraja", "Naveen Shankar", ""], ["Schwarz", "Loren", ""], ["Navab", "Nassir", ""], ["Tombari", "Federico", ""]]}, {"id": "1903.01254", "submitter": "Frederik Diehl", "authors": "Frederik Diehl, Thomas Brunner, Michael Truong Le, Alois Knoll", "title": "Graph Neural Networks for Modelling Traffic Participant Interaction", "comments": "To be published at IEEE Intelligent Vehicles Symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By interpreting a traffic scene as a graph of interacting vehicles, we gain a\nflexible abstract representation which allows us to apply Graph Neural Network\n(GNN) models for traffic prediction. These naturally take interaction between\ntraffic participants into account while being computationally efficient and\nproviding large model capacity. We evaluate two state-of-the art GNN\narchitectures and introduce several adaptations for our specific scenario. We\nshow that prediction error in scenarios with much interaction decreases by 30%\ncompared to a model that does not take interactions into account. This suggests\nthat interaction is important, and shows that we can model it using graphs.\nThis makes GNNs a worthwhile addition to traffic prediction systems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:15:07 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 08:53:01 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Diehl", "Frederik", ""], ["Brunner", "Thomas", ""], ["Le", "Michael Truong", ""], ["Knoll", "Alois", ""]]}, {"id": "1903.01263", "submitter": "Markus Borg", "authors": "Jens Henriksson, Christian Berger, Markus Borg, Lars Tornberg,\n  Cristofer Englund, Sankar Raman Sathyamoorthy, Stig Ursing", "title": "Towards Structured Evaluation of Deep Neural Network Supervisors", "comments": "Preprint of paper accepted for presentation at The First IEEE\n  International Conference on Artificial Intelligence Testing, April 4-9, 2019,\n  San Francisco East Bay, California, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) have improved the quality of several non-safety\nrelated products in the past years. However, before DNNs should be deployed to\nsafety-critical applications, their robustness needs to be systematically\nanalyzed. A common challenge for DNNs occurs when input is dissimilar to the\ntraining set, which might lead to high confidence predictions despite proper\nknowledge of the input. Several previous studies have proposed to complement\nDNNs with a supervisor that detects when inputs are outside the scope of the\nnetwork. Most of these supervisors, however, are developed and tested for a\nselected scenario using a specific performance metric. In this work, we\nemphasize the need to assess and compare the performance of supervisors in a\nstructured way. We present a framework constituted by four datasets organized\nin six test cases combined with seven evaluation metrics. The test cases\nprovide varying complexity and include data from publicly available sources as\nwell as a novel dataset consisting of images from simulated driving scenarios.\nThe latter we plan to make publicly available. Our framework can be used to\nsupport DNN supervisor evaluation, which in turn could be used to motive\ndevelopment, validation, and deployment of DNNs in safety-critical\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:23:00 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 16:17:37 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Henriksson", "Jens", ""], ["Berger", "Christian", ""], ["Borg", "Markus", ""], ["Tornberg", "Lars", ""], ["Englund", "Cristofer", ""], ["Sathyamoorthy", "Sankar Raman", ""], ["Ursing", "Stig", ""]]}, {"id": "1903.01267", "submitter": "Daniel Angelov", "authors": "Daniel Angelov, Yordan Hristov, Subramanian Ramamoorthy", "title": "Using Causal Analysis to Learn Specifications from Task Demonstrations", "comments": null, "journal-ref": "Proceedings of the 18th International Conference on Autonomous\n  Agents and MultiAgent Systems, Pages 1341-1349, Montreal QC, Canada, May 13 -\n  17, 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning models of user behaviour is an important problem that is broadly\napplicable across many application domains requiring human-robot interaction.\nIn this work we show that it is possible to learn a generative model for\ndistinct user behavioral types, extracted from human demonstrations, by\nenforcing clustering of preferred task solutions within the latent space. We\nuse this model to differentiate between user types and to find cases with\noverlapping solutions. Moreover, we can alter an initially guessed solution to\nsatisfy the preferences that constitute a particular user type by\nbackpropagating through the learned differentiable model. An advantage of\nstructuring generative models in this way is that it allows us to extract\ncausal relationships between symbols that might form part of the user's\nspecification of the task, as manifested in the demonstrations. We show that\nthe proposed method is capable of correctly distinguishing between three user\ntypes, who differ in degrees of cautiousness in their motion, while performing\nthe task of moving objects with a kinesthetically driven robot in a tabletop\nenvironment. Our method successfully identifies the correct type, within the\nspecified time, in 99% [97.8 - 99.8] of the cases, which outperforms an IRL\nbaseline. We also show that our proposed method correctly changes a default\ntrajectory to one satisfying a particular user specification even with unseen\nobjects. The resulting trajectory is shown to be directly implementable on a\nPR2 humanoid robot completing the same task.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:26:13 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Angelov", "Daniel", ""], ["Hristov", "Yordan", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1903.01287", "submitter": "Mahyar Fazlyab", "authors": "Mahyar Fazlyab, Manfred Morari, George J. Pappas", "title": "Safety Verification and Robustness Analysis of Neural Networks via\n  Quadratic Constraints and Semidefinite Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certifying the safety or robustness of neural networks against input\nuncertainties and adversarial attacks is an emerging challenge in the area of\nsafe machine learning and control. To provide such a guarantee, one must be\nable to bound the output of neural networks when their input changes within a\nbounded set. In this paper, we propose a semidefinite programming (SDP)\nframework to address this problem for feed-forward neural networks with general\nactivation functions and input uncertainty sets. Our main idea is to abstract\nvarious properties of activation functions (e.g., monotonicity, bounded slope,\nbounded values, and repetition across layers) with the formalism of quadratic\nconstraints. We then analyze the safety properties of the abstracted network\nvia the S-procedure and semidefinite programming. Our framework spans the\ntrade-off between conservatism and computational efficiency and applies to\nproblems beyond safety verification. We evaluate the performance of our\napproach via numerical problem instances of various sizes.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:51:45 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 13:50:32 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Fazlyab", "Mahyar", ""], ["Morari", "Manfred", ""], ["Pappas", "George J.", ""]]}, {"id": "1903.01298", "submitter": "Elvin Isufi", "authors": "Elvin Isufi, Fernando Gama, Alejandro Ribeiro", "title": "Generalizing Graph Convolutional Neural Networks with Edge-Variant\n  Recursions on Graphs", "comments": "submitted to EUSIPCO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews graph convolutional neural networks (GCNNs) through the\nlens of edge-variant graph filters. The edge-variant graph filter is a finite\norder, linear, and local recursion that allows each node, in each iteration, to\nweigh differently the information of its neighbors. By exploiting this\nrecursion, we formulate a general framework for GCNNs which considers\nstate-of-the-art solutions as particular cases. This framework results useful\nto i) understand the tradeoff between local detail and the number of parameters\nof each solution and ii) provide guidelines for developing a myriad of novel\napproaches that can be implemented locally in the vertex domain. One of such\napproaches is presented here showing superior performance w.r.t. current\nalternatives in graph signal classification problems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 15:05:36 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Isufi", "Elvin", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1903.01310", "submitter": "Arvind Prasadan", "authors": "Arvind Prasadan and Raj Rao Nadakuditi", "title": "Time Series Source Separation using Dynamic Mode Decomposition", "comments": "Accepted in SIADS (SIAM's Journal of Applied Dynamical Systems)", "journal-ref": null, "doi": "10.5281/zenodo.2656681", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Dynamic Mode Decomposition (DMD) extracted dynamic modes are the\nnon-orthogonal eigenvectors of the matrix that best approximates the one-step\ntemporal evolution of the multivariate samples. In the context of dynamical\nsystem analysis, the extracted dynamic modes are a generalization of global\nstability modes. We apply DMD to a data matrix whose rows are linearly\nindependent, additive mixtures of latent time series. We show that when the\nlatent time series are uncorrelated at a lag of one time-step then, in the\nlarge sample limit, the recovered dynamic modes will approximate, up to a\ncolumn-wise normalization, the columns of the mixing matrix. Thus, DMD is a\ntime series blind source separation algorithm in disguise, but is different\nfrom closely related second order algorithms such as the Second-Order Blind\nIdentification (SOBI) method and the Algorithm for Multiple Unknown Signals\nExtraction (AMUSE). All can unmix mixed stationary, ergodic Gaussian time\nseries in a way that kurtosis-based Independent Components Analysis (ICA)\nfundamentally cannot. We use our insights on single lag DMD to develop a\nhigher-lag extension, analyze the finite sample performance with and without\nrandomly missing data, and identify settings where the higher lag variant can\noutperform the conventional single lag variant. We validate our results with\nnumerical simulations, and highlight how DMD can be used in change point\ndetection.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 15:37:14 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 17:08:16 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 16:16:05 GMT"}, {"version": "v4", "created": "Thu, 5 Mar 2020 21:57:15 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Prasadan", "Arvind", ""], ["Nadakuditi", "Raj Rao", ""]]}, {"id": "1903.01334", "submitter": "Florian Dumpert", "authors": "Florian Dumpert", "title": "Quantitative Robustness of Localized Support Vector Machines", "comments": "arXiv admin note: text overlap with arXiv:1703.06528", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The huge amount of available data nowadays is a challenge for kernel-based\nmachine learning algorithms like SVMs with respect to runtime and storage\ncapacities. Local approaches might help to relieve these issues and to improve\nstatistical accuracy. It has already been shown that these local approaches are\nconsistent and robust in a basic sense. This article refines the analysis of\nrobustness properties towards the so-called influence function which expresses\nthe differentiability of the learning method: We show that there is a\ndifferentiable dependency of our locally learned predictor on the underlying\ndistribution. The assumptions of the proven theorems can be verified without\nknowing anything about this distribution. This makes the results interesting\nalso from an applied point of view.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 15:12:15 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Dumpert", "Florian", ""]]}, {"id": "1903.01341", "submitter": "Federico Galatolo", "authors": "Federico A. Galatolo, Mario G. C. A. Cimino, Gigliola Vaglini", "title": "Using stigmergy as a computational memory in the design of recurrent\n  neural networks", "comments": null, "journal-ref": null, "doi": "10.5220/0007581508300836", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel architecture of Recurrent Neural Network (RNN) is\ndesigned and experimented. The proposed RNN adopts a computational memory based\non the concept of stigmergy. The basic principle of a Stigmergic Memory (SM) is\nthat the activity of deposit/removal of a quantity in the SM stimulates the\nnext activities of deposit/removal. Accordingly, subsequent SM activities tend\nto reinforce/weaken each other, generating a coherent coordination between the\nSM activities and the input temporal stimulus. We show that, in a problem of\nsupervised classification, the SM encodes the temporal input in an emergent\nrepresentational model, by coordinating the deposit, removal and classification\nactivities. This study lays down a basic framework for the derivation of a\nSM-RNN. A formal ontology of SM is discussed, and the SM-RNN architecture is\ndetailed. To appreciate the computational power of an SM-RNN, comparative NNs\nhave been selected and trained to solve the MNIST handwritten digits\nrecognition benchmark in its two variants: spatial (sequences of bitmap rows)\nand temporal (sequences of pen strokes).\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 22:26:39 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Galatolo", "Federico A.", ""], ["Cimino", "Mario G. C. A.", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "1903.01344", "submitter": "Zhou Fan", "authors": "Zhou Fan, Rui Su, Weinan Zhang and Yong Yu", "title": "Hybrid Actor-Critic Reinforcement Learning in Parameterized Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a hybrid architecture of actor-critic algorithms for\nreinforcement learning in parameterized action space, which consists of\nmultiple parallel sub-actor networks to decompose the structured action space\ninto simpler action spaces along with a critic network to guide the training of\nall sub-actor networks. While this paper is mainly focused on parameterized\naction space, the proposed architecture, which we call hybrid actor-critic, can\nbe extended for more general action spaces which has a hierarchical structure.\nWe present an instance of the hybrid actor-critic architecture based on\nproximal policy optimization (PPO), which we refer to as hybrid proximal policy\noptimization (H-PPO). Our experiments test H-PPO on a collection of tasks with\nparameterized action space, where H-PPO demonstrates superior performance over\nprevious methods of parameterized action reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 16:33:15 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 08:32:06 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 13:02:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Fan", "Zhou", ""], ["Su", "Rui", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1903.01365", "submitter": "Giulio Bacchiani", "authors": "Giulio Bacchiani, Daniele Molinari, Marco Patander", "title": "Microscopic Traffic Simulation by Cooperative Multi-agent Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert human drivers perform actions relying on traffic laws and their\nprevious experience. While traffic laws are easily embedded into an artificial\nbrain, modeling human complex behaviors which come from past experience is a\nmore challenging task. One of these behaviors is the capability of\ncommunicating intentions and negotiating the right of way through driving\nactions, as when a driver is entering a crowded roundabout and observes other\ncars movements to guess the best time to merge in. In addition, each driver has\nits own unique driving style, which is conditioned by both its personal\ncharacteristics, such as age and quality of sight, and external factors, such\nas being late or in a bad mood. For these reasons, the interaction between\ndifferent drivers is not trivial to simulate in a realistic manner. In this\npaper, this problem is addressed by developing a microscopic simulator using a\nDeep Reinforcement Learning Algorithm based on a combination of visual frames,\nrepresenting the perception around the vehicle, and a vector of numerical\nparameters. In particular, the algorithm called Asynchronous Advantage\nActor-Critic has been extended to a multi-agent scenario in which every agent\nneeds to learn to interact with other similar agents. Moreover, the model\nincludes a novel architecture such that the driving style of each vehicle is\nadjustable by tuning some of its input parameters, permitting to simulate\ndrivers with different levels of aggressiveness and desired cruising speeds.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 17:05:38 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Bacchiani", "Giulio", ""], ["Molinari", "Daniele", ""], ["Patander", "Marco", ""]]}, {"id": "1903.01385", "submitter": "Minne Li", "authors": "Minne Li, Zheng Tian, Pranav Nashikkar, Ian Davies, Ying Wen, Jun Wang", "title": "Joint Perception and Control as Inference with an Object-based\n  Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing model-based reinforcement learning methods often study perception\nmodeling and decision making separately. We introduce joint Perception and\nControl as Inference (PCI), a general framework to combine perception and\ncontrol for partially observable environments through Bayesian inference. Based\non the fact that object-level inductive biases are critical in human perceptual\nlearning and reasoning, we propose Object-based Perception Control (OPC), an\ninstantiation of PCI which manages to facilitate control using automatic\ndiscovered object-based representations. We develop an unsupervised end-to-end\nsolution and analyze the convergence of the perception model update.\nExperiments in a high-dimensional pixel environment demonstrate the learning\neffectiveness of our object-based perception control approach. Specifically, we\nshow that OPC achieves good perceptual grouping quality and outperforms several\nstrong baselines in accumulated rewards.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 17:30:12 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 10:44:50 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 12:54:29 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Li", "Minne", ""], ["Tian", "Zheng", ""], ["Nashikkar", "Pranav", ""], ["Davies", "Ian", ""], ["Wen", "Ying", ""], ["Wang", "Jun", ""]]}, {"id": "1903.01390", "submitter": "Wenhao Yu", "authors": "Wenhao Yu, Visak CV Kumar, Greg Turk, C. Karen Liu", "title": "Sim-to-Real Transfer for Biped Locomotion", "comments": "International Conference on Intelligent Robots and Systems (IROS),\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for transfer of dynamic robot control policies such\nas biped locomotion from simulation to real hardware. Key to our approach is to\nperform system identification of the model parameters {\\mu} of the hardware\n(e.g. friction, center-of-mass) in two distinct stages, before policy learning\n(pre-sysID) and after policy learning (post-sysID). Pre-sysID begins by\ncollecting trajectories from the physical hardware based on a set of generic\nmotion sequences. Because the trajectories may not be related to the task of\ninterest, presysID does not attempt to accurately identify the true value of\n{\\mu}, but only to approximate the range of {\\mu} to guide the policy learning.\nNext, a Projected Universal Policy (PUP) is created by simultaneously training\na network that projects {\\mu} to a low-dimensional latent variable {\\eta} and a\nfamily of policies that are conditioned on {\\eta}. The second round of system\nidentification (post-sysID) is then carried out by deploying the PUP on the\nrobot hardware using task-relevant trajectories. We use Bayesian Optimization\nto determine the values for {\\eta} that optimizes the performance of PUP on the\nreal hardware. We have used this approach to create three successful biped\nlocomotion controllers (walk forward, walk backwards, walk sideways) on the\nDarwin OP2 robot.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 17:37:43 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 21:21:05 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Yu", "Wenhao", ""], ["Kumar", "Visak CV", ""], ["Turk", "Greg", ""], ["Liu", "C. Karen", ""]]}, {"id": "1903.01396", "submitter": "Tahar Kechadi M", "authors": "Yoan Chabot, Aur\\'elie Bertaux, Christophe Nicollea, Tahar Kechadi", "title": "A complete formalized knowledge representation model for advanced\n  digital forensics timeline analysis", "comments": null, "journal-ref": "Digital Investigation Volume 11, Supplement 2, August 2014, Pages\n  S95-S105", "doi": "10.1016/j.diin.2014.05.009", "report-no": null, "categories": "cs.CY cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having a clear view of events that occurred over time is a difficult\nobjective to achieve in digital investigations (DI). Event reconstruction,\nwhich allows investigators to understand the timeline of a crime, is one of the\nmost important step of a DI process. This complex task requires exploration of\na large amount of events due to the pervasiveness of new technologies nowadays.\nAny evidence produced at the end of the investigative process must also meet\nthe requirements of the courts, such as reproducibility, verifiability,\nvalidation, etc. For this purpose, we propose a new methodology, supported by\ntheoretical concepts, that can assist investigators through the whole process\nincluding the construction and the interpretation of the events describing the\ncase. The proposed approach is based on a model which integrates knowledge of\nexperts from the fields of digital forensics and software development to allow\na semantically rich representation of events related to the incident. The main\npurpose of this model is to allow the analysis of these events in an automatic\nand efficient way. This paper describes the approach and then focuses on the\nmain conceptual and formal aspects: a formal incident modelization and\noperators for timeline reconstruction and analysis.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 13:25:00 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Chabot", "Yoan", ""], ["Bertaux", "Aur\u00e9lie", ""], ["Nicollea", "Christophe", ""], ["Kechadi", "Tahar", ""]]}, {"id": "1903.01422", "submitter": "Osman Dai", "authors": "Osman Emre Dai, Daniel Cullina, Negar Kiyavash", "title": "Database Alignment with Gaussian Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aligning a pair of databases with jointly Gaussian\nfeatures. We consider two algorithms, complete database alignment via MAP\nestimation among all possible database alignments, and partial alignment via a\nthresholding approach of log likelihood ratios. We derive conditions on mutual\ninformation between feature pairs, identifying the regimes where the algorithms\nare guaranteed to perform reliably and those where they cannot be expected to\nsucceed.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 18:30:22 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 21:50:08 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Dai", "Osman Emre", ""], ["Cullina", "Daniel", ""], ["Kiyavash", "Negar", ""]]}, {"id": "1903.01432", "submitter": "Yi Hao", "authors": "Yi Hao, Alon Orlitsky", "title": "Data Amplification: Instance-Optimal Property Estimation", "comments": "In this new version, we strengthened the previous results by\n  eliminating unnecessary assumptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best-known and most commonly used distribution-property estimation\ntechnique uses a plug-in estimator, with empirical frequency replacing the\nunderlying distribution. We present novel linear-time-computable estimators\nthat significantly \"amplify\" the effective amount of data available. For a\nlarge variety of distribution properties including four of the most popular\nones and for every underlying distribution, they achieve the accuracy that the\nempirical-frequency plug-in estimators would attain using a logarithmic-factor\nmore samples.\n  Specifically, for Shannon entropy and a very broad class of properties\nincluding $\\ell_1$-distance, the new estimators use $n$ samples to achieve the\naccuracy attained by the empirical estimators with $n\\log n$ samples. For\nsupport-size and coverage, the new estimators use $n$ samples to achieve the\nperformance of empirical frequency with sample size $n$ times the logarithm of\nthe property value. Significantly strengthening the traditional min-max\nformulation, these results hold not only for the worst distributions, but for\neach and every underlying distribution. Furthermore, the logarithmic\namplification factors are optimal. Experiments on a wide variety of\ndistributions show that the new estimators outperform the previous\nstate-of-the-art estimators designed for each specific property.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 18:55:09 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 18:55:10 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Hao", "Yi", ""], ["Orlitsky", "Alon", ""]]}, {"id": "1903.01434", "submitter": "Manoj Kumar", "authors": "Manoj Kumar, Mohammad Babaeizadeh, Dumitru Erhan, Chelsea Finn, Sergey\n  Levine, Laurent Dinh, Durk Kingma", "title": "VideoFlow: A Conditional Flow-Based Model for Stochastic Video\n  Generation", "comments": "ICLR 2020 Camera-Ready. Previous title: VideoFlow: A Flow-Based\n  Generative Model for Video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models that can model and predict sequences of future events can,\nin principle, learn to capture complex real-world phenomena, such as physical\ninteractions. However, a central challenge in video prediction is that the\nfuture is highly uncertain: a sequence of past observations of events can imply\nmany possible futures. Although a number of recent works have studied\nprobabilistic models that can represent uncertain futures, such models are\neither extremely expensive computationally as in the case of pixel-level\nautoregressive models, or do not directly optimize the likelihood of the data.\nTo our knowledge, our work is the first to propose multi-frame video prediction\nwith normalizing flows, which allows for direct optimization of the data\nlikelihood, and produces high-quality stochastic predictions. We describe an\napproach for modeling the latent space dynamics, and demonstrate that\nflow-based generative models offer a viable and competitive approach to\ngenerative modelling of video.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 18:55:45 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 17:40:04 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 16:55:25 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kumar", "Manoj", ""], ["Babaeizadeh", "Mohammad", ""], ["Erhan", "Dumitru", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""], ["Dinh", "Laurent", ""], ["Kingma", "Durk", ""]]}, {"id": "1903.01435", "submitter": "Ping Li", "authors": "Jun-Kun Wang, Xiaoyun Li, Belhal Karimi, Ping Li", "title": "An Optimistic Acceleration of AMSGrad for Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new variant of AMSGrad, a popular adaptive gradient based\noptimization algorithm widely used for training deep neural networks. Our\nalgorithm adds prior knowledge about the sequence of consecutive mini-batch\ngradients and leverages its underlying structure making the gradients\nsequentially predictable. By exploiting the predictability and ideas from\noptimistic online learning, the proposed algorithm can accelerate the\nconvergence and increase sample efficiency. After establishing a tighter upper\nbound under some convexity conditions on the regret, we offer a complimentary\nview of our algorithm which generalizes the offline and stochastic version of\nnonconvex optimization. In the nonconvex case, we establish a non-asymptotic\nconvergence bound independently of the initialization. We illustrate the\npractical speedup on several deep learning models via numerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 18:56:40 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 15:00:02 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 17:57:21 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Jun-Kun", ""], ["Li", "Xiaoyun", ""], ["Karimi", "Belhal", ""], ["Li", "Ping", ""]]}, {"id": "1903.01454", "submitter": "Brijnesh Jain", "authors": "Brijnesh Jain", "title": "Making the Dynamic Time Warping Distance Warping-Invariant", "comments": "arXiv admin note: substantial text overlap with arXiv:1808.09964", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature postulates that the dynamic time warping (dtw) distance can\ncope with temporal variations but stores and processes time series in a form as\nif the dtw-distance cannot cope with such variations. To address this\ninconsistency, we first show that the dtw-distance is not warping-invariant.\nThe lack of warping-invariance contributes to the inconsistency mentioned above\nand to a strange behavior. To eliminate these peculiarities, we convert the\ndtw-distance to a warping-invariant semi-metric, called time-warp-invariant\n(twi) distance. Empirical results suggest that the error rates of the twi and\ndtw nearest-neighbor classifier are practically equivalent in a Bayesian sense.\nHowever, the twi-distance requires less storage and computation time than the\ndtw-distance for a broad range of problems. These results challenge the current\npractice of applying the dtw-distance in nearest-neighbor classification and\nsuggest the proposed twi-distance as a more efficient and consistent option.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 09:50:23 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 17:31:08 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Jain", "Brijnesh", ""]]}, {"id": "1903.01458", "submitter": "Katherine Storrs", "authors": "Katherine R. Storrs and Nikolaus Kriegeskorte", "title": "Deep Learning for Cognitive Neuroscience", "comments": "Chapter to appear in The Cognitive Neurosciences, 6th Edition", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models can now recognise images, understand text, translate\nlanguages, and play many human games at human or superhuman levels. These\nsystems are highly abstracted, but are inspired by biological brains and use\nonly biologically plausible computations. In the coming years, neural networks\nare likely to become less reliant on learning from massive labelled datasets,\nand more robust and generalisable in their task performance. From their\nsuccesses and failures, we can learn about the computational requirements of\nthe different tasks at which brains excel. Deep learning also provides the\ntools for testing cognitive theories. In order to test a theory, we need to\nrealise the proposed information-processing system at scale, so as to be able\nto assess its feasibility and emergent behaviours. Deep learning allows us to\nscale up from principles and circuit models to end-to-end trainable models\ncapable of performing complex tasks. There are many levels at which cognitive\nneuroscientists can use deep learning in their work, from inspiring theories to\nserving as full computational models. Ongoing advances in deep learning bring\nus closer to understanding how cognition and perception may be implemented in\nthe brain -- the grand challenge at the core of cognitive neuroscience.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:34:52 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Storrs", "Katherine R.", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1903.01461", "submitter": "Ruihao Zhu", "authors": "Wang Chi Cheung and David Simchi-Levi and Ruihao Zhu", "title": "Hedging the Drift: Learning to Optimize under Non-Stationarity", "comments": "Journal version of the AISTATS 2019 version (available at\n  arXiv:1810.03024). This version fixed an error in the proof of Theorem 2 with\n  Assumption 4 of arXiv:2103.05750", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce data-driven decision-making algorithms that achieve\nstate-of-the-art \\emph{dynamic regret} bounds for non-stationary bandit\nsettings. These settings capture applications such as advertisement allocation,\ndynamic pricing, and traffic network routing in changing environments. We show\nhow the difficulty posed by the (unknown \\emph{a priori} and possibly\nadversarial) non-stationarity can be overcome by an unconventional marriage\nbetween stochastic and adversarial bandit learning algorithms. Our main\ncontribution is a general algorithmic recipe for a wide variety of\nnon-stationary bandit problems. Specifically, we design and analyze the sliding\nwindow-upper confidence bound algorithm that achieves the optimal dynamic\nregret bound for each of the settings when we know the respective underlying\n\\emph{variation budget}, which quantifies the total amount of temporal\nvariation of the latent environments. Boosted by the novel bandit-over-bandit\nframework that adapts to the latent changes, we can further enjoy the (nearly)\noptimal dynamic regret bounds in a (surprisingly) parameter-free manner. In\naddition to the classical exploration-exploitation trade-off, our algorithms\nleverage the power of the \"forgetting principle\" in the learning processes,\nwhich is vital in changing environments. Our extensive numerical experiments on\nboth synthetic and real world online auto-loan datasets show that our proposed\nalgorithms achieve superior empirical performance compared to existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 15:51:41 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 14:57:29 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 14:37:49 GMT"}, {"version": "v4", "created": "Wed, 17 Mar 2021 21:30:08 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Cheung", "Wang Chi", ""], ["Simchi-Levi", "David", ""], ["Zhu", "Ruihao", ""]]}, {"id": "1903.01462", "submitter": "Philipp Holl", "authors": "P. Holl, L. Hauertmann, B. Majorovits, O. Schulz, M. Schuster, A.J.\n  Zsigmond", "title": "Deep learning based pulse shape discrimination for germanium detectors", "comments": "Published in Eur. Phys. J. C. 9 pages, 10 figures, 3 tables", "journal-ref": "Eur. Phys. J. C (2019) 79: 450", "doi": "10.1140/epjc/s10052-019-6869-2", "report-no": null, "categories": "physics.ins-det cs.LG nucl-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiments searching for rare processes like neutrinoless double beta decay\nheavily rely on the identification of background events to reduce their\nbackground level and increase their sensitivity. We present a novel machine\nlearning based method to recognize one of the most abundant classes of\nbackground events in these experiments. By combining a neural network for\nfeature extraction with a smaller classification network, our method can be\ntrained with only a small number of labeled events. To validate our method, we\nuse signals from a broad-energy germanium detector irradiated with a $^{228}$Th\ngamma source. We find that it matches the performance of state-of-the-art\nalgorithms commonly used for this detector type. However, it requires less\ntuning and calibration and shows potential to identify certain types of\nbackground events missed by other methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 16:40:30 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 10:03:53 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Holl", "P.", ""], ["Hauertmann", "L.", ""], ["Majorovits", "B.", ""], ["Schulz", "O.", ""], ["Schuster", "M.", ""], ["Zsigmond", "A. J.", ""]]}, {"id": "1903.01463", "submitter": "Dheeraj Nagaraj", "authors": "Prateek Jain, Dheeraj Nagaraj and Praneeth Netrapalli", "title": "SGD without Replacement: Sharper Rates for General Smooth Convex\n  Functions", "comments": "Version 2 corrects a minor error in the bounds for K", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic gradient descent {\\em without replacement} (\\sgdwor) for\nsmooth convex functions. \\sgdwor is widely observed to converge faster than\ntrue \\sgd where each sample is drawn independently {\\em with replacement}\n\\cite{bottou2009curiously} and hence, is more popular in practice. But it's\nconvergence properties are not well understood as sampling without replacement\nleads to coupling between iterates and gradients. By using method of\nexchangeable pairs to bound Wasserstein distance, we provide the first\nnon-asymptotic results for \\sgdwor when applied to {\\em general smooth,\nstrongly-convex} functions. In particular, we show that \\sgdwor converges at a\nrate of $O(1/K^2)$ while \\sgd is known to converge at $O(1/K)$ rate, where $K$\ndenotes the number of passes over data and is required to be {\\em large\nenough}. Existing results for \\sgdwor in this setting require additional {\\em\nHessian Lipschitz assumption} \\cite{gurbuzbalaban2015random,haochen2018random}.\n  For {\\em small} $K$, we show \\sgdwor can achieve same convergence rate as\n\\sgd for {\\em general smooth strongly-convex} functions. Existing results in\nthis setting require $K=1$ and hold only for generalized linear models\n\\cite{shamir2016without}. In addition, by careful analysis of the coupling, for\nboth large and small $K$, we obtain better dependence on problem dependent\nparameters like condition number.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 16:52:23 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 03:26:57 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Jain", "Prateek", ""], ["Nagaraj", "Dheeraj", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1903.01521", "submitter": "Ganesh Dasika", "authors": "Partha Maji, Andrew Mundy, Ganesh Dasika, Jesse Beu, Matthew Mattina,\n  Robert Mullins", "title": "Efficient Winograd or Cook-Toom Convolution Kernel Implementation on\n  Widely Used Mobile CPUs", "comments": "HPCA.EMC2 Feb 17, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Winograd or Cook-Toom class of algorithms help to reduce the overall\ncompute complexity of many modern deep convolutional neural networks (CNNs).\nAlthough there has been a lot of research done on model and algorithmic\noptimization of CNN, little attention has been paid to the efficient\nimplementation of these algorithms on embedded CPUs, which usually have very\nlimited memory and low power budget. This paper aims to fill this gap and\nfocuses on the efficient implementation of Winograd or Cook-Toom based\nconvolution on modern Arm Cortex-A CPUs, widely used in mobile devices today.\nSpecifically, we demonstrate a reduction in inference latency by using a set of\noptimization strategies that improve the utilization of computational\nresources, and by effectively leveraging the ARMv8-A NEON SIMD instruction set.\nWe evaluated our proposed region-wise multi-channel implementations on Arm\nCortex-A73 platform using several representative CNNs. The results show\nsignificant performance improvements in full network, up to 60%, over existing\nim2row/im2col based optimization techniques\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 20:15:15 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Maji", "Partha", ""], ["Mundy", "Andrew", ""], ["Dasika", "Ganesh", ""], ["Beu", "Jesse", ""], ["Mattina", "Matthew", ""], ["Mullins", "Robert", ""]]}, {"id": "1903.01531", "submitter": "Dibakar Gope", "authors": "Dibakar Gope, Ganesh Dasika, Matthew Mattina", "title": "Ternary Hybrid Neural-Tree Networks for Highly Constrained IoT\n  Applications", "comments": null, "journal-ref": "2nd Conference on Systems and Machine Learning (SysML), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based applications are increasingly prevalent in IoT\ndevices. The power and storage constraints of these devices make it\nparticularly challenging to run modern neural networks, limiting the number of\nnew applications that can be deployed on an IoT system. A number of compression\ntechniques have been proposed, each with its own trade-offs. We propose a\nhybrid network which combines the strengths of current neural- and tree-based\nlearning techniques in conjunction with ternary quantization, and show a\ndetailed analysis of the associated model design space. Using this hybrid model\nwe obtained a 11.1% reduction in the number of computations, a 52.2% reduction\nin the model size, and a 30.6% reduction in the overall memory footprint over a\nstate-of-the-art keyword-spotting neural network, with negligible loss in\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 20:41:06 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Gope", "Dibakar", ""], ["Dasika", "Ganesh", ""], ["Mattina", "Matthew", ""]]}, {"id": "1903.01534", "submitter": "Changhao Chen", "authors": "Changhao Chen, Stefano Rosa, Yishu Miao, Chris Xiaoxuan Lu, Wei Wu,\n  Andrew Markham, Niki Trigoni", "title": "Selective Sensor Fusion for Neural Visual-Inertial Odometry", "comments": "Accepted by CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning approaches for Visual-Inertial Odometry (VIO) have proven\nsuccessful, but they rarely focus on incorporating robust fusion strategies for\ndealing with imperfect input sensory data. We propose a novel end-to-end\nselective sensor fusion framework for monocular VIO, which fuses monocular\nimages and inertial measurements in order to estimate the trajectory whilst\nimproving robustness to real-life issues, such as missing and corrupted data or\nbad sensor synchronization. In particular, we propose two fusion modalities\nbased on different masking strategies: deterministic soft fusion and stochastic\nhard fusion, and we compare with previously proposed direct fusion baselines.\nDuring testing, the network is able to selectively process the features of the\navailable sensor modalities and produce a trajectory at scale. We present a\nthorough investigation on the performances on three public autonomous driving,\nMicro Aerial Vehicle (MAV) and hand-held VIO datasets. The results demonstrate\nthe effectiveness of the fusion strategies, which offer better performances\ncompared to direct fusion, particularly in presence of corrupted data. In\naddition, we study the interpretability of the fusion networks by visualising\nthe masking layers in different scenarios and with varying data corruption,\nrevealing interesting correlations between the fusion networks and imperfect\nsensory input data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 20:51:37 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Chen", "Changhao", ""], ["Rosa", "Stefano", ""], ["Miao", "Yishu", ""], ["Lu", "Chris Xiaoxuan", ""], ["Wu", "Wei", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1903.01537", "submitter": "Navyata Sanghvi", "authors": "Navyata Sanghvi, Ryo Yonetani, Kris Kitani", "title": "MGpi: A Computational Model of Multiagent Group Perception and\n  Interaction", "comments": "To be published in: Proceedings of the 19th International Conference\n  on Autonomous Agents and Multiagent Systems (AAMAS 2020), May 2020, Auckland,\n  New Zealand", "journal-ref": "Proceedings of the 19th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2020), pp. 1196-1205", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toward enabling next-generation robots capable of socially intelligent\ninteraction with humans, we present a $\\mathbf{computational\\; model}$ of\ninteractions in a social environment of multiple agents and multiple groups.\nThe Multiagent Group Perception and Interaction (MGpi) network is a deep neural\nnetwork that predicts the appropriate social action to execute in a group\nconversation (e.g., speak, listen, respond, leave), taking into account\nneighbors' observable features (e.g., location of people, gaze orientation,\ndistraction, etc.). A central component of MGpi is the Kinesic-Proxemic-Message\n(KPM) gate, that performs social signal gating to extract important information\nfrom a group conversation. In particular, KPM gate filters incoming social cues\nfrom nearby agents by observing their body gestures (kinesics) and spatial\nbehavior (proxemics). The MGpi network and its KPM gate are learned via\nimitation learning, using demonstrations from our designed $\\mathbf{social\\;\ninteraction\\; simulator}$. Further, we demonstrate the efficacy of the KPM gate\nas a social attention mechanism, achieving state-of-the-art performance on the\ntask of $\\mathbf{group\\; identification}$ without using explicit group\nannotations, layout assumptions, or manually chosen parameters.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 21:04:22 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 20:39:57 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Sanghvi", "Navyata", ""], ["Yonetani", "Ryo", ""], ["Kitani", "Kris", ""]]}, {"id": "1903.01548", "submitter": "Namwoo Kang", "authors": "Sangeun Oh, Yongsu Jung, Seongsin Kim, Ikjin Lee, Namwoo Kang", "title": "Deep Generative Design: Integration of Topology Optimization and\n  Generative Models", "comments": null, "journal-ref": "Journal of Mechanical Design, 141(11), 111405", "doi": "10.1115/1.4044229", "report-no": null, "categories": "cs.LG cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has recently been applied to various research areas of design\noptimization. This study presents the need and effectiveness of adopting deep\nlearning for generative design (or design exploration) research area. This work\nproposes an artificial intelligent (AI)-based design automation framework that\nis capable of generating numerous design options which are not only aesthetic\nbut also optimized for engineering performance. The proposed framework\nintegrates topology optimization and deep generative models (e.g., generative\nadversarial networks (GANs)) in an iterative manner to explore new design\noptions, thus generating a large number of designs starting from limited\nprevious design data. In addition, anomaly detection can evaluate the novelty\nof generated designs, thus helping designers choose among design options. The\n2D wheel design problem is applied as a case study for validation of the\nproposed framework. The framework manifests better aesthetics, diversity, and\nrobustness of generated designs than previous generative design methods.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 07:38:41 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 14:07:42 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Oh", "Sangeun", ""], ["Jung", "Yongsu", ""], ["Kim", "Seongsin", ""], ["Lee", "Ikjin", ""], ["Kang", "Namwoo", ""]]}, {"id": "1903.01549", "submitter": "Abdelkerim Amari", "authors": "Abdelkerim Amari, Xiang Lin, Octavia A. Dobre, Ramachandran\n  Venkatesan, Alex Alvarado", "title": "A Machine Learning-Based Detection Technique for Optical Fiber\n  Nonlinearity Mitigation", "comments": "Accepted for publication in IEEE Photonics Technology Letters", "journal-ref": null, "doi": "10.1109/LPT.2019.2902973", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance of a machine learning classification\ntechnique, called the Parzen window, to mitigate the fiber nonlinearity in the\ncontext of dispersion managed and dispersion unmanaged systems. The technique\nis applied for detection at the receiver side, and deals with the non-Gaussian\nnonlinear effects by designing improved decision boundaries. We also propose a\ntwo-stage mitigation technique using digital back propagation and Parzen window\nfor dispersion unmanaged systems. In this case, digital back propagation\ncompensates for the deterministic nonlinearity and the Parzen window deals with\nthe stochastic nonlinear signal-noise interactions, which are not taken into\naccount by digital back propagation. A performance improvement up to 0:4 dB in\nterms of Q factor is observed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 09:25:45 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 19:38:44 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Amari", "Abdelkerim", ""], ["Lin", "Xiang", ""], ["Dobre", "Octavia A.", ""], ["Venkatesan", "Ramachandran", ""], ["Alvarado", "Alex", ""]]}, {"id": "1903.01550", "submitter": "Matthias Brust R.", "authors": "Mostafa Rezazad, Matthias R. Brust, Mohammad Akbari, Pascal Bouvry,\n  Ngai-Man Cheung", "title": "Detecting Target-Area Link-Flooding DDoS Attacks using Traffic Analysis\n  and Supervised Learning", "comments": "arXiv admin note: text overlap with arXiv:1801.00235", "journal-ref": "Advances in Intelligent Systems and Computing, 2018", "doi": "10.1007/978-3-030-03405-4_12", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel class of extreme link-flooding DDoS (Distributed Denial of Service)\nattacks is designed to cut off entire geographical areas such as cities and\neven countries from the Internet by simultaneously targeting a selected set of\nnetwork links. The Crossfire attack is a target-area link-flooding attack,\nwhich is orchestrated in three complex phases. The attack uses a massively\ndistributed large-scale botnet to generate low-rate benign traffic aiming to\ncongest selected network links, so-called target links. The adoption of benign\ntraffic, while simultaneously targeting multiple network links, makes detecting\nthe Crossfire attack a serious challenge. In this paper, we present analytical\nand emulated results showing hitherto unidentified vulnerabilities in the\nexecution of the attack, such as a correlation between coordination of the\nbotnet traffic and the quality of the attack, and a correlation between the\nattack distribution and detectability of the attack. Additionally, we\nidentified a warm-up period due to the bot synchronization. For attack\ndetection, we report results of using two supervised machine learning\napproaches: Support Vector Machine (SVM) and Random Forest (RF) for\nclassification of network traffic to normal and abnormal traffic, i.e, attack\ntraffic. These machine learning models have been trained in various scenarios\nusing the link volume as the main feature set.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 14:29:01 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Rezazad", "Mostafa", ""], ["Brust", "Matthias R.", ""], ["Akbari", "Mohammad", ""], ["Bouvry", "Pascal", ""], ["Cheung", "Ngai-Man", ""]]}, {"id": "1903.01551", "submitter": "Dawei Gao", "authors": "Dawei Gao and Qinghua Guo", "title": "Extreme Learning Machine-Based Receiver for MIMO LED Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work concerns receiver design for light-emitting diode (LED) multiple\ninput multiple output (MIMO) communications where the LED nonlinearity can\nseverely degrade the performance of communications. In this paper, we propose\nan extreme learning machine (ELM) based receiver to jointly handle the LED\nnonlinearity and cross-LED interference, and a circulant input weight matrix is\nemployed, which significantly reduces the complexity of the receiver with the\nfast Fourier transform (FFT). It is demonstrated that the proposed receiver can\nefficiently handle the LED nonlinearity and cross-LED interference.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 14:22:05 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Gao", "Dawei", ""], ["Guo", "Qinghua", ""]]}, {"id": "1903.01552", "submitter": "Morteza Zabihi", "authors": "Morteza Zabihi, Ali Bahrami Rad, Serkan Kiranyaz, Simo S\\\"arkk\\\"a,\n  Moncef Gabbouj", "title": "1D Convolutional Neural Network Models for Sleep Arousal Detection", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep arousals transition the depth of sleep to a more superficial stage. The\noccurrence of such events is often considered as a protective mechanism to\nalert the body of harmful stimuli. Thus, accurate sleep arousal detection can\nlead to an enhanced understanding of the underlying causes and influencing the\nassessment of sleep quality. Previous studies and guidelines have suggested\nthat sleep arousals are linked mainly to abrupt frequency shifts in EEG\nsignals, but the proposed rules are shown to be insufficient for a\ncomprehensive characterization of arousals. This study investigates the\napplication of five recent convolutional neural networks (CNNs) for sleep\narousal detection and performs comparative evaluations to determine the best\nmodel for this task. The investigated state-of-the-art CNN models have\noriginally been designed for image or speech processing. A detailed set of\nevaluations is performed on the benchmark dataset provided by\nPhysioNet/Computing in Cardiology Challenge 2018, and the results show that the\nbest 1D CNN model has achieved an average of 0.31 and 0.84 for the area under\nthe precision-recall and area under the ROC curves, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 15:10:53 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Zabihi", "Morteza", ""], ["Rad", "Ali Bahrami", ""], ["Kiranyaz", "Serkan", ""], ["S\u00e4rkk\u00e4", "Simo", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1903.01563", "submitter": "Bryse Flowers", "authors": "Bryse Flowers, R. Michael Buehrer, and William C. Headley", "title": "Evaluating Adversarial Evasion Attacks in the Context of Wireless\n  Communications", "comments": "13 pages, 14 figures, Submitted to IEEE Transactions on Information\n  Forensics & Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in radio frequency machine learning (RFML) have\ndemonstrated the use of raw in-phase and quadrature (IQ) samples for multiple\nspectrum sensing tasks. Yet, deep learning techniques have been shown, in other\napplications, to be vulnerable to adversarial machine learning (ML) techniques,\nwhich seek to craft small perturbations that are added to the input to cause a\nmisclassification. The current work differentiates the threats that adversarial\nML poses to RFML systems based on where the attack is executed from: direct\naccess to classifier input, synchronously transmitted over the air (OTA), or\nasynchronously transmitted from a separate device. Additionally, the current\nwork develops a methodology for evaluating adversarial success in the context\nof wireless communications, where the primary metric of interest is bit error\nrate and not human perception, as is the case in image recognition. The\nmethodology is demonstrated using the well known Fast Gradient Sign Method to\nevaluate the vulnerabilities of raw IQ based Automatic Modulation\nClassification and concludes RFML is vulnerable to adversarial examples, even\nin OTA attacks. However, RFML domain specific receiver effects, which would be\nencountered in an OTA attack, can present significant impairments to\nadversarial evasion.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 16:21:34 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Flowers", "Bryse", ""], ["Buehrer", "R. Michael", ""], ["Headley", "William C.", ""]]}, {"id": "1903.01567", "submitter": "Jayesh Gupta", "authors": "Bohan Wu, Jayesh K. Gupta, Mykel J. Kochenderfer", "title": "Model Primitive Hierarchical Lifelong Reinforcement Learning", "comments": "9 pages, 10 figures. Accepted as a full paper at AAMAS 2019", "journal-ref": "International Conference on Autonomous Agents and Multiagent\n  Systems (AAMAS 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning interpretable and transferable subpolicies and performing task\ndecomposition from a single, complex task is difficult. Some traditional\nhierarchical reinforcement learning techniques enforce this decomposition in a\ntop-down manner, while meta-learning techniques require a task distribution at\nhand to learn such decompositions. This paper presents a framework for using\ndiverse suboptimal world models to decompose complex task solutions into\nsimpler modular subpolicies. This framework performs automatic decomposition of\na single source task in a bottom up manner, concurrently learning the required\nmodular subpolicies as well as a controller to coordinate them. We perform a\nseries of experiments on high dimensional continuous action control tasks to\ndemonstrate the effectiveness of this approach at both complex single task\nlearning and lifelong learning. Finally, we perform ablation studies to\nunderstand the importance and robustness of different elements in the framework\nand limitations to this approach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 22:14:23 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Wu", "Bohan", ""], ["Gupta", "Jayesh K.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1903.01576", "submitter": "Hossein Nourkhiz Mahjoub", "authors": "Hossein Nourkhiz Mahjoub, Behrad Toghi, S M Osman Gani, and Yaser P.\n  Fallah", "title": "V2X System Architecture Utilizing Hybrid Gaussian Process-based Model\n  Structures", "comments": "Accepted for Oral Presentation at the 13th IEEE Systems Conference\n  (SysCon 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable communication is of utmost importance for reliable dissemination of\ntime-sensitive information in cooperative vehicular ad-hoc networks (VANETs),\nwhich is, in turn, an essential prerequisite for the proper operation of the\ncritical cooperative safety applications. The model-based communication (MBC)\nis a recently-explored scalability solution proposed in the literature, which\nhas shown a promising potential to reduce the channel congestion to a great\nextent. In this work, based on the MBC notion, a technology-agnostic hybrid\nmodel selection policy for Vehicle-to-Everything (V2X) communication is\nproposed which benefits from the characteristics of the non-parametric Bayesian\ninference techniques, specifically Gaussian Processes. The results show the\neffectiveness of the proposed communication architecture on both reducing the\nrequired message exchange rate and increasing the remote agent tracking\nprecision.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 22:53:08 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 02:08:14 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Mahjoub", "Hossein Nourkhiz", ""], ["Toghi", "Behrad", ""], ["Gani", "S M Osman", ""], ["Fallah", "Yaser P.", ""]]}, {"id": "1903.01577", "submitter": "Victor Dorobantu", "authors": "Andrew J. Taylor, Victor D. Dorobantu, Hoang M. Le, Yisong Yue, Aaron\n  D. Ames", "title": "Episodic Learning with Control Lyapunov Functions for Uncertain Robotic\n  Systems", "comments": null, "journal-ref": null, "doi": "10.1109/IROS40897.2019.8967820", "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern nonlinear control methods aim to endow systems with guaranteed\nproperties, such as stability or safety, and have been successfully applied to\nthe domain of robotics. However, model uncertainty remains a persistent\nchallenge, weakening theoretical guarantees and causing implementation failures\non physical systems. This paper develops a machine learning framework centered\naround Control Lyapunov Functions (CLFs) to adapt to parametric uncertainty and\nunmodeled dynamics in general robotic systems. Our proposed method proceeds by\niteratively updating estimates of Lyapunov function derivatives and improving\ncontrollers, ultimately yielding a stabilizing quadratic program model-based\ncontroller. We validate our approach on a planar Segway simulation,\ndemonstrating substantial performance improvements by iteratively refining on a\nbase model-free controller.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 22:53:47 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Taylor", "Andrew J.", ""], ["Dorobantu", "Victor D.", ""], ["Le", "Hoang M.", ""], ["Yue", "Yisong", ""], ["Ames", "Aaron D.", ""]]}, {"id": "1903.01599", "submitter": "Nan Rosemary Ke", "authors": "Nan Rosemary Ke, Amanpreet Singh, Ahmed Touati, Anirudh Goyal, Yoshua\n  Bengio, Devi Parikh, Dhruv Batra", "title": "Learning Dynamics Model in Reinforcement Learning by Incorporating the\n  Long Term Future", "comments": "To appear at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model-based reinforcement learning, the agent interleaves between model\nlearning and planning. These two components are inextricably intertwined. If\nthe model is not able to provide sensible long-term prediction, the executed\nplanner would exploit model flaws, which can yield catastrophic failures. This\npaper focuses on building a model that reasons about the long-term future and\ndemonstrates how to use this for efficient planning and exploration. To this\nend, we build a latent-variable autoregressive model by leveraging recent ideas\nin variational inference. We argue that forcing latent variables to carry\nfuture information through an auxiliary task substantially improves long-term\npredictions. Moreover, by planning in the latent space, the planner's solution\nis ensured to be within regions where the model is valid. An exploration\nstrategy can be devised by searching for unlikely trajectories under the model.\nOur method achieves higher reward faster compared to baselines on a variety of\ntasks and environments in both the imitation learning and model-based\nreinforcement learning settings.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 00:15:21 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 17:10:08 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Ke", "Nan Rosemary", ""], ["Singh", "Amanpreet", ""], ["Touati", "Ahmed", ""], ["Goyal", "Anirudh", ""], ["Bengio", "Yoshua", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1903.01608", "submitter": "Maxim Raginsky", "authors": "Belinda Tzen and Maxim Raginsky", "title": "Theoretical guarantees for sampling and inference in generative models\n  with latent diffusions", "comments": "To appear in COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study a class of probabilistic generative models, where the\nlatent object is a finite-dimensional diffusion process on a finite time\ninterval and the observed variable is drawn conditionally on the terminal point\nof the diffusion. We make the following contributions:\n  We provide a unified viewpoint on both sampling and variational inference in\nsuch generative models through the lens of stochastic control.\n  We quantify the expressiveness of diffusion-based generative models.\nSpecifically, we show that one can efficiently sample from a wide class of\nterminal target distributions by choosing the drift of the latent diffusion\nfrom the class of multilayer feedforward neural nets, with the accuracy of\nsampling measured by the Kullback-Leibler divergence to the target\ndistribution.\n  Finally, we present and analyze a scheme for unbiased simulation of\ngenerative models with latent diffusions and provide bounds on the variance of\nthe resulting estimators. This scheme can be implemented as a deep generative\nmodel with a random number of layers.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 00:38:49 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 15:23:24 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Tzen", "Belinda", ""], ["Raginsky", "Maxim", ""]]}, {"id": "1903.01610", "submitter": "Huijun Wu", "authors": "Huijun Wu, Chen Wang, Yuriy Tyshetskiy, Andrew Docherty, Kai Lu,\n  Liming Zhu", "title": "Adversarial Examples on Graph Data: Deep Insights into Attack and\n  Defense", "comments": "to appear in IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph deep learning models, such as graph convolutional networks (GCN)\nachieve remarkable performance for tasks on graph data. Similar to other types\nof deep models, graph deep learning models often suffer from adversarial\nattacks. However, compared with non-graph data, the discrete features, graph\nconnections and different definitions of imperceptible perturbations bring\nunique challenges and opportunities for the adversarial attacks and defenses\nfor graph data. In this paper, we propose both attack and defense techniques.\nFor attack, we show that the discreteness problem could easily be resolved by\nintroducing integrated gradients which could accurately reflect the effect of\nperturbing certain features or edges while still benefiting from the parallel\ncomputations. For defense, we observe that the adversarially manipulated graph\nfor the targeted attack differs from normal graphs statistically. Based on this\nobservation, we propose a defense approach which inspects the graph and\nrecovers the potential adversarial perturbations. Our experiments on a number\nof datasets show the effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 00:43:48 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 05:20:00 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 08:45:44 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Wu", "Huijun", ""], ["Wang", "Chen", ""], ["Tyshetskiy", "Yuriy", ""], ["Docherty", "Andrew", ""], ["Lu", "Kai", ""], ["Zhu", "Liming", ""]]}, {"id": "1903.01611", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M. Roy, Michael\n  Carbin", "title": "Stabilizing the Lottery Ticket Hypothesis", "comments": "This article has been subsumed by \"Linear Mode Connectivity and the\n  Lottery Ticket Hypothesis\" (arXiv:1912.05671, ICML 2020). Please read/cite\n  that article instead", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning is a well-established technique for removing unnecessary structure\nfrom neural networks after training to improve the performance of inference.\nSeveral recent results have explored the possibility of pruning at\ninitialization time to provide similar benefits during training. In particular,\nthe \"lottery ticket hypothesis\" conjectures that typical neural networks\ncontain small subnetworks that can train to similar accuracy in a commensurate\nnumber of steps. The evidence for this claim is that a procedure based on\niterative magnitude pruning (IMP) reliably finds such subnetworks retroactively\non small vision tasks. However, IMP fails on deeper networks, and proposed\nmethods to prune before training or train pruned networks encounter similar\nscaling limitations. In this paper, we argue that these efforts have struggled\non deeper networks because they have focused on pruning precisely at\ninitialization. We modify IMP to search for subnetworks that could have been\nobtained by pruning early in training (0.1% to 7% through) rather than at\niteration 0. With this change, it finds small subnetworks of deeper networks\n(e.g., 80% sparsity on Resnet-50) that can complete the training process to\nmatch the accuracy of the original network on more challenging tasks (e.g.,\nImageNet). In situations where IMP fails at iteration 0, the accuracy benefits\nof delaying pruning accrue rapidly over the earliest iterations of training. To\nexplain these behaviors, we study subnetwork \"stability,\" finding that - as\naccuracy improves in this fashion - IMP subnetworks train to parameters closer\nto those of the full network and do so with improved consistency in the face of\ngradient noise. These results offer new insights into the opportunity to prune\nlarge-scale networks early in training and the behaviors underlying the lottery\nticket hypothesis\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 00:52:12 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 23:40:16 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 16:50:33 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Frankle", "Jonathan", ""], ["Dziugaite", "Gintare Karolina", ""], ["Roy", "Daniel M.", ""], ["Carbin", "Michael", ""]]}, {"id": "1903.01612", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey, Laurens van der Maaten, Zeki Yalniz, Yixuan Li, Dhruv\n  Mahajan", "title": "Defense Against Adversarial Images using Web-Scale Nearest-Neighbor\n  Search", "comments": "CVPR 2019 Oral presentation; camera-ready with supplement (14 pages).\n  v1 updated from error in Table 2, row 10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of recent work has shown that convolutional networks are not\nrobust to adversarial images: images that are created by perturbing a sample\nfrom the data distribution as to maximize the loss on the perturbed example. In\nthis work, we hypothesize that adversarial perturbations move the image away\nfrom the image manifold in the sense that there exists no physical process that\ncould have produced the adversarial image. This hypothesis suggests that a\nsuccessful defense mechanism against adversarial images should aim to project\nthe images back onto the image manifold. We study such defense mechanisms,\nwhich approximate the projection onto the unknown image manifold by a\nnearest-neighbor search against a web-scale image database containing tens of\nbillions of images. Empirical evaluations of this defense strategy on ImageNet\nsuggest that it is very effective in attack settings in which the adversary\ndoes not have access to the image database. We also propose two novel attack\nmethods to break nearest-neighbor defenses, and demonstrate conditions under\nwhich nearest-neighbor defense fails. We perform a series of ablation\nexperiments, which suggest that there is a trade-off between robustness and\naccuracy in our defenses, that a large image database (with hundreds of\nmillions of images) is crucial to get good performance, and that careful\nconstruction the image database is important to be robust against attacks\ntailored to circumvent our defenses.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 00:53:56 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 20:34:14 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["van der Maaten", "Laurens", ""], ["Yalniz", "Zeki", ""], ["Li", "Yixuan", ""], ["Mahajan", "Dhruv", ""]]}, {"id": "1903.01620", "submitter": "Pasha Khosravi", "authors": "Pasha Khosravi, Yitao Liang, YooJung Choi, Guy Van den Broeck", "title": "What to Expect of Classifiers? Reasoning about Logistic Regression with\n  Missing Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While discriminative classifiers often yield strong predictive performance,\nmissing feature values at prediction time can still be a challenge. Classifiers\nmay not behave as expected under certain ways of substituting the missing\nvalues, since they inherently make assumptions about the data distribution they\nwere trained on. In this paper, we propose a novel framework that classifies\nexamples with missing features by computing the expected prediction with\nrespect to a feature distribution. Moreover, we use geometric programming to\nlearn a naive Bayes distribution that embeds a given logistic regression\nclassifier and can efficiently take its expected predictions. Empirical\nevaluations show that our model achieves the same performance as the logistic\nregression with all features observed, and outperforms standard imputation\ntechniques when features go missing during prediction time. Furthermore, we\ndemonstrate that our method can be used to generate \"sufficient explanations\"\nof logistic regression classifications, by removing features that do not affect\nthe classification.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 01:16:10 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 19:36:26 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Khosravi", "Pasha", ""], ["Liang", "Yitao", ""], ["Choi", "YooJung", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1903.01635", "submitter": "Brian Hoskins", "authors": "Brian D. Hoskins, Matthew W. Daniels, Siyuan Huang, Advait Madhavan,\n  Gina C. Adam, Nikolai Zhitenev, Jabez J. McClelland, Mark D. Stiles", "title": "Streaming Batch Eigenupdates for Hardware Neuromorphic Networks", "comments": "13 pages, 5 figures", "journal-ref": "Frontiers in Neuroscience 13 (2019): 793", "doi": "10.3389/fnins.2019.00793", "report-no": null, "categories": "cs.LG cs.ET cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Neuromorphic networks based on nanodevices, such as metal oxide memristors,\nphase change memories, and flash memory cells, have generated considerable\ninterest for their increased energy efficiency and density in comparison to\ngraphics processing units (GPUs) and central processing units (CPUs). Though\nimmense acceleration of the training process can be achieved by leveraging the\nfact that the time complexity of training does not scale with the network size,\nit is limited by the space complexity of stochastic gradient descent, which\ngrows quadratically. The main objective of this work is to reduce this space\ncomplexity by using low-rank approximations of stochastic gradient descent.\nThis low spatial complexity combined with streaming methods allows for\nsignificant reductions in memory and compute overhead, opening the doors for\nimprovements in area, time and energy efficiency of training. We refer to this\nalgorithm and architecture to implement it as the streaming batch eigenupdate\n(SBE) approach.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 02:35:52 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Hoskins", "Brian D.", ""], ["Daniels", "Matthew W.", ""], ["Huang", "Siyuan", ""], ["Madhavan", "Advait", ""], ["Adam", "Gina C.", ""], ["Zhitenev", "Nikolai", ""], ["McClelland", "Jabez J.", ""], ["Stiles", "Mark D.", ""]]}, {"id": "1903.01666", "submitter": "Xuezhou Zhang", "authors": "Xuezhou Zhang, Xiaojin Zhu, Laurent Lessard", "title": "Online Data Poisoning Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study data poisoning attacks in the online setting where training items\narrive sequentially, and the attacker may perturb the current item to\nmanipulate online learning. Importantly, the attacker has no knowledge of\nfuture training items nor the data generating distribution. We formulate online\ndata poisoning attack as a stochastic optimal control problem, and solve it\nwith model predictive control and deep reinforcement learning. We also upper\nbound the suboptimality suffered by the attacker for not knowing the data\ngenerating distribution. Experiments validate our control approach in\ngenerating near-optimal attacks on both supervised and unsupervised learning\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 04:50:56 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 23:02:31 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Zhang", "Xuezhou", ""], ["Zhu", "Xiaojin", ""], ["Lessard", "Laurent", ""]]}, {"id": "1903.01669", "submitter": "Vijaya Sai Krishna Gottipati", "authors": "Sai Krishna, Keehong Seo, Dhaivat Bhatt, Vincent Mai, Krishna Murthy,\n  Liam Paull", "title": "Deep Active Localization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Active localization is the problem of generating robot actions that allow it\nto maximally disambiguate its pose within a reference map. Traditional\napproaches to this use an information-theoretic criterion for action selection\nand hand-crafted perceptual models. In this work we propose an end-to-end\ndifferentiable method for learning to take informative actions that is\ntrainable entirely in simulation and then transferable to real robot hardware\nwith zero refinement. The system is composed of two modules: a convolutional\nneural network for perception, and a deep reinforcement learned planning\nmodule. We introduce a multi-scale approach to the learned perceptual model\nsince the accuracy needed to perform action selection with reinforcement\nlearning is much less than the accuracy needed for robot control. We\ndemonstrate that the resulting system outperforms using the traditional\napproach for either perception or planning. We also demonstrate our approaches\nrobustness to different map configurations and other nuisance parameters\nthrough the use of domain randomization in training. The code is also\ncompatible with the OpenAI gym framework, as well as the Gazebo simulator.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 05:00:08 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Krishna", "Sai", ""], ["Seo", "Keehong", ""], ["Bhatt", "Dhaivat", ""], ["Mai", "Vincent", ""], ["Murthy", "Krishna", ""], ["Paull", "Liam", ""]]}, {"id": "1903.01672", "submitter": "Biwei Huang", "authors": "Biwei Huang, Kun Zhang, Jiji Zhang, Joseph Ramsey, Ruben\n  Sanchez-Romero, Clark Glymour, Bernhard Sch\\\"olkopf", "title": "Causal Discovery from Heterogeneous/Nonstationary Data with Independent\n  Changes", "comments": null, "journal-ref": "Journal of Machine Learning Research 21 (2020) 1-53", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonplace to encounter heterogeneous or nonstationary data, of which\nthe underlying generating process changes across domains or over time. Such a\ndistribution shift feature presents both challenges and opportunities for\ncausal discovery. In this paper, we develop a framework for causal discovery\nfrom such data, called Constraint-based causal Discovery from\nheterogeneous/NOnstationary Data (CD-NOD), to find causal skeleton and\ndirections and estimate the properties of mechanism changes. First, we propose\nan enhanced constraint-based procedure to detect variables whose local\nmechanisms change and recover the skeleton of the causal structure over\nobserved variables. Second, we present a method to determine causal\norientations by making use of independent changes in the data distribution\nimplied by the underlying causal model, benefiting from information carried by\nchanging distributions. After learning the causal structure, next, we\ninvestigate how to efficiently estimate the \"driving force\" of the\nnonstationarity of a causal mechanism. That is, we aim to extract from data a\nlow-dimensional representation of changes. The proposed methods are\nnonparametric, with no hard restrictions on data distributions and causal\nmechanisms, and do not rely on window segmentation. Furthermore, we find that\ndata heterogeneity benefits causal structure identification even with\nparticular types of confounders. Finally, we show the connection between\nheterogeneity/nonstationarity and soft intervention in causal discovery.\nExperimental results on various synthetic and real-world data sets (task-fMRI\nand stock market data) are presented to demonstrate the efficacy of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 05:07:13 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 14:22:19 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 02:24:19 GMT"}, {"version": "v4", "created": "Thu, 18 Jun 2020 14:23:55 GMT"}, {"version": "v5", "created": "Thu, 25 Jun 2020 14:39:01 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Huang", "Biwei", ""], ["Zhang", "Kun", ""], ["Zhang", "Jiji", ""], ["Ramsey", "Joseph", ""], ["Sanchez-Romero", "Ruben", ""], ["Glymour", "Clark", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1903.01678", "submitter": "Ruimin Ke", "authors": "Ruimin Ke, Wan Li, Zhiyong Cui, Yinhai Wang", "title": "Two-Stream Multi-Channel Convolutional Neural Network (TM-CNN) for\n  Multi-Lane Traffic Speed Prediction Considering Traffic Volume Impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic speed prediction is a critically important component of intelligent\ntransportation systems (ITS). Recently, with the rapid development of deep\nlearning and transportation data science, a growing body of new traffic speed\nprediction models have been designed, which achieved high accuracy and\nlarge-scale prediction. However, existing studies have two major limitations.\nFirst, they predict aggregated traffic speed rather than lane-level traffic\nspeed; second, most studies ignore the impact of other traffic flow parameters\nin speed prediction. To address these issues, we propose a two-stream\nmulti-channel convolutional neural network (TM-CNN) model for multi-lane\ntraffic speed prediction considering traffic volume impact. In this model, we\nfirst introduce a new data conversion method that converts raw traffic speed\ndata and volume data into spatial-temporal multi-channel matrices. Then we\ncarefully design a two-stream deep neural network to effectively learn the\nfeatures and correlations between individual lanes, in the spatial-temporal\ndimensions, and between speed and volume. Accordingly, a new loss function that\nconsiders the volume impact in speed prediction is developed. A case study\nusing one-year data validates the TM-CNN model and demonstrates its\nsuperiority. This paper contributes to two research areas: (1) traffic speed\nprediction, and (2) multi-lane traffic flow study.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 05:31:12 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Ke", "Ruimin", ""], ["Li", "Wan", ""], ["Cui", "Zhiyong", ""], ["Wang", "Yinhai", ""]]}, {"id": "1903.01689", "submitter": "Yifan Wu", "authors": "Yifan Wu, Ezra Winston, Divyansh Kaushik, Zachary Lipton", "title": "Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation addresses the common problem when the target distribution\ngenerating our test data drifts from the source (training) distribution. While\nabsent assumptions, domain adaptation is impossible, strict conditions, e.g.\ncovariate or label shift, enable principled algorithms. Recently-proposed\ndomain-adversarial approaches consist of aligning source and target encodings,\noften motivating this approach as minimizing two (of three) terms in a\ntheoretical bound on target error. Unfortunately, this minimization can cause\narbitrary increases in the third term, e.g. they can break down under shifting\nlabel distributions. We propose asymmetrically-relaxed distribution alignment,\na new approach that overcomes some limitations of standard domain-adversarial\nalgorithms. Moreover, we characterize precise assumptions under which our\nalgorithm is theoretically principled and demonstrate empirical benefits on\nboth synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 06:11:07 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 21:25:26 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Wu", "Yifan", ""], ["Winston", "Ezra", ""], ["Kaushik", "Divyansh", ""], ["Lipton", "Zachary", ""]]}, {"id": "1903.01707", "submitter": "Yang Li", "authors": "Yang Li, Kevin Korb, Lloyd Allison", "title": "The Complexity of Morality: Checking Markov Blanket Consistency with\n  DAGs via Morality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A family of Markov blankets in a faithful Bayesian network satisfies the\nsymmetry and consistency properties. In this paper, we draw a bijection between\nfamilies of consistent Markov blankets and moral graphs. We define the new\nconcepts of weak recursive simpliciality and perfect elimination kits. We prove\nthat they are equivalent to graph morality. In addition, we prove that morality\ncan be decided in polynomial time for graphs with maximum degree less than $5$,\nbut the problem is NP-complete for graphs with higher maximum degrees.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 07:39:46 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Li", "Yang", ""], ["Korb", "Kevin", ""], ["Allison", "Lloyd", ""]]}, {"id": "1903.01715", "submitter": "Gaelle Loosli", "authors": "Isma\\\"ila Seck (LIMOS, LITIS), Ga\\\"elle Loosli (LIMOS), Stephane Canu\n  (LITIS)", "title": "L 1-norm double backpropagation adversarial defense", "comments": "ESANN - European Symposium on Artificial Neural Networks,\n  Computational Intelligence and Machine Learning, Apr 2019, Bruges, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are a challenging open problem for deep neural networks.\nWe propose in this paper to add a penalization term that forces the decision\nfunction to be at in some regions of the input space, such that it becomes, at\nleast locally, less sensitive to attacks. Our proposition is theoretically\nmotivated and shows on a first set of carefully conducted experiments that it\nbehaves as expected when used alone, and seems promising when coupled with\nadversarial training.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 08:04:34 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Seck", "Isma\u00efla", "", "LIMOS, LITIS"], ["Loosli", "Ga\u00eblle", "", "LIMOS"], ["Canu", "Stephane", "", "LITIS"]]}, {"id": "1903.01720", "submitter": "James Bailey", "authors": "James P. Bailey, Georgios Piliouras", "title": "Multi-Agent Learning in Network Zero-Sum Games is a Hamiltonian System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-sum games are natural, if informal, analogues of closed physical systems\nwhere no energy/utility can enter or exit. This analogy can be extended even\nfurther if we consider zero-sum network (polymatrix) games where multiple\nagents interact in a closed economy. Typically, (network) zero-sum games are\nstudied from the perspective of Nash equilibria. Nevertheless, this comes in\ncontrast with the way we typically think about closed physical systems, e.g.,\nEarth-moon systems which move perpetually along recurrent trajectories of\nconstant energy.\n  We establish a formal and robust connection between multi-agent systems and\nHamiltonian dynamics -- the same dynamics that describe conservative systems in\nphysics. Specifically, we show that no matter the size, or network structure of\nsuch closed economies, even if agents use different online learning dynamics\nfrom the standard class of Follow-the-Regularized-Leader, they yield\nHamiltonian dynamics. This approach generalizes the known connection to\nHamiltonians for the special case of replicator dynamics in two agent zero-sum\ngames developed by Hofbauer. Moreover, our results extend beyond zero-sum\nsettings and provide a type of a Rosetta stone (see e.g. Table 1) that helps to\ntranslate results and techniques between online optimization, convex analysis,\ngames theory, and physics.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 08:11:13 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Bailey", "James P.", ""], ["Piliouras", "Georgios", ""]]}, {"id": "1903.01730", "submitter": "R\\'emi Domingues", "authors": "R\\'emi Domingues", "title": "Probabilistic Modeling for Novelty Detection with Applications to Fraud\n  Identification", "comments": "PhD thesis; 167 pages, 40 figures, 16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novelty detection is the unsupervised problem of identifying anomalies in\ntest data which significantly differ from the training set. Novelty detection\nis one of the classic challenges in Machine Learning and a core component of\nseveral research areas such as fraud detection, intrusion detection, medical\ndiagnosis, data cleaning, and fault prevention. While numerous algorithms were\ndesigned to address this problem, most methods are only suitable to model\ncontinuous numerical data. Tackling datasets composed of mixed-type features,\nsuch as numerical and categorical data, or temporal datasets describing\ndiscrete event sequences is a challenging task. In addition to the supported\ndata types, the key criteria for efficient novelty detection methods are the\nability to accurately dissociate novelties from nominal samples, the\ninterpretability, the scalability and the robustness to anomalies located in\nthe training data.\n  In this thesis, we investigate novel ways to tackle these issues. In\nparticular, we propose (i) an experimental comparison of novelty detection\nmethods for mixed-type data (ii) an experimental comparison of novelty\ndetection methods for sequence data, (iii) a probabilistic nonparametric\nnovelty detection method for mixed-type data based on Dirichlet process\nmixtures and exponential-family distributions and (iv) an autoencoder-based\nnovelty detection model with encoder/decoder modelled as deep Gaussian\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 08:54:24 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Domingues", "R\u00e9mi", ""]]}, {"id": "1903.01734", "submitter": "Jiaqiyu Zhan", "authors": "Jiaqiyu Zhan, Zhiqiang Bai, Yuesheng Zhu", "title": "A Novel Efficient Approach with Data-Adaptive Capability for OMP-based\n  Sparse Subspace Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal Matching Pursuit (OMP) plays an important role in data science and\nits applications such as sparse subspace clustering and image processing.\nHowever, the existing OMP-based approaches lack of data adaptiveness so that\nthe data cannot be represented well enough and may lose the accuracy. This\npaper proposes a novel approach to enhance the data-adaptive capability for\nOMP-based sparse subspace clustering. In our method a parameter selection\nprocess is developed to adjust the parameters based on the data distribution\nfor information representation. Our theoretical analysis indicates that the\nparameter selection process can efficiently coordinate with any OMP-based\nmethods to improve the clustering performance. Also a new\nSelf-Expressive-Affinity (SEA) ratio metric is defined to measure the sparse\nrepresentation conversion efficiency for spectral clustering to obtain data\nsegmentations. Our experiments show that proposed approach can achieve better\nperformances compared with other OMP-based sparse subspace clustering\nalgorithms in terms of clustering accuracy, SEA ratio and representation\nquality, also keep the time efficiency and anti-noise ability.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 09:00:58 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 09:32:37 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Zhan", "Jiaqiyu", ""], ["Bai", "Zhiqiang", ""], ["Zhu", "Yuesheng", ""]]}, {"id": "1903.01743", "submitter": "Zheng Li", "authors": "Zheng Li, Chengyu Hu, Yang Zhang, Shanqing Guo", "title": "How to Prove Your Model Belongs to You: A Blind-Watermark based\n  Framework to Protect Intellectual Property of DNN", "comments": "To be published in ACSAC'19", "journal-ref": null, "doi": "10.1145/3359789.3359801", "report-no": null, "categories": "cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have made tremendous progress in a variety of\nchallenging tasks, such as image recognition and machine translation, during\nthe past decade. Training deep neural networks is computationally expensive and\nrequires both human and intellectual resources. Therefore, it is necessary to\nprotect the intellectual property of the model and externally verify the\nownership of the model. However, previous studies either fail to defend against\nthe evasion attack or have not explicitly dealt with fraudulent claims of\nownership by adversaries. Furthermore, they can not establish a clear\nassociation between the model and the creator's identity.\n  To fill these gaps, in this paper, we propose a novel intellectual property\nprotection (IPP) framework based on blind-watermark for watermarking deep\nneural networks that meet the requirements of security and feasibility. Our\nframework accepts ordinary samples and the exclusive logo as inputs, outputting\nnewly generated samples as watermarks, which are almost indistinguishable from\nthe origin, and infuses these watermarks into DNN models by assigning specific\nlabels, leaving the backdoor as the basis for our copyright claim. We evaluated\nour IPP framework on two benchmark datasets and 15 popular deep learning\nmodels. The results show that our framework successfully verifies the ownership\nof all the models without a noticeable impact on their primary task. Most\nimportantly, we are the first to successfully design and implement a\nblind-watermark based framework, which can achieve state-of-art performances on\nundetectability against evasion attack and unforgeability against fraudulent\nclaims of ownership. Further, our framework shows remarkable robustness and\nestablishes a clear association between the model and the author's identity.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 09:32:36 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 08:43:51 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 06:54:43 GMT"}, {"version": "v4", "created": "Thu, 7 Nov 2019 13:08:57 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Li", "Zheng", ""], ["Hu", "Chengyu", ""], ["Zhang", "Yang", ""], ["Guo", "Shanqing", ""]]}, {"id": "1903.01747", "submitter": "Ziyu Liu", "authors": "Ziyu Liu, Meng Zhou, Weiqing Cao, Qiang Qu, Henry Wing Fung Yeung,\n  Vera Yuk Ying Chung", "title": "Towards Understanding Chinese Checkers with Heuristics, Monte Carlo Tree\n  Search, and Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of Chinese Checkers is a challenging traditional board game of\nperfect information that differs from other traditional games in two main\naspects: first, unlike Chess, all checkers remain indefinitely in the game and\nhence the branching factor of the search tree does not decrease as the game\nprogresses; second, unlike Go, there are also no upper bounds on the depth of\nthe search tree since repetitions and backward movements are allowed.\nTherefore, even in a restricted game instance, the state-space of the game can\nstill be unbounded, making it challenging for a computer program to excel. In\nthis work, we present an approach that effectively combines the use of\nheuristics, Monte Carlo tree search, and deep reinforcement learning for\nbuilding a Chinese Checkers agent without the use of any human game-play data.\nExperiment results show that our agent is competent under different scenarios\nand reaches the level of experienced human players.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 09:44:22 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 12:35:10 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Liu", "Ziyu", ""], ["Zhou", "Meng", ""], ["Cao", "Weiqing", ""], ["Qu", "Qiang", ""], ["Yeung", "Henry Wing Fung", ""], ["Chung", "Vera Yuk Ying", ""]]}, {"id": "1903.01777", "submitter": "Amedeo Esposito", "authors": "Amedeo Roberto Esposito, Michael Gastpar, Ibrahim Issa", "title": "A New Approach to Adaptive Data Analysis and Learning via Maximal\n  Leakage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing concern that most current published research findings\nare false. The main cause seems to lie in the fundamental disconnection between\ntheory and practice in data analysis. While the former typically relies on\nstatistical independence, the latter is an inherently adaptive process: new\nhypotheses are formulated based on the outcomes of previous analyses. A recent\nline of work tries to mitigate these issues by enforcing constraints, such as\ndifferential privacy, that compose adaptively while degrading gracefully and\nthus provide statistical guarantees even in adaptive contexts. Our contribution\nconsists in the introduction of a new approach, based on the concept of Maximal\nLeakage, an information-theoretic measure of leakage of information. The main\nresult allows us to compare the probability of an event happening when\nadaptivity is considered with respect to the non-adaptive scenario. The bound\nwe derive represents a generalization of the bounds used in non-adaptive\nscenarios (e.g., McDiarmid's inequality for $c$-sensitive functions, false\ndiscovery error control via significance level, etc.), and allows us to\nreplicate or even improve, in certain regimes, the results obtained using\nMax-Information or Differential Privacy. In contrast with the line of work\nstarted by Dwork et al., our results do not rely on Differential Privacy but\nare, in principle, applicable to every algorithm that has a bounded leakage,\nincluding the differentially private algorithms and the ones with a short\ndescription length.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 11:59:06 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Esposito", "Amedeo Roberto", ""], ["Gastpar", "Michael", ""], ["Issa", "Ibrahim", ""]]}, {"id": "1903.01804", "submitter": "Abhinav Valada", "authors": "Federico Boniardi, Abhinav Valada, Rohit Mohan, Tim Caselitz, Wolfram\n  Burgard", "title": "Robot Localization in Floor Plans Using a Room Layout Edge Extraction\n  Network", "comments": "Accepted for IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indoor localization is one of the crucial enablers for deployment of service\nrobots. Although several successful techniques for indoor localization have\nbeen proposed, the majority of them relies on maps generated from data gathered\nwith the same sensor modality used for localization. Typically, tedious labor\nby experts is needed to acquire this data, thus limiting the readiness of the\nsystem as well as its ease of installation for inexperienced operators. In this\npaper, we propose a memory and computationally efficient monocular camera-based\nlocalization system that allows a robot to estimate its pose given an\narchitectural floor plan. Our method employs a convolutional neural network to\npredict room layout edges from a single camera image and estimates the robot\npose using a particle filter that matches the extracted edges to the given\nfloor plan. We evaluate our localization system using multiple real-world\nexperiments and demonstrate that it has the robustness and accuracy required\nfor reliable indoor navigation.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 13:09:18 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 10:59:11 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Boniardi", "Federico", ""], ["Valada", "Abhinav", ""], ["Mohan", "Rohit", ""], ["Caselitz", "Tim", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1903.01855", "submitter": "Akshay Agrawal", "authors": "Akshay Agrawal, Akshay Naresh Modi, Alexandre Passos, Allen Lavoie,\n  Ashish Agarwal, Asim Shankar, Igor Ganichev, Josh Levenberg, Mingsheng Hong,\n  Rajat Monga, Shanqing Cai", "title": "TensorFlow Eager: A Multi-Stage, Python-Embedded DSL for Machine\n  Learning", "comments": null, "journal-ref": "Proc. of the 2nd SysML Conference, 2019", "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TensorFlow Eager is a multi-stage, Python-embedded domain-specific language\nfor hardware-accelerated machine learning, suitable for both interactive\nresearch and production. TensorFlow, which TensorFlow Eager extends, requires\nusers to represent computations as dataflow graphs; this permits compiler\noptimizations and simplifies deployment but hinders rapid prototyping and\nrun-time dynamism. TensorFlow Eager eliminates these usability costs without\nsacrificing the benefits furnished by graphs: It provides an imperative\nfront-end to TensorFlow that executes operations immediately and a JIT tracer\nthat translates Python functions composed of TensorFlow operations into\nexecutable dataflow graphs. TensorFlow Eager thus offers a multi-stage\nprogramming model that makes it easy to interpolate between imperative and\nstaged execution in a single package.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 03:08:20 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Agrawal", "Akshay", ""], ["Modi", "Akshay Naresh", ""], ["Passos", "Alexandre", ""], ["Lavoie", "Allen", ""], ["Agarwal", "Ashish", ""], ["Shankar", "Asim", ""], ["Ganichev", "Igor", ""], ["Levenberg", "Josh", ""], ["Hong", "Mingsheng", ""], ["Monga", "Rajat", ""], ["Cai", "Shanqing", ""]]}, {"id": "1903.01867", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Multiple-Kernel Dictionary Learning for Reconstruction and Clustering of\n  Unseen Multivariate Time-series", "comments": "6 pages, ESANN 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist many approaches for description and recognition of unseen classes\nin datasets. Nevertheless, it becomes a challenging problem when we deal with\nmultivariate time-series (MTS) (e.g., motion data), where we cannot apply the\nvectorial algorithms directly to the inputs. In this work, we propose a novel\nmultiple-kernel dictionary learning (MKD) which learns semantic attributes\nbased on specific combinations of MTS dimensions in the feature space. Hence,\nMKD can fully/partially reconstructs the unseen classes based on the training\ndata (seen classes). Furthermore, we obtain sparse encodings for unseen classes\nbased on the learned MKD attributes, and upon which we propose a simple but\neffective incremental clustering algorithm to categorize the unseen MTS classes\nin an unsupervised way. According to the empirical evaluation of our MKD\nframework on real benchmarks, it provides an interpretable reconstruction of\nunseen MTS data as well as a high performance regarding their online\nclustering.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 14:53:15 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 10:32:48 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 21:31:04 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.01879", "submitter": "Irene Unceta", "authors": "Irene Unceta, Jordi Nin, Oriol Pujol", "title": "Copying Machine Learning Classifiers", "comments": "22 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study model-agnostic copies of machine learning classifiers. We develop\nthe theory behind the problem of copying, highlighting its differences with\nthat of learning, and propose a framework to copy the functionality of any\nclassifier using no prior knowledge of its parameters or training data\ndistribution. We identify the different sources of loss and provide guidelines\non how best to generate synthetic sets for the copying process. We further\nintroduce a set of metrics to evaluate copies in practice. We validate our\nframework through extensive experiments using data from a series of well-known\nproblems. We demonstrate the value of copies in use cases where desiderata such\nas interpretability, fairness or productivization constrains need to be\naddressed. Results show that copies can be exploited to enhance existing\nsolutions and improve them adding new features and characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 15:03:37 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 16:23:58 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Unceta", "Irene", ""], ["Nin", "Jordi", ""], ["Pujol", "Oriol", ""]]}, {"id": "1903.01882", "submitter": "Reuben Feinman", "authors": "Reuben Feinman, Brenden M. Lake", "title": "Learning a smooth kernel regularizer for convolutional neural networks", "comments": "Submitted to CogSci 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural networks require a tremendous amount of data to train,\noften needing hundreds or thousands of labeled examples to learn an effective\nrepresentation. For these networks to work with less data, more structure must\nbe built into their architectures or learned from previous experience. The\nlearned weights of convolutional neural networks (CNNs) trained on large\ndatasets for object recognition contain a substantial amount of structure.\nThese representations have parallels to simple cells in the primary visual\ncortex, where receptive fields are smooth and contain many regularities.\nIncorporating smoothness constraints over the kernel weights of modern CNN\narchitectures is a promising way to improve their sample complexity. We propose\na smooth kernel regularizer that encourages spatial correlations in convolution\nkernel weights. The correlation parameters of this regularizer are learned from\nprevious experience, yielding a method with a hierarchical Bayesian\ninterpretation. We show that our correlated regularizer can help constrain\nmodels for visual recognition, improving over an L2 regularization baseline.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 15:07:29 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Feinman", "Reuben", ""], ["Lake", "Brenden M.", ""]]}, {"id": "1903.01886", "submitter": "Simyung Chang", "authors": "Simyung Chang, John Yang, Jaeseok Choi, Nojun Kwak", "title": "Genetic-Gated Networks for Deep Reinforcement", "comments": null, "journal-ref": null, "doi": null, "report-no": "14pages, This paper is accepted at NIPS 2018", "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Genetic-Gated Networks (G2Ns), simple neural networks that\ncombine a gate vector composed of binary genetic genes in the hidden layer(s)\nof networks. Our method can take both advantages of gradient-free optimization\nand gradient-based optimization methods, of which the former is effective for\nproblems with multiple local minima, while the latter can quickly find local\nminima. In addition, multiple chromosomes can define different models, making\nit easy to construct multiple models and can be effectively applied to problems\nthat require multiple models. We show that this G2N can be applied to typical\nreinforcement learning algorithms to achieve a large improvement in sample\nefficiency and performance.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 21:56:05 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Chang", "Simyung", ""], ["Yang", "John", ""], ["Choi", "Jaeseok", ""], ["Kwak", "Nojun", ""]]}, {"id": "1903.01888", "submitter": "Luana Ruiz", "authors": "Luana Ruiz, Fernando Gama and Alejandro Ribeiro", "title": "Gated Graph Convolutional Recurrent Neural Networks", "comments": "Accepted at EUSIPCO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph processes model a number of important problems such as identifying the\nepicenter of an earthquake or predicting weather. In this paper, we propose a\nGraph Convolutional Recurrent Neural Network (GCRNN) architecture specifically\ntailored to deal with these problems. GCRNNs use convolutional filter banks to\nkeep the number of trainable parameters independent of the size of the graph\nand of the time sequences considered. We also put forward Gated GCRNNs, a\ntime-gated variation of GCRNNs akin to LSTMs. When compared with GNNs and\nanother graph recurrent architecture in experiments using both synthetic and\nreal-word data, GCRNNs significantly improve performance while using\nconsiderably less parameters.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 15:13:02 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 14:15:19 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 14:55:04 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Ruiz", "Luana", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1903.01895", "submitter": "Marijn Van Knippenberg", "authors": "Marijn van Knippenberg, Vlado Menkovski, Sergio Consoli", "title": "Evolutionary Construction of Convolutional Neural Networks", "comments": null, "journal-ref": "Springer Lecture Notes in Computer Science 11331 (2018) 293-304", "doi": "10.1007/978-3-030-13709-0_25", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neuro-Evolution is a field of study that has recently gained significantly\nincreased traction in the deep learning community. It combines deep neural\nnetworks and evolutionary algorithms to improve and/or automate the\nconstruction of neural networks. Recent Neuro-Evolution approaches have shown\npromising results, rivaling hand-crafted neural networks in terms of accuracy.\nA two-step approach is introduced where a convolutional autoencoder is created\nthat efficiently compresses the input data in the first step, and a\nconvolutional neural network is created to classify the compressed data in the\nsecond step. The creation of networks in both steps is guided by by an\nevolutionary process, where new networks are constantly being generated by\nmutating members of a collection of existing networks. Additionally, a method\nis introduced that considers the trade-off between compression and information\nloss of different convolutional autoencoders. This is used to select the\noptimal convolutional autoencoder from among those evolved to compress the data\nfor the second step. The complete framework is implemented, tested on the\npopular CIFAR-10 data set, and the results are discussed. Finally, a number of\npossible directions for future work with this particular framework in mind are\nconsidered, including opportunities to improve its efficiency and its\napplication in particular areas.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 12:30:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["van Knippenberg", "Marijn", ""], ["Menkovski", "Vlado", ""], ["Consoli", "Sergio", ""]]}, {"id": "1903.01899", "submitter": "Antoine Barbez", "authors": "Antoine Barbez, Foutse Khomh, Yann-Ga\\\"el Gu\\'eh\\'eneuc", "title": "A Machine-learning Based Ensemble Method For Anti-patterns Detection", "comments": "Preprint Submitted to Journal of Systems and Software, Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anti-patterns are poor solutions to recurring design problems. Several\nempirical studies have highlighted their negative impact on program\ncomprehension, maintainability, as well as fault-proneness. A variety of\ndetection approaches have been proposed to identify their occurrences in source\ncode. However, these approaches can identify only a subset of the occurrences\nand report large numbers of false positives and misses. Furthermore, a low\nagreement is generally observed among different approaches. Recent studies have\nshown the potential of machine-learning models to improve this situation.\nHowever, such algorithms require large sets of manually-produced training-data,\nwhich often limits their application in practice. In this paper, we present\nSMAD (SMart Aggregation of Anti-patterns Detectors), a machine-learning based\nensemble method to aggregate various anti-patterns detection approaches on the\nbasis of their internal detection rules. Thus, our method uses several\ndetection tools to produce an improved prediction from a reasonable number of\ntraining examples. We implemented SMAD for the detection of two well known\nanti-patterns: God Class and Feature Envy. With the results of our experiments\nconducted on eight java projects, we show that: (1) our method clearly improves\nthe so aggregated tools; (2) SMAD significantly outperforms other ensemble\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 21:29:05 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 22:35:45 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 20:16:09 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Barbez", "Antoine", ""], ["Khomh", "Foutse", ""], ["Gu\u00e9h\u00e9neuc", "Yann-Ga\u00ebl", ""]]}, {"id": "1903.01930", "submitter": "Matteo Stefanini", "authors": "Matteo Stefanini, Riccardo Lancellotti, Lorenzo Baraldi, Simone\n  Calderara", "title": "A Deep Learning based approach to VM behavior identification in cloud\n  systems", "comments": "Accepted at CLOSER2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing data centers are growing in size and complexity to the point\nwhere monitoring and management of the infrastructure become a challenge due to\nscalability issues. A possible approach to cope with the size of such data\ncenters is to identify VMs exhibiting a similar behavior. Existing literature\ndemonstrated that clustering together VMs that show a similar behavior may\nimprove the scalability of both monitoring andmanagement of a data center.\nHowever, available techniques suffer from a trade-off between accuracy and time\nto achieve this result. Throughout this paper we propose a different approach\nwhere, instead of an unsupervised clustering, we rely on classifiers based on\ndeep learning techniques to assigna newly deployed VMs to a cluster of\nalready-known VMs. The two proposed classifiers, namely DeepConv and DeepFFT\nuse a convolution neural network and (in the latter model) exploits Fast\nFourier Transformation to classify the VMs. Our proposal is validated using a\nset of traces describing the behavior of VMs from a realcloud data center. The\nexperiments compare our proposal with state-of-the-art solutions available in\nliterature, demonstrating that our proposal achieve better performance.\nFurthermore, we show that our solution issignificantly faster than the\nalternatives as it can produce a perfect classification even with just a few\nsamples of data, making our proposal viable also toclassify on-demand VMs that\nare characterized by a short life span.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 16:49:00 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Stefanini", "Matteo", ""], ["Lancellotti", "Riccardo", ""], ["Baraldi", "Lorenzo", ""], ["Calderara", "Simone", ""]]}, {"id": "1903.01931", "submitter": "Jianlin Su", "authors": "Jianlin Su", "title": "O-GAN: Extremely Concise Approach for Auto-Encoding Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose Orthogonal Generative Adversarial Networks\n(O-GANs). We decompose the network of discriminator orthogonally and add an\nextra loss into the objective of common GANs, which can enforce discriminator\nbecome an effective encoder. The same extra loss can be embedded into any kind\nof GANs and there is almost no increase in computation. Furthermore, we discuss\nthe principle of our method, which is relative to the fully-exploiting of the\nremaining degrees of freedom of discriminator. As we know, our solution is the\nsimplest approach to train a generative adversarial network with auto-encoding\nability.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 17:01:49 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Su", "Jianlin", ""]]}, {"id": "1903.01939", "submitter": "Yuuki Takai", "authors": "Akiyoshi Sannai, Yuuki Takai, Matthieu Cordonnier", "title": "Universal approximations of permutation invariant/equivariant functions\n  by deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a theory about the relationship between\n$G$-invariant/equivariant functions and deep neural networks for finite group\n$G$. Especially, for a given $G$-invariant/equivariant function, we construct\nits universal approximator by deep neural network whose layers equip\n$G$-actions and each affine transformations are $G$-equivariant/invariant. Due\nto representation theory, we can show that this approximator has exponentially\nfewer free parameters than usual models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 17:17:02 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 08:12:15 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 05:43:19 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Sannai", "Akiyoshi", ""], ["Takai", "Yuuki", ""], ["Cordonnier", "Matthieu", ""]]}, {"id": "1903.01944", "submitter": "Chao Gao", "authors": "Chao Gao, Yuan Yao, Weizhi Zhu", "title": "Generative Adversarial Nets for Robust Scatter Estimation: A Proper\n  Scoring Rule Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust scatter estimation is a fundamental task in statistics. The recent\ndiscovery on the connection between robust estimation and generative\nadversarial nets (GANs) by Gao et al. (2018) suggests that it is possible to\ncompute depth-like robust estimators using similar techniques that optimize\nGANs. In this paper, we introduce a general learning via classification\nframework based on the notion of proper scoring rules. This framework allows us\nto understand both matrix depth function and various GANs through the lens of\nvariational approximations of $f$-divergences induced by proper scoring rules.\nWe then propose a new class of robust scatter estimators in this framework by\ncarefully constructing discriminators with appropriate neural network\nstructures. These estimators are proved to achieve the minimax rate of scatter\nestimation under Huber's contamination model. Our numerical results demonstrate\nits good performance under various settings against competitors in the\nliterature.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 17:29:04 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Gao", "Chao", ""], ["Yao", "Yuan", ""], ["Zhu", "Weizhi", ""]]}, {"id": "1903.01959", "submitter": "Tao Chen", "authors": "Tao Chen, Saurabh Gupta, Abhinav Gupta", "title": "Learning Exploration Policies for Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous past works have tackled the problem of task-driven navigation. But,\nhow to effectively explore a new environment to enable a variety of down-stream\ntasks has received much less attention. In this work, we study how agents can\nautonomously explore realistic and complex 3D environments without the context\nof task-rewards. We propose a learning-based approach and investigate different\npolicy architectures, reward functions, and training paradigms. We find that\nthe use of policies with spatial memory that are bootstrapped with imitation\nlearning and finally finetuned with coverage rewards derived purely from\non-board sensors can be effective at exploring novel environments. We show that\nour learned exploration policies can explore better than classical approaches\nbased on geometry alone and generic learning-based exploration techniques.\nFinally, we also show how such task-agnostic exploration can be used for\ndown-stream tasks. Code and Videos are available at:\nhttps://sites.google.com/view/exploration-for-nav.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 18:03:47 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Chen", "Tao", ""], ["Gupta", "Saurabh", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1903.01969", "submitter": "Saeed Amizadeh", "authors": "Saeed Amizadeh, Sergiy Matusevych, Markus Weimer", "title": "PDP: A General Neural Framework for Learning Constraint Satisfaction\n  Solvers", "comments": "Neuro-symbolic Methods, Neural Combinatorial Optimization, Geometric\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been recent efforts for incorporating Graph Neural Network models\nfor learning full-stack solvers for constraint satisfaction problems (CSP) and\nparticularly Boolean satisfiability (SAT). Despite the unique representational\npower of these neural embedding models, it is not clear how the search strategy\nin the learned models actually works. On the other hand, by fixing the search\nstrategy (e.g. greedy search), we would effectively deprive the neural models\nof learning better strategies than those given. In this paper, we propose a\ngeneric neural framework for learning CSP solvers that can be described in\nterms of probabilistic inference and yet learn search strategies beyond greedy\nsearch. Our framework is based on the idea of propagation, decimation and\nprediction (and hence the name PDP) in graphical models, and can be trained\ndirectly toward solving CSP in a fully unsupervised manner via energy\nminimization, as shown in the paper. Our experimental results demonstrate the\neffectiveness of our framework for SAT solving compared to both neural and the\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 18:26:33 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Amizadeh", "Saeed", ""], ["Matusevych", "Sergiy", ""], ["Weimer", "Markus", ""]]}, {"id": "1903.01974", "submitter": "Mehmet Emre Ozfatura", "authors": "Emre Ozfatura and Deniz Gunduz and Sennur Ulukus", "title": "Gradient Coding with Clustering and Multi-message Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent (GD) methods are commonly employed in machine learning\nproblems to optimize the parameters of the model in an iterative fashion. For\nproblems with massive datasets, computations are distributed to many parallel\ncomputing servers (i.e., workers) to speed up GD iterations. While distributed\ncomputing can increase the computation speed significantly, the per-iteration\ncompletion time is limited by the slowest straggling workers. Coded distributed\ncomputing can mitigate straggling workers by introducing redundant\ncomputations; however, existing coded computing schemes are mainly designed\nagainst persistent stragglers, and partial computations at straggling workers\nare discarded, leading to wasted computational capacity. In this paper, we\npropose a novel gradient coding (GC) scheme which allows multiple coded\ncomputations to be conveyed from each worker to the master per iteration. We\nnumerically show that the proposed GC with multi-message communication (MMC)\ntogether with clustering provides significant improvements in the average\ncompletion time (of each iteration), with minimal or no increase in the\ncommunication load.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 18:38:15 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Ozfatura", "Emre", ""], ["Gunduz", "Deniz", ""], ["Ulukus", "Sennur", ""]]}, {"id": "1903.01980", "submitter": "Matthew Wicker", "authors": "Luca Cardelli, Marta Kwiatkowska, Luca Laurenti, Nicola Paoletti,\n  Andrea Patane, and Matthew Wicker", "title": "Statistical Guarantees for the Robustness of Bayesian Neural Networks", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a probabilistic robustness measure for Bayesian Neural Networks\n(BNNs), defined as the probability that, given a test point, there exists a\npoint within a bounded set such that the BNN prediction differs between the\ntwo. Such a measure can be used, for instance, to quantify the probability of\nthe existence of adversarial examples. Building on statistical verification\ntechniques for probabilistic models, we develop a framework that allows us to\nestimate probabilistic robustness for a BNN with statistical guarantees, i.e.,\nwith a priori error and confidence bounds. We provide experimental comparison\nfor several approximate BNN inference techniques on image classification tasks\nassociated to MNIST and a two-class subset of the GTSRB dataset. Our results\nenable quantification of uncertainty of BNN predictions in adversarial\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 18:49:40 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Cardelli", "Luca", ""], ["Kwiatkowska", "Marta", ""], ["Laurenti", "Luca", ""], ["Paoletti", "Nicola", ""], ["Patane", "Andrea", ""], ["Wicker", "Matthew", ""]]}, {"id": "1903.01997", "submitter": "Masayoshi Kubo", "authors": "Masayoshi Kubo, Ryotaro Banno, Hidetaka Manabe and Masataka Minoji", "title": "Implicit Regularization in Over-parameterized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parameterized neural networks generalize well in practice without any\nexplicit regularization. Although it has not been proven yet, empirical\nevidence suggests that implicit regularization plays a crucial role in deep\nlearning and prevents the network from overfitting. In this work, we introduce\nthe gradient gap deviation and the gradient deflection as statistical measures\ncorresponding to the network curvature and the Hessian matrix to analyze\nvariations of network derivatives with respect to input parameters, and\ninvestigate how implicit regularization works in ReLU neural networks from both\ntheoretical and empirical perspectives. Our result reveals that the network\noutput between each pair of input samples is properly controlled by random\ninitialization and stochastic gradient descent to keep interpolating between\nsamples almost straight, which results in low complexity of over-parameterized\nneural networks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 19:00:01 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Kubo", "Masayoshi", ""], ["Banno", "Ryotaro", ""], ["Manabe", "Hidetaka", ""], ["Minoji", "Masataka", ""]]}, {"id": "1903.01998", "submitter": "Hongyu Shen", "authors": "Hongyu Shen, E. A. Huerta, Eamonn O'Shea, Prayush Kumar, Zhizhen Zhao", "title": "Statistically-informed deep learning for gravitational wave parameter\n  estimation", "comments": "v3: 14 pages, 6 figures, First application of Neural Networks for\n  gravitational wave parameter posterior estimation across multiple events with\n  single training", "journal-ref": null, "doi": null, "report-no": null, "categories": "gr-qc astro-ph.HE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce deep learning models for gravitational wave parameter estimation\nthat combine a modified $\\texttt{WaveNet}$ architecture with\n$\\textit{constrastive learning}$ and $\\textit{normalizing flow}$. To ascertain\nthe statistical consistency of these models, we validated their predictions\nagainst a Gaussian conjugate prior family whose posterior distribution is\ndescribed by a closed analytical expression. Upon confirming that our models\nproduce statistically consistent results, we used them to estimate the\nastrophysical parameters of five binary black holes: $\\texttt{GW150914}$,\n$\\texttt{GW170104}$, $\\texttt{GW170814}$, $\\texttt{GW190521}$ and\n$\\texttt{GW190630}$. Our findings indicate that our deep learning approach\npredicts posterior distributions that encode physical correlations, and that\nour data-driven median results and $90\\%$ confidence intervals are consistent\nwith those obtained with gravitational wave Bayesian analyses. This methodology\nrequires a single V100 $\\texttt{NVIDIA}$ GPU to produce median values and\nposterior distributions within two milliseconds for each event. This neural\nnetwork, and a tutorial for its use, are available at the $\\texttt{Data and\nLearning Hub for Science}$.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 19:00:02 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 17:39:55 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 01:48:35 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Shen", "Hongyu", ""], ["Huerta", "E. A.", ""], ["O'Shea", "Eamonn", ""], ["Kumar", "Prayush", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1903.02013", "submitter": "Michael Wojnowicz", "authors": "Michael Thomas Wojnowicz and Xuan Zhao", "title": "PROPS: Probabilistic personalization of black-box sequence models", "comments": null, "journal-ref": "2018 IEEE International Conference on Big Data (Big Data),\n  4768-4774", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PROPS, a lightweight transfer learning mechanism for sequential\ndata. PROPS learns probabilistic perturbations around the predictions of one or\nmore arbitrarily complex, pre-trained black box models (such as recurrent\nneural networks). The technique pins the black-box prediction functions to\n\"source nodes\" of a hidden Markov model (HMM), and uses the remaining nodes as\n\"perturbation nodes\" for learning customized perturbations around those\npredictions. In this paper, we describe the PROPS model, provide an algorithm\nfor online learning of its parameters, and demonstrate the consistency of this\nestimation. We also explore the utility of PROPS in the context of personalized\nlanguage modeling. In particular, we construct a baseline language model by\ntraining a LSTM on the entire Wikipedia corpus of 2.5 million articles (around\n6.6 billion words), and then use PROPS to provide lightweight customization\ninto a personalized language model of President Donald J. Trump's tweeting. We\nachieved good customization after only 2,000 additional words, and find that\nthe PROPS model, being fully probabilistic, provides insight into when\nPresident Trump's speech departs from generic patterns in the Wikipedia corpus.\nPython code (for both the PROPS training algorithm as well as experiment\nreproducibility) is available at\nhttps://github.com/cylance/perturbed-sequence-model.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 19:02:11 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Wojnowicz", "Michael Thomas", ""], ["Zhao", "Xuan", ""]]}, {"id": "1903.02020", "submitter": "Prasoon Goyal", "authors": "Prasoon Goyal, Scott Niekum, Raymond J. Mooney", "title": "Using Natural Language for Reward Shaping in Reinforcement Learning", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent reinforcement learning (RL) approaches have shown strong performance\nin complex domains such as Atari games, but are often highly sample\ninefficient. A common approach to reduce interaction time with the environment\nis to use reward shaping, which involves carefully designing reward functions\nthat provide the agent intermediate rewards for progress towards the goal.\nHowever, designing appropriate shaping rewards is known to be difficult as well\nas time-consuming. In this work, we address this problem by using natural\nlanguage instructions to perform reward shaping. We propose the LanguagE-Action\nReward Network (LEARN), a framework that maps free-form natural language\ninstructions to intermediate rewards based on actions taken by the agent. These\nintermediate language-based rewards can seamlessly be integrated into any\nstandard reinforcement learning algorithm. We experiment with Montezuma's\nRevenge from the Atari Learning Environment, a popular benchmark in RL. Our\nexperiments on a diverse set of 15 tasks demonstrate that, for the same number\nof interactions with the environment, language-based rewards lead to successful\ncompletion of the task 60% more often on average, compared to learning without\nlanguage.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 19:20:35 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 04:58:07 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Goyal", "Prasoon", ""], ["Niekum", "Scott", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1903.02048", "submitter": "Xiaowei Xu", "authors": "Xiaowei Xu", "title": "On the Quantization of Cellular Neural Networks for Cyber-Physical\n  Systems", "comments": "14 pages,10 figures", "journal-ref": "TC-CCPS Newsletter, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems (CPSs) have been pervasive including smart grid,\nautonomous automobile systems, medical monitoring, process control systems,\nrobotics systems, and automatic pilot avionics. As usually implemented on\nembedded devices, CPS is typically constrained by computation capacity and\nenergy consumption. In some CPS applications such as telemedicine and advanced\ndriving assistance system (ADAS), data processing on the embedded devices is\npreferred due to security/safety and real-time requirement. Therefore, high\nefficiency is highly desirable for such CPS applications. In this paper we\npresent CeNN quantization for high-efficient processing for CPS applications,\nparticularly telemedicine and ADAS applications. We systematically put forward\npowers-of-two based incremental quantization of CeNNs for efficient hardware\nimplementation. The incremental quantization contains iterative procedures\nincluding parameter partition, parameter quantization, and re-training. We\npropose five different strategies including random strategy, pruning inspired\nstrategy, weighted pruning inspired strategy, nearest neighbor strategy, and\nweighted nearest neighbor strategy. Experimental results show that our approach\ncan achieve a speedup up to 7.8x with no performance loss compared with the\nstate-of-the-art FPGA solutions for CeNNs.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 20:47:33 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Xu", "Xiaowei", ""]]}, {"id": "1903.02050", "submitter": "Yukun Ding", "authors": "Yukun Ding, Jinglan Liu, Jinjun Xiong, Yiyu Shi", "title": "Revisiting the Evaluation of Uncertainty Estimation and Its Application\n  to Explore Model Complexity-Uncertainty Trade-Off", "comments": "CVPR 2020 - Fair, Data Efficient and Trusted Computer Vision Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately estimating uncertainties in neural network predictions is of great\nimportance in building trusted DNNs-based models, and there is an increasing\ninterest in providing accurate uncertainty estimation on many tasks, such as\nsecurity cameras and autonomous driving vehicles. In this paper, we focus on\nthe two main use cases of uncertainty estimation, i.e. selective prediction and\nconfidence calibration. We first reveal potential issues of commonly used\nquality metrics for uncertainty estimation in both use cases, and propose our\nnew metrics to mitigate them. We then apply these new metrics to explore the\ntrade-off between model complexity and uncertainty estimation quality, a\ncritically missing work in the literature. Our empirical experiment results\nvalidate the superiority of the proposed metrics, and some interesting trends\nabout the complexity-uncertainty trade-off are observed.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 21:02:44 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 15:50:52 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 00:06:45 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Ding", "Yukun", ""], ["Liu", "Jinglan", ""], ["Xiong", "Jinjun", ""], ["Shi", "Yiyu", ""]]}, {"id": "1903.02054", "submitter": "Karthikeyan Shanmugam", "authors": "Dmitriy Katz, Karthikeyan Shanmugam, Chandler Squires, Caroline Uhler", "title": "Size of Interventional Markov Equivalence Classes in Random DAG Models", "comments": "19 pages, 5 figures. Accepted to AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed acyclic graph (DAG) models are popular for capturing causal\nrelationships. From observational and interventional data, a DAG model can only\nbe determined up to its \\emph{interventional Markov equivalence class} (I-MEC).\nWe investigate the size of MECs for random DAG models generated by uniformly\nsampling and ordering an Erd\\H{o}s-R\\'{e}nyi graph. For constant density, we\nshow that the expected $\\log$ observational MEC size asymptotically (in the\nnumber of vertices) approaches a constant. We characterize I-MEC size in a\nsimilar fashion in the above settings with high precision. We show that the\nasymptotic expected number of interventions required to fully identify a DAG is\na constant. These results are obtained by exploiting Meek rules and coupling\narguments to provide sharp upper and lower bounds on the asymptotic quantities,\nwhich are then calculated numerically up to high precision. Our results have\nimportant consequences for experimental design of interventions and the\ndevelopment of algorithms for causal inference.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 21:09:37 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Katz", "Dmitriy", ""], ["Shanmugam", "Karthikeyan", ""], ["Squires", "Chandler", ""], ["Uhler", "Caroline", ""]]}, {"id": "1903.02063", "submitter": "Richard Oentaryo", "authors": "Thong Hoang, Julia Lawall, Richard J. Oentaryo, Yuan Tian, David Lo", "title": "PatchNet: A Tool for Deep Patch Classification", "comments": null, "journal-ref": "International Conference on Software Engineering (ICSE), 2019", "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes PatchNet, an automated tool based on hierarchical deep\nlearning for classifying patches by extracting features from commit messages\nand code changes. PatchNet contains a deep hierarchical structure that mirrors\nthe hierarchical and sequential structure of a code change, differentiating it\nfrom the existing deep learning models on source code. PatchNet provides\nseveral options allowing users to select parameters for the training process.\nThe tool has been validated in the context of automatic identification of\nstable-relevant patches in the Linux kernel and is potentially applicable to\nautomate other software engineering tasks that can be formulated as patch\nclassification problems. A video demonstrating PatchNet is available at\nhttps://goo.gl/CZjG6X. The PatchNet implementation is available at\nhttps://github.com/hvdthong/PatchNetTool.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 06:51:42 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 16:54:51 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Hoang", "Thong", ""], ["Lawall", "Julia", ""], ["Oentaryo", "Richard J.", ""], ["Tian", "Yuan", ""], ["Lo", "David", ""]]}, {"id": "1903.02074", "submitter": "Jonathon Sather", "authors": "Jonathon Sather and Xiaozheng Jane Zhang", "title": "Viewpoint Optimization for Autonomous Strawberry Harvesting with Deep\n  Reinforcement Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous harvesting may provide a viable solution to mounting labor\npressures in the United States's strawberry industry. However, due to\nbottlenecks in machine perception and economic viability, a profitable and\ncommercially adopted strawberry harvesting system remains elusive. In this\nresearch, we explore the feasibility of using deep reinforcement learning to\novercome these bottlenecks and develop a practical algorithm to address the\nsub-objective of viewpoint optimization, or the development of a control policy\nto direct a camera to favorable vantage points for autonomous harvesting. We\nevaluate the algorithm's performance in a custom, open-source simulated\nenvironment and observe encouraging results. Our trained agent yields 8.7 times\nhigher returns than random actions and 8.8 percent faster exploration than our\nbest baseline policy, which uses visual servoing. Visual investigation shows\nthe agent is able to fixate on favorable viewpoints, despite having no explicit\nmeans to propagate information through time. Overall, we conclude that deep\nreinforcement learning is a promising area of research to advance the state of\nthe art in autonomous strawberry harvesting.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 21:54:46 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 05:01:24 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Sather", "Jonathon", ""], ["Zhang", "Xiaozheng Jane", ""]]}, {"id": "1903.02079", "submitter": "Nazeeh Ghatasheh", "authors": "Nazeeh Ghatasheh, Hossam Faris, Ibrahim Aljarah, Rizik M. H. Al-Sayyed", "title": "Optimizing Software Effort Estimation Models Using Firefly Algorithm", "comments": "9 pages", "journal-ref": "Journal of Software Engineering and Applications, 8, 133-142\n  (2018)", "doi": "10.4236/jsea.2015.83014", "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software development effort estimation is considered a fundamental task for\nsoftware development life cycle as well as for managing project cost, time and\nquality. Therefore, accurate estimation is a substantial factor in projects\nsuccess and reducing the risks. In recent years, software effort estimation has\nreceived a considerable amount of attention from researchers and became a\nchallenge for software industry. In the last two decades, many researchers and\npractitioners proposed statistical and machine learning-based models for\nsoftware effort estimation. In this work, Firefly Algorithm is proposed as a\nmetaheuristic optimization method for optimizing the parameters of three\nCOCOMO-based models. These models include the basic COCOMO model and other two\nmodels proposed in the literature as extensions of the basic COCOMO model. The\ndeveloped estimation models are evaluated using different evaluation metrics.\nExperimental results show high accuracy and significant error minimization of\nFirefly Algorithm over other metaheuristic optimization algorithms including\nGenetic Algorithms and Particle Swarm Optimization.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 23:34:43 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Ghatasheh", "Nazeeh", ""], ["Faris", "Hossam", ""], ["Aljarah", "Ibrahim", ""], ["Al-Sayyed", "Rizik M. H.", ""]]}, {"id": "1903.02080", "submitter": "Senthil Yogamani", "authors": "Sambit Mohapatra, Heinrich Gotzig, Senthil Yogamani, Stefan Milz and\n  Raoul Zollner", "title": "Exploring Deep Spiking Neural Networks for Automated Driving\n  Applications", "comments": "Accepted for Oral Presentation at VISAPP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become the standard model for various computer vision\ntasks in automated driving including semantic segmentation, moving object\ndetection, depth estimation, visual odometry, etc. The main flavors of neural\nnetworks which are used commonly are convolutional (CNN) and recurrent (RNN).\nIn spite of rapid progress in embedded processors, power consumption and cost\nis still a bottleneck. Spiking Neural Networks (SNNs) are gradually progressing\nto achieve low-power event-driven hardware architecture which has a potential\nfor high efficiency. In this paper, we explore the role of deep spiking neural\nnetworks (SNN) for automated driving applications. We provide an overview of\nprogress on SNN and argue how it can be a good fit for automated driving\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 18:40:42 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Mohapatra", "Sambit", ""], ["Gotzig", "Heinrich", ""], ["Yogamani", "Senthil", ""], ["Milz", "Stefan", ""], ["Zollner", "Raoul", ""]]}, {"id": "1903.02081", "submitter": "Samira Vafay Eslahi", "authors": "Samira Vafay Eslahi, Nader Jafarnia Dabanloo, Keivan Maghooli", "title": "A GA-based feature selection of the EEG signals by classification\n  evaluation: Application in BCI systems", "comments": "12 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In electroencephalogram (EEG) signal processing, finding the appropriate\ninformation from a dataset has been a big challenge for successful signal\nclassification. The feature selection methods make it possible to solve this\nproblem; however, the method selection is still under investigation to find out\nwhich feature can perform the best to extract the most proper features of the\nsignal to improve the classification performance. In this study, we use the\ngenetic algorithm (GA), a heuristic searching algorithm, to find the optimum\ncombination of the feature extraction methods and the classifiers, in the\nbrain-computer interface (BCI) applications. A BCI system can be practical if\nand only if it performs with high accuracy and high speed alongside each other.\nIn the proposed method, GA performs as a searching engine to find the best\ncombination of the features and classifications. The features used here are\nKatz, Higuchi, Petrosian, Sevcik, and box-counting dimension (BCD) feature\nextraction methods. These features are applied to the wavelet subbands and are\nclassified with four classifiers such as adaptive neuro-fuzzy inference system\n(ANFIS), fuzzy k-nearest neighbors (FKNN), support vector machine (SVM) and\nlinear discriminant analysis (LDA). Due to the huge number of features, the GA\noptimization is used to find the features with the optimum fitness value (FV).\nResults reveal that Katz fractal feature estimation method with LDA\nclassification has the best FV. Consequently, due to the low computation time\nof the first Daubechies wavelet transformation in comparison to the original\nsignal, the final selected methods contain the fractal features of the first\ncoefficient of the detail subbands.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 05:31:08 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Eslahi", "Samira Vafay", ""], ["Dabanloo", "Nader Jafarnia", ""], ["Maghooli", "Keivan", ""]]}, {"id": "1903.02082", "submitter": "Yifeng Zhang", "authors": "Yifeng Zhang, Ka-Ho Chow, S.-H. Gary Chan", "title": "DA-LSTM: A Long Short-Term Memory with Depth Adaptive to Non-uniform\n  Information Flow in Sequential Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much sequential data exhibits highly non-uniform information distribution.\nThis cannot be correctly modeled by traditional Long Short-Term Memory (LSTM).\nTo address that, recent works have extended LSTM by adding more activations\nbetween adjacent inputs. However, the approaches often use a fixed depth, which\nis at the step of the most information content. This one-size-fits-all\nworst-case approach is not satisfactory, because when little information is\ndistributed to some steps, shallow structures can achieve faster convergence\nand consume less computation resource. In this paper, we develop a\nDepth-Adaptive Long Short-Term Memory (DA-LSTM) architecture, which can\ndynamically adjust the structure depending on information distribution without\nprior knowledge. Experimental results on real-world datasets show that DA-LSTM\ncosts much less computation resource and substantially reduce convergence time\nby $41.78\\%$ and $46.01 \\%$, compared with Stacked LSTM and Deep Transition\nLSTM, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 14:21:12 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Zhang", "Yifeng", ""], ["Chow", "Ka-Ho", ""], ["Chan", "S. -H. Gary", ""]]}, {"id": "1903.02083", "submitter": "Brian Crafton Mr.", "authors": "Brian Crafton, Abhinav Parihar, Evan Gebhardt, Arijit Raychowdhury", "title": "Direct Feedback Alignment with Sparse Connections for Local Learning", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep neural networks (DNNs) owe their success to training\nalgorithms that use backpropagation and gradient-descent. Backpropagation,\nwhile highly effective on von Neumann architectures, becomes inefficient when\nscaling to large networks. Commonly referred to as the weight transport\nproblem, each neuron's dependence on the weights and errors located deeper in\nthe network require exhaustive data movement which presents a key problem in\nenhancing the performance and energy-efficiency of machine-learning hardware.\nIn this work, we propose a bio-plausible alternative to backpropagation drawing\nfrom advances in feedback alignment algorithms in which the error computation\nat a single synapse reduces to the product of three scalar values. Using a\nsparse feedback matrix, we show that a neuron needs only a fraction of the\ninformation previously used by the feedback alignment algorithms. Consequently,\nmemory and compute can be partitioned and distributed whichever way produces\nthe most efficient forward pass so long as a single error can be delivered to\neach neuron. Our results show orders of magnitude improvement in data movement\nand $2\\times$ improvement in multiply-and-accumulate operations over\nbackpropagation. Like previous work, we observe that any variant of feedback\nalignment suffers significant losses in classification accuracy on deep\nconvolutional neural networks. By transferring trained convolutional layers and\ntraining the fully connected layers using direct feedback alignment, we\ndemonstrate that direct feedback alignment can obtain results competitive with\nbackpropagation. Furthermore, we observe that using an extremely sparse\nfeedback matrix, rather than a dense one, results in a small accuracy drop\nwhile yielding hardware advantages. All the code and results are available\nunder https://github.com/bcrafton/ssdfa.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 16:33:08 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 14:13:29 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Crafton", "Brian", ""], ["Parihar", "Abhinav", ""], ["Gebhardt", "Evan", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "1903.02088", "submitter": "Lucy Vasserman", "authors": "Daniel Borkan, Lucas Dixon, John Li, Jeffrey Sorensen, Nithum Thain,\n  Lucy Vasserman", "title": "Limitations of Pinned AUC for Measuring Unintended Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report examines the Pinned AUC metric introduced and highlights some of\nits limitations. Pinned AUC provides a threshold-agnostic measure of unintended\nbias in a classification model, inspired by the ROC-AUC metric. However, as we\nhighlight in this report, there are ways that the metric can obscure different\nkinds of unintended biases when the underlying class distributions on which\nbias is being measured are not carefully controlled.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 22:18:36 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Borkan", "Daniel", ""], ["Dixon", "Lucas", ""], ["Li", "John", ""], ["Sorensen", "Jeffrey", ""], ["Thain", "Nithum", ""], ["Vasserman", "Lucy", ""]]}, {"id": "1903.02108", "submitter": "Sajad Mousavi", "authors": "Sajad Mousavi, Fatemeh Afghah, U. Rajendra Acharya", "title": "SleepEEGNet: Automated Sleep Stage Scoring with Sequence to Sequence\n  Deep Learning Approach", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0216456", "report-no": null, "categories": "eess.SP cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalogram (EEG) is a common base signal used to monitor brain\nactivity and diagnose sleep disorders. Manual sleep stage scoring is a\ntime-consuming task for sleep experts and is limited by inter-rater\nreliability. In this paper, we propose an automatic sleep stage annotation\nmethod called SleepEEGNet using a single-channel EEG signal. The SleepEEGNet is\ncomposed of deep convolutional neural networks (CNNs) to extract time-invariant\nfeatures, frequency information, and a sequence to sequence model to capture\nthe complex and long short-term context dependencies between sleep epochs and\nscores. In addition, to reduce the effect of the class imbalance problem\npresented in the available sleep datasets, we applied novel loss functions to\nhave an equal misclassified error for each sleep stage while training the\nnetwork. We evaluated the proposed method on different single-EEG channels\n(i.e., Fpz-Cz and Pz-Oz EEG channels) from the Physionet Sleep-EDF datasets\npublished in 2013 and 2018. The evaluation results demonstrate that the\nproposed method achieved the best annotation performance compared to current\nliterature, with an overall accuracy of 84.26%, a macro F1-score of 79.66% and\nCohen's Kappa coefficient = 0.79. Our developed model is ready to test with\nmore sleep EEG signals and aid the sleep specialists to arrive at an accurate\ndiagnosis. The source code is available at\nhttps://github.com/SajadMo/SleepEEGNet.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 23:30:26 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Mousavi", "Sajad", ""], ["Afghah", "Fatemeh", ""], ["Acharya", "U. Rajendra", ""]]}, {"id": "1903.02114", "submitter": "Jo\\~ao Silv\\'erio", "authors": "Jo\\~ao Silv\\'erio, Yanlong Huang, Fares J. Abu-Dakka, Leonel Rozo and\n  Darwin G. Caldwell", "title": "Uncertainty-Aware Imitation Learning using Kernelized Movement\n  Primitives", "comments": "Published in the proceedings of IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past few years, probabilistic approaches to imitation learning\nhave earned a relevant place in the literature. One of their most prominent\nfeatures, in addition to extracting a mean trajectory from task demonstrations,\nis that they provide a variance estimation. The intuitive meaning of this\nvariance, however, changes across different techniques, indicating either\nvariability or uncertainty. In this paper we leverage kernelized movement\nprimitives (KMP) to provide a new perspective on imitation learning by\npredicting variability, correlations and uncertainty about robot actions. This\nrich set of information is used in combination with optimal controller fusion\nto learn actions from data, with two main advantages: i) robots become safe\nwhen uncertain about their actions and ii) they are able to leverage partial\ndemonstrations, given as elementary sub-tasks, to optimally perform a higher\nlevel, more complex task. We showcase our approach in a painting task, where a\nhuman user and a KUKA robot collaborate to paint a wooden board. The task is\ndivided into two sub-tasks and we show that using our approach the robot\nbecomes compliant (hence safe) outside the training regions and executes the\ntwo sub-tasks with optimal gains.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 23:45:20 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 13:55:14 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 16:23:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Silv\u00e9rio", "Jo\u00e3o", ""], ["Huang", "Yanlong", ""], ["Abu-Dakka", "Fares J.", ""], ["Rozo", "Leonel", ""], ["Caldwell", "Darwin G.", ""]]}, {"id": "1903.02125", "submitter": "Ghazaleh Beigi", "authors": "Ghazaleh Beigi, Suhas Ranganath, Huan Liu", "title": "Signed Link Prediction with Sparse Data: The Role of Personality\n  Information", "comments": "Companion Proceedings of the 2019 World Wide Web Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting signed links in social networks often faces the problem of signed\nlink data sparsity, i.e., only a small percentage of signed links are given.\nThe problem is exacerbated when the number of negative links is much smaller\nthan that of positive links. Boosting signed link prediction necessitates\nadditional information to compensate for data sparsity. According to psychology\ntheories, one rich source of such information is user's personality such as\noptimism and pessimism that can help determine her propensity in establishing\npositive and negative links. In this study, we investigate how personality\ninformation can be obtained, and if personality information can help alleviate\nthe data sparsity problem for signed link prediction. We propose a novel signed\nlink prediction model that enables empirical exploration of user personality\nvia social media data. We evaluate our proposed model on two datasets of\nreal-world signed link networks. The results demonstrate the complementary role\nof personality information in the signed link prediction problem. Experimental\nresults also indicate the effectiveness of different levels of personality\ninformation for signed link data sparsity problem.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 00:22:21 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Beigi", "Ghazaleh", ""], ["Ranganath", "Suhas", ""], ["Liu", "Huan", ""]]}, {"id": "1903.02134", "submitter": "Tianxing He", "authors": "Tianxing He and James Glass", "title": "Negative Training for Neural Dialogue Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning models have brought tremendous advancements to the\nfield of open-domain dialogue response generation, recent research results have\nrevealed that the trained models have undesirable generation behaviors, such as\nmalicious responses and generic (boring) responses. In this work, we propose a\nframework named \"Negative Training\" to minimize such behaviors. Given a trained\nmodel, the framework will first find generated samples that exhibit the\nundesirable behavior, and then use them to feed negative training signals for\nfine-tuning the model. Our experiments show that negative training can\nsignificantly reduce the hit rate of malicious responses, or discourage\nfrequent responses and improve response diversity.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 01:37:51 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 19:59:16 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 13:58:21 GMT"}, {"version": "v4", "created": "Tue, 7 Apr 2020 01:37:11 GMT"}, {"version": "v5", "created": "Tue, 18 Aug 2020 16:27:57 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["He", "Tianxing", ""], ["Glass", "James", ""]]}, {"id": "1903.02140", "submitter": "Hui Jiang", "authors": "Hui Jiang", "title": "Why Learning of Large-Scale Neural Networks Behaves Like Convex\n  Optimization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present some theoretical work to explain why simple\ngradient descent methods are so successful in solving non-convex optimization\nproblems in learning large-scale neural networks (NN). After introducing a\nmathematical tool called canonical space, we have proved that the objective\nfunctions in learning NNs are convex in the canonical model space. We further\nelucidate that the gradients between the original NN model space and the\ncanonical space are related by a pointwise linear transformation, which is\nrepresented by the so-called disparity matrix. Furthermore, we have proved that\ngradient descent methods surely converge to a global minimum of zero loss\nprovided that the disparity matrices maintain full rank. If this full-rank\ncondition holds, the learning of NNs behaves in the same way as normal convex\noptimization. At last, we have shown that the chance to have singular disparity\nmatrices is extremely slim in large NNs. In particular, when over-parameterized\nNNs are randomly initialized, the gradient decent algorithms converge to a\nglobal minimum of zero loss in probability.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 02:21:37 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Jiang", "Hui", ""]]}, {"id": "1903.02152", "submitter": "Jiangchao Yao", "authors": "Jiangchao Yao, Ya Zhang, Ivor W. Tsang and Jun Sun", "title": "Safeguarded Dynamic Label Regression for Generalized Noisy Supervision", "comments": "Submitted to Transactions on Image Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with noisy labels, which aims to reduce expensive labors on accurate\nannotations, has become imperative in the Big Data era. Previous noise\ntransition based method has achieved promising results and presented a\ntheoretical guarantee on performance in the case of class-conditional noise.\nHowever, this type of approaches critically depend on an accurate\npre-estimation of the noise transition, which is usually impractical.\nSubsequent improvement adapts the pre-estimation along with the training\nprogress via a Softmax layer. However, the parameters in the Softmax layer are\nhighly tweaked for the fragile performance due to the ill-posed stochastic\napproximation. To address these issues, we propose a Latent Class-Conditional\nNoise model (LCCN) that naturally embeds the noise transition under a Bayesian\nframework. By projecting the noise transition into a Dirichlet-distributed\nspace, the learning is constrained on a simplex based on the whole dataset,\ninstead of some ad-hoc parametric space. We then deduce a dynamic label\nregression method for LCCN to iteratively infer the latent labels, to\nstochastically train the classifier and to model the noise. Our approach\nsafeguards the bounded update of the noise transition, which avoids previous\narbitrarily tuning via a batch of samples. We further generalize LCCN for\nopen-set noisy labels and the semi-supervised setting. We perform extensive\nexperiments with the controllable noise data sets, CIFAR-10 and CIFAR-100, and\nthe agnostic noise data sets, Clothing1M and WebVision17. The experimental\nresults have demonstrated that the proposed model outperforms several\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 03:20:09 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Yao", "Jiangchao", ""], ["Zhang", "Ya", ""], ["Tsang", "Ivor W.", ""], ["Sun", "Jun", ""]]}, {"id": "1903.02154", "submitter": "Qingcan Wang", "authors": "Weinan E, Chao Ma, Qingcan Wang", "title": "A Priori Estimates of the Population Risk for Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal a priori estimates are derived for the population risk, also known as\nthe generalization error, of a regularized residual network model. An important\npart of the regularized model is the usage of a new path norm, called the\nweighted path norm, as the regularization term. The weighted path norm treats\nthe skip connections and the nonlinearities differently so that paths with more\nnonlinearities are regularized by larger weights. The error estimates are a\npriori in the sense that the estimates depend only on the target function, not\non the parameters obtained in the training process. The estimates are optimal,\nin a high dimensional setting, in the sense that both the bound for the\napproximation and estimation errors are comparable to the Monte Carlo error\nrates. A crucial step in the proof is to establish an optimal bound for the\nRademacher complexity of the residual networks. Comparisons are made with\nexisting norm-based generalization error bounds.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 03:35:30 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 00:30:40 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["E", "Weinan", ""], ["Ma", "Chao", ""], ["Wang", "Qingcan", ""]]}, {"id": "1903.02163", "submitter": "Sanghwan Bae", "authors": "Sanghwan Bae, Jihun Choi, Sang-goo Lee", "title": "SNU_IDS at SemEval-2019 Task 3: Addressing Training-Test Class\n  Distribution Mismatch in Conversational Classification", "comments": "International Workshop on Semantic Evaluation (SemEval 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several techniques to tackle the mismatch in class distributions\nbetween training and test data in the Contextual Emotion Detection task of\nSemEval 2019, by extending the existing methods for class imbalance problem.\nReducing the distance between the distribution of prediction and ground truth,\nthey consistently show positive effects on the performance. Also we propose a\nnovel neural architecture which utilizes representation of overall context as\nwell as of each utterance. The combination of the methods and the models\nachieved micro F1 score of about 0.766 on the final evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 03:53:19 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 11:55:47 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Bae", "Sanghwan", ""], ["Choi", "Jihun", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1903.02164", "submitter": "Yuchen Li", "authors": "Ahmed Ayyad, Yuchen Li, Nassir Navab, Shadi Albarqouni, Mohamed\n  Elhoseiny", "title": "Semi-Supervised Few-Shot Learning with Prototypical Random Walks", "comments": "Accepted by AAAI 2021 Workshop (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent progress has shown that few-shot learning can be improved with access\nto unlabelled data, known as semi-supervised few-shot learning(SS-FSL). We\nintroduce an SS-FSL approach, dubbed as Prototypical Random Walk\nNetworks(PRWN), built on top of Prototypical Networks (PN). We develop a random\nwalk semi-supervised loss that enables the network to learn representations\nthat are compact and well-separated. Our work is related to the very recent\ndevelopment of graph-based approaches for few-shot learning. However, we show\nthat compact and well-separated class representations can be achieved by\nmodeling our prototypical random walk notion without needing additional\ngraph-NN parameters or requiring a transductive setting where a collective test\nset is provided. Our model outperforms baselines in most benchmarks with\nsignificant improvements in some cases. Our model, trained with 40$\\%$ of the\ndata as labeled, compares competitively against fully supervised prototypical\nnetworks, trained on 100$\\%$ of the labels, even outperforming it in the 1-shot\nmini-Imagenet case with 50.89$\\%$ to 49.4$\\%$ accuracy. We also show that our\nloss is resistant to distractors, unlabeled data that does not belong to any of\nthe training classes, and hence reflecting robustness to labeled/unlabeled\nclass distribution mismatch. Associated GitHub page can be found at\nhttps://prototypical-random-walk.github.io.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 03:54:40 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 20:33:17 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 06:19:56 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Ayyad", "Ahmed", ""], ["Li", "Yuchen", ""], ["Navab", "Nassir", ""], ["Albarqouni", "Shadi", ""], ["Elhoseiny", "Mohamed", ""]]}, {"id": "1903.02172", "submitter": "Marwan Mattar", "authors": "Marwan Mattar, Roozbeh Mottaghi, Julian Togelius, Danny Lange", "title": "AAAI-2019 Workshop on Games and Simulations for Artificial Intelligence", "comments": "AAAI-2019 Workshop on Games and Simulations for Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume represents the accepted submissions from the AAAI-2019 Workshop\non Games and Simulations for Artificial Intelligence held on January 29, 2019\nin Honolulu, Hawaii, USA. https://www.gamesim.ai\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 04:49:07 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Mattar", "Marwan", ""], ["Mottaghi", "Roozbeh", ""], ["Togelius", "Julian", ""], ["Lange", "Danny", ""]]}, {"id": "1903.02173", "submitter": "Gan Sun", "authors": "Gan Sun, Yang Cong, Qianqian Wang, Bineng Zhong, Yun Fu", "title": "Representative Task Self-selection for Flexible Clustered Lifelong\n  Learning", "comments": "15 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the lifelong machine learning paradigm whose objective is to learn a\nsequence of tasks depending on previous experiences, e.g., knowledge library or\ndeep network weights. However, the knowledge libraries or deep networks for\nmost recent lifelong learning models are with prescribed size, and can\ndegenerate the performance for both learned tasks and coming ones when facing\nwith a new task environment (cluster). To address this challenge, we propose a\nnovel incremental clustered lifelong learning framework with two knowledge\nlibraries: feature learning library and model knowledge library, called\nFlexible Clustered Lifelong Learning (FCL3). Specifically, the feature learning\nlibrary modeled by an autoencoder architecture maintains a set of\nrepresentation common across all the observed tasks, and the model knowledge\nlibrary can be self-selected by identifying and adding new representative\nmodels (clusters). When a new task arrives, our proposed FCL3model firstly\ntransfers knowledge from these libraries to encode the new task,\ni.e.,effectively and selectively soft-assigning this new task to multiple\nrepresentative models over feature learning library. Then, 1) the new task with\na higher outlier probability will be judged as a new representative, and used\nto redefine both feature learning library and representative models over time;\nor 2) the new task with lower outlier probability will only refine the feature\nlearning library. For model optimization, we cast this lifelong learning\nproblem as an alternating direction minimization problem as a new task comes.\nFinally, we evaluate the proposed framework by analyzing several multi-task\ndatasets, and the experimental results demonstrate that our FCL3 model can\nachieve better performance than most lifelong learning frameworks, even batch\nclustered multi-task learning models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 04:49:55 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 17:12:27 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Sun", "Gan", ""], ["Cong", "Yang", ""], ["Wang", "Qianqian", ""], ["Zhong", "Bineng", ""], ["Fu", "Yun", ""]]}, {"id": "1903.02174", "submitter": "Wen Zhang", "authors": "Wen Zhang, Kai Shu, Huan Liu, Yalin Wang", "title": "Graph Neural Networks for User Identity Linkage", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popularity and diversity of social media sites has encouraged\nmore and more people to participate in multiple online social networks to enjoy\ntheir services. Each user may create a user identity to represent his or her\nunique public figure in every social network. User identity linkage across\nonline social networks is an emerging task and has attracted increasing\nattention, which could potentially impact various domains such as\nrecommendations and link predictions. The majority of existing work focuses on\nmining network proximity or user profile data for discovering user identity\nlinkages. With the recent advancements in graph neural networks (GNNs), it\nprovides great potential to advance user identity linkage since users are\nconnected in social graphs, and learning latent factors of users and items is\nthe key. However, predicting user identity linkages based on GNNs faces\nchallenges. For example, the user social graphs encode both \\textit{local}\nstructure such as users' neighborhood signals, and \\textit{global} structure\nwith community properties. To address these challenges simultaneously, in this\npaper, we present a novel graph neural network framework ({\\m}) for user\nidentity linkage. In particular, we provide a principled approach to jointly\ncapture local and global information in the user-user social graph and propose\nthe framework {\\m}, which jointly learning user representations for user\nidentity linkage. Extensive experiments on real-world datasets demonstrate the\neffectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 04:58:43 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Zhang", "Wen", ""], ["Shu", "Kai", ""], ["Liu", "Huan", ""], ["Wang", "Yalin", ""]]}, {"id": "1903.02201", "submitter": "Yang Li", "authors": "Yang Li, Lloyd Allison, Kevin Korb", "title": "Proving the NP-completeness of optimal moral graph triangulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moral graphs were introduced in the 1980s as an intermediate step when\ntransforming a Bayesian network to a junction tree, on which exact belief\npropagation can be efficiently done. The moral graph of a Bayesian network can\nbe trivially obtained by connecting non-adjacent parents for each node in the\nBayesian network and dropping the direction of each edge. Perhaps because the\nmoralization process looks simple, there has been little attention on the\nproperties of moral graphs and their impact in belief propagation on Bayesian\nnetworks. This paper addresses the mistaken claim that it has been previously\nproved that optimal moral graph triangulation with the constraints of minimum\nfill-in, treewidth or total states is NP-complete. The problems are in fact\nNP-complete, but they have not previously been proved. We now prove these.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 06:52:21 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Li", "Yang", ""], ["Allison", "Lloyd", ""], ["Korb", "Kevin", ""]]}, {"id": "1903.02219", "submitter": "Guillaume Bellegarda", "authors": "Guillaume Bellegarda and Katie Byl", "title": "Training in Task Space to Speed Up and Guide Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in the reinforcement learning (RL) community have made\nsignificant advances towards learning and deploying policies on real world\nrobotic systems. However, even with the current state-of-the-art algorithms and\ncomputational resources, these algorithms are still plagued with high sample\ncomplexity, and thus long training times, especially for high degree of freedom\n(DOF) systems. There are also concerns arising from lack of perceived stability\nor robustness guarantees from emerging policies. This paper aims at mitigating\nthese drawbacks by: (1) modeling a complex, high DOF system with a\nrepresentative simple one, (2) making explicit use of forward and inverse\nkinematics without forcing the RL algorithm to \"learn\" them on its own, and (3)\nlearning locomotion policies in Cartesian space instead of joint space. In this\npaper these methods are applied to JPL's Robosimian, but can be readily used on\nany system with a base and end effector(s). These locomotion policies can be\nproduced in just a few minutes, trained on a single laptop. We compare the\nrobustness of the resulting learned policies to those of other control methods.\nAn accompanying video for this paper can be found at\nhttps://youtu.be/xDxxSw5ahnc .\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 07:39:11 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Bellegarda", "Guillaume", ""], ["Byl", "Katie", ""]]}, {"id": "1903.02237", "submitter": "Qi Meng", "authors": "Mingyang Yi, Qi Meng, Wei Chen, Zhi-ming Ma and Tie-Yan Liu", "title": "Positively Scale-Invariant Flatness of ReLU Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was empirically confirmed by Keskar et al.\\cite{SharpMinima} that flatter\nminima generalize better. However, for the popular ReLU network, sharp minimum\ncan also generalize well \\cite{SharpMinimacan}. The conclusion demonstrates\nthat the existing definitions of flatness fail to account for the complex\ngeometry of ReLU neural networks because they can't cover the Positively\nScale-Invariant (PSI) property of ReLU network. In this paper, we formalize the\nPSI causes problem of existing definitions of flatness and propose a new\ndescription of flatness - \\emph{PSI-flatness}. PSI-flatness is defined on the\nvalues of basis paths \\cite{GSGD} instead of weights. Values of basis paths\nhave been shown to be the PSI-variables and can sufficiently represent the ReLU\nneural networks which ensure the PSI property of PSI-flatness. Then we study\nthe relation between PSI-flatness and generalization theoretically and\nempirically. First, we formulate a generalization bound based on PSI-flatness\nwhich shows generalization error decreasing with the ratio between the largest\nbasis path value and the smallest basis path value. That is to say, the minimum\nwith balanced values of basis paths will more likely to be flatter and\ngeneralize better. Finally. we visualize the PSI-flatness of loss surface\naround two learned models which indicates the minimum with smaller PSI-flatness\ncan indeed generalize better.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 08:21:09 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Yi", "Mingyang", ""], ["Meng", "Qi", ""], ["Chen", "Wei", ""], ["Ma", "Zhi-ming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1903.02242", "submitter": "Zhiyuan Jiang", "authors": "Zhiyuan Jiang and Sheng Zhou and Zhisheng Niu", "title": "Distributed Policy Learning Based Random Access for Diversified QoS\n  Requirements", "comments": "To appear in ICC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future wireless access networks need to support diversified quality of\nservice (QoS) metrics required by various types of Internet-of-Things (IoT)\ndevices, e.g., age of information (AoI) for status generating sources and ultra\nlow latency for safety information in vehicular networks. In this paper, a\nnovel inner-state driven random access (ISDA) framework is proposed based on\ndistributed policy learning, in particular a cross-entropy method. Conventional\nrandom access schemes, e.g., $p$-CSMA, assume state-less terminals, and thus\nassigning equal priorities to all. In ISDA, the inner-states of terminals are\ndescribed by a time-varying state vector, and the transmission probabilities of\nterminals in the contention period are determined by their respective\ninner-states. Neural networks are leveraged to approximate the function\nmappings from inner-states to transmission probabilities, and an iterative\napproach is adopted to improve these mappings in a distributed manner.\nExperiment results show that ISDA can improve the QoS of heterogeneous\nterminals simultaneously compared to conventional CSMA schemes.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 08:38:03 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Jiang", "Zhiyuan", ""], ["Zhou", "Sheng", ""], ["Niu", "Zhisheng", ""]]}, {"id": "1903.02271", "submitter": "Michael Tschannen", "authors": "Mario Lucic, Michael Tschannen, Marvin Ritter, Xiaohua Zhai, Olivier\n  Bachem, Sylvain Gelly", "title": "High-Fidelity Image Generation With Fewer Labels", "comments": "Mario Lucic, Michael Tschannen, and Marvin Ritter contributed equally\n  to this work. ICML 2019 camera-ready version. Code available at\n  https://github.com/google/compare_gan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are becoming a cornerstone of modern machine learning.\nRecent work on conditional generative adversarial networks has shown that\nlearning complex, high-dimensional distributions over natural images is within\nreach. While the latest models are able to generate high-fidelity, diverse\nnatural images at high resolution, they rely on a vast quantity of labeled\ndata. In this work we demonstrate how one can benefit from recent work on self-\nand semi-supervised learning to outperform the state of the art on both\nunsupervised ImageNet synthesis, as well as in the conditional setting. In\nparticular, the proposed approach is able to match the sample quality (as\nmeasured by FID) of the current state-of-the-art conditional model BigGAN on\nImageNet using only 10% of the labels and outperform it using 20% of the\nlabels.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 09:52:49 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 15:27:42 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Lucic", "Mario", ""], ["Tschannen", "Michael", ""], ["Ritter", "Marvin", ""], ["Zhai", "Xiaohua", ""], ["Bachem", "Olivier", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1903.02313", "submitter": "Konstantinos Nikolaidis", "authors": "Konstantinos Nikolaidis, Stein Kristiansen, Vera Goebel, Thomas\n  Plagemann", "title": "Learning from Higher-Layer Feature Visualizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the goal to enable sleep apnea monitoring and machine\nlearning-based detection at home with small mobile devices, we investigate\nwhether interpretation-based indirect knowledge transfer can be used to create\nclassifiers with acceptable performance. Interpretation-based indirect\nknowledge transfer means that a classifier (student) learns from a synthetic\ndataset based on the knowledge representation from an already trained Deep\nNetwork (teacher). We use activation maximization to generate visualizations\nand create a synthetic dataset to train the student classifier. This approach\nhas the advantage that student classifiers can be trained without access to the\noriginal training data. With experiments we investigate the feasibility of\ninterpretation-based indirect knowledge transfer and its limitations. The\nstudent achieves an accuracy of 97.8% on MNIST (teacher accuracy: 99.3%) with a\nsimilar smaller architecture to that of the teacher. The student classifier\nachieves an accuracy of 86.1% and 89.5% for a subset of the Apnea-ECG dataset\n(teacher: 89.5% and 91.1%, respectively).\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 11:01:17 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Nikolaidis", "Konstantinos", ""], ["Kristiansen", "Stein", ""], ["Goebel", "Vera", ""], ["Plagemann", "Thomas", ""]]}, {"id": "1903.02318", "submitter": "Urtats Etxegarai Susaeta", "authors": "U. Etxegarai, E. Portillo, J. Irazusta, L. A. Koefoed, N. Kasabov", "title": "A heuristic approach for lactate threshold estimation for training\n  decision-making: An accessible and easy to use solution for recreational\n  runners", "comments": "25 pages, 11 figures", "journal-ref": null, "doi": "10.1016/j.ejor.2019.08.023", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a heuristic as operational tool to estimate the lactate\nthreshold and to facilitate its integration into the training process of\nrecreational runners is proposed. To do so, we formalize the principles for the\nlactate threshold estimation from empirical data and an iterative methodology\nthat enables experience based learning. This strategy arises as a robust and\nadaptive approach to solve data analysis problems. We compare the results of\nthe heuristic with the most commonly used protocol by making a first\nquantitative error analysis to show its reliability. Additionally, we provide a\ncomputational algorithm so that this quantitative analysis can be easily\nperformed in other lactate threshold protocols. With this work, we have shown\nthat a heuristic %60 of 'endurance running speed reserve', serves for the same\npurpose of the most commonly used protocol in recreational runners, but\nimproving its operational limitations of accessibility and consistent use.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 11:09:58 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Etxegarai", "U.", ""], ["Portillo", "E.", ""], ["Irazusta", "J.", ""], ["Koefoed", "L. A.", ""], ["Kasabov", "N.", ""]]}, {"id": "1903.02334", "submitter": "Saeed Saremi", "authors": "Saeed Saremi, Aapo Hyvarinen", "title": "Neural Empirical Bayes", "comments": "23 pages, 10 figures", "journal-ref": "Journal of Machine Learning Research 20(181), 1-23, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We unify $\\textit{kernel density estimation}$ and $\\textit{empirical Bayes}$\nand address a set of problems in unsupervised learning with a geometric\ninterpretation of those methods, rooted in the $\\textit{concentration of\nmeasure}$ phenomenon. Kernel density is viewed symbolically as\n$X\\rightharpoonup Y$ where the random variable $X$ is smoothed to $Y=\nX+N(0,\\sigma^2 I_d)$, and empirical Bayes is the machinery to denoise in a\nleast-squares sense, which we express as $X \\leftharpoondown Y$. A learning\nobjective is derived by combining these two, symbolically captured by $X\n\\rightleftharpoons Y$. Crucially, instead of using the original nonparametric\nestimators, we parametrize $\\textit{the energy function}$ with a neural network\ndenoted by $\\phi$; at optimality, $\\nabla \\phi \\approx -\\nabla \\log f$ where\n$f$ is the density of $Y$. The optimization problem is abstracted as\ninteractions of high-dimensional spheres which emerge due to the concentration\nof isotropic gaussians. We introduce two algorithmic frameworks based on this\nmachinery: (i) a \"walk-jump\" sampling scheme that combines Langevin MCMC\n(walks) and empirical Bayes (jumps), and (ii) a probabilistic framework for\n$\\textit{associative memory}$, called NEBULA, defined \\`{a} la Hopfield by the\n$\\textit{gradient flow}$ of the learned energy to a set of attractors. We\nfinish the paper by reporting the emergence of very rich \"creative memories\" as\nattractors of NEBULA for highly-overlapping spheres.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 12:04:44 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 03:12:26 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Saremi", "Saeed", ""], ["Hyvarinen", "Aapo", ""]]}, {"id": "1903.02380", "submitter": "Roman Werpachowski", "authors": "Roman Werpachowski, Andr\\'as Gy\\\"orgy and Csaba Szepesv\\'ari", "title": "Detecting Overfitting via Adversarial Examples", "comments": "17 pages", "journal-ref": "Part of: Advances in Neural Information Processing Systems 32\n  (NIPS 2019) pre-proceedings", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The repeated community-wide reuse of test sets in popular benchmark problems\nraises doubts about the credibility of reported test-error rates. Verifying\nwhether a learned model is overfitted to a test set is challenging as\nindependent test sets drawn from the same data distribution are usually\nunavailable, while other test sets may introduce a distribution shift. We\npropose a new hypothesis test that uses only the original test data to detect\noverfitting. It utilizes a new unbiased error estimate that is based on\nadversarial examples generated from the test data and importance weighting.\nOverfitting is detected if this error estimate is sufficiently different from\nthe original test error rate. We develop a specialized variant of our test for\nmulticlass image classification, and apply it to testing overfitting of recent\nmodels to the popular ImageNet benchmark. Our method correctly indicates\noverfitting of the trained model to the training set, but is not able to detect\nany overfitting to the test set, in line with other recent work on this topic.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 13:49:18 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 11:16:01 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Werpachowski", "Roman", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1903.02407", "submitter": "Li Ant", "authors": "Liat Antwarg, Ronnie Mindlin Miller, Bracha Shapira, Lior Rokach", "title": "Explaining Anomalies Detected by Autoencoders Using SHAP", "comments": "Added more evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection algorithms are often thought to be limited because they\ndon't facilitate the process of validating results performed by domain experts.\nIn Contrast, deep learning algorithms for anomaly detection, such as\nautoencoders, point out the outliers, saving experts the time-consuming task of\nexamining normal cases in order to find anomalies. Most outlier detection\nalgorithms output a score for each instance in the database. The top-k most\nintense outliers are returned to the user for further inspection; however the\nmanual validation of results becomes challenging without additional clues. An\nexplanation of why an instance is anomalous enables the experts to focus their\ninvestigation on most important anomalies and may increase their trust in the\nalgorithm.\n  Recently, a game theory-based framework known as SHapley Additive\nexPlanations (SHAP) has been shown to be effective in explaining various\nsupervised learning models. In this research, we extend SHAP to explain\nanomalies detected by an autoencoder, an unsupervised model. The proposed\nmethod extracts and visually depicts both the features that most contributed to\nthe anomaly and those that offset it. A preliminary experimental study using\nreal world data demonstrates the usefulness of the proposed method in assisting\nthe domain experts to understand the anomaly and filtering out the\nuninteresting anomalies, aiming at minimizing the false positive rate of\ndetected anomalies.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 14:29:27 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 20:32:25 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Antwarg", "Liat", ""], ["Miller", "Ronnie Mindlin", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""]]}, {"id": "1903.02409", "submitter": "Prashan Madumal", "authors": "Prashan Madumal, Tim Miller, Liz Sonenberg, Frank Vetere", "title": "A Grounded Interaction Protocol for Explainable Artificial Intelligence", "comments": "To appear in 18th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2019) as a full paper. arXiv admin note:\n  substantial text overlap with arXiv:1806.08055", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (XAI) systems need to include an\nexplanation model to communicate the internal decisions, behaviours and actions\nto the interacting humans. Successful explanation involves both cognitive and\nsocial processes. In this paper we focus on the challenge of meaningful\ninteraction between an explainer and an explainee and investigate the\nstructural aspects of an interactive explanation to propose an interaction\nprotocol. We follow a bottom-up approach to derive the model by analysing\ntranscripts of different explanation dialogue types with 398 explanation\ndialogues. We use grounded theory to code and identify key components of an\nexplanation dialogue. We formalize the model using the agent dialogue framework\n(ADF) as a new dialogue type and then evaluate it in a human-agent interaction\nstudy with 101 dialogues from 14 participants. Our results show that the\nproposed model can closely follow the explanation dialogues of human-agent\nconversations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 09:44:16 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Madumal", "Prashan", ""], ["Miller", "Tim", ""], ["Sonenberg", "Liz", ""], ["Vetere", "Frank", ""]]}, {"id": "1903.02428", "submitter": "Matthias Fey", "authors": "Matthias Fey, Jan Eric Lenssen", "title": "Fast Graph Representation Learning with PyTorch Geometric", "comments": "ICLR 2019 (RLGM Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PyTorch Geometric, a library for deep learning on irregularly\nstructured input data such as graphs, point clouds and manifolds, built upon\nPyTorch. In addition to general graph data structures and processing methods,\nit contains a variety of recently published methods from the domains of\nrelational learning and 3D data processing. PyTorch Geometric achieves high\ndata throughput by leveraging sparse GPU acceleration, by providing dedicated\nCUDA kernels and by introducing efficient mini-batch handling for input\nexamples of different size. In this work, we present the library in detail and\nperform a comprehensive comparative study of the implemented methods in\nhomogeneous evaluation scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 14:50:02 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 17:07:42 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 10:06:09 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Fey", "Matthias", ""], ["Lenssen", "Jan Eric", ""]]}, {"id": "1903.02456", "submitter": "Stefan Bauer", "authors": "Anant Raj and Luigi Gresele and Michel Besserve and Bernhard\n  Sch\\\"olkopf and Stefan Bauer", "title": "Orthogonal Structure Search for Efficient Causal Discovery from\n  Observational Data", "comments": "first author uploaded a new version as \"Causal Feature Selection via\n  Orthogonal Search\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of inferring the direct causal parents of a response variable\namong a large set of explanatory variables is of high practical importance in\nmany disciplines. Recent work exploits stability of regression coefficients or\ninvariance properties of models across different experimental conditions for\nreconstructing the full causal graph. These approaches generally do not scale\nwell with the number of the explanatory variables and are difficult to extend\nto nonlinear relationships. Contrary to existing work, we propose an approach\nwhich even works for observational data alone, while still offering theoretical\nguarantees including the case of partially nonlinear relationships. Our\nalgorithm requires only one estimation for each variable and in our experiments\nwe apply our causal discovery algorithm even to large graphs, demonstrating\nsignificant improvements compared to well established approaches.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 15:51:10 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 13:53:21 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Raj", "Anant", ""], ["Gresele", "Luigi", ""], ["Besserve", "Michel", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bauer", "Stefan", ""]]}, {"id": "1903.02482", "submitter": "Yuan Zhou", "authors": "Yuan Zhou, Bradley J. Gram-Hansen, Tobias Kohn, Tom Rainforth,\n  Hongseok Yang, Frank Wood", "title": "LF-PPL: A Low-Level First Order Probabilistic Programming Language for\n  Non-Differentiable Models", "comments": "Published in the proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new Low-level, First-order Probabilistic Programming Language\n(LF-PPL) suited for models containing a mix of continuous, discrete, and/or\npiecewise-continuous variables. The key success of this language and its\ncompilation scheme is in its ability to automatically distinguish parameters\nthe density function is discontinuous with respect to, while further providing\nruntime checks for boundary crossings. This enables the introduction of new\ninference engines that are able to exploit gradient information, while\nremaining efficient for models which are not everywhere differentiable. We\ndemonstrate this ability by incorporating a discontinuous Hamiltonian Monte\nCarlo (DHMC) inference engine that is able to deliver automated and efficient\ninference for non-differentiable models. Our system is backed up by a\nmathematical formalism that ensures that any model expressed in this language\nhas a density with measure zero discontinuities to maintain the validity of the\ninference engine.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 16:29:20 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Zhou", "Yuan", ""], ["Gram-Hansen", "Bradley J.", ""], ["Kohn", "Tobias", ""], ["Rainforth", "Tom", ""], ["Yang", "Hongseok", ""], ["Wood", "Frank", ""]]}, {"id": "1903.02489", "submitter": "Alexandre Gari\\'epy", "authors": "Alexandre Gari\\'epy, Jean-Christophe Ruel, Brahim Chaib-draa and\n  Philippe Gigu\\`ere", "title": "GQ-STN: Optimizing One-Shot Grasp Detection based on Robustness\n  Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grasping is a fundamental robotic task needed for the deployment of household\nrobots or furthering warehouse automation. However, few approaches are able to\nperform grasp detection in real time (frame rate). To this effect, we present\nGrasp Quality Spatial Transformer Network (GQ-STN), a one-shot grasp detection\nnetwork. Being based on the Spatial Transformer Network (STN), it produces not\nonly a grasp configuration, but also directly outputs a depth image centered at\nthis configuration. By connecting our architecture to an externally-trained\ngrasp robustness evaluation network, we can train efficiently to satisfy a\nrobustness metric via the backpropagation of the gradient emanating from the\nevaluation network. This removes the difficulty of training detection networks\non sparsely annotated databases, a common issue in grasping. We further propose\nto use this robustness classifier to compare approaches, being more reliable\nthan the traditional rectangle metric. Our GQ-STN is able to detect robust\ngrasps on the depth images of the Dex-Net 2.0 dataset with 92.4 % accuracy in a\nsingle pass of the network. We finally demonstrate in a physical benchmark that\nour method can propose robust grasps more often than previous sampling-based\nmethods, while being more than 60 times faster.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 16:53:46 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 00:56:36 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Gari\u00e9py", "Alexandre", ""], ["Ruel", "Jean-Christophe", ""], ["Chaib-draa", "Brahim", ""], ["Gigu\u00e8re", "Philippe", ""]]}, {"id": "1903.02511", "submitter": "Miguel Vasco", "authors": "Miguel Vasco, Francisco S. Melo, David Martins de Matos, Ana Paiva,\n  Tetsunari Inamura", "title": "Learning multimodal representations for sample-efficient recognition of\n  human actions", "comments": "7 pages, 6 figures, submitted to 2019 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans interact in rich and diverse ways with the environment. However, the\nrepresentation of such behavior by artificial agents is often limited. In this\nwork we present \\textit{motion concepts}, a novel multimodal representation of\nhuman actions in a household environment. A motion concept encompasses a\nprobabilistic description of the kinematics of the action along with its\ncontextual background, namely the location and the objects held during the\nperformance. Furthermore, we present Online Motion Concept Learning (OMCL), a\nnew algorithm which learns novel motion concepts from action demonstrations and\nrecognizes previously learned motion concepts. The algorithm is evaluated on a\nvirtual-reality household environment with the presence of a human avatar. OMCL\noutperforms standard motion recognition algorithms on an one-shot recognition\ntask, attesting to its potential for sample-efficient recognition of human\nactions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 17:37:21 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Vasco", "Miguel", ""], ["Melo", "Francisco S.", ""], ["de Matos", "David Martins", ""], ["Paiva", "Ana", ""], ["Inamura", "Tetsunari", ""]]}, {"id": "1903.02521", "submitter": "Aritra Chowdhury", "authors": "Aritra Chowdhury, Malik Magdin-Ismail, Bulent Yener", "title": "Quantifying error contributions of computational steps, algorithms and\n  hyperparameter choices in image classification pipelines", "comments": "arXiv admin note: substantial text overlap with arXiv:1903.00405", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data science relies on pipelines that are organized in the form of\ninterdependent computational steps. Each step consists of various candidate\nalgorithms that maybe used for performing a particular function. Each algorithm\nconsists of several hyperparameters. Algorithms and hyperparameters must be\noptimized as a whole to produce the best performance. Typical machine learning\npipelines typically consist of complex algorithms in each of the steps. Not\nonly is the selection process combinatorial, but it is also important to\ninterpret and understand the pipelines. We propose a method to quantify the\nimportance of different layers in the pipeline, by computing an error\ncontribution relative to an agnostic choice of algorithms in that layer. We\ndemonstrate our methodology on image classification pipelines. The agnostic\nmethodology quantifies the error contributions from the computational steps,\nalgorithms and hyperparameters in the image classification pipeline. We show\nthat algorithm selection and hyper-parameter optimization methods can be used\nto quantify the error contribution and that random search is able to quantify\nthe contribution more accurately than Bayesian optimization. This methodology\ncan be used by domain experts to understand machine learning and data analysis\npipelines in terms of their individual components, which can help in\nprioritizing different components of the pipeline.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 19:16:58 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Chowdhury", "Aritra", ""], ["Magdin-Ismail", "Malik", ""], ["Yener", "Bulent", ""]]}, {"id": "1903.02526", "submitter": "Jiameng Fan", "authors": "Jiameng Fan, Wenchao Li", "title": "Safety-Guided Deep Reinforcement Learning via Online Gaussian Process\n  Estimation", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important facet of reinforcement learning (RL) has to do with how the\nagent goes about exploring the environment. Traditional exploration strategies\ntypically focus on efficiency and ignore safety. However, for practical\napplications, ensuring safety of the agent during exploration is crucial since\nperforming an unsafe action or reaching an unsafe state could result in\nirreversible damage to the agent. The main challenge of safe exploration is\nthat characterizing the unsafe states and actions is difficult for large\ncontinuous state or action spaces and unknown environments. In this paper, we\npropose a novel approach to incorporate estimations of safety to guide\nexploration and policy search in deep reinforcement learning. By using a cost\nfunction to capture trajectory-based safety, our key idea is to formulate the\nstate-action value function of this safety cost as a candidate Lyapunov\nfunction and extend control-theoretic results to approximate its derivative\nusing online Gaussian Process (GP) estimation. We show how to use these\nstatistical models to guide the agent in unknown environments to obtain\nhigh-performance control policies with provable stability certificates.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 18:02:08 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 02:59:27 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Fan", "Jiameng", ""], ["Li", "Wenchao", ""]]}, {"id": "1903.02531", "submitter": "Somil Bansal", "authors": "Somil Bansal, Varun Tolani, Saurabh Gupta, Jitendra Malik, Claire\n  Tomlin", "title": "Combining Optimal Control and Learning for Visual Navigation in Novel\n  Environments", "comments": "Project website: https://vtolani95.github.io/WayPtNav/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based control is a popular paradigm for robot navigation because it can\nleverage a known dynamics model to efficiently plan robust robot trajectories.\nHowever, it is challenging to use model-based methods in settings where the\nenvironment is a priori unknown and can only be observed partially through\non-board sensors on the robot. In this work, we address this short-coming by\ncoupling model-based control with learning-based perception. The learning-based\nperception module produces a series of waypoints that guide the robot to the\ngoal via a collision-free path. These waypoints are used by a model-based\nplanner to generate a smooth and dynamically feasible trajectory that is\nexecuted on the physical system using feedback control. Our experiments in\nsimulated real-world cluttered environments and on an actual ground vehicle\ndemonstrate that the proposed approach can reach goal locations more reliably\nand efficiently in novel environments as compared to purely geometric\nmapping-based or end-to-end learning-based alternatives. Our approach does not\nrely on detailed explicit 3D maps of the environment, works well with low frame\nrates, and generalizes well from simulation to the real world. Videos\ndescribing our approach and experiments are available on the project website.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 18:11:32 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 22:32:51 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Bansal", "Somil", ""], ["Tolani", "Varun", ""], ["Gupta", "Saurabh", ""], ["Malik", "Jitendra", ""], ["Tomlin", "Claire", ""]]}, {"id": "1903.02536", "submitter": "H. Sebastian Seung", "authors": "H. Sebastian Seung", "title": "Convergence of gradient descent-ascent analyzed as a Newtonian dynamical\n  system with dissipation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dynamical system is defined in terms of the gradient of a payoff function.\nDynamical variables are of two types, ascent and descent. The ascent variables\nmove in the direction of the gradient, while the descent variables move in the\nopposite direction. Dynamical systems of this form or very similar forms have\nbeen studied in diverse fields such as game theory, optimization, neural\nnetworks, and population biology. Gradient descent-ascent is approximated as a\nNewtonian dynamical system that conserves total energy, defined as the sum of\nthe kinetic energy and a potential energy that is proportional to the payoff\nfunction. The error of the approximation is a residual force that violates\nenergy conservation. If the residual force is purely dissipative, then the\nenergy serves as a Lyapunov function, and convergence of bounded trajectories\nto steady states is guaranteed. A previous convergence theorem due to Kose and\nUzawa required the payoff function to be convex in the descent variables, and\nconcave in the ascent variables. Here the assumption is relaxed, so that the\npayoff function need only be globally `less convex' or `more concave' in the\nascent variables than in the descent variables. Such relative convexity\nconditions allow the existence of multiple steady states, unlike the\nconvex-concave assumption. When combined with sufficient conditions that imply\nthe existence of a minimax equilibrium, boundedness of trajectories is also\nassured.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 03:09:20 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Seung", "H. Sebastian", ""]]}, {"id": "1903.02540", "submitter": "Gerasimos Spanakis", "authors": "Matteo Maggiolo and Gerasimos Spanakis", "title": "Autoregressive Convolutional Recurrent Neural Network for Univariate and\n  Multivariate Time Series Prediction", "comments": "ESAN2019 accepted paper, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time Series forecasting (univariate and multivariate) is a problem of high\ncomplexity due the different patterns that have to be detected in the input,\nranging from high to low frequencies ones. In this paper we propose a new model\nfor timeseries prediction that utilizes convolutional layers for feature\nextraction, a recurrent encoder and a linear autoregressive component. We\nmotivate the model and we test and compare it against a baseline of widely used\nexisting architectures for univariate and multivariate timeseries. The proposed\nmodel appears to outperform the baselines in almost every case of the\nmultivariate timeseries datasets, in some cases even with 50% improvement which\nshows the strengths of such a hybrid architecture in complex timeseries.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 18:37:05 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Maggiolo", "Matteo", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1903.02541", "submitter": "Ryan Murphy", "authors": "Ryan L. Murphy and Balasubramaniam Srinivasan and Vinayak Rao and\n  Bruno Ribeiro", "title": "Relational Pooling for Graph Representations", "comments": "ICML 2019 Camera-Ready. Added to molecular experiments and balanced\n  the classes of the validation folds for the synthetic-graph experiments.\n  Clarified some discussions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work generalizes graph neural networks (GNNs) beyond those based on the\nWeisfeiler-Lehman (WL) algorithm, graph Laplacians, and diffusions. Our\napproach, denoted Relational Pooling (RP), draws from the theory of finite\npartial exchangeability to provide a framework with maximal representation\npower for graphs. RP can work with existing graph representation models and,\nsomewhat counterintuitively, can make them even more powerful than the original\nWL isomorphism test. Additionally, RP allows architectures like Recurrent\nNeural Networks and Convolutional Neural Networks to be used in a theoretically\nsound approach for graph classification. We demonstrate improved performance of\nRP-based graph representations over state-of-the-art methods on a number of\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 18:37:26 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 18:03:34 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Murphy", "Ryan L.", ""], ["Srinivasan", "Balasubramaniam", ""], ["Rao", "Vinayak", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "1903.02547", "submitter": "Xiujun Li", "authors": "Liyiming Ke and Xiujun Li and Yonatan Bisk and Ari Holtzman and Zhe\n  Gan and Jingjing Liu and Jianfeng Gao and Yejin Choi and Siddhartha Srinivasa", "title": "Tactical Rewind: Self-Correction via Backtracking in Vision-and-Language\n  Navigation", "comments": "CVPR 2019 Oral, video demo: https://youtu.be/AD9TNohXoPA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Frontier Aware Search with backTracking (FAST) Navigator, a\ngeneral framework for action decoding, that achieves state-of-the-art results\non the Room-to-Room (R2R) Vision-and-Language navigation challenge of Anderson\net. al. (2018). Given a natural language instruction and photo-realistic image\nviews of a previously unseen environment, the agent was tasked with navigating\nfrom source to target location as quickly as possible. While all current\napproaches make local action decisions or score entire trajectories using beam\nsearch, ours balances local and global signals when exploring an unobserved\nenvironment. Importantly, this lets us act greedily but use global signals to\nbacktrack when necessary. Applying FAST framework to existing state-of-the-art\nmodels achieved a 17% relative gain, an absolute 6% gain on Success rate\nweighted by Path Length (SPL).\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 18:54:55 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 17:48:26 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Ke", "Liyiming", ""], ["Li", "Xiujun", ""], ["Bisk", "Yonatan", ""], ["Holtzman", "Ari", ""], ["Gan", "Zhe", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""], ["Choi", "Yejin", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "1903.02585", "submitter": "Guanxiong Liu", "authors": "Guanxiong Liu, Issa Khalil, Abdallah Khreishah", "title": "GanDef: A GAN based Adversarial Training Defense for Neural Network\n  Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models, especially neural network (NN) classifiers, are\nwidely used in many applications including natural language processing,\ncomputer vision and cybersecurity. They provide high accuracy under the\nassumption of attack-free scenarios. However, this assumption has been defied\nby the introduction of adversarial examples -- carefully perturbed samples of\ninput that are usually misclassified. Many researchers have tried to develop a\ndefense against adversarial examples; however, we are still far from achieving\nthat goal. In this paper, we design a Generative Adversarial Net (GAN) based\nadversarial training defense, dubbed GanDef, which utilizes a competition game\nto regulate the feature selection during the training. We analytically show\nthat GanDef can train a classifier so it can defend against adversarial\nexamples. Through extensive evaluation on different white-box adversarial\nexamples, the classifier trained by GanDef shows the same level of test\naccuracy as those trained by state-of-the-art adversarial training defenses.\nMore importantly, GanDef-Comb, a variant of GanDef, could utilize the\ndiscriminator to achieve a dynamic trade-off between correctly classifying\noriginal and adversarial examples. As a result, it achieves the highest overall\ntest accuracy when the ratio of adversarial examples exceeds 41.7%.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 19:09:47 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Liu", "Guanxiong", ""], ["Khalil", "Issa", ""], ["Khreishah", "Abdallah", ""]]}, {"id": "1903.02606", "submitter": "Mingwei Wei", "authors": "Mingwei Wei, James Stokes, David J Schwab", "title": "Mean-field Analysis of Batch Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BatchNorm) is an extremely useful component of modern\nneural network architectures, enabling optimization using higher learning rates\nand achieving faster convergence. In this paper, we use mean-field theory to\nanalytically quantify the impact of BatchNorm on the geometry of the loss\nlandscape for multi-layer networks consisting of fully-connected and\nconvolutional layers. We show that it has a flattening effect on the loss\nlandscape, as quantified by the maximum eigenvalue of the Fisher Information\nMatrix. These findings are then used to justify the use of larger learning\nrates for networks that use BatchNorm, and we provide quantitative\ncharacterization of the maximal allowable learning rate to ensure convergence.\nExperiments support our theoretically predicted maximum learning rate, and\nfurthermore suggest that networks with smaller values of the BatchNorm\nparameter achieve lower loss after the same number of epochs of training.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 20:50:29 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Wei", "Mingwei", ""], ["Stokes", "James", ""], ["Schwab", "David J", ""]]}, {"id": "1903.02610", "submitter": "Gabriel Loaiza-Ganem", "authors": "Gabriel Loaiza-Ganem, Sean M. Perkins, Karen E. Schroeder, Mark M.\n  Churchland, John P. Cunningham", "title": "Deep Random Splines for Point Process Intensity Estimation of Neural\n  Population Data", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are the leading class of distributions on random\nfunctions, but they suffer from well known issues including difficulty scaling\nand inflexibility with respect to certain shape constraints (such as\nnonnegativity). Here we propose Deep Random Splines, a flexible class of random\nfunctions obtained by transforming Gaussian noise through a deep neural network\nwhose output are the parameters of a spline. Unlike Gaussian processes, Deep\nRandom Splines allow us to readily enforce shape constraints while inheriting\nthe richness and tractability of deep generative models. We also present an\nobservational model for point process data which uses Deep Random Splines to\nmodel the intensity function of each point process and apply it to neural\npopulation data to obtain a low-dimensional representation of spiking activity.\nInference is performed via a variational autoencoder that uses a novel\nrecurrent encoder architecture that can handle multiple point processes as\ninput. We use a newly collected dataset where a primate completes a pedaling\ntask, and observe better dimensionality reduction with our model than with\ncompeting alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 21:01:03 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 00:28:06 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 19:39:54 GMT"}, {"version": "v4", "created": "Thu, 10 Oct 2019 01:20:17 GMT"}, {"version": "v5", "created": "Thu, 21 Nov 2019 03:46:59 GMT"}, {"version": "v6", "created": "Sun, 29 Dec 2019 23:52:01 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Loaiza-Ganem", "Gabriel", ""], ["Perkins", "Sean M.", ""], ["Schroeder", "Karen E.", ""], ["Churchland", "Mark M.", ""], ["Cunningham", "John P.", ""]]}, {"id": "1903.02640", "submitter": "Da Xu", "authors": "Da Xu, Chuanwei Ruan, Kamiya Motwani, Evren Korpeoglu, Sushant Kumar,\n  Kannan Achan", "title": "Generative Graph Convolutional Network for Growing Graphs", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682360", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling generative process of growing graphs has wide applications in social\nnetworks and recommendation systems, where cold start problem leads to new\nnodes isolated from existing graph. Despite the emerging literature in learning\ngraph representation and graph generation, most of them can not handle isolated\nnew nodes without nontrivial modifications. The challenge arises due to the\nfact that learning to generate representations for nodes in observed graph\nrelies heavily on topological features, whereas for new nodes only node\nattributes are available. Here we propose a unified generative graph\nconvolutional network that learns node representations for all nodes adaptively\nin a generative model framework, by sampling graph generation sequences\nconstructed from observed graph data. We optimize over a variational lower\nbound that consists of a graph reconstruction term and an adaptive\nKullback-Leibler divergence regularization term. We demonstrate the superior\nperformance of our approach on several benchmark citation network datasets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 22:36:57 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Xu", "Da", ""], ["Ruan", "Chuanwei", ""], ["Motwani", "Kamiya", ""], ["Korpeoglu", "Evren", ""], ["Kumar", "Sushant", ""], ["Achan", "Kannan", ""]]}, {"id": "1903.02642", "submitter": "Adri\\'an Javaloy Born\\'as", "authors": "Adri\\'an Javaloy Born\\'as and Gin\\'es Garc\\'ia Mateos", "title": "A Character-Level Approach to the Text Normalization Problem Based on a\n  New Causal Encoder", "comments": "19 pages, 14 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text normalization is a ubiquitous process that appears as the first step of\nmany Natural Language Processing problems. However, previous Deep Learning\napproaches have suffered from so-called silly errors, which are undetectable on\nunsupervised frameworks, making those models unsuitable for deployment. In this\nwork, we make use of an attention-based encoder-decoder architecture that\novercomes these undetectable errors by using a fine-grained character-level\napproach rather than a word-level one. Furthermore, our new general-purpose\nencoder based on causal convolutions, called Causal Feature Extractor (CFE), is\nintroduced and compared to other common encoders. The experimental results show\nthe feasibility of this encoder, which leverages the attention mechanisms the\nmost and obtains better results in terms of accuracy, number of parameters and\nconvergence time. While our method results in a slightly worse initial accuracy\n(92.74%), errors can be automatically detected and, thus, more readily solved,\nobtaining a more robust model for deployment. Furthermore, there is still\nplenty of room for future improvements that will push even further these\nadvantages.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 22:48:21 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Born\u00e1s", "Adri\u00e1n Javaloy", ""], ["Mateos", "Gin\u00e9s Garc\u00eda", ""]]}, {"id": "1903.02647", "submitter": "Nicholas Ketz", "authors": "Nicholas Ketz, Soheil Kolouri, Praveen Pilly", "title": "Continual Learning Using World Models for Pseudo-Rehearsal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utility of learning a dynamics/world model of the environment in\nreinforcement learning has been shown in a many ways. When using neural\nnetworks, however, these models suffer catastrophic forgetting when learned in\na lifelong or continual fashion. Current solutions to the continual learning\nproblem require experience to be segmented and labeled as discrete tasks,\nhowever, in continuous experience it is generally unclear what a sufficient\nsegmentation of tasks would be. Here we propose a method to continually learn\nthese internal world models through the interleaving of internally generated\nepisodes of past experiences (i.e., pseudo-rehearsal). We show this method can\nsequentially learn unsupervised temporal prediction, without task labels, in a\ndisparate set of Atari games. Empirically, this interleaving of the internally\ngenerated rollouts with the external environment's observations leads to a\nconsistent reduction in temporal prediction loss compared to non-interleaved\nlearning and is preserved over repeated random exposures to various tasks.\nSimilarly, using a network distillation approach, we show that modern policy\ngradient based reinforcement learning algorithms can use this internal model to\ncontinually learn to optimize reward based on the world model's representation\nof the environment.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 22:58:36 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 17:35:52 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Ketz", "Nicholas", ""], ["Kolouri", "Soheil", ""], ["Pilly", "Praveen", ""]]}, {"id": "1903.02650", "submitter": "Jessica Hoffmann", "authors": "Jessica Hoffmann, Constantine Caramanis", "title": "Learning Graphs from Noisy Epidemic Cascades", "comments": "32 pages, 3 figures. Accepted at SIGMETRICS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the weighted edges of a graph by\nobserving the noisy times of infection for multiple epidemic cascades on this\ngraph. Past work has considered this problem when the cascade information,\ni.e., infection times, are known exactly. Though the noisy setting is well\nmotivated by many epidemic processes (e.g., most human epidemics), to the best\nof our knowledge, very little is known about when it is solvable. Previous work\non the no-noise setting critically uses the ordering information. If noise can\nreverse this -- a node's reported (noisy) infection time comes after the\nreported infection time of some node it infected -- then we are unable to see\nhow previous results can be extended.\n  We therefore tackle two versions of the noisy setting: the limited-noise\nsetting, where we know noisy times of infections, and the extreme-noise\nsetting, in which we only know whether or not a node was infected. We provide a\npolynomial time algorithm for recovering the structure of bidirectional trees\nin the extreme-noise setting, and show our algorithm almost matches lower\nbounds established in the no-noise setting, and hence is optimal up to\nlog-factors. We extend our results for general degree-bounded graphs, where\nagain we show that our (poly-time) algorithm can recover the structure of the\ngraph with optimal sample complexity. We also provide the first efficient\nalgorithm to learn the weights of the bidirectional tree in the limited-noise\nsetting. Finally, we give a polynomial time algorithm for learning the weights\nof general bounded-degree graphs in the limited-noise setting. This algorithm\nextends to general graphs (at the price of exponential running time), proving\nthe problem is solvable in the general case. All our algorithms work for any\nnoise distribution, without any restriction on the variance.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 23:07:12 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 16:59:13 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Hoffmann", "Jessica", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1903.02656", "submitter": "Sharon Qian", "authors": "Sharon Qian, Yaron Singer", "title": "Fast Parallel Algorithms for Statistical Subset Selection Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new framework for designing fast parallel\nalgorithms for fundamental statistical subset selection tasks that include\nfeature selection and experimental design. Such tasks are known to be weakly\nsubmodular and are amenable to optimization via the standard greedy algorithm.\nDespite its desirable approximation guarantees, the greedy algorithm is\ninherently sequential and in the worst case, its parallel runtime is linear in\nthe size of the data. Recently, there has been a surge of interest in a\nparallel optimization technique called adaptive sampling which produces\nsolutions with desirable approximation guarantees for submodular maximization\nin exponentially faster parallel runtime. Unfortunately, we show that for\ngeneral weakly submodular functions such accelerations are impossible. The\nmajor contribution in this paper is a novel relaxation of submodularity which\nwe call differential submodularity. We first prove that differential\nsubmodularity characterizes objectives like feature selection and experimental\ndesign. We then design an adaptive sampling algorithm for differentially\nsubmodular functions whose parallel runtime is logarithmic in the size of the\ndata and achieves strong approximation guarantees. Through experiments, we show\nthe algorithm's performance is competitive with state-of-the-art methods and\nobtains dramatic speedups for feature selection and experimental design\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 23:26:38 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 22:15:33 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 17:37:57 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Qian", "Sharon", ""], ["Singer", "Yaron", ""]]}, {"id": "1903.02675", "submitter": "Yair Carmon", "authors": "Yair Carmon, John C. Duchi, Aaron Sidford and Kevin Tian", "title": "A Rank-1 Sketch for Matrix Multiplicative Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a simple randomized sketch of the matrix multiplicative weight\n(MMW) update enjoys (in expectation) the same regret bounds as MMW, up to a\nsmall constant factor. Unlike MMW, where every step requires full matrix\nexponentiation, our steps require only a single product of the form $e^A b$,\nwhich the Lanczos method approximates efficiently. Our key technique is to view\nthe sketch as a $\\textit{randomized mirror projection}$, and perform mirror\ndescent analysis on the $\\textit{expected projection}$. Our sketch solves the\nonline eigenvector problem, improving the best known complexity bounds by\n$\\Omega(\\log^5 n)$. We also apply this sketch to semidefinite programming in\nsaddle-point form, yielding a simple primal-dual scheme with guarantees\nmatching the best in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 01:05:27 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 03:16:37 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Carmon", "Yair", ""], ["Duchi", "John C.", ""], ["Sidford", "Aaron", ""], ["Tian", "Kevin", ""]]}, {"id": "1903.02709", "submitter": "Christopher Beckham", "authors": "Christopher Beckham, Sina Honari, Vikas Verma, Alex Lamb, Farnoosh\n  Ghadiri, R Devon Hjelm, Yoshua Bengio, Christopher Pal", "title": "On Adversarial Mixup Resynthesis", "comments": "'Camera-ready draft'", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore new approaches to combining information encoded\nwithin the learned representations of auto-encoders. We explore models that are\ncapable of combining the attributes of multiple inputs such that a\nresynthesised output is trained to fool an adversarial discriminator for real\nversus synthesised data. Furthermore, we explore the use of such an\narchitecture in the context of semi-supervised learning, where we learn a\nmixing function whose objective is to produce interpolations of hidden states,\nor masked combinations of latent representations that are consistent with a\nconditioned class label. We show quantitative and qualitative evidence that\nsuch a formulation is an interesting avenue of research.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 03:28:25 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 14:05:21 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 13:35:09 GMT"}, {"version": "v4", "created": "Wed, 23 Oct 2019 21:13:36 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Beckham", "Christopher", ""], ["Honari", "Sina", ""], ["Verma", "Vikas", ""], ["Lamb", "Alex", ""], ["Ghadiri", "Farnoosh", ""], ["Hjelm", "R Devon", ""], ["Bengio", "Yoshua", ""], ["Pal", "Christopher", ""]]}, {"id": "1903.02741", "submitter": "Chi Zhang", "authors": "Chi Zhang, Feng Gao, Baoxiong Jia, Yixin Zhu, Song-Chun Zhu", "title": "RAVEN: A Dataset for Relational and Analogical Visual rEasoNing", "comments": "CVPR 2019 paper. Supplementary:\n  http://wellyzhang.github.io/attach/cvpr19zhang_supp.pdf Project:\n  http://wellyzhang.github.io/project/raven.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dramatic progress has been witnessed in basic vision tasks involving\nlow-level perception, such as object recognition, detection, and tracking.\nUnfortunately, there is still an enormous performance gap between artificial\nvision systems and human intelligence in terms of higher-level vision problems,\nespecially ones involving reasoning. Earlier attempts in equipping machines\nwith high-level reasoning have hovered around Visual Question Answering (VQA),\none typical task associating vision and language understanding. In this work,\nwe propose a new dataset, built in the context of Raven's Progressive Matrices\n(RPM) and aimed at lifting machine intelligence by associating vision with\nstructural, relational, and analogical reasoning in a hierarchical\nrepresentation. Unlike previous works in measuring abstract reasoning using\nRPM, we establish a semantic link between vision and reasoning by providing\nstructure representation. This addition enables a new type of abstract\nreasoning by jointly operating on the structure representation. Machine\nreasoning ability using modern computer vision is evaluated in this newly\nproposed dataset. Additionally, we also provide human performance as a\nreference. Finally, we show consistent improvement across all models by\nincorporating a simple neural module that combines visual understanding and\nstructure reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 06:28:44 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Zhang", "Chi", ""], ["Gao", "Feng", ""], ["Jia", "Baoxiong", ""], ["Zhu", "Yixin", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1903.02750", "submitter": "Soma Yokoi", "authors": "Soma Yokoi and Takuma Otsuka and Issei Sato", "title": "On Transformations in Stochastic Gradient MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient Langevin dynamics (SGLD) is a computationally efficient\nsampler for Bayesian posterior inference given a large scale dataset. Although\nSGLD is designed for unbounded random variables, many practical models\nincorporate variables with boundaries such as non-negative ones or those in a\nfinite interval. To bridge this gap, we consider mapping unbounded samples into\nthe target interval. This paper reveals that several mapping approaches\ncommonly used in the literature produces erroneous samples from theoretical and\nempirical perspectives. We show that the change of random variable using an\ninvertible Lipschitz mapping function overcomes the pitfall as well as attains\nthe weak convergence. Experiments demonstrate its efficacy for widely-used\nmodels with bounded latent variables including Bayesian non-negative matrix\nfactorization and binary neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 06:57:54 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 05:46:55 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Yokoi", "Soma", ""], ["Otsuka", "Takuma", ""], ["Sato", "Issei", ""]]}, {"id": "1903.02785", "submitter": "Menglei Hu", "authors": "Menglei Hu and Songcan Chen", "title": "Doubly Aligned Incomplete Multi-view Clustering", "comments": "8 pages, IJCAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, multi-view clustering has attracted more and more attention. To\ndate, almost all the previous studies assume that views are complete. However,\nin reality, it is often the case that each view may contain some missing\ninstances. Such incompleteness makes it impossible to directly use traditional\nmulti-view clustering methods. In this paper, we propose a Doubly Aligned\nIncomplete Multi-view Clustering algorithm (DAIMC) based on weighted\nsemi-nonnegative matrix factorization (semi-NMF). Specifically, on the one\nhand, DAIMC utilizes the given instance alignment information to learn a common\nlatent feature matrix for all the views. On the other hand, DAIMC establishes a\nconsensus basis matrix with the help of $L_{2,1}$-Norm regularized regression\nfor reducing the influence of missing instances. Consequently, compared with\nexisting methods, besides inheriting the strength of semi-NMF with ability to\nhandle negative entries, DAIMC has two unique advantages: 1) solving the\nincomplete view problem by introducing a respective weight matrix for each\nview, making it able to easily adapt to the case with more than two views; 2)\nreducing the influence of view incompleteness on clustering by enforcing the\nbasis matrices of individual views being aligned with the help of regression.\nExperiments on four real-world datasets demonstrate its advantages.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 09:25:25 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Hu", "Menglei", ""], ["Chen", "Songcan", ""]]}, {"id": "1903.02787", "submitter": "Feng Li", "authors": "Yanfei Kang, Rob J Hyndman, Feng Li", "title": "GRATIS: GeneRAting TIme Series with diverse and controllable\n  characteristics", "comments": null, "journal-ref": "Statistical Analysis and Data Mining 2020", "doi": "10.1002/sam.11461", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of time series data in recent years has brought a flourish of\nnew time series analysis methods, for forecasting, clustering, classification\nand other tasks. The evaluation of these new methods requires either collecting\nor simulating a diverse set of time series benchmarking data to enable reliable\ncomparisons against alternative approaches. We propose GeneRAting TIme Series\nwith diverse and controllable characteristics, named GRATIS, with the use of\nmixture autoregressive (MAR) models. We simulate sets of time series using MAR\nmodels and investigate the diversity and coverage of the generated time series\nin a time series feature space. By tuning the parameters of the MAR models,\nGRATIS is also able to efficiently generate new time series with controllable\nfeatures. In general, as a costless surrogate to the traditional data\ncollection approach, GRATIS can be used as an evaluation tool for tasks such as\ntime series forecasting and classification. We illustrate the usefulness of our\ntime series generation process through a time series forecasting application.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 09:29:31 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 13:07:19 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Kang", "Yanfei", ""], ["Hyndman", "Rob J", ""], ["Li", "Feng", ""]]}, {"id": "1903.02788", "submitter": "Thomas Unterthiner", "authors": "Kristina Preuer, G\\\"unter Klambauer, Friedrich Rippmann, Sepp\n  Hochreiter, Thomas Unterthiner", "title": "Interpretable Deep Learning in Drug Discovery", "comments": "Code available at\n  https://github.com/bioinf-jku/interpretable_ml_drug_discovery", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Without any means of interpretation, neural networks that predict molecular\nproperties and bioactivities are merely black boxes. We will unravel these\nblack boxes and will demonstrate approaches to understand the learned\nrepresentations which are hidden inside these models. We show how single\nneurons can be interpreted as classifiers which determine the presence or\nabsence of pharmacophore- or toxicophore-like structures, thereby generating\nnew insights and relevant knowledge for chemistry, pharmacology and\nbiochemistry. We further discuss how these novel pharmacophores/toxicophores\ncan be determined from the network by identifying the most relevant components\nof a compound for the prediction of the network. Additionally, we propose a\nmethod which can be used to extract new pharmacophores from a model and will\nshow that these extracted structures are consistent with literature findings.\nWe envision that having access to such interpretable knowledge is a crucial aid\nin the development and design of new pharmaceutically active molecules, and\nhelps to investigate and understand failures and successes of current methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 09:39:08 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 15:34:48 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Preuer", "Kristina", ""], ["Klambauer", "G\u00fcnter", ""], ["Rippmann", "Friedrich", ""], ["Hochreiter", "Sepp", ""], ["Unterthiner", "Thomas", ""]]}, {"id": "1903.02791", "submitter": "Niklas Christoffer Petersen", "authors": "Niklas Christoffer Petersen and Filipe Rodrigues and Francisco Camara\n  Pereira", "title": "Multi-output Bus Travel Time Prediction with Convolutional LSTM Neural\n  Network", "comments": null, "journal-ref": "Expert Systems with Applications, Volume 120, 15 April 2019, Pages\n  426-435", "doi": "10.1016/j.eswa.2018.11.028", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and reliable travel time predictions in public transport networks\nare essential for delivering an attractive service that is able to compete with\nother modes of transport in urban areas. The traditional application of this\ninformation, where arrival and departure predictions are displayed on digital\nboards, is highly visible in the city landscape of most modern metropolises.\nMore recently, the same information has become critical as input for\nsmart-phone trip planners in order to alert passengers about unreachable\nconnections, alternative route choices and prolonged travel times. More\nsophisticated Intelligent Transport Systems (ITS) include the predictions of\nconnection assurance, i.e. to hold back services in case a connecting service\nis delayed. In order to operate such systems, and to ensure the confidence of\npassengers in the systems, the information provided must be accurate and\nreliable. Traditional methods have trouble with this as congestion, and thus\ntravel time variability, increases in cities, consequently making travel time\npredictions in urban areas a non-trivial task. This paper presents a system for\nbus travel time prediction that leverages the non-static spatio-temporal\ncorrelations present in urban bus networks, allowing the discovery of complex\npatterns not captured by traditional methods. The underlying model is a\nmulti-output, multi-time-step, deep neural network that uses a combination of\nconvolutional and long short-term memory (LSTM) layers. The method is\nempirically evaluated and compared to other popular approaches for link travel\ntime prediction and currently available services, including the currently\ndeployed model in Copenhagen, Denmark. We find that the proposed model\nsignificantly outperforms all the other methods we compare with, and is able to\ndetect small irregular peaks in bus travel times very quickly.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 09:47:11 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Petersen", "Niklas Christoffer", ""], ["Rodrigues", "Filipe", ""], ["Pereira", "Francisco Camara", ""]]}, {"id": "1903.02809", "submitter": "Linu Pinto", "authors": "Linu Pinto and Dr. Sasi Gopalan", "title": "Limiting Network Size within Finite Bounds for Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Largest theoretical contribution to Neural Networks comes from VC Dimension\nwhich characterizes the sample complexity of classification model in a\nprobabilistic view and are widely used to study the generalization error. So\nfar in the literature the VC Dimension has only been used to approximate the\ngeneralization error bounds on different Neural Network architectures. VC\nDimension has not yet been implicitly or explicitly stated to fix the network\nsize which is important as the wrong configuration could lead to high\ncomputation effort in training and leads to over fitting. So there is a need to\nbound these units so that task can be computed with only sufficient number of\nparameters. For binary classification tasks shallow networks are used as they\nhave universal approximation property and it is enough to size the hidden layer\nwidth for such networks. The paper brings out a theoretical justification on\nrequired attribute size and its corresponding hidden layer dimension for a\ngiven sample set that gives an optimal binary classification results with\nminimum training complexity in a single layered feed forward network framework.\nThe paper also establishes proof on the existence of bounds on the width of the\nhidden layer and its range subjected to certain conditions. Findings in this\npaper are experimentally analyzed on three different dataset using Mathlab 2018\n(b) software.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 10:15:21 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Pinto", "Linu", ""], ["Gopalan", "Dr. Sasi", ""]]}, {"id": "1903.02831", "submitter": "Steffen Eger", "authors": "Steffen Eger, Chao Li, Florian Netzer, Iryna Gurevych", "title": "Predicting Research Trends From Arxiv", "comments": "Refresh workshop paper (December 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform trend detection on two datasets of Arxiv papers, derived from its\nmachine learning (cs.LG) and natural language processing (cs.CL) categories.\nOur approach is bottom-up: we first rank papers by their normalized citation\ncounts, then group top-ranked papers into different categories based on the\ntasks that they pursue and the methods they use. We then analyze these\nresulting topics. We find that the dominating paradigm in cs.CL revolves around\nnatural language generation problems and those in cs.LG revolve around\nreinforcement learning and adversarial principles. By extrapolation, we predict\nthat these topics will remain lead problems/approaches in their fields in the\nshort- and mid-term.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 11:06:10 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Eger", "Steffen", ""], ["Li", "Chao", ""], ["Netzer", "Florian", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1903.02837", "submitter": "Borja Balle", "authors": "Borja Balle, James Bell, Adria Gascon, Kobbi Nissim", "title": "The Privacy Blanket of the Shuffle Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies differential privacy in the context of the recently\nproposed shuffle model. Unlike in the local model, where the server collecting\nprivatized data from users can track back an input to a specific user, in the\nshuffle model users submit their privatized inputs to a server anonymously.\nThis setup yields a trust model which sits in between the classical curator and\nlocal models for differential privacy. The shuffle model is the core idea in\nthe Encode, Shuffle, Analyze (ESA) model introduced by Bittau et al. (SOPS\n2017). Recent work by Cheu et al. (EUROCRYPT 2019) analyzes the differential\nprivacy properties of the shuffle model and shows that in some cases shuffled\nprotocols provide strictly better accuracy than local protocols. Additionally,\nErlingsson et al. (SODA 2019) provide a privacy amplification bound quantifying\nthe level of curator differential privacy achieved by the shuffle model in\nterms of the local differential privacy of the randomizer used by each user. In\nthis context, we make three contributions. First, we provide an optimal single\nmessage protocol for summation of real numbers in the shuffle model. Our\nprotocol is very simple and has better accuracy and communication than the\nprotocols for this same problem proposed by Cheu et al. Optimality of this\nprotocol follows from our second contribution, a new lower bound for the\naccuracy of private protocols for summation of real numbers in the shuffle\nmodel. The third contribution is a new amplification bound for analyzing the\nprivacy of protocols in the shuffle model in terms of the privacy provided by\nthe corresponding local randomizer. Our amplification bound generalizes the\nresults by Erlingsson et al. to a wider range of parameters, and provides a\nwhole family of methods to analyze privacy amplification in the shuffle model.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 11:12:39 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 10:18:32 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Balle", "Borja", ""], ["Bell", "James", ""], ["Gascon", "Adria", ""], ["Nissim", "Kobbi", ""]]}, {"id": "1903.02840", "submitter": "Srinivasan Arunachalam", "authors": "Srinivasan Arunachalam, Alex B. Grilo, Aarthi Sundaram", "title": "Quantum hardness of learning shallow classical circuits", "comments": "43 pages. v2 fixes a mistake in the previous version of the paper and\n  proves stronger results", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the quantum learnability of constant-depth classical\ncircuits under the uniform distribution and in the distribution-independent\nframework of PAC learning. In order to attain our results, we establish\nconnections between quantum learning and quantum-secure cryptosystems. We then\nachieve the following results.\n  1) Hardness of learning AC$^0$ and TC$^0$ under the uniform distribution. Our\nfirst result concerns the concept class TC$^0$ (resp. AC$^0$), the class of\nconstant-depth and polynomial-sized circuits with unbounded fan-in majority\ngates (resp. AND, OR, NOT gates). We show that if there exists no quantum\npolynomial-time (resp. strong sub-exponential time) algorithm to solve the Ring\nLearning with Errors (RLWE) problem, then there exists no polynomial-time\nquantum learning algorithm for TC$^0$ (resp. AC$^0$) under the uniform\ndistribution (even with access to quantum membership queries). The main\ntechnique in this result uses explicit pseudo-random functions that are\nbelieved to be quantum-secure to construct concept classes that are hard to\nlearn quantumly under the uniform distribution.\n  2) Hardness of learning TC$^0_2$ in the PAC setting. Our second result shows\nthat if there exists no quantum polynomial time algorithm for the LWE problem,\nthen there exists no polynomial time quantum PAC learning algorithm for the\nclass TC$^0_2$, i.e., depth-2 TC$^0$ circuits. The main technique in this\nresult is to establish a connection between the quantum security of public-key\ncryptosystems and the learnability of a concept class that consists of\ndecryption functions of the cryptosystem.\n  This gives a strong (conditional) negative answer to one of the \"Ten\nSemi-Grand Challenges for Quantum Computing Theory\" raised by Aaronson [Aar05],\nwho asked if AC$^0$ and TC$^0$ can be PAC-learned in quantum polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 11:21:54 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 12:45:08 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Grilo", "Alex B.", ""], ["Sundaram", "Aarthi", ""]]}, {"id": "1903.02850", "submitter": "Gorka Mu\\~noz-Gil", "authors": "Gorka Mu\\~noz-Gil, Miguel Angel Garcia-March, Carlo Manzo, Jos\\'e D.\n  Mart\\'in-Guerrero and Maciej Lewenstein", "title": "Machine learning method for single trajectory characterization", "comments": "Complementary code can be found in\n  https://github.com/gorkamunoz/RF-Single-Trajectory-Characterization", "journal-ref": null, "doi": "10.1088/1367-2630/ab6065", "report-no": null, "categories": "cond-mat.stat-mech cs.LG physics.bio-ph", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In order to study transport in complex environments, it is extremely\nimportant to determine the physical mechanism underlying diffusion, and\nprecisely characterize its nature and parameters. Often, this task is strongly\nimpacted by data consisting of trajectories with short length and limited\nlocalization precision. In this paper, we propose a machine learning method\nbased on a random forest architecture, which is able to associate even very\nshort trajectories to the underlying diffusion mechanism with a high accuracy.\nIn addition, the method is able to classify the motion according to normal or\nanomalous diffusion, and determine its anomalous exponent with a small error.\nThe method provides highly accurate outputs even when working with very short\ntrajectories and in the presence of experimental noise. We further demonstrate\nthe application of transfer learning to experimental and simulated data not\nincluded in the training/testing dataset. This allows for a full, high-accuracy\ncharacterization of experimental trajectories without the need of any prior\ninformation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 11:34:54 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 11:31:49 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mu\u00f1oz-Gil", "Gorka", ""], ["Garcia-March", "Miguel Angel", ""], ["Manzo", "Carlo", ""], ["Mart\u00edn-Guerrero", "Jos\u00e9 D.", ""], ["Lewenstein", "Maciej", ""]]}, {"id": "1903.02865", "submitter": "Rick Fritschek", "authors": "Rick Fritschek, Rafael F. Schaefer, Gerhard Wunder", "title": "Deep Learning for Channel Coding via Neural Mutual Information\n  Estimation", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end deep learning for communication systems, i.e., systems whose\nencoder and decoder are learned, has attracted significant interest recently,\ndue to its performance which comes close to well-developed classical\nencoder-decoder designs. However, one of the drawbacks of current learning\napproaches is that a differentiable channel model is needed for the training of\nthe underlying neural networks. In real-world scenarios, such a channel model\nis hardly available and often the channel density is not even known at all.\nSome works, therefore, focus on a generative approach, i.e., generating the\nchannel from samples, or rely on reinforcement learning to circumvent this\nproblem. We present a novel approach which utilizes a recently proposed neural\nestimator of mutual information. We use this estimator to optimize the encoder\nfor a maximized mutual information, only relying on channel samples. Moreover,\nwe show that our approach achieves the same performance as state-of-the-art\nend-to-end learning with perfect channel model knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 12:21:27 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Fritschek", "Rick", ""], ["Schaefer", "Rafael F.", ""], ["Wunder", "Gerhard", ""]]}, {"id": "1903.02868", "submitter": "Tonghan Wang", "authors": "Xinliang Song, Tonghan Wang, Chongjie Zhang", "title": "Convergence of Multi-Agent Learning with a Finite Step Size in\n  General-Sum Games", "comments": "AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in a multi-agent system is challenging because agents are\nsimultaneously learning and the environment is not stationary, undermining\nconvergence guarantees. To address this challenge, this paper presents a new\ngradient-based learning algorithm, called Gradient Ascent with Shrinking Policy\nPrediction (GA-SPP), which augments the basic gradient ascent approach with the\nconcept of shrinking policy prediction. The key idea behind this algorithm is\nthat an agent adjusts its strategy in response to the forecasted strategy of\nthe other agent, instead of its current one. GA-SPP is shown formally to have\nNash convergence in larger settings than existing gradient-based multi-agent\nlearning methods. Furthermore, unlike existing gradient-based methods, GA-SPP's\ntheoretical guarantees do not assume the learning rate to be infinitesimal.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 12:23:15 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Song", "Xinliang", ""], ["Wang", "Tonghan", ""], ["Zhang", "Chongjie", ""]]}, {"id": "1903.02875", "submitter": "Chongwen Huang", "authors": "Chongwen Huang, George C. Alexandropoulos, Alessio Zappone, Chau Yuen,\n  and M\\'erouane Debbah", "title": "Deep Learning for UL/DL Channel Calibration in Generic Massive MIMO\n  Systems", "comments": "6-pages, accepted by ICC WC Symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental challenges to realize massive Multiple-Input\nMultiple-Output (MIMO) communications is the accurate acquisition of channel\nstate information for a plurality of users at the base station. This is usually\naccomplished in the UpLink (UL) direction profiting from the time division\nduplexing mode. In practical base station transceivers, there exist inevitably\nnonlinear hardware components, like signal amplifiers and various analog\nfilters, which complicates the calibration task. To deal with this challenge,\nwe design a deep neural network for channel calibration between the UL and\nDownLink (DL) directions. During the initial training phase, the deep neural\nnetwork is trained from both UL and DL channel measurements. We then leverage\nthe trained deep neural network with the instantaneously estimated UL channel\nto calibrate the DL one, which is not observable during the UL transmission\nphase. Our numerical results confirm the merits of the proposed approach, and\nshow that it can achieve performance comparable to conventional approaches,\nlike the Agros method and methods based on least squares, that however assume\nlinear hardware behavior models. More importantly, considering generic\nnonlinear relationships between the UL and DL channels, it is demonstrated that\nour deep neural network approach exhibits robust performance, even when the\nnumber of training sequences is limited.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 12:33:00 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 13:57:27 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Huang", "Chongwen", ""], ["Alexandropoulos", "George C.", ""], ["Zappone", "Alessio", ""], ["Yuen", "Chau", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "1903.02891", "submitter": "Felix Sattler", "authors": "Felix Sattler, Simon Wiedemann, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Robust and Communication-Efficient Federated Learning from Non-IID Data", "comments": "17 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning allows multiple parties to jointly train a deep learning\nmodel on their combined data, without any of the participants having to reveal\ntheir local data to a centralized server. This form of privacy-preserving\ncollaborative learning however comes at the cost of a significant communication\noverhead during training. To address this problem, several compression methods\nhave been proposed in the distributed training literature that can reduce the\namount of required communication by up to three orders of magnitude. These\nexisting methods however are only of limited utility in the Federated Learning\nsetting, as they either only compress the upstream communication from the\nclients to the server (leaving the downstream communication uncompressed) or\nonly perform well under idealized conditions such as iid distribution of the\nclient data, which typically can not be found in Federated Learning. In this\nwork, we propose Sparse Ternary Compression (STC), a new compression framework\nthat is specifically designed to meet the requirements of the Federated\nLearning environment. Our experiments on four different learning tasks\ndemonstrate that STC distinctively outperforms Federated Averaging in common\nFederated Learning scenarios where clients either a) hold non-iid data, b) use\nsmall batch sizes during training, or where c) the number of clients is large\nand the participation rate in every communication round is low. We furthermore\nshow that even if the clients hold iid data and use medium sized batches for\ntraining, STC still behaves pareto-superior to Federated Averaging in the sense\nthat it achieves fixed target accuracies on our benchmarks within both fewer\ntraining iterations and a smaller communication budget.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 13:10:30 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Sattler", "Felix", ""], ["Wiedemann", "Simon", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1903.02893", "submitter": "Vivek Bakaraju", "authors": "Vivek Bakaraju, Kishore Reddy Konda", "title": "Only sparsity based loss function for learning representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the emergence of sparse representations in neural networks. We show\nthat in unsupervised models with regularization, the emergence of sparsity is\nthe result of the input data samples being distributed along highly non-linear\nor discontinuous manifold. We also derive a similar argument for\ndiscriminatively trained networks and present experiments to support this\nhypothesis. Based on our study of sparsity, we introduce a new loss function\nwhich can be used as regularization term for models like autoencoders and MLPs.\nFurther, the same loss function can also be used as a cost function for an\nunsupervised single-layered neural network model for learning efficient\nrepresentations.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 13:11:39 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Bakaraju", "Vivek", ""], ["Konda", "Kishore Reddy", ""]]}, {"id": "1903.02926", "submitter": "Dario Pasquini", "authors": "Dario Pasquini, Marco Mingione and Massimo Bernaschi", "title": "Adversarial Out-domain Examples for Generative Models", "comments": "accepted in proceedings of the Workshop on Machine Learning for\n  Cyber-Crime Investigation and Cybersecurity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are rapidly becoming a common tool for researchers and\ndevelopers. However, as exhaustively shown for the family of discriminative\nmodels, the test-time inference of deep neural networks cannot be fully\ncontrolled and erroneous behaviors can be induced by an attacker. In the\npresent work, we show how a malicious user can force a pre-trained generator to\nreproduce arbitrary data instances by feeding it suitable adversarial inputs.\nMoreover, we show that these adversarial latent vectors can be shaped so as to\nbe statistically indistinguishable from the set of genuine inputs. The proposed\nattack technique is evaluated with respect to various GAN images generators\nusing different architectures, training processes and for both conditional and\nnot-conditional setups.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 14:13:59 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 20:01:02 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Pasquini", "Dario", ""], ["Mingione", "Marco", ""], ["Bernaschi", "Massimo", ""]]}, {"id": "1903.02948", "submitter": "Sandesh Ghimire", "authors": "Sandesh Ghimire, Prashnna Kumar Gyawali, Jwala Dhamala, John L Sapp,\n  Milan Horacek and Linwei Wang", "title": "Improving Generalization of Deep Networks for Inverse Reconstruction of\n  Image Sequences", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.05713", "journal-ref": "International Conference on Information Processing and Medical\n  Imaging 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning networks have shown state-of-the-art performance in many image\nreconstruction problems. However, it is not well understood what properties of\nrepresentation and learning may improve the generalization ability of the\nnetwork. In this paper, we propose that the generalization ability of an\nencoder-decoder network for inverse reconstruction can be improved in two\nmeans. First, drawing from analytical learning theory, we theoretically show\nthat a stochastic latent space will improve the ability of a network to\ngeneralize to test data outside the training distribution. Second, following\nthe information bottleneck principle, we show that a latent representation\nminimally informative of the input data will help a network generalize to\nunseen input variations that are irrelevant to the output reconstruction.\nTherefore, we present a sequence image reconstruction network optimized by a\nvariational approximation of the information bottleneck principle with\nstochastic latent space. In the application setting of reconstructing the\nsequence of cardiac transmembrane potential from bodysurface potential, we\nassess the two types of generalization abilities of the presented network\nagainst its deterministic counterpart. The results demonstrate that the\ngeneralization ability of an inverse reconstruction network can be improved by\nstochasticity as well as the information bottleneck.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 23:26:16 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ghimire", "Sandesh", ""], ["Gyawali", "Prashnna Kumar", ""], ["Dhamala", "Jwala", ""], ["Sapp", "John L", ""], ["Horacek", "Milan", ""], ["Wang", "Linwei", ""]]}, {"id": "1903.02958", "submitter": "Tim R. Davidson", "authors": "Luca Falorsi, Pim de Haan, Tim R. Davidson, Patrick Forr\\'e", "title": "Reparameterizing Distributions on Lie Groups", "comments": "AISTATS (2019), code available at https://github.com/pimdh/relie", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG math.PR math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reparameterizable densities are an important way to learn probability\ndistributions in a deep learning setting. For many distributions it is possible\nto create low-variance gradient estimators by utilizing a `reparameterization\ntrick'. Due to the absence of a general reparameterization trick, much research\nhas recently been devoted to extend the number of reparameterizable\ndistributional families. Unfortunately, this research has primarily focused on\ndistributions defined in Euclidean space, ruling out the usage of one of the\nmost influential class of spaces with non-trivial topologies: Lie groups. In\nthis work we define a general framework to create reparameterizable densities\non arbitrary Lie groups, and provide a detailed practitioners guide to further\nthe ease of usage. We demonstrate how to create complex and multimodal\ndistributions on the well known oriented group of 3D rotations,\n$\\operatorname{SO}(3)$, using normalizing flows. Our experiments on applying\nsuch distributions in a Bayesian setting for pose estimation on objects with\ndiscrete and continuous symmetries, showcase their necessity in achieving\nrealistic uncertainty estimates.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 14:49:30 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Falorsi", "Luca", ""], ["de Haan", "Pim", ""], ["Davidson", "Tim R.", ""], ["Forr\u00e9", "Patrick", ""]]}, {"id": "1903.02966", "submitter": "Sanjay Sahay", "authors": "Sanjay Sharma, C. Rama Krishna and Sanjay K. Sahay", "title": "Detection of Advanced Malware by Machine Learning Techniques", "comments": "Conference Paper, 7 Pages", "journal-ref": "Springer, Advances in Intelligent Systems and Computing, Vol. 742,\n  pp. 332-342, 2018", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's digital world most of the anti-malware tools are signature based\nwhich is ineffective to detect advanced unknown malware viz. metamorphic\nmalware. In this paper, we study the frequency of opcode occurrence to detect\nunknown malware by using machine learning technique. For the purpose, we have\nused kaggle Microsoft malware classification challenge dataset. The top 20\nfeatures obtained from fisher score, information gain, gain ratio, chi-square\nand symmetric uncertainty feature selection methods are compared. We also\nstudied multiple classifier available in WEKA GUI based machine learning tool\nand found that five of them (Random Forest, LMT, NBT, J48 Graft and REPTree)\ndetect malware with almost 100% accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 14:56:13 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Sharma", "Sanjay", ""], ["Krishna", "C. Rama", ""], ["Sahay", "Sanjay K.", ""]]}, {"id": "1903.02974", "submitter": "Richard Droste", "authors": "Richard Droste, Yifan Cai, Harshita Sharma, Pierre Chatelain, Lior\n  Drukker, Aris T. Papageorghiou, J. Alison Noble", "title": "Ultrasound Image Representation Learning by Modeling Sonographer Visual\n  Attention", "comments": "Accepted at the international conference on Information Processing in\n  Medical Imaging (IPMI) 2019", "journal-ref": null, "doi": "10.1007/978-3-030-20351-1_46", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image representations are commonly learned from class labels, which are a\nsimplistic approximation of human image understanding. In this paper we\ndemonstrate that transferable representations of images can be learned without\nmanual annotations by modeling human visual attention. The basis of our\nanalyses is a unique gaze tracking dataset of sonographers performing routine\nclinical fetal anomaly screenings. Models of sonographer visual attention are\nlearned by training a convolutional neural network (CNN) to predict gaze on\nultrasound video frames through visual saliency prediction or gaze-point\nregression. We evaluate the transferability of the learned representations to\nthe task of ultrasound standard plane detection in two contexts. Firstly, we\nperform transfer learning by fine-tuning the CNN with a limited number of\nlabeled standard plane images. We find that fine-tuning the saliency predictor\nis superior to training from random initialization, with an average F1-score\nimprovement of 9.6% overall and 15.3% for the cardiac planes. Secondly, we\ntrain a simple softmax regression on the feature activations of each CNN layer\nin order to evaluate the representations independently of transfer learning\nhyper-parameters. We find that the attention models derive strong\nrepresentations, approaching the precision of a fully-supervised baseline model\nfor all but the last layer.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 15:05:31 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 11:55:31 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Droste", "Richard", ""], ["Cai", "Yifan", ""], ["Sharma", "Harshita", ""], ["Chatelain", "Pierre", ""], ["Drukker", "Lior", ""], ["Papageorghiou", "Aris T.", ""], ["Noble", "J. Alison", ""]]}, {"id": "1903.02984", "submitter": "Da Tang", "authors": "Da Tang, Rajesh Ranganath", "title": "The Variational Predictive Natural Gradient", "comments": "International Conference on Machine Learning (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference transforms posterior inference into parametric\noptimization thereby enabling the use of latent variable models where otherwise\nimpractical. However, variational inference can be finicky when different\nvariational parameters control variables that are strongly correlated under the\nmodel. Traditional natural gradients based on the variational approximation\nfail to correct for correlations when the approximation is not the true\nposterior. To address this, we construct a new natural gradient called the\nVariational Predictive Natural Gradient (VPNG). Unlike traditional natural\ngradients for variational inference, this natural gradient accounts for the\nrelationship between model parameters and variational parameters. We\ndemonstrate the insight with a simple example as well as the empirical value on\na classification task, a deep generative model of images, and probabilistic\nmatrix factorization for recommendation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 15:22:23 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 00:59:41 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 22:56:52 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Tang", "Da", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1903.02993", "submitter": "Jack Parker-Holder", "authors": "Krzysztof Choromanski, Aldo Pacchiano, Jack Parker-Holder, Yunhao\n  Tang, Deepali Jain, Yuxiang Yang, Atil Iscen, Jasmine Hsu and Vikas Sindhwani", "title": "Provably Robust Blackbox Optimization for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in derivative-free optimization (DFO) and \"evolutionary strategies\"\n(ES) has recently surged in the Reinforcement Learning (RL) community, with\ngrowing evidence that they can match state of the art methods for policy\noptimization problems in Robotics. However, it is well known that DFO methods\nsuffer from prohibitively high sampling complexity. They can also be very\nsensitive to noisy rewards and stochastic dynamics. In this paper, we propose a\nnew class of algorithms, called Robust Blackbox Optimization (RBO). Remarkably,\neven if up to $23\\%$ of all the measurements are arbitrarily corrupted, RBO can\nprovably recover gradients to high accuracy. RBO relies on learning gradient\nflows using robust regression methods to enable off-policy updates. On several\nMuJoCo robot control tasks, when all other RL approaches collapse in the\npresence of adversarial noise, RBO is able to train policies effectively. We\nalso show that RBO can be applied to legged locomotion tasks including path\ntracking for quadruped robots.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 15:29:05 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 12:30:07 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Pacchiano", "Aldo", ""], ["Parker-Holder", "Jack", ""], ["Tang", "Yunhao", ""], ["Jain", "Deepali", ""], ["Yang", "Yuxiang", ""], ["Iscen", "Atil", ""], ["Hsu", "Jasmine", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "1903.03008", "submitter": "Tahar Kechadi M", "authors": "Lamine M. Aouad, Nhien-An Le-Khac, Tahar M. Kechadi", "title": "Performance study of distributed Apriori-like frequent itemsets mining", "comments": null, "journal-ref": "Knowledge and Information Systems April 2010, Volume 23, Issue 1", "doi": "10.1007/s10115-009-0205-3", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we focus on distributed Apriori-based frequent itemsets\nmining. We present a new distributed approach which takes into account inherent\ncharacteristics of this algorithm. We study the distribution aspect of this\nalgorithm and give a comparison of the proposed approach with a classical\nApriori-like distributed algorithm, using both analytical and experimental\nstudies. We find that under a wide range of conditions and datasets, the\nperformance of a distributed Apriori-like algorithm is not related to global\nstrategies of pruning since the performance of the local Apriori generation is\nusually characterized by relatively high success rates of candidate sets\nfrequency at low levels which switch to very low rates at some stage, and often\ndrops to zero. This means that the intermediate communication steps and remote\nsupport counts computation and collection in classical distributed schemes are\ncomputationally inefficient locally, and then constrains the global\nperformance. Our performance evaluation is done on a large cluster of\nworkstations using the Condor system and its workflow manager DAGMan. The\nresults show that the presented approach greatly enhances the performance and\nachieves good scalability compared to a typical distributed Apriori founded\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 13:47:35 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Aouad", "Lamine M.", ""], ["Le-Khac", "Nhien-An", ""], ["Kechadi", "Tahar M.", ""]]}, {"id": "1903.03040", "submitter": "Kjetil Olsen Lye", "authors": "Kjetil O. Lye, Siddhartha Mishra, Deep Ray", "title": "Deep learning observables in computational fluid dynamics", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109339", "report-no": null, "categories": "physics.comp-ph cs.LG cs.NA math.NA physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many large scale problems in computational fluid dynamics such as uncertainty\nquantification, Bayesian inversion, data assimilation and PDE constrained\noptimization are considered very challenging computationally as they require a\nlarge number of expensive (forward) numerical solutions of the corresponding\nPDEs. We propose a machine learning algorithm, based on deep artificial neural\nnetworks, that predicts the underlying \\emph{input parameters to observable}\nmap from a few training samples (computed realizations of this map). By a\njudicious combination of theoretical arguments and empirical observations, we\nfind suitable network architectures and training hyperparameters that result in\nrobust and efficient neural network approximations of the parameters to\nobservable map. Numerical experiments are presented to demonstrate low\nprediction errors for the trained network networks, even when the network has\nbeen trained with a few samples, at a computational cost which is several\norders of magnitude lower than the underlying PDE solver.\n  Moreover, we combine the proposed deep learning algorithm with Monte Carlo\n(MC) and Quasi-Monte Carlo (QMC) methods to efficiently compute uncertainty\npropagation for nonlinear PDEs. Under the assumption that the underlying neural\nnetworks generalize well, we prove that the deep learning MC and QMC algorithms\nare guaranteed to be faster than the baseline (quasi-) Monte Carlo methods.\nNumerical experiments demonstrating one to two orders of magnitude speed up\nover baseline QMC and MC algorithms, for the intricate problem of computing\nprobability distributions of the observable, are also presented.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 16:57:52 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 09:31:28 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Lye", "Kjetil O.", ""], ["Mishra", "Siddhartha", ""], ["Ray", "Deep", ""]]}, {"id": "1903.03044", "submitter": "Olivier Debeir Pr", "authors": "Olivier Debeir, Justine Allard, Christine Decaestecker, Jean-Pierre\n  Hermand", "title": "Characterization of Posidonia Oceanica Seagrass Aerenchyma through Whole\n  Slide Imaging: A Pilot Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.TO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing the tissue morphology and anatomy of seagrasses is essential\nto predicting their acoustic behavior. In this pilot study, we use histology\ntechniques and whole slide imaging (WSI) to describe the composition and\ntopology of the aerenchyma of an entire leaf blade in an automatic way\ncombining the advantages of X-ray microtomography and optical microscopy.\nParaffin blocks are prepared in such a way that microtome slices contain an\narbitrarily large number of cross sections distributed along the full length of\na blade. The sample organization in the paraffin block coupled with whole slide\nimage analysis allows high throughput data extraction and an exhaustive\ncharacterization along the whole blade length. The core of the work are image\nprocessing algorithms that can identify cells and air lacunae (or void) from\nfiber strand, epidermis, mesophyll and vascular system. A set of specific\nfeatures is developed to adequately describe the convexity of cells and voids\nwhere standard descriptors fail. The features scrutinize the local curvature of\nthe object borders to allow an accurate discrimination between void and cell\nthrough machine learning. The algorithm allows to reconstruct the cells and\ncell membrane features that are relevant to tissue density, compressibility and\nrigidity. Size distribution of the different cell types and gas spaces, total\nbiomass and total void volume fraction are then extracted from the high\nresolution slices to provide a complete characterization of the tissue along\nthe leave from its base to the apex.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 17:01:32 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 14:51:28 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Debeir", "Olivier", ""], ["Allard", "Justine", ""], ["Decaestecker", "Christine", ""], ["Hermand", "Jean-Pierre", ""]]}, {"id": "1903.03046", "submitter": "Xitong Gao", "authors": "Yiren Zhao, Xitong Gao, Daniel Bates, Robert Mullins, Cheng-Zhong Xu", "title": "Focused Quantization for Sparse CNNs", "comments": "To appear in NeurIPS 2019, this is the same paper adapted for viewing\n  on arXiv. TL;DR: Better size/accuracy trade-off of compressed sparse models\n  with focused quantization. 11 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep convolutional neural networks (CNNs) are powerful tools for a wide range\nof vision tasks, but the enormous amount of memory and compute resources\nrequired by CNNs pose a challenge in deploying them on constrained devices.\nExisting compression techniques, while excelling at reducing model sizes,\nstruggle to be computationally friendly. In this paper, we attend to the\nstatistical properties of sparse CNNs and present focused quantization, a novel\nquantization strategy based on power-of-two values, which exploits the weight\ndistributions after fine-grained pruning. The proposed method dynamically\ndiscovers the most effective numerical representation for weights in layers\nwith varying sparsities, significantly reducing model sizes. Multiplications in\nquantized CNNs are replaced with much cheaper bit-shift operations for\nefficient inference. Coupled with lossless encoding, we built a compression\npipeline that provides CNNs with high compression ratios (CR), low computation\ncost and minimal loss in accuracy. In ResNet-50, we achieved a 18.08x CR with\nonly 0.24% loss in top-5 accuracy, outperforming existing compression methods.\nWe fully compressed a ResNet-18 and found that it is not only higher in CR and\ntop-5 accuracy, but also more hardware efficient as it requires fewer logic\ngates to implement when compared to other state-of-the-art quantization methods\nassuming the same throughput.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 17:06:07 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 07:26:05 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 03:44:03 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Zhao", "Yiren", ""], ["Gao", "Xitong", ""], ["Bates", "Daniel", ""], ["Mullins", "Robert", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "1903.03058", "submitter": "Wen Tang", "authors": "Wen Tang, Ashkan Panahi, Hamid Krim, Liyi Dai", "title": "Analysis Dictionary Learning: An Efficient and Discriminative Solution", "comments": "ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminative Dictionary Learning (DL) methods have been widely advocated\nfor image classification problems. To further sharpen their discriminative\ncapabilities, most state-of-the-art DL methods have additional constraints\nincluded in the learning stages. These various constraints, however, lead to\nadditional computational complexity. We hence propose an efficient\nDiscriminative Convolutional Analysis Dictionary Learning (DCADL) method, as a\nlower cost Discriminative DL framework, to both characterize the image\nstructures and refine the interclass structure representations. The proposed\nDCADL jointly learns a convolutional analysis dictionary and a universal\nclassifier, while greatly reducing the time complexity in both training and\ntesting phases, and achieving a competitive accuracy, thus demonstrating great\nperformance in many experiments with standard databases.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 17:32:32 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Tang", "Wen", ""], ["Panahi", "Ashkan", ""], ["Krim", "Hamid", ""], ["Dai", "Liyi", ""]]}, {"id": "1903.03064", "submitter": "Ekaterina Abramova", "authors": "Ekaterina Abramova, Luke Dickens, Daniel Kuhn and Aldo Faisal", "title": "RLOC: Neurobiologically Inspired Hierarchical Reinforcement Learning\n  Algorithm for Continuous Control of Nonlinear Dynamical Systems", "comments": "33 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear optimal control problems are often solved with numerical methods\nthat require knowledge of system's dynamics which may be difficult to infer,\nand that carry a large computational cost associated with iterative\ncalculations. We present a novel neurobiologically inspired hierarchical\nlearning framework, Reinforcement Learning Optimal Control, which operates on\ntwo levels of abstraction and utilises a reduced number of controllers to solve\nnonlinear systems with unknown dynamics in continuous state and action spaces.\nOur approach is inspired by research at two levels of abstraction: first, at\nthe level of limb coordination human behaviour is explained by linear optimal\nfeedback control theory. Second, in cognitive tasks involving learning symbolic\nlevel action selection, humans learn such problems using model-free and\nmodel-based reinforcement learning algorithms. We propose that combining these\ntwo levels of abstraction leads to a fast global solution of nonlinear control\nproblems using reduced number of controllers. Our framework learns the local\ntask dynamics from naive experience and forms locally optimal infinite horizon\nLinear Quadratic Regulators which produce continuous low-level control. A\ntop-level reinforcement learner uses the controllers as actions and learns how\nto best combine them in state space while maximising a long-term reward. A\nsingle optimal control objective function drives high-level symbolic learning\nby providing training signals on desirability of each selected controller. We\nshow that a small number of locally optimal linear controllers are able to\nsolve global nonlinear control problems with unknown dynamics when combined\nwith a reinforcement learner in this hierarchical framework. Our algorithm\ncompetes in terms of computational cost and solution quality with sophisticated\ncontrol algorithms and we illustrate this with solutions to benchmark problems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 17:37:53 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Abramova", "Ekaterina", ""], ["Dickens", "Luke", ""], ["Kuhn", "Daniel", ""], ["Faisal", "Aldo", ""]]}, {"id": "1903.03082", "submitter": "Fabio Gonzalez", "authors": "Fabio A. Gonz\\'alez and Juan C. Caicedo", "title": "Quantum Latent Semantic Analysis", "comments": "ICTIR2011 International Conference on the Theory of Information\n  Retrieval", "journal-ref": null, "doi": "10.1007/978-3-642-23318-0_7", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this paper is to explore latent topic analysis (LTA), in the\ncontext of quantum information retrieval. LTA is a valuable technique for\ndocument analysis and representation, which has been extensively used in\ninformation retrieval and machine learning. Different LTA techniques have been\nproposed, some based on geometrical modeling (such as latent semantic analysis,\nLSA) and others based on a strong statistical foundation. However, these two\ndifferent approaches are not usually mixed. Quantum information retrieval has\nthe remarkable virtue of combining both geometry and probability in a common\nprincipled framework. We built on this quantum framework to propose a new LTA\nmethod, which has a clear geometrical motivation but also supports a\nwell-founded probabilistic interpretation. An initial exploratory\nexperimentation was performed on three standard data sets. The results show\nthat the proposed method outperforms LSA on two of the three datasets. These\nresults suggests that the quantum-motivated representation is an alternative\nfor geometrical latent topic modeling worthy of further exploration.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:19:55 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Gonz\u00e1lez", "Fabio A.", ""], ["Caicedo", "Juan C.", ""]]}, {"id": "1903.03088", "submitter": "Matthew MacKay", "authors": "Matthew MacKay, Paul Vicol, Jon Lorraine, David Duvenaud, Roger Grosse", "title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using\n  Structured Best-Response Functions", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization can be formulated as a bilevel optimization\nproblem, where the optimal parameters on the training set depend on the\nhyperparameters. We aim to adapt regularization hyperparameters for neural\nnetworks by fitting compact approximations to the best-response function, which\nmaps hyperparameters to optimal weights and biases. We show how to construct\nscalable best-response approximations for neural networks by modeling the\nbest-response as a single network whose hidden units are gated conditionally on\nthe regularizer. We justify this approximation by showing the exact\nbest-response for a shallow linear network with L2-regularized Jacobian can be\nrepresented by a similar gating mechanism. We fit this model using a\ngradient-based hyperparameter optimization algorithm which alternates between\napproximating the best-response around the current hyperparameters and\noptimizing the hyperparameters using the approximate best-response function.\nUnlike other gradient-based approaches, we do not require differentiating the\ntraining loss with respect to the hyperparameters, allowing us to tune discrete\nhyperparameters, data augmentation hyperparameters, and dropout probabilities.\nBecause the hyperparameters are adapted online, our approach discovers\nhyperparameter schedules that can outperform fixed hyperparameter values.\nEmpirically, our approach outperforms competing hyperparameter optimization\nmethods on large-scale deep learning problems. We call our networks, which\nupdate their own hyperparameters online during training, Self-Tuning Networks\n(STNs).\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:26:46 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["MacKay", "Matthew", ""], ["Vicol", "Paul", ""], ["Lorraine", "Jon", ""], ["Duvenaud", "David", ""], ["Grosse", "Roger", ""]]}, {"id": "1903.03096", "submitter": "Pascal Lamblin", "authors": "Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Utku\n  Evci, Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine\n  Manzagol, Hugo Larochelle", "title": "Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few\n  Examples", "comments": "Code available at https://github.com/google-research/meta-dataset", "journal-ref": "International Conference on Learning Representations (2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot classification refers to learning a classifier for new classes given\nonly a few examples. While a plethora of models have emerged to tackle it, we\nfind the procedure and datasets that are used to assess their progress lacking.\nTo address this limitation, we propose Meta-Dataset: a new benchmark for\ntraining and evaluating models that is large-scale, consists of diverse\ndatasets, and presents more realistic tasks. We experiment with popular\nbaselines and meta-learners on Meta-Dataset, along with a competitive method\nthat we propose. We analyze performance as a function of various\ncharacteristics of test tasks and examine the models' ability to leverage\ndiverse training sources for improving their generalization. We also propose a\nnew set of baselines for quantifying the benefit of meta-learning in\nMeta-Dataset. Our extensive experimentation has uncovered important research\nchallenges and we hope to inspire work in these directions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:48:55 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 16:04:30 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 22:22:53 GMT"}, {"version": "v4", "created": "Wed, 8 Apr 2020 15:58:20 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Triantafillou", "Eleni", ""], ["Zhu", "Tyler", ""], ["Dumoulin", "Vincent", ""], ["Lamblin", "Pascal", ""], ["Evci", "Utku", ""], ["Xu", "Kelvin", ""], ["Goroshin", "Ross", ""], ["Gelada", "Carles", ""], ["Swersky", "Kevin", ""], ["Manzagol", "Pierre-Antoine", ""], ["Larochelle", "Hugo", ""]]}, {"id": "1903.03104", "submitter": "James Bagrow", "authors": "Abigail Hotaling and James P. Bagrow", "title": "Accurate inference of crowdsourcing properties when using efficient\n  allocation strategies", "comments": "21 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allocation strategies improve the efficiency of crowdsourcing by decreasing\nthe work needed to complete individual tasks accurately. However, these\nalgorithms introduce bias by preferentially allocating workers onto easy tasks,\nleading to sets of completed tasks that are no longer representative of all\ntasks. This bias challenges inference of problem-wide properties such as\ntypical task difficulty or crowd properties such as worker completion times,\nimportant information that goes beyond the crowd responses themselves. Here we\nstudy inference about problem properties when using an allocation algorithm to\nimprove crowd efficiency. We introduce Decision-Explicit Probability Sampling\n(DEPS), a method to perform inference of problem properties while accounting\nfor the potential bias introduced by an allocation strategy. Experiments on\nreal and synthetic crowdsourcing data show that DEPS outperforms baseline\ninference methods while still leveraging the efficiency gains of the allocation\nmethod. The ability to perform accurate inference of general properties when\nusing non-representative data allows crowdsourcers to extract more knowledge\nout of a given crowdsourced dataset.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:58:34 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Hotaling", "Abigail", ""], ["Bagrow", "James P.", ""]]}, {"id": "1903.03105", "submitter": "Hongyu Shen", "authors": "Hongyu Shen, Daniel George, E. A. Huerta and Zhizhen Zhao", "title": "Denoising Gravitational Waves with Enhanced Deep Recurrent Denoising\n  Auto-Encoders", "comments": "5 pages, 11 figures and 3 tables, accepted to ICASSP 2019", "journal-ref": "ICASSP 2019 - 2019 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP.2019.8683061", "report-no": null, "categories": "astro-ph.CO astro-ph.IM cs.LG eess.SP gr-qc", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denoising of time domain data is a crucial task for many applications such as\ncommunication, translation, virtual assistants etc. For this task, a\ncombination of a recurrent neural net (RNNs) with a Denoising Auto-Encoder\n(DAEs) has shown promising results. However, this combined model is challenged\nwhen operating with low signal-to-noise ratio (SNR) data embedded in\nnon-Gaussian and non-stationary noise. To address this issue, we design a novel\nmodel, referred to as 'Enhanced Deep Recurrent Denoising Auto-Encoder'\n(EDRDAE), that incorporates a signal amplifier layer, and applies curriculum\nlearning by first denoising high SNR signals, before gradually decreasing the\nSNR until the signals become noise dominated. We showcase the performance of\nEDRDAE using time-series data that describes gravitational waves embedded in\nvery noisy backgrounds. In addition, we show that EDRDAE can accurately denoise\nsignals whose topology is significantly more complex than those used for\ntraining, demonstrating that our model generalizes to new classes of\ngravitational waves that are beyond the scope of established denoising\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 19:00:02 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Shen", "Hongyu", ""], ["George", "Daniel", ""], ["Huerta", "E. A.", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1903.03107", "submitter": "Hyeong-Seok Choi", "authors": "Hyeong-Seok Choi, Jang-Hyun Kim, Jaesung Huh, Adrian Kim, Jung-Woo Ha,\n  and Kyogu Lee", "title": "Phase-aware Speech Enhancement with Deep Complex U-Net", "comments": "Significant error was found in data processing step, therefore will\n  be retracted from International Conference on Learning Representations (ICLR)\n  2019. It is not recommended to read current version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep learning-based models for speech enhancement have mainly focused on\nestimating the magnitude of spectrogram while reusing the phase from noisy\nspeech for reconstruction. This is due to the difficulty of estimating the\nphase of clean speech. To improve speech enhancement performance, we tackle the\nphase estimation problem in three ways. First, we propose Deep Complex U-Net,\nan advanced U-Net structured model incorporating well-defined complex-valued\nbuilding blocks to deal with complex-valued spectrograms. Second, we propose a\npolar coordinate-wise complex-valued masking method to reflect the distribution\nof complex ideal ratio masks. Third, we define a novel loss function, weighted\nsource-to-distortion ratio (wSDR) loss, which is designed to directly correlate\nwith a quantitative evaluation measure. Our model was evaluated on a mixture of\nthe Voice Bank corpus and DEMAND database, which has been widely used by many\ndeep learning models for speech enhancement. Ablation experiments were\nconducted on the mixed dataset showing that all three proposed approaches are\nempirically valid. Experimental results show that the proposed method achieves\nstate-of-the-art performance in all metrics, outperforming previous approaches\nby a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 10:41:37 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 08:11:35 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Choi", "Hyeong-Seok", ""], ["Kim", "Jang-Hyun", ""], ["Huh", "Jaesung", ""], ["Kim", "Adrian", ""], ["Ha", "Jung-Woo", ""], ["Lee", "Kyogu", ""]]}, {"id": "1903.03129", "submitter": "Beidi Chen", "authors": "Beidi Chen, Tharun Medini, James Farwell, Sameh Gobriel, Charlie Tai,\n  Anshumali Shrivastava", "title": "SLIDE : In Defense of Smart Algorithms over Hardware Acceleration for\n  Large-Scale Deep Learning Systems", "comments": "Published at MLSys 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) algorithms are the central focus of modern machine\nlearning systems. As data volumes keep growing, it has become customary to\ntrain large neural networks with hundreds of millions of parameters to maintain\nenough capacity to memorize these volumes and obtain state-of-the-art accuracy.\nTo get around the costly computations associated with large models and data,\nthe community is increasingly investing in specialized hardware for model\ntraining. However, specialized hardware is expensive and hard to generalize to\na multitude of tasks. The progress on the algorithmic front has failed to\ndemonstrate a direct advantage over powerful hardware such as NVIDIA-V100 GPUs.\nThis paper provides an exception. We propose SLIDE (Sub-LInear Deep learning\nEngine) that uniquely blends smart randomized algorithms, with multi-core\nparallelism and workload optimization. Using just a CPU, SLIDE drastically\nreduces the computations during both training and inference outperforming an\noptimized implementation of Tensorflow (TF) on the best available GPU. Our\nevaluations on industry-scale recommendation datasets, with large fully\nconnected architectures, show that training with SLIDE on a 44 core CPU is more\nthan 3.5 times (1 hour vs. 3.5 hours) faster than the same network trained\nusing TF on Tesla V100 at any given accuracy level. On the same CPU hardware,\nSLIDE is over 10x faster than TF. We provide codes and scripts for\nreproducibility.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 19:12:07 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 03:17:52 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Beidi", ""], ["Medini", "Tharun", ""], ["Farwell", "James", ""], ["Gobriel", "Sameh", ""], ["Tai", "Charlie", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1903.03132", "submitter": "Mike Borowczak", "authors": "Rasana Manandhar and Shaya Wolf and Mike Borowczak", "title": "Dynamic Anonymized Evaluation for Behavioral Continuous Authentication", "comments": "6 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging technology demands reliable authentication mechanisms, particularly\nin interconnected systems. Current systems rely on a single moment of\nauthentication, however continuous authentication systems assess a users\nidentity utilizing a constant biometric analysis. Spy Hunter, a continuous\nauthentication mechanism uses keystroke dynamics to validate users over blocks\nof data. This easily-incorporated periodic biometric authentication system\nvalidates genuine users and detects intruders quickly. Because it verifies\nusers in the background, Spy Hunter is not constrained to a password box.\nInstead, it is flexible and can be layered with other mechanisms to provide\nhigh-level security. Where other continuous authentication techniques rely on\nscripted typing, Spy Hunter validates over free text in authentic environments.\nThis is accomplished in two phases, one where the user is provided a prompt and\nanother where the user is allowed free access to their computer. Additionally,\nSpy Hunter focuses on the timing of different keystrokes rather than the\nspecific key being pressed. This allows for anonymous data to authenticate\nusers and avoids holding personal data. Utilizing a couple K-fold\ncross-validation techniques, Spy Hunter is assessed based on how often the\nsystem falsely accepts an intruder, how often the system falsely rejects a\ngenuine user, and the time it takes to validate a users identity. Spy Hunter\nmaintains error rates below 6% and identifies users in minimal numbers of\nkeystrokes. Continuous authentication provides higher level security than\none-time verification processes and Spy Hunter expands on the possibilities for\nbehavioral analysis based on keystroke dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 19:19:40 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Manandhar", "Rasana", ""], ["Wolf", "Shaya", ""], ["Borowczak", "Mike", ""]]}, {"id": "1903.03161", "submitter": "Poojan Oza", "authors": "Poojan Oza and Vishal M. Patel", "title": "Deep CNN-based Multi-task Learning for Open-Set Recognition", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep convolutional neural network (CNN) based multi-task\nlearning approach for open-set visual recognition. We combine a classifier\nnetwork and a decoder network with a shared feature extractor network within a\nmulti-task learning framework. We show that this approach results in better\nopen-set recognition accuracy. In our approach, reconstruction errors from the\ndecoder network are utilized for open-set rejection. In addition, we model the\ntail of the reconstruction error distribution from the known classes using the\nstatistical Extreme Value Theory to improve the overall performance.\nExperiments on multiple image classification datasets are performed and it is\nshown that this method can perform significantly better than many competitive\nopen set recognition algorithms available in the literature. The code will be\nmade available at: github.com/otkupjnoz/mlosr.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 20:11:32 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Oza", "Poojan", ""], ["Patel", "Vishal M.", ""]]}, {"id": "1903.03166", "submitter": "Satwik Kottur", "authors": "Satwik Kottur, Jos\\'e M. F. Moura, Devi Parikh, Dhruv Batra, Marcus\n  Rohrbach", "title": "CLEVR-Dialog: A Diagnostic Dataset for Multi-Round Reasoning in Visual\n  Dialog", "comments": "13 pages, 11 figures, 3 tables, accepted as a short paper at NAACL\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Dialog is a multimodal task of answering a sequence of questions\ngrounded in an image, using the conversation history as context. It entails\nchallenges in vision, language, reasoning, and grounding. However, studying\nthese subtasks in isolation on large, real datasets is infeasible as it\nrequires prohibitively-expensive complete annotation of the 'state' of all\nimages and dialogs.\n  We develop CLEVR-Dialog, a large diagnostic dataset for studying multi-round\nreasoning in visual dialog. Specifically, we construct a dialog grammar that is\ngrounded in the scene graphs of the images from the CLEVR dataset. This\ncombination results in a dataset where all aspects of the visual dialog are\nfully annotated. In total, CLEVR-Dialog contains 5 instances of 10-round\ndialogs for about 85k CLEVR images, totaling to 4.25M question-answer pairs.\n  We use CLEVR-Dialog to benchmark performance of standard visual dialog\nmodels; in particular, on visual coreference resolution (as a function of the\ncoreference distance). This is the first analysis of its kind for visual dialog\nmodels that was not possible without this dataset. We hope the findings from\nCLEVR-Dialog will help inform the development of future models for visual\ndialog. Our dataset and code are publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 20:18:39 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 18:04:43 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Kottur", "Satwik", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1903.03176", "submitter": "Kenneth Young", "authors": "Kenny Young and Tian Tian", "title": "MinAtar: An Atari-Inspired Testbed for Thorough and Reproducible\n  Reinforcement Learning Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Arcade Learning Environment (ALE) is a popular platform for evaluating\nreinforcement learning agents. Much of the appeal comes from the fact that\nAtari games demonstrate aspects of competency we expect from an intelligent\nagent and are not biased toward any particular solution approach. The challenge\nof the ALE includes (1) the representation learning problem of extracting\npertinent information from raw pixels, and (2) the behavioural learning problem\nof leveraging complex, delayed associations between actions and rewards. Often,\nthe research questions we are interested in pertain more to the latter, but the\nrepresentation learning problem adds significant computational expense. We\nintroduce MinAtar, short for miniature Atari, a new set of environments that\ncapture the general mechanics of specific Atari games while simplifying the\nrepresentational complexity to focus more on the behavioural challenges.\nMinAtar consists of analogues of five Atari games: Seaquest, Breakout, Asterix,\nFreeway and Space Invaders. Each MinAtar environment provides the agent with a\n10x10xn binary state representation. Each game plays out on a 10x10 grid with n\nchannels corresponding to game-specific objects, such as ball, paddle and brick\nin the game Breakout. To investigate the behavioural challenges posed by\nMinAtar, we evaluated a smaller version of the DQN architecture as well as\nonline actor-critic with eligibility traces. With the representation learning\nproblem simplified, we can perform experiments with significantly less\ncomputational expense. In our experiments, we use the saved compute time to\nperform step-size parameter sweeps and more runs than is typical for the ALE.\nExperiments like this improve reproducibility, and allow us to draw more\nconfident conclusions. We hope that MinAtar can allow researchers to thoroughly\ninvestigate behavioural challenges similar to those inherent in the ALE.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 20:34:36 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 00:36:50 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Young", "Kenny", ""], ["Tian", "Tian", ""]]}, {"id": "1903.03178", "submitter": "Arindam Paul", "authors": "Arindam Paul, Dipendra Jha, Reda Al-Bahrani, Wei-keng Liao, Alok\n  Choudhary, Ankit Agrawal", "title": "Transfer Learning Using Ensemble Neural Networks for Organic Solar Cell\n  Screening", "comments": "8 pages, 11 figures, International Joint Conference on Neural\n  Networks", "journal-ref": "International Joint Conference on Neural Networks, Budapest\n  Hungary, 14-19 July 2019", "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organic Solar Cells are a promising technology for solving the clean energy\ncrisis in the world. However, generating candidate chemical compounds for solar\ncells is a time-consuming process requiring thousands of hours of laboratory\nanalysis. For a solar cell, the most important property is the power conversion\nefficiency which is dependent on the highest occupied molecular orbitals (HOMO)\nvalues of the donor molecules. Recently, machine learning techniques have\nproved to be very useful in building predictive models for HOMO values of donor\nstructures of Organic Photovoltaic Cells (OPVs). Since experimental datasets\nare limited in size, current machine learning models are trained on data\nderived from calculations based on density functional theory (DFT). Molecular\nline notations such as SMILES or InChI are popular input representations for\ndescribing the molecular structure of donor molecules. The two types of line\nrepresentations encode different information, such as SMILES defines the bond\ntypes while InChi defines protonation. In this work, we present an ensemble\ndeep neural network architecture, called SINet, which harnesses both the SMILES\nand InChI molecular representations to predict HOMO values and leverage the\npotential of transfer learning from a sizeable DFT-computed dataset- Harvard\nCEP to build more robust predictive models for relatively smaller HOPV\ndatasets. Harvard CEP dataset contains molecular structures and properties for\n2.3 million candidate donor structures for OPV while HOPV contains DFT-computed\nand experimental values of 350 and 243 molecules respectively. Our results\ndemonstrate significant performance improvement from the use of transfer\nlearning and leveraging both molecular representations.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 20:45:15 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 20:31:27 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 21:16:27 GMT"}, {"version": "v4", "created": "Sun, 28 Jul 2019 22:25:12 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Paul", "Arindam", ""], ["Jha", "Dipendra", ""], ["Al-Bahrani", "Reda", ""], ["Liao", "Wei-keng", ""], ["Choudhary", "Alok", ""], ["Agrawal", "Ankit", ""]]}, {"id": "1903.03182", "submitter": "Josef Urban", "authors": "Karel Chvalovsk\\'y and Jan Jakub\\r{u}v and Martin Suda and Josef Urban", "title": "ENIGMA-NG: Efficient Neural and Gradient-Boosted Inference Guidance for\n  E", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an efficient implementation of clause guidance in\nsaturation-based automated theorem provers extending the ENIGMA approach.\nUnlike in the first ENIGMA implementation where fast linear classifier is\ntrained and used together with manually engineered features, we have started to\nexperiment with more sophisticated state-of-the-art machine learning methods\nsuch as gradient boosted trees and recursive neural networks. In particular the\nlatter approach poses challenges in terms of efficiency of clause evaluation,\nhowever, we show that deep integration of the neural evaluation with the ATP\ndata-structures can largely amortize this cost and lead to competitive\nreal-time results. Both methods are evaluated on a large dataset of theorem\nproving problems and compared with the previous approaches. The resulting\nmethods improve on the manually designed clause guidance, providing the first\npractically convincing application of gradient-boosted and neural clause\nguidance in saturation-style automated theorem provers.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 20:54:12 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Chvalovsk\u00fd", "Karel", ""], ["Jakub\u016fv", "Jan", ""], ["Suda", "Martin", ""], ["Urban", "Josef", ""]]}, {"id": "1903.03202", "submitter": "Xiao Qiao", "authors": "Alexander James, Yaser S. Abu-Mostafa, Xiao Qiao", "title": "Nowcasting Recessions using the SVM Machine Learning Algorithm", "comments": "My company policy about sharing research papers has been changed. As\n  a result, I would like to withdraw the paper, with the full understanding\n  that previous version will remain accessible. Thank you very much", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG econ.GN q-fin.EC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel application of Support Vector Machines (SVM), an\nimportant Machine Learning algorithm, to determine the beginning and end of\nrecessions in real time. Nowcasting, \"forecasting\" a condition about the\npresent time because the full information about it is not available until\nlater, is key for recessions, which are only determined months after the fact.\nWe show that SVM has excellent predictive performance for this task, and we\nprovide implementation details to facilitate its use in similar problems in\neconomics and finance.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 15:04:35 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 14:53:06 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["James", "Alexander", ""], ["Abu-Mostafa", "Yaser S.", ""], ["Qiao", "Xiao", ""]]}, {"id": "1903.03213", "submitter": "Chaozhuo Li", "authors": "Chaozhuo Li, Senzhang Wang, Philip S. Yu, and Zhoujun Li", "title": "Multi-Hot Compact Network Embedding", "comments": null, "journal-ref": "Published in CIKM 2019", "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding, as a promising way of the network representation learning,\nis capable of supporting various subsequent network mining and analysis tasks,\nand has attracted growing research interests recently. Traditional approaches\nassign each node with an independent continuous vector, which will cause huge\nmemory overhead for large networks. In this paper we propose a novel multi-hot\ncompact embedding strategy to effectively reduce memory cost by learning\npartially shared embeddings. The insight is that a node embedding vector is\ncomposed of several basis vectors, which can significantly reduce the number of\ncontinuous vectors while maintain similar data representation ability.\nSpecifically, we propose a MCNE model to learn compact embeddings from\npre-learned node features. A novel component named compressor is integrated\ninto MCNE to tackle the challenge that popular back-propagation optimization\ncannot propagate through discrete samples. We further propose an end-to-end\nmodel MCNE$_{t}$ to learn compact embeddings from the input network directly.\nEmpirically, we evaluate the proposed models over three real network datasets,\nand the results demonstrate that our proposals can save about 90\\% of memory\ncost of network embeddings without significantly performance decline.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 23:04:35 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 15:01:19 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Li", "Chaozhuo", ""], ["Wang", "Senzhang", ""], ["Yu", "Philip S.", ""], ["Li", "Zhoujun", ""]]}, {"id": "1903.03216", "submitter": "Dong-Ki Kim", "authors": "Dong-Ki Kim, Miao Liu, Shayegan Omidshafiei, Sebastian Lopez-Cot,\n  Matthew Riemer, Golnaz Habibi, Gerald Tesauro, Sami Mourad, Murray Campbell,\n  Jonathan P. How", "title": "Learning Hierarchical Teaching Policies for Cooperative Agents", "comments": "Presented at AAMAS 2020; arXiv version added with the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective learning can be greatly enhanced when agents effectively exchange\nknowledge with their peers. In particular, recent work studying agents that\nlearn to teach other teammates has demonstrated that action advising\naccelerates team-wide learning. However, the prior work has simplified the\nlearning of advising policies by using simple function approximations and only\nconsidered advising with primitive (low-level) actions, limiting the\nscalability of learning and teaching to complex domains. This paper introduces\na novel learning-to-teach framework, called hierarchical multiagent teaching\n(HMAT), that improves scalability to complex environments by using the deep\nrepresentation for student policies and by advising with more expressive\nextended action sequences over multiple levels of temporal abstraction. Our\nempirical evaluations demonstrate that HMAT improves team-wide learning\nprogress in large, complex domains where previous approaches fail. HMAT also\nlearns teaching policies that can effectively transfer knowledge to different\nteammates with knowledge of different tasks, even when the teammates have\nheterogeneous action spaces.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 23:12:30 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 20:13:48 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 15:08:14 GMT"}, {"version": "v4", "created": "Fri, 29 Nov 2019 05:26:30 GMT"}, {"version": "v5", "created": "Mon, 2 Mar 2020 16:50:32 GMT"}, {"version": "v6", "created": "Mon, 18 May 2020 15:50:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kim", "Dong-Ki", ""], ["Liu", "Miao", ""], ["Omidshafiei", "Shayegan", ""], ["Lopez-Cot", "Sebastian", ""], ["Riemer", "Matthew", ""], ["Habibi", "Golnaz", ""], ["Tesauro", "Gerald", ""], ["Mourad", "Sami", ""], ["Campbell", "Murray", ""], ["How", "Jonathan P.", ""]]}, {"id": "1903.03227", "submitter": "Bohan Wu", "authors": "Bohan Wu, Iretiayo Akinola and Peter K. Allen", "title": "Pixel-Attentive Policy Gradient for Multi-Fingered Grasping in Cluttered\n  Scenes", "comments": "Accepted at IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in on-policy reinforcement learning (RL) methods enabled\nlearning agents in virtual environments to master complex tasks with\nhigh-dimensional and continuous observation and action spaces. However,\nleveraging this family of algorithms in multi-fingered robotic grasping remains\na challenge due to large sim-to-real fidelity gaps and the high sample\ncomplexity of on-policy RL algorithms. This work aims to bridge these gaps by\nfirst reinforcement-learning a multi-fingered robotic grasping policy in\nsimulation that operates in the pixel space of the input: a single depth image.\nUsing a mapping from pixel space to Cartesian space according to the depth map,\nthis method transfers to the real world with high fidelity and introduces a\nnovel attention mechanism that substantially improves grasp success rate in\ncluttered environments. Finally, the direct-generative nature of this method\nallows learning of multi-fingered grasps that have flexible end-effector\npositions, orientations and rotations, as well as all degrees of freedom of the\nhand.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 00:26:57 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 17:43:56 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 16:52:54 GMT"}, {"version": "v4", "created": "Sat, 21 Sep 2019 18:15:23 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Wu", "Bohan", ""], ["Akinola", "Iretiayo", ""], ["Allen", "Peter K.", ""]]}, {"id": "1903.03232", "submitter": "Umar Asif", "authors": "Umar Asif, Subhrajit Roy, Jianbin Tang and Stefan Harrer", "title": "SeizureNet: Multi-Spectral Deep Feature Learning for Seizure Type\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic classification of epileptic seizure types in electroencephalograms\n(EEGs) data can enable more precise diagnosis and efficient management of the\ndisease. This task is challenging due to factors such as low signal-to-noise\nratios, signal artefacts, high variance in seizure semiology among epileptic\npatients, and limited availability of clinical data. To overcome these\nchallenges, in this paper, we present SeizureNet, a deep learning framework\nwhich learns multi-spectral feature embeddings using an ensemble architecture\nfor cross-patient seizure type classification. We used the recently released\nTUH EEG Seizure Corpus (V1.4.0 and V1.5.2) to evaluate the performance of\nSeizureNet. Experiments show that SeizureNet can reach a weighted F1 score of\nup to 0.94 for seizure-wise cross validation and 0.59 for patient-wise cross\nvalidation for scalp EEG based multi-class seizure type classification. We also\nshow that the high-level feature embeddings learnt by SeizureNet considerably\nimprove the accuracy of smaller networks through knowledge distillation for\napplications with low-memory constraints.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 00:49:31 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 03:17:25 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 07:48:25 GMT"}, {"version": "v4", "created": "Thu, 2 Apr 2020 06:32:59 GMT"}, {"version": "v5", "created": "Sun, 23 Aug 2020 05:08:41 GMT"}, {"version": "v6", "created": "Wed, 30 Sep 2020 03:09:00 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Asif", "Umar", ""], ["Roy", "Subhrajit", ""], ["Tang", "Jianbin", ""], ["Harrer", "Stefan", ""]]}, {"id": "1903.03234", "submitter": "Srinivasan Sivanandan", "authors": "Vaibhav Saxena, Srinivasan Sivanandan, Pulkit Mathur", "title": "Dyna-AIL : Adversarial Imitation Learning by Planning", "comments": "8 pages, 6 figures, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial methods for imitation learning have been shown to perform well on\nvarious control tasks. However, they require a large number of environment\ninteractions for convergence. In this paper, we propose an end-to-end\ndifferentiable adversarial imitation learning algorithm in a Dyna-like\nframework for switching between model-based planning and model-free learning\nfrom expert data. Our results on both discrete and continuous environments show\nthat our approach of using model-based planning along with model-free learning\nconverges to an optimal policy with fewer number of environment interactions in\ncomparison to the state-of-the-art learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 00:54:49 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Saxena", "Vaibhav", ""], ["Sivanandan", "Srinivasan", ""], ["Mathur", "Pulkit", ""]]}, {"id": "1903.03237", "submitter": "Kazuyoshi Yoshii", "authors": "Kouhei Sekiguchi, Aditya Arie Nugraha, Yoshiaki Bando, Kazuyoshi\n  Yoshii", "title": "Fast Multichannel Source Separation Based on Jointly Diagonalizable\n  Spatial Covariance Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a versatile method that accelerates multichannel source\nseparation methods based on full-rank spatial modeling. A popular approach to\nmultichannel source separation is to integrate a spatial model with a source\nmodel for estimating the spatial covariance matrices (SCMs) and power spectral\ndensities (PSDs) of each sound source in the time-frequency domain. One of the\nmost successful examples of this approach is multichannel nonnegative matrix\nfactorization (MNMF) based on a full-rank spatial model and a low-rank source\nmodel. MNMF, however, is computationally expensive and often works poorly due\nto the difficulty of estimating the unconstrained full-rank SCMs. Instead of\nrestricting the SCMs to rank-1 matrices with the severe loss of the spatial\nmodeling ability as in independent low-rank matrix analysis (ILRMA), we\nrestrict the SCMs of each frequency bin to jointly-diagonalizable but still\nfull-rank matrices. For such a fast version of MNMF, we propose a\ncomputationally-efficient and convergence-guaranteed algorithm that is similar\nin form to that of ILRMA. Similarly, we propose a fast version of a\nstate-of-the-art speech enhancement method based on a deep speech model and a\nlow-rank noise model. Experimental results showed that the fast versions of\nMNMF and the deep speech enhancement method were several times faster and\nperformed even better than the original versions of those methods,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 01:17:23 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Sekiguchi", "Kouhei", ""], ["Nugraha", "Aditya Arie", ""], ["Bando", "Yoshiaki", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1903.03252", "submitter": "Alex Kearney", "authors": "Alex Kearney, Vivek Veeriah, Jaden Travnik, Patrick M. Pilarski,\n  Richard S. Sutton", "title": "Learning Feature Relevance Through Step Size Adaptation in\n  Temporal-Difference Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a long history of using meta learning as representation learning,\nspecifically for determining the relevance of inputs. In this paper, we examine\nan instance of meta-learning in which feature relevance is learned by adapting\nstep size parameters of stochastic gradient descent---building on a variety of\nprior work in stochastic approximation, machine learning, and artificial neural\nnetworks. In particular, we focus on stochastic meta-descent introduced in the\nIncremental Delta-Bar-Delta (IDBD) algorithm for setting individual step sizes\nfor each feature of a linear function approximator. Using IDBD, a feature with\nlarge or small step sizes will have a large or small impact on generalization\nfrom training examples. As a main contribution of this work, we extend IDBD to\ntemporal-difference (TD) learning---a form of learning which is effective in\nsequential, non i.i.d. problems. We derive a variety of IDBD generalizations\nfor TD learning, demonstrating that they are able to distinguish which features\nare relevant and which are not. We demonstrate that TD IDBD is effective at\nlearning feature relevance in both an idealized gridworld and a real-world\nrobotic prediction task.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 02:29:22 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Kearney", "Alex", ""], ["Veeriah", "Vivek", ""], ["Travnik", "Jaden", ""], ["Pilarski", "Patrick M.", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1903.03253", "submitter": "Yaqing Wang", "authors": "Yaqing Wang, James T. Kwok, and Lionel M. Ni", "title": "General Convolutional Sparse Coding with Unknown Noise", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2020.2980980", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional sparse coding (CSC) can learn representative shift-invariant\npatterns from multiple kinds of data. However, existing CSC methods can only\nmodel noises from Gaussian distribution, which is restrictive and unrealistic.\nIn this paper, we propose a general CSC model capable of dealing with\ncomplicated unknown noise. The noise is now modeled by Gaussian mixture model,\nwhich can approximate any continuous probability density function. We use the\nexpectation-maximization algorithm to solve the problem and design an efficient\nmethod for the weighted CSC problem in maximization step. The crux is to speed\nup the convolution in the frequency domain while keeping the other computation\ninvolving weight matrix in the spatial domain. Besides, we simultaneously\nupdate the dictionary and codes by nonconvex accelerated proximal gradient\nalgorithm without bringing in extra alternating loops. The resultant method\nobtains comparable time and space complexity compared with existing CSC\nmethods. Extensive experiments on synthetic and real noisy biomedical data sets\nvalidate that our method can model noise effectively and obtain high-quality\nfilters and representation.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 02:32:43 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Wang", "Yaqing", ""], ["Kwok", "James T.", ""], ["Ni", "Lionel M.", ""]]}, {"id": "1903.03254", "submitter": "Christian Pieringer", "authors": "Christian Pieringer and Karim Pichara and M\\'arcio Catel\\'an and\n  Pavlos Protopapas", "title": "An Algorithm for the Visualization of Relevant Patterns in Astronomical\n  Light Curves", "comments": "Accepted 2019 January 8. Received 2019 January 8; in original form\n  2018 January 29. 7 pages, 6 figures", "journal-ref": "Monthly Notices of the Astronomical Society, MNRAS 484, 3071 to\n  3077 (2019)", "doi": "10.1093/mnras/stz106", "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the last years, the classification of variable stars with Machine\nLearning has become a mainstream area of research. Recently, visualization of\ntime series is attracting more attention in data science as a tool to visually\nhelp scientists to recognize significant patterns in complex dynamics. Within\nthe Machine Learning literature, dictionary-based methods have been widely used\nto encode relevant parts of image data. These methods intrinsically assign a\ndegree of importance to patches in pictures, according to their contribution in\nthe image reconstruction. Inspired by dictionary-based techniques, we present\nan approach that naturally provides the visualization of salient parts in\nastronomical light curves, making the analogy between image patches and\nrelevant pieces in time series. Our approach encodes the most meaningful\npatterns such that we can approximately reconstruct light curves by just using\nthe encoded information. We test our method in light curves from the OGLE-III\nand StarLight databases. Our results show that the proposed model delivers an\nautomatic and intuitive visualization of relevant light curve parts, such as\nlocal peaks and drops in magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 02:32:55 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Pieringer", "Christian", ""], ["Pichara", "Karim", ""], ["Catel\u00e1n", "M\u00e1rcio", ""], ["Protopapas", "Pavlos", ""]]}, {"id": "1903.03269", "submitter": "Kazuyoshi Yoshii", "authors": "Aditya Arie Nugraha, Kouhei Sekiguchi, Kazuyoshi Yoshii", "title": "A Deep Generative Model of Speech Complex Spectrograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an approach to the joint modeling of the short-time\nFourier transform magnitude and phase spectrograms with a deep generative\nmodel. We assume that the magnitude follows a Gaussian distribution and the\nphase follows a von Mises distribution. To improve the consistency of the phase\nvalues in the time-frequency domain, we also apply the von Mises distribution\nto the phase derivatives, i.e., the group delay and the instantaneous\nfrequency. Based on these assumptions, we explore and compare several\ncombinations of loss functions for training our models. Built upon the\nvariational autoencoder framework, our model consists of three convolutional\nneural networks acting as an encoder, a magnitude decoder, and a phase decoder.\nIn addition to the latent variables, we propose to also condition the phase\nestimation on the estimated magnitude. Evaluated for a time-domain speech\nreconstruction task, our models could generate speech with a high perceptual\nquality and a high intelligibility.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 03:57:30 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Nugraha", "Aditya Arie", ""], ["Sekiguchi", "Kouhei", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1903.03279", "submitter": "Yu Inatsu", "authors": "Yu Inatsu, Daisuke Sugita, Kazuaki Toyoura, Ichiro Takeuchi", "title": "Active learning for enumerating local minima based on Gaussian process\n  derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study active learning (AL) based on Gaussian Processes (GPs) for\nefficiently enumerating all of the local minimum solutions of a black-box\nfunction. This problem is challenging due to the fact that local solutions are\ncharacterized by their zero gradient and positive-definite Hessian properties,\nbut those derivatives cannot be directly observed. We propose a new AL method\nin which the input points are sequentially selected such that the confidence\nintervals of the GP derivatives are effectively updated for enumerating local\nminimum solutions. We theoretically analyze the proposed method and demonstrate\nits usefulness through numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 04:35:02 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Inatsu", "Yu", ""], ["Sugita", "Daisuke", ""], ["Toyoura", "Kazuaki", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1903.03300", "submitter": "Dominique Gay", "authors": "Dominique Gay and Vincent Lemaire", "title": "Should we Reload Time Series Classification Performance Evaluation ? (a\n  position paper)", "comments": "8 pages", "journal-ref": "3rd ECML/PKDD Workshop on Advanced Analytics and Learning on\n  Temporal Data (AALTD 2018)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the introduction and the public availability of the \\textsc{ucr} time\nseries benchmark data sets, numerous Time Series Classification (TSC) methods\nhas been designed, evaluated and compared to each others. We suggest a critical\nview of TSC performance evaluation protocols put in place in recent TSC\nliterature. The main goal of this `position' paper is to stimulate discussion\nand reflexion about performance evaluation in TSC literature.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 06:26:59 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Gay", "Dominique", ""], ["Lemaire", "Vincent", ""]]}, {"id": "1903.03315", "submitter": "Huyan Huang", "authors": "Huyan Huang and Yipeng Liu and Ce Zhu", "title": "Provable Tensor Ring Completion", "comments": null, "journal-ref": "Signal Processing, vol. 171, p. 107486, 2020", "doi": "10.1016/j.sigpro.2020.107486", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor completion recovers a multi-dimensional array from a limited number of\nmeasurements. Using the recently proposed tensor ring (TR) decomposition, in\nthis paper we show that a d-order tensor of dimensional size n and TR rank r\ncan be exactly recovered with high probability by solving a convex optimization\nprogram, given n^{d/2} r^2 ln^7(n^{d/2})samples. The proposed TR incoherence\ncondition under which the result holds is similar to the matrix incoherence\ncondition. The experiments on synthetic data verify the recovery guarantee for\nTR completion. Moreover, the experiments on real-world data show that our\nmethod improves the recovery performance compared with the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 08:04:25 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 12:32:52 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 05:35:21 GMT"}, {"version": "v4", "created": "Sun, 17 Mar 2019 13:15:43 GMT"}, {"version": "v5", "created": "Thu, 21 Mar 2019 02:20:01 GMT"}, {"version": "v6", "created": "Thu, 9 Jan 2020 03:14:22 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Huang", "Huyan", ""], ["Liu", "Yipeng", ""], ["Zhu", "Ce", ""]]}, {"id": "1903.03324", "submitter": "Mikel Elkano", "authors": "Mikel Elkano and Humberto Bustince and Mikel Galar", "title": "Do we still need fuzzy classifiers for Small Data in the Era of Big\n  Data?", "comments": "To appear in 2019 IEEE International Conference on Fuzzy Systems\n  (FUZZ-IEEE 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Era of Big Data has forced researchers to explore new distributed\nsolutions for building fuzzy classifiers, which often introduce approximation\nerrors or make strong assumptions to reduce computational and memory\nrequirements. As a result, Big Data classifiers might be expected to be\ninferior to those designed for standard classification tasks (Small Data) in\nterms of accuracy and model complexity. To our knowledge, however, there is no\nempirical evidence to confirm such a conjecture yet. Here, we investigate the\nextent to which state-of-the-art fuzzy classifiers for Big Data sacrifice\nperformance in favor of scalability. To this end, we carry out an empirical\nstudy that compares these classifiers with some of the best performing\nalgorithms for Small Data. Assuming the latter were generally designed for\nmaximizing performance without considering scalability issues, the results of\nthis study provide some intuition around the tradeoff between performance and\nscalability achieved by current Big Data solutions. Our findings show that,\nalthough slightly inferior, Big Data classifiers are gradually catching up with\nstate-of-the-art classifiers for Small data, suggesting that a unified learning\nalgorithm for Big and Small Data might be possible.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 08:46:27 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Elkano", "Mikel", ""], ["Bustince", "Humberto", ""], ["Galar", "Mikel", ""]]}, {"id": "1903.03332", "submitter": "Sourav Medya", "authors": "Sahil Manchanda and Akash Mittal and Anuj Dhawan and Sourav Medya and\n  Sayan Ranu and Ambuj Singh", "title": "Learning Heuristics over Large Graphs via Deep Reinforcement Learning", "comments": "To appear in NeurIPS 2020\n  https://papers.nips.cc/paper/2020/hash/e7532dbeff7ef901f2e70daacb3f452d-Abstract.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increased interest in discovering heuristics for\ncombinatorial problems on graphs through machine learning. While existing\ntechniques have primarily focused on obtaining high-quality solutions,\nscalability to billion-sized graphs has not been adequately addressed. In\naddition, the impact of budget-constraint, which is necessary for many\npractical scenarios, remains to be studied. In this paper, we propose a\nframework called GCOMB to bridge these gaps. GCOMB trains a Graph Convolutional\nNetwork (GCN) using a novel probabilistic greedy mechanism to predict the\nquality of a node. To further facilitate the combinatorial nature of the\nproblem, GCOMB utilizes a Q-learning framework, which is made efficient through\nimportance sampling. We perform extensive experiments on real graphs to\nbenchmark the efficiency and efficacy of GCOMB. Our results establish that\nGCOMB is 100 times faster and marginally better in quality than\nstate-of-the-art algorithms for learning combinatorial algorithms.\nAdditionally, a case-study on the practical combinatorial problem of Influence\nMaximization (IM) shows GCOMB is 150 times faster than the specialized IM\nalgorithm IMM with similar quality.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 09:23:08 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 03:31:07 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 08:01:08 GMT"}, {"version": "v4", "created": "Wed, 2 Dec 2020 12:17:04 GMT"}, {"version": "v5", "created": "Thu, 3 Dec 2020 05:51:59 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Manchanda", "Sahil", ""], ["Mittal", "Akash", ""], ["Dhawan", "Anuj", ""], ["Medya", "Sourav", ""], ["Ranu", "Sayan", ""], ["Singh", "Ambuj", ""]]}, {"id": "1903.03348", "submitter": "Wei Shao Dr", "authors": "Wei Shao, Flora D. Salim, Jeffrey Chan, Sean Morrison and Fabio\n  Zambetta", "title": "Approximating Optimisation Solutions for Travelling Officer Problem with\n  Customised Deep Learning Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been extended to a number of new domains with critical\nsuccess, though some traditional orienteering problems such as the Travelling\nSalesman Problem (TSP) and its variants are not commonly solved using such\ntechniques. Deep neural networks (DNNs) are a potentially promising and\nunder-explored solution to solve these problems due to their powerful function\napproximation abilities, and their fast feed-forward computation. In this\npaper, we outline a method for converting an orienteering problem into a\nclassification problem, and design a customised multi-layer deep learning\nnetwork to approximate traditional optimisation solutions to this problem. We\ntest the performance of the network on a real-world parking violation dataset,\nand conduct a generic study that empirically shows the critical architectural\ncomponents that affect network performance for this problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 10:04:27 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Shao", "Wei", ""], ["Salim", "Flora D.", ""], ["Chan", "Jeffrey", ""], ["Morrison", "Sean", ""], ["Zambetta", "Fabio", ""]]}, {"id": "1903.03364", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Large-Margin Multiple Kernel Learning for Discriminative Features\n  Selection and Representation Learning", "comments": "8 Pages, 2 figures, IJCNN 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple kernel learning (MKL) algorithms combine different base kernels to\nobtain a more efficient representation in the feature space. Focusing on\ndiscriminative tasks, MKL has been used successfully for feature selection and\nfinding the significant modalities of the data. In such applications, each base\nkernel represents one dimension of the data or is derived from one specific\ndescriptor. Therefore, MKL finds an optimal weighting scheme for the given\nkernels to increase the classification accuracy. Nevertheless, the majority of\nthe works in this area focus on only binary classification problems or aim for\nlinear separation of the classes in the kernel space, which are not realistic\nassumptions for many real-world problems. In this paper, we propose a novel\nmulti-class MKL framework which improves the state-of-the-art by enhancing the\nlocal separation of the classes in the feature space. Besides, by using a\nsparsity term, our large-margin multiple kernel algorithm (LMMK) performs\ndiscriminative feature selection by aiming to employ a small subset of the base\nkernels. Based on our empirical evaluations on different real-world datasets,\nLMMK provides a competitive classification accuracy compared with the\nstate-of-the-art algorithms in MKL. Additionally, it learns a sparse set of\nnon-zero kernel weights which leads to a more interpretable feature selection\nand representation learning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 10:51:03 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 23:00:12 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.03386", "submitter": "Vikram Venkatraghavan", "authors": "Vikram Venkatraghavan and Florian Dubost and Esther E. Bron and Wiro\n  J. Niessen and Marleen de Bruijne and Stefan Klein", "title": "Event-Based Modeling with High-Dimensional Imaging Biomarkers for\n  Estimating Spatial Progression of Dementia", "comments": "IPMI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Event-based models (EBM) are a class of disease progression models that can\nbe used to estimate temporal ordering of neuropathological changes from\ncross-sectional data. Current EBMs only handle scalar biomarkers, such as\nregional volumes, as inputs. However, regional aggregates are a crude summary\nof the underlying high-resolution images, potentially limiting the accuracy of\nEBM. Therefore, we propose a novel method that exploits high-dimensional\nvoxel-wise imaging biomarkers: n-dimensional discriminative EBM (nDEBM). nDEBM\nis based on an insight that mixture modeling, which is a key element of\nconventional EBMs, can be replaced by a more scalable semi-supervised support\nvector machine (SVM) approach. This SVM is used to estimate the degree of\nabnormality of each region which is then used to obtain subject-specific\ndisease progression patterns. These patterns are in turn used for estimating\nthe mean ordering by fitting a generalized Mallows model. In order to validate\nthe biomarker ordering obtained using nDEBM, we also present a framework for\nSimulation of Imaging Biomarkers' Temporal Evolution (SImBioTE) that mimics\nneurodegeneration in brain regions. SImBioTE trains variational auto-encoders\n(VAE) in different brain regions independently to simulate images at varying\nstages of disease progression. We also validate nDEBM clinically using data\nfrom the Alzheimer's Disease Neuroimaging Initiative (ADNI). In both\nexperiments, nDEBM using high-dimensional features gave better performance than\nstate-of-the-art EBM methods using regional volume biomarkers. This suggests\nthat nDEBM is a promising approach for disease progression modeling.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 12:05:58 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Venkatraghavan", "Vikram", ""], ["Dubost", "Florian", ""], ["Bron", "Esther E.", ""], ["Niessen", "Wiro J.", ""], ["de Bruijne", "Marleen", ""], ["Klein", "Stefan", ""]]}, {"id": "1903.03404", "submitter": "Zeke Wang Dr.", "authors": "Zeke Wang, Kaan Kara, Hantian Zhang, Gustavo Alonso, Onur Mutlu, Ce\n  Zhang", "title": "Accelerating Generalized Linear Models with MLWeaving: A\n  One-Size-Fits-All System for Any-precision Learning (Technical Report)", "comments": "18 pages", "journal-ref": "PVLDB, 2019", "doi": "10.14778/3317315.3317322", "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from the data stored in a database is an important function\nincreasingly available in relational engines. Methods using lower precision\ninput data are of special interest given their overall higher efficiency but,\nin databases, these methods have a hidden cost: the quantization of the real\nvalue into a smaller number is an expensive step. To address the issue, in this\npaper we present MLWeaving, a data structure and hardware acceleration\ntechnique intended to speed up learning of generalized linear models in\ndatabases. ML-Weaving provides a compact, in-memory representation enabling the\nretrieval of data at any level of precision. MLWeaving also takes advantage of\nthe increasing availability of FPGA-based accelerators to provide a highly\nefficient implementation of stochastic gradient descent. The solution adopted\nin MLWeaving is more efficient than existing designs in terms of space (since\nit can process any resolution on the same design) and resources (via the use of\nbit-serial multipliers). MLWeaving also enables the runtime tuning of\nprecision, instead of a fixed precision level during the training. We\nillustrate this using a simple, dynamic precision schedule. Experimental\nresults show MLWeaving achieves up to16 performance improvement over\nlow-precision CPU implementations of first-order methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 13:03:11 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 08:25:41 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Wang", "Zeke", ""], ["Kara", "Kaan", ""], ["Zhang", "Hantian", ""], ["Alonso", "Gustavo", ""], ["Mutlu", "Onur", ""], ["Zhang", "Ce", ""]]}, {"id": "1903.03411", "submitter": "Thiago Freitas Dos Santos", "authors": "Thiago Freitas dos Santos, Paulo E. Santos, Leonardo A. Ferreira,\n  Reinaldo A. C. Bianchi, Pedro Cabalar", "title": "Heuristics, Answer Set Programming and Markov Decision Process for\n  Solving a Set of Spatial Puzzles", "comments": "Submitted to Journal of Heuristics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial puzzles composed of rigid objects, flexible strings and holes offer\ninteresting domains for reasoning about spatial entities that are common in the\nhuman daily-life's activities. The goal of this work is to investigate the\nautomated solution of this kind of puzzles adapting an algorithm that combines\nAnswer Set Programming (ASP) with Markov Decision Process (MDP), algorithm\noASP(MDP), to use heuristics accelerating the learning process. ASP is applied\nto represent the domain as an MDP, while a Reinforcement Learning algorithm\n(Q-Learning) is used to find the optimal policies. In this work, the heuristics\nwere obtained from the solution of relaxed versions of the puzzles. Experiments\nwere performed on deterministic, non-deterministic and non-stationary versions\nof the puzzles. Results show that the proposed approach can accelerate the\nlearning process, presenting an advantage when compared to the non-heuristic\nversions of oASP(MDP) and Q-Learning.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 01:18:29 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Santos", "Thiago Freitas dos", ""], ["Santos", "Paulo E.", ""], ["Ferreira", "Leonardo A.", ""], ["Bianchi", "Reinaldo A. C.", ""], ["Cabalar", "Pedro", ""]]}, {"id": "1903.03412", "submitter": "Dong Zhang", "authors": "Dong-dong Zhang, Lei Zhang, Vladimir Zaborovsky, Feng Xie, Yan-wen Wu,\n  Ting-ting Lu", "title": "Research on the pixel-based and object-oriented methods of urban feature\n  extraction with GF-2 remote-sensing images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.CV cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the rapid urbanization construction of China, acquisition of urban\ngeographic information and timely data updating are important and fundamental\ntasks for the refined management of cities. With the development of domestic\nremote sensing technology, the application of Gaofen-2 (GF-2) high-resolution\nremote sensing images can greatly improve the accuracy of information\nextraction. This paper introduces an approach using object-oriented\nclassification methods for urban feature extraction based on GF-2 satellite\ndata. A combination of spectral, spatial attributes and membership functions\nwas employed for mapping the urban features of Qinhuai District, Nanjing. The\ndata preprocessing is carried out by ENVI software, and the subsequent data is\nexported into the eCognition software for object-oriented classification and\nextraction of urban feature information. Finally, the obtained raster image\nclassification results are vectorized using the ARCGIS software, and the vector\ngraphics are stored in the library, which can be used for further analysis and\nmodeling. Accuracy assessment was performed using ground truth data acquired by\nvisual interpretation and from other reliable secondary data sources. Compared\nwith the result of pixel-based supervised (neural net) classification, the\ndeveloped object-oriented method can significantly improve extraction accuracy,\nand after manual interpretation, an overall accuracy of 95.44% can be achieved,\nwith a Kappa coefficient of 0.9405, which objectively confirmed the superiority\nof the object-oriented method and the feasibility of the utilization of GF-2\nsatellite data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 15:19:36 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Zhang", "Dong-dong", ""], ["Zhang", "Lei", ""], ["Zaborovsky", "Vladimir", ""], ["Xie", "Feng", ""], ["Wu", "Yan-wen", ""], ["Lu", "Ting-ting", ""]]}, {"id": "1903.03425", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "The Ethics of AI Ethics -- An Evaluation of Guidelines", "comments": "16 pages, 1 table", "journal-ref": "Minds & Machines, 2020", "doi": "10.1007/s11023-020-09517-8", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current advances in research, development and application of artificial\nintelligence (AI) systems have yielded a far-reaching discourse on AI ethics.\nIn consequence, a number of ethics guidelines have been released in recent\nyears. These guidelines comprise normative principles and recommendations aimed\nto harness the \"disruptive\" potentials of new AI technologies. Designed as a\ncomprehensive evaluation, this paper analyzes and compares these guidelines\nhighlighting overlaps but also omissions. As a result, I give a detailed\noverview of the field of AI ethics. Finally, I also examine to what extent the\nrespective ethical principles and values are implemented in the practice of\nresearch, development and application of AI systems - and how the effectiveness\nin the demands of AI ethics can be improved.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 15:50:35 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 08:44:31 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "1903.03441", "submitter": "Tim Adler", "authors": "Tim J. Adler, Lynton Ardizzone, Anant Vemuri, Leonardo Ayala, Janek\n  Gr\\\"ohl, Thomas Kirchner, Sebastian Wirkert, Jakob Kruse, Carsten Rother,\n  Ullrich K\\\"othe and Lena Maier-Hein", "title": "Uncertainty-aware performance assessment of optical imaging modalities\n  with invertible neural networks", "comments": "Accepted at IPCAI 2019", "journal-ref": null, "doi": "10.1007/s11548-019-01939-9", "report-no": null, "categories": "physics.med-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Optical imaging is evolving as a key technique for advanced sensing\nin the operating room. Recent research has shown that machine learning\nalgorithms can be used to address the inverse problem of converting pixel-wise\nmultispectral reflectance measurements to underlying tissue parameters, such as\noxygenation. Assessment of the specific hardware used in conjunction with such\nalgorithms, however, has not properly addressed the possibility that the\nproblem may be ill-posed.\n  Methods: We present a novel approach to the assessment of optical imaging\nmodalities, which is sensitive to the different types of uncertainties that may\noccur when inferring tissue parameters. Based on the concept of invertible\nneural networks, our framework goes beyond point estimates and maps each\nmultispectral measurement to a full posterior probability distribution which is\ncapable of representing ambiguity in the solution via multiple modes.\nPerformance metrics for a hardware setup can then be computed from the\ncharacteristics of the posteriors.\n  Results: Application of the assessment framework to the specific use case of\ncamera selection for physiological parameter estimation yields the following\ninsights: (1) Estimation of tissue oxygenation from multispectral images is a\nwell-posed problem, while (2) blood volume fraction may not be recovered\nwithout ambiguity. (3) In general, ambiguity may be reduced by increasing the\nnumber of spectral bands in the camera.\n  Conclusion: Our method could help to optimize optical camera design in an\napplication-specific manner.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 13:39:15 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Adler", "Tim J.", ""], ["Ardizzone", "Lynton", ""], ["Vemuri", "Anant", ""], ["Ayala", "Leonardo", ""], ["Gr\u00f6hl", "Janek", ""], ["Kirchner", "Thomas", ""], ["Wirkert", "Sebastian", ""], ["Kruse", "Jakob", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""], ["Maier-Hein", "Lena", ""]]}, {"id": "1903.03445", "submitter": "Enzo Ferrante", "authors": "Nicolas Roulet and Diego Fernandez Slezak and Enzo Ferrante", "title": "Joint Learning of Brain Lesion and Anatomy Segmentation from\n  Heterogeneous Datasets", "comments": "Accepted for publication at MIDL 2019. Open reviews available at:\n  https://openreview.net/forum?id=Syest0rxlN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain lesion and anatomy segmentation in magnetic resonance images are\nfundamental tasks in neuroimaging research and clinical practice. Given enough\ntraining data, convolutional neuronal networks (CNN) proved to outperform all\nexistent techniques in both tasks independently. However, to date, little work\nhas been done regarding simultaneous learning of brain lesion and anatomy\nsegmentation from disjoint datasets.\n  In this work we focus on training a single CNN model to predict brain tissue\nand lesion segmentations using heterogeneous datasets labeled independently,\naccording to only one of these tasks (a common scenario when using publicly\navailable datasets). We show that label contradiction issues can arise in this\ncase, and propose a novel adaptive cross entropy (ACE) loss function that makes\nsuch training possible. We provide quantitative evaluation in two different\nscenarios, benchmarking the proposed method in comparison with a multi-network\napproach. Our experiments suggest that ACE loss enables training of single\nmodels when standard cross entropy and Dice loss functions tend to fail.\nMoreover, we show that it is possible to achieve competitive results when\ncomparing with multiple networks trained for independent tasks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 13:49:44 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 15:23:14 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Roulet", "Nicolas", ""], ["Slezak", "Diego Fernandez", ""], ["Ferrante", "Enzo", ""]]}, {"id": "1903.03447", "submitter": "Malik Tiomoko", "authors": "Malik Tiomoko and Romain Couillet", "title": "Random Matrix-Improved Estimation of the Wasserstein Distance between\n  two Centered Gaussian Distributions", "comments": "Submitted to European Signal Processing Conference (EUSIPCO'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a method to consistently estimate functionals\n$\\frac1p\\sum_{i=1}^pf(\\lambda_i(C_1C_2))$ of the eigenvalues of the product of\ntwo covariance matrices $C_1,C_2\\in\\mathbb{R}^{p\\times p}$ based on the\nempirical estimates $\\lambda_i(\\hat C_1\\hat C_2)$ ($\\hat\nC_a=\\frac1{n_a}\\sum_{i=1}^{n_a} x_i^{(a)}x_i^{(a){{\\sf T}}}$), when the size\n$p$ and number $n_a$ of the (zero mean) samples $x_i^{(a)}$ are similar. As a\ncorollary, a consistent estimate of the Wasserstein distance (related to the\ncase $f(t)=\\sqrt{t}$) between centered Gaussian distributions is derived.\n  The new estimate is shown to largely outperform the classical sample\ncovariance-based `plug-in' estimator. Based on this finding, a practical\napplication to covariance estimation is then devised which demonstrates\npotentially significant performance gains with respect to state-of-the-art\nalternatives.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 13:54:14 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Tiomoko", "Malik", ""], ["Couillet", "Romain", ""]]}, {"id": "1903.03448", "submitter": "Fredrik D. Johansson", "authors": "Fredrik D. Johansson, David Sontag, Rajesh Ranganath", "title": "Support and Invertibility in Domain-Invariant Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning domain-invariant representations has become a popular approach to\nunsupervised domain adaptation and is often justified by invoking a particular\nsuite of theoretical results. We argue that there are two significant flaws in\nsuch arguments. First, the results in question hold only for a fixed\nrepresentation and do not account for information lost in non-invertible\ntransformations. Second, domain invariance is often a far too strict\nrequirement and does not always lead to consistent estimation, even under\nstrong and favorable assumptions. In this work, we give generalization bounds\nfor unsupervised domain adaptation that hold for any representation function by\nacknowledging the cost of non-invertibility. In addition, we show that\npenalizing distance between densities is often wasteful and propose a bound\nbased on measuring the extent to which the support of the source domain covers\nthe target domain. We perform experiments on well-known benchmarks that\nillustrate the short-comings of current standard practice.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 13:56:24 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 15:39:57 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 12:48:05 GMT"}, {"version": "v4", "created": "Wed, 3 Jul 2019 22:58:51 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Johansson", "Fredrik D.", ""], ["Sontag", "David", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1903.03472", "submitter": "Sheng Zhou", "authors": "Wenqi Shi, Yunzhong Hou, Sheng Zhou, Zhisheng Niu, Yang Zhang, Lu Geng", "title": "Improving Device-Edge Cooperative Inference of Deep Learning via 2-Step\n  Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are state-of-the-art solutions for many machine\nlearning applications, and have been widely used on mobile devices. Running\nDNNs on resource-constrained mobile devices often requires the help from edge\nservers via computation offloading. However, offloading through a\nbandwidth-limited wireless link is non-trivial due to the tight interplay\nbetween the computation resources on mobile devices and wireless resources.\nExisting studies have focused on cooperative inference where DNN models are\npartitioned at different neural network layers, and the two parts are executed\nat the mobile device and the edge server, respectively. Since the output data\nsize of a DNN layer can be larger than that of the raw data, offloading\nintermediate data between layers can suffer from high transmission latency\nunder limited wireless bandwidth. In this paper, we propose an efficient and\nflexible 2-step pruning framework for DNN partition between mobile devices and\nedge servers. In our framework, the DNN model only needs to be pruned once in\nthe training phase where unimportant convolutional filters are removed\niteratively. By limiting the pruning region, our framework can greatly reduce\neither the wireless transmission workload of the device or the total\ncomputation workload. A series of pruned models are generated in the training\nphase, from which the framework can automatically select to satisfy varying\nlatency and accuracy requirements. Furthermore, coding for the intermediate\ndata is added to provide extra transmission workload reduction. Our experiments\nshow that the proposed framework can achieve up to 25.6$\\times$ reduction on\ntransmission workload, 6.01$\\times$ acceleration on total computation and\n4.81$\\times$ reduction on end-to-end latency as compared to partitioning the\noriginal DNN model without pruning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 14:44:56 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Shi", "Wenqi", ""], ["Hou", "Yunzhong", ""], ["Zhou", "Sheng", ""], ["Niu", "Zhisheng", ""], ["Zhang", "Yang", ""], ["Geng", "Lu", ""]]}, {"id": "1903.03488", "submitter": "Eran Malach", "authors": "Eran Malach, Shai Shalev-Shwartz", "title": "Is Deeper Better only when Shallow is Good?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the power of depth in feed-forward neural networks is an\nongoing challenge in the field of deep learning theory. While current works\naccount for the importance of depth for the expressive power of\nneural-networks, it remains an open question whether these benefits are\nexploited during a gradient-based optimization process. In this work we explore\nthe relation between expressivity properties of deep networks and the ability\nto train them efficiently using gradient-based algorithms. We give a depth\nseparation argument for distributions with fractal structure, showing that they\ncan be expressed efficiently by deep networks, but not with shallow ones. These\ndistributions have a natural coarse-to-fine structure, and we show that the\nbalance between the coarse and fine details has a crucial effect on whether the\noptimization process is likely to succeed. We prove that when the distribution\nis concentrated on the fine details, gradient-based algorithms are likely to\nfail. Using this result we prove that, at least in some distributions, the\nsuccess of learning deep networks depends on whether the distribution can be\nwell approximated by shallower networks, and we conjecture that this property\nholds in general.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 15:14:30 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Malach", "Eran", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "1903.03503", "submitter": "Adrian Dalca", "authors": "Adrian V. Dalca, John Guttag, Mert R. Sabuncu", "title": "Unsupervised Data Imputation via Variational Inference of Deep Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide range of systems exhibit high dimensional incomplete data. Accurate\nestimation of the missing data is often desired, and is crucial for many\ndownstream analyses. Many state-of-the-art recovery methods involve supervised\nlearning using datasets containing full observations. In contrast, we focus on\nunsupervised estimation of missing image data, where no full observations are\navailable - a common situation in practice. Unsupervised imputation methods for\nimages often employ a simple linear subspace to capture correlations between\ndata dimensions, omitting more complex relationships. In this work, we\nintroduce a general probabilistic model that describes sparse high dimensional\nimaging data as being generated by a deep non-linear embedding. We derive a\nlearning algorithm using a variational approximation based on convolutional\nneural networks and discuss its relationship to linear imputation models, the\nvariational auto encoder, and deep image priors. We introduce sparsity-aware\nnetwork building blocks that explicitly model observed and missing data. We\nanalyze proposed sparsity-aware network building blocks, evaluate our method on\npublic domain imaging datasets, and conclude by showing that our method enables\nimputation in an important real-world problem involving medical images. The\ncode is freely available as part of the \\verb|neuron| library at\nhttp://github.com/adalca/neuron.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 15:28:48 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Dalca", "Adrian V.", ""], ["Guttag", "John", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1903.03511", "submitter": "Zhenfeng Cao", "authors": "Zhenfeng Cao", "title": "Realizing Continual Learning through Modeling a Learning System as a\n  Fiber Bundle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A human brain is capable of continual learning by nature; however the current\nmainstream deep neural networks suffer from a phenomenon named catastrophic\nforgetting (i.e., learning a new set of patterns suddenly and completely would\nresult in fully forgetting what has already been learned). In this paper we\npropose a generic learning model, which regards a learning system as a fiber\nbundle. By comparing the learning performance of our model with conventional\nones whose neural networks are multilayer perceptrons through a variety of\nmachine-learning experiments, we found our proposed model not only enjoys a\ndistinguished capability of continual learning but also bears a high\ninformation capacity. In addition, we found in some learning scenarios the\nlearning performance can be further enhanced by making the learning time-aware\nto mimic the episodic memory in human brain. Last but not least, we found that\nthe properties of forgetting in our model correspond well to those of human\nmemory. This work may shed light on how a human brain learns.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 01:14:19 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Cao", "Zhenfeng", ""]]}, {"id": "1903.03512", "submitter": "Hrishikesh Ganu", "authors": "Hrishikesh Ganu, Mithun Ghosh, Shashi Roshan", "title": "AgentBuddy: A Contextual Bandit based Decision Support System for\n  Customer Support Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this short paper, we present early insights from a Decision Support System\nfor Customer Support Agents (CSAs) serving customers of a leading accounting\nsoftware. The system is under development and is designed to provide\nsuggestions to CSAs to make them more productive. A unique aspect of the\nsolution is the use of bandit algorithms to create a tractable\nhuman-in-the-loop system that can learn from CSAs in an online fashion. In\naddition to discussing the ML aspects, we also bring out important insights we\ngleaned from early feedback from CSAs. These insights motivate our future work\nand also might be of wider interest to ML practitioners.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 19:13:04 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Ganu", "Hrishikesh", ""], ["Ghosh", "Mithun", ""], ["Roshan", "Shashi", ""]]}, {"id": "1903.03536", "submitter": "Martin Wistuba", "authors": "Martin Wistuba, Tejaswini Pedapati", "title": "Inductive Transfer for Neural Architecture Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advent of automated neural network architecture search led to\nseveral methods that outperform state-of-the-art human-designed architectures.\nHowever, these approaches are computationally expensive, in extreme cases\nconsuming GPU years. We propose two novel methods which aim to expedite this\noptimization problem by transferring knowledge acquired from previous tasks to\nnew ones. First, we propose a novel neural architecture selection method which\nemploys this knowledge to identify strong and weak characteristics of neural\narchitectures across datasets. Thus, these characteristics do not need to be\nrediscovered in every search, a strong weakness of current state-of-the-art\nsearches. Second, we propose a method for learning curve extrapolation to\ndetermine if a training process can be terminated early. In contrast to\nexisting work, we propose to learn from learning curves of architectures\ntrained on other datasets to improve the prediction accuracy for novel\ndatasets. On five different image classification benchmarks, we empirically\ndemonstrate that both of our orthogonal contributions independently lead to an\nacceleration, without any significant loss in accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 16:27:32 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Wistuba", "Martin", ""], ["Pedapati", "Tejaswini", ""]]}, {"id": "1903.03571", "submitter": "David Burt", "authors": "David R. Burt, Carl E. Rasmussen, Mark van der Wilk", "title": "Rates of Convergence for Sparse Variational Gaussian Process Regression", "comments": "International Conference on Machine Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excellent variational approximations to Gaussian process posteriors have been\ndeveloped which avoid the $\\mathcal{O}\\left(N^3\\right)$ scaling with dataset\nsize $N$. They reduce the computational cost to $\\mathcal{O}\\left(NM^2\\right)$,\nwith $M\\ll N$ being the number of inducing variables, which summarise the\nprocess. While the computational cost seems to be linear in $N$, the true\ncomplexity of the algorithm depends on how $M$ must increase to ensure a\ncertain quality of approximation. We address this by characterising the\nbehavior of an upper bound on the KL divergence to the posterior. We show that\nwith high probability the KL divergence can be made arbitrarily small by\ngrowing $M$ more slowly than $N$. A particular case of interest is that for\nregression with normally distributed inputs in D-dimensions with the popular\nSquared Exponential kernel, $M=\\mathcal{O}(\\log^D N)$ is sufficient. Our\nresults show that as datasets grow, Gaussian process posteriors can truly be\napproximated cheaply, and provide a concrete rule for how to increase $M$ in\ncontinual learning scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 17:26:52 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 14:14:58 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 18:39:56 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Burt", "David R.", ""], ["Rasmussen", "Carl E.", ""], ["van der Wilk", "Mark", ""]]}, {"id": "1903.03588", "submitter": "Micha{\\l} {\\L}epek", "authors": "Mateusz Soli\\'nski, Micha{\\l} {\\L}epek, {\\L}ukasz Ko{\\l}towski", "title": "Automatic cough detection based on airflow signals for portable\n  spirometry system", "comments": "18 pages, original work. Few improvements and some additional\n  analysis added in this version", "journal-ref": "Informatics in Medicine Unlocked 18 (2020) 100313", "doi": "10.1016/j.imu.2020.100313", "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a short introduction to cough detection efforts that were undertaken\nduring the last decade and we describe the solution for automatic cough\ndetection developed for the AioCare portable spirometry system. In contrast to\nmore popular analysis of sound and audio recordings, we fully based our\napproach on airflow signals only. As the system is intended to be used in a\nlarge variety of environments and different patients, we trained and validated\nthe algorithm using AioCare-collected data and the large database of spirometry\ncurves from the NHANES database by the American National Center for Health\nStatistics. We trained different classifiers, such as logistic regression,\nfeed-forward artificial neural network, support vector machine, and random\nforest to choose the one with the best performance. The ANN solution was\nselected as the final classifier. The classification results on the test set\n(AioCare data) are: 0.86 (sensitivity), 0.91 (specificity), 0.91 (accuracy) and\n0.88 (F1 score). The classification methodology developed in this study is\nrobust for detecting cough events during spirometry measurements. As far as we\nknow, the solution presented in this work is the first fully reproducible\ndescription of the automatic cough detection algorithm based totally on airflow\nsignals and the first cough detection implemented in a commercial spirometry\nsystem that is to be published.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 15:55:09 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 14:58:22 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 08:36:00 GMT"}, {"version": "v4", "created": "Wed, 25 Mar 2020 13:26:37 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Soli\u0144ski", "Mateusz", ""], ["\u0141epek", "Micha\u0142", ""], ["Ko\u0142towski", "\u0141ukasz", ""]]}, {"id": "1903.03591", "submitter": "Justin Lin", "authors": "Justin Lin, Roberto Calandra, and Sergey Levine", "title": "Learning to Identify Object Instances by Touch: Tactile Recognition via\n  Multimodal Matching", "comments": "6 pages; accepted to IEEE International Conference on Robotics and\n  Automation 2019 (ICRA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the literature on robotic perception focuses on the visual modality.\nVision provides a global observation of a scene, making it broadly useful.\nHowever, in the domain of robotic manipulation, vision alone can sometimes\nprove inadequate: in the presence of occlusions or poor lighting, visual object\nidentification might be difficult. The sense of touch can provide robots with\nan alternative mechanism for recognizing objects. In this paper, we study the\nproblem of touch-based instance recognition. We propose a novel framing of the\nproblem as multi-modal recognition: the goal of our system is to recognize,\ngiven a visual and tactile observation, whether or not these observations\ncorrespond to the same object. To our knowledge, our work is the first to\naddress this type of multi-modal instance recognition problem on such a\nlarge-scale with our analysis spanning 98 different objects. We employ a robot\nequipped with two GelSight touch sensors, one on each finger, and a\nself-supervised, autonomous data collection procedure to collect a dataset of\ntactile observations and images. Our experimental results show that it is\npossible to accurately recognize object instances by touch alone, including\ninstances of novel objects that were never seen during training. Our learned\nmodel outperforms other methods on this complex task, including that of human\nvolunteers.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 18:18:16 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Lin", "Justin", ""], ["Calandra", "Roberto", ""], ["Levine", "Sergey", ""]]}, {"id": "1903.03605", "submitter": "Meena Jagadeesan", "authors": "Meena Jagadeesan", "title": "Understanding Sparse JL for Feature Hashing", "comments": "Appeared at NeurIPS 2019; this is the full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature hashing and other random projection schemes are commonly used to\nreduce the dimensionality of feature vectors. The goal is to efficiently\nproject a high-dimensional feature vector living in $\\mathbb{R}^n$ into a much\nlower-dimensional space $\\mathbb{R}^m$, while approximately preserving\nEuclidean norm. These schemes can be constructed using sparse random\nprojections, for example using a sparse Johnson-Lindenstrauss (JL) transform. A\nline of work introduced by Weinberger et. al (ICML '09) analyzes the accuracy\nof sparse JL with sparsity 1 on feature vectors with small\n$\\ell_\\infty$-to-$\\ell_2$ norm ratio. Recently, Freksen, Kamma, and Larsen\n(NeurIPS '18) closed this line of work by proving a tight tradeoff between\n$\\ell_\\infty$-to-$\\ell_2$ norm ratio and accuracy for sparse JL with sparsity\n$1$.\n  In this paper, we demonstrate the benefits of using sparsity $s$ greater than\n$1$ in sparse JL on feature vectors. Our main result is a tight tradeoff\nbetween $\\ell_\\infty$-to-$\\ell_2$ norm ratio and accuracy for a general\nsparsity $s$, that significantly generalizes the result of Freksen et. al. Our\nresult theoretically demonstrates that sparse JL with $s > 1$ can have\nsignificantly better norm-preservation properties on feature vectors than\nsparse JL with $s = 1$; we also empirically demonstrate this finding.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 18:50:42 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 17:51:43 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Jagadeesan", "Meena", ""]]}, {"id": "1903.03609", "submitter": "Yang Zhang", "authors": "Yang Zhang, Mingming Lu", "title": "Based on Graph-VAE Model to Predict Student's Score", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The OECD pointed out that the best way to keep students up to school is to\nintervene as early as possible [1]. Using education big data and deep learning\nto predict student's score provides new resources and perspectives for early\nintervention. Previous forecasting schemes often requires manual filter of\nfeatures , a large amount of prior knowledge and expert knowledge. Deep\nlearning can automatically extract features without manual intervention to\nachieve better predictive performance. In this paper, the graph neural network\nmatrix filling model (Graph-VAE) based on deep learning can automatically\nextract features without a large amount of prior knowledge. The experiment\nproves that our model is better than the traditional solution in the student's\nscore dataset, and it better describes the correlation and difference between\nthe students and the curriculum, and dimensionality reducing the vector of\ncoding result is visualized, the clustering effect is consistent with the real\ndata distribution clustering. In addition, we use gradient-based attribution\nmethods to analyze the key factors that influence performance prediction.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 03:12:46 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Zhang", "Yang", ""], ["Lu", "Mingming", ""]]}, {"id": "1903.03614", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Gradient Descent based Optimization Algorithms for Deep Learning Models\n  Training", "comments": "arXiv admin note: text overlap with arXiv:1805.07500", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim at providing an introduction to the gradient descent\nbased optimization algorithms for learning deep neural network models. Deep\nlearning models involving multiple nonlinear projection layers are very\nchallenging to train. Nowadays, most of the deep learning model training still\nrelies on the back propagation algorithm actually. In back propagation, the\nmodel variables will be updated iteratively until convergence with gradient\ndescent based optimization algorithms. Besides the conventional vanilla\ngradient descent algorithm, many gradient descent variants have also been\nproposed in recent years to improve the learning performance, including\nMomentum, Adagrad, Adam, Gadam, etc., which will all be introduced in this\npaper respectively.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 12:59:47 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1903.03630", "submitter": "Masatoshi Uehara", "authors": "Masatoshi Uehara, Takeru Matsuda, Jae Kwang Kim", "title": "Imputation estimators for unnormalized models with missing data", "comments": "To appear (AISTATS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several statistical models are given in the form of unnormalized densities,\nand calculation of the normalization constant is intractable. We propose\nestimation methods for such unnormalized models with missing data. The key\nconcept is to combine imputation techniques with estimators for unnormalized\nmodels including noise contrastive estimation and score matching. In addition,\nwe derive asymptotic distributions of the proposed estimators and construct\nconfidence intervals. Simulation results with truncated Gaussian graphical\nmodels and the application to real data of wind direction reveal that the\nproposed methods effectively enable statistical inference with unnormalized\nmodels from missing data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 19:01:45 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 21:51:57 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Uehara", "Masatoshi", ""], ["Matsuda", "Takeru", ""], ["Kim", "Jae Kwang", ""]]}, {"id": "1903.03642", "submitter": "Xiaobai Ma Mr.", "authors": "Xiaobai Ma, Katherine Driggs-Campbell, and Mykel J. Kochenderfer", "title": "Improved Robustness and Safety for Autonomous Vehicle Control with\n  Adversarial Reinforcement Learning", "comments": "intelligent vehicles symposium 2018", "journal-ref": "Intelligent Vehicles Symposium (IV), 2018 IEEE", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To improve efficiency and reduce failures in autonomous vehicles, research\nhas focused on developing robust and safe learning methods that take into\naccount disturbances in the environment. Existing literature in robust\nreinforcement learning poses the learning problem as a two player game between\nthe autonomous system and disturbances. This paper examines two different\nalgorithms to solve the game, Robust Adversarial Reinforcement Learning and\nNeural Fictitious Self Play, and compares performance on an autonomous driving\nscenario. We extend the game formulation to a semi-competitive setting and\ndemonstrate that the resulting adversary better captures meaningful\ndisturbances that lead to better overall performance. The resulting robust\npolicy exhibits improved driving efficiency while effectively reducing\ncollision rates compared to baseline control policies produced by traditional\nreinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 19:44:29 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Ma", "Xiaobai", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1903.03652", "submitter": "Mohit Sharma Dr.", "authors": "Mohit K Sharma, Alessio Zappone, Merouane Debbah, Mohamad Assaad", "title": "Deep Learning Based Online Power Control for Large Energy Harvesting\n  Networks", "comments": "5 pages, to appear at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep learning based approach to design online\npower control policies for large EH networks, which are often intractable\nstochastic control problems. In the proposed approach, for a given EH network,\nthe optimal online power control rule is learned by training a deep neural\nnetwork (DNN), using the solution of offline policy design problem. Under the\nproposed scheme, in a given time slot, the transmit power is obtained by\nfeeding the current system state to the trained DNN. Our results illustrate\nthat the DNN based online power control scheme outperforms a Markov decision\nprocess based policy. In general, the proposed deep learning based approach can\nbe used to find solutions to large intractable stochastic control problems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 20:10:20 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Sharma", "Mohit K", ""], ["Zappone", "Alessio", ""], ["Debbah", "Merouane", ""], ["Assaad", "Mohamad", ""]]}, {"id": "1903.03671", "submitter": "Brendan Fong", "authors": "Brendan Fong and Michael Johnson", "title": "Lenses and Learners", "comments": "14 pages", "journal-ref": "In: J. Cheney, H-S. Ko (eds.): Proceedings of the Eighth\n  International Workshop on Bidirectional Transformations (Bx 2019),\n  Philadelphia, PA, USA, June 4, 2019, published at http://ceur-ws.org", "doi": null, "report-no": null, "categories": "cs.LG cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lenses are a well-established structure for modelling bidirectional\ntransformations, such as the interactions between a database and a view of it.\nLenses may be symmetric or asymmetric, and may be composed, forming the\nmorphisms of a monoidal category. More recently, the notion of a learner has\nbeen proposed: these provide a compositional way of modelling supervised\nlearning algorithms, and again form the morphisms of a monoidal category. In\nthis paper, we show that the two concepts are tightly linked. We show both that\nthere is a faithful, identity-on-objects symmetric monoidal functor embedding a\ncategory of asymmetric lenses into the category of learners, and furthermore\nthere is such a functor embedding the category of learners into a category of\nsymmetric lenses.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 17:57:59 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 18:07:27 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Fong", "Brendan", ""], ["Johnson", "Michael", ""]]}, {"id": "1903.03674", "submitter": "Ruiyang Xu", "authors": "Ruiyang Xu and Karl Lieberherr", "title": "Learning Self-Game-Play Agents for Combinatorial Optimization Problems", "comments": "Accepted as an Extended Abstract in AAMAS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in reinforcement learning (RL) using self-game-play has shown\nremarkable performance on several board games (e.g., Chess and Go) as well as\nvideo games (e.g., Atari games and Dota2). It is plausible to consider that RL,\nstarting from zero knowledge, might be able to gradually approximate a winning\nstrategy after a certain amount of training. In this paper, we explore neural\nMonte-Carlo-Tree-Search (neural MCTS), an RL algorithm which has been applied\nsuccessfully by DeepMind to play Go and Chess at a super-human level. We try to\nleverage the computational power of neural MCTS to solve a class of\ncombinatorial optimization problems. Following the idea of Hintikka's\nGame-Theoretical Semantics, we propose the Zermelo Gamification (ZG) to\ntransform specific combinatorial optimization problems into Zermelo games whose\nwinning strategies correspond to the solutions of the original optimization\nproblem. The ZG also provides a specially designed neural MCTS. We use a\ncombinatorial planning problem for which the ground-truth policy is efficiently\ncomputable to demonstrate that ZG is promising.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 21:38:33 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 00:40:17 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Xu", "Ruiyang", ""], ["Lieberherr", "Karl", ""]]}, {"id": "1903.03684", "submitter": "Zakaria El Mrabet", "authors": "Zakaria El Mrabet, Youness Arjoune, Hassan El Ghazi, Badr Abou Al\n  Majd, Naima Kaabouch", "title": "Primary User Emulation Attacks: A Detection Technique Based on Kalman\n  Filter", "comments": "14 pages, 9 figures", "journal-ref": "J. Sens. Actuator Netw. 2018, 7(3), 26", "doi": "10.3390/jsan7030026", "report-no": null, "categories": "cs.CR cs.LG cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive radio technology addresses the problem of spectrum scarcity by\nallowing secondary users to use the vacant spectrum bands without causing\ninterference to the primary users. However, several attacks could disturb the\nnormal functioning of the cognitive radio network. Primary user emulation\nattacks are one of the most severe attacks in which a malicious user emulates\nthe primary user signal characteristics to either prevent other legitimate\nsecondary users from accessing the idle channels or causing harmful\ninterference to the primary users. There are several proposed approaches to\ndetect the primary user emulation attackers. However, most of these techniques\nassume that the primary user location is fixed, which does not make them valid\nwhen the primary user is mobile. In this paper, we propose a new approach based\non the Kalman filter framework for detecting the primary user emulation attacks\nwith a non-stationary primary user. Several experiments have been conducted and\nthe advantages of the proposed approach are demonstrated through the simulation\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 22:13:06 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Mrabet", "Zakaria El", ""], ["Arjoune", "Youness", ""], ["Ghazi", "Hassan El", ""], ["Majd", "Badr Abou Al", ""], ["Kaabouch", "Naima", ""]]}, {"id": "1903.03691", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Shuai Xia, Iacopo Masi, Wael AbdAlmageed", "title": "RoPAD: Robust Presentation Attack Detection through Unsupervised\n  Adversarial Invariance", "comments": "To appear in Proceedings of International Conference on Biometrics\n  (ICB), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For enterprise, personal and societal applications, there is now an\nincreasing demand for automated authentication of identity from images using\ncomputer vision. However, current authentication technologies are still\nvulnerable to presentation attacks. We present RoPAD, an end-to-end deep\nlearning model for presentation attack detection that employs unsupervised\nadversarial invariance to ignore visual distractors in images for increased\nrobustness and reduced overfitting. Experiments show that the proposed\nframework exhibits state-of-the-art performance on presentation attack\ndetection on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 22:43:01 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 22:48:49 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Jaiswal", "Ayush", ""], ["Xia", "Shuai", ""], ["Masi", "Iacopo", ""], ["AbdAlmageed", "Wael", ""]]}, {"id": "1903.03694", "submitter": "Weiran Wang", "authors": "Weiran Wang", "title": "Everything old is new again: A multi-view learning approach to learning\n  using privileged information and distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adopt a multi-view approach for analyzing two knowledge transfer\nsettings---learning using privileged information (LUPI) and distillation---in a\ncommon framework. Under reasonable assumptions about the complexities of\nhypothesis spaces, and being optimistic about the expected loss achievable by\nthe student (in distillation) and a transformed teacher predictor (in LUPI), we\nshow that encouraging agreement between the teacher and the student leads to\nreduced search space. As a result, improved convergence rate can be obtained\nwith regularized empirical risk minimization.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 23:04:11 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Weiran", ""]]}, {"id": "1903.03698", "submitter": "Vitchyr H. Pong", "authors": "Vitchyr H. Pong, Murtaza Dalal, Steven Lin, Ashvin Nair, Shikhar Bahl,\n  Sergey Levine", "title": "Skew-Fit: State-Covering Self-Supervised Reinforcement Learning", "comments": "ICML 2020. 8 pages, 8 figures; 9 pages appendix (6 additional\n  figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents that must exhibit flexible and broad capabilities will need\nto be equipped with large repertoires of skills. Defining each skill with a\nmanually-designed reward function limits this repertoire and imposes a manual\nengineering burden. Self-supervised agents that set their own goals can\nautomate this process, but designing appropriate goal setting objectives can be\ndifficult, and often involves heuristic design decisions. In this paper, we\npropose a formal exploration objective for goal-reaching policies that\nmaximizes state coverage. We show that this objective is equivalent to\nmaximizing goal reaching performance together with the entropy of the goal\ndistribution, where goals correspond to full state observations. To instantiate\nthis principle, we present an algorithm called Skew-Fit for learning a\nmaximum-entropy goal distributions. We prove that, under regularity conditions,\nSkew-Fit converges to a uniform distribution over the set of valid states, even\nwhen we do not know this set beforehand. Our experiments show that combining\nSkew-Fit for learning goal distributions with existing goal-reaching methods\noutperforms a variety of prior methods on open-sourced visual goal-reaching\ntasks. Moreover, we demonstrate that Skew-Fit enables a real-world robot to\nlearn to open a door, entirely from scratch, from pixels, and without any\nmanually-designed reward function.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 23:32:17 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 15:30:20 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 20:24:12 GMT"}, {"version": "v4", "created": "Tue, 4 Aug 2020 04:07:27 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Pong", "Vitchyr H.", ""], ["Dalal", "Murtaza", ""], ["Lin", "Steven", ""], ["Nair", "Ashvin", ""], ["Bahl", "Shikhar", ""], ["Levine", "Sergey", ""]]}, {"id": "1903.03705", "submitter": "Urvashi Oswal", "authors": "Urvashi Oswal, Aniruddha Bhargava, and Robert Nowak", "title": "Linear Bandits with Feature Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a new form of the linear bandit problem in which the\nalgorithm receives the usual stochastic rewards as well as stochastic feedback\nabout which features are relevant to the rewards, the latter feedback being the\nnovel aspect. The focus of this paper is the development of new theory and\nalgorithms for linear bandits with feature feedback. We show that linear\nbandits with feature feedback can achieve regret over time horizon $T$ that\nscales like $k\\sqrt{T}$, without prior knowledge of which features are relevant\nnor the number $k$ of relevant features. In comparison, the regret of\ntraditional linear bandits is $d\\sqrt{T}$, where $d$ is the total number of\n(relevant and irrelevant) features, so the improvement can be dramatic if $k\\ll\nd$. The computational complexity of the new algorithm is proportional to $k$\nrather than $d$, making it much more suitable for real-world applications\ncompared to traditional linear bandits. We demonstrate the performance of the\nnew algorithm with synthetic and real human-labeled data.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 00:32:28 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 00:46:49 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Oswal", "Urvashi", ""], ["Bhargava", "Aniruddha", ""], ["Nowak", "Robert", ""]]}, {"id": "1903.03711", "submitter": "Toshiaki Koike-Akino", "authors": "Ye Wang, Toshiaki Koike-Akino", "title": "Learning to Modulate for Non-coherent MIMO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep learning trend has recently impacted a variety of fields, including\ncommunication systems, where various approaches have explored the application\nof neural networks in place of traditional designs. Neural networks flexibly\nallow for data/simulation-driven optimization, but are often employed as black\nboxes detached from direct application of domain knowledge. Our work considers\nlearning-based approaches addressing modulation and signal detection design for\nthe non-coherent MIMO channel. We demonstrate that simulation-driven\noptimization can be performed while entirely avoiding neural networks, yet\nstill perform comparably. Additionally, we show the feasibility of MIMO\ncommunications over extremely short coherence windows (i.e., channel\ncoefficient stability period), with as few as two time slots.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 00:50:17 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Ye", ""], ["Koike-Akino", "Toshiaki", ""]]}, {"id": "1903.03712", "submitter": "Qiuhua Huang", "authors": "Qiuhua Huang, Renke Huang, Weituo Hao, Jie Tan, Rui Fan, Zhenyu Huang", "title": "Adaptive Power System Emergency Control using Deep Reinforcement\n  Learning", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Power system emergency control is generally regarded as the last safety net\nfor grid security and resiliency. Existing emergency control schemes are\nusually designed off-line based on either the conceived \"worst\" case scenario\nor a few typical operation scenarios. These schemes are facing significant\nadaptiveness and robustness issues as increasing uncertainties and variations\noccur in modern electrical grids. To address these challenges, for the first\ntime, this paper developed novel adaptive emergency control schemes using deep\nreinforcement learning (DRL), by leveraging the high-dimensional feature\nextraction and non-linear generalization capabilities of DRL for complex power\nsystems. Furthermore, an open-source platform named RLGC has been designed for\nthe first time to assist the development and benchmarking of DRL algorithms for\npower system control. Details of the platform and DRL-based emergency control\nschemes for generator dynamic braking and under-voltage load shedding are\npresented. Extensive case studies performed in both two-area four-machine\nsystem and IEEE 39-Bus system have demonstrated the excellent performance and\nrobustness of the proposed schemes.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 00:59:40 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 15:50:19 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Huang", "Qiuhua", ""], ["Huang", "Renke", ""], ["Hao", "Weituo", ""], ["Tan", "Jie", ""], ["Fan", "Rui", ""], ["Huang", "Zhenyu", ""]]}, {"id": "1903.03713", "submitter": "Toshiaki Koike-Akino", "authors": "Toshiki Matsumine, Toshiaki Koike-Akino, Ye Wang", "title": "Deep Learning-Based Constellation Optimization for Physical Network\n  Coding in Two-Way Relay Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a new application of deep learning (DL) for optimizing\nconstellations in two-way relaying with physical-layer network coding (PNC),\nwhere deep neural network (DNN)-based modulation and demodulation are employed\nat each terminal and relay node. We train DNNs such that the cross entropy loss\nis directly minimized, and thus it maximizes the likelihood, rather than\nconsidering the Euclidean distance of the constellations. The proposed scheme\ncan be extended to higher level constellations with slight modification of the\nDNN structure. Simulation results demonstrate a significant performance gain in\nterms of the achievable sum rate over conventional relaying schemes.\nFurthermore, since our DNN demodulator directly outputs bit-wise probabilities,\nit is straightforward to concatenate with soft-decision channel decoding.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 01:05:27 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Matsumine", "Toshiki", ""], ["Koike-Akino", "Toshiaki", ""], ["Wang", "Ye", ""]]}, {"id": "1903.03714", "submitter": "Xiang Ren", "authors": "Weizhi Ma, Min Zhang, Yue Cao, Woojeong, Jin, Chenyang Wang, Yiqun\n  Liu, Shaoping Ma, Xiang Ren", "title": "Jointly Learning Explainable Rules for Recommendation with Knowledge\n  Graph", "comments": "10 pages, plus 1-page references; accepted at The Web Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability and effectiveness are two key aspects for building recommender\nsystems. Prior efforts mostly focus on incorporating side information to\nachieve better recommendation performance. However, these methods have some\nweaknesses: (1) prediction of neural network-based embedding methods are hard\nto explain and debug; (2) symbolic, graph-based approaches (e.g., meta\npath-based models) require manual efforts and domain knowledge to define\npatterns and rules, and ignore the item association types (e.g. substitutable\nand complementary). In this paper, we propose a novel joint learning framework\nto integrate \\textit{induction of explainable rules from knowledge graph} with\n\\textit{construction of a rule-guided neural recommendation model}. The\nframework encourages two modules to complement each other in generating\neffective and explainable recommendation: 1) inductive rules, mined from\nitem-centric knowledge graphs, summarize common multi-hop relational patterns\nfor inferring different item associations and provide human-readable\nexplanation for model prediction; 2) recommendation module can be augmented by\ninduced rules and thus have better generalization ability dealing with the\ncold-start issue. Extensive experiments\\footnote{Code and data can be found at:\n\\url{https://github.com/THUIR/RuleRec}} show that our proposed method has\nachieved significant improvements in item recommendation over baselines on\nreal-world datasets. Our model demonstrates robust performance over \"noisy\"\nitem knowledge graphs, generated by linking item names to related entities.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 01:06:04 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Ma", "Weizhi", ""], ["Zhang", "Min", ""], ["Cao", "Yue", ""], ["Woojeong", "", ""], ["Jin", "", ""], ["Wang", "Chenyang", ""], ["Liu", "Yiqun", ""], ["Ma", "Shaoping", ""], ["Ren", "Xiang", ""]]}, {"id": "1903.03730", "submitter": "Sandesh Adhikary", "authors": "Sandesh Adhikary, Siddarth Srinivasan, Byron Boots", "title": "Learning Quantum Graphical Models using Constrained Gradient Descent on\n  the Stiefel Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum graphical models (QGMs) extend the classical framework for reasoning\nabout uncertainty by incorporating the quantum mechanical view of probability.\nPrior work on QGMs has focused on hidden quantum Markov models (HQMMs), which\ncan be formulated using quantum analogues of the sum rule and Bayes rule used\nin classical graphical models. Despite the focus on developing the QGM\nframework, there has been little progress in learning these models from data.\nThe existing state-of-the-art approach randomly initializes parameters and\niteratively finds unitary transformations that increase the likelihood of the\ndata. While this algorithm demonstrated theoretical strengths of HQMMs over\nHMMs, it is slow and can only handle a small number of hidden states. In this\npaper, we tackle the learning problem by solving a constrained optimization\nproblem on the Stiefel manifold using a well-known retraction-based algorithm.\nWe demonstrate that this approach is not only faster and yields better\nsolutions on several datasets, but also scales to larger models that were\nprohibitively slow to train via the earlier method.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 03:48:18 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Adhikary", "Sandesh", ""], ["Srinivasan", "Siddarth", ""], ["Boots", "Byron", ""]]}, {"id": "1903.03731", "submitter": "Hirak Jyoti Kashyap", "authors": "Hirak J Kashyap, Charless Fowlkes, Jeffrey L Krichmar", "title": "Sparse Representations for Object and Ego-motion Estimation in Dynamic\n  Scenes", "comments": "With supplementary material", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3006467", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic scenes that contain both object motion and egomotion are a challenge\nfor monocular visual odometry (VO). Another issue with monocular VO is the\nscale ambiguity, i.e. these methods cannot estimate scene depth and camera\nmotion in real scale. Here, we propose a learning based approach to predict\ncamera motion parameters directly from optic flow, by marginalizing depthmap\nvariations and outliers. This is achieved by learning a sparse overcomplete\nbasis set of egomotion in an autoencoder network, which is able to eliminate\nirrelevant components of optic flow for the task of camera parameter or\nmotionfield estimation. The model is trained using a sparsity regularizer and a\nsupervised egomotion loss, and achieves the state-of-the-art performances on\ntrajectory prediction and camera rotation prediction tasks on KITTI and Virtual\nKITTI datasets, respectively. The sparse latent space egomotion representation\nlearned by the model is robust and requires only 5% of the hidden layer neurons\nto maintain the best trajectory prediction accuracy on KITTI dataset.\nAdditionally, in presence of depth information, the proposed method\ndemonstrates faithful object velocity prediction for wide range of object sizes\nand speeds by global compensation of predicted egomotion and a divisive\nnormalization procedure.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 03:56:53 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Kashyap", "Hirak J", ""], ["Fowlkes", "Charless", ""], ["Krichmar", "Jeffrey L", ""]]}, {"id": "1903.03746", "submitter": "Gal Kaplun", "authors": "Dimitris Kalimeris and Gal Kaplun and Yaron Singer", "title": "Robust Influence Maximization for Hyperparametric Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of robust influence maximization in the\nindependent cascade model under a hyperparametric assumption. In social\nnetworks users influence and are influenced by individuals with similar\ncharacteristics and as such, they are associated with some features. A recent\nsurging research direction in influence maximization focuses on the case where\nthe edge probabilities on the graph are not arbitrary but are generated as a\nfunction of the features of the users and a global hyperparameter. We propose a\nmodel where the objective is to maximize the worst-case number of influenced\nusers for any possible value of that hyperparameter. We provide theoretical\nresults showing that proper robust solution in our model is NP-hard and an\nalgorithm that achieves improper robust optimization. We make-use of sampling\nbased techniques and of the renowned multiplicative weight updates algorithm.\nAdditionally, we validate our method empirically and prove that it outperforms\nthe state-of-the-art robust influence maximization techniques.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 06:23:11 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 00:32:44 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Kalimeris", "Dimitris", ""], ["Kaplun", "Gal", ""], ["Singer", "Yaron", ""]]}, {"id": "1903.03756", "submitter": "Yuan Tang", "authors": "Ying Tang", "title": "Two-Hop Walks Indicate PageRank Order", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that pairwise PageRank orders emerge from two-hop walks. The\nmain tool used here refers to a specially designed sign-mirror function and a\nparameter curve, whose low-order derivative information implies pairwise\nPageRank orders with high probability. We study the pairwise correct rate by\nplacing the Google matrix $\\textbf{G}$ in a probabilistic framework, where\n$\\textbf{G}$ may be equipped with different random ensembles for\nmodel-generated or real-world networks with sparse, small-world, scale-free\nfeatures, the proof of which is mixed by mathematical and numerical evidence.\nWe believe that the underlying spectral distribution of aforementioned networks\nis responsible for the high pairwise correct rate. Moreover, the perspective of\nthis paper naturally leads to an $O(1)$ algorithm for any single pairwise\nPageRank comparison if assuming both $\\textbf{A}=\\textbf{G}-\\textbf{I}_n$,\nwhere $\\textbf{I}_n$ denotes the identity matrix of order $n$, and\n$\\textbf{A}^2$ are ready on hand (e.g., constructed offline in an incremental\nmanner), based on which it is easy to extract the top $k$ list in $O(kn)$, thus\nmaking it possible for PageRank algorithm to deal with super large-scale\ndatasets in real time.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 07:54:10 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Tang", "Ying", ""]]}, {"id": "1903.03759", "submitter": "Zheqi Zhu", "authors": "Zheqi Zhu, Pingyi Fan", "title": "Machine Learning Based Prediction and Classification of Computational\n  Jobs in Cloud Computing Centers", "comments": null, "journal-ref": null, "doi": "10.1109/IWCMC.2019.8766558", "report-no": null, "categories": "cs.LG cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of the data volume and the fast increasing of the\ncomputational model complexity in the scenario of cloud computing, it becomes\nan important topic that how to handle users' requests by scheduling\ncomputational jobs and assigning the resources in data center.\n  In order to have a better perception of the computing jobs and their requests\nof resources, we analyze its characteristics and focus on the prediction and\nclassification of the computing jobs with some machine learning approaches.\nSpecifically, we apply LSTM neural network to predict the arrival of the jobs\nand the aggregated requests for computing resources. Then we evaluate it on\nGoogle Cluster dataset and it shows that the accuracy has been improved\ncompared to the current existing methods. Additionally, to have a better\nunderstanding of the computing jobs, we use an unsupervised hierarchical\nclustering algorithm, BIRCH, to make classification and get some\ninterpretability of our results in the computing centers.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 08:02:18 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Zhu", "Zheqi", ""], ["Fan", "Pingyi", ""]]}, {"id": "1903.03763", "submitter": "Pan Li", "authors": "Pan Li, Baihong Jin, Ruoxuan Xiong, Dai Wang, Alberto\n  Sangiovanni-Vincentelli, Baosen Zhang", "title": "A tractable ellipsoidal approximation for voltage regulation problems", "comments": "accepted by ACC2019 http://acc2019.a2c2.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine learning approach to the solution of chance constrained\noptimizations in the context of voltage regulation problems in power system\noperation. The novelty of our approach resides in approximating the feasible\nregion of uncertainty with an ellipsoid. We formulate this problem using a\nlearning model similar to Support Vector Machines (SVM) and propose a sampling\nalgorithm that efficiently trains the model. We demonstrate our approach on a\nvoltage regulation problem using standard IEEE distribution test feeders.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 08:32:32 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Li", "Pan", ""], ["Jin", "Baihong", ""], ["Xiong", "Ruoxuan", ""], ["Wang", "Dai", ""], ["Sangiovanni-Vincentelli", "Alberto", ""], ["Zhang", "Baosen", ""]]}, {"id": "1903.03768", "submitter": "Shangsheng Xie", "authors": "Shangsheng Xie, Mingming Lu", "title": "Interpreting and Understanding Graph Convolutional Neural Network using\n  Gradient-based Attribution Method", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve the problem that convolutional neural networks (CNNs) are difficult\nto process non-grid type relational data like graphs, Kipf et al. proposed a\ngraph convolutional neural network (GCN). The core idea of the GCN is to\nperform two-fold informational fusion for each node in a given graph during\neach iteration: the fusion of graph structure information and the fusion of\nnode feature dimensions. Because of the characteristic of the combinatorial\ngeneralizations, GCN has been widely used in the fields of scene semantic\nrelationship analysis, natural language processing and few-shot learning etc.\nHowever, due to its two-fold informational fusion involves mathematical\nirreversible calculations, it is hard to explain the decision reason for the\nprediction of the each node classification. Unfortunately, most of the existing\nattribution analysis methods concentrate on the models like CNNs, which are\nutilized to process grid-like data. It is difficult to apply those analysis\nmethods to the GCN directly. It is because compared with the independence among\nCNNs input data, there is correlation between the GCN input data. This\nresulting in the existing attribution analysis methods can only obtain the\npartial model contribution from the central node features to the final decision\nof the GCN, but ignores the other model contribution from central node features\nand its neighbor nodes features to that decision. To this end, we propose a\ngradient attribution analysis method for the GCN called Node Attribution Method\n(NAM), which can get the model contribution from not only the central node but\nalso its neighbor nodes to the GCN output. We also propose the Node Importance\nVisualization (NIV) method to visualize the central node and its neighbor nodes\nbased on the value of the contribution...\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 09:21:37 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 09:22:48 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Xie", "Shangsheng", ""], ["Lu", "Mingming", ""]]}, {"id": "1903.03784", "submitter": "Jiri Hron", "authors": "Mark Rowland and Jiri Hron and Yunhao Tang and Krzysztof Choromanski\n  and Tamas Sarlos and Adrian Weller", "title": "Orthogonal Estimation of Wasserstein Distances", "comments": "Published at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein distances are increasingly used in a wide variety of applications\nin machine learning. Sliced Wasserstein distances form an important subclass\nwhich may be estimated efficiently through one-dimensional sorting operations.\nIn this paper, we propose a new variant of sliced Wasserstein distance, study\nthe use of orthogonal coupling in Monte Carlo estimation of Wasserstein\ndistances and draw connections with stratified sampling, and evaluate our\napproaches experimentally in a range of large-scale experiments in generative\nmodelling and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 11:26:51 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 09:19:02 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Rowland", "Mark", ""], ["Hron", "Jiri", ""], ["Tang", "Yunhao", ""], ["Choromanski", "Krzysztof", ""], ["Sarlos", "Tamas", ""], ["Weller", "Adrian", ""]]}, {"id": "1903.03812", "submitter": "Kamanchi Chandramouli", "authors": "Chandramouli Kamanchi, Raghuram Bharadwaj Diddigi, Shalabh Bhatnagar", "title": "Successive Over Relaxation Q-Learning", "comments": null, "journal-ref": "IEEE Control Systems Letters 2019", "doi": "10.1109/LCSYS.2019.2921158", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a discounted reward Markov Decision Process (MDP), the objective is to\nfind the optimal value function, i.e., the value function corresponding to an\noptimal policy. This problem reduces to solving a functional equation known as\nthe Bellman equation and a fixed point iteration scheme known as the value\niteration is utilized to obtain the solution. In literature, a successive\nover-relaxation based value iteration scheme is proposed to speed-up the\ncomputation of the optimal value function. The speed-up is achieved by\nconstructing a modified Bellman equation that ensures faster convergence to the\noptimal value function. However, in many practical applications, the model\ninformation is not known and we resort to Reinforcement Learning (RL)\nalgorithms to obtain optimal policy and value function. One such popular\nalgorithm is Q-learning. In this paper, we propose Successive Over-Relaxation\n(SOR) Q-learning. We first derive a modified fixed point iteration for SOR\nQ-values and utilize stochastic approximation to derive a learning algorithm to\ncompute the optimal value function and an optimal policy. We then prove the\nalmost sure convergence of the SOR Q-learning to SOR Q-values. Finally, through\nnumerical experiments, we show that SOR Q-learning is faster compared to the\nstandard Q-learning algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 15:03:18 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 18:38:53 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 18:49:22 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Kamanchi", "Chandramouli", ""], ["Diddigi", "Raghuram Bharadwaj", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1903.03825", "submitter": "Vikas Verma", "authors": "Vikas Verma, Kenji Kawaguchi, Alex Lamb, Juho Kannala, Yoshua Bengio,\n  David Lopez-Paz", "title": "Interpolation Consistency Training for Semi-Supervised Learning", "comments": "Extended version of IJCAI 2019 paper. Semi-supervised Learning, Deep\n  Learning, Neural Networks. All the previous results are unchanged; we added\n  new theoretical and empirical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Interpolation Consistency Training (ICT), a simple and\ncomputation efficient algorithm for training Deep Neural Networks in the\nsemi-supervised learning paradigm. ICT encourages the prediction at an\ninterpolation of unlabeled points to be consistent with the interpolation of\nthe predictions at those points. In classification problems, ICT moves the\ndecision boundary to low-density regions of the data distribution. Our\nexperiments show that ICT achieves state-of-the-art performance when applied to\nstandard neural network architectures on the CIFAR-10 and SVHN benchmark\ndatasets. Our theoretical analysis shows that ICT corresponds to a certain type\nof data-adaptive regularization with unlabeled points which reduces overfitting\nto labeled points under high confidence values.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 16:39:22 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 17:46:54 GMT"}, {"version": "v3", "created": "Sun, 19 May 2019 05:00:06 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2020 15:31:56 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Verma", "Vikas", ""], ["Kawaguchi", "Kenji", ""], ["Lamb", "Alex", ""], ["Kannala", "Juho", ""], ["Bengio", "Yoshua", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1903.03850", "submitter": "Ashkan Panahi", "authors": "Ashkan Panahi, Arman Rahbar, Morteza Haghir Chehreghani, Devdatt\n  Dubhashi", "title": "Stochastic Proximal Algorithms with SON Regularization: Towards\n  Efficient Optimal Transport for Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new regularizer for optimal transport (OT) which is tailored to\nbetter preserve the class structure of the subjected process. Accordingly, we\nprovide the first theoretical guarantees for an OT scheme that respects class\nstructure. We derive an accelerated proximal algorithm with a closed form\nprojection and proximal operator scheme thereby affording a highly scalable\nalgorithm for computing optimal transport plans. We provide a novel argument\nfor the uniqueness of the optimum even in the absence of strong convexity.Our\nexperiments show that the new regularizer does not only result in a better\npreservation of the class structure but also in additional robustness relative\nto previous regularizers.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 18:54:21 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 11:34:03 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Panahi", "Ashkan", ""], ["Rahbar", "Arman", ""], ["Chehreghani", "Morteza Haghir", ""], ["Dubhashi", "Devdatt", ""]]}, {"id": "1903.03867", "submitter": "Raed Al Kontar", "authors": "Xubo Yue, Raed Kontar", "title": "Variational Inference of Joint Models using Multivariate Gaussian\n  Convolution Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a non-parametric prognostic framework for individualized event\nprediction based on joint modeling of both longitudinal and time-to-event data.\nOur approach exploits a multivariate Gaussian convolution process (MGCP) to\nmodel the evolution of longitudinal signals and a Cox model to map\ntime-to-event data with longitudinal data modeled through the MGCP. Taking\nadvantage of the unique structure imposed by convolved processes, we provide a\nvariational inference framework to simultaneously estimate parameters in the\njoint MGCP-Cox model. This significantly reduces computational complexity and\nsafeguards against model overfitting. Experiments on synthetic and real world\ndata show that the proposed framework outperforms state-of-the art approaches\nbuilt on two-stage inference and strong parametric assumptions.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 20:41:13 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Yue", "Xubo", ""], ["Kontar", "Raed", ""]]}, {"id": "1903.03871", "submitter": "Raed Al Kontar", "authors": "Seokhyun Chung, Raed Kontar", "title": "Functional Principal Component Analysis for Extrapolating Multi-stream\n  Longitudinal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advance of modern sensor technologies enables collection of multi-stream\nlongitudinal data where multiple signals from different units are collected in\nreal-time. In this article, we present a non-parametric approach to predict the\nevolution of multi-stream longitudinal data for an in-service unit through\nborrowing strength from other historical units. Our approach first decomposes\neach stream into a linear combination of eigenfunctions and their corresponding\nfunctional principal component (FPC) scores. A Gaussian process prior for the\nFPC scores is then established based on a functional semi-metric that measures\nsimilarities between streams of historical units and the in-service unit.\nFinally, an empirical Bayesian updating strategy is derived to update the\nestablished prior using real-time stream data obtained from the in-service\nunit. Experiments on synthetic and real world data show that the proposed\nframework outperforms state-of-the-art approaches and can effectively account\nfor heterogeneity as well as achieve high predictive accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 21:22:54 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Chung", "Seokhyun", ""], ["Kontar", "Raed", ""]]}, {"id": "1903.03878", "submitter": "Kuan Fang", "authors": "Kuan Fang, Alexander Toshev, Li Fei-Fei, Silvio Savarese", "title": "Scene Memory Transformer for Embodied Agents in Long-Horizon Tasks", "comments": "CVPR 2019 paper with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many robotic applications require the agent to perform long-horizon tasks in\npartially observable environments. In such applications, decision making at any\nstep can depend on observations received far in the past. Hence, being able to\nproperly memorize and utilize the long-term history is crucial. In this work,\nwe propose a novel memory-based policy, named Scene Memory Transformer (SMT).\nThe proposed policy embeds and adds each observation to a memory and uses the\nattention mechanism to exploit spatio-temporal dependencies. This model is\ngeneric and can be efficiently trained with reinforcement learning over long\nepisodes. On a range of visual navigation tasks, SMT demonstrates superior\nperformance to existing reactive and memory-based policies by a margin.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 22:03:02 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Fang", "Kuan", ""], ["Toshev", "Alexander", ""], ["Fei-Fei", "Li", ""], ["Savarese", "Silvio", ""]]}, {"id": "1903.03891", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Felix H\\\"ulsmann, Mario Botsch, Barbara Hammer", "title": "Non-Negative Kernel Sparse Coding for the Classification of Motion Data", "comments": "8 pages, ICANN 2016 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the decomposition of motion data into a sparse linear\ncombination of base functions which enable efficient data processing. We\ncombine two prominent frameworks: dynamic time warping (DTW), which offers\nparticularly successful pairwise motion data comparison, and sparse coding\n(SC), which enables an automatic decomposition of vectorial data into a sparse\nlinear combination of base vectors. We enhance SC as follows: an efficient\nkernelization which extends its application domain to general similarity data\nsuch as offered by DTW, and its restriction to non-negative linear\nrepresentations of signals and base vectors in order to guarantee a meaningful\ndictionary. Empirical evaluations on motion capture benchmarks show the\neffectiveness of our framework regarding interpretation and discrimination\nconcerns.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 00:45:05 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 10:00:39 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Hosseini", "Babak", ""], ["H\u00fclsmann", "Felix", ""], ["Botsch", "Mario", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.03893", "submitter": "Bin Wang", "authors": "Bin Wang, Yanan Sun, Bing Xue, Mengjie Zhang", "title": "A Hybrid GA-PSO Method for Evolving Architecture and Short Connections\n  of Deep Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification is a difficult machine learning task, where\nConvolutional Neural Networks (CNNs) have been applied for over 20 years in\norder to solve the problem. In recent years, instead of the traditional way of\nonly connecting the current layer with its next layer, shortcut connections\nhave been proposed to connect the current layer with its forward layers apart\nfrom its next layer, which has been proved to be able to facilitate the\ntraining process of deep CNNs. However, there are various ways to build the\nshortcut connections, it is hard to manually design the best shortcut\nconnections when solving a particular problem, especially given the design of\nthe network architecture is already very challenging.\n  In this paper, a hybrid evolutionary computation (EC) method is proposed to\n\\textit{automatically} evolve both the architecture of deep CNNs and the\nshortcut connections. Three major contributions of this work are: Firstly, a\nnew encoding strategy is proposed to encode a CNN, where the architecture and\nthe shortcut connections are encoded separately; Secondly, a hybrid two-level\nEC method, which combines particle swarm optimisation and genetic algorithms,\nis developed to search for the optimal CNNs; Lastly, an adjustable learning\nrate is introduced for the fitness evaluations, which provides a better\nlearning rate for the training process given a fixed number of epochs. The\nproposed algorithm is evaluated on three widely used benchmark datasets of\nimage classification and compared with 12 peer Non-EC based competitors and one\nEC based competitor. The experimental results demonstrate that the proposed\nmethod outperforms all of the peer competitors in terms of classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 00:51:19 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Bin", ""], ["Sun", "Yanan", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1903.03894", "submitter": "Rex Ying", "authors": "Rex Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, Jure Leskovec", "title": "GNNExplainer: Generating Explanations for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are a powerful tool for machine learning on\ngraphs.GNNs combine node feature information with the graph structure by\nrecursively passing neural messages along edges of the input graph. However,\nincorporating both graph structure and feature information leads to complex\nmodels, and explaining predictions made by GNNs remains unsolved. Here we\npropose GNNExplainer, the first general, model-agnostic approach for providing\ninterpretable explanations for predictions of any GNN-based model on any\ngraph-based machine learning task. Given an instance, GNNExplainer identifies a\ncompact subgraph structure and a small subset of node features that have a\ncrucial role in GNN's prediction. Further, GNNExplainer can generate consistent\nand concise explanations for an entire class of instances. We formulate\nGNNExplainer as an optimization task that maximizes the mutual information\nbetween a GNN's prediction and distribution of possible subgraph structures.\nExperiments on synthetic and real-world graphs show that our approach can\nidentify important graph structures as well as node features, and outperforms\nbaselines by 17.1% on average. GNNExplainer provides a variety of benefits,\nfrom the ability to visualize semantically relevant structures to\ninterpretability, to giving insights into errors of faulty GNNs.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 00:56:26 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 22:53:52 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 19:08:14 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2019 22:36:57 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Ying", "Rex", ""], ["Bourgeois", "Dylan", ""], ["You", "Jiaxuan", ""], ["Zitnik", "Marinka", ""], ["Leskovec", "Jure", ""]]}, {"id": "1903.03905", "submitter": "Ousmane Dia", "authors": "Ousmane Amadou Dia, Elnaz Barshan, Reza Babanezhad", "title": "Semantics Preserving Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While progress has been made in crafting visually imperceptible adversarial\nexamples, constructing semantically meaningful ones remains a challenge. In\nthis paper, we propose a framework to generate semantics preserving adversarial\nexamples. First, we present a manifold learning method to capture the semantics\nof the inputs. The motivating principle is to learn the low-dimensional\ngeometric summaries of the inputs via statistical inference. Then, we perturb\nthe elements of the learned manifold using the Gram-Schmidt process to induce\nthe perturbed elements to remain in the manifold. To produce adversarial\nexamples, we propose an efficient algorithm whereby we leverage the semantics\nof the inputs as a source of knowledge upon which we impose adversarial\nconstraints. We apply our approach on toy data, images and text, and show its\neffectiveness in producing semantics preserving adversarial examples which\nevade existing defenses against adversarial attacks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 02:48:46 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 02:09:39 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 03:25:33 GMT"}, {"version": "v4", "created": "Sun, 26 May 2019 00:04:52 GMT"}, {"version": "v5", "created": "Sat, 21 Dec 2019 13:02:43 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dia", "Ousmane Amadou", ""], ["Barshan", "Elnaz", ""], ["Babanezhad", "Reza", ""]]}, {"id": "1903.03906", "submitter": "Xuhui Fan", "authors": "Xuhui Fan and Bin Li and Scott Anthony Sisson", "title": "Rectangular Bounding Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic partition models divide a multi-dimensional space into a number of\nrectangular regions, such that the data within each region exhibit certain\ntypes of homogeneity. Due to the nature of their partition strategy, existing\npartition models may create many unnecessary divisions in sparse regions when\ntrying to describe data in dense regions. To avoid this problem we introduce a\nnew parsimonious partition model -- the Rectangular Bounding Process (RBP) --\nto efficiently partition multi-dimensional spaces, by employing a bounding\nstrategy to enclose data points within rectangular bounding boxes. Unlike\nexisting approaches, the RBP possesses several attractive theoretical\nproperties that make it a powerful nonparametric partition prior on a\nhypercube. In particular, the RBP is self-consistent and as such can be\ndirectly extended from a finite hypercube to infinite (unbounded) space. We\napply the RBP to regression trees and relational models as a flexible partition\nprior. The experimental results validate the merit of the RBP {in rich yet\nparsimonious expressiveness} compared to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 02:52:32 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott Anthony", ""]]}, {"id": "1903.03910", "submitter": "Ashkan Rezaei", "authors": "Ashkan Rezaei, Rizal Fathony, Omid Memarrast, Brian Ziebart", "title": "Fairness for Robust Log Loss Classification", "comments": null, "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence\n  (2020), Vol 34 No 04: AAAI-20 Technical Tracks 4", "doi": "10.1609/aaai.v34i04.6002", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing classification methods with high accuracy that also avoid unfair\ntreatment of different groups has become increasingly important for data-driven\ndecision making in social applications. Many existing methods enforce fairness\nconstraints on a selected classifier (e.g., logistic regression) by directly\nforming constrained optimizations. We instead re-derive a new classifier from\nthe first principles of distributional robustness that incorporates fairness\ncriteria into a worst-case logarithmic loss minimization. This construction\ntakes the form of a minimax game and produces a parametric exponential family\nconditional distribution that resembles truncated logistic regression. We\npresent the theoretical benefits of our approach in terms of its convexity and\nasymptotic convergence. We then demonstrate the practical advantages of our\napproach on three benchmark fairness datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 03:18:33 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 07:34:33 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 19:22:37 GMT"}, {"version": "v4", "created": "Wed, 14 Oct 2020 04:36:21 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Rezaei", "Ashkan", ""], ["Fathony", "Rizal", ""], ["Memarrast", "Omid", ""], ["Ziebart", "Brian", ""]]}, {"id": "1903.03927", "submitter": "Satyananda Kashyap", "authors": "Satyananda Kashyap, Honghai Zhang, Karan Rao, Milan Sonka", "title": "Learning-Based Cost Functions for 3D and 4D Multi-Surface Multi-Object\n  Segmentation of Knee MRI: Data from the Osteoarthritis Initiative", "comments": "IEEE Transactions in Medical Imaging, 11 pages", "journal-ref": "Published in: IEEE Transactions on Medical Imaging ( Volume: 37 ,\n  Issue: 5 , May 2018 )", "doi": "10.1109/TMI.2017.2781541", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fully automated knee MRI segmentation method to study osteoarthritis (OA)\nwas developed using a novel hierarchical set of random forests (RF) classifiers\nto learn the appearance of cartilage regions and their boundaries. A\nneighborhood approximation forest is used first to provide contextual feature\nto the second-level RF classifier that also considers local features and\nproduces location-specific costs for the layered optimal graph image\nsegmentation of multiple objects and surfaces (LOGISMOS) framework. Double echo\nsteady state (DESS) MRIs used in this work originated from the Osteoarthritis\nInitiative (OAI) study. Trained on 34 MRIs with varying degrees of OA, the\nperformance of the learning-based method tested on 108 MRIs showed a\nsignificant reduction in segmentation errors (\\emph{p}$<$0.05) compared with\nthe conventional gradient-based and single-stage RF-learned costs. The 3D\nLOGISMOS was extended to longitudinal-3D (4D) to simultaneously segment\nmultiple follow-up visits of the same patient. As such, data from all\ntime-points of the temporal sequence contribute information to a single optimal\nsolution that utilizes both spatial 3D and temporal contexts. 4D LOGISMOS\nvalidation on 108 MRIs from baseline and 12 month follow-up scans of 54\npatients showed a significant reduction in segmentation errors\n(\\emph{p}$<$0.01) compared to 3D. Finally, the potential of 4D LOGISMOS was\nfurther explored on the same 54 patients using 5 annual follow-up scans\ndemonstrating a significant improvement of measuring cartilage thickness\n(\\emph{p}$<$0.01) compared to the sequential 3D approach.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 05:48:53 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kashyap", "Satyananda", ""], ["Zhang", "Honghai", ""], ["Rao", "Karan", ""], ["Sonka", "Milan", ""]]}, {"id": "1903.03929", "submitter": "Satyananda Kashyap", "authors": "Satyananda Kashyap, Ipek Oguz, Honghai Zhang, Milan Sonka", "title": "Automated Segmentation of Knee MRI Using Hierarchical Classifiers and\n  Just Enough Interaction Based Learning: Data from Osteoarthritis Initiative", "comments": "KEYWORDS: Graph based segmentation; Just enough interaction;\n  LOGISMOS; Neighborhood approximation forests; Osteoarthritis; Random forest\n  classifier; knee MRI PMID: 28626842 PMCID: PMC5471813", "journal-ref": "Med Image Comput Comput Assist Interv. 2016 Oct;9901:344-351. doi:\n  10.1007/978-3-319-46723-8_40. Epub 2016 Oct 2", "doi": "10.1007/978-3-319-46723-8_40", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fully automated learning-based approach for segmenting knee\ncartilage in the presence of osteoarthritis (OA). The algorithm employs a\nhierarchical set of two random forest classifiers. The first is a neighborhood\napproximation forest, the output probability map of which is utilized as a\nfeature set for the second random forest (RF) classifier. The output\nprobabilities of the hierarchical approach are used as cost functions in a\nLayered Optimal Graph Segmentation of Multiple Objects and Surfaces (LOGISMOS).\nIn this work, we highlight a novel post-processing interaction called\njust-enough interaction (JEI) which enables quick and accurate generation of a\nlarge set of training examples. Disjoint sets of 15 and 13 subjects were used\nfor training and tested on another disjoint set of 53 knee datasets. All images\nwere acquired using a double echo steady state (DESS) MRI sequence and are from\nthe osteoarthritis initiative (OAI) database. Segmentation performance using\nthe learning-based cost function showed significant reduction in segmentation\nerrors ($p< 0.05$) in comparison with conventional gradient-based cost\nfunctions.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 06:01:23 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kashyap", "Satyananda", ""], ["Oguz", "Ipek", ""], ["Zhang", "Honghai", ""], ["Sonka", "Milan", ""]]}, {"id": "1903.03934", "submitter": "Cong Xie", "authors": "Cong Xie, Sanmi Koyejo, Indranil Gupta", "title": "Asynchronous Federated Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables training on a massive number of edge devices. To\nimprove flexibility and scalability, we propose a new asynchronous federated\noptimization algorithm. We prove that the proposed approach has near-linear\nconvergence to a global optimum, for both strongly convex and a restricted\nfamily of non-convex problems. Empirical results show that the proposed\nalgorithm converges quickly and tolerates staleness in various applications.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 06:19:38 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 14:19:49 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 05:17:39 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2019 21:54:02 GMT"}, {"version": "v5", "created": "Sat, 5 Dec 2020 01:33:57 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Xie", "Cong", ""], ["Koyejo", "Sanmi", ""], ["Gupta", "Indranil", ""]]}, {"id": "1903.03936", "submitter": "Cong Xie", "authors": "Cong Xie, Sanmi Koyejo, Indranil Gupta", "title": "Fall of Empires: Breaking Byzantine-tolerant SGD by Inner Product\n  Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, new defense techniques have been developed to tolerate Byzantine\nfailures for distributed machine learning. The Byzantine model captures workers\nthat behave arbitrarily, including malicious and compromised workers. In this\npaper, we break two prevailing Byzantine-tolerant techniques. Specifically we\nshow robust aggregation methods for synchronous SGD -- coordinate-wise median\nand Krum -- can be broken using new attack strategies based on inner product\nmanipulation. We prove our results theoretically, as well as show empirical\nvalidation.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 06:26:01 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Xie", "Cong", ""], ["Koyejo", "Sanmi", ""], ["Gupta", "Indranil", ""]]}, {"id": "1903.03971", "submitter": "Yoshiki Masuyama", "authors": "Yoshiki Masuyama, Kohei Yatabe, Yuma Koizumi, Yasuhiro Oikawa, Noboru\n  Harada", "title": "Deep Griffin-Lim Iteration", "comments": "5 pages, to appear in IEEE ICASSP 2019 (Paper Code: AASP-L3.1,\n  Session: Source Separation and Speech Enhancement I)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel phase reconstruction method (only from a given\namplitude spectrogram) by combining a signal-processing-based approach and a\ndeep neural network (DNN). To retrieve a time-domain signal from its amplitude\nspectrogram, the corresponding phase is required. One of the popular phase\nreconstruction methods is the Griffin-Lim algorithm (GLA), which is based on\nthe redundancy of the short-time Fourier transform. However, GLA often involves\nmany iterations and produces low-quality signals owing to the lack of prior\nknowledge of the target signal. In order to address these issues, in this\nstudy, we propose an architecture which stacks a sub-block including two\nGLA-inspired fixed layers and a DNN. The number of stacked sub-blocks is\nadjustable, and we can trade the performance and computational load based on\nrequirements of applications. The effectiveness of the proposed method is\ninvestigated by reconstructing phases from amplitude spectrograms of speeches.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 11:27:34 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Masuyama", "Yoshiki", ""], ["Yatabe", "Kohei", ""], ["Koizumi", "Yuma", ""], ["Oikawa", "Yasuhiro", ""], ["Harada", "Noboru", ""]]}, {"id": "1903.03986", "submitter": "Edwin Bonilla", "authors": "Astrid Dahl, Edwin V. Bonilla", "title": "Scalable Grouped Gaussian Processes via Direct Cholesky Functional\n  Representations", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-task regression models where observations are assumed to be\na linear combination of several latent node and weight functions, all drawn\nfrom Gaussian process (GP) priors that allow nonzero covariance between grouped\nlatent functions. We show that when these grouped functions are conditionally\nindependent given a group-dependent pivot, it is possible to parameterize the\nprior through sparse Cholesky factors directly, hence avoiding their\ncomputation during inference. Furthermore, we establish that kernels that are\nmultiplicatively separable over input points give rise to such sparse\nparameterizations naturally without any additional assumptions. Finally, we\nextend the use of these sparse structures to approximate posteriors within\nvariational inference, further improving scalability on the number of\nfunctions. We test our approach on multi-task datasets concerning distributed\nsolar forecasting and show that it outperforms several multi-task GP baselines\nand that our sparse specifications achieve the same or better accuracy than\nnon-sparse counterparts.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 13:20:16 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 06:06:13 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Dahl", "Astrid", ""], ["Bonilla", "Edwin V.", ""]]}, {"id": "1903.03989", "submitter": "Weiqi Ji", "authors": "Weiqi Ji, Zhuyin Ren and Chung K. Law", "title": "Uncertainty Propagation in Deep Neural Network Using Active Subspace", "comments": "Add link to github repo", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inputs of deep neural network (DNN) from real-world data usually come\nwith uncertainties. Yet, it is challenging to propagate the uncertainty in the\ninput features to the DNN predictions at a low computational cost. This work\nemploys a gradient-based subspace method and response surface technique to\naccelerate the uncertainty propagation in DNN. Specifically, the active\nsubspace method is employed to identify the most important subspace in the\ninput features using the gradient of the DNN output to the inputs. Then the\nresponse surface within that low-dimensional subspace can be efficiently built,\nand the uncertainty of the prediction can be acquired by evaluating the\ncomputationally cheap response surface instead of the DNN models. In addition,\nthe subspace can help explain the adversarial examples. The approach is\ndemonstrated in MNIST datasets with a convolutional neural network. Code is\navailable at: https://github.com/jiweiqi/nnsubspace.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 13:38:43 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 22:34:28 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ji", "Weiqi", ""], ["Ren", "Zhuyin", ""], ["Law", "Chung K.", ""]]}, {"id": "1903.04003", "submitter": "Yiming Li", "authors": "Yiming Li, Jiawang Bai, Jiawei Li, Xue Yang, Yong Jiang, Chun Li,\n  Shutao Xia", "title": "Multinomial Random Forest: Toward Consistency and Privacy-Preservation", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the impressive performance of random forests (RF), its theoretical\nproperties have not been thoroughly understood. In this paper, we propose a\nnovel RF framework, dubbed multinomial random forest (MRF), to analyze the\n\\emph{consistency} and \\emph{privacy-preservation}. Instead of deterministic\ngreedy split rule or with simple randomness, the MRF adopts two impurity-based\nmultinomial distributions to randomly select a split feature and a split value\nrespectively. Theoretically, we prove the consistency of the proposed MRF and\nanalyze its privacy-preservation within the framework of differential privacy.\nWe also demonstrate with multiple datasets that its performance is on par with\nthe standard RF. To the best of our knowledge, MRF is the first consistent RF\nvariant that has comparable performance to the standard RF.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 14:47:16 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 15:00:22 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 13:35:28 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Li", "Yiming", ""], ["Bai", "Jiawang", ""], ["Li", "Jiawei", ""], ["Yang", "Xue", ""], ["Jiang", "Yong", ""], ["Li", "Chun", ""], ["Xia", "Shutao", ""]]}, {"id": "1903.04012", "submitter": "David Kirkpatrick", "authors": "David Kirkpatrick, Hans U. Simon, Sandra Zilles", "title": "Optimal Collusion-Free Teaching", "comments": "26 pages and 6 figures. This is an expanded version of a similarly\n  titled paper to appear in Proceedings of Machine Learning Research (ALT\n  2019), vol. 98, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal models of learning from teachers need to respect certain criteria to\navoid collusion. The most commonly accepted notion of collusion-freeness was\nproposed by Goldman and Mathias (1996), and various teaching models obeying\ntheir criterion have been studied. For each model $M$ and each concept class\n$\\mathcal{C}$, a parameter $M$-$\\mathrm{TD}(\\mathcal{C})$ refers to the\nteaching dimension of concept class $\\mathcal{C}$ in model $M$---defined to be\nthe number of examples required for teaching a concept, in the worst case over\nall concepts in $\\mathcal{C}$.\n  This paper introduces a new model of teaching, called no-clash teaching,\ntogether with the corresponding parameter $\\mathrm{NCTD}(\\mathcal{C})$.\nNo-clash teaching is provably optimal in the strong sense that, given any\nconcept class $\\mathcal{C}$ and any model $M$ obeying Goldman and Mathias's\ncollusion-freeness criterion, one obtains $\\mathrm{NCTD}(\\mathcal{C})\\le\nM$-$\\mathrm{TD}(\\mathcal{C})$. We also study a corresponding notion\n$\\mathrm{NCTD}^+$ for the case of learning from positive data only, establish\nuseful bounds on $\\mathrm{NCTD}$ and $\\mathrm{NCTD}^+$, and discuss relations\nof these parameters to the VC-dimension and to sample compression.\n  In addition to formulating an optimal model of collusion-free teaching, our\nmain results are on the computational complexity of deciding whether\n$\\mathrm{NCTD}^+(\\mathcal{C})=k$ (or $\\mathrm{NCTD}(\\mathcal{C})=k$) for given\n$\\mathcal{C}$ and $k$. We show some such decision problems to be equivalent to\nthe existence question for certain constrained matchings in bipartite graphs.\nOur NP-hardness results for the latter are of independent interest in the study\nof constrained graph matchings.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 15:23:05 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kirkpatrick", "David", ""], ["Simon", "Hans U.", ""], ["Zilles", "Sandra", ""]]}, {"id": "1903.04016", "submitter": "Yu Chen", "authors": "Yu Chen and Telmo Silva Filho and Ricardo B. C. Prud\\^encio and Tom\n  Diethe and Peter Flach", "title": "$\\beta^3$-IRT: A New Item Response Model and its Applications", "comments": null, "journal-ref": "AISTATS 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item Response Theory (IRT) aims to assess latent abilities of respondents\nbased on the correctness of their answers in aptitude test items with different\ndifficulty levels. In this paper, we propose the $\\beta^3$-IRT model, which\nmodels continuous responses and can generate a much enriched family of Item\nCharacteristic Curve (ICC). In experiments we applied the proposed model to\ndata from an online exam platform, and show our model outperforms a more\nstandard 2PL-ND model on all datasets. Furthermore, we show how to apply\n$\\beta^3$-IRT to assess the ability of machine learning classifiers. This novel\napplication results in a new metric for evaluating the quality of the\nclassifier's probability estimates, based on the inferred difficulty and\ndiscrimination of data instances.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 16:06:50 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 11:09:51 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 16:07:12 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Chen", "Yu", ""], ["Filho", "Telmo Silva", ""], ["Prud\u00eancio", "Ricardo B. C.", ""], ["Diethe", "Tom", ""], ["Flach", "Peter", ""]]}, {"id": "1903.04042", "submitter": "Ga\\\"el Beck", "authors": "Andriantsiory Dina Faneva, Mustapha Lebbah, Hanane Azzag, Ga\\\"el Beck", "title": "Algorithms for an Efficient Tensor Biclustering", "comments": "Algorithms available on Clustering4Ever github,\n  https://github.com/Clustering4Ever/Clustering4Ever", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a data set collected by (individuals-features) pairs in different\ntimes. It can be represented as a tensor of three dimensions (Individuals,\nfeatures and times). The tensor biclustering problem computes a subset of\nindividuals and a subset of features whose signal trajectories over time lie in\na low-dimensional subspace, modeling similarity among the signal trajectories\nwhile allowing different scalings across different individuals or different\nfeatures. This approach are based on spectral decomposition in order to build\nthe desired biclusters. We evaluate the quality of the results from each\nalgorithms with both synthetic and real data set.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 18:56:14 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Faneva", "Andriantsiory Dina", ""], ["Lebbah", "Mustapha", ""], ["Azzag", "Hanane", ""], ["Beck", "Ga\u00ebl", ""]]}, {"id": "1903.04053", "submitter": "Aleksi H\\\"am\\\"al\\\"ainen", "authors": "Aleksi H\\\"am\\\"al\\\"ainen, Karol Arndt, Ali Ghadirzadeh and Ville Kyrki", "title": "Affordance Learning for End-to-End Visuomotor Robot Control", "comments": "7 pages, 7 figures. Submitted to 2019 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training end-to-end deep robot policies requires a lot of domain-, task-, and\nhardware-specific data, which is often costly to provide. In this work, we\npropose to tackle this issue by employing a deep neural network with a modular\narchitecture, consisting of separate perception, policy, and trajectory parts.\nEach part of the system is trained fully on synthetic data or in simulation.\nThe data is exchanged between parts of the system as low-dimensional latent\nrepresentations of affordances and trajectories. The performance is then\nevaluated in a zero-shot transfer scenario using Franka Panda robot arm.\nResults demonstrate that a low-dimensional representation of scene affordances\nextracted from an RGB image is sufficient to successfully train manipulator\npolicies. We also introduce a method for affordance dataset generation, which\nis easily generalizable to new tasks, objects and environments, and requires no\nmanual pixel labeling.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 20:16:45 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Aleksi", ""], ["Arndt", "Karol", ""], ["Ghadirzadeh", "Ali", ""], ["Kyrki", "Ville", ""]]}, {"id": "1903.04056", "submitter": "Eric Kightley", "authors": "Eric Kightley and Stephen Becker", "title": "One-Pass Sparsified Gaussian Mixtures", "comments": "submitted to IEEE DSW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a one-pass sparsified Gaussian mixture model (SGMM). Given $N$\ndata points in $P$ dimensions, $X$, the model fits $K$ Gaussian distributions\nto $X$ and (softly) classifies each point to these clusters. After paying an\nup-front cost of $\\mathcal{O}(NP\\log P)$ to precondition the data, we subsample\n$Q$ entries of each data point and discard the full $P$-dimensional data. SGMM\noperates in $\\mathcal{O}(KNQ)$ time per iteration for diagonal or spherical\ncovariances, independent of $P$, while estimating the model parameters in the\nfull $P$-dimensional space, making it one-pass and hence suitable for streaming\ndata. We derive the maximum likelihood estimators for the parameters in the\nsparsified regime, demonstrate clustering on synthetic and real data, and show\nthat SGMM is faster than GMM while preserving accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 20:40:02 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 22:14:30 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Kightley", "Eric", ""], ["Becker", "Stephen", ""]]}, {"id": "1903.04057", "submitter": "Gilles Louppe", "authors": "Joeri Hermans, Volodimir Begy, Gilles Louppe", "title": "Likelihood-free MCMC with Amortized Approximate Ratio Estimators", "comments": "v5: Camera-ready version presented at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Posterior inference with an intractable likelihood is becoming an\nincreasingly common task in scientific domains which rely on sophisticated\ncomputer simulations. Typically, these forward models do not admit tractable\ndensities forcing practitioners to make use of approximations. This work\nintroduces a novel approach to address the intractability of the likelihood and\nthe marginal model. We achieve this by learning a flexible amortized estimator\nwhich approximates the likelihood-to-evidence ratio. We demonstrate that the\nlearned ratio estimator can be embedded in MCMC samplers to approximate\nlikelihood-ratios between consecutive states in the Markov chain, allowing us\nto draw samples from the intractable posterior. Techniques are presented to\nimprove the numerical stability and to measure the quality of an approximation.\nThe accuracy of our approach is demonstrated on a variety of benchmarks against\nwell-established techniques. Scientific applications in physics show its\napplicability.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 20:51:02 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 13:06:38 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 08:29:11 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 16:57:52 GMT"}, {"version": "v5", "created": "Fri, 26 Jun 2020 08:15:43 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Hermans", "Joeri", ""], ["Begy", "Volodimir", ""], ["Louppe", "Gilles", ""]]}, {"id": "1903.04064", "submitter": "Chen-Yu Lee", "authors": "Chen-Yu Lee, Tanmay Batra, Mohammad Haris Baig, Daniel Ulbricht", "title": "Sliced Wasserstein Discrepancy for Unsupervised Domain Adaptation", "comments": "Accepted at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we connect two distinct concepts for unsupervised domain\nadaptation: feature distribution alignment between domains by utilizing the\ntask-specific decision boundary and the Wasserstein metric. Our proposed sliced\nWasserstein discrepancy (SWD) is designed to capture the natural notion of\ndissimilarity between the outputs of task-specific classifiers. It provides a\ngeometrically meaningful guidance to detect target samples that are far from\nthe support of the source and enables efficient distribution alignment in an\nend-to-end trainable fashion. In the experiments, we validate the effectiveness\nand genericness of our method on digit and sign recognition, image\nclassification, semantic segmentation, and object detection.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 21:56:45 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Lee", "Chen-Yu", ""], ["Batra", "Tanmay", ""], ["Baig", "Mohammad Haris", ""], ["Ulbricht", "Daniel", ""]]}, {"id": "1903.04101", "submitter": "Chun Kai Ling", "authors": "Chun Kai Ling, Fei Fang, J. Zico Kolter", "title": "Large Scale Learning of Agent Rationality in Two-Player Zero-Sum Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advances in solving large, zero-sum extensive form games,\nthere is a growing interest in the inverse problem of inferring underlying game\nparameters given only access to agent actions. Although a recent work provides\na powerful differentiable end-to-end learning frameworks which embed a game\nsolver within a deep-learning framework, allowing unknown game parameters to be\nlearned via backpropagation, this framework faces significant limitations when\napplied to boundedly rational human agents and large scale problems, leading to\npoor practicality. In this paper, we address these limitations and propose a\nframework that is applicable for more practical settings. First, seeking to\nlearn the rationality of human agents in complex two-player zero-sum games, we\ndraw upon well-known ideas in decision theory to obtain a concise and\ninterpretable agent behavior model, and derive solvers and gradients for\nend-to-end learning. Second, to scale up to large, real-world scenarios, we\npropose an efficient first-order primal-dual method which exploits the\nstructure of extensive-form games, yielding significantly faster computation\nfor both game solving and gradient computation. When tested on randomly\ngenerated games, we report speedups of orders of magnitude over previous\napproaches. We also demonstrate the effectiveness of our model on both\nreal-world one-player settings and synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 02:15:02 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Ling", "Chun Kai", ""], ["Fang", "Fei", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1903.04110", "submitter": "Xiaoxiao Guo", "authors": "Xiaoxiao Guo, Shiyu Chang, Mo Yu, Gerald Tesauro, Murray Campbell", "title": "Hybrid Reinforcement Learning with Expert State Sequences", "comments": "AAAI 2019; https://github.com/XiaoxiaoGuo/tensor4rl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing imitation learning approaches often require that the complete\ndemonstration data, including sequences of actions and states, are available.\nIn this paper, we consider a more realistic and difficult scenario where a\nreinforcement learning agent only has access to the state sequences of an\nexpert, while the expert actions are unobserved. We propose a novel\ntensor-based model to infer the unobserved actions of the expert state\nsequences. The policy of the agent is then optimized via a hybrid objective\ncombining reinforcement learning and imitation learning. We evaluated our\nhybrid approach on an illustrative domain and Atari games. The empirical\nresults show that (1) the agents are able to leverage state expert sequences to\nlearn faster than pure reinforcement learning baselines, (2) our tensor-based\naction inference model is advantageous compared to standard deep neural\nnetworks in inferring expert actions, and (3) the hybrid policy optimization\nobjective is robust against noise in expert state sequences.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 03:28:13 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Guo", "Xiaoxiao", ""], ["Chang", "Shiyu", ""], ["Yu", "Mo", ""], ["Tesauro", "Gerald", ""], ["Campbell", "Murray", ""]]}, {"id": "1903.04120", "submitter": "Pravendra Singh", "authors": "Pravendra Singh, Vinay Kumar Verma, Piyush Rai, Vinay P. Namboodiri", "title": "HetConv: Heterogeneous Kernel-Based Convolutions for Deep CNNs", "comments": "Accepted in CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel deep learning architecture in which the convolution\noperation leverages heterogeneous kernels. The proposed HetConv (Heterogeneous\nKernel-Based Convolution) reduces the computation (FLOPs) and the number of\nparameters as compared to standard convolution operation while still\nmaintaining representational efficiency. To show the effectiveness of our\nproposed convolution, we present extensive experimental results on the standard\nconvolutional neural network (CNN) architectures such as VGG \\cite{vgg2014very}\nand ResNet \\cite{resnet}. We find that after replacing the standard\nconvolutional filters in these architectures with our proposed HetConv filters,\nwe achieve 3X to 8X FLOPs based improvement in speed while still maintaining\n(and sometimes improving) the accuracy. We also compare our proposed\nconvolutions with group/depth wise convolutions and show that it achieves more\nFLOPs reduction with significantly higher accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 04:20:38 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 09:52:55 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Singh", "Pravendra", ""], ["Verma", "Vinay Kumar", ""], ["Rai", "Piyush", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1903.04124", "submitter": "Jinxi Guo", "authors": "Xin Chen, Wei Chu, Jinxi Guo, Ning Xu", "title": "Singing voice conversion with non-parallel data", "comments": "Accepted to MIPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singing voice conversion is a task to convert a song sang by a source singer\nto the voice of a target singer. In this paper, we propose using a parallel\ndata free, many-to-one voice conversion technique on singing voices. A phonetic\nposterior feature is first generated by decoding singing voices through a\nrobust Automatic Speech Recognition Engine (ASR). Then, a trained Recurrent\nNeural Network (RNN) with a Deep Bidirectional Long Short Term Memory (DBLSTM)\nstructure is used to model the mapping from person-independent content to the\nacoustic features of the target person. F0 and aperiodic are obtained through\nthe original singing voice, and used with acoustic features to reconstruct the\ntarget singing voice through a vocoder. In the obtained singing voice, the\ntargeted and sourced singers sound similar. To our knowledge, this is the first\nstudy that uses non parallel data to train a singing voice conversion system.\nSubjective evaluations demonstrate that the proposed method effectively\nconverts singing voices.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 04:52:36 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Chen", "Xin", ""], ["Chu", "Wei", ""], ["Guo", "Jinxi", ""], ["Xu", "Ning", ""]]}, {"id": "1903.04128", "submitter": "Stephen Tian", "authors": "Stephen Tian, Frederik Ebert, Dinesh Jayaraman, Mayur Mudigonda,\n  Chelsea Finn, Roberto Calandra, Sergey Levine", "title": "Manipulation by Feel: Touch-Based Control with Deep Predictive Models", "comments": "Accepted to ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Touch sensing is widely acknowledged to be important for dexterous robotic\nmanipulation, but exploiting tactile sensing for continuous, non-prehensile\nmanipulation is challenging. General purpose control techniques that are able\nto effectively leverage tactile sensing as well as accurate physics models of\ncontacts and forces remain largely elusive, and it is unclear how to even\nspecify a desired behavior in terms of tactile percepts. In this paper, we take\na step towards addressing these issues by combining high-resolution tactile\nsensing with data-driven modeling using deep neural network dynamics models. We\npropose deep tactile MPC, a framework for learning to perform tactile servoing\nfrom raw tactile sensor inputs, without manual supervision. We show that this\nmethod enables a robot equipped with a GelSight-style tactile sensor to\nmanipulate a ball, analog stick, and 20-sided die, learning from unsupervised\nautonomous interaction and then using the learned tactile predictive model to\nreposition each object to user-specified configurations, indicated by a goal\ntactile reading. Videos, visualizations and the code are available here:\nhttps://sites.google.com/view/deeptactilempc\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 05:14:34 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Tian", "Stephen", ""], ["Ebert", "Frederik", ""], ["Jayaraman", "Dinesh", ""], ["Mudigonda", "Mayur", ""], ["Finn", "Chelsea", ""], ["Calandra", "Roberto", ""], ["Levine", "Sergey", ""]]}, {"id": "1903.04146", "submitter": "Amr Amr", "authors": "Amr Adel Helmy, Yasser M.K. Omar, Rania Hodhod", "title": "An Innovative Word Encoding Method For Text Classification Using\n  Convolutional Neural Network", "comments": "Accepted @ 14th International Computer Engineering Conference\n  (ICENCO2018), Faculty of Engineering , Cairo University, Egypt, Dec. 29-30,\n  2018", "journal-ref": null, "doi": "10.1109/ICENCO.2018.8636143", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification plays a vital role today especially with the intensive\nuse of social networking media. Recently, different architectures of\nconvolutional neural networks have been used for text classification in which\none-hot vector, and word embedding methods are commonly used. This paper\npresents a new language independent word encoding method for text\nclassification. The proposed model converts raw text data to low-level feature\ndimension with minimal or no preprocessing steps by using a new approach called\nbinary unique number of word \"BUNOW\". BUNOW allows each unique word to have an\ninteger ID in a dictionary that is represented as a k-dimensional vector of its\nbinary equivalent. The output vector of this encoding is fed into a\nconvolutional neural network (CNN) model for classification. Moreover, the\nproposed model reduces the neural network parameters, allows faster computation\nwith few network layers, where a word is atomic representation the document as\nin word level, and decrease memory consumption for character level\nrepresentation. The provided CNN model is able to work with other languages or\nmulti-lingual text without the need for any changes in the encoding method. The\nmodel outperforms the character level and very deep character level CNNs models\nin terms of accuracy, network parameters, and memory consumption; the results\nshow total classification accuracy 91.99% and error 8.01% using AG's News\ndataset compared to the state of art methods that have total classification\naccuracy 91.45% and error 8.55%, in addition to the reduction in input feature\nvector and neural network parameters by 62% and 34%, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 07:08:39 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Helmy", "Amr Adel", ""], ["Omar", "Yasser M. K.", ""], ["Hodhod", "Rania", ""]]}, {"id": "1903.04154", "submitter": "Ke Sun", "authors": "Ke Sun, Piotr Koniusz, Zhen Wang", "title": "Fisher-Bures Adversary Graph Convolutional Networks", "comments": "Published in UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a graph convolutional network, we assume that the graph $G$ is generated\nwrt some observation noise. During learning, we make small random perturbations\n$\\Delta{}G$ of the graph and try to improve generalization. Based on quantum\ninformation geometry, $\\Delta{}G$ can be characterized by the\neigendecomposition of the graph Laplacian matrix. We try to minimize the loss\nwrt the perturbed $G+\\Delta{G}$ while making $\\Delta{G}$ to be effective in\nterms of the Fisher information of the neural network. Our proposed model can\nconsistently improve graph convolutional networks on semi-supervised node\nclassification tasks with reasonable computational overhead. We present three\ndifferent geometries on the manifold of graphs: the intrinsic geometry measures\nthe information theoretic dynamics of a graph; the extrinsic geometry\ncharacterizes how such dynamics can affect externally a graph neural network;\nthe embedding geometry is for measuring node embeddings. These new analytical\ntools are useful in developing a good understanding of graph neural networks\nand fostering new techniques.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 07:47:33 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 23:48:34 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Sun", "Ke", ""], ["Koniusz", "Piotr", ""], ["Wang", "Zhen", ""]]}, {"id": "1903.04188", "submitter": "Vojtech Mrazek", "authors": "Zdenek Vasicek and Vojtech Mrazek and Lukas Sekanina", "title": "Automated Circuit Approximation Method Driven by Data Distribution", "comments": "Accepted for publication at Design, Automation and Test in Europe\n  (DATE 2019). Florence, Italy", "journal-ref": null, "doi": "10.23919/DATE.2019.8714977", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an application-tailored data-driven fully automated method for\nfunctional approximation of combinational circuits. We demonstrate how an\napplication-level error metric such as the classification accuracy can be\ntranslated to a component-level error metric needed for an efficient and fast\nsearch in the space of approximate low-level components that are used in the\napplication. This is possible by employing a weighted mean error distance\n(WMED) metric for steering the circuit approximation process which is conducted\nby means of genetic programming. WMED introduces a set of weights (calculated\nfrom the data distribution measured on a selected signal in a given\napplication) determining the importance of each input vector for the\napproximation process. The method is evaluated using synthetic benchmarks and\napplication-specific approximate MAC (multiply-and-accumulate) units that are\ndesigned to provide the best trade-offs between the classification accuracy and\npower consumption of two image classifiers based on neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 09:36:06 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Vasicek", "Zdenek", ""], ["Mrazek", "Vojtech", ""], ["Sekanina", "Lukas", ""]]}, {"id": "1903.04191", "submitter": "Wouter Kouw", "authors": "Wouter M. Kouw, Silas N. {\\O}rting, Jens Petersen, Kim S. Pedersen,\n  Marleen de Bruijne", "title": "A cross-center smoothness prior for variational Bayesian brain tissue\n  segmentation", "comments": "12 pages, 2 figures, 1 table. Accepted to the International\n  Conference on Information Processing in Medical Imaging (2019)", "journal-ref": "International Conference on Information Processing in Medical\n  Imaging (IPMI), Hong Kong, 2019, pp. 360-371", "doi": "10.1007/978-3-030-20351-1_27", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose one is faced with the challenge of tissue segmentation in MR images,\nwithout annotators at their center to provide labeled training data. One option\nis to go to another medical center for a trained classifier. Sadly, tissue\nclassifiers do not generalize well across centers due to voxel intensity shifts\ncaused by center-specific acquisition protocols. However, certain aspects of\nsegmentations, such as spatial smoothness, remain relatively consistent and can\nbe learned separately. Here we present a smoothness prior that is fit to\nsegmentations produced at another medical center. This informative prior is\npresented to an unsupervised Bayesian model. The model clusters the voxel\nintensities, such that it produces segmentations that are similarly smooth to\nthose of the other medical center. In addition, the unsupervised Bayesian model\nis extended to a semi-supervised variant, which needs no visual interpretation\nof clusters into tissues.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 09:54:07 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Kouw", "Wouter M.", ""], ["\u00d8rting", "Silas N.", ""], ["Petersen", "Jens", ""], ["Pedersen", "Kim S.", ""], ["de Bruijne", "Marleen", ""]]}, {"id": "1903.04192", "submitter": "Xinyu Peng", "authors": "Xinyu Peng, Li Li, Fei-Yue Wang", "title": "Accelerating Minibatch Stochastic Gradient Descent using Typicality\n  Sampling", "comments": "10 pages, 4 figures, for journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning, especially deep neural networks, has been rapidly developed\nin fields including computer vision, speech recognition and reinforcement\nlearning. Although Mini-batch SGD is one of the most popular stochastic\noptimization methods in training deep networks, it shows a slow convergence\nrate due to the large noise in gradient approximation. In this paper, we\nattempt to remedy this problem by building more efficient batch selection\nmethod based on typicality sampling, which reduces the error of gradient\nestimation in conventional Minibatch SGD. We analyze the convergence rate of\nthe resulting typical batch SGD algorithm and compare convergence properties\nbetween Minibatch SGD and the algorithm. Experimental results demonstrate that\nour batch selection scheme works well and more complex Minibatch SGD variants\ncan benefit from the proposed batch selection strategy.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 09:57:18 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Peng", "Xinyu", ""], ["Li", "Li", ""], ["Wang", "Fei-Yue", ""]]}, {"id": "1903.04193", "submitter": "Denis Steckelmacher", "authors": "Denis Steckelmacher, H\\'el\\`ene Plisnier, Diederik M. Roijers, Ann\n  Now\\'e", "title": "Sample-Efficient Model-Free Reinforcement Learning with Off-Policy\n  Critics", "comments": "Accepted at the European Conference on Machine Learning 2019 (ECML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-based reinforcement-learning algorithms provide state-of-the-art\nresults in model-free discrete-action settings, and tend to outperform\nactor-critic algorithms. We argue that actor-critic algorithms are limited by\ntheir need for an on-policy critic. We propose Bootstrapped Dual Policy\nIteration (BDPI), a novel model-free reinforcement-learning algorithm for\ncontinuous states and discrete actions, with an actor and several off-policy\ncritics. Off-policy critics are compatible with experience replay, ensuring\nhigh sample-efficiency, without the need for off-policy corrections. The actor,\nby slowly imitating the average greedy policy of the critics, leads to\nhigh-quality and state-specific exploration, which we compare to Thompson\nsampling. Because the actor and critics are fully decoupled, BDPI is remarkably\nstable, and unusually robust to its hyper-parameters. BDPI is significantly\nmore sample-efficient than Bootstrapped DQN, PPO, and ACKTR, on discrete,\ncontinuous and pixel-based tasks. Source code:\nhttps://github.com/vub-ai-lab/bdpi.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 09:59:58 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:49:50 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Steckelmacher", "Denis", ""], ["Plisnier", "H\u00e9l\u00e8ne", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1903.04209", "submitter": "Andreas Joseph Mr.", "authors": "Andreas Joseph", "title": "Parametric inference with universal function approximators", "comments": "38 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Universal function approximators, such as artificial neural networks, can\nlearn a large variety of target functions arbitrarily well given sufficient\ntraining data. This flexibility comes at the cost of the ability to perform\nparametric inference. We address this gap by proposing a generic framework\nbased on the Shapley-Taylor decomposition of a model. A surrogate parametric\nregression analysis is performed in the space spanned by the Shapley value\nexpansion of a model. This allows for the testing of standard hypotheses of\ninterest. At the same time, the proposed approach provides novel insights into\nstatistical learning processes themselves derived from the consistency and bias\nproperties of the nonparametric estimators. We apply the framework to the\nestimation of heterogeneous treatment effects in simulated and real-world\nrandomised experiments. We introduce an explicit treatment function based on\nhigher-order Shapley-Taylor indices. This can be used to identify potentially\ncomplex treatment channels and help the generalisation of findings from\nexperimental settings. More generally, the presented approach allows for a\nstandardised use and communication of results from machine learning models.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 10:37:05 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 18:02:56 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 13:40:22 GMT"}, {"version": "v4", "created": "Sun, 4 Oct 2020 20:18:27 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Joseph", "Andreas", ""]]}, {"id": "1903.04233", "submitter": "Anees Kazi", "authors": "Anees Kazi, Shayan shekarforoush, S.Arvind krishna, Hendrik Burwinkel,\n  Gerome Vivar, Karsten Kortuem, Seyed-Ahmad Ahmadi, Shadi Albarqouni, Nassir\n  Navab", "title": "InceptionGCN: Receptive Field Aware Graph Convolutional Network for\n  Disease Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric deep learning provides a principled and versatile manner for the\nintegration of imaging and non-imaging modalities in the medical domain. Graph\nConvolutional Networks (GCNs) in particular have been explored on a wide\nvariety of problems such as disease prediction, segmentation, and matrix\ncompletion by leveraging large, multimodal datasets. In this paper, we\nintroduce a new spectral domain architecture for deep learning on graphs for\ndisease prediction. The novelty lies in defining geometric 'inception modules'\nwhich are capable of capturing intra- and inter-graph structural heterogeneity\nduring convolutions. We design filters with different kernel sizes to build our\narchitecture. We show our disease prediction results on two publicly available\ndatasets. Further, we provide insights on the behaviour of regular GCNs and our\nproposed model under varying input scenarios on simulated data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 11:55:54 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kazi", "Anees", ""], ["shekarforoush", "Shayan", ""], ["krishna", "S. Arvind", ""], ["Burwinkel", "Hendrik", ""], ["Vivar", "Gerome", ""], ["Kortuem", "Karsten", ""], ["Ahmadi", "Seyed-Ahmad", ""], ["Albarqouni", "Shadi", ""], ["Navab", "Nassir", ""]]}, {"id": "1903.04235", "submitter": "Zhao Kang", "authors": "Zhao Kang, Yiwei Lu, Yuanzhang Su, Changsheng Li, Zenglin Xu", "title": "Similarity Learning via Kernel Preserving Embedding", "comments": "Published in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data similarity is a key concept in many data-driven applications. Many\nalgorithms are sensitive to similarity measures. To tackle this fundamental\nproblem, automatically learning of similarity information from data via\nself-expression has been developed and successfully applied in various models,\nsuch as low-rank representation, sparse subspace learning, semi-supervised\nlearning. However, it just tries to reconstruct the original data and some\nvaluable information, e.g., the manifold structure, is largely ignored. In this\npaper, we argue that it is beneficial to preserve the overall relations when we\nextract similarity information. Specifically, we propose a novel similarity\nlearning framework by minimizing the reconstruction error of kernel matrices,\nrather than the reconstruction error of original data adopted by existing work.\nTaking the clustering task as an example to evaluate our method, we observe\nconsiderable improvements compared to other state-of-the-art methods. More\nimportantly, our proposed framework is very general and provides a novel and\nfundamental building block for many other similarity-based tasks. Besides, our\nproposed kernel preserving opens up a large number of possibilities to embed\nhigh-dimensional data into low-dimensional space.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 11:58:40 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kang", "Zhao", ""], ["Lu", "Yiwei", ""], ["Su", "Yuanzhang", ""], ["Li", "Changsheng", ""], ["Xu", "Zenglin", ""]]}, {"id": "1903.04243", "submitter": "Ashish Agarwal", "authors": "Ashish Agarwal, Igor Ganichev", "title": "Auto-Vectorizing TensorFlow Graphs: Jacobians, Auto-Batching And Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a static loop vectorization optimization on top of high level\ndataflow IR used by frameworks like TensorFlow. A new statically vectorized\nparallel-for abstraction is provided on top of TensorFlow, and used for\napplications ranging from auto-batching and per-example gradients, to jacobian\ncomputation, optimized map functions and input pipeline optimization. We report\nhuge speedups compared to both loop based implementations, as well as run-time\nbatching adopted by the DyNet framework.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 03:11:02 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Agarwal", "Ashish", ""], ["Ganichev", "Igor", ""]]}, {"id": "1903.04254", "submitter": "Abhinandan Krishnan", "authors": "Abhinandan Krishnan, Abilash Amarthaluri", "title": "Large Scale Product Categorization using Structured and Unstructured\n  Attributes", "comments": "Submitted to KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product categorization using text data for eCommerce is a very challenging\nextreme classification problem with several thousands of classes and several\nmillions of products to classify. Even though multi-class text classification\nis a well studied problem both in academia and industry, most approaches either\ndeal with treating product content as a single pile of text, or only consider a\nfew product attributes for modelling purposes. Given the variety of products\nsold on popular eCommerce platforms, it is hard to consider all available\nproduct attributes as part of the modeling exercise, considering that products\npossess their own unique set of attributes based on category. In this paper, we\ncompare hierarchical models to flat models and show that in specific cases,\nflat models perform better. We explore two Deep Learning based models that\nextract features from individual pieces of unstructured data from each product\nand then combine them to create a product signature. We also propose a novel\nidea of using structured attributes and their values together in an\nunstructured fashion along with convolutional filters such that the ordering of\nthe attributes and the differing attributes by product categories no longer\nbecomes a modelling challenge. This approach is also more robust to the\npresence of faulty product attribute names and values and can elegantly\ngeneralize to use both closed list and open list attributes.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 23:41:10 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Krishnan", "Abhinandan", ""], ["Amarthaluri", "Abilash", ""]]}, {"id": "1903.04263", "submitter": "Shubhra-Kanti Karmaker-Santu", "authors": "Shubhra Kanti Karmaker Santu, Parikshit Sondhi, ChengXiang Zhai", "title": "On Application of Learning to Rank for E-Commerce Search", "comments": null, "journal-ref": null, "doi": "10.1145/3077136.3080838", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-Commerce (E-Com) search is an emerging important new application of\ninformation retrieval. Learning to Rank (LETOR) is a general effective strategy\nfor optimizing search engines, and is thus also a key technology for E-Com\nsearch. While the use of LETOR for web search has been well studied, its use\nfor E-Com search has not yet been well explored. In this paper, we discuss the\npractical challenges in applying learning to rank methods to E-Com search,\nincluding the challenges in feature representation, obtaining reliable\nrelevance judgments, and optimally exploiting multiple user feedback signals\nsuch as click rates, add-to-cart ratios, order rates, and revenue. We study\nthese new challenges using experiments on industry data sets and report several\ninteresting findings that can provide guidance on how to optimally apply LETOR\nto E-Com search: First, popularity-based features defined solely on product\nitems are very useful and LETOR methods were able to effectively optimize their\ncombination with relevance-based features. Second, query attribute sparsity\nraises challenges for LETOR, and selecting features to reduce/avoid sparsity is\nbeneficial. Third, while crowdsourcing is often useful for obtaining relevance\njudgments for Web search, it does not work as well for E-Com search due to\ndifficulty in eliciting sufficiently fine grained relevance judgments. Finally,\namong the multiple feedback signals, the order rate is found to be the most\nrobust training objective, followed by click rate, while add-to-cart ratio\nseems least robust, suggesting that an effective practical strategy may be to\ninitially use click rates for training and gradually shift to using order rates\nas they become available.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 22:10:14 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Santu", "Shubhra Kanti Karmaker", ""], ["Sondhi", "Parikshit", ""], ["Zhai", "ChengXiang", ""]]}, {"id": "1903.04268", "submitter": "Yunhao Tang", "authors": "Krzysztof Choromanski, Aldo Pacchiano, Jack Parker-Holder, Yunhao Tang", "title": "From Complexity to Simplicity: Adaptive ES-Active Subspaces for Blackbox\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm ASEBO for optimizing high-dimensional blackbox\nfunctions. ASEBO adapts to the geometry of the function and learns optimal sets\nof sensing directions, which are used to probe it, on-the-fly. It addresses the\nexploration-exploitation trade-off of blackbox optimization with expensive\nblackbox queries by continuously learning the bias of the lower-dimensional\nmodel used to approximate gradients of smoothings of the function via\ncompressed sensing and contextual bandits methods. To obtain this model, it\nleverages techniques from the emerging theory of active subspaces in the novel\nES blackbox optimization context. As a result, ASEBO learns the dynamically\nchanging intrinsic dimensionality of the gradient space and adapts to the\nhardness of different stages of the optimization without external supervision.\nConsequently, it leads to more sample-efficient blackbox optimization than\nstate-of-the-art algorithms. We provide theoretical results and test ASEBO\nadvantages over other methods empirically by evaluating it on the set of\nreinforcement learning policy optimization tasks as well as functions from the\nrecently open-sourced Nevergrad library.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 16:04:13 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 15:23:27 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 22:25:10 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Pacchiano", "Aldo", ""], ["Parker-Holder", "Jack", ""], ["Tang", "Yunhao", ""]]}, {"id": "1903.04276", "submitter": "Leonidas Akritidis Mr", "authors": "Leonidas Akritidis, Athanasios Fevgas, Panayiotis Bozanis, Christos\n  Makris", "title": "A Clustering-Based Combinatorial Approach to Unsupervised Matching of\n  Product Titles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constant growth of the e-commerce industry has rendered the problem of\nproduct retrieval particularly important. As more enterprises move their\nactivities on the Web, the volume and the diversity of the product-related\ninformation increase quickly. These factors make it difficult for the users to\nidentify and compare the features of their desired products. Recent studies\nproved that the standard similarity metrics cannot effectively identify\nidentical products, since similar titles often refer to different products and\nvice-versa. Other studies employed external data sources (search engines) to\nenrich the titles; these solutions are rather impractical mainly because the\nexternal data fetching is slow. In this paper we introduce UPM, an unsupervised\nalgorithm for matching products by their titles. UPM is independent of any\nexternal sources, since it analyzes the titles and extracts combinations of\nwords out of them. These combinations are evaluated according to several\ncriteria, and the most appropriate of them constitutes the cluster where a\nproduct is classified into. UPM is also parameter-free, it avoids product\npairwise comparisons, and includes a post-processing verification stage which\ncorrects the erroneous matches. The experimental evaluation of UPM demonstrated\nits superiority against the state-of-the-art approaches in terms of both\nefficiency and effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 02:22:48 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Akritidis", "Leonidas", ""], ["Fevgas", "Athanasios", ""], ["Bozanis", "Panayiotis", ""], ["Makris", "Christos", ""]]}, {"id": "1903.04277", "submitter": "Xinlei Yi", "authors": "Xinlei Yi, Xiuxian Li, Lihua Xie, and Karl H. Johansson", "title": "Distributed Online Convex Optimization with Time-Varying Coupled\n  Inequality Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers distributed online optimization with time-varying\ncoupled inequality constraints. The global objective function is composed of\nlocal convex cost and regularization functions and the coupled constraint\nfunction is the sum of local convex functions. A distributed online primal-dual\ndynamic mirror descent algorithm is proposed to solve this problem, where the\nlocal cost, regularization, and constraint functions are held privately and\nrevealed only after each time slot. Without assuming Slater's condition, we\nfirst derive regret and constraint violation bounds for the algorithm and show\nhow they depend on the stepsize sequences, the accumulated dynamic variation of\nthe comparator sequence, the number of agents, and the network connectivity. As\na result, under some natural decreasing stepsize sequences, we prove that the\nalgorithm achieves sublinear dynamic regret and constraint violation if the\naccumulated dynamic variation of the optimal sequence also grows sublinearly.\nWe also prove that the algorithm achieves sublinear static regret and\nconstraint violation under mild conditions. Assuming Slater's condition, we\nshow that the algorithm achieves smaller bounds on the constraint violation. In\naddition, smaller bounds on the static regret are achieved when the objective\nfunction is strongly convex. Finally, numerical simulations are provided to\nillustrate the effectiveness of the theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 20:29:00 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 10:09:40 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Yi", "Xinlei", ""], ["Li", "Xiuxian", ""], ["Xie", "Lihua", ""], ["Johansson", "Karl H.", ""]]}, {"id": "1903.04297", "submitter": "Shuai Ma", "authors": "Hongmei Wang, Zhenzhen Wu, Shuai Ma, Songtao Lu, Han Zhang, Guoru\n  Ding, and Shiyin Li", "title": "Deep Learning for Signal Demodulation in Physical Layer Wireless\n  Communications: Prototype Platform, Open Dataset, and Analytics", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2019.2903130", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate deep learning (DL)-enabled signal demodulation\nmethods and establish the first open dataset of real modulated signals for\nwireless communication systems. Specifically, we propose a flexible\ncommunication prototype platform for measuring real modulation dataset. Then,\nbased on the measured dataset, two DL-based demodulators, called deep belief\nnetwork (DBN)-support vector machine (SVM) demodulator and adaptive boosting\n(AdaBoost) based demodulator, are proposed. The proposed DBN-SVM based\ndemodulator exploits the advantages of both DBN and SVM, i.e., the advantage of\nDBN as a feature extractor and SVM as a feature classifier. In DBN-SVM based\ndemodulator, the received signals are normalized before being fed to the DBN\nnetwork. Furthermore, an AdaBoost based demodulator is developed, which employs\nthe $k$-Nearest Neighbor (KNN) as a weak classifier to form a strong combined\nclassifier. Finally, experimental results indicate that the proposed DBN-SVM\nbased demodulator and AdaBoost based demodulator are superior to the single\nclassification method using DBN, SVM, and maximum likelihood (MLD) based\ndemodulator.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 12:47:57 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Hongmei", ""], ["Wu", "Zhenzhen", ""], ["Ma", "Shuai", ""], ["Lu", "Songtao", ""], ["Zhang", "Han", ""], ["Ding", "Guoru", ""], ["Li", "Shiyin", ""]]}, {"id": "1903.04307", "submitter": "WaiChing Sun", "authors": "Kun Wang, WaiChing Sun, Qiang Du", "title": "A cooperative game for automated learning of elasto-plasticity knowledge\n  graphs and models with AI-guided experimentation", "comments": null, "journal-ref": null, "doi": "10.1007/s00466-019-01723-1", "report-no": null, "categories": "cs.LG cond-mat.soft", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a multi-agent meta-modeling game to generate data, knowledge,\nand models that make predictions on constitutive responses of elasto-plastic\nmaterials. We introduce a new concept from graph theory where a modeler agent\nis tasked with evaluating all the modeling options recast as a directed\nmultigraph and find the optimal path that links the source of the directed\ngraph (e.g. strain history) to the target (e.g. stress) measured by an\nobjective function. Meanwhile, the data agent, which is tasked with generating\ndata from real or virtual experiments (e.g. molecular dynamics, discrete\nelement simulations), interacts with the modeling agent sequentially and uses\nreinforcement learning to design new experiments to optimize the prediction\ncapacity. Consequently, this treatment enables us to emulate an idealized\nscientific collaboration as selections of the optimal choices in a decision\ntree search done automatically via deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 15:05:50 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Wang", "Kun", ""], ["Sun", "WaiChing", ""], ["Du", "Qiang", ""]]}, {"id": "1903.04311", "submitter": "Clement Romac", "authors": "Cl\\'ement Romac, Vincent B\\'eraud", "title": "Deep Recurrent Q-Learning vs Deep Q-Learning on a simple Partially\n  Observable Markov Decision Process with Minecraft", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-Learning has been successfully applied to a wide variety of tasks in\nthe past several years. However, the architecture of the vanilla Deep Q-Network\nis not suited to deal with partially observable environments such as 3D video\ngames. For this, recurrent layers have been added to the Deep Q-Network in\norder to allow it to handle past dependencies. We here use Minecraft for its\ncustomization advantages and design two very simple missions that can be frames\nas Partially Observable Markov Decision Process. We compare on these missions\nthe Deep Q-Network and the Deep Recurrent Q-Network in order to see if the\nlatter, which is trickier and longer to train, is always the best architecture\nwhen the agent has to deal with partial observability.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 14:11:20 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 07:11:13 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Romac", "Cl\u00e9ment", ""], ["B\u00e9raud", "Vincent", ""]]}, {"id": "1903.04337", "submitter": "Daniel Wesierski", "authors": "Lukasz Czekaj, Wojciech Ziembla, Pawel Jezierski, Pawel Swiniarski,\n  Anna Kolodziejak, Pawel Ogniewski, Pawel Niedbalski, Anna Jezierska, Daniel\n  Wesierski", "title": "Labeler-hot Detection of EEG Epileptic Transients", "comments": "5 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preventing early progression of epilepsy and so the severity of seizures\nrequires an effective diagnosis. Epileptic transients indicate the ability to\ndevelop seizures but humans overlook such brief events in an\nelectroencephalogram (EEG) what compromises patient treatment. Traditionally,\ntraining of the EEG event detection algorithms has relied on ground truth\nlabels, obtained from the consensus of the majority of labelers. In this work,\nwe go beyond labeler consensus on EEG data. Our event descriptor integrates EEG\nsignal features with one-hot encoded labeler category that is a key to improved\ngeneralization performance. Notably, boosted decision trees take advantage of\nsingly-labeled but more varied training sets. Our quantitative experiments show\nthe proposed labeler-hot epileptic event detector consistently outperforms a\nconsensus-trained detector and maintains confidence bounds of the detection.\nThe results on our infant EEG recordings suggest datasets can gain higher event\nvariety faster and thus better performance by shifting available human effort\nfrom consensus-oriented to separate labeling when labels include both, the\nevent and the labeler category.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 14:48:49 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 12:01:55 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 08:59:41 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Czekaj", "Lukasz", ""], ["Ziembla", "Wojciech", ""], ["Jezierski", "Pawel", ""], ["Swiniarski", "Pawel", ""], ["Kolodziejak", "Anna", ""], ["Ogniewski", "Pawel", ""], ["Niedbalski", "Pawel", ""], ["Jezierska", "Anna", ""], ["Wesierski", "Daniel", ""]]}, {"id": "1903.04360", "submitter": "Yiming Xu", "authors": "Yiming Xu, Dnyanesh Rajpathak, Ian Gibbs, Diego Klabjan", "title": "Automatic Ontology Learning from Domain-Specific Short Unstructured Text\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology learning is a critical task in industry, dealing with identifying\nand extracting concepts captured in text data such that these concepts can be\nused in different tasks, e.g. information retrieval. Ontology learning is\nnon-trivial due to several reasons with limited amount of prior research work\nthat automatically learns a domain specific ontology from data. In our work, we\npropose a two-stage classification system to automatically learn an ontology\nfrom unstructured text data. We first collect candidate concepts, which are\nclassified into concepts and irrelevant collocates by our first classifier. The\nconcepts from the first classifier are further classified by the second\nclassifier into different concept types. The proposed system is deployed as a\nprototype at a company and its performance is validated by using complaint and\nrepair verbatim data collected in automotive industry from different data\nsources.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 18:48:02 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Xu", "Yiming", ""], ["Rajpathak", "Dnyanesh", ""], ["Gibbs", "Ian", ""], ["Klabjan", "Diego", ""]]}, {"id": "1903.04377", "submitter": "Bahareh Pourbabaee", "authors": "Bahareh Pourbabaee, Matthew Howe-Patterson, Matthew Patterson,\n  Frederic Benard", "title": "SleepNet: Automated Sleep Analysis via Dense Convolutional Neural\n  Network Using Physiological Time Series", "comments": "20 pages, 4 figures, Accepted to be published by Physiological\n  Measurement Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a dense recurrent convolutional neural network (DRCNN) was\nconstructed to detect sleep disorders including arousal, apnea and hypopnea\nusing Polysomnography (PSG) measurement channels provided in the 2018 Physionet\nchallenge database. Our model structure is composed of multiple dense\nconvolutional units (DCU) followed by a bidirectional long-short term memory\n(LSTM) layer followed by a softmax output layer. The sleep events including\nsleep stages, arousal regions and multiple types of apnea and hypopnea are\nmanually annotated by experts which enables us to train our proposed network\nusing a multi-task learning mechanism. Three binary cross-entropy loss\nfunctions corresponding to sleep/wake, target arousal and apnea-hypopnea/normal\ndetection tasks are summed up to generate our overall network loss function\nthat is optimized using the Adam method. Our model performance was evaluated\nusing two metrics: the area under the precision-recall curve (AUPRC) and the\narea under the receiver operating characteristic curve (AUROC). To measure our\nmodel generalization, 4-fold cross-validation was also performed. For training,\nour model was applied to full night recording data. Finally, the average AUPRC\nand AUROC values associated with the arousal detection task were 0.505 and\n0.922, respectively on our testing dataset. An ensemble of four models trained\non different data folds improved the AUPRC and AUROC to 0.543 and 0.931,\nrespectively. Our proposed algorithm achieved the first place in the official\nstage of the 2018 Physionet challenge for detecting sleep arousals with AUPRC\nof 0.54 on the blind testing dataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 15:41:55 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 16:17:16 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Pourbabaee", "Bahareh", ""], ["Howe-Patterson", "Matthew", ""], ["Patterson", "Matthew", ""], ["Benard", "Frederic", ""]]}, {"id": "1903.04388", "submitter": "Daniel Elton", "authors": "Daniel C. Elton, Zois Boukouvalas, Mark D. Fuge, Peter W. Chung", "title": "Deep learning for molecular design - a review of the state of the art", "comments": "24 pages, new title, published in RSC MSDE", "journal-ref": "Molecular Systems Design & Engineering, 2019", "doi": "10.1039/C9ME00039A", "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the space of only a few years, deep generative modeling has revolutionized\nhow we think of artificial creativity, yielding autonomous systems which\nproduce original images, music, and text. Inspired by these successes,\nresearchers are now applying deep generative modeling techniques to the\ngeneration and optimization of molecules - in our review we found 45 papers on\nthe subject published in the past two years. These works point to a future\nwhere such systems will be used to generate lead molecules, greatly reducing\nresources spent downstream synthesizing and characterizing bad leads in the\nlab. In this review we survey the increasingly complex landscape of models and\nrepresentation schemes that have been proposed. The four classes of techniques\nwe describe are recursive neural networks, autoencoders, generative adversarial\nnetworks, and reinforcement learning. After first discussing some of the\nmathematical fundamentals of each technique, we draw high level connections and\ncomparisons with other techniques and expose the pros and cons of each. Several\nimportant high level themes emerge as a result of this work, including the\nshift away from the SMILES string representation of molecules towards more\nsophisticated representations such as graph grammars and 3D representations,\nthe importance of reward function design, the need for better standards for\nbenchmarking and testing, and the benefits of adversarial training and\nreinforcement learning over maximum likelihood based training.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 15:51:47 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 14:02:24 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 21:00:25 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Elton", "Daniel C.", ""], ["Boukouvalas", "Zois", ""], ["Fuge", "Mark D.", ""], ["Chung", "Peter W.", ""]]}, {"id": "1903.04407", "submitter": "Pravendra Singh", "authors": "Pravendra Singh, Pratik Mazumder, Vinay P. Namboodiri", "title": "Accuracy Booster: Performance Boosting using Feature Map Re-calibration", "comments": "IEEE Winter Conference on Applications of Computer Vision (WACV),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution Neural Networks (CNN) have been extremely successful in solving\nintensive computer vision tasks. The convolutional filters used in CNNs have\nplayed a major role in this success, by extracting useful features from the\ninputs. Recently researchers have tried to boost the performance of CNNs by\nre-calibrating the feature maps produced by these filters, e.g.,\nSqueeze-and-Excitation Networks (SENets). These approaches have achieved better\nperformance by Exciting up the important channels or feature maps while\ndiminishing the rest. However, in the process, architectural complexity has\nincreased. We propose an architectural block that introduces much lower\ncomplexity than the existing methods of CNN performance boosting while\nperforming significantly better than them. We carry out experiments on the\nCIFAR, ImageNet and MS-COCO datasets, and show that the proposed block can\nchallenge the state-of-the-art results. Our method boosts the ResNet-50\narchitecture to perform comparably to the ResNet-152 architecture, which is a\nthree times deeper network, on classification. We also show experimentally that\nour method is not limited to classification but also generalizes well to other\ntasks such as object detection.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:16:03 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 10:44:44 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Singh", "Pravendra", ""], ["Mazumder", "Pratik", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1903.04413", "submitter": "Alexandre Coninx", "authors": "Leni K. Le Goff, Oussama Yaakoubi, Alexandre Coninx and Stephane\n  Doncieux", "title": "Building an Affordances Map with Interactive Perception", "comments": "14 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots need to understand their environment to perform their task. If it is\npossible to pre-program a visual scene analysis process in closed environments,\nrobots operating in an open environment would benefit from the ability to learn\nit through their interaction with their environment. This ability furthermore\nopens the way to the acquisition of affordances maps in which the action\ncapabilities of the robot structure its visual scene understanding. We propose\nan approach to build such affordances maps by relying on an interactive\nperception approach and an online classification. In the proposed formalization\nof affordances, actions and effects are related to visual features, not\nobjects, and they can be combined. We have tested the approach on three action\nprimitives and on a real PR2 robot.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:24:04 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Goff", "Leni K. Le", ""], ["Yaakoubi", "Oussama", ""], ["Coninx", "Alexandre", ""], ["Doncieux", "Stephane", ""]]}, {"id": "1903.04416", "submitter": "Xiaohui Chen", "authors": "Xiaohui Chen, Yun Yang", "title": "Diffusion $K$-means clustering on manifolds: provable exact recovery via\n  semidefinite relaxations", "comments": "accepted to Applied and Computational Harmonic Analysis", "journal-ref": null, "doi": "10.1016/j.acha.2020.03.002", "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the {\\it diffusion $K$-means} clustering method on Riemannian\nsubmanifolds, which maximizes the within-cluster connectedness based on the\ndiffusion distance. The diffusion $K$-means constructs a random walk on the\nsimilarity graph with vertices as data points randomly sampled on the manifolds\nand edges as similarities given by a kernel that captures the local geometry of\nmanifolds. The diffusion $K$-means is a multi-scale clustering tool that is\nsuitable for data with non-linear and non-Euclidean geometric features in mixed\ndimensions. Given the number of clusters, we propose a polynomial-time convex\nrelaxation algorithm via the semidefinite programming (SDP) to solve the\ndiffusion $K$-means. In addition, we also propose a nuclear norm regularized\nSDP that is adaptive to the number of clusters. In both cases, we show that\nexact recovery of the SDPs for diffusion $K$-means can be achieved under\nsuitable between-cluster separability and within-cluster connectedness of the\nsubmanifolds, which together quantify the hardness of the manifold clustering\nproblem. We further propose the {\\it localized diffusion $K$-means} by using\nthe local adaptive bandwidth estimated from the nearest neighbors. We show that\nexact recovery of the localized diffusion $K$-means is fully adaptive to the\nlocal probability density and geometric structures of the underlying\nsubmanifolds.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:29:27 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 01:01:56 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 03:27:37 GMT"}, {"version": "v4", "created": "Mon, 16 Mar 2020 16:49:41 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Chen", "Xiaohui", ""], ["Yang", "Yun", ""]]}, {"id": "1903.04442", "submitter": "Bo Fu", "authors": "Patrick O'Driscoll, Jaehoon Lee and Bo Fu", "title": "Physics Enhanced Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose that intelligently combining models from the domains of Artificial\nIntelligence or Machine Learning with Physical and Expert models will yield a\nmore \"trustworthy\" model than any one model from a single domain, given a\ncomplex and narrow enough problem. Based on mean-variance portfolio theory and\nbias-variance trade-off analysis, we prove combining models from various\ndomains produces a model that has lower risk, increasing user trust. We call\nsuch combined models - physics enhanced artificial intelligence (PEAI), and\nsuggest use cases for PEAI.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:03:19 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["O'Driscoll", "Patrick", ""], ["Lee", "Jaehoon", ""], ["Fu", "Bo", ""]]}, {"id": "1903.04455", "submitter": "Jonathan Donier", "authors": "Jonathan Donier", "title": "Scaling up deep neural networks: a capacity allocation perspective", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the recent work on capacity allocation, we formulate the conjecture\nthat the shattering problem in deep neural networks can only be avoided if the\ncapacity propagation through layers has a non-degenerate continuous limit when\nthe number of layers tends to infinity. This allows us to study a number of\ncommonly used architectures and determine which scaling relations should be\nenforced in practice as the number of layers grows large. In particular, we\nrecover the conditions of Xavier initialization in the multi-channel case, and\nwe find that weights and biases should be scaled down as the inverse square\nroot of the number of layers for deep residual networks and as the inverse\nsquare root of the desired memory length for recurrent networks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:24:57 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 10:29:24 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Donier", "Jonathan", ""]]}, {"id": "1903.04476", "submitter": "Siavash Golkar", "authors": "Siavash Golkar, Michael Kagan, Kyunghyun Cho", "title": "Continual Learning via Neural Pruning", "comments": "12 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Continual Learning via Neural Pruning (CLNP), a new method aimed\nat lifelong learning in fixed capacity models based on neuronal model\nsparsification. In this method, subsequent tasks are trained using the inactive\nneurons and filters of the sparsified network and cause zero deterioration to\nthe performance of previous tasks. In order to deal with the possible\ncompromise between model sparsity and performance, we formalize and incorporate\nthe concept of graceful forgetting: the idea that it is preferable to suffer a\nsmall amount of forgetting in a controlled manner if it helps regain network\ncapacity and prevents uncontrolled loss of performance during the training of\nfuture tasks. CLNP also provides simple continual learning diagnostic tools in\nterms of the number of free neurons left for the training of future tasks as\nwell as the number of neurons that are being reused. In particular, we see in\nexperiments that CLNP verifies and automatically takes advantage of the fact\nthat the features of earlier layers are more transferable. We show empirically\nthat CLNP leads to significantly improved results over current weight\nelasticity based methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:53:34 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Golkar", "Siavash", ""], ["Kagan", "Michael", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1903.04478", "submitter": "Ali Taylan Cemgil", "authors": "Ali Taylan Cemgil, Mehmet Burak Kurutmaz, Sinan Yildirim, Melih\n  Barsbey, Umut Simsekli", "title": "Bayesian Allocation Model: Inference by Sequential Monte Carlo for\n  Nonnegative Tensor Factorizations and Topic Models using Polya Urns", "comments": "70 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a dynamic generative model, Bayesian allocation model (BAM),\nwhich establishes explicit connections between nonnegative tensor factorization\n(NTF), graphical models of discrete probability distributions and their\nBayesian extensions, and the topic models such as the latent Dirichlet\nallocation. BAM is based on a Poisson process, whose events are marked by using\na Bayesian network, where the conditional probability tables of this network\nare then integrated out analytically. We show that the resulting marginal\nprocess turns out to be a Polya urn, an integer valued self-reinforcing\nprocess. This urn processes, which we name a Polya-Bayes process, obey certain\nconditional independence properties that provide further insight about the\nnature of NTF. These insights also let us develop space efficient simulation\nalgorithms that respect the potential sparsity of data: we propose a class of\nsequential importance sampling algorithms for computing NTF and approximating\ntheir marginal likelihood, which would be useful for model selection. The\nresulting methods can also be viewed as a model scoring method for topic models\nand discrete Bayesian networks with hidden variables. The new algorithms have\nfavourable properties in the sparse data regime when contrasted with\nvariational algorithms that become more accurate when the total sum of the\nelements of the observed tensor goes to infinity. We illustrate the performance\non several examples and numerically study the behaviour of the algorithms for\nvarious data regimes.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:54:59 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Cemgil", "Ali Taylan", ""], ["Kurutmaz", "Mehmet Burak", ""], ["Yildirim", "Sinan", ""], ["Barsbey", "Melih", ""], ["Simsekli", "Umut", ""]]}, {"id": "1903.04479", "submitter": "Benjamin Guedj", "authors": "St\\'ephane Chr\\'etien and Benjamin Guedj", "title": "Revisiting clustering as matrix factorisation on the Stiefel manifold", "comments": "Accepted at the LOD 2020 Conference -- The Sixth International\n  Conference on Machine Learning, Optimization, and Data Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper studies clustering for possibly high dimensional data (e.g.\nimages, time series, gene expression data, and many other settings), and\nrephrase it as low rank matrix estimation in the PAC-Bayesian framework. Our\napproach leverages the well known Burer-Monteiro factorisation strategy from\nlarge scale optimisation, in the context of low rank estimation. Moreover, our\nBurer-Monteiro factors are shown to lie on a Stiefel manifold. We propose a new\ngeneralized Bayesian estimator for this problem and prove novel prediction\nbounds for clustering. We also devise a componentwise Langevin sampler on the\nStiefel manifold to compute this estimator.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:56:13 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 16:15:01 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Chr\u00e9tien", "St\u00e9phane", ""], ["Guedj", "Benjamin", ""]]}, {"id": "1903.04486", "submitter": "Iman Niazazari", "authors": "Iman Niazazari, Reza Jalilzadeh Hamidi, Hanif Livani, and Reza\n  Arghandeh", "title": "Cause Identification of Electromagnetic Transient Events using\n  Spatiotemporal Feature Learning", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a spatiotemporal unsupervised feature learning method for\ncause identification of electromagnetic transient events (EMTE) in power grids.\nThe proposed method is formulated based on the availability of\ntime-synchronized high-frequency measurement, and using the convolutional\nneural network (CNN) as the spatiotemporal feature representation along with\nsoftmax function. Despite the existing threshold-based, or energy-based events\nanalysis methods, such as support vector machine (SVM), autoencoder, and\ntapered multi-layer perception (t-MLP) neural network, the proposed feature\nlearning is carried out with respect to both time and space. The effectiveness\nof the proposed feature learning and the subsequent cause identification is\nvalidated through the EMTP simulation of different events such as line\nenergization, capacitor bank energization, lightning, fault, and high-impedance\nfault in the IEEE 30-bus, and the real-time digital simulation (RTDS) of the\nWSCC 9-bus system.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 01:00:17 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Niazazari", "Iman", ""], ["Hamidi", "Reza Jalilzadeh", ""], ["Livani", "Hanif", ""], ["Arghandeh", "Reza", ""]]}, {"id": "1903.04488", "submitter": "Enayat Ullah", "authors": "Nikita Ivkin, Daniel Rothchild, Enayat Ullah, Vladimir Braverman, Ion\n  Stoica, Raman Arora", "title": "Communication-efficient distributed SGD with Sketching", "comments": "19 pages, 6 figures, published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale distributed training of neural networks is often limited by\nnetwork bandwidth, wherein the communication time overwhelms the local\ncomputation time. Motivated by the success of sketching methods in\nsub-linear/streaming algorithms, we introduce Sketched SGD, an algorithm for\ncarrying out distributed SGD by communicating sketches instead of full\ngradients. We show that Sketched SGD has favorable convergence rates on several\nclasses of functions. When considering all communication -- both of gradients\nand of updated model weights -- Sketched SGD reduces the amount of\ncommunication required compared to other gradient compression methods from\n$\\mathcal{O}(d)$ or $\\mathcal{O}(W)$ to $\\mathcal{O}(\\log d)$, where $d$ is the\nnumber of model parameters and $W$ is the number of workers participating in\ntraining. We run experiments on a transformer model, an LSTM, and a residual\nnetwork, demonstrating up to a 40x reduction in total communication cost with\nno loss in final model performance. We also show experimentally that Sketched\nSGD scales to at least 256 workers without increasing communication cost or\ndegrading model performance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 17:59:48 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 21:49:03 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 15:59:50 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Ivkin", "Nikita", ""], ["Rothchild", "Daniel", ""], ["Ullah", "Enayat", ""], ["Braverman", "Vladimir", ""], ["Stoica", "Ion", ""], ["Arora", "Raman", ""]]}, {"id": "1903.04489", "submitter": "Baogui Xin", "authors": "Wei Peng, Baogui Xin", "title": "SPMF: A Social Trust and Preference Segmentation-based Matrix\n  Factorization Recommendation Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional social recommendation algorithm ignores the following fact:\nthe preferences of users with trust relationships are not necessarily similar,\nand the consideration of user preference similarity should be limited to\nspecific areas. A social trust and preference segmentation-based matrix\nfactorization (SPMF) recommendation system is proposed to solve the\nabove-mentioned problems. Experimental results based on the Ciao and Epinions\ndatasets show that the accuracy of the SPMF algorithm is significantly higher\nthan that of some state-of-the-art recommendation algorithms. The proposed SPMF\nalgorithm is a more accurate and effective recommendation algorithm based on\ndistinguishing the difference of trust relations and preference domain, which\ncan support commercial activities such as product marketing.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 14:18:43 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Peng", "Wei", ""], ["Xin", "Baogui", ""]]}, {"id": "1903.04527", "submitter": "Zhaojian Li", "authors": "Tianshu Chu, Jie Wang, Lara Codec\\`a, Zhaojian Li", "title": "Multi-Agent Deep Reinforcement Learning for Large-scale Traffic Signal\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a promising data-driven approach for adaptive\ntraffic signal control (ATSC) in complex urban traffic networks, and deep\nneural networks further enhance its learning power. However, centralized RL is\ninfeasible for large-scale ATSC due to the extremely high dimension of the\njoint action space. Multi-agent RL (MARL) overcomes the scalability issue by\ndistributing the global control to each local RL agent, but it introduces new\nchallenges: now the environment becomes partially observable from the viewpoint\nof each local agent due to limited communication among agents. Most existing\nstudies in MARL focus on designing efficient communication and coordination\namong traditional Q-learning agents. This paper presents, for the first time, a\nfully scalable and decentralized MARL algorithm for the state-of-the-art deep\nRL agent: advantage actor critic (A2C), within the context of ATSC. In\nparticular, two methods are proposed to stabilize the learning procedure, by\nimproving the observability and reducing the learning difficulty of each local\nagent. The proposed multi-agent A2C is compared against independent A2C and\nindependent Q-learning algorithms, in both a large synthetic traffic grid and a\nlarge real-world traffic network of Monaco city, under simulated peak-hour\ntraffic dynamics. Results demonstrate its optimality, robustness, and sample\nefficiency over other state-of-the-art decentralized MARL algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 18:28:58 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Chu", "Tianshu", ""], ["Wang", "Jie", ""], ["Codec\u00e0", "Lara", ""], ["Li", "Zhaojian", ""]]}, {"id": "1903.04538", "submitter": "Richard Galvez", "authors": "Richard Galvez, David F. Fouhey, Meng Jin, Alexandre Szenicer,\n  Andr\\'es Mu\\~noz-Jaramillo, Mark C. M. Cheung, Paul J. Wright, Monica G.\n  Bobra, Yang Liu, James Mason, Rajat Thomas", "title": "A Machine Learning Dataset Prepared From the NASA Solar Dynamics\n  Observatory Mission", "comments": "Accepted to The Astrophysical Journal Supplement Series; 11 pages, 8\n  figures", "journal-ref": null, "doi": "10.3847/1538-4365/ab1005", "report-no": null, "categories": "astro-ph.SR cs.AI cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present a curated dataset from the NASA Solar Dynamics\nObservatory (SDO) mission in a format suitable for machine learning research.\nBeginning from level 1 scientific products we have processed various\ninstrumental corrections, downsampled to manageable spatial and temporal\nresolutions, and synchronized observations spatially and temporally. We\nillustrate the use of this dataset with two example applications: forecasting\nfuture EVE irradiance from present EVE irradiance and translating HMI\nobservations into AIA observations. For each application we provide metrics and\nbaselines for future model comparison. We anticipate this curated dataset will\nfacilitate machine learning research in heliophysics and the physical sciences\ngenerally, increasing the scientific return of the SDO mission. This work is a\ndirect result of the 2018 NASA Frontier Development Laboratory Program. Please\nsee the appendix for access to the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 18:50:48 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Galvez", "Richard", ""], ["Fouhey", "David F.", ""], ["Jin", "Meng", ""], ["Szenicer", "Alexandre", ""], ["Mu\u00f1oz-Jaramillo", "Andr\u00e9s", ""], ["Cheung", "Mark C. M.", ""], ["Wright", "Paul J.", ""], ["Bobra", "Monica G.", ""], ["Liu", "Yang", ""], ["Mason", "James", ""], ["Thomas", "Rajat", ""]]}, {"id": "1903.04556", "submitter": "Diego Mesquita", "authors": "Diego Mesquita, Paul Blomstedt, Samuel Kaski", "title": "Embarrassingly parallel MCMC using deep invertible transformations", "comments": "Accepted to UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While MCMC methods have become a main work-horse for Bayesian inference,\nscaling them to large distributed datasets is still a challenge. Embarrassingly\nparallel MCMC strategies take a divide-and-conquer stance to achieve this by\nwriting the target posterior as a product of subposteriors, running MCMC for\neach of them in parallel and subsequently combining the results. The challenge\nthen lies in devising efficient aggregation strategies. Current strategies\ntrade-off between approximation quality, and costs of communication and\ncomputation. In this work, we introduce a novel method that addresses these\nissues simultaneously. Our key insight is to introduce a deep invertible\ntransformation to approximate each of the subposteriors. These approximations\ncan be made accurate even for complex distributions and serve as intermediate\nrepresentations, keeping the total communication cost limited. Moreover, they\nenable us to sample from the product of the subposteriors using an efficient\nand stable importance sampling scheme. We demonstrate the approach outperforms\navailable state-of-the-art methods in a range of challenging scenarios,\nincluding high-dimensional and heterogeneous subposteriors.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 19:23:22 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 08:27:24 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Mesquita", "Diego", ""], ["Blomstedt", "Paul", ""], ["Kaski", "Samuel", ""]]}, {"id": "1903.04561", "submitter": "Nithum Thain", "authors": "Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, Lucy\n  Vasserman", "title": "Nuanced Metrics for Measuring Unintended Bias with Real Data for Text\n  Classification", "comments": "Updated to fix typo in Equation 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unintended bias in Machine Learning can manifest as systemic differences in\nperformance for different demographic groups, potentially compounding existing\nchallenges to fairness in society at large. In this paper, we introduce a suite\nof threshold-agnostic metrics that provide a nuanced view of this unintended\nbias, by considering the various ways that a classifier's score distribution\ncan vary across designated groups. We also introduce a large new test set of\nonline comments with crowd-sourced annotations for identity references. We use\nthis to show how our metrics can be used to find new and potentially subtle\nunintended bias in existing public models.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 19:45:54 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 14:39:41 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Borkan", "Daniel", ""], ["Dixon", "Lucas", ""], ["Sorensen", "Jeffrey", ""], ["Thain", "Nithum", ""], ["Vasserman", "Lucy", ""]]}, {"id": "1903.04566", "submitter": "Mohammad Rostami", "authors": "Mohammad Rostami, Soheil Kolouri, Praveen K. Pilly", "title": "Complementary Learning for Overcoming Catastrophic Forgetting Using\n  Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite huge success, deep networks are unable to learn effectively in\nsequential multitask learning settings as they forget the past learned tasks\nafter learning new tasks. Inspired from complementary learning systems theory,\nwe address this challenge by learning a generative model that couples the\ncurrent task to the past learned tasks through a discriminative embedding\nspace. We learn an abstract level generative distribution in the embedding that\nallows the generation of data points to represent the experience. We sample\nfrom this distribution and utilize experience replay to avoid forgetting and\nsimultaneously accumulate new knowledge to the abstract distribution in order\nto couple the current task with past experience. We demonstrate theoretically\nand empirically that our framework learns a distribution in the embedding that\nis shared across all task and as a result tackles catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 19:50:38 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 18:28:05 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Rostami", "Mohammad", ""], ["Kolouri", "Soheil", ""], ["Pilly", "Praveen K.", ""]]}, {"id": "1903.04571", "submitter": "Guy Shtar", "authors": "Guy Shtar, Lior Rokach, Bracha Shapira", "title": "Detecting drug-drug interactions using artificial neural networks and\n  classic graph similarity measures", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0219796", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug-drug interactions are preventable causes of medical injuries and often\nresult in doctor and emergency room visits. Computational techniques can be\nused to predict potential drug-drug interactions. We approach the drug-drug\ninteraction prediction problem as a link prediction problem and present two\nnovel methods for drug-drug interaction prediction based on artificial neural\nnetworks and factor propagation over graph nodes: adjacency matrix\nfactorization (AMF) and adjacency matrix factorization with propagation (AMFP).\nWe conduct a retrospective analysis by training our models on a previous\nrelease of the DrugBank database with 1,141 drugs and 45,296 drug-drug\ninteractions and evaluate the results on a later version of DrugBank with 1,440\ndrugs and 248,146 drug-drug interactions. Additionally, we perform a holdout\nanalysis using DrugBank. We report an area under the receiver operating\ncharacteristic curve score of 0.807 and 0.990 for the retrospective and holdout\nanalyses respectively. Finally, we create an ensemble-based classifier using\nAMF, AMFP, and existing link prediction methods and obtain an area under the\nreceiver operating characteristic curve of 0.814 and 0.991 for the\nretrospective and the holdout analyses. We demonstrate that AMF and AMFP\nprovide state of the art results compared to existing methods and that the\nensemble-based classifier improves the performance by combining various\npredictors. These results suggest that AMF, AMFP, and the proposed\nensemble-based classifier can provide important information during drug\ndevelopment and regarding drug prescription given only partial or noisy data.\nThese methods can also be used to solve other link prediction problems. Drug\nembeddings (compressed representations) created when training our models using\nthe interaction network have been made public.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 19:59:29 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 09:31:26 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Shtar", "Guy", ""], ["Rokach", "Lior", ""], ["Shapira", "Bracha", ""]]}, {"id": "1903.04598", "submitter": "Henrique Lemos", "authors": "Henrique Lemos and Marcelo Prates and Pedro Avelar and Luis Lamb", "title": "Graph Colouring Meets Deep Learning: Effective Graph Neural Network\n  Models for Combinatorial Problems", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has consistently defied state-of-the-art techniques in many\nfields over the last decade. However, we are just beginning to understand the\ncapabilities of neural learning in symbolic domains. Deep learning\narchitectures that employ parameter sharing over graphs can produce models\nwhich can be trained on complex properties of relational data. These include\nhighly relevant NP-Complete problems, such as SAT and TSP. In this work, we\nshowcase how Graph Neural Networks (GNN) can be engineered -- with a very\nsimple architecture -- to solve the fundamental combinatorial problem of graph\ncolouring. Our results show that the model, which achieves high accuracy upon\ntraining on random instances, is able to generalise to graph distributions\ndifferent from those seen at training time. Further, it performs better than\nthe Neurosat, Tabucol and greedy baselines for some distributions. In addition,\nwe show how vertex embeddings can be clustered in multidimensional spaces to\nyield constructive solutions even though our model is only trained as a binary\nclassifier. In summary, our results contribute to shorten the gap in our\nunderstanding of the algorithms learned by GNNs, as well as hoarding empirical\nevidence for their capability on hard combinatorial problems. Our results thus\ncontribute to the standing challenge of integrating robust learning and\nsymbolic reasoning in Deep Learning systems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 20:46:47 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 19:00:53 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lemos", "Henrique", ""], ["Prates", "Marcelo", ""], ["Avelar", "Pedro", ""], ["Lamb", "Luis", ""]]}, {"id": "1903.04610", "submitter": "Murat Ozbayoglu", "authors": "Omer Berat Sezer, Ahmet Murat Ozbayoglu", "title": "Financial Trading Model with Stock Bar Chart Image Time Series with Deep\n  Convolutional Neural Networks", "comments": "accepted to be published in Intelligent Automation and Soft Computing\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though computational intelligence techniques have been extensively\nutilized in financial trading systems, almost all developed models use the time\nseries data for price prediction or identifying buy-sell points. However, in\nthis study we decided to use 2-D stock bar chart images directly without\nintroducing any additional time series associated with the underlying stock. We\npropose a novel algorithmic trading model CNN-BI (Convolutional Neural Network\nwith Bar Images) using a 2-D Convolutional Neural Network. We generated 2-D\nimages of sliding windows of 30-day bar charts for Dow 30 stocks and trained a\ndeep Convolutional Neural Network (CNN) model for our algorithmic trading\nmodel. We tested our model separately between 2007-2012 and 2012-2017 for\nrepresenting different market conditions. The results indicate that the model\nwas able to outperform Buy and Hold strategy, especially in trendless or bear\nmarkets. Since this is a preliminary study and probably one of the first\nattempts using such an unconventional approach, there is always potential for\nimprovement. Overall, the results are promising and the model might be\nintegrated as part of an ensemble trading model combined with different\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 21:17:20 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Sezer", "Omer Berat", ""], ["Ozbayoglu", "Ahmet Murat", ""]]}, {"id": "1903.04613", "submitter": "Rakshit Agrawal", "authors": "Rakshit Agrawal, Luca de Alfaro", "title": "Learning Edge Properties in Graphs from Path Aggregations", "comments": "To be published in The Proceedings of the 2019 World Wide Web\n  Conference (WWW'19)", "journal-ref": null, "doi": "10.1145/3308558.3313695", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph edges, along with their labels, can represent information of\nfundamental importance, such as links between web pages, friendship between\nusers, the rating given by users to other users or items, and much more. We\nintroduce LEAP, a trainable, general framework for predicting the presence and\nproperties of edges on the basis of the local structure, topology, and labels\nof the graph. The LEAP framework is based on the exploration and\nmachine-learning aggregation of the paths connecting nodes in a graph. We\nprovide several methods for performing the aggregation phase by training path\naggregators, and we demonstrate the flexibility and generality of the framework\nby applying it to the prediction of links and user ratings in social networks.\n  We validate the LEAP framework on two problems: link prediction, and user\nrating prediction. On eight large datasets, among which the arXiv collaboration\nnetwork, the Yeast protein-protein interaction, and the US airlines routes\nnetwork, we show that the link prediction performance of LEAP is at least as\ngood as the current state of the art methods, such as SEAL and WLNM. Next, we\nconsider the problem of predicting user ratings on other users: this problem is\nknown as the edge-weight prediction problem in weighted signed networks (WSN).\nOn Bitcoin networks, and Wikipedia RfA, we show that LEAP performs consistently\nbetter than the Fairness & Goodness based regression models, varying the amount\nof training edges between 10 to 90%. These examples demonstrate that LEAP, in\nspite of its generality, can match or best the performance of approaches that\nhave been especially crafted to solve very specific edge prediction problems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 21:31:04 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Agrawal", "Rakshit", ""], ["de Alfaro", "Luca", ""]]}, {"id": "1903.04631", "submitter": "Asad Haris", "authors": "Asad Haris, Noah Simon, Ali Shojaie", "title": "Wavelet regression and additive models for irregularly spaced data", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 2018, 8987-8997", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for nonparametric regression using wavelet basis\nfunctions. Our proposal, $\\texttt{waveMesh}$, can be applied to non-equispaced\ndata with sample size not necessarily a power of 2. We develop an efficient\nproximal gradient descent algorithm for computing the estimator and establish\nadaptive minimax convergence rates. The main appeal of our approach is that it\nnaturally extends to additive and sparse additive models for a potentially\nlarge number of covariates. We prove minimax optimal convergence rates under a\nweak compatibility condition for sparse additive models. The compatibility\ncondition holds when we have a small number of covariates. Additionally, we\nestablish convergence rates for when the condition is not met. We complement\nour theoretical results with empirical studies comparing $\\texttt{waveMesh}$ to\nexisting methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 22:14:40 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Haris", "Asad", ""], ["Simon", "Noah", ""], ["Shojaie", "Ali", ""]]}, {"id": "1903.04656", "submitter": "Marius Arvinte", "authors": "Marius Arvinte, Ahmed H. Tewfik, Sriram Vishwanath", "title": "Deep Log-Likelihood Ratio Quantization", "comments": "Accepted for publication at EUSIPCO 2019. Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, a deep learning-based method for log-likelihood ratio (LLR)\nlossy compression and quantization is proposed, with emphasis on a single-input\nsingle-output uncorrelated fading communication setting. A deep autoencoder\nnetwork is trained to compress, quantize and reconstruct the bit log-likelihood\nratios corresponding to a single transmitted symbol. Specifically, the encoder\nmaps to a latent space with dimension equal to the number of sufficient\nstatistics required to recover the inputs - equal to three in this case - while\nthe decoder aims to reconstruct a noisy version of the latent representation\nwith the purpose of modeling quantization effects in a differentiable way.\nSimulation results show that, when applied to a standard rate-1/2 low-density\nparity-check (LDPC) code, a finite precision compression factor of nearly three\ntimes is achieved when storing an entire codeword, with an incurred loss of\nperformance lower than 0.1 dB compared to straightforward scalar quantization\nof the log-likelihood ratios.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 23:40:05 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 15:17:44 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 23:24:12 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Arvinte", "Marius", ""], ["Tewfik", "Ahmed H.", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1903.04666", "submitter": "Joseph Gaudio", "authors": "Joseph E. Gaudio, Travis E. Gibson, Anuradha M. Annaswamy, Michael A.\n  Bolender", "title": "Provably Correct Learning Algorithms in the Presence of Time-Varying\n  Features Using a Variational Perspective", "comments": "25 pages, additional simulation detail, paper rewritten", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Features in machine learning problems are often time-varying and may be\nrelated to outputs in an algebraic or dynamical manner. The dynamic nature of\nthese machine learning problems renders current higher order accelerated\ngradient descent methods unstable or weakens their convergence guarantees.\nInspired by methods employed in adaptive control, this paper proposes new\nalgorithms for the case when time-varying features are present, and\ndemonstrates provable performance guarantees. In particular, we develop a\nunified variational perspective within a continuous time algorithm. This\nvariational perspective includes higher order learning concepts and\nnormalization, both of which stem from adaptive control, and allows stability\nto be established for dynamical machine learning problems where time-varying\nfeatures are present. These higher order algorithms are also examined for\nprovably correct learning in adaptive control and identification. Simulations\nare provided to verify the theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 00:03:44 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 17:21:10 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 20:30:25 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Gaudio", "Joseph E.", ""], ["Gibson", "Travis E.", ""], ["Annaswamy", "Anuradha M.", ""], ["Bolender", "Michael A.", ""]]}, {"id": "1903.04677", "submitter": "M. Tauhidur Rahman", "authors": "Kyle Worley and Md Tauhidur Rahman", "title": "Supervised Machine Learning Techniques for Trojan Detection with Ring\n  Oscillator Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the globalization of the semiconductor manufacturing process, electronic\ndevices are powerless against malicious modification of hardware in the supply\nchain. The ever-increasing threat of hardware Trojan attacks against integrated\ncircuits has spurred a need for accurate and efficient detection methods. Ring\noscillator network (RON) is used to detect the Trojan by capturing the\ndifference in power consumption; the power consumption of a Trojan-free circuit\nis different from the Trojan-inserted circuit. However, the process variation\nand measurement noise are the major obstacles to detect hardware Trojan with\nhigh accuracy. In this paper, we quantitatively compare four supervised machine\nlearning algorithms and classifier optimization strategies for maximizing\naccuracy and minimizing the false positive rate (FPR). These supervised\nlearning techniques show an improved false positive rate compared to principal\ncomponent analysis (PCA) and convex hull classification by nearly 40% while\nmaintaining > 90\\% binary classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 00:37:33 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Worley", "Kyle", ""], ["Rahman", "Md Tauhidur", ""]]}, {"id": "1903.04681", "submitter": "Wei Ma", "authors": "Wei Ma, Xidong Pi, Sean Qian", "title": "Estimating multi-class dynamic origin-destination demand through a\n  forward-backward algorithm on computational graphs", "comments": "31 pages, 21 figures, submitted to Transportation Research Part C:\n  Emerging Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation networks are unprecedentedly complex with heterogeneous\nvehicular flow. Conventionally, vehicle classes are considered by vehicle\nclassifications (such as standard passenger cars and trucks). However, vehicle\nflow heterogeneity stems from many other aspects in general, e.g.,\nride-sourcing vehicles versus personal vehicles, human driven vehicles versus\nconnected and automated vehicles. Provided with some observations of vehicular\nflow for each class in a large-scale transportation network, how to estimate\nthe multi-class spatio-temporal vehicular flow, in terms of time-varying\nOrigin-Destination (OD) demand and path/link flow, remains a big challenge.\nThis paper presents a solution framework for multi-class dynamic OD demand\nestimation (MCDODE) in large-scale networks. The proposed framework is built on\na computational graph with tensor representations of spatio-temporal flow and\nall intermediate features involved in the MCDODE formulation. A\nforward-backward algorithm is proposed to efficiently solve the MCDODE\nformulation on computational graphs. In addition, we propose a novel concept of\ntree-based cumulative curves to estimate the gradient of OD demand. A Growing\nTree algorithm is developed to construct tree-based cumulative curves. The\nproposed framework is examined on a small network as well as a real-world\nlarge-scale network. The experiment results indicate that the proposed\nframework is compelling, satisfactory and computationally plausible.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 01:05:46 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Ma", "Wei", ""], ["Pi", "Xidong", ""], ["Qian", "Sean", ""]]}, {"id": "1903.04703", "submitter": "Jian Wu", "authors": "Jian Wu, Saul Toscano-Palmerin, Peter I. Frazier and Andrew Gordon\n  Wilson", "title": "Practical Multi-fidelity Bayesian Optimization for Hyperparameter Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is popular for optimizing time-consuming black-box\nobjectives. Nonetheless, for hyperparameter tuning in deep neural networks, the\ntime required to evaluate the validation error for even a few hyperparameter\nsettings remains a bottleneck. Multi-fidelity optimization promises relief\nusing cheaper proxies to such objectives --- for example, validation error for\na network trained using a subset of the training points or fewer iterations\nthan required for convergence. We propose a highly flexible and practical\napproach to multi-fidelity Bayesian optimization, focused on efficiently\noptimizing hyperparameters for iteratively trained supervised learning models.\nWe introduce a new acquisition function, the trace-aware knowledge-gradient,\nwhich efficiently leverages both multiple continuous fidelity controls and\ntrace observations --- values of the objective at a sequence of fidelities,\navailable when varying fidelity using training iterations. We provide a\nprovably convergent method for optimizing our acquisition function and show it\noutperforms state-of-the-art alternatives for hyperparameter tuning of deep\nneural networks and large-scale kernel learning.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 02:14:04 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Wu", "Jian", ""], ["Toscano-Palmerin", "Saul", ""], ["Frazier", "Peter I.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1903.04711", "submitter": "Wentao Zhu", "authors": "Wentao Zhu", "title": "Deep Learning for Automated Medical Image Analysis", "comments": "PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical imaging is an essential tool in many areas of medical applications,\nused for both diagnosis and treatment. However, reading medical images and\nmaking diagnosis or treatment recommendations require specially trained medical\nspecialists. The current practice of reading medical images is labor-intensive,\ntime-consuming, costly, and error-prone. It would be more desirable to have a\ncomputer-aided system that can automatically make diagnosis and treatment\nrecommendations. Recent advances in deep learning enable us to rethink the ways\nof clinician diagnosis based on medical images. In this thesis, we will\nintroduce 1) mammograms for detecting breast cancers, the most frequently\ndiagnosed solid cancer for U.S. women, 2) lung CT images for detecting lung\ncancers, the most frequently diagnosed malignant cancer, and 3) head and neck\nCT images for automated delineation of organs at risk in radiotherapy. First,\nwe will show how to employ the adversarial concept to generate the hard\nexamples improving mammogram mass segmentation. Second, we will demonstrate how\nto use the weakly labeled data for the mammogram breast cancer diagnosis by\nefficiently design deep learning for multi-instance learning. Third, the thesis\nwill walk through DeepLung system which combines deep 3D ConvNets and GBM for\nautomated lung nodule detection and classification. Fourth, we will show how to\nuse weakly labeled data to improve existing lung nodule detection system by\nintegrating deep learning with a probabilistic graphic model. Lastly, we will\ndemonstrate the AnatomyNet which is thousands of times faster and more accurate\nthan previous methods on automated anatomy segmentation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 03:28:37 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Zhu", "Wentao", ""]]}, {"id": "1903.04714", "submitter": "Michael Teng", "authors": "Michael Teng, Tuan Anh Le, Adam Scibior, Frank Wood", "title": "Imitation Learning of Factored Multi-agent Reactive Models", "comments": "incorporated into another paper with different motivations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply recent advances in deep generative modeling to the task of imitation\nlearning from biological agents. Specifically, we apply variations of the\nvariational recurrent neural network model to a multi-agent setting where we\nlearn policies of individual uncoordinated agents acting based on their\nperceptual inputs and their hidden belief state. We learn stochastic policies\nfor these agents directly from observational data, without constructing a\nreward function. An inference network learned jointly with the policy allows\nfor efficient inference over the agent's belief state given a sequence of its\ncurrent perceptual inputs and the prior actions it performed, which lets us\nextrapolate observed sequences of behavior into the future while maintaining\nuncertainty estimates over future trajectories. We test our approach on a\ndataset of flies interacting in a 2D environment, where we demonstrate better\npredictive performance than existing approaches which learn deterministic\npolicies with recurrent neural networks. We further show that the uncertainty\nestimates over future trajectories we obtain are well calibrated, which makes\nthem useful for a variety of downstream processing tasks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 03:50:27 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 21:13:23 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Teng", "Michael", ""], ["Le", "Tuan Anh", ""], ["Scibior", "Adam", ""], ["Wood", "Frank", ""]]}, {"id": "1903.04717", "submitter": "Scott Coull", "authors": "Scott E. Coull and Christopher Gardner", "title": "Activation Analysis of a Byte-Based Deep Neural Network for Malware\n  Classification", "comments": "2nd Deep Learning and Security Workshop (DLS 2019)", "journal-ref": "2nd Deep Learning and Security Workshop (DLS 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature engineering is one of the most costly aspects of developing effective\nmachine learning models, and that cost is even greater in specialized problem\ndomains, like malware classification, where expert skills are necessary to\nidentify useful features. Recent work, however, has shown that deep learning\nmodels can be used to automatically learn feature representations directly from\nthe raw, unstructured bytes of the binaries themselves. In this paper, we\nexplore what these models are learning about malware. To do so, we examine the\nlearned features at multiple levels of resolution, from individual byte\nembeddings to end-to-end analysis of the model. At each step, we connect these\nbyte-oriented activations to their original semantics through parsing and\ndisassembly of the binary to arrive at human-understandable features. Through\nour results, we identify several interesting features learned by the model and\ntheir connection to manually-derived features typically used by traditional\nmachine learning models. Additionally, we explore the impact of training data\nvolume and regularization on the quality of the learned features and the\nefficacy of the classifiers, revealing the somewhat paradoxical insight that\nbetter generalization does not necessarily result in better performance for\nbyte-based malware classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 04:00:42 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 02:57:07 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Coull", "Scott E.", ""], ["Gardner", "Christopher", ""]]}, {"id": "1903.04722", "submitter": "Manan Oza", "authors": "Manan Oza, Himanshu Vaghela, Kriti Srivastava", "title": "Progressive Generative Adversarial Binary Networks for Music Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent improvements in generative adversarial network (GAN) training\ntechniques prove that progressively training a GAN drastically stabilizes the\ntraining and improves the quality of outputs produced. Adding layers after the\nprevious ones have converged has proven to help in better overall convergence\nand stability of the model as well as reducing the training time by a\nsufficient amount. Thus we use this training technique to train the model\nprogressively in the time and pitch domain i.e. starting from a very small time\nvalue and pitch range we gradually expand the matrix sizes until the end result\nis a completely trained model giving outputs having tensor sizes [4 (bar) x 96\n(time steps) x 84 (pitch values) x 8 (tracks)]. As proven in previously\nproposed models deterministic binary neurons also help in improving the\nresults. Thus we make use of a layer of deterministic binary neurons at the end\nof the generator to get binary valued outputs instead of fractional values\nexisting between 0 and 1.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 04:16:20 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Oza", "Manan", ""], ["Vaghela", "Himanshu", ""], ["Srivastava", "Kriti", ""]]}, {"id": "1903.04735", "submitter": "Huyan Huang", "authors": "Huyan Huang, Yipeng Liu, Ce Zhu", "title": "Low-rank Tensor Grid for Image Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor completion estimates missing components by exploiting the low-rank\nstructure of multi-way data. The recently proposed methods based on tensor\ntrain (TT) and tensor ring (TR) show better performance in image recovery than\nclassical ones. Compared with TT and TR, the projected entangled pair state\n(PEPS), which is also called tensor grid (TG), allows more interactions between\ndifferent dimensions, and may lead to more compact representation. In this\npaper, we propose to perform image completion based on low-rank tensor grid. A\ntwo-stage density matrix renormalization group algorithm is used for\ninitialization of TG decomposition, which consists of multiple TT\ndecompositions. The latent TG factors can be alternatively obtained by solving\nalternating least squares problems. To further improve the computational\nefficiency, a multi-linear matrix factorization for low rank TG completion is\ndeveloped by using parallel matrix factorization. Experimental results on\nsynthetic data and real-world images show the proposed methods outperform the\nexisting ones in terms of recovery accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 05:36:37 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 02:41:09 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 07:58:20 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Huang", "Huyan", ""], ["Liu", "Yipeng", ""], ["Zhu", "Ce", ""]]}, {"id": "1903.04774", "submitter": "Patrick Schlachter", "authors": "Patrick Schlachter, Yiwen Liao and Bin Yang", "title": "Open-Set Recognition Using Intra-Class Splitting", "comments": "IEEE European Signal Processing Conference 2019 (EUSIPCO 2019)", "journal-ref": null, "doi": "10.23919/EUSIPCO.2019.8902738", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method to use deep neural networks as end-to-end\nopen-set classifiers. It is based on intra-class data splitting. In open-set\nrecognition, only samples from a limited number of known classes are available\nfor training. During inference, an open-set classifier must reject samples from\nunknown classes while correctly classifying samples from known classes. The\nproposed method splits given data into typical and atypical normal subsets by\nusing a closed-set classifier. This enables to model the abnormal classes by\natypical normal samples. Accordingly, the open-set recognition problem is\nreformulated into a traditional classification problem. In addition, a\nclosed-set regularization is proposed to guarantee a high closed-set\nclassification performance. Intensive experiments on five well-known image\ndatasets showed the effectiveness of the proposed method which outperformed the\nbaselines and achieved a distinct improvement over the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 08:24:15 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 14:07:31 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 13:50:35 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Schlachter", "Patrick", ""], ["Liao", "Yiwen", ""], ["Yang", "Bin", ""]]}, {"id": "1903.04797", "submitter": "Christian A. Naesseth", "authors": "Christian A. Naesseth and Fredrik Lindsten and Thomas B. Sch\\\"on", "title": "Elements of Sequential Monte Carlo", "comments": "Under review at Foundations and Trends in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core problem in statistics and probabilistic machine learning is to compute\nprobability distributions and expectations. This is the fundamental problem of\nBayesian statistics and machine learning, which frames all inference as\nexpectations with respect to the posterior distribution. The key challenge is\nto approximate these intractable expectations. In this tutorial, we review\nsequential Monte Carlo (SMC), a random-sampling-based class of methods for\napproximate inference. First, we explain the basics of SMC, discuss practical\nissues, and review theoretical results. We then examine two of the main user\ndesign choices: the proposal distributions and the so called intermediate\ntarget distributions. We review recent results on how variational inference and\namortization can be used to learn efficient proposals and target distributions.\nNext, we discuss the SMC estimate of the normalizing constant, how this can be\nused for pseudo-marginal inference and inference evaluation. Throughout the\ntutorial we illustrate the use of SMC on various models commonly used in\nmachine learning, such as stochastic recurrent neural networks, probabilistic\ngraphical models, and probabilistic programs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 09:28:05 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Naesseth", "Christian A.", ""], ["Lindsten", "Fredrik", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1903.04820", "submitter": "Parviz Asghari", "authors": "Parviz Asghari, Elnaz Soelimani, Ehsan Nazerfard", "title": "Online Human Activity Recognition Employing Hierarchical Hidden Markov\n  Models", "comments": "9 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years there has been a growing interest in Human Activity\nRecognition~(HAR) topic. Sensor-based HAR approaches, in particular, has been\ngaining more popularity owing to their privacy preserving nature. Furthermore,\ndue to the widespread accessibility of the internet, a broad range of\nstreaming-based applications such as online HAR, has emerged over the past\ndecades. However, proposing sufficiently robust online activity recognition\napproach in smart environment setting is still considered as a remarkable\nchallenge. This paper presents a novel online application of Hierarchical\nHidden Markov Model in order to detect the current activity on the live\nstreaming of sensor events. Our method consists of two phases. In the first\nphase, data stream is segmented based on the beginning and ending of the\nactivity patterns. Also, on-going activity is reported with every receiving\nobservation. This phase is implemented using Hierarchical Hidden Markov models.\nThe second phase is devoted to the correction of the provided label for the\nsegmented data stream based on statistical features. The proposed model can\nalso discover the activities that happen during another activity - so-called\ninterrupted activities. After detecting the activity pane, the predicted label\nwill be corrected utilizing statistical features such as time of day at which\nthe activity happened and the duration of the activity. We validated our\nproposed method by testing it against two different smart home datasets and\ndemonstrated its effectiveness, which is competing with the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 10:22:33 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Asghari", "Parviz", ""], ["Soelimani", "Elnaz", ""], ["Nazerfard", "Ehsan", ""]]}, {"id": "1903.04829", "submitter": "Alexander Marx", "authors": "Alexander Marx and Jilles Vreeken", "title": "Testing Conditional Independence on Discrete Data using Stochastic\n  Complexity", "comments": "18 pages, accepted at AISTATS'19, the proposed test was released in\n  the R package SCCI", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing for conditional independence is a core aspect of constraint-based\ncausal discovery. Although commonly used tests are perfect in theory, they\noften fail to reject independence in practice, especially when conditioning on\nmultiple variables.\n  We focus on discrete data and propose a new test based on the notion of\nalgorithmic independence that we instantiate using stochastic complexity.\nAmongst others, we show that our proposed test, SCI, is an asymptotically\nunbiased as well as $L_2$ consistent estimator for conditional mutual\ninformation (CMI). Further, we show that SCI can be reformulated to find a\nsensible threshold for CMI that works well on limited samples. Empirical\nevaluation shows that SCI has a lower type II error than commonly used tests.\nAs a result, we obtain a higher recall when we use SCI in causal discovery\nalgorithms, without compromising the precision.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 10:40:42 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Marx", "Alexander", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1903.04860", "submitter": "Jaeyoon Yoo", "authors": "Jaeyoon Yoo, Changhwa Park, Yongjun Hong, Sungroh Yoon", "title": "Learning Condensed and Aligned Features for Unsupervised Domain\n  Adaptation Using Label Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation aiming to learn a specific task for one domain\nusing another domain data has emerged to address the labeling issue in\nsupervised learning, especially because it is difficult to obtain massive\namounts of labeled data in practice. The existing methods have succeeded by\nreducing the difference between the embedded features of both domains, but the\nperformance is still unsatisfactory compared to the supervised learning scheme.\nThis is attributable to the embedded features that lay around each other but do\nnot align perfectly and establish clearly separable clusters. We propose a\nnovel domain adaptation method based on label propagation and cycle consistency\nto let the clusters of the features from the two domains overlap exactly and\nbecome clear for high accuracy. Specifically, we introduce cycle consistency to\nenforce the relationship between each cluster and exploit label propagation to\nachieve the association between the data from the perspective of the manifold\nstructure instead of a one-to-one relation. Hence, we successfully formed\naligned and discriminative clusters. We present the empirical results of our\nmethod for various domain adaptation scenarios and visualize the embedded\nfeatures to prove that our method is critical for better domain adaptation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 12:06:57 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Yoo", "Jaeyoon", ""], ["Park", "Changhwa", ""], ["Hong", "Yongjun", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1903.04870", "submitter": "Marcel Bollmann", "authors": "Marcel Bollmann, Natalia Korchagina, Anders S{\\o}gaard", "title": "Few-Shot and Zero-Shot Learning for Historical Text Normalization", "comments": "Accepted at DeepLo-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Historical text normalization often relies on small training datasets. Recent\nwork has shown that multi-task learning can lead to significant improvements by\nexploiting synergies with related datasets, but there has been no systematic\nstudy of different multi-task learning architectures. This paper evaluates\n63~multi-task learning configurations for sequence-to-sequence-based historical\ntext normalization across ten datasets from eight languages, using\nautoencoding, grapheme-to-phoneme mapping, and lemmatization as auxiliary\ntasks. We observe consistent, significant improvements across languages when\ntraining data for the target task is limited, but minimal or no improvements\nwhen training data is abundant. We also show that zero-shot learning\noutperforms the simple, but relatively strong, identity baseline.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 12:30:54 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 13:42:32 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Bollmann", "Marcel", ""], ["Korchagina", "Natalia", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1903.04879", "submitter": "Indraneil Paul Mr.", "authors": "Indraneil Paul, Abhinav Khattar, Shaan Chopra, Ponnurangam Kumaraguru,\n  Manish Gupta", "title": "What sets Verified Users apart? Insights, Analysis and Prediction of\n  Verified Users on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social network and publishing platforms, such as Twitter, support the concept\nof a secret proprietary verification process, for handles they deem worthy of\nplatform-wide public interest. In line with significant prior work which\nsuggests that possessing such a status symbolizes enhanced credibility in the\neyes of the platform audience, a verified badge is clearly coveted among public\nfigures and brands. What are less obvious are the inner workings of the\nverification process and what being verified represents. This lack of clarity,\ncoupled with the flak that Twitter received by extending aforementioned status\nto political extremists in 2017, backed Twitter into publicly admitting that\nthe process and what the status represented needed to be rethought.\n  With this in mind, we seek to unravel the aspects of a user's profile which\nlikely engender or preclude verification. The aim of the paper is two-fold:\nFirst, we test if discerning the verification status of a handle from profile\nmetadata and content features is feasible. Second, we unravel the features\nwhich have the greatest bearing on a handle's verification status. We collected\na dataset consisting of profile metadata of all 231,235 verified\nEnglish-speaking users (as of July 2018), a control sample of 175,930\nnon-verified English-speaking users and all their 494 million tweets over a one\nyear collection period. Our proposed models are able to reliably identify\nverification status (Area under curve AUC > 99%). We show that number of public\nlist memberships, presence of neutral sentiment in tweets and an authoritative\nlanguage style are the most pertinent predictors of verification status.\n  To the best of our knowledge, this work represents the first attempt at\ndiscerning and classifying verification worthy users on Twitter.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 12:56:22 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Paul", "Indraneil", ""], ["Khattar", "Abhinav", ""], ["Chopra", "Shaan", ""], ["Kumaraguru", "Ponnurangam", ""], ["Gupta", "Manish", ""]]}, {"id": "1903.04887", "submitter": "Honghao Wei", "authors": "Honghao Wei, Xiaohan Kang, Weina Wang, Lei Ying", "title": "QuickStop: A Markov Optimal Stopping Approach for Quickest\n  Misinformation Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper combines data-driven and model-driven methods for real-time\nmisinformation detection. Our algorithm, named QuickStop, is an optimal\nstopping algorithm based on a probabilistic information spreading model\nobtained from labeled data. The algorithm consists of an offline machine\nlearning algorithm for learning the probabilistic information spreading model\nand an online optimal stopping algorithm to detect misinformation. The online\ndetection algorithm has both low computational and memory complexities. Our\nnumerical evaluations with a real-world dataset show that QuickStop outperforms\nexisting misinformation detection algorithms in terms of both accuracy and\ndetection time (number of observations needed for detection). Our evaluations\nwith synthetic data further show that QuickStop is robust to (offline) learning\nerrors.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 22:23:33 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 20:29:36 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Wei", "Honghao", ""], ["Kang", "Xiaohan", ""], ["Wang", "Weina", ""], ["Ying", "Lei", ""]]}, {"id": "1903.04925", "submitter": "Angana Chakraborty", "authors": "Angana Chakraborty and Sanghamitra Bandyopadhyay", "title": "conLSH: Context based Locality Sensitive Hashing for Mapping of noisy\n  SMRT Reads", "comments": "arXiv admin note: text overlap with arXiv:1705.03933", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single Molecule Real-Time (SMRT) sequencing is a recent advancement of Next\nGen technology developed by Pacific Bio (PacBio). It comes with an explosion of\nlong and noisy reads demanding cutting edge research to get most out of it. To\ndeal with the high error probability of SMRT data, a novel contextual Locality\nSensitive Hashing (conLSH) based algorithm is proposed in this article, which\ncan effectively align the noisy SMRT reads to the reference genome. Here,\nsequences are hashed together based not only on their closeness, but also on\nsimilarity of context. The algorithm has $\\mathcal{O}(n^{\\rho+1})$ space\nrequirement, where $n$ is the number of sequences in the corpus and $\\rho$ is a\nconstant. The indexing time and querying time are bounded by $\\mathcal{O}(\n\\frac{n^{\\rho+1} \\cdot \\ln n}{\\ln \\frac{1}{P_2}})$ and $\\mathcal{O}(n^\\rho)$\nrespectively, where $P_2 > 0$, is a probability value. This algorithm is\nparticularly useful for retrieving similar sequences, a widely used task in\nbiology. The proposed conLSH based aligner is compared with rHAT, popularly\nused for aligning SMRT reads, and is found to comprehensively beat it in speed\nas well as in memory requirements. In particular, it takes approximately\n$24.2\\%$ less processing time, while saving about $70.3\\%$ in peak memory\nrequirement for H.sapiens PacBio dataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 17:49:01 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Chakraborty", "Angana", ""], ["Bandyopadhyay", "Sanghamitra", ""]]}, {"id": "1903.04932", "submitter": "Minju Jung", "authors": "Minju Jung, Takazumi Matsumoto, Jun Tani", "title": "Goal-Directed Behavior under Variational Predictive Coding: Dynamic\n  Organization of Visual Attention and Working Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental simulation is a critical cognitive function for goal-directed behavior\nbecause it is essential for assessing actions and their consequences. When a\nself-generated or externally specified goal is given, a sequence of actions\nthat is most likely to attain that goal is selected among other candidates via\nmental simulation. Therefore, better mental simulation leads to better\ngoal-directed action planning. However, developing a mental simulation model is\nchallenging because it requires knowledge of self and the environment. The\ncurrent paper studies how adequate goal-directed action plans of robots can be\nmentally generated by dynamically organizing top-down visual attention and\nvisual working memory. For this purpose, we propose a neural network model\nbased on variational Bayes predictive coding, where goal-directed action\nplanning is formulated by Bayesian inference of latent intentional space. Our\nexperimental results showed that cognitively meaningful competencies, such as\nautonomous top-down attention to the robot end effector (its hand) as well as\ndynamic organization of occlusion-free visual working memory, emerged.\nFurthermore, our analysis of comparative experiments indicated that\nintroduction of visual working memory and the inference mechanism using\nvariational Bayes predictive coding significantly improve the performance in\nplanning adequate goal-directed actions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:00:53 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Jung", "Minju", ""], ["Matsumoto", "Takazumi", ""], ["Tani", "Jun", ""]]}, {"id": "1903.04933", "submitter": "Sander Dieleman", "authors": "Jeffrey De Fauw, Sander Dieleman, Karen Simonyan", "title": "Hierarchical Autoregressive Image Models with Auxiliary Decoders", "comments": "Updated: added human evaluation results, incorporated review feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive generative models of images tend to be biased towards\ncapturing local structure, and as a result they often produce samples which are\nlacking in terms of large-scale coherence. To address this, we propose two\nmethods to learn discrete representations of images which abstract away local\ndetail. We show that autoregressive models conditioned on these representations\ncan produce high-fidelity reconstructions of images, and that we can train\nautoregressive priors on these representations that produce samples with\nlarge-scale coherence. We can recursively apply the learning procedure,\nyielding a hierarchy of progressively more abstract image representations. We\ntrain hierarchical class-conditional autoregressive models on the ImageNet\ndataset and demonstrate that they are able to generate realistic images at\nresolutions of 128$\\times$128 and 256$\\times$256 pixels. We also perform a\nhuman evaluation study comparing our models with both adversarial and\nlikelihood-based state-of-the-art generative models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 22:13:52 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 17:55:59 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["De Fauw", "Jeffrey", ""], ["Dieleman", "Sander", ""], ["Simonyan", "Karen", ""]]}, {"id": "1903.04958", "submitter": "Yukun Ding", "authors": "Yukun Ding, Yiyu Shi", "title": "Real-Time Boiler Control Optimization with Machine Learning", "comments": "To appear in TC-CPS Newsletter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In coal-fired power plants, it is critical to improve the operational\nefficiency of boilers for sustainability. In this work, we formulate real-time\nboiler control as an optimization problem that looks for the best distribution\nof temperature in different zones and oxygen content from the flue to improve\nthe boiler's stability and energy efficiency. We employ an efficient algorithm\nby integrating appropriate machine learning and optimization techniques. We\nobtain a large dataset collected from a real boiler for more than two months\nfrom our industry partner, and conduct extensive experiments to demonstrate the\neffectiveness and efficiency of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 04:25:36 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Ding", "Yukun", ""], ["Shi", "Yiyu", ""]]}, {"id": "1903.04959", "submitter": "Haotian Fu", "authors": "Haotian Fu, Hongyao Tang, Jianye Hao, Zihan Lei, Yingfeng Chen,\n  Changjie Fan", "title": "Deep Multi-Agent Reinforcement Learning with Discrete-Continuous Hybrid\n  Action Spaces", "comments": null, "journal-ref": "IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has been applied to address a variety of\ncooperative multi-agent problems with either discrete action spaces or\ncontinuous action spaces. However, to the best of our knowledge, no previous\nwork has ever succeeded in applying DRL to multi-agent problems with\ndiscrete-continuous hybrid (or parameterized) action spaces which is very\ncommon in practice. Our work fills this gap by proposing two novel algorithms:\nDeep Multi-Agent Parameterized Q-Networks (Deep MAPQN) and Deep Multi-Agent\nHierarchical Hybrid Q-Networks (Deep MAHHQN). We follow the centralized\ntraining but decentralized execution paradigm: different levels of\ncommunication between different agents are used to facilitate the training\nprocess, while each agent executes its policy independently based on local\nobservations during execution. Our empirical results on several challenging\ntasks (simulated RoboCup Soccer and game Ghost Story) show that both Deep MAPQN\nand Deep MAHHQN are effective and significantly outperform existing independent\ndeep parameterized Q-learning method.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:40:32 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Fu", "Haotian", ""], ["Tang", "Hongyao", ""], ["Hao", "Jianye", ""], ["Lei", "Zihan", ""], ["Chen", "Yingfeng", ""], ["Fan", "Changjie", ""]]}, {"id": "1903.04982", "submitter": "Yujian Li", "authors": "Yujian Li and Chuanhui Shan", "title": "A Capsule-unified Framework of Deep Neural Networks for Graphical\n  Programming", "comments": "20 pages; 26 figures. arXiv admin note: text overlap with\n  arXiv:1805.03551", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the growth of deep learning has produced a large number of deep\nneural networks. How to describe these networks unifiedly is becoming an\nimportant issue. We first formalize neural networks in a mathematical\ndefinition, give their directed graph representations, and prove a generation\ntheorem about the induced networks of connected directed acyclic graphs. Then,\nusing the concept of capsule to extend neural networks, we set up a\ncapsule-unified framework for deep learning, including a mathematical\ndefinition of capsules, an induced model for capsule networks and a universal\nbackpropagation algorithm for training them. Finally, we discuss potential\napplications of the framework to graphical programming with standard graphical\nsymbols of capsules, neurons, and connections.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 13:32:05 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 05:02:59 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Li", "Yujian", ""], ["Shan", "Chuanhui", ""]]}, {"id": "1903.04988", "submitter": "Breton Minnehan", "authors": "Breton Minnehan and Andreas Savakis", "title": "Cascaded Projection: End-to-End Network Compression and Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven approach for deep convolutional neural network\ncompression that achieves high accuracy with high throughput and low memory\nrequirements. Current network compression methods either find a low-rank\nfactorization of the features that requires more memory, or select only a\nsubset of features by pruning entire filter channels. We propose the Cascaded\nProjection (CaP) compression method that projects the output and input filter\nchannels of successive layers to a unified low dimensional space based on a\nlow-rank projection. We optimize the projection to minimize classification loss\nand the difference between the next layer's features in the compressed and\nuncompressed networks. To solve this non-convex optimization problem we propose\na new optimization method of a proxy matrix using backpropagation and\nStochastic Gradient Descent (SGD) with geometric constraints. Our cascaded\nprojection approach leads to improvements in all critical areas of network\ncompression: high accuracy, low memory consumption, low parameter count and\nhigh processing speed. The proposed CaP method demonstrates state-of-the-art\nresults compressing VGG16 and ResNet networks with over 4x reduction in the\nnumber of computations and excellent performance in top-5 accuracy on the\nImageNet dataset before and after fine-tuning.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 15:20:10 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Minnehan", "Breton", ""], ["Savakis", "Andreas", ""]]}, {"id": "1903.04991", "submitter": "Andrzej Banburski", "authors": "Andrzej Banburski, Qianli Liao, Brando Miranda, Lorenzo Rosasco,\n  Fernanda De La Torre, Jack Hidary and Tomaso Poggio", "title": "Theory III: Dynamics and Generalization in Deep Networks", "comments": "47 pages, 11 figures. This replaces previous versions of Theory III,\n  that appeared on Arxiv [arXiv:1806.11379, arXiv:1801.00173] or on the CBMM\n  site. v5: Changes throughout the paper to the presentation and tightening\n  some of the statements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key to generalization is controlling the complexity of the network.\nHowever, there is no obvious control of complexity -- such as an explicit\nregularization term -- in the training of deep networks for classification. We\nwill show that a classical form of norm control -- but kind of hidden -- is\npresent in deep networks trained with gradient descent techniques on\nexponential-type losses. In particular, gradient descent induces a dynamics of\nthe normalized weights which converge for $t \\to \\infty$ to an equilibrium\nwhich corresponds to a minimum norm (or maximum margin) solution. For\nsufficiently large but finite $\\rho$ -- and thus finite $t$ -- the dynamics\nconverges to one of several margin maximizers, with the margin monotonically\nincreasing towards a limit stationary point of the flow. In the usual case of\nstochastic gradient descent, most of the stationary points are likely to be\nconvex minima corresponding to a constrained minimizer -- the network with\nnormalized weights-- which corresponds to vanishing regularization. The\nsolution has zero generalization gap, for fixed architecture, asymptotically\nfor $N \\to \\infty$, where $N$ is the number of training examples. Our approach\nextends some of the original results of Srebro from linear networks to deep\nnetworks and provides a new perspective on the implicit bias of gradient\ndescent. We believe that the elusive complexity control we describe is\nresponsible for the puzzling empirical finding of good predictive performance\nby deep networks, despite overparametrization.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 15:24:26 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 22:38:08 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 02:02:40 GMT"}, {"version": "v4", "created": "Wed, 3 Jul 2019 22:59:20 GMT"}, {"version": "v5", "created": "Sat, 11 Apr 2020 00:21:50 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Banburski", "Andrzej", ""], ["Liao", "Qianli", ""], ["Miranda", "Brando", ""], ["Rosasco", "Lorenzo", ""], ["De La Torre", "Fernanda", ""], ["Hidary", "Jack", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1903.05006", "submitter": "Zengde Deng", "authors": "Zengde Deng, Anthony Man-Cho So", "title": "An Efficient Augmented Lagrangian Based Method for Constrained Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection is one of the most important tasks in statistics and\nmachine learning. To incorporate more prior information about the regression\ncoefficients, the constrained Lasso model has been proposed in the literature.\nIn this paper, we present an inexact augmented Lagrangian method to solve the\nLasso problem with linear equality constraints. By fully exploiting\nsecond-order sparsity of the problem, we are able to greatly reduce the\ncomputational cost and obtain highly efficient implementations. Furthermore,\nnumerical results on both synthetic data and real data show that our algorithm\nis superior to existing first-order methods in terms of both running time and\nsolution accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 15:51:20 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Deng", "Zengde", ""], ["So", "Anthony Man-Cho", ""]]}, {"id": "1903.05014", "submitter": "Hanno Winter", "authors": "Hanno Winter, Stefan Luthardt, Volker Willert, J\\\"urgen Adamy", "title": "Generating Compact Geometric Track-Maps for Train Positioning\n  Applications", "comments": null, "journal-ref": null, "doi": "10.1109/IVS.2019.8813901", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method to generate compact geometric track-maps\nfor train-borne localization applications. Therefore, we first give a brief\noverview on the purpose of track maps in train-positioning applications. It\nbecomes apparent that there are hardly any adequate methods to generate\nsuitable geometric track-maps. This is why we present a novel map generation\nprocedure. It uses an optimization formulation to find the continuous sequence\nof track geometries that fits the available measurement data best. The\noptimization is initialized with the results from a localization filter\ndeveloped in our previous work. The localization filter also provides the\nrequired information for shape identification and measurement association. The\npresented approach will be evaluated on simulated data as well as on real\nmeasurements.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 16:00:01 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 08:39:26 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Winter", "Hanno", ""], ["Luthardt", "Stefan", ""], ["Willert", "Volker", ""], ["Adamy", "J\u00fcrgen", ""]]}, {"id": "1903.05063", "submitter": "Michael Lingzhi Li", "authors": "Michael Lingzhi Li, Elliott Wolf, Daniel Wintz", "title": "Duration-of-Stay Storage Assignment under Uncertainty", "comments": "15 pages, 4 figures. Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing storage assignment is a central problem in warehousing. Past\nliterature has shown the superiority of the Duration-of-Stay (DoS) method in\nassigning pallets, but the methodology requires perfect prior knowledge of DoS\nfor each pallet, which is unknown and uncertain under realistic conditions. The\ndynamic nature of a warehouse further complicates the validity of synthetic\ndata testing that is often conducted for algorithms. In this paper, in\ncollaboration with a large cold storage company, we release the first publicly\navailable set of warehousing records to facilitate research into this central\nproblem. We introduce a new framework for storage assignment that accounts for\nuncertainty in warehouses. Then, by utilizing a combination of convolutional\nand recurrent neural network models, ParallelNet, we show that it is able to\npredict future shipments well: it achieves up to 29% decrease in MAPE compared\nto CNN-LSTM on unseen future shipments, and suffers less performance decay over\ntime. The framework is then integrated into a first-of-its-kind Storage\nAssignment system, which is being piloted in warehouses across the country,\nwith initial results showing up to 19% in labor savings.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 17:12:07 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 19:27:10 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 01:38:44 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Michael Lingzhi", ""], ["Wolf", "Elliott", ""], ["Wintz", "Daniel", ""]]}, {"id": "1903.05071", "submitter": "Jacob Reinier Maat", "authors": "Jacob Reinier Maat, Nikos Gianniotis, Pavlos Protopapas", "title": "Efficient Optimization of Echo State Networks for Time Series Datasets", "comments": null, "journal-ref": "2018 International Joint Conference on Neural Networks (IJCNN),\n  pp. 1-7. IEEE, 2018", "doi": "10.1109/IJCNN.2018.8489094", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo State Networks (ESNs) are recurrent neural networks that only train\ntheir output layer, thereby precluding the need to backpropagate gradients\nthrough time, which leads to significant computational gains. Nevertheless, a\ncommon issue in ESNs is determining its hyperparameters, which are crucial in\ninstantiating a well performing reservoir, but are often set manually or using\nheuristics. In this work we optimize the ESN hyperparameters using Bayesian\noptimization which, given a limited budget of function evaluations, outperforms\na grid search strategy. In the context of large volumes of time series data,\nsuch as light curves in the field of astronomy, we can further reduce the\noptimization cost of ESNs. In particular, we wish to avoid tuning\nhyperparameters per individual time series as this is costly; instead, we want\nto find ESNs with hyperparameters that perform well not just on individual time\nseries but rather on groups of similar time series without sacrificing\npredictive performance significantly. This naturally leads to a notion of\nclusters, where each cluster is represented by an ESN tuned to model a group of\ntime series of similar temporal behavior. We demonstrate this approach both on\nsynthetic datasets and real world light curves from the MACHO survey. We show\nthat our approach results in a significant reduction in the number of ESN\nmodels required to model a whole dataset, while retaining predictive\nperformance for the series in each cluster.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 17:27:19 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Maat", "Jacob Reinier", ""], ["Gianniotis", "Nikos", ""], ["Protopapas", "Pavlos", ""]]}, {"id": "1903.05082", "submitter": "Michela Paganini", "authors": "Michela Paganini", "title": "Machine Learning Solutions for High Energy Physics: Applications to\n  Electromagnetic Shower Generation, Flavor Tagging, and the Search for\n  di-Higgs Production", "comments": "413 pages, 10 chapters", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ex cs.LG hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis demonstrate the efficacy of designing and developing machine\nlearning (ML) algorithms to selected use cases that encompass many of the\noutstanding challenges in the field of experimental high energy physics.\nAlthough simple implementations of neural networks and boosted decision trees\nhave been used in high energy physics for a long time, the field of ML has\nquickly evolved by devising more complex, fast and stable implementations of\nlearning algorithms. The complexity and power of state-of-the-art deep learning\nfar exceeds those of the learning algorithms implemented in the CERN-developed\n\\texttt{ROOT} library. All aspects of experimental high energy physics have\nbeen and will continue being revolutionized by the software- and hardware-based\ntechnological advances spearheaded by both academic and industrial research in\nother technical disciplines, and the emergent trend of increased\ninterdisciplinarity will soon reframe many scientific domains. This thesis\nexemplifies this spirit of versatility and multidisciplinarity by bridging the\ngap between ML and particle physics, and exploring original lines of work to\nmodernize the reconstruction, particle identification, simulation, and analysis\nworkflows. This contribution documents a collection of novel approaches to\naugment traditional domain-specific methods with modern, automated techniques\nbased on industry-standard, open-source libraries. Specifically, it contributes\nto setting the state-of-the-art for impact parameter-based flavor tagging and\ndi-Higgs searches in the $\\gamma \\gamma b\\bar{b} $ channel with the ATLAS\ndetector at the LHC, it introduces and lays the foundations for the use of\ngenerative adversarial networks for the simulation of particle showers in\ncalorimeters. These results substantiate the notion of ML powering particle\nphysics in the upcoming years and establish baselines for future applications.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 03:49:39 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Paganini", "Michela", ""]]}, {"id": "1903.05083", "submitter": "Rustem Takhanov", "authors": "Rustem Takhanov", "title": "Dimension reduction as an optimization problem over a set of generalized\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical dimension reduction problem can be loosely formulated as a problem\nof finding a $k$-dimensional affine subspace of ${\\mathbb R}^n$ onto which data\npoints ${\\mathbf x}_1,\\cdots, {\\mathbf x}_N$ can be projected without loss of\nvaluable information. We reformulate this problem in the language of tempered\ndistributions, i.e. as a problem of approximating an empirical probability\ndensity function $p_{\\rm{emp}}({\\mathbf x}) = \\frac{1}{N} \\sum_{i=1}^N \\delta^n\n(\\bold{x} - \\bold{x}_i)$, where $\\delta^n$ is an $n$-dimensional Dirac delta\nfunction, by another tempered distribution $q({\\mathbf x})$ whose density is\nsupported in some $k$-dimensional subspace. Thus, our problem is reduced to the\nminimization of a certain loss function $I(q)$ measuring the distance from $q$\nto $p_{\\rm{emp}}$ over a pertinent set of generalized functions, denoted\n$\\mathcal{G}_k$.\n  Another classical problem of data analysis is the sufficient dimension\nreduction problem. We show that it can be reduced to the following problem:\ngiven a function $f: {\\mathbb R}^n\\rightarrow {\\mathbb R}$ and a probability\ndensity function $p({\\mathbf x})$, find a function of the form $g({\\mathbf\nw}^T_1{\\mathbf x}, \\cdots, {\\mathbf w}^T_k{\\mathbf x})$ that minimizes the loss\n${\\mathbb E}_{{\\mathbf x}\\sim p} |f({\\mathbf x})-g({\\mathbf w}^T_1{\\mathbf x},\n\\cdots, {\\mathbf w}^T_k{\\mathbf x})|^2$.\n  We first show that search spaces of the latter two problems are in one-to-one\ncorrespondence which is defined by the Fourier transform. We introduce a\nnonnegative penalty function $R(f)$ and a set of ordinary functions\n$\\Omega_\\epsilon = \\{f| R(f)\\leq \\epsilon\\}$ in such a way that\n$\\Omega_\\epsilon$ `approximates' the space $\\mathcal{G}_k$ when $\\epsilon\n\\rightarrow 0$. Then we present an algorithm for minimization of $I(f)+\\lambda\nR(f)$, based on the idea of two-step iterative computation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:25:18 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Takhanov", "Rustem", ""]]}, {"id": "1903.05084", "submitter": "Julian Theis", "authors": "Julian Theis and Houshang Darabi", "title": "Decay Replay Mining to Predict Next Process Events", "comments": "Revised manuscript. Github repository added", "journal-ref": "IEEE Access, vol. 7, pp. 119787-119803, 2019", "doi": "10.1109/ACCESS.2019.2937085", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex processes, various events can happen in different sequences. The\nprediction of the next event given an a-priori process state is of importance\nin such processes. Recent methods have proposed deep learning techniques such\nas recurrent neural networks, developed on raw event logs, to predict the next\nevent from a process state. However, such deep learning models by themselves\nlack a clear representation of the process states. At the same time, recent\nmethods have neglected the time feature of event instances. In this paper, we\ntake advantage of Petri nets as a powerful tool in modeling complex process\nbehaviors considering time as an elemental variable. We propose an approach\nwhich starts from a Petri net process model constructed by a process mining\nalgorithm. We enhance the Petri net model with time decay functions to create\ncontinuous process state samples. Finally, we use these samples in combination\nwith discrete token movement counters and Petri net markings to train a deep\nlearning model that predicts the next event. We demonstrate significant\nperformance improvements and outperform the state-of-the-art methods on nine\nreal-world benchmark event logs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:53:10 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 15:04:55 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 20:54:32 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Theis", "Julian", ""], ["Darabi", "Houshang", ""]]}, {"id": "1903.05133", "submitter": "Fan Zhou", "authors": "Fan Zhou and Guojing Cong", "title": "A Distributed Hierarchical SGD Algorithm with Sparse Global Reduction", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing communication in training large-scale machine learning applications\non distributed platform is still a big challenge. To address this issue, we\npropose a distributed hierarchical averaging stochastic gradient descent\n(Hier-AVG) algorithm with infrequent global reduction by introducing local\nreduction. As a general type of parallel SGD, Hier-AVG can reproduce several\npopular synchronous parallel SGD variants by adjusting its parameters. We show\nthat Hier-AVG with infrequent global reduction can still achieve standard\nconvergence rate for non-convex optimization problems. In addition, we show\nthat more frequent local averaging with more participants involved can lead to\nfaster training convergence. By comparing Hier-AVG with another popular\ndistributed training algorithm K-AVG, we show that through deploying local\naveraging with fewer number of global averaging, Hier-AVG can still achieve\ncomparable training speed while frequently get better test accuracy. This\nindicates that local averaging can serve as an alternative remedy to\neffectively reduce communication overhead when the number of learners is large.\nExperimental results of Hier-AVG with several state-of-the-art deep neural nets\non CIFAR-10 and IMAGENET-1K are presented to validate our analysis and show its\nsuperiority.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 18:34:49 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 06:18:49 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhou", "Fan", ""], ["Cong", "Guojing", ""]]}, {"id": "1903.05136", "submitter": "Zhijian Liu", "authors": "Zhenjia Xu, Zhijian Liu, Chen Sun, Kevin Murphy, William T. Freeman,\n  Joshua B. Tenenbaum, Jiajun Wu", "title": "Unsupervised Discovery of Parts, Structure, and Dynamics", "comments": "ICLR 2019. The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans easily recognize object parts and their hierarchical structure by\nwatching how they move; they can then predict how each part moves in the\nfuture. In this paper, we propose a novel formulation that simultaneously\nlearns a hierarchical, disentangled object representation and a dynamics model\nfor object parts from unlabeled videos. Our Parts, Structure, and Dynamics\n(PSD) model learns to, first, recognize the object parts via a layered image\nrepresentation; second, predict hierarchy via a structural descriptor that\ncomposes low-level concepts into a hierarchical structure; and third, model the\nsystem dynamics by predicting the future. Experiments on multiple real and\nsynthetic datasets demonstrate that our PSD model works well on all three\ntasks: segmenting object parts, building their hierarchical structure, and\ncapturing their motion distributions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 18:39:10 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Xu", "Zhenjia", ""], ["Liu", "Zhijian", ""], ["Sun", "Chen", ""], ["Murphy", "Kevin", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "1903.05153", "submitter": "Vijil Chenthamarakshan", "authors": "Tian Gao, Jie Chen, Vijil Chenthamarakshan, Michael Witbrock", "title": "A Sequential Set Generation Method for Predicting Set-Valued Outputs", "comments": "Published at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a general machine learning setting where the output is a set of\nlabels or sequences. This output set is unordered and its size varies with the\ninput. Whereas multi-label classification methods seem a natural first resort,\nthey are not readily applicable to set-valued outputs because of the growth\nrate of the output space; and because conventional sequence generation doesn't\nreflect sets' order-free nature. In this paper, we propose a unified\nframework--sequential set generation (SSG)--that can handle output sets of\nlabels and sequences. SSG is a meta-algorithm that leverages any probabilistic\nlearning method for label or sequence prediction, but employs a proper\nregularization such that a new label or sequence is generated repeatedly until\nthe full set is produced. Though SSG is sequential in nature, it does not\npenalize the ordering of the appearance of the set elements and can be applied\nto a variety of set output problems, such as a set of classification labels or\nsequences. We perform experiments with both benchmark and synthetic data sets\nand demonstrate SSG's strong performance over baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:06:18 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Gao", "Tian", ""], ["Chen", "Jie", ""], ["Chenthamarakshan", "Vijil", ""], ["Witbrock", "Michael", ""]]}, {"id": "1903.05157", "submitter": "Adith Boloor", "authors": "Adith Boloor, Xin He, Christopher Gill, Yevgeniy Vorobeychik, Xuan\n  Zhang", "title": "Simple Physical Adversarial Examples against End-to-End Autonomous\n  Driving Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in machine learning, especially techniques such as deep\nneural networks, are promoting a range of high-stakes applications, including\nautonomous driving, which often relies on deep learning for perception. While\ndeep learning for perception has been shown to be vulnerable to a host of\nsubtle adversarial manipulations of images, end-to-end demonstrations of\nsuccessful attacks, which manipulate the physical environment and result in\nphysical consequences, are scarce. Moreover, attacks typically involve\ncarefully constructed adversarial examples at the level of pixels. We\ndemonstrate the first end-to-end attacks on autonomous driving in simulation,\nusing simple physically realizable attacks: the painting of black lines on the\nroad. These attacks target deep neural network models for end-to-end autonomous\ndriving control. A systematic investigation shows that such attacks are\nsurprisingly easy to engineer, and we describe scenarios (e.g., right turns) in\nwhich they are highly effective, and others that are less vulnerable (e.g.,\ndriving straight). Further, we use network deconvolution to demonstrate that\nthe attacks succeed by inducing activation patterns similar to entirely\ndifferent scenarios used in training.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:13:12 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Boloor", "Adith", ""], ["He", "Xin", ""], ["Gill", "Christopher", ""], ["Vorobeychik", "Yevgeniy", ""], ["Zhang", "Xuan", ""]]}, {"id": "1903.05168", "submitter": "Ryan Lowe T.", "authors": "Ryan Lowe and Jakob Foerster and Y-Lan Boureau and Joelle Pineau and\n  Yann Dauphin", "title": "On the Pitfalls of Measuring Emergent Communication", "comments": "AAMAS 2019. 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do we know if communication is emerging in a multi-agent system? The vast\nmajority of recent papers on emergent communication show that adding a\ncommunication channel leads to an increase in reward or task success. This is a\nuseful indicator, but provides only a coarse measure of the agent's learned\ncommunication abilities. As we move towards more complex environments, it\nbecomes imperative to have a set of finer tools that allow qualitative and\nquantitative insights into the emergence of communication. This may be\nespecially useful to allow humans to monitor agents' behaviour, whether for\nfault detection, assessing performance, or even building trust. In this paper,\nwe examine a few intuitive existing metrics for measuring communication, and\nshow that they can be misleading. Specifically, by training deep reinforcement\nlearning agents to play simple matrix games augmented with a communication\nchannel, we find a scenario where agents appear to communicate (their messages\nprovide information about their subsequent action), and yet the messages do not\nimpact the environment or other agent in any way. We explain this phenomenon\nusing ablation studies and by visualizing the representations of the learned\npolicies. We also survey some commonly used metrics for measuring emergent\ncommunication, and provide recommendations as to when these metrics should be\nused.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:33:49 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Lowe", "Ryan", ""], ["Foerster", "Jakob", ""], ["Boureau", "Y-Lan", ""], ["Pineau", "Joelle", ""], ["Dauphin", "Yann", ""]]}, {"id": "1903.05174", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Alessio Micheli", "title": "Richness of Deep Echo State Network Dynamics", "comments": "Preprint of the paper accepted at IWANN 2019", "journal-ref": null, "doi": "10.1007/978-3-030-20521-8_40", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir Computing (RC) is a popular methodology for the efficient design of\nRecurrent Neural Networks (RNNs). Recently, the advantages of the RC approach\nhave been extended to the context of multi-layered RNNs, with the introduction\nof the Deep Echo State Network (DeepESN) model. In this paper, we study the\nquality of state dynamics in progressively higher layers of DeepESNs, using\ntools from the areas of information theory and numerical analysis. Our\nexperimental results on RC benchmark datasets reveal the fundamental role\nplayed by the strength of inter-reservoir connections to increasingly enrich\nthe representations developed in higher layers. Our analysis also gives\ninteresting insights into the possibility of effective exploitation of training\nalgorithms based on stochastic gradient descent in the RC field.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:39:36 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 15:49:55 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "1903.05176", "submitter": "Liam Li", "authors": "Liam Li, Evan Sparks, Kevin Jamieson, Ameet Talwalkar", "title": "Exploiting Reuse in Pipeline-Aware Hyperparameter Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter tuning of multi-stage pipelines introduces a significant\ncomputational burden. Motivated by the observation that work can be reused\nacross pipelines if the intermediate computations are the same, we propose a\npipeline-aware approach to hyperparameter tuning. Our approach optimizes both\nthe design and execution of pipelines to maximize reuse. We design pipelines\namenable for reuse by (i) introducing a novel hybrid hyperparameter tuning\nmethod called gridded random search, and (ii) reducing the average training\ntime in pipelines by adapting early-stopping hyperparameter tuning approaches.\nWe then realize the potential for reuse during execution by introducing a novel\ncaching problem for ML workloads which we pose as a mixed integer linear\nprogram (ILP), and subsequently evaluating various caching heuristics relative\nto the optimal solution of the ILP. We conduct experiments on simulated and\nreal-world machine learning pipelines to show that a pipeline-aware approach to\nhyperparameter tuning can offer over an order-of-magnitude speedup over\nindependently evaluating pipeline configurations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:40:28 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Li", "Liam", ""], ["Sparks", "Evan", ""], ["Jamieson", "Kevin", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1903.05179", "submitter": "Zhengze Zhou", "authors": "Zhengze Zhou, Giles Hooker", "title": "Unbiased Measurement of Feature Importance in Tree-Based Methods", "comments": "add Section 3.4 to compare with other methods for dealing with\n  similar bias; add more simulation results in Section 5; add link to Github\n  repository for code access", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a modification that corrects for split-improvement variable\nimportance measures in Random Forests and other tree-based methods. These\nmethods have been shown to be biased towards increasing the importance of\nfeatures with more potential splits. We show that by appropriately\nincorporating split-improvement as measured on out of sample data, this bias\ncan be corrected yielding better summaries and screening tools.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:52:53 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 19:09:03 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Zhou", "Zhengze", ""], ["Hooker", "Giles", ""]]}, {"id": "1903.05196", "submitter": "Karl Mason", "authors": "Karl Mason, Santiago Grijalva", "title": "A Review of Reinforcement Learning for Autonomous Building Energy\n  Management", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of building energy management has received a significant amount of\ninterest in recent years. This area is concerned with combining advancements in\nsensor technologies, communications and advanced control algorithms to optimize\nenergy utilization. Reinforcement learning is one of the most prominent machine\nlearning algorithms used for control problems and has had many successful\napplications in the area of building energy management. This research gives a\ncomprehensive review of the literature relating to the application of\nreinforcement learning to developing autonomous building energy management\nsystems. The main direction for future research and challenges in reinforcement\nlearning are also outlined.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 20:38:54 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 17:06:11 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Mason", "Karl", ""], ["Grijalva", "Santiago", ""]]}, {"id": "1903.05202", "submitter": "Tom Diethe", "authors": "Tom Diethe, Tom Borchert, Eno Thereska, Borja Balle, Neil Lawrence", "title": "Continual Learning in Practice", "comments": "Presented at the NeurIPS 2018 workshop on Continual Learning\n  https://sites.google.com/view/continual2018/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a reference architecture for self-maintaining systems\nthat can learn continually, as data arrives. In environments where data\nevolves, we need architectures that manage Machine Learning (ML) models in\nproduction, adapt to shifting data distributions, cope with outliers, retrain\nwhen necessary, and adapt to new tasks. This represents continual AutoML or\nAutomatically Adaptive Machine Learning. We describe the challenges and\nproposes a reference architecture.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 20:41:36 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 14:44:53 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Diethe", "Tom", ""], ["Borchert", "Tom", ""], ["Thereska", "Eno", ""], ["Balle", "Borja", ""], ["Lawrence", "Neil", ""]]}, {"id": "1903.05216", "submitter": "Daan Wout", "authors": "Daan Wout, Jan Scholten, Carlos Celemin, Jens Kober", "title": "Learning Gaussian Policies from Corrective Human Feedback", "comments": "Submitted to the Uncertainty in Artificial Intelligence (UAI)\n  Conference of 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from human feedback is a viable alternative to control design that\ndoes not require modelling or control expertise. Particularly, learning from\ncorrective advice garners advantages over evaluative feedback as it is a more\nintuitive and scalable format. The current state-of-the-art in this field,\nCOACH, has proven to be a effective approach for confined problems. However, it\nparameterizes the policy with Radial Basis Function networks, which require\nmeticulous feature space engineering for higher order systems. We introduce\nGaussian Process Coach (GPC), where feature space engineering is avoided by\nemploying Gaussian Processes. In addition, we use the available policy\nuncertainty to 1) inquire feedback samples of maximal utility and 2) to adapt\nthe learning rate to the teacher's learning phase. We demonstrate that the\nnovel algorithm outperforms the current state-of-the-art in final performance,\nconvergence rate and robustness to erroneous feedback in OpenAI Gym continuous\ncontrol benchmarks, both for simulated and real human teachers.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 21:10:18 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Wout", "Daan", ""], ["Scholten", "Jan", ""], ["Celemin", "Carlos", ""], ["Kober", "Jens", ""]]}, {"id": "1903.05219", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Confident Kernel Sparse Coding and Dictionary Learning", "comments": "10 pages, ICDM 2018 conference", "journal-ref": null, "doi": "10.1109/ICDM.2018.00130", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, kernel-based sparse coding (K-SRC) has received particular\nattention due to its efficient representation of nonlinear data structures in\nthe feature space. Nevertheless, the existing K-SRC methods suffer from the\nlack of consistency between their training and test optimization frameworks. In\nthis work, we propose a novel confident K-SRC and dictionary learning algorithm\n(CKSC) which focuses on the discriminative reconstruction of the data based on\nits representation in the kernel space. CKSC focuses on reconstructing each\ndata sample via weighted contributions which are confident in its corresponding\nclass of data. We employ novel discriminative terms to apply this scheme to\nboth training and test frameworks in our algorithm. This specific design\nincreases the consistency of these optimization frameworks and improves the\ndiscriminative performance in the recall phase. In addition, CKSC directly\nemploys the supervised information in its dictionary learning framework to\nenhance the discriminative structure of the dictionary. For empirical\nevaluations, we implement our CKSC algorithm on multivariate time-series\nbenchmarks such as DynTex++ and UTKinect. Our claims regarding the superior\nperformance of the proposed algorithm are justified throughout comparing its\nclassification results to the state-of-the-art K-SRC algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 21:15:51 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.05239", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Non-Negative Local Sparse Coding for Subspace Clustering", "comments": "15 pages, IDA 2018 conference", "journal-ref": null, "doi": "10.1007/978-3-030-01768-2_12", "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace sparse coding (SSC) algorithms have proven to be beneficial to\nclustering problems. They provide an alternative data representation in which\nthe underlying structure of the clusters can be better captured. However, most\nof the research in this area is mainly focused on enhancing the sparse coding\npart of the problem. In contrast, we introduce a novel objective term in our\nproposed SSC framework which focuses on the separability of data points in the\ncoding space. We also provide mathematical insights into how this\nlocal-separability term improves the clustering result of the SSC framework.\nOur proposed non-linear local SSC algorithm (NLSSC) also benefits from the\nefficient choice of its sparsity terms and constraints. The NLSSC algorithm is\nalso formulated in the kernel-based framework (NLKSSC) which can represent the\nnonlinear structure of data. In addition, we address the possibility of having\nredundancies in sparse coding results and its negative effect on graph-based\nclustering problems. We introduce the link-restore post-processing step to\nimprove the representation graph of non-negative SSC algorithms such as ours.\nEmpirical evaluations on well-known clustering benchmarks show that our\nproposed NLSSC framework results in better clusterings compared to the\nstate-of-the-art baselines and demonstrate the effectiveness of the\nlink-restore post-processing in improving the clustering accuracy via\ncorrecting the broken links of the representation graph.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 22:20:10 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.05246", "submitter": "Nate Veldt", "authors": "Nate Veldt and David F. Gleich and Anthony Wirth", "title": "Learning Resolution Parameters for Graph Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding clusters of well-connected nodes in a graph is an extensively studied\nproblem in graph-based data analysis. Because of its many applications, a large\nnumber of distinct graph clustering objective functions and algorithms have\nalready been proposed and analyzed. To aid practitioners in determining the\nbest clustering approach to use in different applications, we present new\ntechniques for automatically learning how to set clustering resolution\nparameters. These parameters control the size and structure of communities that\nare formed by optimizing a generalized objective function. We begin by\nformalizing the notion of a parameter fitness function, which measures how well\na fixed input clustering approximately solves a generalized clustering\nobjective for a specific resolution parameter value. Under reasonable\nassumptions, which suit two key graph clustering applications, such a parameter\nfitness function can be efficiently minimized using a bisection-like method,\nyielding a resolution parameter that fits well with the example clustering. We\nview our framework as a type of single-shot hyperparameter tuning, as we are\nable to learn a good resolution parameter with just a single example. Our\ngeneral approach can be applied to learn resolution parameters for both local\nand global graph clustering objectives. We demonstrate its utility in several\nexperiments on real-world data where it is helpful to learn resolution\nparameters from a given example clustering.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 22:40:19 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Veldt", "Nate", ""], ["Gleich", "David F.", ""], ["Wirth", "Anthony", ""]]}, {"id": "1903.05263", "submitter": "Hugo Jair  Escalante", "authors": "Hugo Jair Escalante, Wei-Wei Tu, Isabelle Guyon, Daniel L. Silver,\n  Evelyne Viegas, Yuqiang Chen, Wenyuan Dai, Qiang Yang", "title": "AutoML @ NeurIPS 2018 challenge: Design and Results", "comments": "Preprint submitted to NeurIPS2018 Volume of Springer Series on\n  Challenges in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We organized a competition on Autonomous Lifelong Machine Learning with Drift\nthat was part of the competition program of NeurIPS 2018. This data driven\ncompetition asked participants to develop computer programs capable of solving\nsupervised learning problems where the i.i.d. assumption did not hold. Large\ndata sets were arranged in a lifelong learning and evaluation scenario and\nCodaLab was used as the challenge platform. The challenge attracted more than\n300 participants in its two month duration. This chapter describes the design\nof the challenge and summarizes its main results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 23:43:59 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 03:02:38 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Escalante", "Hugo Jair", ""], ["Tu", "Wei-Wei", ""], ["Guyon", "Isabelle", ""], ["Silver", "Daniel L.", ""], ["Viegas", "Evelyne", ""], ["Chen", "Yuqiang", ""], ["Dai", "Wenyuan", ""], ["Yang", "Qiang", ""]]}, {"id": "1903.05271", "submitter": "Minsung Hyun", "authors": "Junyoung Choi, Minsung Hyun, Nojun Kwak", "title": "Task-oriented Design through Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new low-cost machine-learning-based methodology which assists\ndesigners in reducing the gap between the problem and the solution in the\ndesign process. Our work applies reinforcement learning (RL) to find the\noptimal task-oriented design solution through the construction of the design\naction for each task. For this task-oriented design, the 3D design process in\nproduct design is assigned to an action space in Deep RL, and the desired 3D\nmodel is obtained by training each design action according to the task. By\nshowing that this method achieves satisfactory design even when applied to a\ntask pursuing multiple goals, we suggest the direction of how machine learning\ncan contribute to the design process. Also, we have validated with product\ndesigners that this methodology can assist the creative part in the process of\ndesign.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 00:49:01 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Choi", "Junyoung", ""], ["Hyun", "Minsung", ""], ["Kwak", "Nojun", ""]]}, {"id": "1903.05274", "submitter": "Yize Chen", "authors": "Congmei Jiang, Yize Chen, Yongfang Mao, Yi Chai, Mingbiao Yu", "title": "Forecasting Spatio-Temporal Renewable Scenarios: a Deep Generative\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The operation and planning of large-scale power systems are becoming more\nchallenging with the increasing penetration of stochastic renewable generation.\nIn order to minimize the decision risks in power systems with large amount of\nrenewable resources, there is a growing need to model the short-term generation\nuncertainty. By producing a group of possible future realizations for certain\nset of renewable generation plants, scenario approach has become one popular\nway for renewables uncertainty modeling. However, due to the complex spatial\nand temporal correlations underlying in renewable generations, traditional\nmodel-based approaches for forecasting future scenarios often require extensive\nknowledge, while fitted models are often hard to scale. To address such\nmodeling burdens, we propose a learning-based, data-driven scenario forecasts\nmethod based on generative adversarial networks (GANs), which is a class of\ndeep-learning generative algorithms used for modeling unknown distributions. We\nfirstly utilize an improved GANs with convergence guarantees to learn the\nintrinsic patterns and model the unknown distributions of (multiple-site)\nrenewable generation time-series. Then by solving an optimization problem, we\nare able to generate forecasted scenarios without any scenario number and\nforecasting horizon restrictions. Our method is totally model-free, and could\nforecast scenarios under different level of forecast uncertainties. Extensive\nnumerical simulations using real-world data from NREL wind and solar\nintegration datasets validate the performance of proposed method in forecasting\nboth wind and solar power scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 01:11:39 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Jiang", "Congmei", ""], ["Chen", "Yize", ""], ["Mao", "Yongfang", ""], ["Chai", "Yi", ""], ["Yu", "Mingbiao", ""]]}, {"id": "1903.05280", "submitter": "Ryan Ong", "authors": "Ryan Ong", "title": "Offensive Language Analysis using Deep Learning Architecture", "comments": "6 pages, 8 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SemEval-2019 Task 6 (Zampieri et al., 2019b) requires us to identify and\ncategorise offensive language in social media. In this paper we will describe\nthe process we took to tackle this challenge. Our process is heavily inspired\nby Sosa (2017) where he proposed CNN-LSTM and LSTM-CNN models to conduct\ntwitter sentiment analysis. We decided to follow his approach as well as\nfurther his work by testing out different variations of RNN models with CNN.\nSpecifically, we have divided the challenge into two parts: data processing and\nsampling and choosing the optimal deep learning architecture. In preprocessing,\nwe experimented with two techniques, SMOTE and Class Weights to counter the\nimbalance between classes. Once we are happy with the quality of our input\ndata, we proceed to choosing the optimal deep learning architecture for this\ntask. Given the quality and quantity of data we have been given, we found that\nthe addition of CNN layer provides very little to no additional improvement to\nour model's performance and sometimes even lead to a decrease in our F1-score.\nIn the end, the deep learning architecture that gives us the highest macro\nF1-score is a simple BiLSTM-CNN.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 09:36:25 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 15:01:47 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 17:23:43 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Ong", "Ryan", ""]]}, {"id": "1903.05284", "submitter": "Yunhao Tang", "authors": "Yunhao Tang, Mingzhang Yin, Mingyuan Zhou", "title": "Augment-Reinforce-Merge Policy Gradient for Binary Stochastic Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the high variance of policy gradients, on-policy optimization\nalgorithms are plagued with low sample efficiency. In this work, we propose\nAugment-Reinforce-Merge (ARM) policy gradient estimator as an unbiased\nlow-variance alternative to previous baseline estimators on tasks with binary\naction space, inspired by the recent ARM gradient estimator for discrete random\nvariable models. We show that the ARM policy gradient estimator achieves\nvariance reduction with theoretical guarantees, and leads to significantly more\nstable and faster convergence of policies parameterized by neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 01:43:50 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Tang", "Yunhao", ""], ["Yin", "Mingzhang", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1903.05297", "submitter": "Zheng Li", "authors": "Zheng Li, Ge Han, Yunqing Wei, Shanqing Guo", "title": "Learning Symmetric and Asymmetric Steganography via Adversarial Training", "comments": "Some experiments need to be done", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steganography refers to the art of concealing secret messages within multiple\nmedia carriers so that an eavesdropper is unable to detect the presence and\ncontent of the hidden messages. In this paper, we firstly propose a novel\nkey-dependent steganographic scheme that achieves steganographic objectives\nwith adversarial training. Symmetric (secret-key) and Asymmetric (public-key)\nsteganographic scheme are separately proposed and each scheme is successfully\ndesigned and implemented. We show that these encodings produced by our scheme\nimprove the invisibility by 20% than previous deep-leanring-based work, and\nfurther that perform competitively remarkable undetectability 25% better than\nclassic steganographic algorithms. Finally, we simulated our scheme in a real\nsituation where the decoder achieved an accuracy of more than 98% of the\noriginal message.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 02:55:09 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 07:36:23 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Li", "Zheng", ""], ["Han", "Ge", ""], ["Wei", "Yunqing", ""], ["Guo", "Shanqing", ""]]}, {"id": "1903.05312", "submitter": "Masato Ishii", "authors": "Masato Ishii, Takashi Takenouchi, and Masashi Sugiyama", "title": "Zero-shot Domain Adaptation Based on Attribute Information", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel domain adaptation method that can be\napplied without target data. We consider the situation where domain shift is\ncaused by a prior change of a specific factor and assume that we know how the\nprior changes between source and target domains. We call this factor an\nattribute, and reformulate the domain adaptation problem to utilize the\nattribute prior instead of target data. In our method, the source data are\nreweighted with the sample-wise weight estimated by the attribute prior and the\ndata themselves so that they are useful in the target domain. We theoretically\nreveal that our method provides more precise estimation of sample-wise\ntransferability than a straightforward attribute-based reweighting approach.\nExperimental results with both toy datasets and benchmark datasets show that\nour method can perform well, though it does not use any target data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 04:50:56 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Ishii", "Masato", ""], ["Takenouchi", "Takashi", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1903.05315", "submitter": "Gil Kur", "authors": "Gil Kur, Yuval Dagan, Alexander Rakhlin", "title": "Optimality of Maximum Likelihood for Log-Concave Density Estimation and\n  Bounded Convex Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study two problems: (1) estimation of a $d$-dimensional\nlog-concave distribution and (2) bounded multivariate convex regression with\nrandom design with an underlying log-concave density or a compactly supported\ndistribution with a continuous density.\n  First, we show that for all $d \\ge 4$ the maximum likelihood estimators of\nboth problems achieve an optimal risk of $\\Theta_d(n^{-2/(d+1)})$ (up to a\nlogarithmic factor) in terms of squared Hellinger distance and $L_2$ squared\ndistance, respectively. Previously, the optimality of both these estimators was\nknown only for $d\\le 3$. We also prove that the $\\epsilon$-entropy numbers of\nthe two aforementioned families are equal up to logarithmic factors. We\ncomplement these results by proving a sharp bound $\\Theta_d(n^{-2/(d+4)})$ on\nthe minimax rate (up to logarithmic factors) with respect to the total\nvariation distance.\n  Finally, we prove that estimating a log-concave density - even a uniform\ndistribution on a convex set - up to a fixed accuracy requires the number of\nsamples \\emph{at least} exponential in the dimension. We do that by improving\nthe dimensional constant in the best known lower bound for the minimax rate\nfrom $2^{-d}\\cdot n^{-2/(d+1)}$ to $c\\cdot n^{-2/(d+1)}$ (when $d\\geq 2$).\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 04:58:36 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 06:19:37 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 13:16:32 GMT"}, {"version": "v4", "created": "Thu, 20 Feb 2020 13:32:11 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kur", "Gil", ""], ["Dagan", "Yuval", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "1903.05316", "submitter": "Shangqing Liu", "authors": "Shangqing Liu, Yanchao Zhao, Fanggang Xue, Bing Chen and Xiang Chen", "title": "DeepCount: Crowd Counting with WiFi via Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the research of wireless sensing has achieved more intelligent\nresults, and the intelligent sensing of human location and activity can be\nrealized by means of WiFi devices. However, most of the current human\nenvironment perception work is limited to a single person's environment,\nbecause the environment in which multiple people exist is more complicated than\nthe environment in which a single person exists. In order to solve the problem\nof human behavior perception in a multi-human environment, we first proposed a\nsolution to achieve crowd counting (inferred population) using deep learning in\na closed environment with WIFI signals - DeepCout, which is the first in a\nmulti-human environment. step. Since the use of WiFi to directly count the\ncrowd is too complicated, we use deep learning to solve this problem, use\nConvolutional Neural Network(CNN) to automatically extract the relationship\nbetween the number of people and the channel, and use Long Short Term\nMemory(LSTM) to resolve the dependencies of number of people and Channel State\nInformation(CSI) . To overcome the massive labelled data required by deep\nlearning method, we add an online learning mechanism to determine whether or\nnot someone is entering/leaving the room by activity recognition model, so as\nto correct the deep learning model in the fine-tune stage, which, in turn,\nreduces the required training data and make our method evolving over time. The\nsystem of DeepCount is performed and evaluated on the commercial WiFi devices.\nBy massive training samples, our end-to-end learning approach can achieve an\naverage of 86.4% prediction accuracy in an environment of up to 5 people.\nMeanwhile, by the amendment mechanism of the activity recognition model to\njudge door switch to get the variance of crowd to amend deep learning predicted\nresults, the accuracy is up to 90%.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 04:59:07 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Liu", "Shangqing", ""], ["Zhao", "Yanchao", ""], ["Xue", "Fanggang", ""], ["Chen", "Bing", ""], ["Chen", "Xiang", ""]]}, {"id": "1903.05334", "submitter": "Zhe Zeng Miss", "authors": "Zhe Zeng, Guy Van den Broeck", "title": "Efficient Search-Based Weighted Model Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted model integration (WMI) extends Weighted model counting (WMC) to the\nintegration of functions over mixed discrete-continuous domains. It has shown\ntremendous promise for solving inference problems in graphical models and\nprobabilistic programming. Yet, state-of-the-art tools for WMI are limited in\nterms of performance and ignore the independence structure that is crucial to\nimproving efficiency. To address this limitation, we propose an efficient model\nintegration algorithm for theories with tree primal graphs. We exploit the\nsparse graph structure by using search to performing integration. Our algorithm\ngreatly improves the computational efficiency on such problems and exploits\ncontext-specific independence between variables. Experimental results show\ndramatic speedups compared to existing WMI solvers on problems with tree-shaped\ndependencies.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 06:46:03 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 14:26:38 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 21:58:55 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 00:17:53 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zeng", "Zhe", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1903.05347", "submitter": "Robi Bhattacharjee", "authors": "Robi Bhattacharjee and Sanjoy Dasgupta", "title": "What relations are reliably embeddable in Euclidean space?", "comments": "Published at ALT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of embedding a relation, represented as a directed\ngraph, into Euclidean space. For three types of embeddings motivated by the\nrecent literature on knowledge graphs, we obtain characterizations of which\nrelations they are able to capture, as well as bounds on the minimal\ndimensionality and precision needed.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 07:54:58 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 23:19:05 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bhattacharjee", "Robi", ""], ["Dasgupta", "Sanjoy", ""]]}, {"id": "1903.05355", "submitter": "Bilal Wehbe", "authors": "Bilal Wehbe, Marc Hildebrandt and Frank Kirchner", "title": "A Framework for On-line Learning of Underwater Vehicles Dynamic Models", "comments": "8 pages, 6 figures, ICRA 2019 authors preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the dynamics of robots from data can help achieve more accurate\ntracking controllers, or aid their navigation algorithms. However, when the\nactual dynamics of the robots change due to external conditions, on-line\nadaptation of their models is required to maintain high fidelity performance.\nIn this work, a framework for on-line learning of robot dynamics is developed\nto adapt to such changes. The proposed framework employs an incremental support\nvector regression method to learn the model sequentially from data streams. In\ncombination with the incremental learning, strategies for including and\nforgetting data are developed to obtain better generalization over the whole\nstate space. The framework is tested in simulation and real experimental\nscenarios demonstrating its adaptation capabilities to changes in the robot's\ndynamics.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 08:33:46 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Wehbe", "Bilal", ""], ["Hildebrandt", "Marc", ""], ["Kirchner", "Frank", ""]]}, {"id": "1903.05359", "submitter": "Zhan Yang", "authors": "Jun Long, WuQing Sun, Zhan Yang, Osolo Ian Raymond", "title": "Asymmetric Residual Neural Network for Accurate Human Activity\n  Recognition", "comments": "Accepted by Information", "journal-ref": null, "doi": "10.3390/info10060203", "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human Activity Recognition (HAR) using deep neural network has become a hot\ntopic in human-computer interaction. Machine can effectively identify human\nnaturalistic activities by learning from a large collection of sensor data.\nActivity recognition is not only an interesting research problem, but also has\nmany real-world practical applications. Based on the success of residual\nnetworks in achieving a high level of aesthetic representation of the automatic\nlearning, we propose a novel \\textbf{A}symmetric \\textbf{R}esidual\n\\textbf{N}etwork, named ARN. ARN is implemented using two identical path\nframeworks consisting of (1) a short time window, which is used to capture\nspatial features, and (2) a long time window, which is used to capture fine\ntemporal features. The long time window path can be made very lightweight by\nreducing its channel capacity, yet still being able to learn useful temporal\nrepresentations for activity recognition. In this paper, we mainly focus on\nproposing a new model to improve the accuracy of HAR. In order to demonstrate\nthe effectiveness of ARN model, we carried out extensive experiments on\nbenchmark datasets (i.e., OPPORTUNITY, UniMiB-SHAR) and compared with some\nconventional and state-of-the-art learning-based methods. Then, we discuss the\ninfluence of networks parameters on performance to provide insights about its\noptimization. Results from our experiments show that ARN is effective in\nrecognizing human activities via wearable datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 08:44:01 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 08:41:42 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 13:05:37 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Long", "Jun", ""], ["Sun", "WuQing", ""], ["Yang", "Zhan", ""], ["Raymond", "Osolo Ian", ""]]}, {"id": "1903.05376", "submitter": "Lior Rokach", "authors": "Saar Tal, Bracha Shapira, Lior Rokach", "title": "Personal Dynamic Cost-Aware Sensing for Latent Context Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, the usage of mobile devices has gone far beyond simple\nactivities like calling and texting. Today, smartphones contain multiple\nembedded sensors and are able to collect useful sensing data about the user and\ninfer the user's context. The more frequent the sensing, the more accurate the\ncontext. However, continuous sensing results in huge energy consumption,\ndecreasing the battery's lifetime. We propose a novel approach for cost-aware\nsensing when performing continuous latent context detection. The suggested\nmethod dynamically determines user's sensors sampling policy based on three\nfactors: (1) User's last known context; (2) Predicted information loss using\nKL-Divergence; and (3) Sensors' sampling costs. The objective function aims at\nminimizing both sampling cost and information loss. The method is based on\nvarious machine learning techniques including autoencoder neural networks for\nlatent context detection, linear regression for information loss prediction,\nand convex optimization for determining the optimal sampling policy. To\nevaluate the suggested method, we performed a series of tests on real-world\ndata recorded at a high-frequency rate; the data was collected from six mobile\nphone sensors of twenty users over the course of a week. Results show that by\napplying a dynamic sampling policy, our method naturally balances information\nloss and energy consumption and outperforms the static approach.% We compared\nthe performance of our method with another state of the art dynamic sampling\nmethod and demonstrate its consistent superiority in various measures. %Our\nmethods outperformed, and were able to improve we achieved better results in\neither sampling cost or information loss, and in some cases we improved both.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 09:34:43 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Tal", "Saar", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""]]}, {"id": "1903.05379", "submitter": "Daniele Ancora", "authors": "Daniele Ancora and Luca Leuzzi", "title": "Transmission Matrix Inference via Pseudolikelihood Decimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG eess.IV physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges in the field of biomedical imaging is the\ncomprehension and the exploitation of the photon scattering through disordered\nmedia. Many studies have pursued the solution to this puzzle, achieving\nlight-focusing control or reconstructing images in complex media. In the\npresent work, we investigate how statistical inference helps the calculation of\nthe transmission matrix in a complex scrambling environment, enabling its usage\nlike a normal optical element. We convert a linear input-output transmission\nproblem into a statistical formulation based on pseudolikelihood maximization,\nlearning the coupling matrix via random sampling of intensity realizations. Our\naim is to uncover insights from the scattering problem, encouraging the\ndevelopment of novel imaging techniques for better medical investigations,\nborrowing a number of statistical tools from spin-glass theory.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 09:43:22 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Ancora", "Daniele", ""], ["Leuzzi", "Luca", ""]]}, {"id": "1903.05382", "submitter": "Lior Rokach", "authors": "Eran Fainman, Bracha Shapira, Lior Rokach, Yisroel Mirsky", "title": "Online Budgeted Learning for Classifier Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world machine learning applications, there is a cost associated with\nsampling of different features. Budgeted learning can be used to select which\nfeature-values to acquire from each instance in a dataset, such that the best\nmodel is induced under a given constraint. However, this approach is not\npossible in the domain of online learning since one may not retroactively\nacquire feature-values from past instances. In online learning, the challenge\nis to find the optimum set of features to be acquired from each instance upon\narrival from a data stream. In this paper we introduce the issue of online\nbudgeted learning and describe a general framework for addressing this\nchallenge. We propose two types of feature value acquisition policies based on\nthe multi-armed bandit problem: random and adaptive. Adaptive policies perform\nonline adjustments according to new information coming from a data stream,\nwhile random policies are not sensitive to the information that arrives from\nthe data stream. Our comparative study on five real-world datasets indicates\nthat adaptive policies outperform random policies for most budget limitations\nand datasets. Furthermore, we found that in some cases adaptive policies\nachieve near-optimal results.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 09:51:33 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Fainman", "Eran", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""], ["Mirsky", "Yisroel", ""]]}, {"id": "1903.05431", "submitter": "Kleanthis Malialis", "authors": "Kleanthis Malialis and Sam Devlin and Daniel Kudenko", "title": "Resource Abstraction for Reinforcement Learning in Multiagent Congestion\n  Problems", "comments": "Keywords: congestion problems, resource management, multiagent\n  reinforcement learning, multiagent systems, multiagent learning, resource\n  abstraction. In Proceedings of the 2016 International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS '16)", "journal-ref": "Proceedings of the International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS), 2016/", "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world congestion problems (e.g. traffic congestion) are typically very\ncomplex and large-scale. Multiagent reinforcement learning (MARL) is a\npromising candidate for dealing with this emerging complexity by providing an\nautonomous and distributed solution to these problems. However, there are three\nlimiting factors that affect the deployability of MARL approaches to congestion\nproblems. These are learning time, scalability and decentralised coordination\ni.e. no communication between the learning agents. In this paper we introduce\nResource Abstraction, an approach that addresses these challenges by allocating\nthe available resources into abstract groups. This abstraction creates new\nreward functions that provide a more informative signal to the learning agents\nand aid the coordination amongst them. Experimental work is conducted on two\nbenchmark domains from the literature, an abstract congestion problem and a\nrealistic traffic congestion problem. The current state-of-the-art for solving\nmultiagent congestion problems is a form of reward shaping called difference\nrewards. We show that the system using Resource Abstraction significantly\nimproves the learning speed and scalability, and achieves the highest possible\nor near-highest joint performance/social welfare for both congestion problems\nin large-scale scenarios involving up to 1000 reinforcement learning agents.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 11:54:04 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Malialis", "Kleanthis", ""], ["Devlin", "Sam", ""], ["Kudenko", "Daniel", ""]]}, {"id": "1903.05457", "submitter": "Karim Abou-Moustafa", "authors": "Karim Abou-Moustafa and Csaba Szepesvari", "title": "An Exponential Efron-Stein Inequality for Lq Stable Learning Rules", "comments": "Additional text and appendices that were not included in the PMLR\n  (ALT'19) proceedings are now included in this version", "journal-ref": "PMLR Vol. 98, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is accumulating evidence in the literature that stability of learning\nalgorithms is a key characteristic that permits a learning algorithm to\ngeneralize. Despite various insightful results in this direction, there seems\nto be an overlooked dichotomy in the type of stability-based generalization\nbounds we have in the literature. On one hand, the literature seems to suggest\nthat exponential generalization bounds for the estimated risk, which are\noptimal, can be only obtained through stringent, distribution independent and\ncomputationally intractable notions of stability such as uniform stability. On\nthe other hand, it seems that weaker notions of stability such as hypothesis\nstability, although it is distribution dependent and more amenable to\ncomputation, can only yield polynomial generalization bounds for the estimated\nrisk, which are suboptimal.\n  In this paper, we address the gap between these two regimes of results. In\nparticular, the main question we address here is \\emph{whether it is possible\nto derive exponential generalization bounds for the estimated risk using a\nnotion of stability that is computationally tractable and distribution\ndependent, but weaker than uniform stability. Using recent advances in\nconcentration inequalities, and using a notion of stability that is weaker than\nuniform stability but distribution dependent and amenable to computation, we\nderive an exponential tail bound for the concentration of the estimated risk of\na hypothesis returned by a general learning rule, where the estimated risk is\nexpressed in terms of either the resubstitution estimate (empirical error), or\nthe deleted (or, leave-one-out) estimate. As an illustration, we derive\nexponential tail bounds for ridge regression with unbounded responses, where we\nshow how stability changes with the tail behavior of the response variables.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 02:33:02 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 22:50:39 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Abou-Moustafa", "Karim", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1903.05460", "submitter": "Francesco Restuccia", "authors": "Francesco Restuccia and Tommaso Melodia", "title": "Big Data Goes Small: Real-Time Spectrum-Driven Embedded Wireless\n  Networking Through Deep Learning in the RF Loop", "comments": "Accepted to IEEE INFOCOM 2019. arXiv admin note: text overlap with\n  arXiv:1901.07947", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of 5G networks and the Internet of Things will result in an\nexceptionally crowded RF environment, where techniques such as spectrum sharing\nand dynamic spectrum access will become essential components of the wireless\ncommunication process. In this vision, wireless devices must be able to (i)\nlearn to autonomously extract knowledge from the spectrum on-the-fly; and (ii)\nreact in real time to the inferred spectrum knowledge by appropriately changing\ncommunication parameters, including frequency band, symbol modulation, coding\nrate, among others. Traditional CPU-based machine learning suffers from high\nlatency, and requires application-specific and computationally-intensive\nfeature extraction/selection algorithms. In this paper, we present RFLearn, the\nfirst system enabling spectrum knowledge extraction from unprocessed I/Q\nsamples by deep learning directly in the RF loop. RFLearn provides (i) a\ncomplete hardware/software architecture where the CPU, radio transceiver and\nlearning/actuation circuits are tightly connected for maximum performance; and\n(ii) a learning circuit design framework where the latency vs. hardware\nresource consumption trade-off can explored. We implement and evaluate the\nperformance of RFLearn on custom software-defined radio built on a\nsystem-on-chip (SoC) ZYNQ-7000 device mounting AD9361 radio transceivers and\nVERT2450 antennas. We showcase the capabilities of RFLearn by applying it to\nsolving the fundamental problems of modulation and OFDM parameter recognition.\nExperimental results reveal that RFLearn decreases latency and power by about\n17x and 15x with respect to a software-based solution, with a comparatively low\nhardware resource consumption.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 12:37:58 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Restuccia", "Francesco", ""], ["Melodia", "Tommaso", ""]]}, {"id": "1903.05480", "submitter": "Adam Foster", "authors": "Adam Foster, Martin Jankowiak, Eli Bingham, Paul Horsfall, Yee Whye\n  Teh, Tom Rainforth, Noah Goodman", "title": "Variational Bayesian Optimal Experimental Design", "comments": "Published as a conference paper at the Thirty-third Conference on\n  Neural Information Processing Systems, Vancouver 2019.\n  https://papers.nips.cc/paper/9553-variational-bayesian-optimal-experimental-design.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimal experimental design (BOED) is a principled framework for\nmaking efficient use of limited experimental resources. Unfortunately, its\napplicability is hampered by the difficulty of obtaining accurate estimates of\nthe expected information gain (EIG) of an experiment. To address this, we\nintroduce several classes of fast EIG estimators by building on ideas from\namortized variational inference. We show theoretically and empirically that\nthese estimators can provide significant gains in speed and accuracy over\nprevious approaches. We further demonstrate the practicality of our approach on\na number of end-to-end experiments.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 13:34:13 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 14:39:15 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 14:49:02 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Foster", "Adam", ""], ["Jankowiak", "Martin", ""], ["Bingham", "Eli", ""], ["Horsfall", "Paul", ""], ["Teh", "Yee Whye", ""], ["Rainforth", "Tom", ""], ["Goodman", "Noah", ""]]}, {"id": "1903.05499", "submitter": "Frank Schneider", "authors": "Frank Schneider, Lukas Balles and Philipp Hennig", "title": "DeepOBS: A Deep Learning Optimizer Benchmark Suite", "comments": "Accepted at ICLR 2019. 9 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because the choice and tuning of the optimizer affects the speed, and\nultimately the performance of deep learning, there is significant past and\nrecent research in this area. Yet, perhaps surprisingly, there is no generally\nagreed-upon protocol for the quantitative and reproducible evaluation of\noptimization strategies for deep learning. We suggest routines and benchmarks\nfor stochastic optimization, with special focus on the unique aspects of deep\nlearning, such as stochasticity, tunability and generalization. As the primary\ncontribution, we present DeepOBS, a Python package of deep learning\noptimization benchmarks. The package addresses key challenges in the\nquantitative assessment of stochastic optimizers, and automates most steps of\nbenchmarking. The library includes a wide and extensible set of ready-to-use\nrealistic optimization problems, such as training Residual Networks for image\nclassification on ImageNet or character-level language prediction models, as\nwell as popular classics like MNIST and CIFAR-10. The package also provides\nrealistic baseline results for the most popular optimizers on these test\nproblems, ensuring a fair comparison to the competition when benchmarking new\noptimizers, and without having to run costly experiments. It comes with output\nback-ends that directly produce LaTeX code for inclusion in academic\npublications. It supports TensorFlow and is available open source.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 14:05:31 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Schneider", "Frank", ""], ["Balles", "Lukas", ""], ["Hennig", "Philipp", ""]]}, {"id": "1903.05501", "submitter": "Hiroshi Kuwajima", "authors": "Hiroshi Kuwajima, Masayuki Tanaka, Masatoshi Okutomi", "title": "Improving Transparency of Deep Neural Inference Process", "comments": "11 pages, 14 figures, 1 table. This is a pre-print of an article\n  accepted in \"Progress in Artificial Intelligence\" on 26 Feb 2019. The final\n  authenticated version will be available online soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques are rapidly advanced recently, and becoming a\nnecessity component for widespread systems. However, the inference process of\ndeep learning is black-box, and not very suitable to safety-critical systems\nwhich must exhibit high transparency. In this paper, to address this black-box\nlimitation, we develop a simple analysis method which consists of 1) structural\nfeature analysis: lists of the features contributing to inference process, 2)\nlinguistic feature analysis: lists of the natural language labels describing\nthe visual attributes for each feature contributing to inference process, and\n3) consistency analysis: measuring consistency among input data, inference\n(label), and the result of our structural and linguistic feature analysis. Our\nanalysis is simplified to reflect the actual inference process for high\ntransparency, whereas it does not include any additional black-box mechanisms\nsuch as LSTM for highly human readable results. We conduct experiments and\ndiscuss the results of our analysis qualitatively and quantitatively, and come\nto believe that our work improves the transparency of neural networks.\nEvaluated through 12,800 human tasks, 75% workers answer that input data and\nresult of our feature analysis are consistent, and 70% workers answer that\ninference (label) and result of our feature analysis are consistent. In\naddition to the evaluation of the proposed analysis, we find that our analysis\nalso provide suggestions, or possible next actions such as expanding neural\nnetwork complexity or collecting training data to improve a neural network.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 14:11:44 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kuwajima", "Hiroshi", ""], ["Tanaka", "Masayuki", ""], ["Okutomi", "Masatoshi", ""]]}, {"id": "1903.05503", "submitter": "Wenzhao Zheng", "authors": "Wenzhao Zheng, Zhaodong Chen, Jiwen Lu, Jie Zhou", "title": "Hardness-Aware Deep Metric Learning", "comments": "Accepted as CVPR 2019 Oral. Source code available at\n  https://github.com/wzzheng/HDML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a hardness-aware deep metric learning (HDML) framework.\nMost previous deep metric learning methods employ the hard negative mining\nstrategy to alleviate the lack of informative samples for training. However,\nthis mining strategy only utilizes a subset of training data, which may not be\nenough to characterize the global geometry of the embedding space\ncomprehensively. To address this problem, we perform linear interpolation on\nembeddings to adaptively manipulate their hard levels and generate\ncorresponding label-preserving synthetics for recycled training, so that\ninformation buried in all samples can be fully exploited and the metric is\nalways challenged with proper difficulty. Our method achieves very competitive\nperformance on the widely used CUB-200-2011, Cars196, and Stanford Online\nProducts datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 14:14:54 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 13:10:32 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Zheng", "Wenzhao", ""], ["Chen", "Zhaodong", ""], ["Lu", "Jiwen", ""], ["Zhou", "Jie", ""]]}, {"id": "1903.05535", "submitter": "Yan Wang", "authors": "Yan Wang, Xuelei Sherry Ni", "title": "Predicting class-imbalanced business risk using resampling,\n  regularization, and model ensembling algorithms", "comments": null, "journal-ref": "International Journal of Managing Information Technology (IJIMIT)\n  Vol. 11, No. 1, Februray 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim at developing and improving the imbalanced business risk modeling via\njointly using proper evaluation criteria, resampling, cross-validation,\nclassifier regularization, and ensembling techniques. Area Under the Receiver\nOperating Characteristic Curve (AUC of ROC) is used for model comparison based\non 10-fold cross validation. Two undersampling strategies including random\nundersampling (RUS) and cluster centroid undersampling (CCUS), as well as two\noversampling methods including random oversampling (ROS) and Synthetic Minority\nOversampling Technique (SMOTE), are applied. Three highly interpretable\nclassifiers, including logistic regression without regularization (LR),\nL1-regularized LR (L1LR), and decision tree (DT) are implemented. Two\nensembling techniques, including Bagging and Boosting, are applied on the DT\nclassifier for further model improvement. The results show that, Boosting on DT\nby using the oversampled data containing 50% positives via SMOTE is the optimal\nmodel and it can achieve AUC, recall, and F1 score valued 0.8633, 0.9260, and\n0.8907, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 15:07:35 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Wang", "Yan", ""], ["Ni", "Xuelei Sherry", ""]]}, {"id": "1903.05537", "submitter": "Yan Jin", "authors": "Yan Jin, John H. Drake, Una Benlic, Kun He", "title": "Effective reinforcement learning based local search for the maximum\n  k-plex problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum k-plex problem is a computationally complex problem, which\nemerged from graph-theoretic social network studies. This paper presents an\neffective hybrid local search for solving the maximum k-plex problem that\ncombines the recently proposed breakout local search algorithm with a\nreinforcement learning strategy. The proposed approach includes distinguishing\nfeatures such as: a unified neighborhood search based on the swapping operator,\na distance-and-quality reward for actions and a new parameter control mechanism\nbased on reinforcement learning. Extensive experiments for the maximum k-plex\nproblem (k = 2, 3, 4, 5) on 80 benchmark instances from the second DIMACS\nChallenge demonstrate that the proposed approach can match the best-known\nresults from the literature in all but four problem instances. In addition, the\nproposed algorithm is able to find 32 new best solutions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 15:11:35 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Jin", "Yan", ""], ["Drake", "John H.", ""], ["Benlic", "Una", ""], ["He", "Kun", ""]]}, {"id": "1903.05561", "submitter": "Hangyu Mao", "authors": "Hangyu Mao, Zhibo Gong, Zhengchao Zhang, Zhen Xiao and Yan Ni", "title": "Learning Multi-agent Communication under Limited-bandwidth Restriction\n  for Internet Packet Routing", "comments": "This paper proposes a gating mechanism with several crucial designs\n  for adaptively prunning the unprofitable communication messages among\n  multiple agents, such that the limited-bandwidth restriction existing in many\n  real-world muli-agent systems can be resolved. Experiments show that our\n  method can prune quite a lot of unprofitable messages with little damage to\n  the performance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is an important factor for the big multi-agent world to stay\norganized and productive. Recently, the AI community has applied the Deep\nReinforcement Learning (DRL) to learn the communication strategy and the\ncontrol policy for multiple agents. However, when implementing the\ncommunication for real-world multi-agent applications, there is a more\npractical limited-bandwidth restriction, which has been largely ignored by the\nexisting DRL-based methods. Specifically, agents trained by most previous\nmethods keep sending messages incessantly in every control cycle; due to\nemitting too many messages, these methods are unsuitable to be applied to the\nreal-world systems that have a limited bandwidth to transmit the messages. To\nhandle this problem, we propose a gating mechanism to adaptively prune\nunprofitable messages. Results show that the gating mechanism can prune more\nthan 80% messages with little damage to the performance. Moreover, our method\noutperforms several state-of-the-art DRL-based and rule-based methods by a\nlarge margin in both the real-world packet routing tasks and four benchmark\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 01:41:40 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Mao", "Hangyu", ""], ["Gong", "Zhibo", ""], ["Zhang", "Zhengchao", ""], ["Xiao", "Zhen", ""], ["Ni", "Yan", ""]]}, {"id": "1903.05566", "submitter": "Xingkun Liu", "authors": "Xingkun Liu, Arash Eshghi, Pawel Swietojanski and Verena Rieser", "title": "Benchmarking Natural Language Understanding Services for building\n  Conversational Agents", "comments": "Accepted by IWSDS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recently seen the emergence of several publicly available Natural\nLanguage Understanding (NLU) toolkits, which map user utterances to structured,\nbut more abstract, Dialogue Act (DA) or Intent specifications, while making\nthis process accessible to the lay developer. In this paper, we present the\nfirst wide coverage evaluation and comparison of some of the most popular NLU\nservices, on a large, multi-domain (21 domains) dataset of 25K user utterances\nthat we have collected and annotated with Intent and Entity Type specifications\nand which will be released as part of this submission. The results show that on\nIntent classification Watson significantly outperforms the other platforms,\nnamely, Dialogflow, LUIS and Rasa; though these also perform well.\nInterestingly, on Entity Type recognition, Watson performs significantly worse\ndue to its low Precision. Again, Dialogflow, LUIS and Rasa perform well on this\ntask.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 16:08:46 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 11:28:11 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 14:57:28 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Liu", "Xingkun", ""], ["Eshghi", "Arash", ""], ["Swietojanski", "Pawel", ""], ["Rieser", "Verena", ""]]}, {"id": "1903.05587", "submitter": "Valerio Perrone", "authors": "Valerio Perrone, Marco Palma, Simon Hengchen, Alessandro Vatri, Jim Q.\n  Smith, Barbara McGillivray", "title": "GASC: Genre-Aware Semantic Change for Ancient Greek", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W19-4707", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word meaning changes over time, depending on linguistic and extra-linguistic\nfactors. Associating a word's correct meaning in its historical context is a\ncentral challenge in diachronic research, and is relevant to a range of NLP\ntasks, including information retrieval and semantic search in historical texts.\nBayesian models for semantic change have emerged as a powerful tool to address\nthis challenge, providing explicit and interpretable representations of\nsemantic change phenomena. However, while corpora typically come with rich\nmetadata, existing models are limited by their inability to exploit contextual\ninformation (such as text genre) beyond the document time-stamp. This is\nparticularly critical in the case of ancient languages, where lack of data and\nlong diachronic span make it harder to draw a clear distinction between\npolysemy (the fact that a word has several senses) and semantic change (the\nprocess of acquiring, losing, or changing senses), and current systems perform\npoorly on these languages. We develop GASC, a dynamic semantic change model\nthat leverages categorical metadata about the texts' genre to boost inference\nand uncover the evolution of meanings in Ancient Greek corpora. In a new\nevaluation framework, our model achieves improved predictive performance\ncompared to the state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 17:32:51 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 12:48:56 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Perrone", "Valerio", ""], ["Palma", "Marco", ""], ["Hengchen", "Simon", ""], ["Vatri", "Alessandro", ""], ["Smith", "Jim Q.", ""], ["McGillivray", "Barbara", ""]]}, {"id": "1903.05594", "submitter": "Daniele Calandriello", "authors": "Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, Michal\n  Valko, Lorenzo Rosasco", "title": "Gaussian Process Optimization with Adaptive Sketching: Scalable and No\n  Regret", "comments": "Accepted at COLT 2019. Corrected typos and improved comparison with\n  existing methods", "journal-ref": "Proceedings of Machine Learning Research vol, 99, (COLT 2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GP) are a well studied Bayesian approach for the\noptimization of black-box functions. Despite their effectiveness in simple\nproblems, GP-based algorithms hardly scale to high-dimensional functions, as\ntheir per-iteration time and space cost is at least quadratic in the number of\ndimensions $d$ and iterations $t$. Given a set of $A$ alternatives to choose\nfrom, the overall runtime $O(t^3A)$ is prohibitive. In this paper we introduce\nBKB (budgeted kernelized bandit), a new approximate GP algorithm for\noptimization under bandit feedback that achieves near-optimal regret (and hence\nnear-optimal convergence rate) with near-constant per-iteration complexity and\nremarkably no assumption on the input space or covariance of the GP.\n  We combine a kernelized linear bandit algorithm (GP-UCB) with randomized\nmatrix sketching based on leverage score sampling, and we prove that randomly\nsampling inducing points based on their posterior variance gives an accurate\nlow-rank approximation of the GP, preserving variance estimates and confidence\nintervals. As a consequence, BKB does not suffer from variance starvation, an\nimportant problem faced by many previous sparse GP approximations. Moreover, we\nshow that our procedure selects at most $\\tilde{O}(d_{eff})$ points, where\n$d_{eff}$ is the effective dimension of the explored space, which is typically\nmuch smaller than both $d$ and $t$. This greatly reduces the dimensionality of\nthe problem, thus leading to a $O(TAd_{eff}^2)$ runtime and $O(A d_{eff})$\nspace complexity.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 16:50:40 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 16:20:21 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Calandriello", "Daniele", ""], ["Carratino", "Luigi", ""], ["Lazaric", "Alessandro", ""], ["Valko", "Michal", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1903.05614", "submitter": "Marc Lanctot", "authors": "Edward Lockhart, Marc Lanctot, Julien P\\'erolat, Jean-Baptiste\n  Lespiau, Dustin Morrill, Finbarr Timbers, Karl Tuyls", "title": "Computing Approximate Equilibria in Sequential Adversarial Games by\n  Exploitability Descent", "comments": "IJCAI 2019, 11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present exploitability descent, a new algorithm to compute\napproximate equilibria in two-player zero-sum extensive-form games with\nimperfect information, by direct policy optimization against worst-case\nopponents. We prove that when following this optimization, the exploitability\nof a player's strategy converges asymptotically to zero, and hence when both\nplayers employ this optimization, the joint policies converge to a Nash\nequilibrium. Unlike fictitious play (XFP) and counterfactual regret\nminimization (CFR), our convergence result pertains to the policies being\noptimized rather than the average policies. Our experiments demonstrate\nconvergence rates comparable to XFP and CFR in four benchmark games in the\ntabular case. Using function approximation, we find that our algorithm\noutperforms the tabular version in two of the games, which, to the best of our\nknowledge, is the first such result in imperfect information games among this\nclass of algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 17:27:04 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 15:14:51 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 22:49:42 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 04:41:23 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Lockhart", "Edward", ""], ["Lanctot", "Marc", ""], ["P\u00e9rolat", "Julien", ""], ["Lespiau", "Jean-Baptiste", ""], ["Morrill", "Dustin", ""], ["Timbers", "Finbarr", ""], ["Tuyls", "Karl", ""]]}, {"id": "1903.05631", "submitter": "Haoteng Yin", "authors": "Bing Yu, Haoteng Yin, Zhanxing Zhu", "title": "ST-UNet: A Spatio-Temporal U-Network for Graph-structured Time Series\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatio-temporal graph learning is becoming an increasingly important\nobject of graph study. Many application domains involve highly dynamic graphs\nwhere temporal information is crucial, e.g. traffic networks and financial\ntransaction graphs. Despite the constant progress made on learning structured\ndata, there is still a lack of effective means to extract dynamic complex\nfeatures from spatio-temporal structures. Particularly, conventional models\nsuch as convolutional networks or recurrent neural networks are incapable of\nrevealing the temporal patterns in short or long terms and exploring the\nspatial properties in local or global scope from spatio-temporal graphs\nsimultaneously. To tackle this problem, we design a novel multi-scale\narchitecture, Spatio-Temporal U-Net (ST-UNet), for graph-structured time series\nmodeling. In this U-shaped network, a paired sampling operation is proposed in\nspacetime domain accordingly: the pooling (ST-Pool) coarsens the input graph in\nspatial from its deterministic partition while abstracts multi-resolution\ntemporal dependencies through dilated recurrent skip connections; based on\nprevious settings in the downsampling, the unpooling (ST-Unpool) restores the\noriginal structure of spatio-temporal graphs and resumes regular intervals\nwithin graph sequences. Experiments on spatio-temporal prediction tasks\ndemonstrate that our model effectively captures comprehensive features in\nmultiple scales and achieves substantial improvements over mainstream methods\non several real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 17:57:12 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 15:51:25 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Yu", "Bing", ""], ["Yin", "Haoteng", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1903.05635", "submitter": "Nino Cauli", "authors": "Jaeseok Kim, Nino Cauli, Pedro Vicente, Bruno Damas, Alexandre\n  Bernardino, Jos\\'e Santos-Victor, Filippo Cavallo", "title": "Cleaning tasks knowledge transfer between heterogeneous robots: a deep\n  learning approach", "comments": "This paper was published in the Journal of Intelligent & Robotic\n  Systems on August 29th, 2019. Link:\n  https://doi.org/10.1007/s10846-019-01072-4", "journal-ref": "Journal of Intelligent & Robotic Systems (2019/08/29).\n  https://doi.org/10.1007/s10846-019-01072-4", "doi": "10.1007/s10846-019-01072-4", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, autonomous service robots are becoming an important topic in\nrobotic research. Differently from typical industrial scenarios, with highly\ncontrolled environments, service robots must show an additional robustness to\ntask perturbations and changes in the characteristics of their sensory\nfeedback. In this paper, a robot is taught to perform two different cleaning\ntasks over a table, using a learning from demonstration paradigm. However,\ndifferently from other approaches, a convolutional neural network is used to\ngeneralize the demonstrations to different, not yet seen dirt or stain patterns\non the same table using only visual feedback, and to perform cleaning movements\naccordingly. Robustness to robot posture and illumination changes is achieved\nusing data augmentation techniques and camera images transformation. This\nrobustness allows the transfer of knowledge regarding execution of cleaning\ntasks between heterogeneous robots operating in different environmental\nsettings. To demonstrate the viability of the proposed approach, a network\ntrained in Lisbon to perform cleaning tasks, using the iCub robot, is\nsuccessfully employed by the DoRo robot in Peccioli, Italy.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 17:59:10 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 17:55:05 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kim", "Jaeseok", ""], ["Cauli", "Nino", ""], ["Vicente", "Pedro", ""], ["Damas", "Bruno", ""], ["Bernardino", "Alexandre", ""], ["Santos-Victor", "Jos\u00e9", ""], ["Cavallo", "Filippo", ""]]}, {"id": "1903.05636", "submitter": "Negin Manshouri", "authors": "Negin Manshouri, Temel Kayikcioglu", "title": "A Comprehensive Analysis of 2D&3D Video Watching of EEG Signals by\n  Increasing PLSR and SVM Classification Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the development of two and three dimensional (2D&3D) technology, it\nhas attracted the attention of researchers in recent years. This research is\ndone to reveal the detailed effects of 2D in comparison with 3D technology on\nthe human brain waves. The impact of 2D&3D video watching using\nelectroencephalography (EEG) brain signals is studied. A group of eight healthy\nvolunteers with the average age of 31+-3.06 years old participated in this\nthree-stage test. EEG signal recording consisted of three stages: After a bit\nof relaxation (a), a 2D video was displayed (b), the recording of the signal\ncontinued for a short period of time as rest (c), and finally the trial ended.\nExactly the same steps were repeated for the 3D video. Power spectrum density\n(PSD) based on short time Fourier transform (STFT) was used to analyze the\nbrain signals of 2D&3D video viewers. After testing all the EEG frequency\nbands, delta and theta were extracted as the features. Partial least squares\nregression (PLSR) and Support vector machine (SVM) classification algorithms\nwere considered in order to classify EEG signals obtained as the result of\n2D&3D video watching. Successful classification results were obtained by\nselecting the correct combinations of effective channels representing the brain\nregions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 09:57:47 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Manshouri", "Negin", ""], ["Kayikcioglu", "Temel", ""]]}, {"id": "1903.05662", "submitter": "Penghang Yin", "authors": "Penghang Yin, Jiancheng Lyu, Shuai Zhang, Stanley Osher, Yingyong Qi,\n  Jack Xin", "title": "Understanding Straight-Through Estimator in Training Activation\n  Quantized Neural Nets", "comments": "in International Conference on Learning Representations (ICLR) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training activation quantized neural networks involves minimizing a piecewise\nconstant function whose gradient vanishes almost everywhere, which is\nundesirable for the standard back-propagation or chain rule. An empirical way\naround this issue is to use a straight-through estimator (STE) (Bengio et al.,\n2013) in the backward pass only, so that the \"gradient\" through the modified\nchain rule becomes non-trivial. Since this unusual \"gradient\" is certainly not\nthe gradient of loss function, the following question arises: why searching in\nits negative direction minimizes the training loss? In this paper, we provide\nthe theoretical justification of the concept of STE by answering this question.\nWe consider the problem of learning a two-linear-layer network with binarized\nReLU activation and Gaussian input data. We shall refer to the unusual\n\"gradient\" given by the STE-modifed chain rule as coarse gradient. The choice\nof STE is not unique. We prove that if the STE is properly chosen, the expected\ncoarse gradient correlates positively with the population gradient (not\navailable for the training), and its negation is a descent direction for\nminimizing the population loss. We further show the associated coarse gradient\ndescent algorithm converges to a critical point of the population loss\nminimization problem. Moreover, we show that a poor choice of STE leads to\ninstability of the training algorithm near certain local minima, which is\nverified with CIFAR-10 experiments.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 18:23:43 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 07:20:39 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 23:51:01 GMT"}, {"version": "v4", "created": "Wed, 25 Sep 2019 14:33:44 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Yin", "Penghang", ""], ["Lyu", "Jiancheng", ""], ["Zhang", "Shuai", ""], ["Osher", "Stanley", ""], ["Qi", "Yingyong", ""], ["Xin", "Jack", ""]]}, {"id": "1903.05675", "submitter": "Mahdieh Zabihimayvan", "authors": "Mahdieh Zabihimayvan, Derek Doran", "title": "Fuzzy Rough Set Feature Selection to Enhance Phishing Attack Detection", "comments": "Preprint of accepted paper in IEEE International Conference on Fuzzy\n  Systems 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing as one of the most well-known cybercrime activities is a deception\nof online users to steal their personal or confidential information by\nimpersonating a legitimate website. Several machine learning-based strategies\nhave been proposed to detect phishing websites. These techniques are dependent\non the features extracted from the website samples. However, few studies have\nactually considered efficient feature selection for detecting phishing attacks.\nIn this work, we investigate an agreement on the definitive features which\nshould be used in phishing detection. We apply Fuzzy Rough Set (FRS) theory as\na tool to select most effective features from three benchmarked data sets. The\nselected features are fed into three often used classifiers for phishing\ndetection. To evaluate the FRS feature selection in developing a generalizable\nphishing detection, the classifiers are trained by a separate out-of-sample\ndata set of 14,000 website samples. The maximum F-measure gained by FRS feature\nselection is 95% using Random Forest classification. Also, there are 9\nuniversal features selected by FRS over all the three data sets. The F-measure\nvalue using this universal feature set is approximately 93% which is a\ncomparable result in contrast to the FRS performance. Since the universal\nfeature set contains no features from third-part services, this finding implies\nthat with no inquiry from external sources, we can gain a faster phishing\ndetection which is also robust toward zero-day attacks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 18:48:52 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Zabihimayvan", "Mahdieh", ""], ["Doran", "Derek", ""]]}, {"id": "1903.05697", "submitter": "Sanjay Thakur", "authors": "Sanjay Thakur, Herke van Hoof, Juan Camilo Gamboa Higuera, Doina\n  Precup, David Meger", "title": "Uncertainty Aware Learning from Demonstrations in Multiple Contexts\n  using Bayesian Neural Networks", "comments": "Copyright 20XX IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diversity of environments is a key challenge that causes learned robotic\ncontrollers to fail due to the discrepancies between the training and\nevaluation conditions. Training from demonstrations in various conditions can\nmitigate---but not completely prevent---such failures. Learned controllers such\nas neural networks typically do not have a notion of uncertainty that allows to\ndiagnose an offset between training and testing conditions, and potentially\nintervene. In this work, we propose to use Bayesian Neural Networks, which have\nsuch a notion of uncertainty. We show that uncertainty can be leveraged to\nconsistently detect situations in high-dimensional simulated and real robotic\ndomains in which the performance of the learned controller would be sub-par.\nAlso, we show that such an uncertainty based solution allows making an informed\ndecision about when to invoke a fallback strategy. One fallback strategy is to\nrequest more data. We empirically show that providing data only when requested\nresults in increased data-efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 19:47:36 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Thakur", "Sanjay", ""], ["van Hoof", "Herke", ""], ["Higuera", "Juan Camilo Gamboa", ""], ["Precup", "Doina", ""], ["Meger", "David", ""]]}, {"id": "1903.05700", "submitter": "Ethan Rudd", "authors": "Ethan M. Rudd, Felipe N. Ducau, Cody Wild, Konstantin Berlin, and\n  Richard Harang", "title": "ALOHA: Auxiliary Loss Optimization for Hypothesis Augmentation", "comments": "Pre-print of a manuscript submitted to Usenix Security Symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware detection is a popular application of Machine Learning for\nInformation Security (ML-Sec), in which an ML classifier is trained to predict\nwhether a given file is malware or benignware. Parameters of this classifier\nare typically optimized such that outputs from the model over a set of input\nsamples most closely match the samples' true malicious/benign (1/0) target\nlabels. However, there are often a number of other sources of contextual\nmetadata for each malware sample, beyond an aggregate malicious/benign label,\nincluding multiple labeling sources and malware type information (e.g.,\nransomware, trojan, etc.), which we can feed to the classifier as auxiliary\nprediction targets. In this work, we fit deep neural networks to multiple\nadditional targets derived from metadata in a threat intelligence feed for\nPortable Executable (PE) malware and benignware, including a multi-source\nmalicious/benign loss, a count loss on multi-source detections, and a semantic\nmalware attribute tag loss. We find that incorporating multiple auxiliary loss\nterms yields a marked improvement in performance on the main detection task. We\nalso demonstrate that these gains likely stem from a more informed neural\nnetwork representation and are not due to a regularization artifact of\nmulti-target learning. Our auxiliary loss architecture yields a significant\nreduction in detection error rate (false negatives) of 42.6% at a false\npositive rate (FPR) of $10^{-3}$ when compared to a similar model with only one\ntarget, and a decrease of 53.8% at $10^{-5}$ FPR.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 19:56:04 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Rudd", "Ethan M.", ""], ["Ducau", "Felipe N.", ""], ["Wild", "Cody", ""], ["Berlin", "Konstantin", ""], ["Harang", "Richard", ""]]}, {"id": "1903.05728", "submitter": "Yuval Nezri", "authors": "Reuven Cohen, Yuval Nezri", "title": "Cardinality Estimation in a Virtualized Network Device Using Online\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardinality estimation algorithms receive a stream of elements, with possible\nrepetitions, and return the number of distinct elements in the stream. Such\nalgorithms seek to minimize the required memory and CPU resource consumption at\nthe price of inaccuracy in their output. In computer networks, cardinality\nestimation algorithms are mainly used for counting the number of distinct\nflows, and they are divided into two categories: sketching algorithms and\nsampling algorithms. Sketching algorithms require the processing of all\npackets, and they are therefore usually implemented by dedicated hardware.\nSampling algorithms do not require processing of all packets, but they are\nknown for their inaccuracy. In this work we identify one of the major drawbacks\nof sampling-based cardinality estimation algorithms: their inability to adapt\nto changes in flow size distribution. To address this problem, we propose a new\nsampling-based adaptive cardinality estimation framework, which uses online\nmachine learning. We evaluate our framework using real traffic traces, and show\nsignificantly better accuracy compared to the best known sampling-based\nalgorithms, for the same fraction of processed packets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 21:39:01 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Cohen", "Reuven", ""], ["Nezri", "Yuval", ""]]}, {"id": "1903.05734", "submitter": "Rafael - Michael Karampatsis", "authors": "Rafael-Michael Karampatsis and Charles Sutton", "title": "Maybe Deep Neural Networks are the Best Choice for Modeling Source Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical language modeling techniques have successfully been applied to\nsource code, yielding a variety of new software development tools, such as\ntools for code suggestion and improving readability. A major issue with these\ntechniques is that code introduces new vocabulary at a far higher rate than\nnatural language, as new identifier names proliferate. But traditional language\nmodels limit the vocabulary to a fixed set of common words. For code, this\nstrong assumption has been shown to have a significant negative effect on\npredictive performance. But the open vocabulary version of the neural network\nlanguage models for code have not been introduced in the literature. We present\na new open-vocabulary neural language model for code that is not limited to a\nfixed vocabulary of identifier names. We employ a segmentation into subword\nunits, subsequences of tokens chosen based on a compression criterion,\nfollowing previous work in machine translation. Our network achieves best in\nclass performance, outperforming even the state-of-the-art methods of\nHellendoorn and Devanbu that are designed specifically to model code.\nFurthermore, we present a simple method for dynamically adapting the model to a\nnew test project, resulting in increased performance. We showcase our\nmethodology on code corpora in three different languages of over a billion\ntokens each, hundreds of times larger than in previous work. To our knowledge,\nthis is the largest neural language model for code that has been reported.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 22:03:22 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Karampatsis", "Rafael-Michael", ""], ["Sutton", "Charles", ""]]}, {"id": "1903.05751", "submitter": "Kei Ota", "authors": "Kei Ota, Devesh K. Jha, Tomoaki Oiki, Mamoru Miura, Takashi Nammoto,\n  Daniel Nikovski, and Toshisada Mariyama", "title": "Trajectory Optimization for Unknown Constrained Systems using\n  Reinforcement Learning", "comments": "8 pages, 6 figures, Accepted to IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a reinforcement learning-based algorithm for\ntrajectory optimization for constrained dynamical systems. This problem is\nmotivated by the fact that for most robotic systems, the dynamics may not\nalways be known. Generating smooth, dynamically feasible trajectories could be\ndifficult for such systems. Using sampling-based algorithms for motion planning\nmay result in trajectories that are prone to undesirable control jumps.\nHowever, they can usually provide a good reference trajectory which a\nmodel-free reinforcement learning algorithm can then exploit by limiting the\nsearch domain and quickly finding a dynamically smooth trajectory. We use this\nidea to train a reinforcement learning agent to learn a dynamically smooth\ntrajectory in a curriculum learning setting. Furthermore, for generalization,\nwe parameterize the policies with goal locations, so that the agent can be\ntrained for multiple goals simultaneously. We show result in both simulated\nenvironments as well as real experiments, for a $6$-DoF manipulator arm\noperated in position-controlled mode to validate the proposed idea. We compare\nthe proposed ideas against a PID controller which is used to track a designed\ntrajectory in configuration space. Our experiments show that our RL agent\ntrained with a reference path outperformed a model-free PID controller of the\ntype commonly used on many robotic platforms for trajectory tracking.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 23:07:29 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 22:24:14 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Ota", "Kei", ""], ["Jha", "Devesh K.", ""], ["Oiki", "Tomoaki", ""], ["Miura", "Mamoru", ""], ["Nammoto", "Takashi", ""], ["Nikovski", "Daniel", ""], ["Mariyama", "Toshisada", ""]]}, {"id": "1903.05766", "submitter": "Raunak Bhattacharyya", "authors": "Raunak P. Bhattacharyya, Derek J. Phillips, Changliu Liu, Jayesh K.\n  Gupta, Katherine Driggs-Campbell, Mykel J. Kochenderfer", "title": "Simulating Emergent Properties of Human Driving Behavior Using\n  Multi-Agent Reward Augmented Imitation Learning", "comments": "Accepted for publication at ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in multi-agent imitation learning have shown promising\nresults for modeling the behavior of human drivers. However, it is challenging\nto capture emergent traffic behaviors that are observed in real-world datasets.\nSuch behaviors arise due to the many local interactions between agents that are\nnot commonly accounted for in imitation learning. This paper proposes Reward\nAugmented Imitation Learning (RAIL), which integrates reward augmentation into\nthe multi-agent imitation learning framework and allows the designer to specify\nprior knowledge in a principled fashion. We prove that convergence guarantees\nfor the imitation learning process are preserved under the application of\nreward augmentation. This method is validated in a driving scenario, where an\nentire traffic scene is controlled by driving policies learned using our\nproposed algorithm. Further, we demonstrate improved performance in comparison\nto traditional imitation learning algorithms both in terms of the local actions\nof a single agent and the behavior of emergent properties in complex,\nmulti-agent settings.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 00:02:03 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Bhattacharyya", "Raunak P.", ""], ["Phillips", "Derek J.", ""], ["Liu", "Changliu", ""], ["Gupta", "Jayesh K.", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1903.05769", "submitter": "Oguzhan Gencoglu", "authors": "Umair Akhtar Hasan Khan, Carolin St\\\"urenberg, Oguzhan Gencoglu, Kevin\n  Sandeman, Timo Heikkinen, Antti Rannikko, Tuomas Mirtti", "title": "Improving Prostate Cancer Detection with Breast Histopathology Images", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": "10.1007/978-3-030-23937-4_11", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have introduced significant advancements in the field of\nmachine learning-based analysis of digital pathology images including prostate\ntissue images. With the help of transfer learning, classification and\nsegmentation performance of neural network models have been further increased.\nHowever, due to the absence of large, extensively annotated, publicly available\nprostate histopathology datasets, several previous studies employ datasets from\nwell-studied computer vision tasks such as ImageNet dataset. In this work, we\npropose a transfer learning scheme from breast histopathology images to improve\nprostate cancer detection performance. We validate our approach on annotated\nprostate whole slide images by using a publicly available breast histopathology\ndataset as pre-training. We show that the proposed cross-cancer approach\noutperforms transfer learning from ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 00:09:14 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Khan", "Umair Akhtar Hasan", ""], ["St\u00fcrenberg", "Carolin", ""], ["Gencoglu", "Oguzhan", ""], ["Sandeman", "Kevin", ""], ["Heikkinen", "Timo", ""], ["Rannikko", "Antti", ""], ["Mirtti", "Tuomas", ""]]}, {"id": "1903.05779", "submitter": "Shengyang Sun", "authors": "Shengyang Sun, Guodong Zhang, Jiaxin Shi, Roger Grosse", "title": "Functional Variational Bayesian Neural Networks", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayesian neural networks (BNNs) perform variational inference\nover weights, but it is difficult to specify meaningful priors and approximate\nposteriors in a high-dimensional weight space. We introduce functional\nvariational Bayesian neural networks (fBNNs), which maximize an Evidence Lower\nBOund (ELBO) defined directly on stochastic processes, i.e. distributions over\nfunctions. We prove that the KL divergence between stochastic processes equals\nthe supremum of marginal KL divergences over all finite sets of inputs. Based\non this, we introduce a practical training objective which approximates the\nfunctional ELBO using finite measurement sets and the spectral Stein gradient\nestimator. With fBNNs, we can specify priors entailing rich structures,\nincluding Gaussian processes and implicit stochastic processes. Empirically, we\nfind fBNNs extrapolate well using various structured priors, provide reliable\nuncertainty estimates, and scale to large datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 01:05:24 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Sun", "Shengyang", ""], ["Zhang", "Guodong", ""], ["Shi", "Jiaxin", ""], ["Grosse", "Roger", ""]]}, {"id": "1903.05789", "submitter": "Bin Dai", "authors": "Bin Dai and David Wipf", "title": "Diagnosing and Enhancing VAE Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although variational autoencoders (VAEs) represent a widely influential deep\ngenerative model, many aspects of the underlying energy function remain poorly\nunderstood. In particular, it is commonly believed that Gaussian\nencoder/decoder assumptions reduce the effectiveness of VAEs in generating\nrealistic samples. In this regard, we rigorously analyze the VAE objective,\ndifferentiating situations where this belief is and is not actually true. We\nthen leverage the corresponding insights to develop a simple VAE enhancement\nthat requires no additional hyperparameters or sensitive tuning.\nQuantitatively, this proposal produces crisp samples and stable FID scores that\nare actually competitive with a variety of GAN models, all while retaining\ndesirable attributes of the original VAE architecture. A shorter version of\nthis work will appear in the ICLR 2019 conference proceedings (Dai and Wipf,\n2019). The code for our model is available at https://github.com/daib13/\nTwoStageVAE.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 02:11:17 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 10:53:11 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Dai", "Bin", ""], ["Wipf", "David", ""]]}, {"id": "1903.05803", "submitter": "Mohamad Kazem Shirani Faradonbeh", "authors": "Mohamad Kazem Shirani Faradonbeh, Ambuj Tewari, George Michailidis", "title": "On Applications of Bootstrap in Continuous Space Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decision making problems for continuous state and action spaces, linear\ndynamical models are widely employed. Specifically, policies for stochastic\nlinear systems subject to quadratic cost functions capture a large number of\napplications in reinforcement learning. Selected randomized policies have been\nstudied in the literature recently that address the trade-off between\nidentification and control. However, little is known about policies based on\nbootstrapping observed states and actions. In this work, we show that\nbootstrap-based policies achieve a square root scaling of regret with respect\nto time. We also obtain results on the accuracy of learning the model's\ndynamics. Corroborative numerical analysis that illustrates the technical\nresults is also provided.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 03:37:49 GMT"}, {"version": "v2", "created": "Sat, 20 Apr 2019 21:37:17 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Faradonbeh", "Mohamad Kazem Shirani", ""], ["Tewari", "Ambuj", ""], ["Michailidis", "George", ""]]}, {"id": "1903.05817", "submitter": "Aritra Mitra", "authors": "Aritra Mitra, John A. Richards and Shreyas Sundaram", "title": "A New Approach for Distributed Hypothesis Testing with Extensions to\n  Byzantine-Resilience", "comments": "To appear in the Proceedings of the American Control Conference, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a setting where a group of agents, each receiving partially\ninformative private observations, seek to collaboratively learn the true state\n(among a set of hypotheses) that explains their joint observation profiles over\ntime. To solve this problem, we propose a distributed learning rule that\ndiffers fundamentally from existing approaches, in the sense, that it does not\nemploy any form of \"belief-averaging\". Specifically, every agent maintains a\nlocal belief (on each hypothesis) that is updated in a Bayesian manner without\nany network influence, and an actual belief that is updated (up to\nnormalization) as the minimum of its own local belief and the actual beliefs of\nits neighbors. Under minimal requirements on the signal structures of the\nagents and the underlying communication graph, we establish consistency of the\nproposed belief update rule, i.e., we show that the actual beliefs of the\nagents asymptotically concentrate on the true state almost surely. As one of\nthe key benefits of our approach, we show that our learning rule can be\nextended to scenarios that capture misbehavior on the part of certain agents in\nthe network, modeled via the Byzantine adversary model. In particular, we prove\nthat each non-adversarial agent can asymptotically learn the true state of the\nworld almost surely, under appropriate conditions on the observation model and\nthe network topology.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 05:06:29 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Mitra", "Aritra", ""], ["Richards", "John A.", ""], ["Sundaram", "Shreyas", ""]]}, {"id": "1903.05818", "submitter": "Frank Nielsen", "authors": "Frank Nielsen and Ga\\\"etan Hadjeres", "title": "On power chi expansions of $f$-divergences", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider both finite and infinite power chi expansions of $f$-divergences\nderived from Taylor's expansions of smooth generators, and elaborate on cases\nwhere these expansions yield closed-form formula, bounded approximations, or\nanalytic divergence series expressions of $f$-divergences.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 05:14:58 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Nielsen", "Frank", ""], ["Hadjeres", "Ga\u00ebtan", ""]]}, {"id": "1903.05821", "submitter": "Sumit Kumar Jha", "authors": "Susmit Jha, Sunny Raj, Steven Lawrence Fernandes, Sumit Kumar Jha,\n  Somesh Jha, Gunjan Verma, Brian Jalaian, Ananthram Swami", "title": "Attribution-driven Causal Analysis for Detection of Adversarial Examples", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods have been developed to explain the decision of a machine\nlearning model on a given input. We use the Integrated Gradient method for\nfinding attributions to define the causal neighborhood of an input by\nincrementally masking high attribution features. We study the robustness of\nmachine learning models on benign and adversarial inputs in this neighborhood.\nOur study indicates that benign inputs are robust to the masking of high\nattribution features but adversarial inputs generated by the state-of-the-art\nadversarial attack methods such as DeepFool, FGSM, CW and PGD, are not robust\nto such masking. Further, our study demonstrates that this concentration of\nhigh-attribution features responsible for the incorrect decision is more\npronounced in physically realizable adversarial examples. This difference in\nattribution of benign and adversarial inputs can be used to detect adversarial\nexamples. Such a defense approach is independent of training data and attack\nmethod, and we demonstrate its effectiveness on digital and physically\nrealizable perturbations.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 05:50:00 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Jha", "Susmit", ""], ["Raj", "Sunny", ""], ["Fernandes", "Steven Lawrence", ""], ["Jha", "Sumit Kumar", ""], ["Jha", "Somesh", ""], ["Verma", "Gunjan", ""], ["Jalaian", "Brian", ""], ["Swami", "Ananthram", ""]]}, {"id": "1903.05831", "submitter": "Naiyan Wang", "authors": "Yuntao Chen, Chenxia Han, Yanghao Li, Zehao Huang, Yi Jiang, Naiyan\n  Wang, Zhaoxiang Zhang", "title": "SimpleDet: A Simple and Versatile Distributed Framework for Object\n  Detection and Instance Recognition", "comments": "Tech Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection and instance recognition play a central role in many AI\napplications like autonomous driving, video surveillance and medical image\nanalysis. However, training object detection models on large scale datasets\nremains computationally expensive and time consuming. This paper presents an\nefficient and open source object detection framework called SimpleDet which\nenables the training of state-of-the-art detection models on consumer grade\nhardware at large scale. SimpleDet supports up-to-date detection models with\nbest practice. SimpleDet also supports distributed training with near linear\nscaling out of box. Codes, examples and documents of SimpleDet can be found at\nhttps://github.com/tusimple/simpledet .\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 06:40:29 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Chen", "Yuntao", ""], ["Han", "Chenxia", ""], ["Li", "Yanghao", ""], ["Huang", "Zehao", ""], ["Jiang", "Yi", ""], ["Wang", "Naiyan", ""], ["Zhang", "Zhaoxiang", ""]]}, {"id": "1903.05844", "submitter": "Frederic Sala", "authors": "Paroma Varma, Frederic Sala, Ann He, Alexander Ratner, Christopher\n  R\\'e", "title": "Learning Dependency Structures for Weak Supervision Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling training data is a key bottleneck in the modern machine learning\npipeline. Recent weak supervision approaches combine labels from multiple noisy\nsources by estimating their accuracies without access to ground truth labels;\nhowever, estimating the dependencies among these sources is a critical\nchallenge. We focus on a robust PCA-based algorithm for learning these\ndependency structures, establish improved theoretical recovery rates, and\noutperform existing methods on various real-world tasks. Under certain\nconditions, we show that the amount of unlabeled data needed can scale\nsublinearly or even logarithmically with the number of sources $m$, improving\nover previous efforts that ignore the sparsity pattern in the dependency\nstructure and scale linearly in $m$. We provide an information-theoretic lower\nbound on the minimum sample complexity of the weak supervision setting. Our\nmethod outperforms weak supervision approaches that assume\nconditionally-independent sources by up to 4.64 F1 points and previous\nstructure learning approaches by up to 4.41 F1 points on real-world relation\nextraction and image classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 07:55:52 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Varma", "Paroma", ""], ["Sala", "Frederic", ""], ["He", "Ann", ""], ["Ratner", "Alexander", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1903.05854", "submitter": "Tingting Qiao", "authors": "Tingting Qiao, Jing Zhang, Duanqing Xu and Dacheng Tao", "title": "MirrorGAN: Learning Text-to-image Generation by Redescription", "comments": "Accepted by CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating an image from a given text description has two goals: visual\nrealism and semantic consistency. Although significant progress has been made\nin generating high-quality and visually realistic images using generative\nadversarial networks, guaranteeing semantic consistency between the text\ndescription and visual content remains very challenging. In this paper, we\naddress this problem by proposing a novel global-local attentive and\nsemantic-preserving text-to-image-to-text framework called MirrorGAN. MirrorGAN\nexploits the idea of learning text-to-image generation by redescription and\nconsists of three modules: a semantic text embedding module (STEM), a\nglobal-local collaborative attentive module for cascaded image generation\n(GLAM), and a semantic text regeneration and alignment module (STREAM). STEM\ngenerates word- and sentence-level embeddings. GLAM has a cascaded architecture\nfor generating target images from coarse to fine scales, leveraging both local\nword attention and global sentence attention to progressively enhance the\ndiversity and semantic consistency of the generated images. STREAM seeks to\nregenerate the text description from the generated image, which semantically\naligns with the given text description. Thorough experiments on two public\nbenchmark datasets demonstrate the superiority of MirrorGAN over other\nrepresentative state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 08:31:05 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Qiao", "Tingting", ""], ["Zhang", "Jing", ""], ["Xu", "Duanqing", ""], ["Tao", "Dacheng", ""]]}, {"id": "1903.05881", "submitter": "Yasunori Ozaki", "authors": "Yasunori Ozaki, Tatsuya Ishihara, Narimune Matsumura, Tadashi Nunobiki", "title": "Can User-Centered Reinforcement Learning Allow a Robot to Attract\n  Passersby without Causing Discomfort?", "comments": "Accepted to The 2019 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The aim of our study was to develop a method by which a social robot can\ngreet passersby and get their attention without causing them to suffer\ndiscomfort.A number of customer services have recently come to be provided by\nsocial robots rather than people, including, serving as receptionists, guides,\nand exhibitors. Robot exhibitors, for example, can explain products being\npromoted by the robot owners. However, a sudden greeting by a robot can startle\npassersby and cause discomfort to passersby.Social robots should thus adapt\ntheir mannerisms to the situation they face regarding passersby.We developed a\nmethod for meeting this requirement on the basis of the results of related\nwork. Our proposed method, user-centered reinforcement learning, enables robots\nto greet passersby and get their attention without causing them to suffer\ndiscomfort (p<0.01) .The results of an experiment in the field, an office\nentrance, demonstrated that our method meets this requirement.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 09:51:04 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 03:52:52 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Ozaki", "Yasunori", ""], ["Ishihara", "Tatsuya", ""], ["Matsumura", "Narimune", ""], ["Nunobiki", "Tadashi", ""]]}, {"id": "1903.05895", "submitter": "Tri Dao", "authors": "Tri Dao, Albert Gu, Matthew Eichhorn, Atri Rudra, Christopher R\\'e", "title": "Learning Fast Algorithms for Linear Transforms Using Butterfly\n  Factorizations", "comments": "International Conference on Machine Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast linear transforms are ubiquitous in machine learning, including the\ndiscrete Fourier transform, discrete cosine transform, and other structured\ntransformations such as convolutions. All of these transforms can be\nrepresented by dense matrix-vector multiplication, yet each has a specialized\nand highly efficient (subquadratic) algorithm. We ask to what extent\nhand-crafting these algorithms and implementations is necessary, what\nstructural priors they encode, and how much knowledge is required to\nautomatically learn a fast algorithm for a provided structured transform.\nMotivated by a characterization of fast matrix-vector multiplication as\nproducts of sparse matrices, we introduce a parameterization of\ndivide-and-conquer methods that is capable of representing a large class of\ntransforms. This generic formulation can automatically learn an efficient\nalgorithm for many important transforms; for example, it recovers the $O(N \\log\nN)$ Cooley-Tukey FFT algorithm to machine precision, for dimensions $N$ up to\n$1024$. Furthermore, our method can be incorporated as a lightweight\nreplacement of generic matrices in machine learning pipelines to learn\nefficient and compressible transformations. On a standard task of compressing a\nsingle hidden-layer network, our method exceeds the classification accuracy of\nunconstrained matrices on CIFAR-10 by 3.9 points -- the first time a structured\napproach has done so -- with 4X faster inference speed and 40X fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 10:20:38 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 03:32:01 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Dao", "Tri", ""], ["Gu", "Albert", ""], ["Eichhorn", "Matthew", ""], ["Rudra", "Atri", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1903.05898", "submitter": "Siqi Wang", "authors": "Siqi Wang, Gayathri Ananthanarayanan, Yifan Zeng, Neeraj Goel, Anuj\n  Pathania, Tulika Mitra", "title": "High-Throughput CNN Inference on Embedded ARM big.LITTLE Multi-Core\n  Processors", "comments": "Accepted to IEEE Transactions on Computer-Aided Design of Integrated\n  Circuits and Systems", "journal-ref": "in IEEE Transactions on Computer-Aided Design of Integrated\n  Circuits and Systems, vol. 39, no. 10, pp. 2254-2267, Oct. 2020", "doi": "10.1109/TCAD.2019.2944584", "report-no": null, "categories": "cs.LG cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT Edge intelligence requires Convolutional Neural Network (CNN) inference\nto take place in the edge devices itself. ARM big.LITTLE architecture is at the\nheart of prevalent commercial edge devices. It comprises of single-ISA\nheterogeneous cores grouped into multiple homogeneous clusters that enable\npower and performance trade-offs. All cores are expected to be simultaneously\nemployed in inference to attain maximal throughput. However, high communication\noverhead involved in parallelization of computations from convolution kernels\nacross clusters is detrimental to throughput. We present an alternative\nframework called Pipe-it that employs pipelined design to split convolutional\nlayers across clusters while limiting parallelization of their respective\nkernels to the assigned cluster. We develop a performance-prediction model that\nutilizes only the convolutional layer descriptors to predict the execution time\nof each layer individually on all permitted core configurations (type and\ncount). Pipe-it then exploits the predictions to create a balanced pipeline\nusing an efficient design space exploration algorithm. Pipe-it on average\nresults in a 39% higher throughput than the highest antecedent throughput.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 10:24:57 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 07:43:41 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 15:46:27 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Wang", "Siqi", ""], ["Ananthanarayanan", "Gayathri", ""], ["Zeng", "Yifan", ""], ["Goel", "Neeraj", ""], ["Pathania", "Anuj", ""], ["Mitra", "Tulika", ""]]}, {"id": "1903.05926", "submitter": "Ling Pan", "authors": "Ling Pan, Qingpeng Cai, Qi Meng, Wei Chen, Longbo Huang, Tie-Yan Liu", "title": "Reinforcement Learning with Dynamic Boltzmann Softmax Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value function estimation is an important task in reinforcement learning,\ni.e., prediction. The Boltzmann softmax operator is a natural value estimator\nand can provide several benefits. However, it does not satisfy the\nnon-expansion property, and its direct use may fail to converge even in value\niteration. In this paper, we propose to update the value function with dynamic\nBoltzmann softmax (DBS) operator, which has good convergence property in the\nsetting of planning and learning. Experimental results on GridWorld show that\nthe DBS operator enables better estimation of the value function, which\nrectifies the convergence issue of the softmax operator. Finally, we propose\nthe DBS-DQN algorithm by applying dynamic Boltzmann softmax updates in deep\nQ-network, which outperforms DQN substantially in 40 out of 49 Atari games.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 11:54:13 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 01:32:58 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 03:40:05 GMT"}, {"version": "v4", "created": "Sun, 8 Sep 2019 07:41:39 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Pan", "Ling", ""], ["Cai", "Qingpeng", ""], ["Meng", "Qi", ""], ["Chen", "Wei", ""], ["Huang", "Longbo", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1903.05946", "submitter": "Tim C Kietzmann", "authors": "Tim C Kietzmann, Courtney J Spoerer, Lynn S\\\"orensen, Radoslaw M\n  Cichy, Olaf Hauk, and Nikolaus Kriegeskorte", "title": "Recurrence is required to capture the representational dynamics of the\n  human visual system", "comments": "https://www.pnas.org/content/early/2019/10/04/1905544116.short?rss=1", "journal-ref": "Proceedings of the National Academy of Sciences, p. 1-10 (2019)", "doi": "10.1073/pnas.1905544116", "report-no": null, "categories": "q-bio.NC cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The human visual system is an intricate network of brain regions that enables\nus to recognize the world around us. Despite its abundant lateral and feedback\nconnections, object processing is commonly viewed and studied as a feedforward\nprocess. Here, we measure and model the rapid representational dynamics across\nmultiple stages of the human ventral stream using time-resolved brain imaging\nand deep learning. We observe substantial representational transformations\nduring the first 300 ms of processing within and across ventral-stream regions.\nCategorical divisions emerge in sequence, cascading forward and in reverse\nacross regions, and Granger causality analysis suggests bidirectional\ninformation flow between regions. Finally, recurrent deep neural network models\nclearly outperform parameter-matched feedforward models in terms of their\nability to capture the multi-region cortical dynamics. Targeted virtual cooling\nexperiments on the recurrent deep network models further substantiate the\nimportance of their lateral and top-down connections. These results establish\nthat recurrent models are required to understand information processing in the\nhuman ventral stream.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 12:43:38 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 08:45:53 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Kietzmann", "Tim C", ""], ["Spoerer", "Courtney J", ""], ["S\u00f6rensen", "Lynn", ""], ["Cichy", "Radoslaw M", ""], ["Hauk", "Olaf", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1903.05955", "submitter": "Bajibabu Bollepalli Mr", "authors": "Bajibabu Bollepalli and Lauri Juvela and Paavo Alku", "title": "Generative adversarial network-based glottal waveform model for\n  statistical parametric speech synthesis", "comments": "Accepted in Interspeech", "journal-ref": "Interspeech-2017", "doi": "10.21437/Interspeech.2017-1288", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that text-to-speech synthesis quality can be\nimproved by using glottal vocoding. This refers to vocoders that parameterize\nspeech into two parts, the glottal excitation and vocal tract, that occur in\nthe human speech production apparatus. Current glottal vocoders generate the\nglottal excitation waveform by using deep neural networks (DNNs). However, the\nsquared error-based training of the present glottal excitation models is\nlimited to generating conditional average waveforms, which fails to capture the\nstochastic variation of the waveforms. As a result, shaped noise is added as\npost-processing. In this study, we propose a new method for predicting glottal\nwaveforms by generative adversarial networks (GANs). GANs are generative models\nthat aim to embed the data distribution in a latent space, enabling generation\nof new instances very similar to the original by randomly sampling the latent\ndistribution. The glottal pulses generated by GANs show a stochastic component\nsimilar to natural glottal pulses. In our experiments, we compare synthetic\nspeech generated using glottal waveforms produced by both DNNs and GANs. The\nresults show that the newly proposed GANs achieve synthesis quality comparable\nto that of widely-used DNNs, without using an additive noise component.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 12:53:45 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Bollepalli", "Bajibabu", ""], ["Juvela", "Lauri", ""], ["Alku", "Paavo", ""]]}, {"id": "1903.05962", "submitter": "Zhao Kang", "authors": "Zhao Kang, Liangjian Wen, Wenyu Chen, Zenglin Xu", "title": "Low-rank Kernel Learning for Graph-based Clustering", "comments": null, "journal-ref": "Knowledge-Based Systems, 2019", "doi": "10.1016/j.knosys.2018.09.009", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing the adjacency graph is fundamental to graph-based clustering.\nGraph learning in kernel space has shown impressive performance on a number of\nbenchmark data sets. However, its performance is largely determined by the\nchosen kernel matrix. To address this issue, the previous multiple kernel\nlearning algorithm has been applied to learn an optimal kernel from a group of\npredefined kernels. This approach might be sensitive to noise and limits the\nrepresentation ability of the consensus kernel. In contrast to existing\nmethods, we propose to learn a low-rank kernel matrix which exploits the\nsimilarity nature of the kernel matrix and seeks an optimal kernel from the\nneighborhood of candidate kernels. By formulating graph construction and kernel\nlearning in a unified framework, the graph and consensus kernel can be\niteratively enhanced by each other. Extensive experimental results validate the\nefficacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 12:59:52 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Kang", "Zhao", ""], ["Wen", "Liangjian", ""], ["Chen", "Wenyu", ""], ["Xu", "Zenglin", ""]]}, {"id": "1903.05965", "submitter": "Yiming Li", "authors": "Jiawang Bai, Yiming Li, Jiawei Li, Yong Jiang, Shutao Xia", "title": "Rectified Decision Trees: Towards Interpretability, Compression and\n  Empirical Soundness", "comments": "This is an early draft of our journal submission 'Rectified Decision\n  Trees: Exploring the Landscape of Interpretable and Effective Machine\n  Learning'. Please refer to our new version (arXiv:2008.09413)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to obtain a model with good interpretability and performance has always\nbeen an important research topic. In this paper, we propose rectified decision\ntrees (ReDT), a knowledge distillation based decision trees rectification with\nhigh interpretability, small model size, and empirical soundness. Specifically,\nwe extend the impurity calculation and the pure ending condition of the\nclassical decision tree to propose a decision tree extension that allows the\nuse of soft labels generated by a well-trained teacher model in training and\nprediction process. It is worth noting that for the acquisition of soft labels,\nwe propose a new multiple cross-validation based method to reduce the effects\nof randomness and overfitting. These approaches ensure that ReDT retains\nexcellent interpretability and even achieves fewer nodes than the decision tree\nin the aspect of compression while having relatively good performance. Besides,\nin contrast to traditional knowledge distillation, back propagation of the\nstudent model is not necessarily required in ReDT, which is an attempt of a new\nknowledge distillation approach. Extensive experiments are conducted, which\ndemonstrates the superiority of ReDT in interpretability, compression, and\nempirical soundness.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 13:04:03 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 02:52:06 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bai", "Jiawang", ""], ["Li", "Yiming", ""], ["Li", "Jiawei", ""], ["Jiang", "Yong", ""], ["Xia", "Shutao", ""]]}, {"id": "1903.05976", "submitter": "Sida Zhou", "authors": "Sida Zhou", "title": "Empirical effect of graph embeddings on fraud detection/ risk mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding technics are studied with interest on public datasets, such\nas BlogCatalog, with the common practice of maximizing scoring on graph\nreconstruction, link prediction metrics etc. However, in the financial sector\nthe important metrics are often more business related, for example fraud\ndetection rates. With our privileged position of having large amount of\nreal-world non-public P2P-lending social data, we aim to study empirically\nwhether recent advances in graph embedding technics provide a useful signal for\nmetrics more closely related to business interests, such as fraud detection\nrate.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 07:49:27 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Zhou", "Sida", ""]]}, {"id": "1903.05980", "submitter": "Leonardo Gutierrez", "authors": "Leonardo Guti\\'errez-G\\'omez, Jean-Charles Delvenne", "title": "Unsupervised Network Embedding for Graph Visualization, Clustering and\n  Classification", "comments": "17 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main challenge in mining network-based data is finding effective ways to\nrepresent or encode graph structures so that it can be efficiently exploited by\nmachine learning algorithms. Several methods have focused in network\nrepresentation at node/edge or substructure level. However, many real life\nchallenges such as time-varying, multilayer, chemical compounds and brain\nnetworks involve analysis of a family of graphs instead of single one opening\nadditional challenges in graph comparison and representation. Traditional\napproaches for learning representations relies on hand-crafting specialized\nheuristics to extract meaningful information about the graphs, e.g statistical\nproperties, structural features, etc. as well as engineered graph distances to\nquantify dissimilarity between networks. In this work we provide an\nunsupervised approach to learn embedding representation for a collection of\ngraphs so that it can be used in numerous graph mining tasks. By using an\nunsupervised neural network approach on input graphs, we aim to capture the\nunderlying distribution of the data in order to discriminate between different\nclass of networks. Our method is assessed empirically on synthetic and real\nlife datasets and evaluated in three different tasks: graph clustering,\nvisualization and classification. Results reveal that our method outperforms\nwell known graph distances and graph-kernels in clustering and classification\ntasks, being highly efficient in runtime.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 08:15:05 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 07:46:36 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Guti\u00e9rrez-G\u00f3mez", "Leonardo", ""], ["Delvenne", "Jean-Charles", ""]]}, {"id": "1903.05987", "submitter": "Sebastian Ruder", "authors": "Matthew E. Peters, Sebastian Ruder, Noah A. Smith", "title": "To Tune or Not to Tune? Adapting Pretrained Representations to Diverse\n  Tasks", "comments": "Proceedings of the 4th Workshop on Representation Learning for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most previous work has focused on different pretraining objectives and\narchitectures for transfer learning, we ask how to best adapt the pretrained\nmodel to a given target task. We focus on the two most common forms of\nadaptation, feature extraction (where the pretrained weights are frozen), and\ndirectly fine-tuning the pretrained model. Our empirical results across diverse\nNLP tasks with two state-of-the-art models show that the relative performance\nof fine-tuning vs. feature extraction depends on the similarity of the\npretraining and target tasks. We explore possible explanations for this finding\nand provide a set of adaptation guidelines for the NLP practitioner.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 13:32:31 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 13:13:46 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Peters", "Matthew E.", ""], ["Ruder", "Sebastian", ""], ["Smith", "Noah A.", ""]]}, {"id": "1903.06007", "submitter": "Esteban Bautista", "authors": "Esteban Bautista and Patrice Abry and Paulo Gon\\c{c}alves", "title": "$L^\\gamma$-PageRank for Semi-Supervised Learning", "comments": "Submitted to Applied Network Science (special issue on machine\n  learning with graphs)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PageRank for Semi-Supervised Learning has shown to leverage data structures\nand limited tagged examples to yield meaningful classification. Despite\nsuccesses, classification performance can still be improved, particularly in\ncases of fuzzy graphs or unbalanced labeled data. To address such limitations,\na novel approach based on powers of the Laplacian matrix $L^\\gamma$ ($\\gamma >\n0$), referred to as $L^\\gamma$-PageRank, is proposed. Its theoretical study\nshows that it operates on signed graphs, where nodes belonging to one same\nclass are more likely to share positive edges while nodes from different\nclasses are more likely to be connected with negative edges. It is shown that\nby selecting an optimal $\\gamma$, classification performance can be\nsignificantly enhanced. A procedure for the automated estimation of the optimal\n$\\gamma$, from a unique observation of data, is devised and assessed.\nExperiments on several datasets demonstrate the effectiveness of both\n$L^\\gamma$-PageRank classification and the optimal $\\gamma$ estimation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:31:37 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Bautista", "Esteban", ""], ["Abry", "Patrice", ""], ["Gon\u00e7alves", "Paulo", ""]]}, {"id": "1903.06009", "submitter": "Issei Sato", "authors": "Issei Sato", "title": "On Learning from Ghost Imaging without Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational ghost imaging is an imaging technique in which an object is\nimaged from light collected using a single-pixel detector with no spatial\nresolution. Recently, ghost cytometry has been proposed for a high-speed\ncell-classification method that involves ghost imaging and machine learning in\nflow cytometry. Ghost cytometry skips the reconstruction of cell images from\nsignals and directly used signals for cell-classification because this\nreconstruction is what creates the bottleneck in the high-speed analysis. In\nthis paper, we provide theoretical analysis for learning from ghost imaging\nwithout imaging.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:04:51 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 01:09:45 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 02:32:27 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 13:59:59 GMT"}, {"version": "v5", "created": "Wed, 29 May 2019 14:55:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Sato", "Issei", ""]]}, {"id": "1903.06023", "submitter": "Rui Li", "authors": "Rui Li, Howard D. Bondell, Brian J. Reich", "title": "Deep Distribution Regression", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their flexibility and predictive performance, machine-learning based\nregression methods have become an important tool for predictive modeling and\nforecasting. However, most methods focus on estimating the conditional mean or\nspecific quantiles of the target quantity and do not provide the full\nconditional distribution, which contains uncertainty information that might be\ncrucial for decision making. In this article, we provide a general solution by\ntransforming a conditional distribution estimation problem into a constrained\nmulti-class classification problem, in which tools such as deep neural\nnetworks. We propose a novel joint binary cross-entropy loss function to\naccomplish this goal. We demonstrate its performance in various simulation\nstudies comparing to state-of-the-art competing methods. Additionally, our\nmethod shows improved accuracy in a probabilistic solar energy forecasting\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:19:39 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Li", "Rui", ""], ["Bondell", "Howard D.", ""], ["Reich", "Brian J.", ""]]}, {"id": "1903.06047", "submitter": "Matthew Gombolay", "authors": "Rohan Paleja and Matthew Gombolay", "title": "Inferring Personalized Bayesian Embeddings for Learning from\n  Heterogeneous Demonstration", "comments": "8 Pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For assistive robots and virtual agents to achieve ubiquity, machines will\nneed to anticipate the needs of their human counterparts. The field of Learning\nfrom Demonstration (LfD) has sought to enable machines to infer predictive\nmodels of human behavior for autonomous robot control. However, humans exhibit\nheterogeneity in decision-making, which traditional LfD approaches fail to\ncapture. To overcome this challenge, we propose a Bayesian LfD framework to\ninfer an integrated representation of all human task demonstrators by inferring\nhuman-specific embeddings, thereby distilling their unique characteristics. We\nvalidate our approach is able to outperform state-of-the-art techniques on both\nsynthetic and real-world data sets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:32:55 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Paleja", "Rohan", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1903.06048", "submitter": "Animesh Karnewar", "authors": "Animesh Karnewar, Oliver Wang", "title": "MSG-GAN: Multi-Scale Gradients for Generative Adversarial Networks", "comments": "CVPR 2020 (Main Conference). Work sponsored by TomTom and Adobe. Code\n  repository: https://github.com/akanimax/msg-stylegan-tf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Generative Adversarial Networks (GANs) have seen huge successes in\nimage synthesis tasks, they are notoriously difficult to adapt to different\ndatasets, in part due to instability during training and sensitivity to\nhyperparameters. One commonly accepted reason for this instability is that\ngradients passing from the discriminator to the generator become uninformative\nwhen there isn't enough overlap in the supports of the real and fake\ndistributions. In this work, we propose the Multi-Scale Gradient Generative\nAdversarial Network (MSG-GAN), a simple but effective technique for addressing\nthis by allowing the flow of gradients from the discriminator to the generator\nat multiple scales. This technique provides a stable approach for high\nresolution image synthesis, and serves as an alternative to the commonly used\nprogressive growing technique. We show that MSG-GAN converges stably on a\nvariety of image datasets of different sizes, resolutions and domains, as well\nas different types of loss functions and architectures, all with the same set\nof fixed hyperparameters. When compared to state-of-the-art GANs, our approach\nmatches or exceeds the performance in most of the cases we tried.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:33:26 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 19:48:01 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 10:47:55 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 20:45:26 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Karnewar", "Animesh", ""], ["Wang", "Oliver", ""]]}, {"id": "1903.06059", "submitter": "Wouter Kool", "authors": "Wouter Kool, Herke van Hoof, Max Welling", "title": "Stochastic Beams and Where to Find Them: The Gumbel-Top-k Trick for\n  Sampling Sequences Without Replacement", "comments": "ICML 2019 ; 13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known Gumbel-Max trick for sampling from a categorical distribution\ncan be extended to sample $k$ elements without replacement. We show how to\nimplicitly apply this 'Gumbel-Top-$k$' trick on a factorized distribution over\nsequences, allowing to draw exact samples without replacement using a\nStochastic Beam Search. Even for exponentially large domains, the number of\nmodel evaluations grows only linear in $k$ and the maximum sampled sequence\nlength. The algorithm creates a theoretical connection between sampling and\n(deterministic) beam search and can be used as a principled intermediate\nalternative. In a translation task, the proposed method compares favourably\nagainst alternatives to obtain diverse yet good quality translations. We show\nthat sequences sampled without replacement can be used to construct\nlow-variance estimators for expected sentence-level BLEU score and model\nentropy.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:56:06 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 20:05:01 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Kool", "Wouter", ""], ["van Hoof", "Herke", ""], ["Welling", "Max", ""]]}, {"id": "1903.06070", "submitter": "Soheil Kolouri", "authors": "Soheil Kolouri, Nicholas Ketz, Xinyun Zou, Jeffrey Krichmar, Praveen\n  Pilly", "title": "Attention-Based Structural-Plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting/interference is a critical problem for lifelong\nlearning machines, which impedes the agents from maintaining their previously\nlearned knowledge while learning new tasks. Neural networks, in particular,\nsuffer plenty from the catastrophic forgetting phenomenon. Recently there has\nbeen several efforts towards overcoming catastrophic forgetting in neural\nnetworks. Here, we propose a biologically inspired method toward overcoming\ncatastrophic forgetting. Specifically, we define an attention-based selective\nplasticity of synapses based on the cholinergic neuromodulatory system in the\nbrain. We define synaptic importance parameters in addition to synaptic weights\nand then use Hebbian learning in parallel with backpropagation algorithm to\nlearn synaptic importances in an online and seamless manner. We test our\nproposed method on benchmark tasks including the Permuted MNIST and the Split\nMNIST problems and show competitive performance compared to the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 22:23:35 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Kolouri", "Soheil", ""], ["Ketz", "Nicholas", ""], ["Zou", "Xinyun", ""], ["Krichmar", "Jeffrey", ""], ["Pilly", "Praveen", ""]]}, {"id": "1903.06133", "submitter": "Giuseppe G. Calvi", "authors": "Giuseppe G. Calvi, Ahmad Moniri, Mahmoud Mahfouz, Qibin Zhao, Danilo\n  P. Mandic", "title": "Compression and Interpretability of Deep Neural Networks via Tucker\n  Tensor Layer: From First Principles to Tensor Valued Back-Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to help resolve the two main stumbling blocks in the\napplication of Deep Neural Networks (DNNs), that is, the exceedingly large\nnumber of trainable parameters and their physical interpretability. This is\nachieved through a tensor valued approach, based on the proposed Tucker Tensor\nLayer (TTL), as an alternative to the dense weight-matrices of DNNs. This\nallows us to treat the weight-matrices of general DNNs as a matrix unfolding of\na higher order weight-tensor. By virtue of the compression properties of tensor\ndecompositions, this enables us to introduce a novel and efficient framework\nfor exploiting the multi-way nature of the weight-tensor in order to\ndramatically reduce the number of DNN parameters. We also derive the tensor\nvalued back-propagation algorithm within the TTL framework, by extending the\nnotion of matrix derivatives to tensors. In this way, the physical\ninterpretability of the Tucker decomposition is exploited to gain physical\ninsights into the NN training, through the process of computing gradients with\nrespect to each factor matrix. The proposed framework is validated on both\nsynthetic data, and the benchmark datasets MNIST, Fashion-MNIST, and CIFAR-10.\nOverall, through the ability to provide the relative importance of each data\nfeature in training, the TTL back-propagation is shown to help mitigate the\n\"black-box\" nature inherent to NNs. Experiments also illustrate that the TTL\nachieves a 66.63-fold compression on MNIST and Fashion-MNIST, while, by\nsimplifying the VGG-16 network, it achieves a 10\\% speed up in training time,\nat a comparable performance.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 17:19:38 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 10:41:42 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Calvi", "Giuseppe G.", ""], ["Moniri", "Ahmad", ""], ["Mahfouz", "Mahmoud", ""], ["Zhao", "Qibin", ""], ["Mandic", "Danilo P.", ""]]}, {"id": "1903.06135", "submitter": "Naveen Goela", "authors": "Payam Delgosha and Naveen Goela", "title": "Deep Switch Networks for Generating Discrete Data and Language", "comments": "To be presented at the AISTATS-2019 conference, 12 pages,\n  double-column", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayer switch networks are proposed as artificial generators of\nhigh-dimensional discrete data (e.g., binary vectors, categorical data, natural\nlanguage, network log files, and discrete-valued time series). Unlike\ndeconvolution networks which generate continuous-valued data and which consist\nof upsampling filters and reverse pooling layers, multilayer switch networks\nare composed of adaptive switches which model conditional distributions of\ndiscrete random variables. An interpretable, statistical framework is\nintroduced for training these nonlinear networks based on a maximum-likelihood\nobjective function. To learn network parameters, stochastic gradient descent is\napplied to the objective. This direct optimization is stable until convergence,\nand does not involve back-propagation over separate encoder and decoder\nnetworks, or adversarial training of dueling networks. While training remains\ntractable for moderately sized networks, Markov-chain Monte Carlo (MCMC)\napproximations of gradients are derived for deep networks which contain latent\nvariables. The statistical framework is evaluated on synthetic data,\nhigh-dimensional binary data of handwritten digits, and web-crawled natural\nlanguage data. Aspects of the model's framework such as interpretability,\ncomputational complexity, and generalization ability are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 17:28:44 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Delgosha", "Payam", ""], ["Goela", "Naveen", ""]]}, {"id": "1903.06151", "submitter": "Jan Scholten", "authors": "Jan Scholten, Daan Wout, Carlos Celemin and Jens Kober", "title": "Deep Reinforcement Learning with Feedback-based Exploration", "comments": "6 pages", "journal-ref": null, "doi": "10.1109/CDC40024.2019.9029503", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has enabled the control of increasingly complex\nand high-dimensional problems. However, the need of vast amounts of data before\nreasonable performance is attained prevents its widespread application. We\nemploy binary corrective feedback as a general and intuitive manner to\nincorporate human intuition and domain knowledge in model-free machine\nlearning. The uncertainty in the policy and the corrective feedback is combined\ndirectly in the action space as probabilistic conditional exploration. As a\nresult, the greatest part of the otherwise ignorant learning process can be\navoided. We demonstrate the proposed method, Predictive Probabilistic Merging\nof Policies (PPMP), in combination with DDPG. In experiments on continuous\ncontrol problems of the OpenAI Gym, we achieve drastic improvements in sample\nefficiency, final performance, and robustness to erroneous feedback, both for\nhuman and synthetic feedback. Additionally, we show solutions beyond the\ndemonstrated knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 17:52:46 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Scholten", "Jan", ""], ["Wout", "Daan", ""], ["Celemin", "Carlos", ""], ["Kober", "Jens", ""]]}, {"id": "1903.06164", "submitter": "Moonsu Han", "authors": "Moonsu Han, Minki Kang, Hyunwoo Jung, Sung Ju Hwang", "title": "Episodic Memory Reader: Learning What to Remember for Question Answering\n  from Streaming Data", "comments": "18 pages, 20 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel question answering (QA) task where the machine needs to\nread from large streaming data (long documents or videos) without knowing when\nthe questions will be given, which is difficult to solve with existing QA\nmethods due to their lack of scalability. To tackle this problem, we propose a\nnovel end-to-end deep network model for reading comprehension, which we refer\nto as Episodic Memory Reader (EMR) that sequentially reads the input contexts\ninto an external memory, while replacing memories that are less important for\nanswering \\emph{unseen} questions. Specifically, we train an RL agent to\nreplace a memory entry when the memory is full, in order to maximize its QA\naccuracy at a future timepoint, while encoding the external memory using either\nthe GRU or the Transformer architecture to learn representations that considers\nrelative importance between the memory entries. We validate our model on a\nsynthetic dataset (bAbI) as well as real-world large-scale textual QA\n(TriviaQA) and video QA (TVQA) datasets, on which it achieves significant\nimprovements over rule-based memory scheduling policies or an RL-based baseline\nthat independently learns the query-specific importance of each memory.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:00:56 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 07:46:25 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 06:58:01 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Han", "Moonsu", ""], ["Kang", "Minki", ""], ["Jung", "Hyunwoo", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1903.06187", "submitter": "Aditya Modi", "authors": "Aditya Modi, Ambuj Tewari", "title": "No-regret Exploration in Contextual Reinforcement Learning", "comments": "Accepted to UAI 2020. PMLR proceedings, volume 124", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the recently proposed reinforcement learning (RL) framework of\nContextual Markov Decision Processes (CMDP), where the agent interacts with a\n(potentially adversarial) sequence of episodic tabular MDPs. In addition, a\ncontext vector determining the MDP parameters is available to the agent at the\nstart of each episode, thereby allowing it to learn a context-dependent\nnear-optimal policy. In this paper, we propose a no-regret online RL algorithm\nin the setting where the MDP parameters are obtained from the context using\ngeneralized linear mappings (GLMs). We propose and analyze optimistic and\nrandomized exploration methods which make (time and space) efficient online\nupdates. The GLM based model subsumes previous work in this area and also\nimproves previous known bounds in the special case where the contextual mapping\nis linear. In addition, we demonstrate a generic template to derive confidence\nsets using an online learning oracle and give a lower bound for the setting.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 18:02:09 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 21:30:26 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 20:02:00 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Modi", "Aditya", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1903.06209", "submitter": "Carl Trimbach", "authors": "Carl Trimbach, Michael Littman", "title": "Teaching with IMPACT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like many problems in AI in their general form, supervised learning is\ncomputationally intractable. We hypothesize that an important reason humans can\nlearn highly complex and varied concepts, in spite of the computational\ndifficulty, is that they benefit tremendously from experienced and insightful\nteachers. This paper proposes a new learning framework that provides a role for\na knowledgeable, benevolent teacher to guide the process of learning a target\nconcept in a series of \"curricular\" phases or rounds. In each round, the\nteacher's role is to act as a moderator, exposing the learner to a subset of\nthe available training data to move it closer to mastering the target concept.\nVia both theoretical and empirical evidence, we argue that this framework\nenables simple, efficient learners to acquire very complex concepts from\nexamples. In particular, we provide multiple examples of concept classes that\nare known to be unlearnable in the standard PAC setting along with provably\nefficient algorithms for learning them in our extended setting. A key focus of\nour work is the ability to learn complex concepts on top of simpler, previously\nlearned, concepts---a direction with the potential of creating more competent\nartificial agents.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 18:30:11 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Trimbach", "Carl", ""], ["Littman", "Michael", ""]]}, {"id": "1903.06236", "submitter": "Vladimir Macko", "authors": "Vladimir Macko, Charles Weill, Hanna Mazzawi, Javier Gonzalvo", "title": "Improving Neural Architecture Search Image Classifiers via Ensemble\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the best neural network architecture requires significant time,\nresources, and human expertise. These challenges are partially addressed by\nneural architecture search (NAS) which is able to find the best convolutional\nlayer or cell that is then used as a building block for the network. However,\nonce a good building block is found, manual design is still required to\nassemble the final architecture as a combination of multiple blocks under a\npredefined parameter budget constraint. A common solution is to stack these\nblocks into a single tower and adjust the width and depth to fill the parameter\nbudget. However, these single tower architectures may not be optimal. Instead,\nin this paper we present the AdaNAS algorithm, that uses ensemble techniques to\ncompose a neural network as an ensemble of smaller networks automatically.\nAdditionally, we introduce a novel technique based on knowledge distillation to\niteratively train the smaller networks using the previous ensemble as a\nteacher. Our experiments demonstrate that ensembles of networks improve\naccuracy upon a single neural network while keeping the same number of\nparameters. Our models achieve comparable results with the state-of-the-art on\nCIFAR-10 and sets a new state-of-the-art on CIFAR-100.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 20:17:33 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Macko", "Vladimir", ""], ["Weill", "Charles", ""], ["Mazzawi", "Hanna", ""], ["Gonzalvo", "Javier", ""]]}, {"id": "1903.06237", "submitter": "Amir Gholami", "authors": "Linjian Ma and Gabe Montague and Jiayu Ye and Zhewei Yao and Amir\n  Gholami and Kurt Keutzer and Michael W. Mahoney", "title": "Inefficiency of K-FAC for Large Batch Size Training", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic optimization, using large batch sizes during training can\nleverage parallel resources to produce faster wall-clock training times per\ntraining epoch. However, for both training loss and testing error, recent\nresults analyzing large batch Stochastic Gradient Descent (SGD) have found\nsharp diminishing returns, beyond a certain critical batch size. In the hopes\nof addressing this, it has been suggested that the Kronecker-Factored\nApproximate Curvature (\\mbox{K-FAC}) method allows for greater scalability to\nlarge batch sizes, for non-convex machine learning problems such as neural\nnetwork optimization, as well as greater robustness to variation in model\nhyperparameters. Here, we perform a detailed empirical analysis of large batch\nsize training %of these two hypotheses, for both \\mbox{K-FAC} and SGD,\nevaluating performance in terms of both wall-clock time and aggregate\ncomputational cost. Our main results are twofold: first, we find that both\n\\mbox{K-FAC} and SGD doesn't have ideal scalability behavior beyond a certain\nbatch size, and that \\mbox{K-FAC} does not exhibit improved large-batch\nscalability behavior, as compared to SGD; and second, we find that\n\\mbox{K-FAC}, in addition to requiring more hyperparameters to tune, suffers\nfrom similar hyperparameter sensitivity behavior as does SGD. We discuss\nextensive results using ResNet and AlexNet on \\mbox{CIFAR-10} and SVHN,\nrespectively, as well as more general implications of our findings.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 20:21:35 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 21:59:03 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 19:28:00 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ma", "Linjian", ""], ["Montague", "Gabe", ""], ["Ye", "Jiayu", ""], ["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Keutzer", "Kurt", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1903.06249", "submitter": "Saeed Masoudnia", "authors": "Omid Mersa, Farhood Etaati, Saeed Masoudnia and Babak N. Araabi", "title": "Learning Representations from Persian Handwriting for Offline Signature\n  Verification, a Deep Transfer Learning Approach", "comments": null, "journal-ref": "2019 4th International Conference on Pattern Recognition and Image\n  Analysis (IPRIA)", "doi": "10.1109/PRIA.2019.8785979", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline Signature Verification (OSV) is a challenging pattern recognition\ntask, especially when it is expected to generalize well on the skilled\nforgeries that are not available during the training. Its challenges also\ninclude small training sample and large intra-class variations. Considering the\nlimitations, we suggest a novel transfer learning approach from Persian\nhandwriting domain to multi-language OSV domain. We train two Residual CNNs on\nthe source domain separately based on two different tasks of word\nclassification and writer identification. Since identifying a person signature\nresembles identifying ones handwriting, it seems perfectly convenient to use\nhandwriting for the feature learning phase. The learned representation on the\nmore varied and plentiful handwriting dataset can compensate for the lack of\ntraining data in the original task, i.e. OSV, without sacrificing the\ngeneralizability. Our proposed OSV system includes two steps: learning\nrepresentation and verification of the input signature. For the first step, the\nsignature images are fed into the trained Residual CNNs. The output\nrepresentations are then used to train SVMs for the verification. We test our\nOSV system on three different signature datasets, including MCYT (a Spanish\nsignature dataset), UTSig (a Persian one) and GPDS-Synthetic (an artificial\ndataset). On UT-SIG, we achieved 9.80% Equal Error Rate (EER) which showed\nsubstantial improvement over the best EER in the literature, 17.45%. Our\nproposed method surpassed state-of-the-arts by 6% on GPDS-Synthetic, achieving\n6.81%. On MCYT, EER of 3.98% was obtained which is comparable to the best\npreviously reported results.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 08:13:55 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Mersa", "Omid", ""], ["Etaati", "Farhood", ""], ["Masoudnia", "Saeed", ""], ["Araabi", "Babak N.", ""]]}, {"id": "1903.06255", "submitter": "Saeed Masoudnia", "authors": "Taraneh Younesian, Saeed Masoudnia, Reshad Hosseini, Babak N. Araabi", "title": "Active Transfer Learning for Persian Offline Signature Verification", "comments": null, "journal-ref": "2019 4th International Conference on Pattern Recognition and Image\n  Analysis (IPRIA)", "doi": "10.1109/PRIA.2019.8786013", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline Signature Verification (OSV) remains a challenging pattern\nrecognition task, especially in the presence of skilled forgeries that are not\navailable during the training. This challenge is aggravated when there are\nsmall labeled training data available but with large intra-personal variations.\nIn this study, we address this issue by employing an active learning approach,\nwhich selects the most informative instances to label and therefore reduces the\nhuman labeling effort significantly. Our proposed OSV includes three steps:\nfeature learning, active learning, and final verification. We benefit from\ntransfer learning using a pre-trained CNN for feature learning. We also propose\nSVM-based active learning for each user to separate his genuine signatures from\nthe random forgeries. We finally used the SVMs to verify the authenticity of\nthe questioned signature. We examined our proposed active transfer learning\nmethod on UTSig: A Persian offline signature dataset. We achieved near 13%\nimprovement compared to the random selection of instances. Our results also\nshowed 1% improvement over the state-of-the-art method in which a fully\nsupervised setting with five more labeled instances per user was used.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 13:49:46 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Younesian", "Taraneh", ""], ["Masoudnia", "Saeed", ""], ["Hosseini", "Reshad", ""], ["Araabi", "Babak N.", ""]]}, {"id": "1903.06256", "submitter": "Haohan Wang", "authors": "Haohan Wang, Zexue He, Zachary C. Lipton, Eric P. Xing", "title": "Learning Robust Representations by Projecting Superficial Statistics Out", "comments": "To appear at ICLR 2019. Implementation:\n  https://github.com/HaohanWang/HEX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite impressive performance as evaluated on i.i.d. holdout data, deep\nneural networks depend heavily on superficial statistics of the training data\nand are liable to break under distribution shift. For example, subtle changes\nto the background or texture of an image can break a seemingly powerful\nclassifier. Building on previous work on domain generalization, we hope to\nproduce a classifier that will generalize to previously unseen domains, even\nwhen domain identifiers are not available during training. This setting is\nchallenging because the model may extract many distribution-specific\n(superficial) signals together with distribution-agnostic (semantic) signals.\nTo overcome this challenge, we incorporate the gray-level co-occurrence matrix\n(GLCM) to extract patterns that our prior knowledge suggests are superficial:\nthey are sensitive to the texture but unable to capture the gestalt of an\nimage. Then we introduce two techniques for improving our networks'\nout-of-sample performance. The first method is built on the reverse gradient\nmethod that pushes our model to learn representations from which the GLCM\nrepresentation is not predictable. The second method is built on the\nindependence introduced by projecting the model's representation onto the\nsubspace orthogonal to GLCM representation's. We test our method on the battery\nof standard domain generalization data sets and, interestingly, achieve\ncomparable or better performance as compared to other domain generalization\nmethods that explicitly require samples from the target distribution for\ntraining.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 00:42:03 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Wang", "Haohan", ""], ["He", "Zexue", ""], ["Lipton", "Zachary C.", ""], ["Xing", "Eric P.", ""]]}, {"id": "1903.06258", "submitter": "Alan JiaXiang Guo", "authors": "Yi Liang, Xin Zhao, Alan J.X. Guo, and Fei Zhu", "title": "Hyperspectral Image Classification with Deep Metric Learning and\n  Conditional Random Field", "comments": null, "journal-ref": null, "doi": "10.1109/LGRS.2019.2939356", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the classification performance in the context of hyperspectral\nimage processing, many works have been developed based on two common\nstrategies, namely the spatial-spectral information integration and the\nutilization of neural networks. However, both strategies typically require more\ntraining data than the classical algorithms, aggregating the shortage of\nlabeled samples. In this letter, we propose a novel framework that organically\ncombines the spectrum-based deep metric learning model and the conditional\nrandom field algorithm. The deep metric learning model is supervised by the\ncenter loss to produce spectrum-based features that gather more tightly in\nEuclidean space within classes. The conditional random field with Gaussian edge\npotentials, which is firstly proposed for image segmentation tasks, is\nintroduced to give the pixel-wise classification over the hyperspectral image\nby utilizing both the geographical distances between pixels and the Euclidean\ndistances between the features produced by the deep metric learning model. The\nproposed framework is trained by spectral pixels at the deep metric learning\nstage and utilizes the half handcrafted spatial features at the conditional\nrandom field stage. This settlement alleviates the shortage of training data to\nsome extent. Experiments on two real hyperspectral images demonstrate the\nadvantages of the proposed method in terms of both classification accuracy and\ncomputation cost.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 09:26:03 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 02:30:41 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Liang", "Yi", ""], ["Zhao", "Xin", ""], ["Guo", "Alan J. X.", ""], ["Zhu", "Fei", ""]]}, {"id": "1903.06259", "submitter": "Adeel Mufti", "authors": "Adeel Mufti, Biagio Antonelli, Julius Monello", "title": "Conditional GANs For Painting Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We examined the use of modern Generative Adversarial Nets to generate novel\nimages of oil paintings using the Painter By Numbers dataset. We implemented\nSpectral Normalization GAN (SN-GAN) and Spectral Normalization GAN with\nGradient Penalty, and compared their outputs to a Deep Convolutional GAN.\nVisually, and quantitatively according to the Sliced Wasserstein Distance\nmetric, we determined that the SN-GAN produced paintings that were most\ncomparable to our training dataset. We then performed a series of experiments\nto add supervised conditioning to SN-GAN, the culmination of which is what we\nbelieve to be a novel architecture that can generate face paintings with\nuser-specified characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 19:47:56 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Mufti", "Adeel", ""], ["Antonelli", "Biagio", ""], ["Monello", "Julius", ""]]}, {"id": "1903.06260", "submitter": "Riddhish Bhalodia", "authors": "Tim Sodergren and Riddhish Bhalodia and Ross Whitaker and Joshua Cates\n  and Nassir Marrouche and Shireen Elhabian", "title": "Mixture Modeling of Global Shape Priors and Autoencoding Local Intensity\n  Priors for Left Atrium Segmentation", "comments": "Statistical Atlases and Computational Models of the Heart. Atrial\n  Segmentation and LV Quantification Challenges 2019", "journal-ref": "Statistical Atlases and Computational Models of the Heart. Atrial\n  Segmentation and LV Quantification Challenges, 2019, Springer International\n  Publishing, Cham 357--367,", "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Difficult image segmentation problems, for instance left atrium MRI, can be\naddressed by incorporating shape priors to find solutions that are consistent\nwith known objects. Nonetheless, a single multivariate Gaussian is not an\nadequate model in cases with significant nonlinear shape variation or where the\nprior distribution is multimodal. Nonparametric density estimation is more\ngeneral, but has a ravenous appetite for training samples and poses serious\nchallenges in optimization, especially in high dimensional spaces. Here, we\npropose a maximum-a-posteriori formulation that relies on a generative image\nmodel by incorporating both local intensity and global shape priors. We use\ndeep autoencoders to capture the complex intensity distribution while avoiding\nthe careful selection of hand-crafted features. We formulate the shape prior as\na mixture of Gaussians and learn the corresponding parameters in a\nhigh-dimensional shape space rather than pre-projecting onto a low-dimensional\nsubspace. In segmentation, we treat the identity of the mixture component as a\nlatent variable and marginalize it within a generalized\nexpectation-maximization framework. We present a conditional maximization-based\nscheme that alternates between a closed-form solution for component-specific\nshape parameters that provides a global update-based optimization strategy, and\nan intensity-based energy minimization that translates the global notion of a\nnonlinear shape prior into a set of local penalties. We demonstrate our\napproach on the left atrial segmentation from gadolinium-enhanced MRI, which is\nuseful in quantifying the atrial geometry in patients with atrial fibrillation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 23:24:08 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Sodergren", "Tim", ""], ["Bhalodia", "Riddhish", ""], ["Whitaker", "Ross", ""], ["Cates", "Joshua", ""], ["Marrouche", "Nassir", ""], ["Elhabian", "Shireen", ""]]}, {"id": "1903.06274", "submitter": "Thomais Asvestopoulou", "authors": "Thomais Asvestopoulou, Victoria Manousaki, Antonis Psistakis, Ioannis\n  Smyrnakis, Vassilios Andreadakis, Ioannis M. Aslanides, Maria Papadopouli", "title": "DysLexML: Screening Tool for Dyslexia Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye movements during text reading can provide insights about reading\ndisorders. Via eye-trackers, we can measure when, where and how eyes move with\nrelation to the words they read. Machine Learning (ML) algorithms can decode\nthis information and provide differential analysis. This work developed\nDysLexML, a screening tool for developmental dyslexia that applies various ML\nalgorithms to analyze fixation points recorded via eye-tracking during silent\nreading of children. It comparatively evaluated its performance using\nmeasurements collected in a systematic field study with 69 native Greek\nspeakers, children, 32 of which were diagnosed as dyslexic by the official\ngovernmental agency for diagnosing learning and reading difficulties in Greece.\nWe examined a large set of features based on statistical properties of\nfixations and saccadic movements and identified the ones with prominent\npredictive power, performing dimensionality reduction. Specifically, DysLexML\nachieves its best performance using linear SVM, with an a accuracy of 97 %,\nwith a small feature set, namely saccade length, number of short forward\nmovements, and number of multiply fixated words. Furthermore, we analyzed the\nimpact of noise on the fixation positions and showed that DysLexML is accurate\nand robust in the presence of noise. These encouraging results set the basis\nfor developing screening tools in less controlled, larger-scale environments,\nwith inexpensive eye-trackers, potentially reaching a larger population for\nearly intervention.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 21:44:52 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Asvestopoulou", "Thomais", ""], ["Manousaki", "Victoria", ""], ["Psistakis", "Antonis", ""], ["Smyrnakis", "Ioannis", ""], ["Andreadakis", "Vassilios", ""], ["Aslanides", "Ioannis M.", ""], ["Papadopouli", "Maria", ""]]}, {"id": "1903.06278", "submitter": "Risto Kojcev", "authors": "Nestor Gonzalez Lopez, Yue Leire Erro Nuin, Elias Barba Moral, Lander\n  Usategui San Juan, Alejandro Solano Rueda, V\\'ictor Mayoral Vilches and Risto\n  Kojcev", "title": "gym-gazebo2, a toolkit for reinforcement learning using ROS 2 and Gazebo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an upgraded, real world application oriented version of\ngym-gazebo, the Robot Operating System (ROS) and Gazebo based Reinforcement\nLearning (RL) toolkit, which complies with OpenAI Gym. The content discusses\nthe new ROS 2 based software architecture and summarizes the results obtained\nusing Proximal Policy Optimization (PPO). Ultimately, the output of this work\npresents a benchmarking system for robotics that allows different techniques\nand algorithms to be compared using the same virtual conditions. We have\nevaluated environments with different levels of complexity of the Modular\nArticulated Robotic Arm (MARA), reaching accuracies in the millimeter scale.\nThe converged results show the feasibility and usefulness of the gym-gazebo 2\ntoolkit, its potential and applicability in industrial use cases, using modular\nrobots.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 22:05:20 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 05:32:11 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Lopez", "Nestor Gonzalez", ""], ["Nuin", "Yue Leire Erro", ""], ["Moral", "Elias Barba", ""], ["Juan", "Lander Usategui San", ""], ["Rueda", "Alejandro Solano", ""], ["Vilches", "V\u00edctor Mayoral", ""], ["Kojcev", "Risto", ""]]}, {"id": "1903.06282", "submitter": "Risto Kojcev", "authors": "Yue Leire Erro Nuin, Nestor Gonzalez Lopez, Elias Barba Moral, Lander\n  Usategui San Juan, Alejandro Solano Rueda, V\\'ictor Mayoral Vilches and Risto\n  Kojcev", "title": "ROS2Learn: a reinforcement learning framework for ROS 2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for Deep Reinforcement Learning (DRL) in modular\nrobotics to train a robot directly from joint states, using traditional robotic\ntools. We use an state-of-the-art implementation of the Proximal Policy\nOptimization, Trust Region Policy Optimization and Actor-Critic\nKronecker-Factored Trust Region algorithms to learn policies in four different\nModular Articulated Robotic Arm (MARA) environments. We support this process\nusing a framework that communicates with typical tools used in robotics, such\nas Gazebo and Robot Operating System 2 (ROS 2). We evaluate several algorithms\nin modular robots with an empirical study in simulation.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 22:13:23 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 05:27:29 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Nuin", "Yue Leire Erro", ""], ["Lopez", "Nestor Gonzalez", ""], ["Moral", "Elias Barba", ""], ["Juan", "Lander Usategui San", ""], ["Rueda", "Alejandro Solano", ""], ["Vilches", "V\u00edctor Mayoral", ""], ["Kojcev", "Risto", ""]]}, {"id": "1903.06293", "submitter": "Ian Goodfellow", "authors": "Ian Goodfellow", "title": "A Research Agenda: Dynamic Models to Defend Against Correlated Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article I describe a research agenda for securing machine learning\nmodels against adversarial inputs at test time. This article does not present\nresults but instead shares some of my thoughts about where I think that the\nfield needs to go. Modern machine learning works very well on I.I.D. data: data\nfor which each example is drawn {\\em independently} and for which the\ndistribution generating each example is {\\em identical}. When these assumptions\nare relaxed, modern machine learning can perform very poorly. When machine\nlearning is used in contexts where security is a concern, it is desirable to\ndesign models that perform well even when the input is designed by a malicious\nadversary. So far most research in this direction has focused on an adversary\nwho violates the {\\em identical} assumption, and imposes some kind of\nrestricted worst-case distribution shift. I argue that machine learning\nsecurity researchers should also address the problem of relaxing the {\\em\nindependence} assumption and that current strategies designed for robustness to\ndistribution shift will not do so. I recommend {\\em dynamic models} that change\neach time they are run as a potential solution path to this problem, and show\nan example of a simple attack using correlated data that can be mitigated by a\nsimple dynamic defense. This is not intended as a real-world security measure,\nbut as a recommendation to explore this research direction and develop more\nrealistic defenses.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 23:07:48 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Goodfellow", "Ian", ""]]}, {"id": "1903.06333", "submitter": "David Burth Kurka", "authors": "David Burth Kurka, Deniz Gunduz", "title": "Successive Refinement of Images with Deep Joint Source-Channel Coding", "comments": "Accepted in IEEE SPAWC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce deep learning based communication methods for successive\nrefinement of images over wireless channels. We present three different\nstrategies for progressive image transmission with deep JSCC, with different\ncomplexity-performance trade-offs, all based on convolutional autoencoders.\nNumerical results show that deep JSCC not only provides graceful degradation\nwith channel signal-to-noise ratio (SNR) and improved performance in low SNR\nand low bandwidth regimes compared to state-of-the-art digital communication\ntechniques, but can also successfully learn a layered representation, achieving\nperformance close to a single-layer scheme. These results suggest that natural\nimages encoded with deep JSCC over Gaussian channels are almost successively\nrefinable.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 02:45:45 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 20:11:49 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Kurka", "David Burth", ""], ["Gunduz", "Deniz", ""]]}, {"id": "1903.06336", "submitter": "Yitong Li", "authors": "Yitong Li, Michael Murias, Samantha Major, Geraldine Dawson, David E.\n  Carlson", "title": "On Target Shift in Adversarial Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrepancy between training and testing domains is a fundamental problem in\nthe generalization of machine learning techniques. Recently, several approaches\nhave been proposed to learn domain invariant feature representations through\nadversarial deep learning. However, label shift, where the percentage of data\nin each class is different between domains, has received less attention. Label\nshift naturally arises in many contexts, especially in behavioral studies where\nthe behaviors are freely chosen. In this work, we propose a method called\nDomain Adversarial nets for Target Shift (DATS) to address label shift while\nlearning a domain invariant representation. This is accomplished by using\ndistribution matching to estimate label proportions in a blind test set. We\nextend this framework to handle multiple domains by developing a scheme to\nupweight source domains most similar to the target domain. Empirical results\nshow that this framework performs well under large label shift in synthetic and\nreal experiments, demonstrating the practical importance.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 02:48:32 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Li", "Yitong", ""], ["Murias", "Michael", ""], ["Major", "Samantha", ""], ["Dawson", "Geraldine", ""], ["Carlson", "David E.", ""]]}, {"id": "1903.06372", "submitter": "Ji Liu", "authors": "Wesley Suttle, Zhuoran Yang, Kaiqing Zhang, Zhaoran Wang, Tamer Basar,\n  Ji Liu", "title": "A Multi-Agent Off-Policy Actor-Critic Algorithm for Distributed\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends off-policy reinforcement learning to the multi-agent case\nin which a set of networked agents communicating with their neighbors according\nto a time-varying graph collaboratively evaluates and improves a target policy\nwhile following a distinct behavior policy. To this end, the paper develops a\nmulti-agent version of emphatic temporal difference learning for off-policy\npolicy evaluation, and proves convergence under linear function approximation.\nThe paper then leverages this result, in conjunction with a novel multi-agent\noff-policy policy gradient theorem and recent work in both multi-agent\non-policy and single-agent off-policy actor-critic methods, to develop and give\nconvergence guarantees for a new multi-agent off-policy actor-critic algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 05:44:12 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 00:41:14 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 21:46:13 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Suttle", "Wesley", ""], ["Yang", "Zhuoran", ""], ["Zhang", "Kaiqing", ""], ["Wang", "Zhaoran", ""], ["Basar", "Tamer", ""], ["Liu", "Ji", ""]]}, {"id": "1903.06396", "submitter": "Dimo Brockhoff", "authors": "Ouassim Elhara (RANDOPT), Konstantinos Varelas (RANDOPT), Duc Nguyen\n  (HNUE), Tea Tusar (IJS), Dimo Brockhoff (RANDOPT), Nikolaus Hansen (RANDOPT),\n  Anne Auger (RANDOPT)", "title": "COCO: The Large Scale Black-Box Optimization Benchmarking\n  (bbob-largescale) Test Suite", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bbob-largescale test suite, containing 24 single-objective functions in\ncontinuous domain, extends the well-known single-objective noiseless bbob test\nsuite, which has been used since 2009 in the BBOB workshop series, to large\ndimension. The core idea is to make the rotational transformations R, Q in\nsearch space that appear in the bbob test suite computationally cheaper while\nretaining some desired properties. This documentation presents an approach that\nreplaces a full rotational transformation with a combination of a\nblock-diagonal matrix and two permutation matrices in order to construct test\nfunctions whose computational and memory costs scale linearly in the dimension\nof the problem.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 07:47:05 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 15:24:13 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Elhara", "Ouassim", "", "RANDOPT"], ["Varelas", "Konstantinos", "", "RANDOPT"], ["Nguyen", "Duc", "", "HNUE"], ["Tusar", "Tea", "", "IJS"], ["Brockhoff", "Dimo", "", "RANDOPT"], ["Hansen", "Nikolaus", "", "RANDOPT"], ["Auger", "Anne", "", "RANDOPT"]]}, {"id": "1903.06412", "submitter": "Mikito Nanashima", "authors": "Mikito Nanashima", "title": "A Faster Algorithm Enumerating Relevant Features over Finite Fields", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of enumerating relevant features hidden in other\nirrelevant information for multi-labeled data, which is formalized as learning\njuntas.\n  A $k$-junta function is a function which depends on only $k$ coordinates of\nthe input. For relatively small $k$ w.r.t. the input size $n$, learning\n$k$-junta functions is one of fundamental problems both theoretically and\npractically in machine learning. For the last two decades, much effort has been\nmade to design efficient learning algorithms for Boolean junta functions, and\nsome novel techniques have been developed. However, in real world,\nmulti-labeled data seem to be obtained in much more often than binary-labeled\none. Thus, it is a natural question whether these techniques can be applied to\nmore general cases about the alphabet size.\n  In this paper, we expand the Fourier detection techniques for the binary\nalphabet to any finite field $\\mathbb{F}_q$, and give, roughly speaking, an\n$O(n^{0.8k})$-time learning algorithm for $k$-juntas over $\\mathbb{F}_q$. Note\nthat our algorithm is the first non-trivial (i.e., non-brute force) algorithm\nfor such a class even in the case where $q=3$ and we give an affirmative answer\nto the question posed by Mossel et al.\n  Our algorithm consists of two reductions: (1) from learning juntas to LDME\nwhich is a variant of the learning with errors (LWE) problems introduced by\nRegev, and (2) from LDME to the light bulb problem (LBP) introduced by\nL.Valiant. Since the reduced problem (i.e., LBP) is a kind of binary problem\nregardless of the alphabet size of the original problem (i.e., learning\njuntas), we can directly apply the techniques for the binary case in the\nprevious work.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 08:51:51 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 14:38:10 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Nanashima", "Mikito", ""]]}, {"id": "1903.06464", "submitter": "Chanwoo Jeong", "authors": "Chanwoo Jeong, Sion Jang, Hyuna Shin, Eunjeong Park, Sungchul Choi", "title": "A Context-Aware Citation Recommendation Model with BERT and Graph\n  Convolutional Networks", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the tremendous growth in the number of scientific papers being\npublished, searching for references while writing a scientific paper is a\ntime-consuming process. A technique that could add a reference citation at the\nappropriate place in a sentence will be beneficial. In this perspective,\ncontext-aware citation recommendation has been researched upon for around two\ndecades. Many researchers have utilized the text data called the context\nsentence, which surrounds the citation tag, and the metadata of the target\npaper to find the appropriate cited research. However, the lack of\nwell-organized benchmarking datasets and no model that can attain high\nperformance has made the research difficult.\n  In this paper, we propose a deep learning based model and well-organized\ndataset for context-aware paper citation recommendation. Our model comprises a\ndocument encoder and a context encoder, which uses Graph Convolutional Networks\n(GCN) layer and Bidirectional Encoder Representations from Transformers (BERT),\nwhich is a pre-trained model of textual data. By modifying the related PeerRead\ndataset, we propose a new dataset called FullTextPeerRead containing context\nsentences to cited references and paper metadata. To the best of our knowledge,\nThis dataset is the first well-organized dataset for context-aware paper\nrecommendation. The results indicate that the proposed model with the proposed\ndatasets can attain state-of-the-art performance and achieve a more than 28%\nimprovement in mean average precision (MAP) and recall@k.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 11:13:22 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Jeong", "Chanwoo", ""], ["Jang", "Sion", ""], ["Shin", "Hyuna", ""], ["Park", "Eunjeong", ""], ["Choi", "Sungchul", ""]]}, {"id": "1903.06478", "submitter": "Sang Il Lee", "authors": "Sang Il Lee and Seong Joon Yoo", "title": "Multimodal Deep Learning for Finance: Integrating and Forecasting\n  International Stock Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's increasingly international economy, return and volatility\nspillover effects across international equity markets are major macroeconomic\ndrivers of stock dynamics. Thus, information regarding foreign markets is one\nof the most important factors in forecasting domestic stock prices. However,\nthe cross-correlation between domestic and foreign markets is highly complex.\nHence, it is extremely difficult to explicitly express this cross-correlation\nwith a dynamical equation. In this study, we develop stock return prediction\nmodels that can jointly consider international markets, using multimodal deep\nlearning. Our contributions are three-fold: (1) we visualize the transfer\ninformation between South Korea and US stock markets by using scatter plots;\n(2) we incorporate the information into the stock prediction models with the\nhelp of multimodal deep learning; (3) we conclusively demonstrate that the\nearly and intermediate fusion models achieve a significant performance boost in\ncomparison with the late fusion and single modality models. Our study indicates\nthat jointly considering international stock markets can improve the prediction\naccuracy and deep neural networks are highly effective for such tasks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 11:52:17 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 12:34:56 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Lee", "Sang Il", ""], ["Yoo", "Seong Joon", ""]]}, {"id": "1903.06482", "submitter": "Shuaifeng Zhi", "authors": "Shuaifeng Zhi, Michael Bloesch, Stefan Leutenegger, Andrew J. Davison", "title": "SceneCode: Monocular Dense Semantic Reconstruction using Learned Encoded\n  Scene Representations", "comments": "To be published in Proceedings of the IEEE Conference on Computer\n  Vision and Pattern Recognition (CVPR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems which incrementally create 3D semantic maps from image sequences must\nstore and update representations of both geometry and semantic entities.\nHowever, while there has been much work on the correct formulation for\ngeometrical estimation, state-of-the-art systems usually rely on simple\nsemantic representations which store and update independent label estimates for\neach surface element (depth pixels, surfels, or voxels). Spatial correlation is\ndiscarded, and fused label maps are incoherent and noisy.\n  We introduce a new compact and optimisable semantic representation by\ntraining a variational auto-encoder that is conditioned on a colour image.\nUsing this learned latent space, we can tackle semantic label fusion by jointly\noptimising the low-dimenional codes associated with each of a set of\noverlapping images, producing consistent fused label maps which preserve\nspatial correlation. We also show how this approach can be used within a\nmonocular keyframe based semantic mapping system where a similar code approach\nis used for geometry. The probabilistic formulation allows a flexible\nformulation where we can jointly estimate motion, geometry and semantics in a\nunified optimisation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 12:02:44 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 16:55:47 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Zhi", "Shuaifeng", ""], ["Bloesch", "Michael", ""], ["Leutenegger", "Stefan", ""], ["Davison", "Andrew J.", ""]]}, {"id": "1903.06496", "submitter": "Valentin Vielzeuf", "authors": "Juan-Manuel P\\'erez-R\\'ua, Valentin Vielzeuf, St\\'ephane Pateux, Moez\n  Baccouche, Fr\\'ed\\'eric Jurie", "title": "MFAS: Multimodal Fusion Architecture Search", "comments": "CVPR 2019, Jun 2019, Long Beach, United States\n  http://cvpr2019.thecvf.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of finding good architectures for multimodal\nclassification problems. We propose a novel and generic search space that spans\na large number of possible fusion architectures. In order to find an optimal\narchitecture for a given dataset in the proposed search space, we leverage an\nefficient sequential model-based exploration approach that is tailored for the\nproblem. We demonstrate the value of posing multimodal fusion as a neural\narchitecture search problem by extensive experimentation on a toy dataset and\ntwo other real multimodal datasets. We discover fusion architectures that\nexhibit state-of-the-art performance for problems with different domain and\ndataset size, including the NTU RGB+D dataset, the largest multi-modal action\nrecognition dataset available.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 12:45:13 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["P\u00e9rez-R\u00faa", "Juan-Manuel", ""], ["Vielzeuf", "Valentin", ""], ["Pateux", "St\u00e9phane", ""], ["Baccouche", "Moez", ""], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1903.06498", "submitter": "Tim Zerrell", "authors": "Tim Zerrell and Jeremy Bruestle", "title": "Stripe: Tensor Compilation via the Nested Polyhedral Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware architectures and machine learning (ML) libraries evolve rapidly.\nTraditional compilers often fail to generate high-performance code across the\nspectrum of new hardware offerings. To mitigate, engineers develop hand-tuned\nkernels for each ML library update and hardware upgrade. Unfortunately, this\napproach requires excessive engineering effort to scale or maintain with any\ndegree of state-of-the-art performance. Here we present a Nested Polyhedral\nModel for representing highly parallelizable computations with limited\ndependencies between iterations. This model provides an underlying framework\nfor an intermediate representation (IR) called Stripe, amenable to standard\ncompiler techniques while naturally modeling key aspects of modern ML\ncomputing. Stripe represents parallelism, efficient memory layout, and multiple\ncompute units at a level of abstraction amenable to automatic optimization. We\ndescribe how Stripe enables a compiler for ML in the style of LLVM that allows\nindependent development of algorithms, optimizations, and hardware\naccelerators. We also discuss the design exploration advantages of Stripe over\nkernel libraries and schedule-based or schedule-space-based code generation.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 17:49:48 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Zerrell", "Tim", ""], ["Bruestle", "Jeremy", ""]]}, {"id": "1903.06500", "submitter": "Rui Xia", "authors": "Rui Xia, Vincent Y. F. Tan, Louis Filstroff, C\\'edric F\\'evotte", "title": "A Ranking Model Motivated by Nonnegative Matrix Factorization with\n  Applications to Tennis Tournaments", "comments": "16 pages, 2 figures, 9 tables. Accepted and to be presented at the\n  European Conference on Machine Learning and Principles and Practice of\n  Knowledge Discovery in Databases (ECML/PKDD) 2019. Supplementary material,\n  code and datasets can be found in this URL\n  https://github.com/XiaRui1996/btl-nmf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel ranking model that combines the Bradley-Terry-Luce\nprobability model with a nonnegative matrix factorization framework to model\nand uncover the presence of latent variables that influence the performance of\ntop tennis players. We derive an efficient, provably convergent, and\nnumerically stable majorization-minimization-based algorithm to maximize the\nlikelihood of datasets under the proposed statistical model. The model is\ntested on datasets involving the outcomes of matches between 20 top male and\nfemale tennis players over 14 major tournaments for men (including the Grand\nSlams and the ATP Masters 1000) and 16 major tournaments for women over the\npast 10 years. Our model automatically infers that the surface of the court\n(e.g., clay or hard court) is a key determinant of the performances of male\nplayers, but less so for females. Top players on various surfaces over this\nlongitudinal period are also identified in an objective manner.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 12:48:33 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 03:56:27 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Xia", "Rui", ""], ["Tan", "Vincent Y. F.", ""], ["Filstroff", "Louis", ""], ["F\u00e9votte", "C\u00e9dric", ""]]}, {"id": "1903.06529", "submitter": "Nicolas Girard", "authors": "Nicolas Girard (UCA, TITANE), Guillaume Charpiat (TAU), Yuliya\n  Tarabalka (UCA, TITANE)", "title": "Noisy Supervision for Correcting Misaligned Cadaster Maps Without\n  Perfect Ground Truth Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning the best performance on a certain task is achieved by\nfully supervised methods when perfect ground truth labels are available.\nHowever, labels are often noisy, especially in remote sensing where manually\ncurated public datasets are rare. We study the multi-modal cadaster map\nalignment problem for which available annotations are mis-aligned polygons,\nresulting in noisy supervision. We subsequently set up a multiple-rounds\ntraining scheme which corrects the ground truth annotations at each round to\nbetter train the model at the next round. We show that it is possible to reduce\nthe noise of the dataset by iteratively training a better alignment model to\ncorrect the annotation alignment.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 14:38:39 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Girard", "Nicolas", "", "UCA, TITANE"], ["Charpiat", "Guillaume", "", "TAU"], ["Tarabalka", "Yuliya", "", "UCA, TITANE"]]}, {"id": "1903.06530", "submitter": "Seijoon Kim", "authors": "Seijoon Kim, Seongsik Park, Byunggook Na, Sungroh Yoon", "title": "Spiking-YOLO: Spiking Neural Network for Energy-Efficient Object\n  Detection", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, deep neural networks (DNNs) have demonstrated\nremarkable performance in a variety of applications. As we try to solve more\nadvanced problems, increasing demands for computing and power resources has\nbecome inevitable. Spiking neural networks (SNNs) have attracted widespread\ninterest as the third-generation of neural networks due to their event-driven\nand low-powered nature. SNNs, however, are difficult to train, mainly owing to\ntheir complex dynamics of neurons and non-differentiable spike operations.\nFurthermore, their applications have been limited to relatively simple tasks\nsuch as image classification. In this study, we investigate the performance\ndegradation of SNNs in a more challenging regression problem (i.e., object\ndetection). Through our in-depth analysis, we introduce two novel methods:\nchannel-wise normalization and signed neuron with imbalanced threshold, both of\nwhich provide fast and accurate information transmission for deep SNNs.\nConsequently, we present a first spiked-based object detection model, called\nSpiking-YOLO. Our experiments show that Spiking-YOLO achieves remarkable\nresults that are comparable (up to 98%) to those of Tiny YOLO on non-trivial\ndatasets, PASCAL VOC and MS COCO. Furthermore, Spiking-YOLO on a neuromorphic\nchip consumes approximately 280 times less energy than Tiny YOLO and converges\n2.3 to 4 times faster than previous SNN conversion methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 08:34:47 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 16:00:31 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Kim", "Seijoon", ""], ["Park", "Seongsik", ""], ["Na", "Byunggook", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1903.06536", "submitter": "Saeed Masoudnia", "authors": "Saeed Masoudnia, Omid Mersa, Babak N. Araabi, Abdol-Hossein Vahabie,\n  Mohammad Amin Sadeghi, and Majid Nili Ahmadabadi", "title": "Multi-Representational Learning for Offline Signature Verification using\n  Multi-Loss Snapshot Ensemble of CNNs", "comments": null, "journal-ref": "Expert Systems with Applications, 2019, 133, 317-330", "doi": "10.1016/j.eswa.2019.03.040", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline Signature Verification (OSV) is a challenging pattern recognition\ntask, especially in presence of skilled forgeries that are not available during\ntraining. This study aims to tackle its challenges and meet the substantial\nneed for generalization for OSV by examining different loss functions for\nConvolutional Neural Network (CNN). We adopt our new approach to OSV by asking\ntwo questions: 1. which classification loss provides more generalization for\nfeature learning in OSV? , and 2. How integration of different losses into a\nunified multi-loss function lead to an improved learning framework? These\nquestions are studied based on analysis of three loss functions, including\ncross entropy, Cauchy-Schwarz divergence, and hinge loss. According to\ncomplementary features of these losses, we combine them into a dynamic\nmulti-loss function and propose a novel ensemble framework for simultaneous use\nof them in CNN. Our proposed Multi-Loss Snapshot Ensemble (MLSE) consists of\nseveral sequential trials. In each trial, a dominant loss function is selected\nfrom the multi-loss set, and the remaining losses act as a regularizer.\nDifferent trials learn diverse representations for each input based on\nsignature identification task. This multi-representation set is then employed\nfor the verification task. An ensemble of SVMs is trained on these\nrepresentations, and their decisions are finally combined according to the\nselection of most generalizable SVM for each user. We conducted two sets of\nexperiments based on two different protocols of OSV, i.e., writer-dependent and\nwriter-independent on three signature datasets: GPDS-Synthetic, MCYT, and\nUT-SIG. Based on the writer-dependent OSV protocol, we achieved substantial\nimprovements over the best EERs in the literature. The results of the second\nset of experiments also confirmed the robustness to the arrival of new users\nenrolled in the OSV system.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 14:11:21 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Masoudnia", "Saeed", ""], ["Mersa", "Omid", ""], ["Araabi", "Babak N.", ""], ["Vahabie", "Abdol-Hossein", ""], ["Sadeghi", "Mohammad Amin", ""], ["Ahmadabadi", "Majid Nili", ""]]}, {"id": "1903.06538", "submitter": "Paresh Malalur", "authors": "Paresh Malalur and Tommi Jaakkola", "title": "Alignment Based Matching Networks for One-Shot Classification and\n  Open-Set Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning for object classification relies heavily on convolutional\nmodels. While effective, CNNs are rarely interpretable after the fact. An\nattention mechanism can be used to highlight the area of the image that the\nmodel focuses on thus offering a narrow view into the mechanism of\nclassification. We expand on this idea by forcing the method to explicitly\nalign images to be classified to reference images representing the classes. The\nmechanism of alignment is learned and therefore does not require that the\nreference objects are anything like those being classified. Beyond explanation,\nour exemplar based cross-alignment method enables classification with only a\nsingle example per category (one-shot). Our model cuts the 5-way, 1-shot error\nrate in Omniglot from 2.1% to 1.4% and in MiniImageNet from 53.5% to 46.5%\nwhile simultaneously providing point-wise alignment information providing some\nunderstanding on what the network is capturing. This method of alignment also\nenables the recognition of an unsupported class (open-set) in the one-shot\nsetting while maintaining an F1-score of above 0.5 for Omniglot even with 19\nother distracting classes while baselines completely fail to separate the\nopen-set class in the one-shot setting.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 02:50:27 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Malalur", "Paresh", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1903.06542", "submitter": "Satyananda Kashyap", "authors": "Alexandros Karargyris, Satyananda Kashyap, Joy T Wu, Arjun Sharma,\n  Mehdi Moradi, Tanveer Syeda-Mahmood", "title": "Age prediction using a large chest X-ray dataset", "comments": "Presented at SPIE Medical Imaging Conference, San Diego, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Age prediction based on appearances of different anatomies in medical images\nhas been clinically explored for many decades. In this paper, we used deep\nlearning to predict a persons age on Chest X-Rays. Specifically, we trained a\nCNN in regression fashion on a large publicly available dataset. Moreover, for\ninterpretability, we explored activation maps to identify which areas of a CXR\nimage are important for the machine (i.e. CNN) to predict a patients age,\noffering insight. Overall, amongst correctly predicted CXRs, we see areas near\nthe clavicles, shoulders, spine, and mediastinum being most activated for age\nprediction, as one would expect biologically. Amongst incorrectly predicted\nCXRs, we have qualitatively identified disease patterns that could possibly\nmake the anatomies appear older or younger than expected. A further technical\nand clinical evaluation would improve this work. As CXR is the most commonly\nrequested imaging exam, a potential use case for estimating age may be found in\nthe preventative counseling of patient health status compared to their\nage-expected average, particularly when there is a large discrepancy between\npredicted age and the real patient age.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 00:12:42 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Karargyris", "Alexandros", ""], ["Kashyap", "Satyananda", ""], ["Wu", "Joy T", ""], ["Sharma", "Arjun", ""], ["Moradi", "Mehdi", ""], ["Syeda-Mahmood", "Tanveer", ""]]}, {"id": "1903.06548", "submitter": "Philip Sellars", "authors": "Philip Sellars, Angelica Aviles-Rivero, and Carola-Bibiane Sch\\\"onlieb", "title": "Superpixel Contracted Graph-Based Learning for Hyperspectral Image\n  Classification", "comments": "11 pages", "journal-ref": null, "doi": "10.1109/TGRS.2019.2961599", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in hyperspectral image classification is obtaining high\nclassification accuracy when using a limited amount of labelled data. In this\npaper we present a novel graph-based framework, which aims to tackle this\nproblem in the presence of large scale data input. Our approach utilises a\nnovel superpixel method, specifically designed for hyperspectral data, to\ndefine meaningful local regions in an image, which with high probability share\nthe same classification label. We then extract spectral and spatial features\nfrom these regions and use these to produce a contracted weighted\ngraph-representation, where each node represents a region rather than a pixel.\nOur graph is then fed into a graph-based semi-supervised classifier which gives\nthe final classification. We show that using superpixels in a graph\nrepresentation is an effective tool for speeding up graphical classifiers\napplied to hyperspectral images. We demonstrate through exhaustive quantitative\nand qualitative results that our proposed method produces accurate\nclassifications when an incredibly small amount of labelled data is used. We\nshow that our approach mitigates the major drawbacks of existing approaches,\nresulting in our approach outperforming several comparative state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 13:23:43 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 09:22:46 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 15:11:25 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Sellars", "Philip", ""], ["Aviles-Rivero", "Angelica", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "1903.06549", "submitter": "Naoya Sogi", "authors": "Naoya Sogi, Rui Zhu, Jing-Hao Xue, Kazuhiro Fukui", "title": "Constrained Mutual Convex Cone Method for Image Set Based Recognition", "comments": "arXiv admin note: substantial text overlap with arXiv:1805.12467", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method for image-set classification based on\nconvex cone models. Image set classification aims to classify a set of images,\nwhich were usually obtained from video frames or multi-view cameras, into a\ntarget object. To accurately and stably classify a set, it is essential to\nrepresent structural information of the set accurately. There are various\nrepresentative image features, such as histogram based features, HLAC, and\nConvolutional Neural Network (CNN) features. We should note that most of them\nhave non-negativity and thus can be effectively represented by a convex cone.\nThis leads us to introduce the convex cone representation to image-set\nclassification. To establish a convex cone based framework, we mathematically\ndefine multiple angles between two convex cones, and then define the geometric\nsimilarity between the cones using the angles. Moreover, to enhance the\nframework, we introduce a discriminant space that maximizes the between-class\nvariance (gaps) and minimizes the within-class variance of the projected convex\ncones onto the discriminant space, similar to the Fisher discriminant analysis.\nFinally, the classification is performed based on the similarity between\nprojected convex cones. The effectiveness of the proposed method is\ndemonstrated experimentally by using five databases: CMU PIE dataset, ETH-80,\nCMU Motion of Body dataset, Youtube Celebrity dataset, and a private database\nof multi-view hand shapes.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 07:14:34 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Sogi", "Naoya", ""], ["Zhu", "Rui", ""], ["Xue", "Jing-Hao", ""], ["Fukui", "Kazuhiro", ""]]}, {"id": "1903.06576", "submitter": "Arnak Dalalyan S.", "authors": "Victor-Emmanuel Brunel, Arnak S. Dalalyan, Nicolas Schreuder", "title": "A nonasymptotic law of iterated logarithm for general M-estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  M-estimators are ubiquitous in machine learning and statistical learning\ntheory. They are used both for defining prediction strategies and for\nevaluating their precision. In this paper, we propose the first non-asymptotic\n\"any-time\" deviation bounds for general M-estimators, where \"any-time\" means\nthat the bound holds with a prescribed probability for every sample size. These\nbounds are nonasymptotic versions of the law of iterated logarithm. They are\nestablished under general assumptions such as Lipschitz continuity of the loss\nfunction and (local) curvature of the population risk. These conditions are\nsatisfied for most examples used in machine learning, including those ensuring\nrobustness to outliers and to heavy tailed distributions. As an example of\napplication, we consider the problem of best arm identification in a parametric\nstochastic multi-arm bandit setting. We show that the established bound can be\nconverted into a new algorithm, with provably optimal theoretical guarantees.\nNumerical experiments illustrating the validity of the algorithm are reported.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 14:37:31 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 12:14:03 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Brunel", "Victor-Emmanuel", ""], ["Dalalyan", "Arnak S.", ""], ["Schreuder", "Nicolas", ""]]}, {"id": "1903.06580", "submitter": "Rogelio Andrade Mancisidor", "authors": "Rogelio A Mancisidor, Michael Kampffmeyer, Kjersti Aas, Robert Jenssen", "title": "Learning Latent Representations of Bank Customers With The Variational\n  Autoencoder", "comments": "arXiv admin note: substantial text overlap with arXiv:1806.02538", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning data representations that reflect the customers' creditworthiness\ncan improve marketing campaigns, customer relationship management, data and\nprocess management or the credit risk assessment in retail banks. In this\nresearch, we adopt the Variational Autoencoder (VAE), which has the ability to\nlearn latent representations that contain useful information. We show that it\nis possible to steer the latent representations in the latent space of the VAE\nusing the Weight of Evidence and forming a specific grouping of the data that\nreflects the customers' creditworthiness. Our proposed method learns a latent\nrepresentation of the data, which shows a well-defied clustering structure\ncapturing the customers' creditworthiness. These clusters are well suited for\nthe aforementioned banks' activities. Further, our methodology generalizes to\nnew customers, captures high-dimensional and complex financial data, and scales\nto large data sets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 17:09:47 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Mancisidor", "Rogelio A", ""], ["Kampffmeyer", "Michael", ""], ["Aas", "Kjersti", ""], ["Jenssen", "Robert", ""]]}, {"id": "1903.06581", "submitter": "Duo Wang", "authors": "Duo Wang, Mateja Jamnik, Pietro Lio", "title": "Unsupervised and interpretable scene discovery with\n  Discrete-Attend-Infer-Repeat", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present Discrete Attend Infer Repeat (Discrete-AIR), a\nRecurrent Auto-Encoder with structured latent distributions containing discrete\ncategorical distributions, continuous attribute distributions, and factorised\nspatial attention. While inspired by the original AIR model andretaining AIR\nmodel's capability in identifying objects in an image, Discrete-AIR provides\ndirect interpretability of the latent codes. We show that for Multi-MNIST and a\nmultiple-objects version of dSprites dataset, the Discrete-AIR model needs just\none categorical latent variable, one attribute variable (for Multi-MNIST only),\ntogether with spatial attention variables, for efficient inference. We perform\nanalysis to show that the learnt categorical distributions effectively capture\nthe categories of objects in the scene for Multi-MNIST and for Multi-Sprites.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 16:30:27 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Wang", "Duo", ""], ["Jamnik", "Mateja", ""], ["Lio", "Pietro", ""]]}, {"id": "1903.06592", "submitter": "Samir Wadhwania", "authors": "Samir Wadhwania, Dong-Ki Kim, Shayegan Omidshafiei, and Jonathan P.\n  How", "title": "Policy Distillation and Value Matching in Multiagent Reinforcement\n  Learning", "comments": "Submitted as a conference paper to IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent reinforcement learning algorithms (MARL) have been demonstrated on\ncomplex tasks that require the coordination of a team of multiple agents to\ncomplete. Existing works have focused on sharing information between agents via\ncentralized critics to stabilize learning or through communication to increase\nperformance, but do not generally look at how information can be shared between\nagents to address the curse of dimensionality in MARL. We posit that a\nmultiagent problem can be decomposed into a multi-task problem where each agent\nexplores a subset of the state space instead of exploring the entire state\nspace. This paper introduces a multiagent actor-critic algorithm and method for\ncombining knowledge from homogeneous agents through distillation and\nvalue-matching that outperforms policy distillation alone and allows further\nlearning in both discrete and continuous action spaces.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 15:13:02 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Wadhwania", "Samir", ""], ["Kim", "Dong-Ki", ""], ["Omidshafiei", "Shayegan", ""], ["How", "Jonathan P.", ""]]}, {"id": "1903.06602", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Deep Neural Network Ensembles for Time Series Classification", "comments": "Accepted at IJCNN 2019", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852316", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have revolutionized many fields such as computer vision\nand natural language processing. Inspired by this recent success, deep learning\nstarted to show promising results for Time Series Classification (TSC).\nHowever, neural networks are still behind the state-of-the-art TSC algorithms,\nthat are currently composed of ensembles of 37 non deep learning based\nclassifiers. We attribute this gap in performance due to the lack of neural\nnetwork ensembles for TSC. Therefore in this paper, we show how an ensemble of\n60 deep learning models can significantly improve upon the current\nstate-of-the-art performance of neural networks for TSC, when evaluated over\nthe UCR/UEA archive: the largest publicly available benchmark for time series\nanalysis. Finally, we show how our proposed Neural Network Ensemble (NNE) is\nthe first time series classifier to outperform COTE while reaching similar\nperformance to the current state-of-the-art ensemble HIVE-COTE.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 15:32:43 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 12:17:07 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1903.06603", "submitter": "Chen Liu", "authors": "Chen Liu, Ryota Tomioka, Volkan Cevher", "title": "On Certifying Non-uniform Bound against Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the robustness certification problem of neural network\nmodels, which aims to find certified adversary-free regions as large as\npossible around data points. In contrast to the existing approaches that seek\nregions bounded uniformly along all input features, we consider non-uniform\nbounds and use it to study the decision boundary of neural network models. We\nformulate our target as an optimization problem with nonlinear constraints.\nThen, a framework applicable for general feedforward neural networks is\nproposed to bound the output logits so that the relaxed problem can be solved\nby the augmented Lagrangian method. Our experiments show the non-uniform bounds\nhave larger volumes than uniform ones and the geometric similarity of the\nnon-uniform bounds gives a quantitative, data-agnostic metric of input\nfeatures' robustness. Further, compared with normal models, the robust models\nhave even larger non-uniform bounds and better interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 15:33:44 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 22:32:54 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 11:17:43 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Liu", "Chen", ""], ["Tomioka", "Ryota", ""], ["Cevher", "Volkan", ""]]}, {"id": "1903.06631", "submitter": "Junzhe Zhang Mr", "authors": "Junzhe Zhang, Sai Ho Yeung, Yao Shu, Bingsheng He, Wei Wang", "title": "Efficient Memory Management for GPU-based Deep Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPU (graphics processing unit) has been used for many data-intensive\napplications. Among them, deep learning systems are one of the most important\nconsumer systems for GPU nowadays. As deep learning applications impose deeper\nand larger models in order to achieve higher accuracy, memory management\nbecomes an important research topic for deep learning systems, given that GPU\nhas limited memory size. Many approaches have been proposed towards this issue,\ne.g., model compression and memory swapping. However, they either degrade the\nmodel accuracy or require a lot of manual intervention. In this paper, we\npropose two orthogonal approaches to reduce the memory cost from the system\nperspective. Our approaches are transparent to the models, and thus do not\naffect the model accuracy. They are achieved by exploiting the iterative nature\nof the training algorithm of deep learning to derive the lifetime and\nread/write order of all variables. With the lifetime semantics, we are able to\nimplement a memory pool with minimal fragments. However, the optimization\nproblem is NP-complete. We propose a heuristic algorithm that reduces up to\n13.3% of memory compared with Nvidia's default memory pool with equal time\ncomplexity. With the read/write semantics, the variables that are not in use\ncan be swapped out from GPU to CPU to reduce the memory footprint. We propose\nmultiple swapping strategies to automatically decide which variable to swap and\nwhen to swap out (in), which reduces the memory cost by up to 34.2% without\ncommunication overhead.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 08:33:04 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Zhang", "Junzhe", ""], ["Yeung", "Sai Ho", ""], ["Shu", "Yao", ""], ["He", "Bingsheng", ""], ["Wang", "Wei", ""]]}, {"id": "1903.06638", "submitter": "Panagiota Kiourti", "authors": "Panagiota Kiourti, Kacper Wardega, Susmit Jha, Wenchao Li", "title": "TrojDRL: Trojan Attacks on Deep Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has identified that classification models implemented as neural\nnetworks are vulnerable to data-poisoning and Trojan attacks at training time.\nIn this work, we show that these training-time vulnerabilities extend to deep\nreinforcement learning (DRL) agents and can be exploited by an adversary with\naccess to the training process. In particular, we focus on Trojan attacks that\naugment the function of reinforcement learning policies with hidden behaviors.\nWe demonstrate that such attacks can be implemented through minuscule data\npoisoning (as little as 0.025% of the training data) and in-band reward\nmodification that does not affect the reward on normal inputs. The policies\nlearned with our proposed attack approach perform imperceptibly similar to\nbenign policies but deteriorate drastically when the Trojan is triggered in\nboth targeted and untargeted settings. Furthermore, we show that existing\nTrojan defense mechanisms for classification tasks are not effective in the\nreinforcement learning setting.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 04:17:32 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Kiourti", "Panagiota", ""], ["Wardega", "Kacper", ""], ["Jha", "Susmit", ""], ["Li", "Wenchao", ""]]}, {"id": "1903.06652", "submitter": "Yufei Zhang", "authors": "Christoph Reisinger, Yufei Zhang", "title": "Rectified deep neural networks overcome the curse of dimensionality for\n  nonsmooth value functions in zero-sum games of nonlinear stiff systems", "comments": "This revised version has been accepted for publication in Analysis\n  and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we establish that for a wide class of controlled stochastic\ndifferential equations (SDEs) with stiff coefficients, the value functions of\ncorresponding zero-sum games can be represented by a deep artificial neural\nnetwork (DNN), whose complexity grows at most polynomially in both the\ndimension of the state equation and the reciprocal of the required accuracy.\nSuch nonlinear stiff systems may arise, for example, from Galerkin\napproximations of controlled stochastic partial differential equations (SPDEs),\nor controlled PDEs with uncertain initial conditions and source terms. This\nimplies that DNNs can break the curse of dimensionality in numerical\napproximations and optimal control of PDEs and SPDEs. The main ingredient of\nour proof is to construct a suitable discrete-time system to effectively\napproximate the evolution of the underlying stochastic dynamics. Similar ideas\ncan also be applied to obtain expression rates of DNNs for value functions\ninduced by stiff systems with regime switching coefficients and driven by\ngeneral L\\'{e}vy noise.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 16:42:52 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 11:06:33 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Reisinger", "Christoph", ""], ["Zhang", "Yufei", ""]]}, {"id": "1903.06661", "submitter": "Kar Wai Lim", "authors": "Quoc Phong Nguyen, Kar Wai Lim, Dinil Mon Divakaran, Kian Hsiang Low,\n  Mun Choon Chan", "title": "GEE: A Gradient-based Explainable Variational Autoencoder for Network\n  Anomaly Detection", "comments": "to appear in 2019 IEEE Conference on Communications and Network\n  Security (CNS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper looks into the problem of detecting network anomalies by analyzing\nNetFlow records. While many previous works have used statistical models and\nmachine learning techniques in a supervised way, such solutions have the\nlimitations that they require large amount of labeled data for training and are\nunlikely to detect zero-day attacks. Existing anomaly detection solutions also\ndo not provide an easy way to explain or identify attacks in the anomalous\ntraffic. To address these limitations, we develop and present GEE, a framework\nfor detecting and explaining anomalies in network traffic. GEE comprises of two\ncomponents: (i) Variational Autoencoder (VAE) - an unsupervised deep-learning\ntechnique for detecting anomalies, and (ii) a gradient-based fingerprinting\ntechnique for explaining anomalies. Evaluation of GEE on the recent UGR dataset\ndemonstrates that our approach is effective in detecting different anomalies as\nwell as identifying fingerprints that are good representations of these various\nattacks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 16:58:34 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Nguyen", "Quoc Phong", ""], ["Lim", "Kar Wai", ""], ["Divakaran", "Dinil Mon", ""], ["Low", "Kian Hsiang", ""], ["Chan", "Mun Choon", ""]]}, {"id": "1903.06668", "submitter": "Ekaterina Abramova", "authors": "Ekaterina Abramova and Derek Bunn", "title": "Estimating Dynamic Conditional Spread Densities to Optimise Daily\n  Storage Trading of Electricity", "comments": "59 pages, 37 figures, CEMA 2019, POM Special Issue", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG econ.EM q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formulates dynamic density functions, based upon skewed-t and\nsimilar representations, to model and forecast electricity price spreads\nbetween different hours of the day. This supports an optimal day ahead storage\nand discharge schedule, and thereby facilitates a bidding strategy for a\nmerchant arbitrage facility into the day-ahead auctions for wholesale\nelectricity. The four latent moments of the density functions are dynamic and\nconditional upon exogenous drivers, thereby permitting the mean, variance,\nskewness and kurtosis of the densities to respond hourly to such factors as\nweather and demand forecasts. The best specification for each spread is\nselected based on the Pinball Loss function, following the closed form\nanalytical solutions of the cumulative density functions. Those analytical\nproperties also allow the calculation of risk associated with the spread\narbitrages. From these spread densities, the optimal daily operation of a\nbattery storage facility is determined.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 20:33:21 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Abramova", "Ekaterina", ""], ["Bunn", "Derek", ""]]}, {"id": "1903.06669", "submitter": "Lily Xu", "authors": "Lily Xu, Shahrzad Gholami, Sara Mc Carthy, Bistra Dilkina, Andrew\n  Plumptre, Milind Tambe, Rohit Singh, Mustapha Nsubuga, Joshua Mabonga,\n  Margaret Driciru, Fred Wanyama, Aggrey Rwetsiba, Tom Okello, Eric Enyel", "title": "Stay Ahead of Poachers: Illegal Wildlife Poaching Prediction and Patrol\n  Planning Under Uncertainty with Field Test Evaluations", "comments": "12 pages, 11 figures. Short paper published in ICDE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Illegal wildlife poaching threatens ecosystems and drives endangered species\ntoward extinction. However, efforts for wildlife protection are constrained by\nthe limited resources of law enforcement agencies. To help combat poaching, the\nProtection Assistant for Wildlife Security (PAWS) is a machine learning\npipeline that has been developed as a data-driven approach to identify areas at\nhigh risk of poaching throughout protected areas and compute optimal patrol\nroutes. In this paper, we take an end-to-end approach to the data-to-deployment\npipeline for anti-poaching. In doing so, we address challenges including\nextreme class imbalance (up to 1:200), bias, and uncertainty in wildlife\npoaching data to enhance PAWS, and we apply our methodology to three national\nparks with diverse characteristics. (i) We use Gaussian processes to quantify\npredictive uncertainty, which we exploit to improve robustness of our\nprescribed patrols and increase detection of snares by an average of 30%. We\nevaluate our approach on real-world historical poaching data from Murchison\nFalls and Queen Elizabeth National Parks in Uganda and, for the first time,\nSrepok Wildlife Sanctuary in Cambodia. (ii) We present the results of\nlarge-scale field tests conducted in Murchison Falls and Srepok Wildlife\nSanctuary which confirm that the predictive power of PAWS extends promisingly\nto multiple parks. This paper is part of an effort to expand PAWS to 800 parks\naround the world through integration with SMART conservation software.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 08:26:07 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 04:11:38 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 03:06:34 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Xu", "Lily", ""], ["Gholami", "Shahrzad", ""], ["Carthy", "Sara Mc", ""], ["Dilkina", "Bistra", ""], ["Plumptre", "Andrew", ""], ["Tambe", "Milind", ""], ["Singh", "Rohit", ""], ["Nsubuga", "Mustapha", ""], ["Mabonga", "Joshua", ""], ["Driciru", "Margaret", ""], ["Wanyama", "Fred", ""], ["Rwetsiba", "Aggrey", ""], ["Okello", "Tom", ""], ["Enyel", "Eric", ""]]}, {"id": "1903.06681", "submitter": "Nikoli Dryden", "authors": "Nikoli Dryden, Naoya Maruyama, Tom Benson, Tim Moon, Marc Snir, Brian\n  Van Essen", "title": "Improving Strong-Scaling of CNN Training by Exploiting Finer-Grained\n  Parallelism", "comments": "To appear at IPDPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling CNN training is necessary to keep up with growing datasets and reduce\ntraining time. We also see an emerging need to handle datasets with very large\nsamples, where memory requirements for training are large. Existing training\nframeworks use a data-parallel approach that partitions samples within a\nmini-batch, but limits to scaling the mini-batch size and memory consumption\nmakes this untenable for large samples. We describe and implement new\napproaches to convolution, which parallelize using spatial decomposition or a\ncombination of sample and spatial decomposition. This introduces many\nperformance knobs for a network, so we develop a performance model for CNNs and\npresent a method for using it to automatically determine efficient\nparallelization strategies.\n  We evaluate our algorithms with microbenchmarks and image classification with\nResNet-50. Our algorithms allow us to prototype a model for a mesh-tangling\ndataset, where sample sizes are very large. We show that our parallelization\nachieves excellent strong and weak scaling and enables training for previously\nunreachable datasets.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 17:25:01 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Dryden", "Nikoli", ""], ["Maruyama", "Naoya", ""], ["Benson", "Tom", ""], ["Moon", "Tim", ""], ["Snir", "Marc", ""], ["Van Essen", "Brian", ""]]}, {"id": "1903.06694", "submitter": "Kirthevasan Kandasamy", "authors": "Kirthevasan Kandasamy, Karun Raju Vysyaraju, Willie Neiswanger,\n  Biswajit Paria, Christopher R. Collins, Jeff Schneider, Barnabas Poczos, Eric\n  P. Xing", "title": "Tuning Hyperparameters without Grad Students: Scalable and Robust\n  Bayesian Optimisation with Dragonfly", "comments": "Journal of Machine Learning Research 2020, Special Issue on Bayesian\n  Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimisation (BO) refers to a suite of techniques for global\noptimisation of expensive black box functions, which use introspective Bayesian\nmodels of the function to efficiently search for the optimum. While BO has been\napplied successfully in many applications, modern optimisation tasks usher in\nnew challenges where conventional methods fail spectacularly. In this work, we\npresent Dragonfly, an open source Python library for scalable and robust BO.\nDragonfly incorporates multiple recently developed methods that allow BO to be\napplied in challenging real world settings; these include better methods for\nhandling higher dimensional domains, methods for handling multi-fidelity\nevaluations when cheap approximations of an expensive function are available,\nmethods for optimising over structured combinatorial spaces, such as the space\nof neural network architectures, and methods for handling parallel evaluations.\nAdditionally, we develop new methodological improvements in BO for selecting\nthe Bayesian model, selecting the acquisition function, and optimising over\ncomplex domains with different variable types and additional constraints. We\ncompare Dragonfly to a suite of other packages and algorithms for global\noptimisation and demonstrate that when the above methods are integrated, they\nenable significant improvements in the performance of BO. The Dragonfly library\nis available at dragonfly.github.io.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 17:45:39 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 18:09:41 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Kandasamy", "Kirthevasan", ""], ["Vysyaraju", "Karun Raju", ""], ["Neiswanger", "Willie", ""], ["Paria", "Biswajit", ""], ["Collins", "Christopher R.", ""], ["Schneider", "Jeff", ""], ["Poczos", "Barnabas", ""], ["Xing", "Eric P.", ""]]}, {"id": "1903.06695", "submitter": "Dorian Cazau", "authors": "Paul Nguyen Hong Duc and Dorian Cazau", "title": "Development details and computational benchmarking of DEPAM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the big data era of observational oceanography, passive acoustics datasets\nare becoming too high volume to be processed on local computers due to their\nprocessor and memory limitations. As a result there is a current need for our\ncommunity to turn to cloud-based distributed computing. We present a scalable\ncomputing system for FFT (Fast Fourier Transform)-based features (e.g., Power\nSpectral Density) based on the Apache distributed frameworks Hadoop and Spark.\nThese features are at the core of many different types of acoustic analysis\nwhere the need of processing data at scale with speed is evident, e.g. serving\nas long-term averaged learning representations of soundscapes to identify\nperiods of acoustic interest. In addition to provide a complete description of\nour system implementation, we also performed a computational benchmark\ncomparing our system to three other Scala-only, Matlab and Python based systems\nin standalone executions, and evaluated its scalability using the speed up\nmetric. Our current results are very promising in terms of computational\nperformance, as we show that our proposed Hadoop/Spark system performs\nreasonably well on a single node setup comparatively to state-of-the-art\nprocessing tools used by the PAM community, and that it could also fully\nleverage more intensive cluster resources with a almost-linear scalability\nbehaviour above a certain dataset volume.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 21:32:52 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 14:04:46 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Duc", "Paul Nguyen Hong", ""], ["Cazau", "Dorian", ""]]}, {"id": "1903.06700", "submitter": "Sanjeev Raja", "authors": "Sanjeev Raja, Ernest Fokou\\'e", "title": "Multi-Stage Fault Warning for Large Electric Grids Using Anomaly\n  Detection and Machine Learning", "comments": "13 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the monitoring of a complex electric grid, it is of paramount importance\nto provide operators with early warnings of anomalies detected on the network,\nalong with a precise classification and diagnosis of the specific fault type.\nIn this paper, we propose a novel multi-stage early warning system prototype\nfor electric grid fault detection, classification, subgroup discovery, and\nvisualization. In the first stage, a computationally efficient anomaly\ndetection method based on quartiles detects the presence of a fault in real\ntime. In the second stage, the fault is classified into one of nine pre-defined\ndisaster scenarios. The time series data are first mapped to highly\ndiscriminative features by applying dimensionality reduction based on temporal\nautocorrelation. The features are then mapped through one of three\nclassification techniques: support vector machine, random forest, and\nartificial neural network. Finally in the third stage, intra-class clustering\nbased on dynamic time warping is used to characterize the fault with further\ngranularity. Results on the Bonneville Power Administration electric grid data\nshow that i) the proposed anomaly detector is both fast and accurate; ii)\ndimensionality reduction leads to dramatic improvement in classification\naccuracy and speed; iii) the random forest method offers the most accurate,\nconsistent, and robust fault classification; and iv) time series within a given\nclass naturally separate into five distinct clusters which correspond closely\nto the geographical distribution of electric grid buses.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 17:52:39 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Raja", "Sanjeev", ""], ["Fokou\u00e9", "Ernest", ""]]}, {"id": "1903.06701", "submitter": "Marco Canini", "authors": "Amedeo Sapio, Marco Canini, Chen-Yu Ho, Jacob Nelson, Panos Kalnis,\n  Changhoon Kim, Arvind Krishnamurthy, Masoud Moshref, Dan R. K. Ports, Peter\n  Richt\\'arik", "title": "Scaling Distributed Machine Learning with In-Network Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning models in parallel is an increasingly important\nworkload. We accelerate distributed parallel training by designing a\ncommunication primitive that uses a programmable switch dataplane to execute a\nkey step of the training process. Our approach, SwitchML, reduces the volume of\nexchanged data by aggregating the model updates from multiple workers in the\nnetwork. We co-design the switch processing with the end-host protocols and ML\nframeworks to provide an efficient solution that speeds up training by up to\n5.5$\\times$ for a number of real-world benchmark models.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 15:10:21 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 09:26:58 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Sapio", "Amedeo", ""], ["Canini", "Marco", ""], ["Ho", "Chen-Yu", ""], ["Nelson", "Jacob", ""], ["Kalnis", "Panos", ""], ["Kim", "Changhoon", ""], ["Krishnamurthy", "Arvind", ""], ["Moshref", "Masoud", ""], ["Ports", "Dan R. K.", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1903.06727", "submitter": "Masoud Badiei Khuzani", "authors": "Masoud Badiei Khuzani, Varun Vasudevan, Hongyi Ren, Lei Xing", "title": "On Sample Complexity of Projection-Free Primal-Dual Methods for Learning\n  Mixture Policies in Markov Decision Processes", "comments": "Manuscript accepted to 58th CDC, 31 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning policy of an infinite-horizon, discounted\ncost, Markov decision process (MDP) with a large number of states. We compute\nthe actions of a policy that is nearly as good as a policy chosen by a suitable\noracle from a given mixture policy class characterized by the convex hull of a\nset of known base policies. To learn the coefficients of the mixture model, we\nrecast the problem as an approximate linear programming (ALP) formulation for\nMDPs, where the feature vectors correspond to the occupation measures of the\nbase policies defined on the state-action space. We then propose a\nprojection-free stochastic primal-dual method with the Bregman divergence to\nsolve the characterized ALP. Furthermore, we analyze the probably approximately\ncorrect (PAC) sample complexity of the proposed stochastic algorithm, namely\nthe number of queries required to achieve near optimal objective value. We also\npropose a modification of our proposed algorithm with the polytope constraint\nsampling for the smoothed ALP, where the restriction to lower bounding\napproximations are relaxed. In addition, we apply the proposed algorithms to a\nqueuing problem, and compare their performance with a penalty function\nalgorithm. The numerical results illustrates that the primal-dual achieves\nbetter efficiency and low variance across different trials compared to the\npenalty function method.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 18:14:55 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 18:04:23 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 17:03:23 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Khuzani", "Masoud Badiei", ""], ["Vasudevan", "Varun", ""], ["Ren", "Hongyi", ""], ["Xing", "Lei", ""]]}, {"id": "1903.06733", "submitter": "Yeonjong Shin", "authors": "Lu Lu, Yeonjong Shin, Yanhui Su, George Em Karniadakis", "title": "Dying ReLU and Initialization: Theory and Numerical Examples", "comments": null, "journal-ref": null, "doi": "10.4208/cicp.OA-2020-0165", "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The dying ReLU refers to the problem when ReLU neurons become inactive and\nonly output 0 for any input. There are many empirical and heuristic\nexplanations of why ReLU neurons die. However, little is known about its\ntheoretical analysis. In this paper, we rigorously prove that a deep ReLU\nnetwork will eventually die in probability as the depth goes to infinite.\nSeveral methods have been proposed to alleviate the dying ReLU. Perhaps, one of\nthe simplest treatments is to modify the initialization procedure. One common\nway of initializing weights and biases uses symmetric probability\ndistributions, which suffers from the dying ReLU. We thus propose a new\ninitialization procedure, namely, a randomized asymmetric initialization. We\nprove that the new initialization can effectively prevent the dying ReLU. All\nparameters required for the new initialization are theoretically designed.\nNumerical examples are provided to demonstrate the effectiveness of the new\ninitialization procedure.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 18:23:55 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 23:15:23 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 19:19:02 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Lu", "Lu", ""], ["Shin", "Yeonjong", ""], ["Su", "Yanhui", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1903.06740", "submitter": "Navoneel Chakrabarty", "authors": "Navoneel Chakrabarty", "title": "A Data Mining Approach to Flight Arrival Delay Prediction for American\n  Airlines", "comments": "The 9th Annual Information Technology, Electromechanical and\n  Microelectronics Conference (IEMECON 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the present scenario of domestic flights in USA, there have been numerous\ninstances of flight delays and cancellations. In the United States, the\nAmerican Airlines, Inc. have been one of the most entrusted and the world's\nlargest airline in terms of number of destinations served. But when it comes to\ndomestic flights, AA has not lived up to the expectations in terms of\npunctuality or on-time performance. Flight Delays also result in airline\ncompanies operating commercial flights to incur huge losses. So, they are\ntrying their best to prevent or avoid Flight Delays and Cancellations by taking\ncertain measures. This study aims at analyzing flight information of US\ndomestic flights operated by American Airlines, covering top 5 busiest airports\nof US and predicting possible arrival delay of the flight using Data Mining and\nMachine Learning Approaches. The Gradient Boosting Classifier Model is deployed\nby training and hyper-parameter tuning it, achieving a maximum accuracy of\n85.73%. Such an Intelligent System is very essential in foretelling\nflights'on-time performance.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 18:37:03 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Chakrabarty", "Navoneel", ""]]}, {"id": "1903.06751", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Juho Kanniainen, Moncef Gabbouj, Alexandros Iosifidis", "title": "Data-driven Neural Architecture Learning For Financial Time-series\n  Forecasting", "comments": "Accepted in DISP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting based on financial time-series is a challenging task since most\nreal-world data exhibits nonstationary property and nonlinear dependencies. In\naddition, different data modalities often embed different nonlinear\nrelationships which are difficult to capture by human-designed models. To\ntackle the supervised learning task in financial time-series prediction, we\npropose the application of a recently formulated algorithm that adaptively\nlearns a mapping function, realized by a heterogeneous neural architecture\ncomposing of Generalized Operational Perceptron, given a set of labeled data.\nWith a modified objective function, the proposed algorithm can accommodate the\nfrequently observed imbalanced data distribution problem. Experiments on a\nlarge-scale Limit Order Book dataset demonstrate that the proposed algorithm\noutperforms related algorithms, including tensor-based methods which have\naccess to a broader set of input information.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 11:32:26 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1903.06753", "submitter": "Cheng Cheng", "authors": "Cheng Cheng, Beitong Zhou, Guijun Ma, Dongrui Wu and Ye Yuan", "title": "Wasserstein Distance based Deep Adversarial Transfer Learning for\n  Intelligent Fault Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand of artificial intelligent adoption for condition-based maintenance\nstrategy is astonishingly increased over the past few years. Intelligent fault\ndiagnosis is one critical topic of maintenance solution for mechanical systems.\nDeep learning models, such as convolutional neural networks (CNNs), have been\nsuccessfully applied to fault diagnosis tasks for mechanical systems and\nachieved promising results. However, for diverse working conditions in the\nindustry, deep learning suffers two difficulties: one is that the well-defined\n(source domain) and new (target domain) datasets are with different feature\ndistributions; another one is the fact that insufficient or no labelled data in\ntarget domain significantly reduce the accuracy of fault diagnosis. As a novel\nidea, deep transfer learning (DTL) is created to perform learning in the target\ndomain by leveraging information from the relevant source domain. Inspired by\nWasserstein distance of optimal transport, in this paper, we propose a novel\nDTL approach to intelligent fault diagnosis, namely Wasserstein Distance based\nDeep Transfer Learning (WD-DTL), to learn domain feature representations\n(generated by a CNN based feature extractor) and to minimize the distributions\nbetween the source and target domains through adversarial training. The\neffectiveness of the proposed WD-DTL is verified through 3 transfer scenarios\nand 16 transfer fault diagnosis experiments of both unsupervised and supervised\n(with insufficient labelled data) learning. We also provide a comprehensive\nanalysis of the network visualization of those transfer tasks.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 08:48:23 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Cheng", "Cheng", ""], ["Zhou", "Beitong", ""], ["Ma", "Guijun", ""], ["Wu", "Dongrui", ""], ["Yuan", "Ye", ""]]}, {"id": "1903.06754", "submitter": "Ruohan Zhang", "authors": "Ruohan Zhang, Calen Walshe, Zhuode Liu, Lin Guan, Karl S. Muller, Jake\n  A. Whritner, Luxin Zhang, Mary M. Hayhoe, Dana H. Ballard", "title": "Atari-HEAD: Atari Human Eye-Tracking and Demonstration Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale public datasets have been shown to benefit research in multiple\nareas of modern artificial intelligence. For decision-making research that\nrequires human data, high-quality datasets serve as important benchmarks to\nfacilitate the development of new methods by providing a common reproducible\nstandard. Many human decision-making tasks require visual attention to obtain\nhigh levels of performance. Therefore, measuring eye movements can provide a\nrich source of information about the strategies that humans use to solve\ndecision-making tasks. Here, we provide a large-scale, high-quality dataset of\nhuman actions with simultaneously recorded eye movements while humans play\nAtari video games. The dataset consists of 117 hours of gameplay data from a\ndiverse set of 20 games, with 8 million action demonstrations and 328 million\ngaze samples. We introduce a novel form of gameplay, in which the human plays\nin a semi-frame-by-frame manner. This leads to near-optimal game decisions and\ngame scores that are comparable or better than known human records. We\ndemonstrate the usefulness of the dataset through two simple applications:\npredicting human gaze and imitating human demonstrated actions. The quality of\nthe data leads to promising results in both tasks. Moreover, using a learned\nhuman gaze model to inform imitation learning leads to an 115\\% increase in\ngame performance. We interpret these results as highlighting the importance of\nincorporating human visual attention in models of decision making and\ndemonstrating the value of the current dataset to the research community. We\nhope that the scale and quality of this dataset can provide more opportunities\nto researchers in the areas of visual attention, imitation learning, and\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 18:55:07 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 20:17:17 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhang", "Ruohan", ""], ["Walshe", "Calen", ""], ["Liu", "Zhuode", ""], ["Guan", "Lin", ""], ["Muller", "Karl S.", ""], ["Whritner", "Jake A.", ""], ["Zhang", "Luxin", ""], ["Hayhoe", "Mary M.", ""], ["Ballard", "Dana H.", ""]]}, {"id": "1903.06756", "submitter": "Ibrahim AlZuabi", "authors": "Ibrahim Mousa AlZuabi, Assef Jafar and Kadan Aljoumaa", "title": "Predicting customer's gender and age depending on mobile phone data", "comments": null, "journal-ref": null, "doi": "10.1186/s40537-019-0180-9", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of data driven solution, the customer demographic attributes, such\nas gender and age, play a core role that may enable companies to enhance the\noffers of their services and target the right customer in the right time and\nplace. In the marketing campaign, the companies want to target the real user of\nthe GSM (global system for mobile communications), not the line owner. Where\nsometimes they may not be the same. This work proposes a method that predicts\nusers' gender and age based on their behavior, services and contract\ninformation. We used call detail records (CDRs), customer relationship\nmanagement (CRM) and billing information as a data source to analyze telecom\ncustomer behavior, and applied different types of machine learning algorithms\nto provide marketing campaigns with more accurate information about customer\ndemographic attributes. This model is built using reliable data set of 18,000\nusers provided by SyriaTel Telecom Company, for training and testing. The model\napplied by using big data technology and achieved 85.6% accuracy in terms of\nuser gender prediction and 65.5% of user age prediction. The main contribution\nof this work is the improvement in the accuracy in terms of user gender\nprediction and user age prediction based on mobile phone data and end-to-end\nsolution that approaches customer data from multiple aspects in the telecom\ndomain.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 07:46:13 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["AlZuabi", "Ibrahim Mousa", ""], ["Jafar", "Assef", ""], ["Aljoumaa", "Kadan", ""]]}, {"id": "1903.06758", "submitter": "Changliu Liu", "authors": "Changliu Liu, Tomer Arnon, Christopher Lazarus, Christopher Strong,\n  Clark Barrett, Mykel J. Kochenderfer", "title": "Algorithms for Verifying Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are widely used for nonlinear function approximation\nwith applications ranging from computer vision to control. Although these\nnetworks involve the composition of simple arithmetic operations, it can be\nvery challenging to verify whether a particular network satisfies certain\ninput-output properties. This article surveys methods that have emerged\nrecently for soundly verifying such properties. These methods borrow insights\nfrom reachability analysis, optimization, and search. We discuss fundamental\ndifferences and connections between existing algorithms. In addition, we\nprovide pedagogical implementations of existing methods and compare them on a\nset of benchmark problems.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 19:02:38 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 21:06:08 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Liu", "Changliu", ""], ["Arnon", "Tomer", ""], ["Lazarus", "Christopher", ""], ["Strong", "Christopher", ""], ["Barrett", "Clark", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1903.06765", "submitter": "Navoneel Chakrabarty", "authors": "Navoneel Chakrabarty", "title": "A Machine Learning Approach to Comment Toxicity Classification", "comments": "INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN PATTERN\n  RECOGNITION (CIPR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Now-a-days, derogatory comments are often made by one another, not only in\noffline environment but also immensely in online environments like social\nnetworking websites and online communities. So, an Identification combined with\nPrevention System in all social networking websites and applications, including\nall the communities, existing in the digital world is a necessity. In such a\nsystem, the Identification Block should identify any negative online behaviour\nand should signal the Prevention Block to take action accordingly. This study\naims to analyse any piece of text and detecting different types of toxicity\nlike obscenity, threats, insults and identity-based hatred. The labelled\nWikipedia Comment Dataset prepared by Jigsaw is used for the purpose. A\n6-headed Machine Learning tf-idf Model has been made and trained separately,\nyielding a Mean Validation Accuracy of 98.08% and Absolute Validation Accuracy\nof 91.61%. Such an Automated System should be deployed for enhancing healthy\nonline conversation\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 07:21:44 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Chakrabarty", "Navoneel", ""]]}, {"id": "1903.06781", "submitter": "Shay Deutsch Dr.", "authors": "Shay Deutsch, Andrea Bertozzi, and Stefano Soatto", "title": "Zero Shot Learning with the Isoperimetric Loss", "comments": "Accepted to AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the isoperimetric loss as a regularization criterion for\nlearning the map from a visual representation to a semantic embedding, to be\nused to transfer knowledge to unknown classes in a zero-shot learning setting.\nWe use a pre-trained deep neural network model as a visual representation of\nimage data, a Word2Vec embedding of class labels, and linear maps between the\nvisual and semantic embedding spaces. However, the spaces themselves are not\nlinear, and we postulate the sample embedding to be populated by noisy samples\nnear otherwise smooth manifolds. We exploit the graph structure defined by the\nsample points to regularize the estimates of the manifolds by inferring the\ngraph connectivity using a generalization of the isoperimetric inequalities\nfrom Riemannian geometry to graphs. Surprisingly, this regularization alone,\npaired with the simplest baseline model, outperforms the state-of-the-art among\nfully automated methods in zero-shot learning benchmarks such as AwA and CUB.\nThis improvement is achieved solely by learning the structure of the underlying\nspaces by imposing regularity.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 19:55:38 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 19:17:12 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Deutsch", "Shay", ""], ["Bertozzi", "Andrea", ""], ["Soatto", "Stefano", ""]]}, {"id": "1903.06787", "submitter": "Eren Balevi", "authors": "Eren Balevi, Jeffrey G. Andrews", "title": "Online Antenna Tuning in Heterogeneous Cellular Networks with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to jointly optimize antenna tilt angle, and vertical and horizontal\nhalf-power beamwidths of the macrocells in a heterogeneous cellular network\n(HetNet). The interactions between the cells, most notably due to their coupled\ninterference render this optimization prohibitively complex. Utilizing a single\nagent reinforcement learning (RL) algorithm for this optimization becomes quite\nsuboptimum despite its scalability, whereas multi-agent RL algorithms yield\nbetter solutions at the expense of scalability. Hence, we propose a compromise\nalgorithm between these two. Specifically, a multi-agent mean field RL\nalgorithm is first utilized in the offline phase so as to transfer information\nas features for the second (online) phase single agent RL algorithm, which\nemploys a deep neural network to learn users locations. This two-step approach\nis a practical solution for real deployments, which should automatically adapt\nto environmental changes in the network. Our results illustrate that the\nproposed algorithm approaches the performance of the multi-agent RL, which\nrequires millions of trials, with hundreds of online trials, assuming\nrelatively low environmental dynamics, and performs much better than a single\nagent RL. Furthermore, the proposed algorithm is compact and implementable, and\nempirically appears to provide a performance guarantee regardless of the amount\nof environmental dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 20:23:18 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 22:36:32 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Balevi", "Eren", ""], ["Andrews", "Jeffrey G.", ""]]}, {"id": "1903.06800", "submitter": "Alessandro Betti", "authors": "Lorenzo Gigoni, Alessandro Betti, Emanuele Crisostomi, Alessandro\n  Franco, Mauro Tucci, Fabrizio Bizzarri, Debora Mucci", "title": "Day-Ahead Hourly Forecasting of Power Generation from Photovoltaic\n  Plants", "comments": "Preprint of IEEE Transactions of Sustainable Energy, Vol. 9, Issue 2,\n  pp. 831 - 842 (2018)", "journal-ref": "IEEE Transactions of Sustainable Energy, Vol. 9, Issue 2, pp. 831\n  - 842 (2018)", "doi": "10.1109/TSTE.2017.2762435", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately forecast power generation from renewable sources is\nnowadays recognised as a fundamental skill to improve the operation of power\nsystems. Despite the general interest of the power community in this topic, it\nis not always simple to compare different forecasting methodologies, and infer\nthe impact of single components in providing accurate predictions. In this\npaper we extensively compare simple forecasting methodologies with more\nsophisticated ones over 32 photovoltaic plants of different size and technology\nover a whole year. Also, we try to evaluate the impact of weather conditions\nand weather forecasts on the prediction of PV power generation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 11:29:18 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Gigoni", "Lorenzo", ""], ["Betti", "Alessandro", ""], ["Crisostomi", "Emanuele", ""], ["Franco", "Alessandro", ""], ["Tucci", "Mauro", ""], ["Bizzarri", "Fabrizio", ""], ["Mucci", "Debora", ""]]}, {"id": "1903.06802", "submitter": "Daniel Crawl", "authors": "Ilkay Altintas, Kyle Marcus, Isaac Nealey, Scott L. Sellars, John\n  Graham, Dima Mishin, Joel Polizzi, Daniel Crawl, Thomas DeFanti, Larry Smarr", "title": "Workflow-Driven Distributed Machine Learning in CHASE-CI: A Cognitive\n  Hardware and Software Ecosystem Community Infrastructure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advances in data, computing and networking over the last two decades led\nto a shift in many application domains that includes machine learning on big\ndata as a part of the scientific process, requiring new capabilities for\nintegrated and distributed hardware and software infrastructure. This paper\ncontributes a workflow-driven approach for dynamic data-driven application\ndevelopment on top of a new kind of networked Cyberinfrastructure called\nCHASE-CI. In particular, we present: 1) The architecture for CHASE-CI, a\nnetwork of distributed fast GPU appliances for machine learning and storage\nmanaged through Kubernetes on the high-speed (10-100Gbps) Pacific Research\nPlatform (PRP); 2) A machine learning software containerization approach and\nlibraries required for turning such a network into a distributed computer for\nbig data analysis; 3) An atmospheric science case study that can only be made\nscalable with an infrastructure like CHASE-CI; 4) Capabilities for virtual\ncluster management for data communication and analysis in a dynamically\nscalable fashion, and visualization across the network in specialized\nvisualization facilities in near real-time; and, 5) A step-by-step workflow and\nperformance measurement approach that enables taking advantage of the dynamic\narchitecture of the CHASE-CI network and container management infrastructure.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 02:09:31 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Altintas", "Ilkay", ""], ["Marcus", "Kyle", ""], ["Nealey", "Isaac", ""], ["Sellars", "Scott L.", ""], ["Graham", "John", ""], ["Mishin", "Dima", ""], ["Polizzi", "Joel", ""], ["Crawl", "Daniel", ""], ["DeFanti", "Thomas", ""], ["Smarr", "Larry", ""]]}, {"id": "1903.06855", "submitter": "Ali Oguz Uzman", "authors": "Ali Oguz Uzman and Jannis Horn and Sven Behnke", "title": "Learning Super-resolution 3D Segmentation of Plant Root MRI Images from\n  Few Examples", "comments": "27th European Symposium on Artificial Neural Networks, Computational\n  Intelligence and Machine Learning (ESANN), Bruges, Belgium, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing plant roots is crucial to understand plant performance in different\nsoil environments. While magnetic resonance imaging (MRI) can be used to obtain\n3D images of plant roots, extracting the root structural model is challenging\ndue to highly noisy soil environments and low-resolution of MRI images. To\nimprove both contrast and resolution, we adapt the state-of-the-art method\nRefineNet for 3D segmentation of the plant root MRI images in super-resolution.\nThe networks are trained from few manual segmentations that are augmented by\ngeometric transformations, realistic noise, and other variabilities. The\nresulting segmentations contain most root structures, including branches not\nextracted by the human annotator.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 01:12:04 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Uzman", "Ali Oguz", ""], ["Horn", "Jannis", ""], ["Behnke", "Sven", ""]]}, {"id": "1903.06864", "submitter": "Tatiana Tommasi", "authors": "Fabio Maria Carlucci, Antonio D'Innocente, Silvia Bucci, Barbara\n  Caputo, Tatiana Tommasi", "title": "Domain Generalization by Solving Jigsaw Puzzles", "comments": "Accepted at CVPR 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human adaptability relies crucially on the ability to learn and merge\nknowledge both from supervised and unsupervised learning: the parents point out\nfew important concepts, but then the children fill in the gaps on their own.\nThis is particularly effective, because supervised learning can never be\nexhaustive and thus learning autonomously allows to discover invariances and\nregularities that help to generalize. In this paper we propose to apply a\nsimilar approach to the task of object recognition across domains: our model\nlearns the semantic labels in a supervised fashion, and broadens its\nunderstanding of the data by learning from self-supervised signals how to solve\na jigsaw puzzle on the same images. This secondary task helps the network to\nlearn the concepts of spatial correlation while acting as a regularizer for the\nclassification task. Multiple experiments on the PACS, VLCS, Office-Home and\ndigits datasets confirm our intuition and show that this simple method\noutperforms previous domain generalization and adaptation solutions. An\nablation study further illustrates the inner workings of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 01:56:59 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 11:03:44 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Carlucci", "Fabio Maria", ""], ["D'Innocente", "Antonio", ""], ["Bucci", "Silvia", ""], ["Caputo", "Barbara", ""], ["Tommasi", "Tatiana", ""]]}, {"id": "1903.06871", "submitter": "Jineng Ren", "authors": "Jineng Ren and Jarvis Haupt", "title": "A Provably Communication-Efficient Asynchronous Distributed Inference\n  Method for Convex and Nonconvex Problems", "comments": "15 pages, 9 figures, preliminary version appeared in the proceedings\n  of the 2018 IEEE Global Conference on Signal and Information Processing\n  (GlobalSIP 2018)", "journal-ref": null, "doi": "10.1109/TSP.2020.2996374", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes and analyzes a communication-efficient distributed\noptimization framework for general nonconvex nonsmooth signal processing and\nmachine learning problems under an asynchronous protocol. At each iteration,\nworker machines compute gradients of a known empirical loss function using\ntheir own local data, and a master machine solves a related minimization\nproblem to update the current estimate. We prove that for nonconvex nonsmooth\nproblems, the proposed algorithm converges with a sublinear rate over the\nnumber of communication rounds, coinciding with the best theoretical rate that\ncan be achieved for this class of problems. Linear convergence is established\nwithout any statistical assumptions of the local data for problems\ncharacterized by composite loss functions whose smooth parts are strongly\nconvex. Extensive numerical experiments verify that the performance of the\nproposed approach indeed improves -- sometimes significantly -- over other\nstate-of-the-art algorithms in terms of total communication efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 03:04:21 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Ren", "Jineng", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1903.06874", "submitter": "Huan Ling", "authors": "Huan Ling and Jun Gao and Amlan Kar and Wenzheng Chen and Sanja Fidler", "title": "Fast Interactive Object Annotation with Curve-GCN", "comments": "In Computer Vision and Pattern Recognition (CVPR), Long Beach, US,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Manually labeling objects by tracing their boundaries is a laborious process.\nIn Polygon-RNN++ the authors proposed Polygon-RNN that produces polygonal\nannotations in a recurrent manner using a CNN-RNN architecture, allowing\ninteractive correction via humans-in-the-loop. We propose a new framework that\nalleviates the sequential nature of Polygon-RNN, by predicting all vertices\nsimultaneously using a Graph Convolutional Network (GCN). Our model is trained\nend-to-end. It supports object annotation by either polygons or splines,\nfacilitating labeling efficiency for both line-based and curved objects. We\nshow that Curve-GCN outperforms all existing approaches in automatic mode,\nincluding the powerful PSP-DeepLab and is significantly more efficient in\ninteractive mode than Polygon-RNN++. Our model runs at 29.3ms in automatic, and\n2.6ms in interactive mode, making it 10x and 100x faster than Polygon-RNN++.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 03:14:41 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Ling", "Huan", ""], ["Gao", "Jun", ""], ["Kar", "Amlan", ""], ["Chen", "Wenzheng", ""], ["Fidler", "Sanja", ""]]}, {"id": "1903.06877", "submitter": "Qiuwei Li", "authors": "Kai Liu, Qiuwei Li, Hua Wang, Gongguo Tang", "title": "Spherical Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) is one of the most important methods to\nhandle high dimensional data. However, most of the studies on PCA aim to\nminimize the loss after projection, which usually measures the Euclidean\ndistance, though in some fields, angle distance is known to be more important\nand critical for analysis. In this paper, we propose a method by adding\nconstraints on factors to unify the Euclidean distance and angle distance.\nHowever, due to the nonconvexity of the objective and constraints, the\noptimized solution is not easy to obtain. We propose an alternating linearized\nminimization method to solve it with provable convergence rate and guarantee.\nExperiments on synthetic data and real-world datasets have validated the\neffectiveness of our method and demonstrated its advantages over state-of-art\nclustering methods.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 04:18:33 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Liu", "Kai", ""], ["Li", "Qiuwei", ""], ["Wang", "Hua", ""], ["Tang", "Gongguo", ""]]}, {"id": "1903.06934", "submitter": "Jiarui Fang", "authors": "Jiarui Fang, Liandeng Li, Haohuan Fu, Jinlei Jiang, Wenlai Zhao,\n  Conghui He, Xin You, Guangwen Yang", "title": "swCaffe: a Parallel Framework for Accelerating Deep Learning\n  Applications on Sunway TaihuLight", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports our efforts on swCaffe, a highly efficient parallel\nframework for accelerating deep neural networks (DNNs) training on Sunway\nTaihuLight, the current fastest supercomputer in the world that adopts a unique\nmany-core heterogeneous architecture, with 40,960 SW26010 processors connected\nthrough a customized communication network. First, we point out some insightful\nprinciples to fully exploit the performance of the innovative many-core\narchitecture. Second, we propose a set of optimization strategies for\nredesigning a variety of neural network layers based on Caffe. Third, we put\nforward a topology-aware parameter synchronization scheme to scale the\nsynchronous Stochastic Gradient Descent (SGD) method to multiple processors\nefficiently. We evaluate our framework by training a variety of widely used\nneural networks with the ImageNet dataset. On a single node, swCaffe can\nachieve 23\\%\\~{}119\\% overall performance compared with Caffe running on K40m\nGPU. As compared with the Caffe on CPU, swCaffe runs 3.04\\~{}7.84x faster on\nall the networks. Finally, we present the scalability of swCaffe for the\ntraining of ResNet-50 and AlexNet on the scale of 1024 nodes.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 14:53:35 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Fang", "Jiarui", ""], ["Li", "Liandeng", ""], ["Fu", "Haohuan", ""], ["Jiang", "Jinlei", ""], ["Zhao", "Wenlai", ""], ["He", "Conghui", ""], ["You", "Xin", ""], ["Yang", "Guangwen", ""]]}, {"id": "1903.06996", "submitter": "Cong Xie", "authors": "Cong Xie, Sanmi Koyejo, Indranil Gupta", "title": "SLSGD: Secure and Efficient Distributed On-device Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed on-device learning with limited communication and\nsecurity requirements. We propose a new robust distributed optimization\nalgorithm with efficient communication and attack tolerance. The proposed\nalgorithm has provable convergence and robustness under non-IID settings.\nEmpirical results show that the proposed algorithm stabilizes the convergence\nand tolerates data poisoning on a small number of workers.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 22:25:20 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 16:53:40 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 20:12:18 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Xie", "Cong", ""], ["Koyejo", "Sanmi", ""], ["Gupta", "Indranil", ""]]}, {"id": "1903.06999", "submitter": "Yang Zheng", "authors": "Yang Zheng, Izzat H. Izzat, Shahrzad Ziaee", "title": "GFD-SSD: Gated Fusion Double SSD for Multispectral Pedestrian Detection", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pedestrian detection is an essential task in autonomous driving research. In\naddition to typical color images, thermal images benefit the detection in dark\nenvironments. Hence, it is worthwhile to explore an integrated approach to take\nadvantage of both color and thermal images simultaneously. In this paper, we\npropose a novel approach to fuse color and thermal sensors using deep neural\nnetworks (DNN). Current state-of-the-art DNN object detectors vary from\ntwo-stage to one-stage mechanisms. Two-stage detectors, like Faster-RCNN,\nachieve higher accuracy, while one-stage detectors such as Single Shot Detector\n(SSD) demonstrate faster performance. To balance the trade-off, especially in\nthe consideration of autonomous driving applications, we investigate a fusion\nstrategy to combine two SSDs on color and thermal inputs. Traditional fusion\nmethods stack selected features from each channel and adjust their weights. In\nthis paper, we propose two variations of novel Gated Fusion Units (GFU), that\nlearn the combination of feature maps generated by the two SSD middle layers.\nLeveraging GFUs for the entire feature pyramid structure, we propose several\nmixed versions of both stack fusion and gated fusion. Experiments are conducted\non the KAIST multispectral pedestrian detection dataset. Our Gated Fusion\nDouble SSD (GFD-SSD) outperforms the stacked fusion and achieves the lowest\nmiss rate in the benchmark, at an inference speed that is two times faster than\nFaster-RCNN based fusion networks.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 22:55:47 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 22:48:57 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Zheng", "Yang", ""], ["Izzat", "Izzat H.", ""], ["Ziaee", "Shahrzad", ""]]}, {"id": "1903.07003", "submitter": "Charlott Vallon", "authors": "Charlott Vallon and Francesco Borrelli", "title": "Task Decomposition for Iterative Learning Model Predictive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A task decomposition method for iterative learning model predictive control\nis presented. We consider a constrained nonlinear dynamical system and assume\nthe availability of state-input pair datasets which solve a task T1. Our\nobjective is to find a feasible model predictive control policy for a second\ntask, T2, using stored data from T1. Our approach applies to tasks T2 which are\ncomposed of subtasks contained in T1. In this paper we propose a formal\ndefinition of subtasks and the task decomposition problem, and provide proofs\nof feasibility and iteration cost improvement over simple initializations. We\ndemonstrate the effectiveness of the proposed method on autonomous racing and\nrobotic manipulation experiments.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 23:55:05 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 15:12:34 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 01:30:01 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 23:16:50 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Vallon", "Charlott", ""], ["Borrelli", "Francesco", ""]]}, {"id": "1903.07020", "submitter": "Cong Xie", "authors": "Cong Xie, Sanmi Koyejo, Indranil Gupta", "title": "Zeno++: Robust Fully Asynchronous SGD", "comments": "ICML version with some additional remarks related to the acceptance\n  rate of Byzantine validation, and also with the full version of error bounds\n  in the theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Zeno++, a new robust asynchronous Stochastic Gradient\nDescent~(SGD) procedure which tolerates Byzantine failures of the workers. In\ncontrast to previous work, Zeno++ removes some unrealistic restrictions on\nworker-server communications, allowing for fully asynchronous updates from\nanonymous workers, arbitrarily stale worker updates, and the possibility of an\nunbounded number of Byzantine workers. The key idea is to estimate the descent\nof the loss value after the candidate gradient is applied, where large descent\nvalues indicate that the update results in optimization progress. We prove the\nconvergence of Zeno++ for non-convex problems under Byzantine failures.\nExperimental results show that Zeno++ outperforms existing approaches.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 03:02:32 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 05:22:43 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 08:19:39 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2019 22:01:24 GMT"}, {"version": "v5", "created": "Sun, 9 May 2021 17:42:44 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Xie", "Cong", ""], ["Koyejo", "Sanmi", ""], ["Gupta", "Indranil", ""]]}, {"id": "1903.07027", "submitter": "James Gornet", "authors": "James Gornet, Kannan Umadevi Venkataraju, Arun Narasimhan, Nicholas\n  Turner, Kisuk Lee, H. Sebastian Seung, Pavel Osten, Uygar S\\\"umb\\\"ul", "title": "Reconstructing neuronal anatomy from whole-brain images", "comments": "2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing multiple molecularly defined neurons from individual brains\nand across multiple brain regions can reveal organizational principles of the\nnervous system. However, high resolution imaging of the whole brain is a\ntechnically challenging and slow process. Recently, oblique light sheet\nmicroscopy has emerged as a rapid imaging method that can provide whole brain\nfluorescence microscopy at a voxel size of 0.4 by 0.4 by 2.5 cubic microns. On\nthe other hand, complex image artifacts due to whole-brain coverage produce\napparent discontinuities in neuronal arbors. Here, we present\nconnectivity-preserving methods and data augmentation strategies for supervised\nlearning of neuroanatomy from light microscopy using neural networks. We\nquantify the merit of our approach by implementing an end-to-end automated\ntracing pipeline. Lastly, we demonstrate a scalable, distributed implementation\nthat can reconstruct the large datasets that sub-micron whole-brain images\nproduce.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 05:06:29 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Gornet", "James", ""], ["Venkataraju", "Kannan Umadevi", ""], ["Narasimhan", "Arun", ""], ["Turner", "Nicholas", ""], ["Lee", "Kisuk", ""], ["Seung", "H. Sebastian", ""], ["Osten", "Pavel", ""], ["S\u00fcmb\u00fcl", "Uygar", ""]]}, {"id": "1903.07045", "submitter": "Ali Mirzaei", "authors": "Ali Mirzaei, Vahid Pourahmadi, Mehran Soltani, Hamid Sheikhzadeh", "title": "Deep Feature Selection using a Teacher-Student Network", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data in many machine learning applications leads to\ncomputational and analytical complexities. Feature selection provides an\neffective way for solving these problems by removing irrelevant and redundant\nfeatures, thus reducing model complexity and improving accuracy and\ngeneralization capability of the model. In this paper, we present a novel\nteacher-student feature selection (TSFS) method in which a 'teacher' (a deep\nneural network or a complicated dimension reduction method) is first employed\nto learn the best representation of data in low dimension. Then a 'student'\nnetwork (a simple neural network) is used to perform feature selection by\nminimizing the reconstruction error of low dimensional representation. Although\nthe teacher-student scheme is not new, to the best of our knowledge, it is the\nfirst time that this scheme is employed for feature selection. The proposed\nTSFS can be used for both supervised and unsupervised feature selection. This\nmethod is evaluated on different datasets and is compared with state-of-the-art\nexisting feature selection methods. The results show that TSFS performs better\nin terms of classification and clustering accuracies and reconstruction error.\nMoreover, experimental evaluations demonstrate a low degree of sensitivity to\nparameter selection in the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 09:07:41 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Mirzaei", "Ali", ""], ["Pourahmadi", "Vahid", ""], ["Soltani", "Mehran", ""], ["Sheikhzadeh", "Hamid", ""]]}, {"id": "1903.07050", "submitter": "Arunselvan Ramaswamy Dr.", "authors": "Arunselvan Ramaswamy", "title": "DSPG: Decentralized Simultaneous Perturbations Gradient Descent Scheme", "comments": "6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed descent-based methods are an essential toolset to solving\noptimization problems in multi-agent system scenarios. Here the agents seek to\noptimize a global objective function through mutual cooperation. Oftentimes,\ncooperation is achieved over a wireless communication network that is prone to\ndelays and errors. There are many scenarios wherein the objective function is\neither non-differentiable or merely observable. In this paper, we present a\ncross-entropy based distributed stochastic approximation algorithm (SA) that\nfinds a minimum of the objective, using only samples. We call this algorithm\nDecentralized Simultaneous Perturbation Stochastic Gradient, with Constant\nSensitivity Parameters (DSPG). This algorithm is a two fold improvement over\nthe classic Simultaneous Perturbation Stochastic Approximations (SPSA)\nalgorithm. Specifically, DSPG allows for (i) the use of old information from\nother agents and (ii) easy implementation through the use simple\nhyper-parameter choices. We analyze the biases and variances that arise due to\nthese two allowances. We show that the biases due to communication delays can\nbe countered by a careful choice of algorithm hyper-parameters. The variance of\nthe gradient estimator and its effect on the rate of convergence is studied. We\npresent numerical results supporting our theory. Finally, we discuss an\napplication to the stochastic consensus problem.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 09:51:18 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 10:31:43 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ramaswamy", "Arunselvan", ""]]}, {"id": "1903.07054", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Adversarial Attacks on Deep Neural Networks for Time Series\n  Classification", "comments": "Accepted at IJCNN 2019", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8851936", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time Series Classification (TSC) problems are encountered in many real life\ndata mining tasks ranging from medicine and security to human activity\nrecognition and food safety. With the recent success of deep neural networks in\nvarious domains such as computer vision and natural language processing,\nresearchers started adopting these techniques for solving time series data\nmining problems. However, to the best of our knowledge, no previous work has\nconsidered the vulnerability of deep learning models to adversarial time series\nexamples, which could potentially make them unreliable in situations where the\ndecision taken by the classifier is crucial such as in medicine and security.\nFor computer vision problems, such attacks have been shown to be very easy to\nperform by altering the image and adding an imperceptible amount of noise to\ntrick the network into wrongly classifying the input image. Following this line\nof work, we propose to leverage existing adversarial attack mechanisms to add a\nspecial noise to the input time series in order to decrease the network's\nconfidence when classifying instances at test time. Our results reveal that\ncurrent state-of-the-art deep learning time series classifiers are vulnerable\nto adversarial attacks which can have major consequences in multiple domains\nsuch as food safety and quality assurance.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 10:04:23 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 12:21:18 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1903.07058", "submitter": "Kai Tian", "authors": "Kai Tian, Shuigeng Zhou, Jianping Fan, Jihong Guan", "title": "Learning Competitive and Discriminative Reconstructions for Anomaly\n  Detection", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing methods for anomaly detection use only positive data to\nlearn the data distribution, thus they usually need a pre-defined threshold at\nthe detection stage to determine whether a test instance is an outlier.\nUnfortunately, a good threshold is vital for the performance and it is really\nhard to find an optimal one. In this paper, we take the discriminative\ninformation implied in unlabeled data into consideration and propose a new\nmethod for anomaly detection that can learn the labels of unlabelled data\ndirectly. Our proposed method has an end-to-end architecture with one encoder\nand two decoders that are trained to model inliers and outliers' data\ndistributions in a competitive way. This architecture works in a discriminative\nmanner without suffering from overfitting, and the training algorithm of our\nmodel is adopted from SGD, thus it is efficient and scalable even for\nlarge-scale datasets. Empirical studies on 7 datasets including KDD99, MNIST,\nCaltech-256, and ImageNet etc. show that our model outperforms the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 11:02:24 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Tian", "Kai", ""], ["Zhou", "Shuigeng", ""], ["Fan", "Jianping", ""], ["Guan", "Jihong", ""]]}, {"id": "1903.07082", "submitter": "Maryam Aziz", "authors": "Maryam Aziz, Emilie Kaufmann, Marie-Karelle Riviere", "title": "On Multi-Armed Bandit Designs for Dose-Finding Clinical Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding the optimal dosage in early stage clinical\ntrials through the multi-armed bandit lens. We advocate the use of the Thompson\nSampling principle, a flexible algorithm that can accommodate different types\nof monotonicity assumptions on the toxicity and efficacy of the doses. For the\nsimplest version of Thompson Sampling, based on a uniform prior distribution\nfor each dose, we provide finite-time upper bounds on the number of sub-optimal\ndose selections, which is unprecedented for dose-finding algorithms. Through a\nlarge simulation study, we then show that variants of Thompson Sampling based\non more sophisticated prior distributions outperform state-of-the-art dose\nidentification algorithms in different types of dose-finding studies that occur\nin phase I or phase I/II trials.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 13:28:27 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 18:53:17 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Aziz", "Maryam", ""], ["Kaufmann", "Emilie", ""], ["Riviere", "Marie-Karelle", ""]]}, {"id": "1903.07091", "submitter": "Naveen Arivazhagan", "authors": "Naveen Arivazhagan, Ankur Bapna, Orhan Firat, Roee Aharoni, Melvin\n  Johnson, Wolfgang Macherey", "title": "The Missing Ingredient in Zero-Shot Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual Neural Machine Translation (NMT) models are capable of\ntranslating between multiple source and target languages. Despite various\napproaches to train such models, they have difficulty with zero-shot\ntranslation: translating between language pairs that were not together seen\nduring training. In this paper we first diagnose why state-of-the-art\nmultilingual NMT models that rely purely on parameter sharing, fail to\ngeneralize to unseen language pairs. We then propose auxiliary losses on the\nNMT encoder that impose representational invariance across languages. Our\nsimple approach vastly improves zero-shot translation quality without\nregressing on supervised directions. For the first time, on WMT14\nEnglish-FrenchGerman, we achieve zero-shot performance that is on par with\npivoting. We also demonstrate the easy scalability of our approach to multiple\nlanguages on the IWSLT 2017 shared task.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 14:01:53 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Arivazhagan", "Naveen", ""], ["Bapna", "Ankur", ""], ["Firat", "Orhan", ""], ["Aharoni", "Roee", ""], ["Johnson", "Melvin", ""], ["Macherey", "Wolfgang", ""]]}, {"id": "1903.07097", "submitter": "Abdullah Alomar", "authors": "Anish Agarwal, Abdullah Alomar, Devavrat Shah", "title": "tspDB: Time Series Predict DB", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major bottleneck of the current Machine Learning (ML) workflow is the time\nconsuming, error prone engineering required to get data from a datastore or a\ndatabase (DB) to the point an ML algorithm can be applied to it. Hence, we\nexplore the feasibility of directly integrating prediction functionality on top\nof a data store or DB. Such a system ideally: (i) provides an intuitive\nprediction query interface which alleviates the unwieldy data engineering; (ii)\nprovides state-of-the-art statistical accuracy while ensuring incremental model\nupdate, low model training time and low latency for making predictions. As the\nmain contribution we explicitly instantiate a proof-of-concept, tspDB, which\ndirectly integrates with PostgreSQL. We rigorously test tspDB's statistical and\ncomputational performance against the state-of-the-art time series algorithms,\nincluding a Long-Short-Term-Memory (LSTM) neural network and DeepAR (industry\nstandard deep learning library by Amazon). Statistically, on standard time\nseries benchmarks, tspDB outperforms LSTM and DeepAR with 1.1-1.3x higher\nrelative accuracy. Computationally, tspDB is 59-62x and 94-95x faster compared\nto LSTM and DeepAR in terms of median ML model training time and prediction\nquery latency, respectively. Further, compared to PostgreSQL's bulk insert time\nand its SELECT query latency, tspDB is slower only by 1.3x and 2.6x\nrespectively. That is, tspDB is a real-time prediction system in that its model\ntraining / prediction query time is similar to just inserting / reading data\nfrom a DB. As an algorithmic contribution, we introduce an incremental\nmultivariate matrix factorization based time series method, which tspDB is\nbuilt off. We show this method also allows one to produce reliable prediction\nintervals by accurately estimating the time-varying variance of a time series,\nthereby addressing an important problem in time series analysis.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 14:28:50 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 00:43:53 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 04:55:58 GMT"}, {"version": "v4", "created": "Wed, 24 Jun 2020 03:12:35 GMT"}, {"version": "v5", "created": "Fri, 10 Jul 2020 20:41:47 GMT"}, {"version": "v6", "created": "Sat, 12 Dec 2020 20:31:12 GMT"}, {"version": "v7", "created": "Sat, 13 Feb 2021 17:58:59 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Agarwal", "Anish", ""], ["Alomar", "Abdullah", ""], ["Shah", "Devavrat", ""]]}, {"id": "1903.07120", "submitter": "Huishuai Zhang", "authors": "Huishuai Zhang, Da Yu, Mingyang Yi, Wei Chen, Tie-Yan Liu", "title": "Convergence Theory of Learning Over-parameterized ResNet: A Full\n  Characterization", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ResNet structure has achieved great empirical success since its debut. Recent\nwork established the convergence of learning over-parameterized ResNet with a\nscaling factor $\\tau=1/L$ on the residual branch where $L$ is the network\ndepth. However, it is not clear how learning ResNet behaves for other values of\n$\\tau$. In this paper, we fully characterize the convergence theory of gradient\ndescent for learning over-parameterized ResNet with different values of $\\tau$.\nSpecifically, with hiding logarithmic factor and constant coefficients, we show\nthat for $\\tau\\le 1/\\sqrt{L}$ gradient descent is guaranteed to converge to the\nglobal minma, and especially when $\\tau\\le 1/L$ the convergence is irrelevant\nof the network depth. Conversely, we show that for $\\tau>L^{-\\frac{1}{2}+c}$,\nthe forward output grows at least with rate $L^c$ in expectation and then the\nlearning fails because of gradient explosion for large $L$. This means the\nbound $\\tau\\le 1/\\sqrt{L}$ is sharp for learning ResNet with arbitrary depth.\nTo the best of our knowledge, this is the first work that studies learning\nResNet with full range of $\\tau$.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 16:15:56 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 05:45:07 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 08:03:07 GMT"}, {"version": "v4", "created": "Fri, 12 Jul 2019 08:33:44 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Zhang", "Huishuai", ""], ["Yu", "Da", ""], ["Yi", "Mingyang", ""], ["Chen", "Wei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1903.07138", "submitter": "Decebal Constantin Mocanu", "authors": "Joost Pieterse and Decebal Constantin Mocanu", "title": "Evolving and Understanding Sparse Deep Neural Networks using Cosine\n  Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training sparse neural networks with adaptive connectivity is an active\nresearch topic. Such networks require less storage and have lower computational\ncomplexity compared to their dense counterparts. The Sparse Evolutionary\nTraining (SET) procedure uses weights magnitude to evolve efficiently the\ntopology of a sparse network to fit the dataset, while enabling it to have\nquadratically less parameters than its dense counterpart. To this end, we\npropose a novel approach that evolves a sparse network topology based on the\nbehavior of neurons in the network. More exactly, the cosine similarities\nbetween the activations of any two neurons are used to determine which\nconnections are added to or removed from the network. By integrating our\napproach within the SET procedure, we propose 5 new algorithms to train sparse\nneural networks. We argue that our approach has low additional computational\ncomplexity and we draw a parallel to Hebbian learning. Experiments are\nperformed on 8 datasets taken from various domains to demonstrate the general\napplicability of our approach. Even without optimizing hyperparameters for\nspecific datasets, the experiments show that our proposed training algorithms\nusually outperform SET and state-of-the-art dense neural network techniques.\nThe last but not the least, we show that the evolved connectivity patterns of\nthe input neurons reflect their impact on the classification task.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 17:45:10 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Pieterse", "Joost", ""], ["Mocanu", "Decebal Constantin", ""]]}, {"id": "1903.07154", "submitter": "Dipan Pal", "authors": "Raied Aljadaany, Dipan K. Pal and Marios Savvides", "title": "Proximal Splitting Networks for Image Restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image restoration problems are typically ill-posed requiring the design of\nsuitable priors. These priors are typically hand-designed and are fully\ninstantiated throughout the process. In this paper, we introduce a novel\nframework for handling inverse problems related to image restoration based on\nelements from the half quadratic splitting method and proximal operators.\nModeling the proximal operator as a convolutional network, we defined an\nimplicit prior on the image space as a function class during training. This is\nin contrast to the common practice in literature of having the prior to be\nfixed and fully instantiated even during training stages. Further, we allow\nthis proximal operator to be tuned differently for each iteration which greatly\nincreases modeling capacity and allows us to reduce the number of iterations by\nan order of magnitude as compared to other approaches. Our final network is an\nend-to-end one whose run time matches the previous fastest algorithms while\noutperforming them in recovery fidelity on two image restoration tasks. Indeed,\nwe find our approach achieves state-of-the-art results on benchmarks in image\ndenoising and image super resolution while recovering more complex and finer\ndetails.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 19:36:52 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Aljadaany", "Raied", ""], ["Pal", "Dipan K.", ""], ["Savvides", "Marios", ""]]}, {"id": "1903.07157", "submitter": "Jiaxiao Zheng", "authors": "Jiaxiao Zheng and Gustavo de Veciana", "title": "Modeling and Optimization of Human-machine Interaction Processes via the\n  Maximum Entropy Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven framework to enable the modeling and optimization of\nhuman-machine interaction processes, e.g., systems aimed at assisting humans in\ndecision-making or learning, work-load allocation, and interactive advertising.\nThis is a challenging problem for several reasons. First, humans' behavior is\nhard to model or infer, as it may reflect biases, long term memory, and\nsensitivity to sequencing, i.e., transience and exponential complexity in the\nlength of the interaction. Second, due to the interactive nature of such\nprocesses, the machine policy used to engage with a human may bias possible\ndata-driven inferences. Finally, in choosing machine policies that optimize\ninteraction rewards, one must, on the one hand, avoid being overly sensitive to\nerror/variability in the estimated human model, and on the other, being overly\ndeterministic/predictable which may result in poor human 'engagement' in the\ninteraction. To meet these challenges, we propose a robust approach, based on\nthe maximum entropy principle, which iteratively estimates human behavior and\noptimizes the machine policy--Alternating Entropy-Reward Ascent (AREA)\nalgorithm. We characterize AREA, in terms of its space and time complexity and\nconvergence. We also provide an initial validation based on synthetic data\ngenerated by an established noisy nonlinear model for human decision-making.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 20:14:04 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Zheng", "Jiaxiao", ""], ["de Veciana", "Gustavo", ""]]}, {"id": "1903.07167", "submitter": "Ripon Patgiri", "authors": "Ripon Patgiri, Sabuzima Nayak, Tanya Akutota, and Bishal Paul", "title": "Machine Learning: A Dark Side of Cancer Computing", "comments": "7 Pages, 21 Figures, 2 Tables, Proceedings of the 2018 International\n  Conference on Bioinformatics and Computational Biology, pp. 92-98, 2018", "journal-ref": "Proceedings of the 2018 International Conference on Bioinformatics\n  and Computational Biology, pp. 92-98, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer analysis and prediction is the utmost important research field for\nwell-being of humankind. The Cancer data are analyzed and predicted using\nmachine learning algorithms. Most of the researcher claims the accuracy of the\npredicted results within 99%. However, we show that machine learning algorithms\ncan easily predict with an accuracy of 100% on Wisconsin Diagnostic Breast\nCancer dataset. We show that the method of gaining accuracy is an unethical\napproach that we can easily mislead the algorithms. In this paper, we exploit\nthe weakness of Machine Learning algorithms. We perform extensive experiments\nfor the correctness of our results to exploit the weakness of machine learning\nalgorithms. The methods are rigorously evaluated to validate our claim. In\naddition, this paper focuses on correctness of accuracy. This paper report\nthree key outcomes of the experiments, namely, correctness of accuracies,\nsignificance of minimum accuracy, and correctness of machine learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 20:44:25 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Patgiri", "Ripon", ""], ["Nayak", "Sabuzima", ""], ["Akutota", "Tanya", ""], ["Paul", "Bishal", ""]]}, {"id": "1903.07173", "submitter": "Mostafa Mehdipour Ghazi", "authors": "Mostafa Mehdipour Ghazi, Mads Nielsen, Akshay Pai, M. Jorge Cardoso,\n  Marc Modat, Sebastien Ourselin, Lauge S{\\o}rensen", "title": "Training recurrent neural networks robust to incomplete data:\n  application to Alzheimer's disease progression modeling", "comments": "arXiv admin note: substantial text overlap with arXiv:1808.05500", "journal-ref": "Medical Image Analysis, Volume 53, Pages 39-46, 2019", "doi": "10.1016/j.media.2019.01.004", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disease progression modeling (DPM) using longitudinal data is a challenging\nmachine learning task. Existing DPM algorithms neglect temporal dependencies\namong measurements, make parametric assumptions about biomarker trajectories,\ndo not model multiple biomarkers jointly, and need an alignment of subjects'\ntrajectories. In this paper, recurrent neural networks (RNNs) are utilized to\naddress these issues. However, in many cases, longitudinal cohorts contain\nincomplete data, which hinders the application of standard RNNs and requires a\npre-processing step such as imputation of the missing values. Instead, we\npropose a generalized training rule for the most widely used RNN architecture,\nlong short-term memory (LSTM) networks, that can handle both missing predictor\nand target values. The proposed LSTM algorithm is applied to model the\nprogression of Alzheimer's disease (AD) using six volumetric magnetic resonance\nimaging (MRI) biomarkers, i.e., volumes of ventricles, hippocampus, whole\nbrain, fusiform, middle temporal gyrus, and entorhinal cortex, and it is\ncompared to standard LSTM networks with data imputation and a parametric,\nregression-based DPM method. The results show that the proposed algorithm\nachieves a significantly lower mean absolute error (MAE) than the alternatives\nwith p < 0.05 using Wilcoxon signed rank test in predicting values of almost\nall of the MRI biomarkers. Moreover, a linear discriminant analysis (LDA)\nclassifier applied to the predicted biomarker values produces a significantly\nlarger AUC of 0.90 vs. at most 0.84 with p < 0.001 using McNemar's test for\nclinical diagnosis of AD. Inspection of MAE curves as a function of the amount\nof missing data reveals that the proposed LSTM algorithm achieves the best\nperformance up until more than 74% missing values. Finally, it is illustrated\nhow the method can successfully be applied to data with varying time intervals.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 21:14:33 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Ghazi", "Mostafa Mehdipour", ""], ["Nielsen", "Mads", ""], ["Pai", "Akshay", ""], ["Cardoso", "M. Jorge", ""], ["Modat", "Marc", ""], ["Ourselin", "Sebastien", ""], ["S\u00f8rensen", "Lauge", ""]]}, {"id": "1903.07181", "submitter": "Keith Dillon", "authors": "Keith Dillon", "title": "On the Computation and Applications of Large Dense Partial Correlation\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While sparse inverse covariance matrices are very popular for modeling\nnetwork connectivity, the value of the dense solution is often overlooked. In\nfact the L2-regularized solution has deep connections to a number of important\napplications to spectral graph theory, dimensionality reduction, and\nuncertainty quantification. We derive an approach to directly compute the\npartial correlations based on concepts from inverse problem theory. This\napproach also leads to new insights on open problems such as model selection\nand data preprocessing, as well as new approaches which relate the above\napplication areas.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 21:46:25 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Dillon", "Keith", ""]]}, {"id": "1903.07214", "submitter": "Victor Dorobantu", "authors": "Andrew J. Taylor, Victor D. Dorobantu, Meera Krishnamoorthy, Hoang M.\n  Le, Yisong Yue, Aaron D. Ames", "title": "A Control Lyapunov Perspective on Episodic Learning via Projection to\n  State Stability", "comments": null, "journal-ref": null, "doi": "10.1109/CDC40024.2019.9029226", "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to understand the impact of learning on control\nsynthesis from a Lyapunov function perspective. In particular, rather than\nconsider uncertainties in the full system dynamics, we employ Control Lyapunov\nFunctions (CLFs) as low-dimensional projections. To understand and characterize\nthe uncertainty that these projected dynamics introduce in the system, we\nintroduce a new notion: Projection to State Stability (PSS). PSS can be viewed\nas a variant of Input to State Stability defined on projected dynamics, and\nenables characterizing robustness of a CLF with respect to the data used to\nlearn system uncertainties. We use PSS to bound uncertainty in affine control,\nand demonstrate that a practical episodic learning approach can use PSS to\ncharacterize uncertainty in the CLF for robust control synthesis.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 00:50:57 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Taylor", "Andrew J.", ""], ["Dorobantu", "Victor D.", ""], ["Krishnamoorthy", "Meera", ""], ["Le", "Hoang M.", ""], ["Yue", "Yisong", ""], ["Ames", "Aaron D.", ""]]}, {"id": "1903.07227", "submitter": "Cheng-Zhi Anna Huang", "authors": "Cheng-Zhi Anna Huang, Tim Cooijmans, Adam Roberts, Aaron Courville,\n  Douglas Eck", "title": "Counterpoint by Convolution", "comments": "Proceedings of the 18th International Society for Music Information\n  Retrieval Conference, ISMIR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models of music typically break up the task of composition\ninto a chronological process, composing a piece of music in a single pass from\nbeginning to end. On the contrary, human composers write music in a nonlinear\nfashion, scribbling motifs here and there, often revisiting choices previously\nmade. In order to better approximate this process, we train a convolutional\nneural network to complete partial musical scores, and explore the use of\nblocked Gibbs sampling as an analogue to rewriting. Neither the model nor the\ngenerative procedure are tied to a particular causal direction of composition.\nOur model is an instance of orderless NADE (Uria et al., 2014), which allows\nmore direct ancestral sampling. However, we find that Gibbs sampling greatly\nimproves sample quality, which we demonstrate to be due to some conditional\ndistributions being poorly modeled. Moreover, we show that even the cheap\napproximate blocked Gibbs procedure from Yao et al. (2014) yields better\nsamples than ancestral sampling, based on both log-likelihood and human\nevaluation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 02:04:23 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Huang", "Cheng-Zhi Anna", ""], ["Cooijmans", "Tim", ""], ["Roberts", "Adam", ""], ["Courville", "Aaron", ""], ["Eck", "Douglas", ""]]}, {"id": "1903.07266", "submitter": "Usman Khan", "authors": "Ran Xin, Anit Kumar Sahu, Usman A. Khan, and Soummya Kar", "title": "Distributed stochastic optimization with gradient tracking over\n  strongly-connected networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study distributed stochastic optimization to minimize a sum\nof smooth and strongly-convex local cost functions over a network of agents,\ncommunicating over a strongly-connected graph. Assuming that each agent has\naccess to a stochastic first-order oracle ($\\mathcal{SFO}$), we propose a novel\ndistributed method, called $\\mathcal{S}$-$\\mathcal{AB}$, where each agent uses\nan auxiliary variable to asymptotically track the gradient of the global cost\nin expectation. The $\\mathcal{S}$-$\\mathcal{AB}$ algorithm employs row- and\ncolumn-stochastic weights simultaneously to ensure both consensus and\noptimality. Since doubly-stochastic weights are not used,\n$\\mathcal{S}$-$\\mathcal{AB}$ is applicable to arbitrary strongly-connected\ngraphs. We show that under a sufficiently small constant step-size,\n$\\mathcal{S}$-$\\mathcal{AB}$ converges linearly (in expected mean-square sense)\nto a neighborhood of the global minimizer. We present numerical simulations\nbased on real-world data sets to illustrate the theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 06:29:08 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 22:23:17 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Xin", "Ran", ""], ["Sahu", "Anit Kumar", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "1903.07272", "submitter": "Omid Bazgir", "authors": "Omid Bazgir, Zeynab Mohammadi, Seyed Amir Hassan Habibi", "title": "Emotion Recognition with Machine Learning Using EEG Signals", "comments": null, "journal-ref": "2018 25th National and 3rd International Iranian Conference on\n  Biomedical Engineering (ICBME)(pp. 1-5). IEEE", "doi": "10.1109/ICBME.2018.8703559", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, an emotion recognition system is developed based on\nvalence/arousal model using electroencephalography (EEG) signals. EEG signals\nare decomposed into the gamma, beta, alpha and theta frequency bands using\ndiscrete wavelet transform (DWT), and spectral features are extracted from each\nfrequency band. Principle component analysis (PCA) is applied to the extracted\nfeatures by preserving the same dimensionality, as a transform, to make the\nfeatures mutually uncorrelated. Support vector machine (SVM), K-nearest\nneighbor (KNN) and artificial neural network (ANN) are used to classify\nemotional states. The cross-validated SVM with radial basis function (RBF)\nkernel using extracted features of 10 EEG channels, performs with 91.3%\naccuracy for arousal and 91.1% accuracy for valence, both in the beta frequency\nband. Our approach shows better performance compared to existing algorithms\napplied to the \"DEAP\" dataset.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 06:49:05 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 04:22:53 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bazgir", "Omid", ""], ["Mohammadi", "Zeynab", ""], ["Habibi", "Seyed Amir Hassan", ""]]}, {"id": "1903.07273", "submitter": "Michael Biehl", "authors": "Michael Biehl, Fthi Abadi, Christina G\u007f\\\"opfert, and Barbara Hammer", "title": "Prototype-based classifiers in the presence of concept drift: A\n  modelling framework", "comments": "Accepted contribution to WSOM+ 2019, Barcelona/Spain, June 2019 13th\n  International Workshop on Self-Organizing Maps and Learning Vector\n  Quantization, Clustering and Data Visualization 11 pages", "journal-ref": null, "doi": "10.1007/978-3-030-19642-4", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modelling framework for the investigation of prototype-based\nclassifiers in non-stationary environments. Specifically, we study Learning\nVector Quantization (LVQ) systems trained from a stream of high-dimensional,\nclustered data.We consider standard winner-takes-all updates known as LVQ1.\nStatistical properties of the input data change on the time scale defined by\nthe training process. We apply analytical methods borrowed from statistical\nphysics which have been used earlier for the exact description of learning in\nstationary environments. The suggested framework facilitates the computation of\nlearning curves in the presence of virtual and real concept drift. Here we\nfocus on timedependent class bias in the training data. First results\ndemonstrate that, while basic LVQ algorithms are suitable for the training in\nnon-stationary environments, weight decay as an explicit mechanism of\nforgetting does not improve the performance under the considered drift\nprocesses.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 06:51:03 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Biehl", "Michael", ""], ["Abadi", "Fthi", ""], ["G\u007f\u00f6pfert", "Christina", ""], ["Hammer", "Barbara", ""]]}, {"id": "1903.07282", "submitter": "Kaitao Song", "authors": "Ping Yu, Kaitao Song, Jianfeng Lu", "title": "Generating Adversarial Examples With Conditional Generative Adversarial\n  Net", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks have significant progress and successful\napplication in various fields, but they are found vulnerable to attack\ninstances, e.g., adversarial examples. State-of-art attack methods can generate\nattack images by adding small perturbation to the source image. These attack\nimages can fool the classifier but have little impact to human. Therefore, such\nattack instances are difficult to generate by searching the feature space. How\nto design an effective and robust generating method has become a spotlight.\nInspired by adversarial examples, we propose two novel generative models to\nproduce adaptive attack instances directly, in which conditional generative\nadversarial network is adopted and distinctive strategy is designed for\ntraining. Compared with the common method, such as Fast Gradient Sign Method,\nour models can reduce the generating cost and improve robustness and has about\none fifth running time for producing attack instance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 07:33:35 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Yu", "Ping", ""], ["Song", "Kaitao", ""], ["Lu", "Jianfeng", ""]]}, {"id": "1903.07288", "submitter": "Mahidhar Dwarampudi", "authors": "Mahidhar Dwarampudi, N V Subba Reddy", "title": "Effects of padding on LSTMs and CNNs", "comments": "5 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Long Short-Term Memory (LSTM) Networks and Convolutional Neural Networks\n(CNN) have become very common and are used in many fields as they were\neffective in solving many problems where the general neural networks were\ninefficient. They were applied to various problems mostly related to images and\nsequences. Since LSTMs and CNNs take inputs of the same length and dimension,\ninput images and sequences are padded to maximum length while testing and\ntraining. This padding can affect the way the networks function and can make a\ngreat deal when it comes to performance and accuracies. This paper studies this\nand suggests the best way to pad an input sequence. This paper uses a simple\nsentiment analysis task for this purpose. We use the same dataset on both the\nnetworks with various padding to show the difference. This paper also discusses\nsome preprocessing techniques done on the data to ensure effective analysis of\nthe data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 07:52:59 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Dwarampudi", "Mahidhar", ""], ["Reddy", "N V Subba", ""]]}, {"id": "1903.07291", "submitter": "Ming-Yu Liu", "authors": "Taesung Park, Ming-Yu Liu, Ting-Chun Wang, Jun-Yan Zhu", "title": "Semantic Image Synthesis with Spatially-Adaptive Normalization", "comments": "Accepted as a CVPR 2019 oral paper", "journal-ref": "CVPR 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose spatially-adaptive normalization, a simple but effective layer for\nsynthesizing photorealistic images given an input semantic layout. Previous\nmethods directly feed the semantic layout as input to the deep network, which\nis then processed through stacks of convolution, normalization, and\nnonlinearity layers. We show that this is suboptimal as the normalization\nlayers tend to ``wash away'' semantic information. To address the issue, we\npropose using the input layout for modulating the activations in normalization\nlayers through a spatially-adaptive, learned transformation. Experiments on\nseveral challenging datasets demonstrate the advantage of the proposed method\nover existing approaches, regarding both visual fidelity and alignment with\ninput layouts. Finally, our model allows user control over both semantic and\nstyle. Code is available at https://github.com/NVlabs/SPADE .\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 08:12:23 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:41:27 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Park", "Taesung", ""], ["Liu", "Ming-Yu", ""], ["Wang", "Ting-Chun", ""], ["Zhu", "Jun-Yan", ""]]}, {"id": "1903.07299", "submitter": "Daniele Grattarola", "authors": "Daniele Zambon, Daniele Grattarola, Lorenzo Livi, Cesare Alippi", "title": "Autoregressive Models for Sequences of Graphs", "comments": "International Joint Conference on Neural Networks (IJCNN) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an autoregressive (AR) model for sequences of graphs,\nwhich generalises traditional AR models. A first novelty consists in\nformalising the AR model for a very general family of graphs, characterised by\na variable topology, and attributes associated with nodes and edges. A graph\nneural network (GNN) is also proposed to learn the AR function associated with\nthe graph-generating process (GGP), and subsequently predict the next graph in\na sequence. The proposed method is compared with four baselines on synthetic\nGGPs, denoting a significantly better performance on all considered problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 08:37:13 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Zambon", "Daniele", ""], ["Grattarola", "Daniele", ""], ["Livi", "Lorenzo", ""], ["Alippi", "Cesare", ""]]}, {"id": "1903.07303", "submitter": "Timo Korthals", "authors": "Timo Korthals", "title": "M$^2$VAE - Derivation of a Multi-Modal Variational Autoencoder Objective\n  from the Marginal Joint Log-Likelihood", "comments": "Appendix for the IEEE FUSION 2019 submission on multi-modal\n  variational Autoencoders for sensor fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work gives an in-depth derivation of the trainable evidence lower bound\nobtained from the marginal joint log-Likelihood with the goal of training a\nMulti-Modal Variational Autoencoder (M$^2$VAE).\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 08:45:27 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Korthals", "Timo", ""]]}, {"id": "1903.07307", "submitter": "Bamdev Mishra", "authors": "Pratik Jawanpuria, Mayank Meghwanshi, and Bamdev Mishra", "title": "Low-rank approximations of hyperbolic embeddings", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hyperbolic manifold is a smooth manifold of negative constant curvature.\nWhile the hyperbolic manifold is well-studied in the literature, it has gained\ninterest in the machine learning and natural language processing communities\nlately due to its usefulness in modeling continuous hierarchies. Tasks with\nhierarchical structures are ubiquitous in those fields and there is a general\ninterest to learning hyperbolic representations or embeddings of such tasks.\nAdditionally, these embeddings of related tasks may also share a low-rank\nsubspace. In this work, we propose to learn hyperbolic embeddings such that\nthey also lie in a low-dimensional subspace. In particular, we consider the\nproblem of learning a low-rank factorization of hyperbolic embeddings. We cast\nthese problems as manifold optimization problems and propose computationally\nefficient algorithms. Empirical results illustrate the efficacy of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 08:50:03 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Jawanpuria", "Pratik", ""], ["Meghwanshi", "Mayank", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1903.07320", "submitter": "Kurt Cutajar", "authors": "Kurt Cutajar, Mark Pullin, Andreas Damianou, Neil Lawrence, Javier\n  Gonz\\'alez", "title": "Deep Gaussian Processes for Multi-fidelity Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-fidelity methods are prominently used when cheaply-obtained, but\npossibly biased and noisy, observations must be effectively combined with\nlimited or expensive true data in order to construct reliable models. This\narises in both fundamental machine learning procedures such as Bayesian\noptimization, as well as more practical science and engineering applications.\nIn this paper we develop a novel multi-fidelity model which treats layers of a\ndeep Gaussian process as fidelity levels, and uses a variational inference\nscheme to propagate uncertainty across them. This allows for capturing\nnonlinear correlations between fidelities with lower risk of overfitting than\nexisting methods exploiting compositional structure, which are conversely\nburdened by structural assumptions and constraints. We show that the proposed\napproach makes substantial improvements in quantifying and propagating\nuncertainty in multi-fidelity set-ups, which in turn improves their\neffectiveness in decision making pipelines.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 09:24:33 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Cutajar", "Kurt", ""], ["Pullin", "Mark", ""], ["Damianou", "Andreas", ""], ["Lawrence", "Neil", ""], ["Gonz\u00e1lez", "Javier", ""]]}, {"id": "1903.07348", "submitter": "Maximilian Soelch", "authors": "Maximilian Soelch, Adnan Akhundov, Patrick van der Smagt, Justin Bayer", "title": "On Deep Set Learning and the Choice of Aggregations", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30487-4_35", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been shown that many functions on sets can be represented by\nsum decompositions. These decompositons easily lend themselves to neural\napproximations, extending the applicability of neural nets to set-valued\ninputs---Deep Set learning. This work investigates a core component of Deep Set\narchitecture: aggregation functions. We suggest and examine alternatives to\ncommonly used aggregation functions, including learnable recurrent aggregation\nfunctions. Empirically, we show that the Deep Set networks are highly sensitive\nto the choice of aggregation functions: beyond improved performance, we find\nthat learnable aggregations lower hyper-parameter sensitivity and generalize\nbetter to out-of-distribution input size.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 10:24:10 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 14:56:07 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Soelch", "Maximilian", ""], ["Akhundov", "Adnan", ""], ["van der Smagt", "Patrick", ""], ["Bayer", "Justin", ""]]}, {"id": "1903.07359", "submitter": "Olga Taran", "authors": "Olga Taran, Slavi Bonev and Slava Voloshynovskiy", "title": "Clonability of anti-counterfeiting printable graphical codes: a machine\n  learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, printable graphical codes have attracted a lot of attention\nenabling a link between the physical and digital worlds, which is of great\ninterest for the IoT and brand protection applications. The security of\nprintable codes in terms of their reproducibility by unauthorized parties or\nclonability is largely unexplored. In this paper, we try to investigate the\nclonability of printable graphical codes from a machine learning perspective.\nThe proposed framework is based on a simple system composed of fully connected\nneural network layers. The results obtained on real codes printed by several\nprinters demonstrate a possibility to accurately estimate digital codes from\ntheir printed counterparts in certain cases. This provides a new insight on\nscenarios, where printable graphical codes can be accurately cloned.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 10:57:36 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Taran", "Olga", ""], ["Bonev", "Slavi", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1903.07377", "submitter": "Johannes Michael", "authors": "Johannes Michael, Roger Labahn, Tobias Gr\\\"uning, Jochen Z\\\"ollner", "title": "Evaluating Sequence-to-Sequence Models for Handwritten Text Recognition", "comments": "8 pages, 1 figure, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder models have become an effective approach for sequence\nlearning tasks like machine translation, image captioning and speech\nrecognition, but have yet to show competitive results for handwritten text\nrecognition. To this end, we propose an attention-based sequence-to-sequence\nmodel. It combines a convolutional neural network as a generic feature\nextractor with a recurrent neural network to encode both the visual\ninformation, as well as the temporal context between characters in the input\nimage, and uses a separate recurrent neural network to decode the actual\ncharacter sequence. We make experimental comparisons between various attention\nmechanisms and positional encodings, in order to find an appropriate alignment\nbetween the input and output sequence. The model can be trained end-to-end and\nthe optional integration of a hybrid loss allows the encoder to retain an\ninterpretable and usable output, if desired. We achieve competitive results on\nthe IAM and ICFHR2016 READ data sets compared to the state-of-the-art without\nthe use of a language model, and we significantly improve over any recent\nsequence-to-sequence approaches.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 11:51:33 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 11:40:53 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Michael", "Johannes", ""], ["Labahn", "Roger", ""], ["Gr\u00fcning", "Tobias", ""], ["Z\u00f6llner", "Jochen", ""]]}, {"id": "1903.07378", "submitter": "Michael Biehl", "authors": "Michiel Straat, Michael Biehl", "title": "On-line learning dynamics of ReLU neural networks using statistical\n  physics techniques", "comments": "Accepted contribution: ESANN 2019, 6 pages European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce exact macroscopic on-line learning dynamics of two-layer neural\nnetworks with ReLU units in the form of a system of differential equations,\nusing techniques borrowed from statistical physics. For the first experiments,\nnumerical solutions reveal similar behavior compared to sigmoidal activation\nresearched in earlier work. In these experiments the theoretical results show\ngood correspondence with simulations. In ove-rrealizable and unrealizable\nlearning scenarios, the learning behavior of ReLU networks shows distinctive\ncharacteristics compared to sigmoidal networks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 12:09:36 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Straat", "Michiel", ""], ["Biehl", "Michael", ""]]}, {"id": "1903.07389", "submitter": "Hamid Karimi", "authors": "Hamid Karimi and Jiliang Tang", "title": "Learning Hierarchical Discourse-level Structure for Fake News Detection", "comments": "Accepted to 2019 Annual Conference of the North American Chapter of\n  the Association for Computational Linguistics June 2-7, 2019 Minneapolis, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  On the one hand, nowadays, fake news articles are easily propagated through\nvarious online media platforms and have become a grand threat to the\ntrustworthiness of information. On the other hand, our understanding of the\nlanguage of fake news is still minimal. Incorporating hierarchical\ndiscourse-level structure of fake and real news articles is one crucial step\ntoward a better understanding of how these articles are structured.\nNevertheless, this has rarely been investigated in the fake news detection\ndomain and faces tremendous challenges. First, existing methods for capturing\ndiscourse-level structure rely on annotated corpora which are not available for\nfake news datasets. Second, how to extract out useful information from such\ndiscovered structures is another challenge. To address these challenges, we\npropose Hierarchical Discourse-level Structure for Fake news detection. HDSF\nlearns and constructs a discourse-level structure for fake/real news articles\nin an automated and data-driven manner. Moreover, we identify insightful\nstructure-related properties, which can explain the discovered structures and\nboost our understating of fake news. Conducted experiments show the\neffectiveness of the proposed approach. Further structural analysis suggests\nthat real and fake news present substantial differences in the hierarchical\ndiscourse-level structures.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 00:03:17 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 01:15:14 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2019 16:18:00 GMT"}, {"version": "v4", "created": "Thu, 4 Apr 2019 02:38:36 GMT"}, {"version": "v5", "created": "Fri, 5 Apr 2019 17:39:05 GMT"}, {"version": "v6", "created": "Wed, 10 Apr 2019 14:20:53 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Karimi", "Hamid", ""], ["Tang", "Jiliang", ""]]}, {"id": "1903.07390", "submitter": "Jorge Gonz\\'alez Ordiano", "authors": "Jorge \\'Angel Gonz\\'alez Ordiano (1), Lutz Gr\\\"oll (1), Ralf Mikut\n  (1), Veit Hagenmeyer (1) ((1) Institute for Automation and Applied\n  Informatics, Karlsruhe Institute of Technology)", "title": "Probabilistic Energy Forecasting using Quantile Regressions based on a\n  new Nearest Neighbors Quantile Filter", "comments": "36 pages, 5 figures, 5 tables", "journal-ref": null, "doi": "10.1016/j.ijforecast.2019.06.003", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parametric quantile regressions are a useful tool for creating probabilistic\nenergy forecasts. Nonetheless, since classical quantile regressions are trained\nusing a non-differentiable cost function, their creation using complex data\nmining techniques (e.g., artificial neural networks) may be complicated. This\narticle presents a method that uses a new nearest neighbors quantile filter to\nobtain quantile regressions independently of the utilized data mining technique\nand without the non-differentiable cost function. Thereafter, a validation of\nthe presented method using the dataset of the Global Energy Forecasting\nCompetition of 2014 is undertaken. The results show that the presented method\nis able to solve the competition's task with a similar accuracy and in a\nsimilar time as the competition's winner, but requiring a much less powerful\ncomputer. This property may be relevant in an online forecasting service for\nwhich the fast computation of probabilistic forecasts using not so powerful\nmachines is required.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 12:41:32 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ordiano", "Jorge \u00c1ngel Gonz\u00e1lez", ""], ["Gr\u00f6ll", "Lutz", ""], ["Mikut", "Ralf", ""], ["Hagenmeyer", "Veit", ""]]}, {"id": "1903.07395", "submitter": "Nicholas Cummins Dr", "authors": "Thomas Wiest, Nicholas Cummins, Alice Baird, Simone Hantke, Judith\n  Dineley, Bj\\\"orn Schuller", "title": "Voice command generation using Progressive Wavegans", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have become exceedingly popular in a\nwide range of data-driven research fields, due in part to their success in\nimage generation. Their ability to generate new samples, often from only a\nsmall amount of input data, makes them an exciting research tool in areas with\nlimited data resources. One less-explored application of GANs is the synthesis\nof speech and audio samples. Herein, we propose a set of extensions to the\nWaveGAN paradigm, a recently proposed approach for sound generation using GANs.\nThe aim of these extensions - preprocessing, Audio-to-Audio generation, skip\nconnections and progressive structures - is to improve the human likeness of\nsynthetic speech samples. Scores from listening tests with 30 volunteers\ndemonstrated a moderate improvement (Cohen's d coefficient of 0.65) in human\nlikeness using the proposed extensions compared to the original WaveGAN\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 18:43:31 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Wiest", "Thomas", ""], ["Cummins", "Nicholas", ""], ["Baird", "Alice", ""], ["Hantke", "Simone", ""], ["Dineley", "Judith", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1903.07398", "submitter": "Gary Wang", "authors": "Gary Wang", "title": "Deep Text-to-Speech System with Seq2Seq Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent trends in neural network based text-to-speech/speech synthesis\npipelines have employed recurrent Seq2seq architectures that can synthesize\nrealistic sounding speech directly from text characters. These systems however\nhave complex architectures and takes a substantial amount of time to train. We\nintroduce several modifications to these Seq2seq architectures that allow for\nfaster training time, and also allows us to reduce the complexity of the model\narchitecture at the same time. We show that our proposed model can achieve\nattention alignment much faster than previous architectures and that good audio\nquality can be achieved with a model that's much smaller in size. Sample audio\navailable at https://soundcloud.com/gary-wang-23/sets/tts-samples-for-cmpt-419.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 18:18:38 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Wang", "Gary", ""]]}, {"id": "1903.07400", "submitter": "Jingwei Zhang", "authors": "Jingwei Zhang, Niklas Wetzel, Nicolai Dorka, Joschka Boedecker and\n  Wolfram Burgard", "title": "Scheduled Intrinsic Drive: A Hierarchical Take on Intrinsically\n  Motivated Exploration", "comments": "A video of our experimental results can be found at\n  https://youtu.be/b0MbY3lUlEI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in sparse reward reinforcement learning remains an open\nchallenge. Many state-of-the-art methods use intrinsic motivation to complement\nthe sparse extrinsic reward signal, giving the agent more opportunities to\nreceive feedback during exploration. Commonly these signals are added as bonus\nrewards, which results in a mixture policy that neither conducts exploration\nnor task fulfillment resolutely. In this paper, we instead learn separate\nintrinsic and extrinsic task policies and schedule between these different\ndrives to accelerate exploration and stabilize learning. Moreover, we introduce\na new type of intrinsic reward denoted as successor feature control (SFC),\nwhich is general and not task-specific. It takes into account statistics over\ncomplete trajectories and thus differs from previous methods that only use\nlocal information to evaluate intrinsic motivation. We evaluate our proposed\nscheduled intrinsic drive (SID) agent using three different environments with\npure visual inputs: VizDoom, DeepMind Lab and DeepMind Control Suite. The\nresults show a substantially improved exploration efficiency with SFC and the\nhierarchical usage of the intrinsic drives. A video of our experimental results\ncan be found at https://youtu.be/b0MbY3lUlEI.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 12:52:57 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 15:41:14 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zhang", "Jingwei", ""], ["Wetzel", "Niklas", ""], ["Dorka", "Nicolai", ""], ["Boedecker", "Joschka", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1903.07406", "submitter": "Shivam Kalra", "authors": "Shivam Kalra, Larry Li, Hamid R. Tizhoosh", "title": "Automatic Classification of Pathology Reports using TF-IDF Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Pathology report is arguably one of the most important documents in\nmedicine containing interpretive information about the visual findings from the\npatient's biopsy sample. Each pathology report has a retention period of up to\n20 years after the treatment of a patient. Cancer registries process and encode\nhigh volumes of free-text pathology reports for surveillance of cancer and\ntumor diseases all across the world. In spite of their extremely valuable\ninformation they hold, pathology reports are not used in any systematic way to\nfacilitate computational pathology. Therefore, in this study, we investigate\nautomated machine-learning techniques to identify/predict the primary diagnosis\n(based on ICD-O code) from pathology reports. We performed experiments by\nextracting the TF-IDF features from the reports and classifying them using\nthree different methods---SVM, XGBoost, and Logistic Regression. We constructed\na new dataset with 1,949 pathology reports arranged into 37 ICD-O categories,\ncollected from four different primary sites, namely lung, kidney, thymus, and\ntestis. The reports were manually transcribed into text format after collecting\nthem as PDF files from NCI Genomic Data Commons public dataset. We subsequently\npre-processed the reports by removing irrelevant textual artifacts produced by\nOCR software. The highest classification accuracy we achieved was 92\\% using\nXGBoost classifier on TF-IDF feature vectors, the linear SVM scored 87\\%\naccuracy. Furthermore, the study shows that TF-IDF vectors are suitable for\nhighlighting the important keywords within a report which can be helpful for\nthe cancer research and diagnostic workflow. The results are encouraging in\ndemonstrating the potential of machine learning methods for classification and\nencoding of pathology reports.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 09:11:53 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Kalra", "Shivam", ""], ["Li", "Larry", ""], ["Tizhoosh", "Hamid R.", ""]]}, {"id": "1903.07424", "submitter": "Yang Chen Mr", "authors": "Yang Chen, Xiaoyan Sun, Yaochu Jin", "title": "Communication-Efficient Federated Deep Learning with Asynchronous Model\n  Update and Temporally Weighted Aggregation", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2019", "doi": "10.1109/TNNLS.2019.2953131", "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning obtains a central model on the server by aggregating\nmodels trained locally on clients. As a result, federated learning does not\nrequire clients to upload their data to the server, thereby preserving the data\nprivacy of the clients. One challenge in federated learning is to reduce the\nclient-server communication since the end devices typically have very limited\ncommunication bandwidth. This paper presents an enhanced federated learning\ntechnique by proposing a synchronous learning strategy on the clients and a\ntemporally weighted aggregation of the local models on the server. In the\nasynchronous learning strategy, different layers of the deep neural networks\nare categorized into shallow and deeps layers and the parameters of the deep\nlayers are updated less frequently than those of the shallow layers.\nFurthermore, a temporally weighted aggregation strategy is introduced on the\nserver to make use of the previously trained local models, thereby enhancing\nthe accuracy and convergence of the central model. The proposed algorithm is\nempirically on two datasets with different deep neural networks. Our results\ndemonstrate that the proposed asynchronous federated deep learning outperforms\nthe baseline algorithm both in terms of communication cost and model accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 13:27:42 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Chen", "Yang", ""], ["Sun", "Xiaoyan", ""], ["Jin", "Yaochu", ""]]}, {"id": "1903.07427", "submitter": "Min-hwan Oh", "authors": "Min-hwan Oh, Peder A. Olsen, Karthikeyan Natesan Ramamurthy", "title": "Crowd Counting with Decomposed Uncertainty", "comments": "Accepted in AAAI 2020 (Main Technical Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research in neural networks in the field of computer vision has achieved\nremarkable accuracy for point estimation. However, the uncertainty in the\nestimation is rarely addressed. Uncertainty quantification accompanied by point\nestimation can lead to a more informed decision, and even improve the\nprediction quality. In this work, we focus on uncertainty estimation in the\ndomain of crowd counting. With increasing occurrences of heavily crowded events\nsuch as political rallies, protests, concerts, etc., automated crowd analysis\nis becoming an increasingly crucial task. The stakes can be very high in many\nof these real-world applications. We propose a scalable neural network\nframework with quantification of decomposed uncertainty using a bootstrap\nensemble. We demonstrate that the proposed uncertainty quantification method\nprovides additional insight to the crowd counting problem and is simple to\nimplement. We also show that our proposed method exhibits the state of the art\nperformances in many benchmark crowd counting datasets.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 16:53:50 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 21:39:06 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 05:02:35 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Oh", "Min-hwan", ""], ["Olsen", "Peder A.", ""], ["Ramamurthy", "Karthikeyan Natesan", ""]]}, {"id": "1903.07438", "submitter": "Dhruva Tirumala", "authors": "Dhruva Tirumala, Hyeonwoo Noh, Alexandre Galashov, Leonard\n  Hasenclever, Arun Ahuja, Greg Wayne, Razvan Pascanu, Yee Whye Teh, Nicolas\n  Heess", "title": "Exploiting Hierarchy for Learning and Transfer in KL-regularized RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As reinforcement learning agents are tasked with solving more challenging and\ndiverse tasks, the ability to incorporate prior knowledge into the learning\nsystem and to exploit reusable structure in solution space is likely to become\nincreasingly important. The KL-regularized expected reward objective\nconstitutes one possible tool to this end. It introduces an additional\ncomponent, a default or prior behavior, which can be learned alongside the\npolicy and as such partially transforms the reinforcement learning problem into\none of behavior modelling. In this work we consider the implications of this\nframework in cases where both the policy and default behavior are augmented\nwith latent variables. We discuss how the resulting hierarchical structures can\nbe used to implement different inductive biases and how their modularity can\nbenefit transfer. Empirically we find that they can lead to faster learning and\ntransfer on a range of continuous control tasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 13:43:12 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 17:00:58 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Tirumala", "Dhruva", ""], ["Noh", "Hyeonwoo", ""], ["Galashov", "Alexandre", ""], ["Hasenclever", "Leonard", ""], ["Ahuja", "Arun", ""], ["Wayne", "Greg", ""], ["Pascanu", "Razvan", ""], ["Teh", "Yee Whye", ""], ["Heess", "Nicolas", ""]]}, {"id": "1903.07445", "submitter": "Harrison Uglow", "authors": "Harrison Uglow, Martin Zlocha, Szymon Zmy\\'slony", "title": "An Exploration of State-of-the-art Methods for Offensive Language\n  Detection", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a comprehensive investigation of different custom and\noff-the-shelf architectures as well as different approaches to generating\nfeature vectors for offensive language detection. We also show that these\napproaches work well on small and noisy datasets such as on the Offensive\nLanguage Identification Dataset (OLID), so it should be possible to use them\nfor other applications.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 13:05:23 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 17:53:30 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Uglow", "Harrison", ""], ["Zlocha", "Martin", ""], ["Zmy\u015blony", "Szymon", ""]]}, {"id": "1903.07461", "submitter": "Geoff Nitschke", "authors": "David Jones and Anja Schroeder and Geoff Nitschke", "title": "Evolutionary Deep Learning to Identify Galaxies in the Zone of Avoidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Zone of Avoidance makes it difficult for astronomers to catalogue\ngalaxies at low latitudes to our galactic plane due to high star densities and\nextinction. However, having a complete sky map of galaxies is important in a\nnumber of fields of research in astronomy. There are many unclassified sources\nof light in the Zone of Avoidance and it is therefore important that there\nexists an accurate automated system to identify and classify galaxies in this\nregion. This study aims to evaluate the efficiency and accuracy of using an\nevolutionary algorithm to evolve the topology and configuration of\nConvolutional Neural Network (CNNs) to automatically identify galaxies in the\nZone of Avoidance. A supervised learning method is used with data containing\nnear-infrared images. Input image resolution and number of near-infrared\npassbands needed by the evolutionary algorithm is also analyzed while the\naccuracy of the best evolved CNN is compared to other CNN variants.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 13:53:27 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 07:22:29 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Jones", "David", ""], ["Schroeder", "Anja", ""], ["Nitschke", "Geoff", ""]]}, {"id": "1903.07479", "submitter": "Phong Nguyen Huu", "authors": "Nguyen Huu Phong and Bernardete Ribeiro", "title": "Offline and Online Deep Learning for Image Recognition", "comments": "5 pages", "journal-ref": "2017 4th Experiment@International Conference (exp.at'17)", "doi": "10.1109/EXPAT.2017.7984421", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image recognition using Deep Learning has been evolved for decades though\nadvances in the field through different settings is still a challenge. In this\npaper, we present our findings in searching for better image classifiers in\noffline and online environments. We resort to Convolutional Neural Network and\nits variations of fully connected Multi-layer Perceptron. Though still\npreliminary, these results are encouraging and may provide a better\nunderstanding about the field and directions toward future works.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 14:39:20 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Phong", "Nguyen Huu", ""], ["Ribeiro", "Bernardete", ""]]}, {"id": "1903.07497", "submitter": "Nguyen Huu Phong", "authors": "Nguyen Huu Phong and Bernardete Ribeiro", "title": "Advanced Capsule Networks via Context Awareness", "comments": "12 pages", "journal-ref": null, "doi": "10.1007/978-3-030-30487-4_14", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule Networks (CN) offer new architectures for Deep Learning (DL)\ncommunity. Though its effectiveness has been demonstrated in MNIST and\nsmallNORB datasets, the networks still face challenges in other datasets for\nimages with distinct contexts. In this research, we improve the design of CN\n(Vector version) namely we expand more Pooling layers to filter image\nbackgrounds and increase Reconstruction layers to make better image\nrestoration. Additionally, we perform experiments to compare accuracy and speed\nof CN versus DL models. In DL models, we utilize Inception V3 and DenseNet V201\nfor powerful computers besides NASNet, MobileNet V1 and MobileNet V2 for small\nand embedded devices. We evaluate our models on a fingerspelling alphabet\ndataset from American Sign Language (ASL). The results show that CNs perform\ncomparably to DL models while dramatically reducing training time. We also make\na demonstration and give a link for the purpose of illustration.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:12:13 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 07:09:02 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Phong", "Nguyen Huu", ""], ["Ribeiro", "Bernardete", ""]]}, {"id": "1903.07507", "submitter": "Ishan Jindal", "authors": "Ishan Jindal, Daniel Pressel, Brian Lester, Matthew Nokleby", "title": "An Effective Label Noise Model for DNN Text Classification", "comments": "Accepted at NAACL-HLT 2019 Main Conference Long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because large, human-annotated datasets suffer from labeling errors, it is\ncrucial to be able to train deep neural networks in the presence of label\nnoise. While training image classification models with label noise have\nreceived much attention, training text classification models have not. In this\npaper, we propose an approach to training deep networks that is robust to label\nnoise. This approach introduces a non-linear processing layer (noise model)\nthat models the statistics of the label noise into a convolutional neural\nnetwork (CNN) architecture. The noise model and the CNN weights are learned\njointly from noisy training data, which prevents the model from overfitting to\nerroneous labels. Through extensive experiments on several text classification\ndatasets, we show that this approach enables the CNN to learn better sentence\nrepresentations and is robust even to extreme label noise. We find that proper\ninitialization and regularization of this noise model is critical. Further, by\ncontrast to results focusing on large batch sizes for mitigating label noise\nfor image classification, we find that altering the batch size does not have\nmuch effect on classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:27:50 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Jindal", "Ishan", ""], ["Pressel", "Daniel", ""], ["Lester", "Brian", ""], ["Nokleby", "Matthew", ""]]}, {"id": "1903.07510", "submitter": "Jack Albright", "authors": "Jack Albright", "title": "Forecasting the Progression of Alzheimer's Disease Using Neural Networks\n  and a Novel Pre-Processing Algorithm", "comments": "10 pages; updated acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease (AD) is the most common neurodegenerative disease in\nolder people. Despite considerable efforts to find a cure for AD, there is a\n99.6% failure rate of clinical trials for AD drugs, likely because AD patients\ncannot easily be identified at early stages. This project investigated machine\nlearning approaches to predict the clinical state of patients in future years\nto benefit AD research. Clinical data from 1737 patients was obtained from the\nAlzheimer's Disease Neuroimaging Initiative (ADNI) database and was processed\nusing the \"All-Pairs\" technique, a novel methodology created for this project\ninvolving the comparison of all possible pairs of temporal data points for each\npatient. This data was then used to train various machine learning models.\nModels were evaluated using 7-fold cross-validation on the training dataset and\nconfirmed using data from a separate testing dataset (110 patients). A neural\nnetwork model was effective (mAUC = 0.866) at predicting the progression of AD\non a month-by-month basis, both in patients who were initially cognitively\nnormal and in patients suffering from mild cognitive impairment. Such a model\ncould be used to identify patients at early stages of AD and who are therefore\ngood candidates for clinical trials for AD therapeutics.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:32:33 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 17:54:44 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Albright", "Jack", ""]]}, {"id": "1903.07512", "submitter": "Klaus Diepold", "authors": "Michael Koller, Johannes Feldmaier, Klaus Diepold", "title": "A Comparison of Prediction Algorithms and Nexting for Short Term Weather\n  Forecasts", "comments": "9 pages, 8 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This report first provides a brief overview of a number of supervised\nlearning algorithms for regression tasks. Among those are neural networks,\nregression trees, and the recently introduced Nexting. Nexting has been\npresented in the context of reinforcement learning where it was used to predict\na large number of signals at different timescales. In the second half of this\nreport, we apply the algorithms to historical weather data in order to evaluate\ntheir suitability to forecast a local weather trend. Our experiments did not\nidentify one clearly preferable method, but rather show that choosing an\nappropriate algorithm depends on the available side information. For slowly\nvarying signals and a proficient number of training samples, Nexting achieved\ngood results in the studied cases.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:37:34 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Koller", "Michael", ""], ["Feldmaier", "Johannes", ""], ["Diepold", "Klaus", ""]]}, {"id": "1903.07515", "submitter": "Sean Bittner", "authors": "Sean R. Bittner and John P. Cunningham", "title": "Approximating exponential family models (not single distributions) with\n  a two-network architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently much attention has been paid to deep generative models, since they\nhave been used to great success for variational inference, generation of\ncomplex data types, and more. In most all of these settings, the goal has been\nto find a particular member of that model family: optimized parameters index a\ndistribution that is close (via a divergence or classification metric) to a\ntarget distribution. Much less attention, however, has been paid to the problem\nof learning a model itself. Here we introduce a two-network architecture and\noptimization procedure for learning intractable exponential family models (not\na single distribution from those models). These exponential families are\nlearned accurately, allowing operations like posterior inference to be executed\ndirectly and generically with an input choice of natural parameters, rather\nthan performing inference via optimization for each particular distribution\nwithin that model.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:43:07 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Bittner", "Sean R.", ""], ["Cunningham", "John P.", ""]]}, {"id": "1903.07518", "submitter": "Andreas Loukas", "authors": "Jean-Baptiste Cordonnier and Andreas Loukas", "title": "Extrapolating paths with graph neural networks", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of path inference: given a path prefix, i.e., a\npartially observed sequence of nodes in a graph, we want to predict which nodes\nare in the missing suffix. In particular, we focus on natural paths occurring\nas a by-product of the interaction of an agent with a network---a driver on the\ntransportation network, an information seeker in Wikipedia, or a client in an\nonline shop. Our interest is sparked by the realization that, in contrast to\nshortest-path problems, natural paths are usually not optimal in any\ngraph-theoretic sense, but might still follow predictable patterns.\n  Our main contribution is a graph neural network called Gretel. Conditioned on\na path prefix, this network can efficiently extrapolate path suffixes, evaluate\npath likelihood, and sample from the future path distribution. Our experiments\nwith GPS traces on a road network and user-navigation paths in Wikipedia\nconfirm that Gretel is able to adapt to graphs with very different properties,\nwhile also comparing favorably to previous solutions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 15:47:28 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Cordonnier", "Jean-Baptiste", ""], ["Loukas", "Andreas", ""]]}, {"id": "1903.07534", "submitter": "Francesco Giannini", "authors": "Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti and Marco\n  Gori", "title": "LYRICS: a General Interface Layer to Integrate Logic Inference and Deep\n  Learning", "comments": "To appear in proceedings of ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the amazing results obtained by deep learning in many\napplications, a real intelligent behavior of an agent acting in a complex\nenvironment is likely to require some kind of higher-level symbolic inference.\nTherefore, there is a clear need for the definition of a general and tight\nintegration between low-level tasks, processing sensorial data that can be\neffectively elaborated using deep learning techniques, and the logic reasoning\nthat allows humans to take decisions in complex environments. This paper\npresents LYRICS, a generic interface layer for AI, which is implemented in\nTersorFlow (TF). LYRICS provides an input language that allows to define\narbitrary First Order Logic (FOL) background knowledge. The predicates and\nfunctions of the FOL knowledge can be bound to any TF computational graph, and\nthe formulas are converted into a set of real-valued constraints, which\nparticipate to the overall optimization problem. This allows to learn the\nweights of the learners, under the constraints imposed by the prior knowledge.\nThe framework is extremely general as it imposes no restrictions in terms of\nwhich models or knowledge can be integrated. In this paper, we show the\ngenerality of the approach showing some use cases of the presented language,\nincluding model checking, supervised learning and collective classification.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 16:23:00 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 15:32:33 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Marra", "Giuseppe", ""], ["Giannini", "Francesco", ""], ["Diligenti", "Michelangelo", ""], ["Gori", "Marco", ""]]}, {"id": "1903.07571", "submitter": "Daniel Hsu", "authors": "Mikhail Belkin, Daniel Hsu, Ji Xu", "title": "Two models of double descent for weak features", "comments": null, "journal-ref": "SIAM Journal on Mathematics of Data Science, 2(4):1167-1180, 2020", "doi": "10.1137/20M1336072", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"double descent\" risk curve was proposed to qualitatively describe the\nout-of-sample prediction accuracy of variably-parameterized machine learning\nmodels. This article provides a precise mathematical analysis for the shape of\nthis curve in two simple data models with the least squares/least norm\npredictor. Specifically, it is shown that the risk peaks when the number of\nfeatures $p$ is close to the sample size $n$, but also that the risk decreases\ntowards its minimum as $p$ increases beyond $n$. This behavior is contrasted\nwith that of \"prescient\" models that select features in an a priori optimal\norder.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 17:09:08 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 02:18:32 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Belkin", "Mikhail", ""], ["Hsu", "Daniel", ""], ["Xu", "Ji", ""]]}, {"id": "1903.07588", "submitter": "Amr Amr", "authors": "Amr Adel Helmy", "title": "A Multilingual Encoding Method for Text Classification and Dialect\n  Identification Using Convolutional Neural Network", "comments": "A dissertation submitted to the AASTMT on February 2019 in partial\n  fulfillment of the requirements for the degree of Master of Science in\n  Computer Science. arXiv admin note: text overlap with arXiv:1807.10854 by\n  other authors without attribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis presents a language-independent text classification model by\nintroduced two new encoding methods \"BUNOW\" and \"BUNOC\" used for feeding the\nraw text data into a new CNN spatial architecture with vertical and horizontal\nconvolutional process instead of commonly used methods like one hot vector or\nword representation (i.e. word2vec) with temporal CNN architecture. The\nproposed model can be classified as hybrid word-character model in its work\nmethodology because it consumes less memory space by using a fewer neural\nnetwork parameters as in character level representation, in addition to\nproviding much faster computations with fewer network layers depth, as in word\nlevel representation. A promising result achieved compared to state of art\nmodels in two different morphological benchmarked dataset one for Arabic\nlanguage and one for English language.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 17:31:14 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Helmy", "Amr Adel", ""]]}, {"id": "1903.07593", "submitter": "Allan Jabri", "authors": "Xiaolong Wang, Allan Jabri, Alexei A. Efros", "title": "Learning Correspondence from the Cycle-Consistency of Time", "comments": "CVPR 2019 Oral. Project page: http://ajabri.github.io/timecycle", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a self-supervised method for learning visual correspondence from\nunlabeled video. The main idea is to use cycle-consistency in time as free\nsupervisory signal for learning visual representations from scratch. At\ntraining time, our model learns a feature map representation to be useful for\nperforming cycle-consistent tracking. At test time, we use the acquired\nrepresentation to find nearest neighbors across space and time. We demonstrate\nthe generalizability of the representation -- without finetuning -- across a\nrange of visual correspondence tasks, including video object segmentation,\nkeypoint tracking, and optical flow. Our approach outperforms previous\nself-supervised methods and performs competitively with strongly supervised\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 17:36:00 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 05:56:01 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Wang", "Xiaolong", ""], ["Jabri", "Allan", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1903.07594", "submitter": "Aliaksandr Hubin", "authors": "Aliaksandr Hubin, Geir Storvik", "title": "Combining Model and Parameter Uncertainty in Bayesian Neural Networks", "comments": "16 pages, 8 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNNs) have recently regained a significant amount\nof attention in the deep learning community due to the development of scalable\napproximate Bayesian inference techniques. There are several advantages of\nusing Bayesian approach: Parameter and prediction uncertainty become easily\navailable, facilitating rigid statistical analysis. Furthermore, prior\nknowledge can be incorporated. However so far there have been no scalable\ntechniques capable of combining both model (structural) and parameter\nuncertainty. In this paper we introduce the concept of model uncertainty in\nBNNs and hence make inference in the joint space of models and parameters.\nMoreover, we suggest an adaptation of a scalable variational inference approach\nwith reparametrization of marginal inclusion probabilities to incorporate the\nmodel space constraints. Finally, we show that incorporating model uncertainty\nvia Bayesian model averaging and Bayesian model selection allows to drastically\nsparsify the structure of BNNs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 17:41:33 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 17:49:40 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 14:07:09 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hubin", "Aliaksandr", ""], ["Storvik", "Geir", ""]]}, {"id": "1903.07609", "submitter": "Xavier Gitiaux", "authors": "Xavier Gitiaux and Huzefa Rangwala", "title": "Multi-Differential Fairness Auditor for Black Box Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are increasingly involved in sensitive\ndecision-making process with adversarial implications on individuals. This\npaper presents mdfa, an approach that identifies the characteristics of the\nvictims of a classifier's discrimination. We measure discrimination as a\nviolation of multi-differential fairness. Multi-differential fairness is a\nguarantee that a black box classifier's outcomes do not leak information on the\nsensitive attributes of a small group of individuals. We reduce the problem of\nidentifying worst-case violations to matching distributions and predicting\nwhere sensitive attributes and classifier's outcomes coincide. We apply mdfa to\na recidivism risk assessment classifier and demonstrate that individuals\nidentified as African-American with little criminal history are three-times\nmore likely to be considered at high risk of violent recidivism than similar\nindividuals but not African-American.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 17:58:47 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Gitiaux", "Xavier", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1903.07663", "submitter": "Tianchen Wang", "authors": "Tianchen Wang, Jinjun Xiong, Xiaowei Xu, Yiyu Shi", "title": "SCNN: A General Distribution based Statistical Convolutional Neural\n  Network with Application to Video Object Detection", "comments": "AAAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various convolutional neural networks (CNNs) were developed recently that\nachieved accuracy comparable with that of human beings in computer vision tasks\nsuch as image recognition, object detection and tracking, etc. Most of these\nnetworks, however, process one single frame of image at a time, and may not\nfully utilize the temporal and contextual correlation typically present in\nmultiple channels of the same image or adjacent frames from a video, thus\nlimiting the achievable throughput. This limitation stems from the fact that\nexisting CNNs operate on deterministic numbers. In this paper, we propose a\nnovel statistical convolutional neural network (SCNN), which extends existing\nCNN architectures but operates directly on correlated distributions rather than\ndeterministic numbers. By introducing a parameterized canonical model to model\ncorrelated data and defining corresponding operations as required for CNN\ntraining and inference, we show that SCNN can process multiple frames of\ncorrelated images effectively, hence achieving significant speedup over\nexisting CNN models. We use a CNN based video object detection as an example to\nillustrate the usefulness of the proposed SCNN as a general network model.\nExperimental results show that even a non-optimized implementation of SCNN can\nstill achieve 178% speedup over existing CNNs with slight accuracy degradation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 16:00:23 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Wang", "Tianchen", ""], ["Xiong", "Jinjun", ""], ["Xu", "Xiaowei", ""], ["Shi", "Yiyu", ""]]}, {"id": "1903.07677", "submitter": "Matthew Dixon", "authors": "Matthew F. Dixon and Nicholas G. Polson", "title": "Deep Fundamental Factor Models", "comments": null, "journal-ref": "Forthcoming in SIAM J. Financial Mathematics, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep fundamental factor models are developed to automatically capture\nnon-linearity and interaction effects in factor modeling. Uncertainty\nquantification provides interpretability with interval estimation, ranking of\nfactor importances and estimation of interaction effects. With no hidden layers\nwe recover a linear factor model and for one or more hidden layers, uncertainty\nbands for the sensitivity to each input naturally arise from the network\nweights. Using 3290 assets in the Russell 1000 index over a period of December\n1989 to January 2018, we assess a 49 factor model and generate information\nratios that are approximately 1.5x greater than the OLS factor model.\nFurthermore, we compare our deep fundamental factor model with a quadratic\nLASSO model and demonstrate the superior performance and robustness to\noutliers. The Python source code and the data used for this study are provided.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 19:10:09 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 19:57:38 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 17:22:04 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Dixon", "Matthew F.", ""], ["Polson", "Nicholas G.", ""]]}, {"id": "1903.07714", "submitter": "Laurent Dinh", "authors": "Laurent Dinh, Jascha Sohl-Dickstein, Hugo Larochelle, Razvan Pascanu", "title": "A RAD approach to deep mixture models", "comments": "18.5 pages of main content, 3 pages of appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow based models such as Real NVP are an extremely powerful approach to\ndensity estimation. However, existing flow based models are restricted to\ntransforming continuous densities over a continuous input space into similarly\ncontinuous distributions over continuous latent variables. This makes them\npoorly suited for modeling and representing discrete structures in data\ndistributions, for example class membership or discrete symmetries. To address\nthis difficulty, we present a normalizing flow architecture which relies on\ndomain partitioning using locally invertible functions, and possesses both real\nand discrete valued latent variables. This Real and Discrete (RAD) approach\nretains the desirable normalizing flow properties of exact sampling, exact\ninference, and analytically computable probabilities, while at the same time\nallowing simultaneous modeling of both continuous and discrete structure in a\ndata distribution.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 20:55:53 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 16:19:49 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 02:25:59 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Dinh", "Laurent", ""], ["Sohl-Dickstein", "Jascha", ""], ["Larochelle", "Hugo", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1903.07722", "submitter": "Lucas May Petry", "authors": "Carlos Andres Ferrero, Lucas May Petry, Luis Otavio Alvares, Willian\n  Zalewski, Vania Bogorny", "title": "Discovering Heterogeneous Subsequences for Trajectory Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new parameter-free method for trajectory\nclassification which finds the best trajectory partition and dimension\ncombination for robust trajectory classification. Preliminary experiments show\nthat our approach is very promising.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 21:10:16 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Ferrero", "Carlos Andres", ""], ["Petry", "Lucas May", ""], ["Alvares", "Luis Otavio", ""], ["Zalewski", "Willian", ""], ["Bogorny", "Vania", ""]]}, {"id": "1903.07740", "submitter": "Alexander Pashevich", "authors": "Alexander Pashevich, Robin Strudel, Igor Kalevatykh, Ivan Laptev,\n  Cordelia Schmid", "title": "Learning to Augment Synthetic Images for Sim2Real Policy Transfer", "comments": "7 pages", "journal-ref": "IROS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision and learning have made significant progress that could improve\nrobotics policies for complex tasks and environments. Learning deep neural\nnetworks for image understanding, however, requires large amounts of\ndomain-specific visual data. While collecting such data from real robots is\npossible, such an approach limits the scalability as learning policies\ntypically requires thousands of trials. In this work we attempt to learn\nmanipulation policies in simulated environments. Simulators enable scalability\nand provide access to the underlying world state during training. Policies\nlearned in simulators, however, do not transfer well to real scenes given the\ndomain gap between real and synthetic data. We follow recent work on domain\nrandomization and augment synthetic images with sequences of random\ntransformations. Our main contribution is to optimize the augmentation strategy\nfor sim2real transfer and to enable domain-independent policy learning. We\ndesign an efficient search for depth image augmentations using object\nlocalization as a proxy task. Given the resulting sequence of random\ntransformations, we use it to augment synthetic depth images during policy\nlearning. Our augmentation strategy is policy-independent and enables policy\nlearning with no real images. We demonstrate our approach to significantly\nimprove accuracy on three manipulation tasks evaluated on a real robot.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 22:01:57 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 14:47:57 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Pashevich", "Alexander", ""], ["Strudel", "Robin", ""], ["Kalevatykh", "Igor", ""], ["Laptev", "Ivan", ""], ["Schmid", "Cordelia", ""]]}, {"id": "1903.07745", "submitter": "Thomas Uriot Tu", "authors": "Thomas Uriot", "title": "Learning with Sets in Multiple Instance Regression Applied to Remote\n  Sensing", "comments": "KDD 2019, FEED Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach to tackle the multiple instance\nregression (MIR) problem. This problem arises when the data is a collection of\nbags, where each bag is made of multiple instances corresponding to the same\nunique real-valued label. Our goal is to train a regression model which maps\nthe instances of an unseen bag to its unique label. This MIR setting is common\nto remote sensing applications where there is high variability in the\nmeasurements and low geographical variability in the quantity being estimated.\nOur approach, in contrast to most competing methods, does not make the\nassumption that there exists a prime instance responsible for the label in each\nbag. Instead, we treat each bag as a set (i.e, an unordered sequence) of\ninstances and learn to map each bag to its unique label by using all the\ninstances in each bag. This is done by implementing an order-invariant\noperation characterized by a particular type of attention mechanism. This\nmethod is very flexible as it does not require domain knowledge nor does it\nmake any assumptions about the distribution of the instances within each bag.\nWe test our algorithm on five real world datasets and outperform previous\nstate-of-the-art on three of the datasets. In addition, we augment our feature\nspace by adding the moments of each feature for each bag, as extra features,\nand show that while the first moments lead to higher accuracy, there is a\ndiminishing return.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 22:27:47 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 16:39:18 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 12:19:50 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Uriot", "Thomas", ""]]}, {"id": "1903.07746", "submitter": "Lucas Maystre", "authors": "Lucas Maystre, Victor Kristof, Matthias Grossglauser", "title": "Pairwise Comparisons with Flexible Time-Dynamics", "comments": "Accepted at KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by applications in sports where the skill of players or teams\ncompeting against each other varies over time, we propose a probabilistic model\nof pairwise-comparison outcomes that can capture a wide range of time dynamics.\nWe achieve this by replacing the static parameters of a class of popular\npairwise-comparison models by continuous-time Gaussian processes; the\ncovariance function of these processes enables expressive dynamics. We develop\nan efficient inference algorithm that computes an approximate Bayesian\nposterior distribution. Despite the flexbility of our model, our inference\nalgorithm requires only a few linear-time iterations over the data and can take\nadvantage of modern multiprocessor computer architectures. We apply our model\nto several historical databases of sports outcomes and find that our approach\noutperforms competing approaches in terms of predictive performance, scales to\nmillions of observations, and generates compelling visualizations that help in\nunderstanding and interpreting the data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 22:31:35 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 11:10:22 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Maystre", "Lucas", ""], ["Kristof", "Victor", ""], ["Grossglauser", "Matthias", ""]]}, {"id": "1903.07749", "submitter": "Aleke Nolte", "authors": "Aleke Nolte, Lingyu Wang, Maciej Bilicki, Benne Holwerda and Michael\n  Biehl", "title": "Galaxy classification: A machine learning analysis of GAMA catalogue\n  data", "comments": "Accepted for the ESANN 2018 Special Issue of Neurocomputing", "journal-ref": "Neurocomputing 342: 172-190, 2019", "doi": "10.1016/j.neucom.2018.12.076", "report-no": null, "categories": "astro-ph.GA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine learning analysis of five labelled galaxy catalogues\nfrom the Galaxy And Mass Assembly (GAMA): The SersicCatVIKING and\nSersicCatUKIDSS catalogues containing morphological features, the\nGaussFitSimple catalogue containing spectroscopic features, the MagPhys\ncatalogue including physical parameters for galaxies, and the Lambdar\ncatalogue, which contains photometric measurements. Extending work previously\npresented at the ESANN 2018 conference - in an analysis based on Generalized\nRelevance Matrix Learning Vector Quantization and Random Forests - we find that\nneither the data from the individual catalogues nor a combined dataset based on\nall 5 catalogues fully supports the visual-inspection-based galaxy\nclassification scheme employed to categorise the galaxies. In particular, only\none class, the Little Blue Spheroids, is consistently separable from the other\nclasses. To aid further insight into the nature of the employed visual-based\nclassification scheme with respect to physical and morphological features, we\npresent the galaxy parameters that are discriminative for the achieved class\ndistinctions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 22:49:39 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Nolte", "Aleke", ""], ["Wang", "Lingyu", ""], ["Bilicki", "Maciej", ""], ["Holwerda", "Benne", ""], ["Biehl", "Michael", ""]]}, {"id": "1903.07756", "submitter": "Wenbo Zhao", "authors": "Wenbo Zhao, Yang Gao, Shahan Ali Memon, Bhiksha Raj, Rita Singh", "title": "Hierarchical Routing Mixture of Experts", "comments": "9 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression tasks the distribution of the data is often too complex to be\nfitted by a single model. In contrast, partition-based models are developed\nwhere data is divided and fitted by local models. These models partition the\ninput space and do not leverage the input-output dependency of\nmultimodal-distributed data, and strong local models are needed to make good\npredictions. Addressing these problems, we propose a binary tree-structured\nhierarchical routing mixture of experts (HRME) model that has classifiers as\nnon-leaf node experts and simple regression models as leaf node experts. The\nclassifier nodes jointly soft-partition the input-output space based on the\nnatural separateness of multimodal data. This enables simple leaf experts to be\neffective for prediction. Further, we develop a probabilistic framework for the\nHRME model, and propose a recursive Expectation-Maximization (EM) based\nalgorithm to learn both the tree structure and the expert models. Experiments\non a collection of regression tasks validate the effectiveness of our method\ncompared to a variety of other regression models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 23:04:45 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Zhao", "Wenbo", ""], ["Gao", "Yang", ""], ["Memon", "Shahan Ali", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "1903.07765", "submitter": "Yao Hengshuai", "authors": "Borislav Mavrin, Hengshuai Yao, Linglong Kong", "title": "Deep Reinforcement Learning with Decorrelation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning an effective representation for high-dimensional data is a\nchallenging problem in reinforcement learning (RL). Deep reinforcement learning\n(DRL) such as Deep Q networks (DQN) achieves remarkable success in computer\ngames by learning deeply encoded representation from convolution networks. In\nthis paper, we propose a simple yet very effective method for representation\nlearning with DRL algorithms. Our key insight is that features learned by DRL\nalgorithms are highly correlated, which interferes with learning. By adding a\nregularized loss that penalizes correlation in latent features (with only\nslight computation), we decorrelate features represented by deep neural\nnetworks incrementally. On 49 Atari games, with the same regularization factor,\nour decorrelation algorithms perform $70\\%$ in terms of human-normalized\nscores, which is $40\\%$ better than DQN. In particular, ours performs better\nthan DQN on 39 games with 4 close ties and lost only slightly on $6$ games.\nEmpirical results also show that the decorrelation method applies to Quantile\nRegression DQN (QR-DQN) and significantly boosts performance. Further\nexperiments on the losing games show that our decorelation algorithms can win\nover DQN and QR-DQN with a fined tuned regularization factor.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 23:35:23 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 17:18:07 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 22:06:55 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Mavrin", "Borislav", ""], ["Yao", "Hengshuai", ""], ["Kong", "Linglong", ""]]}, {"id": "1903.07768", "submitter": "Denisa Roberts", "authors": "Denisa Roberts", "title": "Neural Networks for Lorenz Map Prediction: A Trip Through Time", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": "AI-2020-0001", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article the Lorenz dynamical system is revived and revisited and the\ncurrent state of the art results for one step ahead forecasting for the Lorenz\ntrajectories are published. Multitask learning is shown to help learning the\nhard to learn z trajectory. The article is a reflection upon the evolution of\nneural networks with respect to the prediction performance on this canonical\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 23:45:40 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 11:49:33 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 13:57:57 GMT"}, {"version": "v4", "created": "Sun, 29 Mar 2020 19:22:13 GMT"}, {"version": "v5", "created": "Sun, 15 Nov 2020 14:53:22 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Roberts", "Denisa", ""]]}, {"id": "1903.07788", "submitter": "Jianxin Wu", "authors": "Kun Yi and Jianxin Wu", "title": "Probabilistic End-to-end Noise Correction for Learning with Noisy Labels", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved excellent performance in various computer vision\ntasks, but requires a lot of training examples with clean labels. It is easy to\ncollect a dataset with noisy labels, but such noise makes networks overfit\nseriously and accuracies drop dramatically. To address this problem, we propose\nan end-to-end framework called PENCIL, which can update both network parameters\nand label estimations as label distributions. PENCIL is independent of the\nbackbone network structure and does not need an auxiliary clean dataset or\nprior information about noise, thus it is more general and robust than existing\nmethods and is easy to apply. PENCIL outperforms previous state-of-the-art\nmethods by large margins on both synthetic and real-world datasets with\ndifferent noise types and noise rates. Experiments show that PENCIL is robust\non clean datasets, too.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 01:38:08 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Yi", "Kun", ""], ["Wu", "Jianxin", ""]]}, {"id": "1903.07789", "submitter": "Junkai Sun", "authors": "Junkai Sun, Junbo Zhang, Qiaofei Li, Xiuwen Yi, Yuxuan Liang, Yu Zheng", "title": "Predicting Citywide Crowd Flows in Irregular Regions Using Multi-View\n  Graph Convolutional Networks", "comments": "12 pages, 13 figures, 5 tables. Published in IEEE TKDE, Date of\n  Publication: Jul. 13, 2020", "journal-ref": "IEEE Transactions on Knowledge and Data Engineering (TKDE), 2020", "doi": "10.1109/TKDE.2020.3008774", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to predict the crowd flows in each and every part of a city,\nespecially in irregular regions, is strategically important for traffic\ncontrol, risk assessment, and public safety. However, it is very challenging\nbecause of interactions and spatial correlations between different regions. In\naddition, it is affected by many factors: i) multiple temporal correlations\namong different time intervals: closeness, period, trend; ii) complex external\ninfluential factors: weather, events; iii) meta features: time of the day, day\nof the week, and so on. In this paper, we formulate crowd flow forecasting in\nirregular regions as a spatio-temporal graph (STG) prediction problem in which\neach node represents a region with time-varying flows. By extending graph\nconvolution to handle the spatial information, we propose using spatial graph\nconvolution to build a multi-view graph convolutional network (MVGCN) for the\ncrowd flow forecasting problem, where different views can capture different\nfactors as mentioned above. We evaluate MVGCN using four real-world datasets\n(taxicabs and bikes) and extensive experimental results show that our approach\noutperforms the adaptations of state-of-the-art methods. And we have developed\na crowd flow forecasting system for irregular regions that can now be used\ninternally.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 01:46:11 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 08:34:11 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Sun", "Junkai", ""], ["Zhang", "Junbo", ""], ["Li", "Qiaofei", ""], ["Yi", "Xiuwen", ""], ["Liang", "Yuxuan", ""], ["Zheng", "Yu", ""]]}, {"id": "1903.07792", "submitter": "Mehrdad Showkatbakhsh", "authors": "Mehrdad Showkatbakhsh, Can Karakus, Suhas Diggavi", "title": "Differentially Private Consensus-Based Distributed Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data privacy is an important concern in learning, when datasets contain\nsensitive information about individuals. This paper considers consensus-based\ndistributed optimization under data privacy constraints. Consensus-based\noptimization consists of a set of computational nodes arranged in a graph, each\nhaving a local objective that depends on their local data, where in every step\nnodes take a linear combination of their neighbors' messages, as well as taking\na new gradient step. Since the algorithm requires exchanging messages that\ndepend on local data, private information gets leaked at every step. Taking\n$(\\epsilon, \\delta)$-differential privacy (DP) as our criterion, we consider\nthe strategy where the nodes add random noise to their messages before\nbroadcasting it, and show that the method achieves convergence with a bounded\nmean-squared error, while satisfying $(\\epsilon, \\delta)$-DP. By relaxing the\nmore stringent $\\epsilon$-DP requirement in previous work, we strengthen a\nknown convergence result in the literature. We conclude the paper with\nnumerical results demonstrating the effectiveness of our methods for mean\nestimation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 02:06:10 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Showkatbakhsh", "Mehrdad", ""], ["Karakus", "Can", ""], ["Diggavi", "Suhas", ""]]}, {"id": "1903.07799", "submitter": "Mohan Shi", "authors": "Mohan Shi, Zhihai Wang, Jodong Yuan and Haiyang Liu", "title": "Random Pairwise Shapelets Forest", "comments": "There is some misunderstanding between authors when this manuscript\n  is submitted. Some of authors disagree to submit this manuscript. So we\n  decide to withdraw the article", "journal-ref": "PAKDD 2018: Advances in Knowledge Discovery and Data Mining", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapelet is a discriminative subsequence of time series. An advanced\nshapelet-based method is to embed shapelet into accurate and fast random\nforest. However, it shows several limitations. First, random shapelet forest\nrequires a large training cost for split threshold searching. Second, a single\nshapelet provides limited information for only one branch of the decision tree,\nresulting in insufficient accuracy and interpretability. Third, randomized\nensemble causes interpretability declining. For that, this paper presents\nRandom Pairwise Shapelets Forest (RPSF). RPSF combines a pair of shapelets from\ndifferent classes to construct random forest. It omits threshold searching to\nbe more efficient, includes more information for each node of the forest to be\nmore effective. Moreover, a discriminability metric, Decomposed Mean Decrease\nImpurity (DMDI), is proposed to identify influential region for every class.\nExtensive experiments show RPSF improves the accuracy and training speed of\nshapelet-based forest. Case studies demonstrate the interpretability of our\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 02:37:02 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 14:14:53 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Shi", "Mohan", ""], ["Wang", "Zhihai", ""], ["Yuan", "Jodong", ""], ["Liu", "Haiyang", ""]]}, {"id": "1903.07803", "submitter": "Rolando Estrada", "authors": "Aashis Khanal and Rolando Estrada", "title": "Dynamic Deep Networks for Retinal Vessel Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmenting the retinal vasculature entails a trade-off between how much of\nthe overall vascular structure we identify vs. how precisely we segment\nindividual vessels. In particular, state-of-the-art methods tend to\nunder-segment faint vessels, as well as pixels that lie on the edges of thicker\nvessels. Thus, they underestimate the width of individual vessels, as well as\nthe ratio of large to small vessels. More generally, many crucial\nbio-markers---including the artery-vein (AV) ratio, branching angles, number of\nbifurcation, fractal dimension, tortuosity, vascular length-to-diameter ratio\nand wall-to-lumen length---require precise measurements of individual vessels.\nTo address this limitation, we propose a novel, stochastic training scheme for\ndeep neural networks that better classifies the faint, ambiguous regions of the\nimage. Our approach relies on two key innovations. First, we train our deep\nnetworks with dynamic weights that fluctuate during each training iteration.\nThis stochastic approach forces the network to learn a mapping that robustly\nbalances precision and recall. Second, we decouple the segmentation process\ninto two steps. In the first half of our pipeline, we estimate the likelihood\nof every pixel and then use these likelihoods to segment pixels that are\nclearly vessel or background. In the latter part of our pipeline, we use a\nsecond network to classify the ambiguous regions in the image. Our proposed\nmethod obtained state-of-the-art results on five retinal datasets---DRIVE,\nSTARE, CHASE-DB, AV-WIDE, and VEVIO---by learning a robust balance between\nfalse positive and false negative rates. In addition, we are the first to\nreport segmentation results on the AV-WIDE dataset, and we have made the\nground-truth annotations for this dataset publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 03:02:24 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 14:37:17 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Khanal", "Aashis", ""], ["Estrada", "Rolando", ""]]}, {"id": "1903.07806", "submitter": "Daichi Yanagisawa Dr.", "authors": "Koki Nagao, Daichi Yanagisawa, and Katsuhiro Nishinari", "title": "Estimation of crowd density applying wavelet transform and machine\n  learning", "comments": "32 pages, 17 figures, 7 tables", "journal-ref": "Physica A, 510, 145-163 (2018)", "doi": "10.1016/j.physa.2018.06.078", "report-no": null, "categories": "physics.soc-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conducted a simple experiment in which one pedestrian passed through a\ncrowded area and measured the body-rotational angular velocity with commercial\ntablets. Then, we developed a new method for predicting crowd density by\napplying the continuous wavelet transform and machine learning to the data\nobtained in the experiment. We found that the accuracy of prediction using\nangular velocity data was as high as that using raw velocity data. Therefore,\nwe concluded that angular velocity has relationship with crowd density and we\ncould estimate crowd density by angular velocity. Our research will contribute\nto management of safety and comfort of pedestrians by developing an easy way to\nmeasure crowd density.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 03:11:25 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Nagao", "Koki", ""], ["Yanagisawa", "Daichi", ""], ["Nishinari", "Katsuhiro", ""]]}, {"id": "1903.07812", "submitter": "Huibing Wang", "authors": "Huibing Wang, Jinjia Peng and Xianping Fu", "title": "Self-Weighted Multiview Metric Learning by Maximizing the Cross\n  Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of multimedia time, one sample can always be described\nfrom multiple views which contain compatible and complementary information.\nMost algorithms cannot take information from multiple views into considerations\nand fail to achieve desirable performance in most situations. For many\napplications, such as image retrieval, face recognition, etc., an appropriate\ndistance metric can better reflect the similarities between various samples.\nTherefore, how to construct a good distance metric learning methods which can\ndeal with multiview data has been an important topic during the last decade. In\nthis paper, we proposed a novel algorithm named Self-weighted Multiview Metric\nLearning (SM2L) which can finish this task by maximizing the cross correlations\nbetween different views. Furthermore, because multiple views have different\ncontributions to the learning procedure of SM2L, we adopt a self-weighted\nlearning framework to assign multiple views with different weights. Various\nexperiments on benchmark datasets can verify the performance of our proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 03:40:40 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Wang", "Huibing", ""], ["Peng", "Jinjia", ""], ["Fu", "Xianping", ""]]}, {"id": "1903.07821", "submitter": "Yu Cheng", "authors": "Danli Wu, Yu Cheng, Dehan Luo, Kin-Yeung Wong, Kevin Hung, Zhijing\n  Yang", "title": "POP-CNN: Predicting Odor's Pleasantness with Convolutional Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting odor's pleasantness simplifies the evaluation of odors and has the\npotential to be applied in perfumes and environmental monitoring industry.\nClassical algorithms for predicting odor's pleasantness generally use a manual\nfeature extractor and an independent classifier. Manual designing a good\nfeature extractor depend on expert knowledge and experience is the key to the\naccuracy of the algorithms. In order to circumvent this difficulty, we proposed\na model for predicting odor's pleasantness by using convolutional neural\nnetwork. In our model, the convolutional neural layers replace manual feature\nextractor and show better performance. The experiments show that the\ncorrelation between our model and human is over 90% on pleasantness rating. And\nour model has 99.9% accuracy in distinguishing between absolutely pleasant or\nunpleasant odors.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 04:13:34 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Wu", "Danli", ""], ["Cheng", "Yu", ""], ["Luo", "Dehan", ""], ["Wong", "Kin-Yeung", ""], ["Hung", "Kevin", ""], ["Yang", "Zhijing", ""]]}, {"id": "1903.07822", "submitter": "Martin Hirzel", "authors": "Subhrajit Roy, Kiran Kate and Martin Hirzel", "title": "A semi-supervised deep learning algorithm for abnormal EEG\n  identification", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems that can automatically analyze EEG signals can aid neurologists by\nreducing heavy workload and delays. However, such systems need to be first\ntrained using a labeled dataset. While large corpuses of EEG data exist, a\nfraction of them are labeled. Hand-labeling data increases workload for the\nvery neurologists we try to aid. This paper proposes a semi-supervised learning\nworkflow that can not only extract meaningful information from large unlabeled\nEEG datasets but also make predictions with minimal supervision, using labeled\ndatasets as small as 5 examples.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 04:23:04 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 21:39:01 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Roy", "Subhrajit", ""], ["Kate", "Kiran", ""], ["Hirzel", "Martin", ""]]}, {"id": "1903.07824", "submitter": "Joseph Cheng", "authors": "Joseph Y. Cheng, Feiyu Chen, Christopher Sandino, Morteza Mardani,\n  John M. Pauly, Shreyas S. Vasanawala", "title": "Compressed Sensing: From Research to Clinical Practice with Data-Driven\n  Learning", "comments": "Submitted to the Special Issue on Computational MRI: Compressed\n  Sensing and Beyond in the IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing in MRI enables high subsampling factors while maintaining\ndiagnostic image quality. This technique enables shortened scan durations\nand/or improved image resolution. Further, compressed sensing can increase the\ndiagnostic information and value from each scan performed. Overall, compressed\nsensing has significant clinical impact in improving the diagnostic quality and\npatient experience for imaging exams. However, a number of challenges exist\nwhen moving compressed sensing from research to the clinic. These challenges\ninclude hand-crafted image priors, sensitive tuning parameters, and long\nreconstruction times. Data-driven learning provides a solution to address these\nchallenges. As a result, compressed sensing can have greater clinical impact.\nIn this tutorial, we will review the compressed sensing formulation and outline\nsteps needed to transform this formulation to a deep learning framework.\nSupplementary open source code in python will be used to demonstrate this\napproach with open databases. Further, we will discuss considerations in\napplying data-driven compressed sensing in the clinical setting.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 04:28:07 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Cheng", "Joseph Y.", ""], ["Chen", "Feiyu", ""], ["Sandino", "Christopher", ""], ["Mardani", "Morteza", ""], ["Pauly", "John M.", ""], ["Vasanawala", "Shreyas S.", ""]]}, {"id": "1903.07839", "submitter": "Junya Honda", "authors": "Junya Honda", "title": "A Note on KL-UCB+ Policy for the Stochastic Bandit", "comments": "6 pages, corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classic setting of the stochastic K-armed bandit problem is considered in\nthis note. In this problem it has been known that KL-UCB policy achieves the\nasymptotically optimal regret bound and KL-UCB+ policy empirically performs\nbetter than the KL-UCB policy although the regret bound for the original form\nof the KL-UCB+ policy has been unknown. This note demonstrates that a simple\nproof of the asymptotic optimality of the KL-UCB+ policy can be given by the\nsame technique as those used for analyses of other known policies.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 05:16:43 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 11:19:45 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Honda", "Junya", ""]]}, {"id": "1903.07840", "submitter": "John Skinner", "authors": "John Skinner, David Hall, Haoyang Zhang, Feras Dayoub, Niko\n  S\\\"underhauf", "title": "The Probabilistic Object Detection Challenge", "comments": "4 pages, workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new challenge for computer and robotic vision, the first ACRV\nRobotic Vision Challenge, Probabilistic Object Detection. Probabilistic object\ndetection is a new variation on traditional object detection tasks, requiring\nestimates of spatial and semantic uncertainty. We extend the traditional\nbounding box format of object detection to express spatial uncertainty using\ngaussian distributions for the box corners. The challenge introduces a new test\ndataset of video sequences, which are designed to more closely resemble the\nkind of data available to a robotic system. We evaluate probabilistic\ndetections using a new probability-based detection quality (PDQ) measure. The\ngoal in creating this challenge is to draw the computer and robotic vision\ncommunities together, toward applying object detection solutions for practical\nrobotics applications.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 05:18:52 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 00:58:24 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Skinner", "John", ""], ["Hall", "David", ""], ["Zhang", "Haoyang", ""], ["Dayoub", "Feras", ""], ["S\u00fcnderhauf", "Niko", ""]]}, {"id": "1903.07844", "submitter": "Li Wang", "authors": "Rong Jin, David Simchi-Levi, Li Wang, Xinshang Wang, Sen Yang", "title": "Shrinking the Upper Confidence Bound: A Dynamic Product Selection\n  Problem for Urban Warehouses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent rising popularity of ultra-fast delivery services on retail\nplatforms fuels the increasing use of urban warehouses, whose proximity to\ncustomers makes fast deliveries viable. The space limit in urban warehouses\nposes a problem for the online retailers: the number of products (SKUs) they\ncarry is no longer \"the more, the better\", yet it can still be significantly\nlarge, reaching hundreds or thousands in a product category. In this paper, we\nstudy algorithms for dynamically identifying a large number of products (i.e.,\nSKUs) with top customer purchase probabilities on the fly, from an ocean of\npotential products to offer on retailers' ultra-fast delivery platforms.\n  We distill the product selection problem into a semi-bandit model with linear\ngeneralization. There are in total $N$ different arms, each with a feature\nvector of dimension $d$. The player pulls $K$ arms in each period and observes\nthe bandit feedback from each of the pulled arms. We focus on the setting where\n$K$ is much greater than the number of total time periods $T$ or the dimension\nof product features $d$. We first analyze a standard UCB algorithm and show its\nregret bound can be expressed as the sum of a $T$-independent part $\\tilde O(K\nd^{3/2})$ and a $T$-dependent part $\\tilde O(d\\sqrt{KT})$, which we refer to as\n\"fixed cost\" and \"variable cost\" respectively. To reduce the fixed cost for\nlarge $K$ values, we propose a novel online learning algorithm, which\niteratively shrinks the upper confidence bounds within each period, and show\nits fixed cost is reduced by a factor of $d$ to $\\tilde O(K \\sqrt{d})$.\nMoreover, we test the algorithms on an industrial dataset from Alibaba Group.\nExperimental results show that our new algorithm reduces the total regret of\nthe standard UCB algorithm by at least 10%.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 05:34:00 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 19:01:14 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Jin", "Rong", ""], ["Simchi-Levi", "David", ""], ["Wang", "Li", ""], ["Wang", "Xinshang", ""], ["Yang", "Sen", ""]]}, {"id": "1903.07854", "submitter": "Liu Naijun", "authors": "Naijun Liu, Tao Lu, Yinghao Cai, Boyao Li, and Shuo Wang", "title": "Hindsight Generative Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to reinforcement learning, imitation learning (IL) is a powerful\nparadigm for training agents to learn control policies efficiently from expert\ndemonstrations. However, in most cases, obtaining demonstration data is costly\nand laborious, which poses a significant challenge in some scenarios. A\npromising alternative is to train agent learning skills via imitation learning\nwithout expert demonstrations, which, to some extent, would extremely expand\nimitation learning areas. To achieve such expectation, in this paper, we\npropose Hindsight Generative Adversarial Imitation Learning (HGAIL) algorithm,\nwith the aim of achieving imitation learning satisfying no need of\ndemonstrations. Combining hindsight idea with the generative adversarial\nimitation learning (GAIL) framework, we realize implementing imitation learning\nsuccessfully in cases of expert demonstration data are not available.\nExperiments show that the proposed method can train policies showing comparable\nperformance to current imitation learning methods. Further more, HGAIL\nessentially endows curriculum learning mechanism which is critical for learning\npolicies.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 06:16:56 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Liu", "Naijun", ""], ["Lu", "Tao", ""], ["Cai", "Yinghao", ""], ["Li", "Boyao", ""], ["Wang", "Shuo", ""]]}, {"id": "1903.07860", "submitter": "Guangneng Hu", "authors": "Guangneng Hu", "title": "Personalized Neural Embeddings for Collaborative Filtering with Text", "comments": "NAACL 2019 short papers, oral presentation", "journal-ref": "NAACL 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) is a core technique for recommender systems.\nTraditional CF approaches exploit user-item relations (e.g., clicks, likes, and\nviews) only and hence they suffer from the data sparsity issue. Items are\nusually associated with unstructured text such as article abstracts and product\nreviews. We develop a Personalized Neural Embedding (PNE) framework to exploit\nboth interactions and words seamlessly. We learn such embeddings of users,\nitems, and words jointly, and predict user preferences on items based on these\nlearned representations. PNE estimates the probability that a user will like an\nitem by two terms---behavior factors and semantic factors. On two real-world\ndatasets, PNE shows better performance than four state-of-the-art baselines in\nterms of three metrics. We also show that PNE learns meaningful word embeddings\nby visualization.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 07:05:59 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hu", "Guangneng", ""]]}, {"id": "1903.07864", "submitter": "Junting Zhang", "authors": "Junting Zhang, Jie Zhang, Shalini Ghosh, Dawei Li, Serafettin Tasci,\n  Larry Heck, Heming Zhang, C.-C. Jay Kuo", "title": "Class-incremental Learning via Deep Model Consolidation", "comments": "WACV 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) often suffer from \"catastrophic forgetting\"\nduring incremental learning (IL) --- an abrupt degradation of performance on\nthe original set of classes when the training objective is adapted to a newly\nadded set of classes. Existing IL approaches tend to produce a model that is\nbiased towards either the old classes or new classes, unless with the help of\nexemplars of the old data. To address this issue, we propose a\nclass-incremental learning paradigm called Deep Model Consolidation (DMC),\nwhich works well even when the original training data is not available. The\nidea is to first train a separate model only for the new classes, and then\ncombine the two individual models trained on data of two distinct set of\nclasses (old classes and new classes) via a novel double distillation training\nobjective. The two existing models are consolidated by exploiting publicly\navailable unlabeled auxiliary data. This overcomes the potential difficulties\ndue to the unavailability of original training data. Compared to the\nstate-of-the-art techniques, DMC demonstrates significantly better performance\nin image classification (CIFAR-100 and CUB-200) and object detection (PASCAL\nVOC 2007) in the single-headed IL setting.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 07:20:38 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 00:06:32 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 06:15:25 GMT"}, {"version": "v4", "created": "Thu, 16 Jan 2020 02:21:49 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Zhang", "Junting", ""], ["Zhang", "Jie", ""], ["Ghosh", "Shalini", ""], ["Li", "Dawei", ""], ["Tasci", "Serafettin", ""], ["Heck", "Larry", ""], ["Zhang", "Heming", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1903.07890", "submitter": "Roman Pogodin", "authors": "Roman Pogodin and Tor Lattimore", "title": "On First-Order Bounds, Variance and Gap-Dependent Bounds for Adversarial\n  Bandits", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make three contributions to the theory of k-armed adversarial bandits.\nFirst, we prove a first-order bound for a modified variant of the INF strategy\nby Audibert and Bubeck [2009], without sacrificing worst case optimality or\nmodifying the loss estimators. Second, we provide a variance analysis for\nalgorithms based on follow the regularised leader, showing that without\nadaptation the variance of the regret is typically {\\Omega}(n^2) where n is the\nhorizon. Finally, we study bounds that depend on the degree of separation of\nthe arms, generalising the results by Cowan and Katehakis [2015] from the\nstochastic setting to the adversarial and improving the result of Seldin and\nSlivkins [2014] by a factor of log(n)/log(log(n)).\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 09:05:43 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 13:09:50 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 12:39:55 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Pogodin", "Roman", ""], ["Lattimore", "Tor", ""]]}, {"id": "1903.07902", "submitter": "Vinay Setty", "authors": "Megha Khosla and Vinay Setty and Avishek Anand", "title": "A Comparative Study for Unsupervised Network Representation Learning", "comments": "Accepted for publication in IEEE TKDE", "journal-ref": null, "doi": "10.1109/TKDE.2019.2951398", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been appreciable progress in unsupervised network representation\nlearning (UNRL) approaches over graphs recently with flexible random-walk\napproaches, new optimization objectives and deep architectures. However, there\nis no common ground for systematic comparison of embeddings to understand their\nbehavior for different graphs and tasks. In this paper we theoretically group\ndifferent approaches under a unifying framework and empirically investigate the\neffectiveness of different network representation methods. In particular, we\nargue that most of the UNRL approaches either explicitly or implicit model and\nexploit context information of a node. Consequently, we propose a framework\nthat casts a variety of approaches -- random walk based, matrix factorization\nand deep learning based -- into a unified context-based optimization function.\nWe systematically group the methods based on their similarities and\ndifferences. We study the differences among these methods in detail which we\nlater use to explain their performance differences (on downstream tasks). We\nconduct a large-scale empirical study considering 9 popular and recent UNRL\ntechniques and 11 real-world datasets with varying structural properties and\ntwo common tasks -- node classification and link prediction. We find that there\nis no single method that is a clear winner and that the choice of a suitable\nmethod is dictated by certain properties of the embedding methods, task and\nstructural properties of the underlying graph. In addition we also report the\ncommon pitfalls in evaluation of UNRL methods and come up with suggestions for\nexperimental design and interpretation of results.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 09:36:22 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 18:19:22 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 20:24:47 GMT"}, {"version": "v4", "created": "Sat, 2 Nov 2019 17:36:28 GMT"}, {"version": "v5", "created": "Mon, 18 Nov 2019 12:07:43 GMT"}, {"version": "v6", "created": "Wed, 11 Mar 2020 14:03:04 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Khosla", "Megha", ""], ["Setty", "Vinay", ""], ["Anand", "Avishek", ""]]}, {"id": "1903.07903", "submitter": "Frederik Kratzert", "authors": "Frederik Kratzert, Mathew Herrnegger, Daniel Klotz, Sepp Hochreiter,\n  G\\\"unter Klambauer", "title": "NeuralHydrology -- Interpreting LSTMs in Hydrology", "comments": "Pre-print of published book chapter. See journal reference and DOI\n  for more info", "journal-ref": "In: Samek W., Montavon G., Vedaldi A., Hansen L., Muller KR. (eds)\n  Explainable AI: Interpreting, Explaining and Visualizing Deep Learning.\n  Lecture Notes in Computer Science, vol 11700. Springer, Cham, 2019", "doi": "10.1007/978-3-030-28954-6_19", "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the huge success of Long Short-Term Memory networks, their\napplications in environmental sciences are scarce. We argue that one reason is\nthe difficulty to interpret the internals of trained networks. In this study,\nwe look at the application of LSTMs for rainfall-runoff forecasting, one of the\ncentral tasks in the field of hydrology, in which the river discharge has to be\npredicted from meteorological observations. LSTMs are particularly well-suited\nfor this problem since memory cells can represent dynamic reservoirs and\nstorages, which are essential components in state-space modelling approaches of\nthe hydrological system. On basis of two different catchments, one with snow\ninfluence and one without, we demonstrate how the trained model can be analyzed\nand interpreted. In the process, we show that the network internally learns to\nrepresent patterns that are consistent with our qualitative understanding of\nthe hydrological system.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 09:38:37 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 07:17:36 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Kratzert", "Frederik", ""], ["Herrnegger", "Mathew", ""], ["Klotz", "Daniel", ""], ["Hochreiter", "Sepp", ""], ["Klambauer", "G\u00fcnter", ""]]}, {"id": "1903.07933", "submitter": "Christoph Sch\\\"oller", "authors": "Christoph Sch\\\"oller, Vincent Aravantinos, Florian Lay, and Alois\n  Knoll", "title": "What the Constant Velocity Model Can Teach Us About Pedestrian Motion\n  Prediction", "comments": "Accepted for publication in the IEEE Robotics and Automation Letters\n  (RA-L) and for presentation at the 2020 International Conference on Robotics\n  and Automation (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pedestrian motion prediction is a fundamental task for autonomous robots and\nvehicles to operate safely. In recent years many complex approaches based on\nneural networks have been proposed to address this problem. In this work we\nshow that - surprisingly - a simple Constant Velocity Model can outperform even\nstate-of-the-art neural models. This indicates that either neural networks are\nnot able to make use of the additional information they are provided with, or\nthat this information is not as relevant as commonly believed. Therefore, we\nanalyze how neural networks process their input and how it impacts their\npredictions. Our analysis reveals pitfalls in training neural networks for\npedestrian motion prediction and clarifies false assumptions about the problem\nitself. In particular, neural networks implicitly learn environmental priors\nthat negatively impact their generalization capability, the motion history of\npedestrians is irrelevant and interactions are too complex to predict. Our work\nshows how neural networks for pedestrian motion prediction can be thoroughly\nevaluated and our results indicate which research directions for neural motion\nprediction are promising in future.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 10:56:44 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 13:25:11 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 11:52:02 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Sch\u00f6ller", "Christoph", ""], ["Aravantinos", "Vincent", ""], ["Lay", "Florian", ""], ["Knoll", "Alois", ""]]}, {"id": "1903.07940", "submitter": "Yuhui Wang", "authors": "Yuhui Wang, Hao He, Chao Wen, Xiaoyang Tan", "title": "Truly Proximal Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal policy optimization (PPO) is one of the most successful deep\nreinforcement-learning methods, achieving state-of-the-art performance across a\nwide range of challenging tasks. However, its optimization behavior is still\nfar from being fully understood. In this paper, we show that PPO could neither\nstrictly restrict the likelihood ratio as it attempts to do nor enforce a\nwell-defined trust region constraint, which means that it may still suffer from\nthe risk of performance instability. To address this issue, we present an\nenhanced PPO method, named Truly PPO. Two critical improvements are made in our\nmethod: 1) it adopts a new clipping function to support a rollback behavior to\nrestrict the difference between the new policy and the old one; 2) the\ntriggering condition for clipping is replaced with a trust region-based one,\nsuch that optimizing the resulted surrogate objective function provides\nguaranteed monotonic improvement of the ultimate policy performance. It seems,\nby adhering more truly to making the algorithm proximal - confining the policy\nwithin the trust region, the new algorithm improves the original PPO on both\nsample efficiency and performance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 11:18:29 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 03:59:49 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Wang", "Yuhui", ""], ["He", "Hao", ""], ["Wen", "Chao", ""], ["Tan", "Xiaoyang", ""]]}, {"id": "1903.07949", "submitter": "Xiangxiang Chu", "authors": "Hailong Ma and Xiangxiang Chu and Bo Zhang and Shaohua Wan and Bo\n  Zhang", "title": "A Matrix-in-matrix Neural Network for Image Super Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning methods have achieved impressive results with\nhigher peak signal-to-noise ratio in single image super-resolution (SISR) tasks\nby utilizing deeper layers. However, their application is quite limited since\nthey require high computing power. In addition, most of the existing methods\nrarely take full advantage of the intermediate features which are helpful for\nrestoration. To address these issues, we propose a moderate-size SISR net work\nnamed matrixed channel attention network (MCAN) by constructing a matrix\nensemble of multi-connected channel attention blocks (MCAB). Several models of\ndifferent sizes are released to meet various practical requirements.\nConclusions can be drawn from our extensive benchmark experiments that the\nproposed models achieve better performance with much fewer multiply-adds and\nparameters. Our models will be made publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 11:39:54 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Ma", "Hailong", ""], ["Chu", "Xiangxiang", ""], ["Zhang", "Bo", ""], ["Wan", "Shaohua", ""], ["Zhang", "Bo", ""]]}, {"id": "1903.07970", "submitter": "Mohammad Siami", "authors": "Mohammad Siami, Mohsen Naderpour, and Jie Lu", "title": "A Choquet Fuzzy Integral Vertical Bagging Classifier for Mobile\n  Telematics Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile app development in recent years has resulted in new products and\nfeatures to improve human life. Mobile telematics is one such development that\nencompasses multidisciplinary fields for transportation safety. The application\nof mobile telematics has been explored in many areas, such as insurance and\nroad safety. However, to the best of our knowledge, its application in gender\ndetection has not been explored. This paper proposes a Choquet fuzzy integral\nvertical bagging classifier that detects gender through mobile telematics. In\nthis model, different random forest classifiers are trained by randomly\ngenerated features with rough set theory, and the top three classifiers are\nfused using the Choquet fuzzy integral. The model is implemented and evaluated\non a real dataset. The empirical results indicate that the Choquet fuzzy\nintegral vertical bagging classifier outperforms other classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 12:52:46 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Siami", "Mohammad", ""], ["Naderpour", "Mohsen", ""], ["Lu", "Jie", ""]]}, {"id": "1903.07971", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Peter Richt\\'arik", "title": "Convergence Analysis of Inexact Randomized Iterative Methods", "comments": "29 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a convergence rate analysis of inexact variants of\nseveral randomized iterative methods. Among the methods studied are: stochastic\ngradient descent, stochastic Newton, stochastic proximal point and stochastic\nsubspace ascent. A common feature of these methods is that in their update rule\na certain sub-problem needs to be solved exactly. We relax this requirement by\nallowing for the sub-problem to be solved inexactly. In particular, we propose\nand analyze inexact randomized iterative methods for solving three closely\nrelated problems: a convex stochastic quadratic optimization problem, a best\napproximation problem and its dual, a concave quadratic maximization problem.\nWe provide iteration complexity results under several assumptions on the\ninexactness error. Inexact variants of many popular and some more exotic\nmethods, including randomized block Kaczmarz, randomized Gaussian Kaczmarz and\nrandomized block coordinate descent, can be cast as special cases. Numerical\nexperiments demonstrate the benefits of allowing inexactness.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 12:58:06 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1903.07977", "submitter": "Ahmad Ilham", "authors": "Ahmad Ilham, Danny Ibrahim, Luqman Assaffat, Achmad Solichan", "title": "Tackling Initial Centroid of K-Means with Distance Part (DP-KMeans)", "comments": "This paper was presented at Proceeding of 2018 International\n  Symposium on Advanced Intelligent Informatics (SAIN), 29-30 August 2018,\n  Yogyakarta, Indonesia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The initial centroid is a fairly challenging problem in the k-means method\nbecause it can affect the clustering results. In addition, choosing the\nstarting centroid of the cluster is not always appropriate, especially, when\nthe number of groups increases.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 02:21:25 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Ilham", "Ahmad", ""], ["Ibrahim", "Danny", ""], ["Assaffat", "Luqman", ""], ["Solichan", "Achmad", ""]]}, {"id": "1903.07981", "submitter": "Umit Kacar", "authors": "Cihan Ak{\\i}n, Umit Kacar, Murvet Kirci", "title": "Twins Recognition with Multi Biometric System: Handcrafted-Deep Learning\n  Based Multi Algorithm with Voice-Ear Recognition Based Multi Modal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of technology, the usage areas and importance of\nbiometric systems have started to increase. Since the characteristics of each\nperson are different from each other, a single model biometric system can yield\nsuccessful results. However, because the characteristics of twin people are\nvery close to each other, multiple biometric systems including multiple\ncharacteristics of individuals will be more appropriate and will increase the\nrecognition rate. In this study, a multiple biometric recognition system\nconsisting of a combination of multiple algorithms and multiple models was\ndeveloped to distinguish people from other people and their twins. Ear and\nvoice biometric data were used for the multimodal model and 38 pair of twin ear\nimages and sound recordings were used in the data set. Sound and ear\nrecognition rates were obtained using classical (hand-crafted) and deep\nlearning algorithms. The results obtained were combined with the score level\nfusion method to achieve a success rate of 94.74% in rank-1 and 100% in rank\n-2.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 12:30:14 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Ak\u0131n", "Cihan", ""], ["Kacar", "Umit", ""], ["Kirci", "Murvet", ""]]}, {"id": "1903.07988", "submitter": "Endre Grovik", "authors": "Endre Gr{\\o}vik, Darvin Yi, Michael Iv, Elisabeth Tong, Daniel L.\n  Rubin, Greg Zaharchuk", "title": "Deep Learning Enables Automatic Detection and Segmentation of Brain\n  Metastases on Multi-Sequence MRI", "comments": null, "journal-ref": null, "doi": "10.1002/jmri.26766", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and segmenting brain metastases is a tedious and time-consuming\ntask for many radiologists, particularly with the growing use of multi-sequence\n3D imaging. This study demonstrates automated detection and segmentation of\nbrain metastases on multi-sequence MRI using a deep learning approach based on\na fully convolution neural network (CNN). In this retrospective study, a total\nof 156 patients with brain metastases from several primary cancers were\nincluded. Pre-therapy MR images (1.5T and 3T) included pre- and post-gadolinium\nT1-weighted 3D fast spin echo, post-gadolinium T1-weighted 3D axial IR-prepped\nFSPGR, and 3D fluid attenuated inversion recovery. The ground truth was\nestablished by manual delineation by two experienced neuroradiologists. CNN\ntraining/development was performed using 100 and 5 patients, respectively, with\na 2.5D network based on a GoogLeNet architecture. The results were evaluated in\n51 patients, equally separated into those with few (1-3), multiple (4-10), and\nmany (>10) lesions. Network performance was evaluated using precision, recall,\nDice/F1 score, and ROC-curve statistics. For an optimal probability threshold,\ndetection and segmentation performance was assessed on a per metastasis basis.\nThe area under the ROC-curve (AUC), averaged across all patients, was 0.98. The\nAUC in the subgroups was 0.99, 0.97, and 0.97 for patients having 1-3, 4-10,\nand >10 metastases, respectively. Using an average optimal probability\nthreshold determined by the development set, precision, recall, and Dice-score\nwere 0.79, 0.53, and 0.79, respectively. At the same probability threshold, the\nnetwork showed an average false positive rate of 8.3/patient (no lesion-size\nlimit) and 3.4/patient (10 mm3 lesion size limit). In conclusion, a deep\nlearning approach using multi-sequence MRI can aid in the detection and\nsegmentation of brain metastases.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 09:48:42 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Gr\u00f8vik", "Endre", ""], ["Yi", "Darvin", ""], ["Iv", "Michael", ""], ["Tong", "Elisabeth", ""], ["Rubin", "Daniel L.", ""], ["Zaharchuk", "Greg", ""]]}, {"id": "1903.07994", "submitter": "Yu-Jing Lin", "authors": "Yu-Jing Lin, Po-Wei Wu, Cheng-Han Hsu, I-Ping Tu, Shih-wei Liao", "title": "An Evaluation of Bitcoin Address Classification based on Transaction\n  History Summarization", "comments": "8 pages; accepted by ICBC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is a cryptocurrency that features a distributed, decentralized and\ntrustworthy mechanism, which has made Bitcoin a popular global transaction\nplatform. The transaction efficiency among nations and the privacy benefiting\nfrom address anonymity of the Bitcoin network have attracted many activities\nsuch as payments, investments, gambling, and even money laundering in the past\ndecade. Unfortunately, some criminal behaviors which took advantage of this\nplatform were not identified. This has discouraged many governments to support\ncryptocurrency. Thus, the capability to identify criminal addresses becomes an\nimportant issue in the cryptocurrency network. In this paper, we propose new\nfeatures in addition to those commonly used in the literature to build a\nclassification model for detecting abnormality of Bitcoin network addresses.\nThese features include various high orders of moments of transaction time\n(represented by block height) which summarizes the transaction history in an\nefficient way. The extracted features are trained by supervised machine\nlearning methods on a labeling category data set. The experimental evaluation\nshows that these features have improved the performance of Bitcoin address\nclassification significantly. We evaluate the results under eight classifiers\nand achieve the highest Micro-F1/Macro-F1 of 87%/86% with LightGBM.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 13:36:36 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Lin", "Yu-Jing", ""], ["Wu", "Po-Wei", ""], ["Hsu", "Cheng-Han", ""], ["Tu", "I-Ping", ""], ["Liao", "Shih-wei", ""]]}, {"id": "1903.08011", "submitter": "Alexander Hvatov", "authors": "Michail Maslyaev and Alexander Hvatov and Anna Kalyuzhnaya", "title": "Data-driven PDE discovery with evolutionary approach", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-22750-0_61", "report-no": null, "categories": "cs.NE cs.LG math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data-driven models allow one to define the model structure in cases when\na priori information is not sufficient to build other types of models. The\npossible way to obtain physical interpretation is the data-driven differential\nequation discovery techniques. The existing methods of PDE (partial derivative\nequations) discovery are bound with the sparse regression. However, sparse\nregression is restricting the resulting model form, since the terms for PDE are\ndefined before regression. The evolutionary approach described in the article\nhas a symbolic regression as the background instead and thus has fewer\nrestrictions on the PDE form. The evolutionary method of PDE discovery (EPDE)\nis described and tested on several canonical PDEs. The question of robustness\nis examined on a noised data example.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 14:16:45 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 09:13:06 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Maslyaev", "Michail", ""], ["Hvatov", "Alexander", ""], ["Kalyuzhnaya", "Anna", ""]]}, {"id": "1903.08012", "submitter": "Fran\\c{c}ois Th\\'eberge", "authors": "Val\\'erie Poulin, Fran\\c{c}ois Th\\'eberge", "title": "Ensemble Clustering for Graphs: Comparisons and Applications", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": "10.1007/s41109-019-0162-z", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recently proposed a new ensemble clustering algorithm for graphs (ECG)\nbased on the concept of consensus clustering. We validated our approach by\nreplicating a study comparing graph clustering algorithms over benchmark\ngraphs, showing that ECG outperforms the leading algorithms. In this paper, we\nextend our comparison by considering a wider range of parameters for the\nbenchmark, generating graphs with different properties. We provide new\nexperimental results showing that the ECG algorithm alleviates the well-known\nresolution limit issue, and that it leads to better stability of the\npartitions. We also illustrate how the ensemble obtained with ECG can be used\nto quantify the presence of community structure in the graph, and to zoom in on\nthe sub-graph most closely associated with seed vertices. Finally, we\nillustrate further applications of ECG by comparing it to previous results for\ncommunity detection on weighted graphs, and community-aware anomaly detection.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 14:18:27 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Poulin", "Val\u00e9rie", ""], ["Th\u00e9berge", "Fran\u00e7ois", ""]]}, {"id": "1903.08023", "submitter": "Pedro Gonnet", "authors": "Pedro Gonnet, Thomas Deselaers", "title": "IndyLSTMs: Independently Recurrent LSTMs", "comments": "8 pages, submitted to ICDAR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Independently Recurrent Long Short-term Memory cells: IndyLSTMs.\nThese differ from regular LSTM cells in that the recurrent weights are not\nmodeled as a full matrix, but as a diagonal matrix, i.e.\\ the output and state\nof each LSTM cell depends on the inputs and its own output/state, as opposed to\nthe input and the outputs/states of all the cells in the layer. The number of\nparameters per IndyLSTM layer, and thus the number of FLOPS per evaluation, is\nlinear in the number of nodes in the layer, as opposed to quadratic for regular\nLSTM layers, resulting in potentially both smaller and faster models. We\nevaluate their performance experimentally by training several models on the\npopular \\iamondb and CASIA online handwriting datasets, as well as on several\nof our in-house datasets. We show that IndyLSTMs, despite their smaller size,\nconsistently outperform regular LSTMs both in terms of accuracy per parameter,\nand in best accuracy overall. We attribute this improved performance to the\nIndyLSTMs being less prone to overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 14:33:49 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Gonnet", "Pedro", ""], ["Deselaers", "Thomas", ""]]}, {"id": "1903.08066", "submitter": "Sambhav R. Jain", "authors": "Sambhav R. Jain, Albert Gural, Michael Wu, Chris H. Dick", "title": "Trained Quantization Thresholds for Accurate and Efficient Fixed-Point\n  Inference of Deep Neural Networks", "comments": "Link to Conference (Oral & Poster) Schedule -\n  https://mlsys.org/Conferences/2020/ScheduleMultitrack?event=1431", "journal-ref": "Proceedings of the 3rd Machine Learning and Systems (MLSys)\n  Conference, Austin, TX, USA, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method of training quantization thresholds (TQT) for uniform\nsymmetric quantizers using standard backpropagation and gradient descent.\nContrary to prior work, we show that a careful analysis of the straight-through\nestimator for threshold gradients allows for a natural range-precision\ntrade-off leading to better optima. Our quantizers are constrained to use\npower-of-2 scale-factors and per-tensor scaling of weights and activations to\nmake it amenable for hardware implementations. We present analytical support\nfor the general robustness of our methods and empirically validate them on\nvarious CNNs for ImageNet classification. We are able to achieve\nnear-floating-point accuracy on traditionally difficult networks such as\nMobileNets with less than 5 epochs of quantized (8-bit) retraining. Finally, we\npresent Graffitist, a framework that enables automatic quantization of\nTensorFlow graphs for TQT (available at https://github.com/Xilinx/graffitist ).\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 15:50:24 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 06:24:16 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 18:21:29 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Jain", "Sambhav R.", ""], ["Gural", "Albert", ""], ["Wu", "Michael", ""], ["Dick", "Chris H.", ""]]}, {"id": "1903.08072", "submitter": "Samy Blusseau", "authors": "Yunxiang Zhang (CMM, LTCI), Samy Blusseau (CMM), Santiago\n  Velasco-Forero (CMM), Isabelle Bloch (LTCI), Jesus Angulo (CMM)", "title": "Max-plus Operators Applied to Filter Selection and Model Pruning in\n  Neural Networks", "comments": null, "journal-ref": "International Symposium on Mathematical Morphology, Jul 2019,\n  Saarbr{\\\"u}cken, Germany", "doi": null, "report-no": null, "categories": "math.ST cs.CV cs.LG cs.NE stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following recent advances in morphological neural networks, we propose to\nstudy in more depth how Max-plus operators can be exploited to define\nmorphological units and how they behave when incorporated in layers of\nconventional neural networks. Besides showing that they can be easily\nimplemented with modern machine learning frameworks , we confirm and extend the\nobservation that a Max-plus layer can be used to select important filters and\nreduce redundancy in its previous layer, without incurring performance loss.\nExperimental results demonstrate that the filter selection strategy enabled by\na Max-plus is highly efficient and robust, through which we successfully\nperformed model pruning on different neural network architectures. We also\npoint out that there is a close connection between Maxout networks and our\npruned Max-plus networks by comparing their respective characteristics. The\ncode for reproducing our experiments is available online.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 15:58:43 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 12:51:57 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhang", "Yunxiang", "", "CMM, LTCI"], ["Blusseau", "Samy", "", "CMM"], ["Velasco-Forero", "Santiago", "", "CMM"], ["Bloch", "Isabelle", "", "LTCI"], ["Angulo", "Jesus", "", "CMM"]]}, {"id": "1903.08082", "submitter": "Tom Eccles", "authors": "Tom Eccles, Edward Hughes, J\\'anos Kram\\'ar, Steven Wheelwright, Joel\n  Z. Leibo", "title": "Learning Reciprocity in Complex Sequential Social Dilemmas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reciprocity is an important feature of human social interaction and underpins\nour cooperative nature. What is more, simple forms of reciprocity have proved\nremarkably resilient in matrix game social dilemmas. Most famously, the\ntit-for-tat strategy performs very well in tournaments of Prisoner's Dilemma.\nUnfortunately this strategy is not readily applicable to the real world, in\nwhich options to cooperate or defect are temporally and spatially extended.\nHere, we present a general online reinforcement learning algorithm that\ndisplays reciprocal behavior towards its co-players. We show that it can induce\npro-social outcomes for the wider group when learning alongside selfish agents,\nboth in a $2$-player Markov game, and in $5$-player intertemporal social\ndilemmas. We analyse the resulting policies to show that the reciprocating\nagents are strongly influenced by their co-players' behavior.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 16:18:00 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Eccles", "Tom", ""], ["Hughes", "Edward", ""], ["Kram\u00e1r", "J\u00e1nos", ""], ["Wheelwright", "Steven", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "1903.08100", "submitter": "Diyuan Lu", "authors": "Diyuan Lu, Jochen Triesch", "title": "Residual Deep Convolutional Neural Network for EEG Signal Classification\n  in Epilepsy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is the fourth most common neurological disorder, affecting about 1%\nof the population at all ages. As many as 60% of people with epilepsy\nexperience focal seizures which originate in a certain brain area and are\nlimited to part of one cerebral hemisphere. In focal epilepsy patients, a\nprecise surgical removal of the seizure onset zone can lead to effective\nseizure control or even a seizure-free outcome. Thus, correct identification of\nthe seizure onset zone is essential. For clinical evaluation purposes,\nelectroencephalography (EEG) recordings are commonly used. However, their\ninterpretation is usually done manually by physicians and is time-consuming and\nerror-prone. In this work, we propose an automated epileptic signal\nclassification method based on modern deep learning methods. In contrast to\nprevious approaches, the network is trained directly on the EEG recordings,\navoiding hand-crafted feature extraction and selection procedures. This\nexploits the ability of deep neural networks to detect and extract relevant\nfeatures automatically, that may be too complex or subtle to be noticed by\nhumans. The proposed network structure is based on a convolutional neural\nnetwork with residual connections. We demonstrate that our network produces\nstate-of-the-art performance on two benchmark data sets, a data set from Bonn\nUniversity and the Bern-Barcelona data set. We conclude that modern deep\nlearning approaches can reach state-of-the-art performance on epileptic EEG\nclassification and automated seizure onset zone identification tasks when\ntrained on raw EEG data. This suggests that such approaches have potential for\nimproving clinical practice.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 16:38:19 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Lu", "Diyuan", ""], ["Triesch", "Jochen", ""]]}, {"id": "1903.08110", "submitter": "Arun Sai Suggala", "authors": "Arun Sai Suggala and Praneeth Netrapalli", "title": "Online Non-Convex Learning: Following the Perturbed Leader is Optimal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online learning with non-convex losses, where the\nlearner has access to an offline optimization oracle. We show that the\nclassical Follow the Perturbed Leader (FTPL) algorithm achieves optimal regret\nrate of $O(T^{-1/2})$ in this setting. This improves upon the previous\nbest-known regret rate of $O(T^{-1/3})$ for FTPL. We further show that an\noptimistic variant of FTPL achieves better regret bounds when the sequence of\nlosses encountered by the learner is `predictable'.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 16:54:43 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 00:19:23 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Suggala", "Arun Sai", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1903.08113", "submitter": "Marco Tulio Valente", "authors": "Joao Eduardo Montandon, Luciana Lourdes Silva, Marco Tulio Valente", "title": "Identifying Experts in Software Libraries and Frameworks among GitHub\n  Users", "comments": "Accepted at MSR 2019: 16th International Conference on Mining\n  Software Repositories", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software development increasingly depends on libraries and frameworks to\nincrease productivity and reduce time-to-market. Despite this fact, we still\nlack techniques to assess developers expertise in widely popular libraries and\nframeworks. In this paper, we evaluate the performance of unsupervised (based\non clustering) and supervised machine learning classifiers (Random Forest and\nSVM) to identify experts in three popular JavaScript libraries: facebook/react,\nmongodb/node-mongodb, and socketio/socket.io. First, we collect 13 features\nabout developers activity on GitHub projects, including commits on source code\nfiles that depend on these libraries. We also build a ground truth including\nthe expertise of 575 developers on the studied libraries, as self-reported by\nthem in a survey. Based on our findings, we document the challenges of using\nmachine learning classifiers to predict expertise in software libraries, using\nfeatures extracted from GitHub. Then, we propose a method to identify library\nexperts based on clustering feature data from GitHub; by triangulating the\nresults of this method with information available on Linkedin profiles, we show\nthat it is able to recommend dozens of GitHub users with evidences of being\nexperts in the studied JavaScript libraries. We also provide a public dataset\nwith the expertise of 575 developers on the studied libraries.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 17:02:37 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Montandon", "Joao Eduardo", ""], ["Silva", "Luciana Lourdes", ""], ["Valente", "Marco Tulio", ""]]}, {"id": "1903.08114", "submitter": "Ke Alexander Wang", "authors": "Ke Alexander Wang, Geoff Pleiss, Jacob R. Gardner, Stephen Tyree,\n  Kilian Q. Weinberger, Andrew Gordon Wilson", "title": "Exact Gaussian Processes on a Million Data Points", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are flexible non-parametric models, with a capacity\nthat grows with the available data. However, computational constraints with\nstandard inference procedures have limited exact GPs to problems with fewer\nthan about ten thousand training points, necessitating approximations for\nlarger datasets. In this paper, we develop a scalable approach for exact GPs\nthat leverages multi-GPU parallelization and methods like linear conjugate\ngradients, accessing the kernel matrix only through matrix multiplication. By\npartitioning and distributing kernel matrix multiplies, we demonstrate that an\nexact GP can be trained on over a million points, a task previously thought to\nbe impossible with current computing hardware, in less than 2 hours. Moreover,\nour approach is generally applicable, without constraints to grid data or\nspecific kernel classes. Enabled by this scalability, we perform the first-ever\ncomparison of exact GPs against scalable GP approximations on datasets with\n$10^4 \\!-\\! 10^6$ data points, showing dramatic performance improvements.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 17:10:28 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 18:44:52 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Wang", "Ke Alexander", ""], ["Pleiss", "Geoff", ""], ["Gardner", "Jacob R.", ""], ["Tyree", "Stephen", ""], ["Weinberger", "Kilian Q.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1903.08129", "submitter": "Hui Wang", "authors": "Hui Wang, Michael Emmerich, Mike Preuss, Aske Plaat", "title": "Hyper-Parameter Sweep on AlphaZero General", "comments": "19 pages 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since AlphaGo and AlphaGo Zero have achieved breakground successes in the\ngame of Go, the programs have been generalized to solve other tasks.\nSubsequently, AlphaZero was developed to play Go, Chess and Shogi. In the\nliterature, the algorithms are explained well. However, AlphaZero contains many\nparameters, and for neither AlphaGo, AlphaGo Zero nor AlphaZero, there is\nsufficient discussion about how to set parameter values in these algorithms.\nTherefore, in this paper, we choose 12 parameters in AlphaZero and evaluate how\nthese parameters contribute to training. We focus on three objectives~(training\nloss, time cost and playing strength). For each parameter, we train 3 models\nusing 3 different values~(minimum value, default value, maximum value). We use\nthe game of play 6$\\times$6 Othello, on the AlphaZeroGeneral open source\nre-implementation of AlphaZero. Overall, experimental results show that\ndifferent values can lead to different training results, proving the importance\nof such a parameter sweep. We categorize these 12 parameters into\ntime-sensitive parameters and time-friendly parameters. Moreover, through\nmulti-objective analysis, this paper provides an insightful basis for further\nhyper-parameter optimization.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 17:38:46 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Wang", "Hui", ""], ["Emmerich", "Michael", ""], ["Preuss", "Mike", ""], ["Plaat", "Aske", ""]]}, {"id": "1903.08131", "submitter": "Corinne Jones", "authors": "Corinne Jones, Vincent Roulet, Zaid Harchaoui", "title": "Kernel-based Translations of Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks, as most artificial neural networks, are\ncommonly viewed as methods different in essence from kernel-based methods. We\nprovide a systematic translation of Convolutional Neural Networks (ConvNets)\ninto their kernel-based counterparts, Convolutional Kernel Networks (CKNs), and\ndemonstrate that this perception is unfounded both formally and empirically. We\nshow that, given a Convolutional Neural Network, we can design a corresponding\nConvolutional Kernel Network, easily trainable using a new stochastic gradient\nalgorithm based on an accurate gradient computation, that performs on par with\nits Convolutional Neural Network counterpart. We present experimental results\nsupporting our claims on landmark ConvNet architectures comparing each ConvNet\nto its CKN counterpart over several parameter settings.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 17:41:48 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Jones", "Corinne", ""], ["Roulet", "Vincent", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "1903.08192", "submitter": "Arun Sai Suggala", "authors": "Arun Sai Suggala, Kush Bhatia, Pradeep Ravikumar, Prateek Jain", "title": "Adaptive Hard Thresholding for Near-optimal Consistent Robust Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robust linear regression with response variable\ncorruptions. We consider the oblivious adversary model, where the adversary\ncorrupts a fraction of the responses in complete ignorance of the data. We\nprovide a nearly linear time estimator which consistently estimates the true\nregression vector, even with $1-o(1)$ fraction of corruptions. Existing results\nin this setting either don't guarantee consistent estimates or can only handle\na small fraction of corruptions. We also extend our estimator to robust sparse\nlinear regression and show that similar guarantees hold in this setting.\nFinally, we apply our estimator to the problem of linear regression with\nheavy-tailed noise and show that our estimator consistently estimates the\nregression vector even when the noise has unbounded variance (e.g., Cauchy\ndistribution), for which most existing results don't even apply. Our estimator\nis based on a novel variant of outlier removal via hard thresholding in which\nthe threshold is chosen adaptively and crucially relies on randomness to escape\nbad fixed points of the non-convex hard thresholding operation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 18:08:20 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Suggala", "Arun Sai", ""], ["Bhatia", "Kush", ""], ["Ravikumar", "Pradeep", ""], ["Jain", "Prateek", ""]]}, {"id": "1903.08193", "submitter": "Junyu Cao", "authors": "Junyu Cao, Wei Sun", "title": "Dynamic Learning of Sequential Choice Bandit Problem under Marketing\n  Fatigue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the observation that overexposure to unwanted marketing\nactivities leads to customer dissatisfaction, we consider a setting where a\nplatform offers a sequence of messages to its users and is penalized when users\nabandon the platform due to marketing fatigue. We propose a novel sequential\nchoice model to capture multiple interactions taking place between the platform\nand its user: Upon receiving a message, a user decides on one of the three\nactions: accept the message, skip and receive the next message, or abandon the\nplatform. Based on user feedback, the platform dynamically learns users'\nabandonment distribution and their valuations of messages to determine the\nlength of the sequence and the order of the messages, while maximizing the\ncumulative payoff over a horizon of length T. We refer to this online learning\ntask as the sequential choice bandit problem. For the offline combinatorial\noptimization problem, we show that an efficient polynomial-time algorithm\nexists. For the online problem, we propose an algorithm that balances\nexploration and exploitation, and characterize its regret bound. Lastly, we\ndemonstrate how to extend the model with user contexts to incorporate\npersonalization.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 18:09:45 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Cao", "Junyu", ""], ["Sun", "Wei", ""]]}, {"id": "1903.08254", "submitter": "Kate Rakelly", "authors": "Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, Sergey\n  Levine", "title": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic\n  Context Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms require large amounts of experience to\nlearn an individual task. While in principle meta-reinforcement learning\n(meta-RL) algorithms enable agents to learn new skills from small amounts of\nexperience, several major challenges preclude their practicality. Current\nmethods rely heavily on on-policy experience, limiting their sample efficiency.\nThe also lack mechanisms to reason about task uncertainty when adapting to new\ntasks, limiting their effectiveness in sparse reward problems. In this paper,\nwe address these challenges by developing an off-policy meta-RL algorithm that\ndisentangles task inference and control. In our approach, we perform online\nprobabilistic filtering of latent task variables to infer how to solve a new\ntask from small amounts of experience. This probabilistic interpretation\nenables posterior sampling for structured and efficient exploration. We\ndemonstrate how to integrate these task variables with off-policy RL algorithms\nto achieve both meta-training and adaptation efficiency. Our method outperforms\nprior algorithms in sample efficiency by 20-100X as well as in asymptotic\nperformance on several meta-RL benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 20:51:04 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Rakelly", "Kate", ""], ["Zhou", "Aurick", ""], ["Quillen", "Deirdre", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "1903.08256", "submitter": "Tim Jaschek", "authors": "Tim Jaschek, Marko Bucyk, and Jaspreet S. Oberoi", "title": "A Quantum Annealing-Based Approach to Extreme Clustering", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering, or grouping, dataset elements based on similarity can be used not\nonly to classify a dataset into a few categories, but also to approximate it by\na relatively large number of representative elements. In the latter scenario,\nreferred to as extreme clustering, datasets are enormous and the number of\nrepresentative clusters is large. We have devised a distributed method that can\nefficiently solve extreme clustering problems using quantum annealing. We prove\nthat this method yields optimal clustering assignments under a separability\nassumption, and show that the generated clustering assignments are of\ncomparable quality to those of assignments generated by common clustering\nalgorithms, yet can be obtained a full order of magnitude faster.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 21:01:59 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 20:00:07 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 23:27:18 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Jaschek", "Tim", ""], ["Bucyk", "Marko", ""], ["Oberoi", "Jaspreet S.", ""]]}, {"id": "1903.08268", "submitter": "Arshit Gupta", "authors": "Arshit Gupta, John Hewitt and Katrin Kirchhoff", "title": "Simple, Fast, Accurate Intent Classification and Slot Labeling for\n  Goal-Oriented Dialogue Systems", "comments": "SIGDIAL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of conversational assistants, like Amazon Alexa, Google Now,\netc., dialogue systems are gaining a lot of traction, especially in industrial\nsetting. These systems typically consist of Spoken Language understanding\ncomponent which, in turn, consists of two tasks - Intent Classification (IC)\nand Slot Labeling (SL). Generally, these two tasks are modeled together jointly\nto achieve best performance. However, this joint modeling adds to model\nobfuscation. In this work, we first design framework for a modularization of\njoint IC-SL task to enhance architecture transparency. Then, we explore a\nnumber of self-attention, convolutional, and recurrent models, contributing a\nlarge-scale analysis of modeling paradigms for IC+SL across two datasets.\nFinally, using this framework, we propose a class of 'label-recurrent' models\nthat otherwise non-recurrent, with a 10-dimensional representation of the label\nhistory, and show that our proposed systems are easy to interpret, highly\naccurate (achieving over 30% error reduction in SL over the state-of-the-art on\nthe Snips dataset), as well as fast, at 2x the inference and 2/3 to 1/2 the\ntraining time of comparable recurrent models, thus giving an edge in critical\nreal-world systems.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 21:58:24 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 18:26:36 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Gupta", "Arshit", ""], ["Hewitt", "John", ""], ["Kirchhoff", "Katrin", ""]]}, {"id": "1903.08289", "submitter": "Athirai A. Irissappane", "authors": "Gray Stanton, Athirai A. Irissappane", "title": "GANs for Semi-Supervised Opinion Spam Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reviews have become a vital source of information in purchasing a\nservice (product). Opinion spammers manipulate reviews, affecting the overall\nperception of the service. A key challenge in detecting opinion spam is\nobtaining ground truth. Though there exists a large set of reviews online, only\na few of them have been labeled spam or non-spam. In this paper, we propose\nspamGAN, a generative adversarial network which relies on limited set of\nlabeled data as well as unlabeled data for opinion spam detection. spamGAN\nimproves the state-of-the-art GAN based techniques for text classification.\nExperiments on TripAdvisor dataset show that spamGAN outperforms existing spam\ndetection techniques when limited labeled data is used. Apart from detecting\nspam reviews, spamGAN can also generate reviews with reasonable perplexity.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 23:33:41 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 19:03:03 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Stanton", "Gray", ""], ["Irissappane", "Athirai A.", ""]]}, {"id": "1903.08297", "submitter": "Nan Wu", "authors": "Nan Wu, Jason Phang, Jungkyu Park, Yiqiu Shen, Zhe Huang, Masha Zorin,\n  Stanis{\\l}aw Jastrz\\k{e}bski, Thibault F\\'evry, Joe Katsnelson, Eric Kim,\n  Stacey Wolfson, Ujas Parikh, Sushma Gaddam, Leng Leng Young Lin, Kara Ho,\n  Joshua D. Weinstein, Beatriu Reig, Yiming Gao, Hildegard Toth, Kristine\n  Pysarenko, Alana Lewin, Jiyon Lee, Krystal Airola, Eralda Mema, Stephanie\n  Chung, Esther Hwang, Naziya Samreen, S. Gene Kim, Laura Heacock, Linda Moy,\n  Kyunghyun Cho and Krzysztof J. Geras", "title": "Deep Neural Networks Improve Radiologists' Performance in Breast Cancer\n  Screening", "comments": "MIDL 2019 [arXiv:1907.08612]", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/SkxYez76FE", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep convolutional neural network for breast cancer screening\nexam classification, trained and evaluated on over 200,000 exams (over\n1,000,000 images). Our network achieves an AUC of 0.895 in predicting whether\nthere is a cancer in the breast, when tested on the screening population. We\nattribute the high accuracy of our model to a two-stage training procedure,\nwhich allows us to use a very high-capacity patch-level network to learn from\npixel-level labels alongside a network learning from macroscopic breast-level\nlabels. To validate our model, we conducted a reader study with 14 readers,\neach reading 720 screening mammogram exams, and find our model to be as\naccurate as experienced radiologists when presented with the same data.\nFinally, we show that a hybrid model, averaging probability of malignancy\npredicted by a radiologist with a prediction of our neural network, is more\naccurate than either of the two separately. To better understand our results,\nwe conduct a thorough analysis of our network's performance on different\nsubpopulations of the screening population, model design, training procedure,\nerrors, and properties of its internal representations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 00:51:01 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Wu", "Nan", ""], ["Phang", "Jason", ""], ["Park", "Jungkyu", ""], ["Shen", "Yiqiu", ""], ["Huang", "Zhe", ""], ["Zorin", "Masha", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["F\u00e9vry", "Thibault", ""], ["Katsnelson", "Joe", ""], ["Kim", "Eric", ""], ["Wolfson", "Stacey", ""], ["Parikh", "Ujas", ""], ["Gaddam", "Sushma", ""], ["Lin", "Leng Leng Young", ""], ["Ho", "Kara", ""], ["Weinstein", "Joshua D.", ""], ["Reig", "Beatriu", ""], ["Gao", "Yiming", ""], ["Toth", "Hildegard", ""], ["Pysarenko", "Kristine", ""], ["Lewin", "Alana", ""], ["Lee", "Jiyon", ""], ["Airola", "Krystal", ""], ["Mema", "Eralda", ""], ["Chung", "Stephanie", ""], ["Hwang", "Esther", ""], ["Samreen", "Naziya", ""], ["Kim", "S. Gene", ""], ["Heacock", "Laura", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "1903.08309", "submitter": "Chris Paxton", "authors": "Chris Paxton, Yonatan Bisk, Jesse Thomason, Arunkumar Byravan, Dieter\n  Fox", "title": "Prospection: Interpretable Plans From Language By Predicting the Future", "comments": "Accepted to ICRA 2019; extended version with appendix containing\n  additional results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level human instructions often correspond to behaviors with multiple\nimplicit steps. In order for robots to be useful in the real world, they must\nbe able to to reason over both motions and intermediate goals implied by human\ninstructions. In this work, we propose a framework for learning representations\nthat convert from a natural-language command to a sequence of intermediate\ngoals for execution on a robot. A key feature of this framework is prospection,\ntraining an agent not just to correctly execute the prescribed command, but to\npredict a horizon of consequences of an action before taking it. We demonstrate\nthe fidelity of plans generated by our framework when interpreting real,\ncrowd-sourced natural language commands for a robot in simulated scenes.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 01:52:37 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Paxton", "Chris", ""], ["Bisk", "Yonatan", ""], ["Thomason", "Jesse", ""], ["Byravan", "Arunkumar", ""], ["Fox", "Dieter", ""]]}, {"id": "1903.08329", "submitter": "Shahin Shahrampour", "authors": "Shahin Shahrampour, Soheil Kolouri", "title": "On Sampling Random Features From Empirical Leverage Scores:\n  Implementation and Theoretical Guarantees", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random features provide a practical framework for large-scale kernel\napproximation and supervised learning. It has been shown that data-dependent\nsampling of random features using leverage scores can significantly reduce the\nnumber of features required to achieve optimal learning bounds. Leverage scores\nintroduce an optimized distribution for features based on an\ninfinite-dimensional integral operator (depending on input distribution), which\nis impractical to sample from. Focusing on empirical leverage scores in this\npaper, we establish an out-of-sample performance bound, revealing an\ninteresting trade-off between the approximated kernel and the eigenvalue decay\nof another kernel in the domain of random features defined based on data\ndistribution. Our experiments verify that the empirical algorithm consistently\noutperforms vanilla Monte Carlo sampling, and with a minor modification the\nmethod is even competitive to supervised data-dependent kernel learning,\nwithout using the output (label) information.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 03:41:01 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Shahrampour", "Shahin", ""], ["Kolouri", "Soheil", ""]]}, {"id": "1903.08351", "submitter": "Mehrdad Ghadiri", "authors": "Mehrdad Ghadiri, Mark Schmidt", "title": "Distributed Maximization of Submodular plus Diversity Functions for\n  Multi-label Feature Selection on Huge Datasets", "comments": "17 pages, accepted in AISTATS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many problems in machine learning and data mining which are\nequivalent to selecting a non-redundant, high \"quality\" set of objects.\nRecommender systems, feature selection, and data summarization are among many\napplications of this. In this paper, we consider this problem as an\noptimization problem that seeks to maximize the sum of a sum-sum diversity\nfunction and a non-negative monotone submodular function. The diversity\nfunction addresses the redundancy, and the submodular function controls the\npredictive quality. We consider the problem in big data settings (in other\nwords, distributed and streaming settings) where the data cannot be stored on a\nsingle machine or the process time is too high for a single machine. We show\nthat a greedy algorithm achieves a constant factor approximation of the optimal\nsolution in these settings. Moreover, we formulate the multi-label feature\nselection problem as such an optimization problem. This formulation combined\nwith our algorithm leads to the first distributed multi-label feature selection\nmethod. We compare the performance of this method with centralized multi-label\nfeature selection methods in the literature, and we show that its performance\nis comparable or in some cases is even better than current centralized\nmulti-label feature selection methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 06:08:03 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 05:29:43 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Ghadiri", "Mehrdad", ""], ["Schmidt", "Mark", ""]]}, {"id": "1903.08356", "submitter": "Omid Alemi", "authors": "Omid Alemi and Philippe Pasquier", "title": "Machine Learning for Data-Driven Movement Generation: a Review of the\n  State of the Art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of non-linear and interactive media such as video games has\nincreased the need for automatic movement animation generation. In this survey,\nwe review and analyze different aspects of building automatic movement\ngeneration systems using machine learning techniques and motion capture data.\nWe cover topics such as high-level movement characterization, training data,\nfeatures representation, machine learning models, and evaluation methods. We\nconclude by presenting a discussion of the reviewed literature and outlining\nthe research gaps and remaining challenges for future work.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 06:32:10 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Alemi", "Omid", ""], ["Pasquier", "Philippe", ""]]}, {"id": "1903.08362", "submitter": "Jie Zhang", "authors": "Jie Zhang, Junting Zhang, Shalini Ghosh, Dawei Li, Jingwen Zhu, Heming\n  Zhang, Yalin Wang", "title": "Regularize, Expand and Compress: Multi-task based Lifelong Learning via\n  NonExpansive AutoML", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning, the problem of continual learning where tasks arrive in\nsequence, has been lately attracting more attention in the computer vision\ncommunity. The aim of lifelong learning is to develop a system that can learn\nnew tasks while maintaining the performance on the previously learned tasks.\nHowever, there are two obstacles for lifelong learning of deep neural networks:\ncatastrophic forgetting and capacity limitation. To solve the above issues,\ninspired by the recent breakthroughs in automatically learning good neural\nnetwork architectures, we develop a Multi-task based lifelong learning via\nnonexpansive AutoML framework termed Regularize, Expand and Compress (REC). REC\nis composed of three stages: 1) continually learns the sequential tasks without\nthe learned tasks' data via a newly proposed multi-task weight consolidation\n(MWC) algorithm; 2) expands the network to help the lifelong learning with\npotentially improved model capability and performance by network-transformation\nbased AutoML; 3) compresses the expanded model after learning every new task to\nmaintain model efficiency and performance. The proposed MWC and REC algorithms\nachieve superior performance over other lifelong learning algorithms on four\ndifferent datasets.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 07:16:58 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Zhang", "Jie", ""], ["Zhang", "Junting", ""], ["Ghosh", "Shalini", ""], ["Li", "Dawei", ""], ["Zhu", "Jingwen", ""], ["Zhang", "Heming", ""], ["Wang", "Yalin", ""]]}, {"id": "1903.08375", "submitter": "Seongok Ryu", "authors": "Seongok Ryu, Yongchan Kwon, and Woo Youn Kim", "title": "Uncertainty quantification of molecular property prediction with\n  Bayesian neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have outperformed existing machine learning models in\nvarious molecular applications. In practical applications, it is still\ndifficult to make confident decisions because of the uncertainty in predictions\narisen from insufficient quality and quantity of training data. Here, we show\nthat Bayesian neural networks are useful to quantify the uncertainty of\nmolecular property prediction with three numerical experiments. In particular,\nit enables us to decompose the predictive variance into the model- and\ndata-driven uncertainties, which helps to elucidate the source of errors. In\nthe logP predictions, we show that data noise affected the data-driven\nuncertainties more significantly than the model-driven ones. Based on this\nanalysis, we were able to find unexpected errors in the Harvard Clean Energy\nProject dataset. Lastly, we show that the confidence of prediction is closely\nrelated to the predictive uncertainty by performing on bio-activity and\ntoxicity classification problems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 07:54:49 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Ryu", "Seongok", ""], ["Kwon", "Yongchan", ""], ["Kim", "Woo Youn", ""]]}, {"id": "1903.08404", "submitter": "Casper Hansen", "authors": "Casper Hansen, Christian Hansen, Stephen Alstrup, Jakob Grue Simonsen,\n  Christina Lioma", "title": "Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking", "comments": "6 pages", "journal-ref": "In Companion Proceedings of the 2019 World Wide Web Conference", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 09:40:19 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Hansen", "Casper", ""], ["Hansen", "Christian", ""], ["Alstrup", "Stephen", ""], ["Simonsen", "Jakob Grue", ""], ["Lioma", "Christina", ""]]}, {"id": "1903.08408", "submitter": "Casper Hansen", "authors": "Christian Hansen, Casper Hansen, Stephen Alstrup, Jakob Grue Simonsen,\n  Christina Lioma", "title": "Modelling Sequential Music Track Skips using a Multi-RNN Approach", "comments": "4 pages", "journal-ref": "12th ACM International Conference on Web Search and Data Mining\n  (WSDM) 2019, WSDM Cup", "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling sequential music skips provides streaming companies the ability to\nbetter understand the needs of the user base, resulting in a better user\nexperience by reducing the need to manually skip certain music tracks. This\npaper describes the solution of the University of Copenhagen DIKU-IR team in\nthe 'Spotify Sequential Skip Prediction Challenge', where the task was to\npredict the skip behaviour of the second half in a music listening session\nconditioned on the first half. We model this task using a Multi-RNN approach\nconsisting of two distinct stacked recurrent neural networks, where one network\nfocuses on encoding the first half of the session and the other network focuses\non utilizing the encoding to make sequential skip predictions. The encoder\nnetwork is initialized by a learned session-wide music encoding, and both of\nthem utilize a learned track embedding. Our final model consists of a majority\nvoted ensemble of individually trained models, and ranked 2nd out of 45\nparticipating teams in the competition with a mean average accuracy of 0.641\nand an accuracy on the first skip prediction of 0.807. Our code is released at\nhttps://github.com/Varyn/WSDM-challenge-2019-spotify.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 09:47:22 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Hansen", "Christian", ""], ["Hansen", "Casper", ""], ["Alstrup", "Stephen", ""], ["Simonsen", "Jakob Grue", ""], ["Lioma", "Christina", ""]]}, {"id": "1903.08428", "submitter": "Nils Jansen", "authors": "Steven Carr, Nils Jansen, Ralf Wimmer, Alexandru C. Serban, Bernd\n  Becker, Ufuk Topcu", "title": "Counterexample-Guided Strategy Improvement for POMDPs Using Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study strategy synthesis for partially observable Markov decision\nprocesses (POMDPs). The particular problem is to determine strategies that\nprovably adhere to (probabilistic) temporal logic constraints. This problem is\ncomputationally intractable and theoretically hard. We propose a novel method\nthat combines techniques from machine learning and formal verification. First,\nwe train a recurrent neural network (RNN) to encode POMDP strategies. The RNN\naccounts for memory-based decisions without the need to expand the full belief\nspace of a POMDP. Secondly, we restrict the RNN-based strategy to represent a\nfinite-memory strategy and implement it on a specific POMDP. For the resulting\nfinite Markov chain, efficient formal verification techniques provide provable\nguarantees against temporal logic specifications. If the specification is not\nsatisfied, counterexamples supply diagnostic information. We use this\ninformation to improve the strategy by iteratively training the RNN. Numerical\nexperiments show that the proposed method elevates the state of the art in\nPOMDP solving by up to three orders of magnitude in terms of solving times and\nmodel sizes.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 10:40:54 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 13:24:02 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Carr", "Steven", ""], ["Jansen", "Nils", ""], ["Wimmer", "Ralf", ""], ["Serban", "Alexandru C.", ""], ["Becker", "Bernd", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1903.08432", "submitter": "Sunae So", "authors": "Sunae So, Junsuk Rho", "title": "Designing nanophotonic structures using conditional-deep convolutional\n  generative adversarial networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven design approaches based on deep-learning have been introduced in\nnanophotonics to reduce time-consuming iterative simulations which have been a\nmajor challenge. Here, we report the first use of conditional deep\nconvolutional generative adversarial networks to design nanophotonic antennae\nthat are not constrained to a predefined shape. For given input reflection\nspectra, the network generates desirable designs in the form of images; this\nform allows suggestions of new structures that cannot be represented by\nstructural parameters. Simulation results obtained from the generated designs\nagreed well with the input reflection spectrum. This method opens new avenues\ntowards the development of nanophotonics by providing a fast and convenient\napproach to design complex nanophotonic structures that have desired optical\nproperties.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 10:55:29 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["So", "Sunae", ""], ["Rho", "Junsuk", ""]]}, {"id": "1903.08481", "submitter": "Jonathan Williams", "authors": "Jonathan Williams, Carola-Bibiane Sch\\\"onlieb, Tom Swinfield, Juheon\n  Lee, Xiaohao Cai, Lan Qie, David A. Coomes", "title": "Three-dimensional Segmentation of Trees Through a Flexible Multi-Class\n  Graph Cut Algorithm (MCGC)", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2019.2940146", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing a robust algorithm for automatic individual tree crown (ITC)\ndetection from laser scanning datasets is important for tracking the responses\nof trees to anthropogenic change. Such approaches allow the size, growth and\nmortality of individual trees to be measured, enabling forest carbon stocks and\ndynamics to be tracked and understood. Many algorithms exist for structurally\nsimple forests including coniferous forests and plantations. Finding a robust\nsolution for structurally complex, species-rich tropical forests remains a\nchallenge; existing segmentation algorithms often perform less well than simple\narea-based approaches when estimating plot-level biomass. Here we describe a\nMulti-Class Graph Cut (MCGC) approach to tree crown delineation. This uses\nlocal three-dimensional geometry and density information, alongside knowledge\nof crown allometries, to segment individual tree crowns from LiDAR point\nclouds. Our approach robustly identifies trees in the top and intermediate\nlayers of the canopy, but cannot recognise small trees. From these\nthree-dimensional crowns, we are able to measure individual tree biomass.\nComparing these estimates to those from permanent inventory plots, our\nalgorithm is able to produce robust estimates of hectare-scale carbon density,\ndemonstrating the power of ITC approaches in monitoring forests. The\nflexibility of our method to add additional dimensions of information, such as\nspectral reflectance, make this approach an obvious avenue for future\ndevelopment and extension to other sources of three-dimensional data, such as\nstructure from motion datasets.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 12:35:17 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Williams", "Jonathan", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""], ["Swinfield", "Tom", ""], ["Lee", "Juheon", ""], ["Cai", "Xiaohao", ""], ["Qie", "Lan", ""], ["Coomes", "David A.", ""]]}, {"id": "1903.08504", "submitter": "Cl\\'audio Rebelo De S\\'a", "authors": "Cl\\'audio Rebelo de S\\'a and Paulo Azevedo and Carlos Soares and\n  Al\\'ipio M\\'ario Jorge and Arno Knobbe", "title": "Preference rules for label ranking: Mining patterns in multi-target\n  relations", "comments": null, "journal-ref": "Information Fusion, Volume 40, March 2018, Pages 112-125", "doi": "10.1016/j.inffus.2017.07.001", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate two variants of association rules for preference\ndata, Label Ranking Association Rules and Pairwise Association Rules. Label\nRanking Association Rules (LRAR) are the equivalent of Class Association Rules\n(CAR) for the Label Ranking task. In CAR, the consequent is a single class, to\nwhich the example is expected to belong to. In LRAR, the consequent is a\nranking of the labels. The generation of LRAR requires special support and\nconfidence measures to assess the similarity of rankings. In this work, we\ncarry out a sensitivity analysis of these similarity-based measures. We want to\nunderstand which datasets benefit more from such measures and which parameters\nhave more influence in the accuracy of the model. Furthermore, we propose an\nalternative type of rules, the Pairwise Association Rules (PAR), which are\ndefined as association rules with a set of pairwise preferences in the\nconsequent. While PAR can be used both as descriptive and predictive models,\nthey are essentially descriptive models. Experimental results show the\npotential of both approaches.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 13:33:31 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["de S\u00e1", "Cl\u00e1udio Rebelo", ""], ["Azevedo", "Paulo", ""], ["Soares", "Carlos", ""], ["Jorge", "Al\u00edpio M\u00e1rio", ""], ["Knobbe", "Arno", ""]]}, {"id": "1903.08514", "submitter": "Juan Luis Gonzalez Bello", "authors": "Juan Luis Gonzalez Bello and Munchurl Kim", "title": "A Novel Monocular Disparity Estimation Network with Domain\n  Transformation and Ambiguity Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) have shown state-of-the-art results for\nlow-level computer vision problems such as stereo and monocular disparity\nestimations, but still, have much room to further improve their performance in\nterms of accuracy, numbers of parameters, etc. Recent works have uncovered the\nadvantages of using an unsupervised scheme to train CNN's to estimate monocular\ndisparity, where only the relatively-easy-to-obtain stereo images are needed\nfor training. We propose a novel encoder-decoder architecture that outperforms\nprevious unsupervised monocular depth estimation networks by (i) taking into\naccount ambiguities, (ii) efficient fusion between encoder and decoder features\nwith rectangular convolutions and (iii) domain transformations between encoder\nand decoder. Our architecture outperforms the Monodepth baseline in all\nmetrics, even with a considerable reduction of parameters. Furthermore, our\narchitecture is capable of estimating a full disparity map in a single forward\npass, whereas the baseline needs two passes. We perform extensive experiments\nto verify the effectiveness of our method on the KITTI dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 14:20:35 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Bello", "Juan Luis Gonzalez", ""], ["Kim", "Munchurl", ""]]}, {"id": "1903.08519", "submitter": "Eduardo Paluzo-Hidalgo", "authors": "Rocio Gonzalez-Diaz, Miguel A. Guti\\'errez-Naranjo, Eduardo\n  Paluzo-Hidalgo", "title": "Representative Datasets: The Perceptron Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main drawbacks of the practical use of neural networks is the long\ntime needed in the training process. Such training process consists in an\niterative change of parameters trying to minimize a loss function. These\nchanges are driven by a dataset, which can be seen as a set of labeled points\nin an n-dimensional space. In this paper, we explore the concept of it\nrepresentative dataset which is smaller than the original dataset and satisfies\na nearness condition independent of isometric transformations. The\nrepresentativeness is measured using persistence diagrams due to its\ncomputational efficiency. We also prove that the accuracy of the learning\nprocess of a neural network on a representative dataset is comparable with the\naccuracy on the original dataset when the neural network architecture is a\nperceptron and the loss function is the mean squared error. These theoretical\nresults accompanied with experimentation open a door to the size reduction of\nthe dataset in order to gain time in the training process of any neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 14:33:20 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 17:07:55 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Gonzalez-Diaz", "Rocio", ""], ["Guti\u00e9rrez-Naranjo", "Miguel A.", ""], ["Paluzo-Hidalgo", "Eduardo", ""]]}, {"id": "1903.08543", "submitter": "Chris Beeler", "authors": "Chris Beeler, Uladzimir Yahorau, Rory Coles, Kyle Mills, Stephen\n  Whitelam, and Isaac Tamblyn", "title": "Optimizing thermodynamic trajectories using evolutionary and\n  gradient-based reinforcement learning", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.stat-mech cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using a model heat engine we show that neural network-based reinforcement\nlearning can identify thermodynamic trajectories of maximal efficiency. We use\nan evolutionary learning algorithm to evolve a population of neural networks,\nsubject to a directive to maximize the efficiency of a trajectory composed of a\nset of elementary thermodynamic processes; the resulting networks learn to\ncarry out the maximally-efficient Carnot, Stirling, or Otto cycles. Given\nadditional irreversible processes this evolutionary scheme learns a previously\nunknown thermodynamic cycle. We also show how an evolutionary approach compares\nwith gradient-based reinforcement learning. Gradient-based reinforcement\nlearning is able to learn the Stirling cycle, whereas an evolutionary approach\nachieves the optimal Carnot cycle. Our results show how the reinforcement\nlearning strategies developed for game playing can be applied to solve physical\nproblems conditioned upon path-extensive order parameters.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 15:09:16 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 18:32:41 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 13:48:24 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Beeler", "Chris", ""], ["Yahorau", "Uladzimir", ""], ["Coles", "Rory", ""], ["Mills", "Kyle", ""], ["Whitelam", "Stephen", ""], ["Tamblyn", "Isaac", ""]]}, {"id": "1903.08548", "submitter": "Maurice Quach", "authors": "Maurice Quach, Giuseppe Valenzise and Frederic Dufaux", "title": "Learning Convolutional Transforms for Lossy Point Cloud Geometry\n  Compression", "comments": "Published in ICIP 2019. The source code can be found at\n  https://github.com/mauriceqch/pcc_geo_cnn and the supplementary material can\n  be found at https://www.mauricequach.com/pcc_geo_cnn_samples", "journal-ref": null, "doi": "10.1109/ICIP.2019.8803413", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient point cloud compression is fundamental to enable the deployment of\nvirtual and mixed reality applications, since the number of points to code can\nrange in the order of millions. In this paper, we present a novel data-driven\ngeometry compression method for static point clouds based on learned\nconvolutional transforms and uniform quantization. We perform joint\noptimization of both rate and distortion using a trade-off parameter. In\naddition, we cast the decoding process as a binary classification of the point\ncloud occupancy map. Our method outperforms the MPEG reference solution in\nterms of rate-distortion on the Microsoft Voxelized Upper Bodies dataset with\n51.5% BDBR savings on average. Moreover, while octree-based methods face\nexponential diminution of the number of points at low bitrates, our method\nstill produces high resolution outputs even at low bitrates. Code and\nsupplementary material are available at\nhttps://github.com/mauriceqch/pcc_geo_cnn .\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 15:14:15 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 15:56:14 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Quach", "Maurice", ""], ["Valenzise", "Giuseppe", ""], ["Dufaux", "Frederic", ""]]}, {"id": "1903.08550", "submitter": "Pramuditha Perera", "authors": "Pramuditha Perera, Ramesh Nallapati, Bing Xiang", "title": "OCGAN: One-class Novelty Detection Using GANs with Constrained Latent\n  Representations", "comments": "CVPR 2019 Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel model called OCGAN for the classical problem of one-class\nnovelty detection, where, given a set of examples from a particular class, the\ngoal is to determine if a query example is from the same class. Our solution is\nbased on learning latent representations of in-class examples using a denoising\nauto-encoder network. The key contribution of our work is our proposal to\nexplicitly constrain the latent space to exclusively represent the given class.\nIn order to accomplish this goal, firstly, we force the latent space to have\nbounded support by introducing a tanh activation in the encoder's output layer.\nSecondly, using a discriminator in the latent space that is trained\nadversarially, we ensure that encoded representations of in-class examples\nresemble uniform random samples drawn from the same bounded space. Thirdly,\nusing a second adversarial discriminator in the input space, we ensure all\nrandomly drawn latent samples generate examples that look real. Finally, we\nintroduce a gradient-descent based sampling technique that explores points in\nthe latent space that generate potential out-of-class examples, which are fed\nback to the network to further train it to generate in-class examples from\nthose points. The effectiveness of the proposed method is measured across four\npublicly available datasets using two one-class novelty detection protocols\nwhere we achieve state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 15:15:05 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Perera", "Pramuditha", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1903.08552", "submitter": "Dominic Kafka", "authors": "Dominic Kafka and Daniel Wilke", "title": "Traversing the noise of dynamic mini-batch sub-sampled loss functions: A\n  visual guide", "comments": "43 pages, 22 Figures, to be submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mini-batch sub-sampling in neural network training is unavoidable, due to\ngrowing data demands, memory-limited computational resources such as graphical\nprocessing units (GPUs), and the dynamics of on-line learning. In this study we\nspecifically distinguish between static mini-batch sub-sampled loss functions,\nwhere mini-batches are intermittently fixed during training, resulting in\nsmooth but biased loss functions; and the dynamic sub-sampling equivalent,\nwhere new mini-batches are sampled at every loss evaluation, trading bias for\nvariance in sampling induced discontinuities. These render automated\noptimization strategies such as minimization line searches ineffective, since\ncritical points may not exist and function minimizers find spurious,\ndiscontinuity induced minima.\n  This paper suggests recasting the optimization problem to find stochastic\nnon-negative associated gradient projection points (SNN-GPPs). We demonstrate\nthat the SNN-GPP optimality criterion is less susceptible to sub-sampling\ninduced discontinuities than critical points or minimizers. We conduct a visual\ninvestigation, comparing local minimum and SNN-GPP optimality criteria in the\nloss functions of a simple neural network training problem for a variety of\npopular activation functions. Since SNN-GPPs better approximate the location of\ntrue optima, particularly when using smooth activation functions with high\ncurvature characteristics, we postulate that line searches locating SNN-GPPs\ncan contribute significantly to automating neural network training\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 15:21:52 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 15:59:52 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kafka", "Dominic", ""], ["Wilke", "Daniel", ""]]}, {"id": "1903.08560", "submitter": "Andrea Montanari", "authors": "Trevor Hastie and Andrea Montanari and Saharon Rosset and Ryan J.\n  Tibshirani", "title": "Surprises in High-Dimensional Ridgeless Least Squares Interpolation", "comments": "68 pages; 16 figures. This revision contains non-asymptotic version\n  of earlier results, and results for general coefficients", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpolators -- estimators that achieve zero training error -- have\nattracted growing attention in machine learning, mainly because state-of-the\nart neural networks appear to be models of this type. In this paper, we study\nminimum $\\ell_2$ norm (``ridgeless'') interpolation in high-dimensional least\nsquares regression. We consider two different models for the feature\ndistribution: a linear model, where the feature vectors $x_i \\in {\\mathbb R}^p$\nare obtained by applying a linear transform to a vector of i.i.d.\\ entries,\n$x_i = \\Sigma^{1/2} z_i$ (with $z_i \\in {\\mathbb R}^p$); and a nonlinear model,\nwhere the feature vectors are obtained by passing the input through a random\none-layer neural network, $x_i = \\varphi(W z_i)$ (with $z_i \\in {\\mathbb R}^d$,\n$W \\in {\\mathbb R}^{p \\times d}$ a matrix of i.i.d.\\ entries, and $\\varphi$ an\nactivation function acting componentwise on $W z_i$). We recover -- in a\nprecise quantitative way -- several phenomena that have been observed in\nlarge-scale neural networks and kernel machines, including the \"double descent\"\nbehavior of the prediction risk, and the potential benefits of\noverparametrization.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 16:53:11 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 16:34:19 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 00:37:59 GMT"}, {"version": "v4", "created": "Mon, 4 Nov 2019 16:47:40 GMT"}, {"version": "v5", "created": "Mon, 7 Dec 2020 17:59:02 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Hastie", "Trevor", ""], ["Montanari", "Andrea", ""], ["Rosset", "Saharon", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "1903.08568", "submitter": "Andre Wibisono", "authors": "Santosh S. Vempala and Andre Wibisono", "title": "Rapid Convergence of the Unadjusted Langevin Algorithm: Isoperimetry\n  Suffices", "comments": "v2: Added analysis of R\\'enyi divergence and Poincar\\'e assumption \\\\\n  v3: Simplified analysis of R\\'enyi divergence, improved exposition, and added\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Unadjusted Langevin Algorithm (ULA) for sampling from a\nprobability distribution $\\nu = e^{-f}$ on $\\mathbb{R}^n$. We prove a\nconvergence guarantee in Kullback-Leibler (KL) divergence assuming $\\nu$\nsatisfies a log-Sobolev inequality and the Hessian of $f$ is bounded. Notably,\nwe do not assume convexity or bounds on higher derivatives. We also prove\nconvergence guarantees in R\\'enyi divergence of order $q > 1$ assuming the\nlimit of ULA satisfies either the log-Sobolev or Poincar\\'e inequality.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 15:49:10 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 16:52:02 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 16:27:16 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Vempala", "Santosh S.", ""], ["Wibisono", "Andre", ""]]}, {"id": "1903.08583", "submitter": "Dmitry Kuznichov", "authors": "Dmitry Kuznichov, Alon Zvirin, Yaron Honen and Ron Kimmel", "title": "Data Augmentation for Leaf Segmentation and Counting Tasks in Rosette\n  Plants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques involving image processing and data analysis are\nconstantly evolving. Many domains adapt these techniques for object\nsegmentation, instantiation and classification. Recently, agricultural\nindustries adopted those techniques in order to bring automation to farmers\naround the globe. One analysis procedure required for automatic visual\ninspection in this domain is leaf count and segmentation. Collecting labeled\ndata from field crops and greenhouses is a complicated task due to the large\nvariety of crops, growth seasons, climate changes, phenotype diversity, and\nmore, especially when specific learning tasks require a large amount of labeled\ndata for training. Data augmentation for training deep neural networks is well\nestablished, examples include data synthesis, using generative semi-synthetic\nmodels, and applying various kinds of transformations. In this paper we propose\na method that preserves the geometric structure of the data objects, thus\nkeeping the physical appearance of the data-set as close as possible to imaged\nplants in real agricultural scenes. The proposed method provides state of the\nart results when applied to the standard benchmark in the field, namely, the\nongoing Leaf Segmentation Challenge hosted by Computer Vision Problems in Plant\nPhenotyping.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 16:13:10 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Kuznichov", "Dmitry", ""], ["Zvirin", "Alon", ""], ["Honen", "Yaron", ""], ["Kimmel", "Ron", ""]]}, {"id": "1903.08597", "submitter": "Volodymyr Miz", "authors": "Nicolas Aspert, Volodymyr Miz, Benjamin Ricaud, Pierre Vandergheynst", "title": "A Graph-structured Dataset for Wikipedia Research", "comments": null, "journal-ref": null, "doi": "10.1145/3308560.3316757", "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wikipedia is a rich and invaluable source of information. Its central place\non the Web makes it a particularly interesting object of study for scientists.\nResearchers from different domains used various complex datasets related to\nWikipedia to study language, social behavior, knowledge organization, and\nnetwork theory. While being a scientific treasure, the large size of the\ndataset hinders pre-processing and may be a challenging obstacle for potential\nnew studies. This issue is particularly acute in scientific domains where\nresearchers may not be technically and data processing savvy. On one hand, the\nsize of Wikipedia dumps is large. It makes the parsing and extraction of\nrelevant information cumbersome. On the other hand, the API is straightforward\nto use but restricted to a relatively small number of requests. The middle\nground is at the mesoscopic scale when researchers need a subset of Wikipedia\nranging from thousands to hundreds of thousands of pages but there exists no\nefficient solution at this scale.\n  In this work, we propose an efficient data structure to make requests and\naccess subnetworks of Wikipedia pages and categories. We provide convenient\ntools for accessing and filtering viewership statistics or \"pagecounts\" of\nWikipedia web pages. The dataset organization leverages principles of graph\ndatabases that allows rapid and intuitive access to subgraphs of Wikipedia\narticles and categories. The dataset and deployment guidelines are available on\nthe LTS2 website \\url{https://lts2.epfl.ch/Datasets/Wikipedia/}.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 16:31:29 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Aspert", "Nicolas", ""], ["Miz", "Volodymyr", ""], ["Ricaud", "Benjamin", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1903.08600", "submitter": "Xiaotian Yu", "authors": "Xiaotian Yu", "title": "Contextual Bandits with Random Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits with linear payoffs, which are also known as linear\nbandits, provide a powerful alternative for solving practical problems of\nsequential decisions, e.g., online advertisements. In the era of big data,\ncontextual data usually tend to be high-dimensional, which leads to new\nchallenges for traditional linear bandits mostly designed for the setting of\nlow-dimensional contextual data. Due to the curse of dimensionality, there are\ntwo challenges in most of the current bandit algorithms: the first is high\ntime-complexity; and the second is extreme large upper regret bounds with\nhigh-dimensional data. In this paper, in order to attack the above two\nchallenges effectively, we develop an algorithm of Contextual Bandits via\nRAndom Projection (\\texttt{CBRAP}) in the setting of linear payoffs, which\nworks especially for high-dimensional contextual data. The proposed\n\\texttt{CBRAP} algorithm is time-efficient and flexible, because it enables\nplayers to choose an arm in a low-dimensional space, and relaxes the sparsity\nassumption of constant number of non-zero components in previous work. Besides,\nwe provide a linear upper regret bound for the proposed algorithm, which is\nassociated with reduced dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 16:34:11 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Yu", "Xiaotian", ""]]}, {"id": "1903.08621", "submitter": "Michael Mior", "authors": "Michael J. Mior and Alexander G. Ororbia II", "title": "Column2Vec: Structural Understanding via Distributed Representations of\n  Database Schemas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Column2Vec, a distributed representation of database columns based\non column metadata. Our distributed representation has several applications.\nUsing known names for groups of columns (i.e., a table name), we train a model\nto generate an appropriate name for columns in an unnamed table. We demonstrate\nthe viability of our approach using schema information collected from open\nsource applications on GitHub.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 17:07:11 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Mior", "Michael J.", ""], ["Ororbia", "Alexander G.", "II"]]}, {"id": "1903.08640", "submitter": "Frederik Heber", "authors": "Frederik Heber, Zofia Trstanova, Benedict Leimkuhler", "title": "TATi-Thermodynamic Analytics ToolkIt: TensorFlow-based software for\n  posterior sampling in machine learning applications", "comments": "25 pages: textual improvements with results unchanged, sections on\n  TATi architecture and software performance removed for size constraints,\n  extended EQN parts, added MNIST nonlinear perceptron example", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of GPU-assisted hardware and maturing high-efficiency\nsoftware platforms such as TensorFlow and PyTorch, Bayesian posterior sampling\nfor neural networks becomes plausible. In this article we discuss Bayesian\nparametrization in machine learning based on Markov Chain Monte Carlo methods,\nspecifically discretized stochastic differential equations such as Langevin\ndynamics and extended system methods in which an ensemble of walkers is\nemployed to enhance sampling. We provide a glimpse of the potential of the\nsampling-intensive approach by studying (and visualizing) the loss landscape of\na neural network applied to the MNIST data set. Moreover, we investigate how\nthe sampling efficiency itself can be significantly enhanced through an\nensemble quasi-Newton preconditioning method. This article accompanies the\nrelease of a new TensorFlow software package, the Thermodynamic Analytics\nToolkIt, which is used in the computational experiments.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 17:56:57 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 20:26:23 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Heber", "Frederik", ""], ["Trstanova", "Zofia", ""], ["Leimkuhler", "Benedict", ""]]}, {"id": "1903.08652", "submitter": "Luchen Liu", "authors": "Luchen Liu, Haoran Li, Zhiting Hu, Haoran Shi, Zichang Wang, Jian\n  Tang, Ming Zhang", "title": "Learning Hierarchical Representations of Electronic Health Records for\n  Clinical Outcome Prediction", "comments": "10 pages, 2 figures, accepted by AMIA annual symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical outcome prediction based on the Electronic Health Record (EHR) plays\na crucial role in improving the quality of healthcare. Conventional deep\nsequential models fail to capture the rich temporal patterns encoded in the\nlongand irregular clinical event sequences. We make the observation that\nclinical events at a long time scale exhibit strongtemporal patterns, while\nevents within a short time period tend to be disordered co-occurrence. We thus\npropose differentiated mechanisms to model clinical events at different time\nscales. Our model learns hierarchical representationsof event sequences, to\nadaptively distinguish between short-range and long-range events, and\naccurately capture coretemporal dependencies. Experimental results on real\nclinical data show that our model greatly improves over previous\nstate-of-the-art models, achieving AUC scores of 0.94 and 0.90 for predicting\ndeath and ICU admission respectively, Our model also successfully identifies\nimportant events for different clinical outcome prediction tasks\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 10:21:42 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 02:22:53 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Liu", "Luchen", ""], ["Li", "Haoran", ""], ["Hu", "Zhiting", ""], ["Shi", "Haoran", ""], ["Wang", "Zichang", ""], ["Tang", "Jian", ""], ["Zhang", "Ming", ""]]}, {"id": "1903.08671", "submitter": "Rahaf Aljundi", "authors": "Rahaf Aljundi, Min Lin, Baptiste Goujaud and Yoshua Bengio", "title": "Gradient based sample selection for online continual learning", "comments": "Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A continual learning agent learns online with a non-stationary and\nnever-ending stream of data. The key to such learning process is to overcome\nthe catastrophic forgetting of previously seen data, which is a well known\nproblem of neural networks. To prevent forgetting, a replay buffer is usually\nemployed to store the previous data for the purpose of rehearsal. Previous\nworks often depend on task boundary and i.i.d. assumptions to properly select\nsamples for the replay buffer. In this work, we formulate sample selection as a\nconstraint reduction problem based on the constrained optimization view of\ncontinual learning. The goal is to select a fixed subset of constraints that\nbest approximate the feasible region defined by the original constraints. We\nshow that it is equivalent to maximizing the diversity of samples in the replay\nbuffer with parameters gradient as the feature. We further develop a greedy\nalternative that is cheap and efficient. The advantage of the proposed method\nis demonstrated by comparing to other alternatives under the continual learning\nsetting. Further comparisons are made against state of the art methods that\nrely on task boundaries which show comparable or even better results for our\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:01:55 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 13:20:35 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 09:00:19 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 15:52:08 GMT"}, {"version": "v5", "created": "Thu, 31 Oct 2019 14:45:47 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Aljundi", "Rahaf", ""], ["Lin", "Min", ""], ["Goujaud", "Baptiste", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1903.08674", "submitter": "Yikuan Li", "authors": "Yikuan Li and Yajie Zhu", "title": "Performance Measurement for Deep Bayesian Neural Network", "comments": "university requires the paper going through a standard procedure\n  before publish, the paper will be published again after the procedure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Bayesian neural network has aroused a great attention in recent years\nsince it combines the benefits of deep neural network and probability theory.\nBecause of this, the network can make predictions and quantify the uncertainty\nof the predictions at the same time, which is important in many\nlife-threatening areas. However, most of the recent researches are mainly\nfocusing on making the Bayesian neural network easier to train, and proposing\nmethods to estimate the uncertainty. I notice there are very few works that\nproperly discuss the ways to measure the performance of the Bayesian neural\nnetwork. Although accuracy and average uncertainty are commonly used for now,\nthey are too general to provide any insight information about the model. In\nthis paper, we would like to introduce more specific criteria and propose\nseveral metrics to measure the model performance from different perspectives,\nwhich include model calibration measurement, data rejection ability and\nuncertainty divergence for samples from the same and different distributions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:04:16 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 13:16:45 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Li", "Yikuan", ""], ["Zhu", "Yajie", ""]]}, {"id": "1903.08689", "submitter": "Yilun Du", "authors": "Yilun Du and Igor Mordatch", "title": "Implicit Generation and Generalization in Energy-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy based models (EBMs) are appealing due to their generality and\nsimplicity in likelihood modeling, but have been traditionally difficult to\ntrain. We present techniques to scale MCMC based EBM training on continuous\nneural networks, and we show its success on the high-dimensional data domains\nof ImageNet32x32, ImageNet128x128, CIFAR-10, and robotic hand trajectories,\nachieving better samples than other likelihood models and nearing the\nperformance of contemporary GAN approaches, while covering all modes of the\ndata. We highlight some unique capabilities of implicit generation such as\ncompositionality and corrupt image reconstruction and inpainting. Finally, we\nshow that EBMs are useful models across a wide variety of tasks, achieving\nstate-of-the-art out-of-distribution classification, adversarially robust\nclassification, state-of-the-art continual online class learning, and coherent\nlong term predicted trajectory rollouts.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:34:29 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 02:54:05 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 19:54:22 GMT"}, {"version": "v4", "created": "Tue, 16 Jun 2020 20:53:53 GMT"}, {"version": "v5", "created": "Wed, 24 Jun 2020 01:52:12 GMT"}, {"version": "v6", "created": "Tue, 30 Jun 2020 03:25:59 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Du", "Yilun", ""], ["Mordatch", "Igor", ""]]}, {"id": "1903.08690", "submitter": "Xiang Wu", "authors": "Xiang Wu, Ruiqi Guo, David Simcha, Dave Dopson, Sanjiv Kumar", "title": "Efficient Inner Product Approximation in Hybrid Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many emerging use cases of data mining and machine learning operate on large\ndatasets with data from heterogeneous sources, specifically with both sparse\nand dense components. For example, dense deep neural network embedding vectors\nare often used in conjunction with sparse textual features to provide high\ndimensional hybrid representation of documents. Efficient search in such hybrid\nspaces is very challenging as the techniques that perform well for sparse\nvectors have little overlap with those that work well for dense vectors.\nPopular techniques like Locality Sensitive Hashing (LSH) and its data-dependent\nvariants also do not give good accuracy in high dimensional hybrid spaces. Even\nthough hybrid scenarios are becoming more prevalent, currently there exist no\nefficient techniques in literature that are both fast and accurate. In this\npaper, we propose a technique that approximates the inner product computation\nin hybrid vectors, leading to substantial speedup in search while maintaining\nhigh accuracy. We also propose efficient data structures that exploit modern\ncomputer architectures, resulting in orders of magnitude faster search than the\nexisting baselines. The performance of the proposed method is demonstrated on\nseveral datasets including a very large scale industrial dataset containing one\nbillion vectors in a billion dimensional space, achieving over 10x speedup and\nhigher accuracy against competitive baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:35:10 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Wu", "Xiang", ""], ["Guo", "Ruiqi", ""], ["Simcha", "David", ""], ["Dopson", "Dave", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1903.08693", "submitter": "Constantinos Chamzas", "authors": "Constantinos Chamzas, Anshumali Shrivastava, Lydia E. Kavraki", "title": "Using Local Experiences for Global Motion Planning", "comments": "6 pages, to appear in International Conference on Robotics and\n  Automation (ICRA), 2019", "journal-ref": "ICRA, 2019, 8606--8612", "doi": "10.1109/ICRA.2019.8794317", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling-based planners are effective in many real-world applications such as\nrobotics manipulation, navigation, and even protein modeling. However, it is\noften challenging to generate a collision-free path in environments where key\nareas are hard to sample. In the absence of any prior information,\nsampling-based planners are forced to explore uniformly or heuristically, which\ncan lead to degraded performance. One way to improve performance is to use\nprior knowledge of environments to adapt the sampling strategy to the problem\nat hand. In this work, we decompose the workspace into local primitives,\nmemorizing local experiences by these primitives in the form of local samplers,\nand store them in a database. We synthesize an efficient global sampler by\nretrieving local experiences relevant to the given situation. Our method\ntransfers knowledge effectively between diverse environments that share local\nprimitives and speeds up the performance dramatically. Our results show, in\nterms of solution time, an improvement of multiple orders of magnitude in two\ntraditionally challenging high-dimensional problems compared to\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:47:36 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Chamzas", "Constantinos", ""], ["Shrivastava", "Anshumali", ""], ["Kavraki", "Lydia E.", ""]]}, {"id": "1903.08701", "submitter": "Ankit Laddha", "authors": "Gregory P. Meyer, Ankit Laddha, Eric Kee, Carlos Vallespi-Gonzalez,\n  Carl K. Wellington", "title": "LaserNet: An Efficient Probabilistic 3D Object Detector for Autonomous\n  Driving", "comments": "Accepted for publication at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present LaserNet, a computationally efficient method for 3D\nobject detection from LiDAR data for autonomous driving. The efficiency results\nfrom processing LiDAR data in the native range view of the sensor, where the\ninput data is naturally compact. Operating in the range view involves well\nknown challenges for learning, including occlusion and scale variation, but it\nalso provides contextual information based on how the sensor data was captured.\nOur approach uses a fully convolutional network to predict a multimodal\ndistribution over 3D boxes for each point and then it efficiently fuses these\ndistributions to generate a prediction for each object. Experiments show that\nmodeling each detection as a distribution rather than a single deterministic\nbox leads to better overall detection performance. Benchmark results show that\nthis approach has significantly lower runtime than other recent detectors and\nthat it achieves state-of-the-art performance when compared on a large dataset\nthat has enough data to overcome the challenges of training on the range view.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 19:02:44 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Meyer", "Gregory P.", ""], ["Laddha", "Ankit", ""], ["Kee", "Eric", ""], ["Vallespi-Gonzalez", "Carlos", ""], ["Wellington", "Carl K.", ""]]}, {"id": "1903.08708", "submitter": "Haihao Lu", "authors": "Haihao Lu, Sai Praneeth Karimireddy, Natalia Ponomareva, Vahab\n  Mirrokni", "title": "Accelerating Gradient Boosting Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Boosting Machine (GBM) is an extremely powerful supervised learning\nalgorithm that is widely used in practice. GBM routinely features as a leading\nalgorithm in machine learning competitions such as Kaggle and the KDDCup. In\nthis work, we propose Accelerated Gradient Boosting Machine (AGBM) by\nincorporating Nesterov's acceleration techniques into the design of GBM. The\ndifficulty in accelerating GBM lies in the fact that weak (inexact) learners\nare commonly used, and therefore the errors can accumulate in the momentum\nterm. To overcome it, we design a \"corrected pseudo residual\" and fit best weak\nlearner to this corrected pseudo residual, in order to perform the z-update.\nThus, we are able to derive novel computational guarantees for AGBM. This is\nthe first GBM type of algorithm with theoretically-justified accelerated\nconvergence rate. Finally we demonstrate with a number of numerical experiments\nthe effectiveness of AGBM over conventional GBM in obtaining a model with good\ntraining and/or testing data fidelity.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 19:19:08 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 19:03:18 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 17:41:35 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Lu", "Haihao", ""], ["Karimireddy", "Sai Praneeth", ""], ["Ponomareva", "Natalia", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1903.08734", "submitter": "Nicolo Frisiani", "authors": "Nicol\\`o Frisiani, Alexis Laignelet, Batuhan G\\\"uler", "title": "Combination of multiple Deep Learning architectures for Offensive\n  Language Detection in Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report contains the details regarding our submission to the OffensEval\n2019 (SemEval 2019 - Task 6). The competition was based on the Offensive\nLanguage Identification Dataset. We first discuss the details of the classifier\nimplemented and the type of input data used and pre-processing performed. We\nthen move onto critically evaluating our performance. We have achieved a\nmacro-average F1-score of 0.76, 0.68, 0.54, respectively for Task a, Task b,\nand Task c, which we believe reflects on the level of sophistication of the\nmodels implemented. Finally, we will be discussing the difficulties encountered\nand possible improvements for the future.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 11:19:38 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 16:13:31 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Frisiani", "Nicol\u00f2", ""], ["Laignelet", "Alexis", ""], ["G\u00fcler", "Batuhan", ""]]}, {"id": "1903.08738", "submitter": "Hoang M. Le", "authors": "Hoang M. Le, Cameron Voloshin, Yisong Yue", "title": "Batch Policy Learning under Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning policies for real-world domains, two important questions arise:\n(i) how to efficiently use pre-collected off-policy, non-optimal behavior data;\nand (ii) how to mediate among different competing objectives and constraints.\nWe thus study the problem of batch policy learning under multiple constraints,\nand offer a systematic solution. We first propose a flexible meta-algorithm\nthat admits any batch reinforcement learning and online learning procedure as\nsubroutines. We then present a specific algorithmic instantiation and provide\nperformance guarantees for the main objective and all constraints. To certify\nconstraint satisfaction, we propose a new and simple method for off-policy\npolicy evaluation (OPE) and derive PAC-style bounds. Our algorithm achieves\nstrong empirical results in different domains, including in a challenging\nproblem of simulated car driving subject to multiple constraints such as lane\nkeeping and smooth driving. We also show experimentally that our OPE method\noutperforms other popular OPE techniques on a standalone basis, especially in a\nhigh-dimensional setting.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 21:01:22 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Le", "Hoang M.", ""], ["Voloshin", "Cameron", ""], ["Yue", "Yisong", ""]]}, {"id": "1903.08739", "submitter": "Gerhard Wohlgenannt Dr.", "authors": "Gerhard Wohlgenannt and Artemii Babushkin and Denis Romashov and Igor\n  Ukrainets and Anton Maskaykin and Ilya Shutov", "title": "Russian Language Datasets in the Digitial Humanities Domain and Their\n  Evaluation with Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present Russian language datasets in the digital humanities\ndomain for the evaluation of word embedding techniques or similar language\nmodeling and feature learning algorithms. The datasets are split into two task\ntypes, word intrusion and word analogy, and contain 31362 task units in total.\nThe characteristics of the tasks and datasets are that they build upon small,\ndomain-specific corpora, and that the datasets contain a high number of named\nentities. The datasets were created manually for two fantasy novel book series\n(\"A Song of Ice and Fire\" and \"Harry Potter\"). We provide baseline evaluations\nwith popular word embedding models trained on the book corpora for the given\ntasks, both for the Russian and English language versions of the datasets.\nFinally, we compare and analyze the results and discuss specifics of Russian\nlanguage with regards to the problem setting.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 14:18:48 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Wohlgenannt", "Gerhard", ""], ["Babushkin", "Artemii", ""], ["Romashov", "Denis", ""], ["Ukrainets", "Igor", ""], ["Maskaykin", "Anton", ""], ["Shutov", "Ilya", ""]]}, {"id": "1903.08742", "submitter": "Vien Van Mai", "authors": "Vien V. Mai and Mikael Johansson", "title": "Noisy Accelerated Power Method for Eigenproblems with Applications", "comments": "Accepted for publication in the IEEE Transaction on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2019.2908126", "report-no": null, "categories": "math.OC cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces an efficient algorithm for finding the dominant\ngeneralized eigenvectors of a pair of symmetric matrices. Combining tools from\napproximation theory and convex optimization, we develop a simple scalable\nalgorithm with strong theoretical performance guarantees. More precisely, the\nalgorithm retains the simplicity of the well-known power method but enjoys the\nasymptotic iteration complexity of the powerful Lanczos method. Unlike these\nclassic techniques, our algorithm is designed to decompose the overall problem\ninto a series of subproblems that only need to be solved approximately. The\ncombination of good initializations, fast iterative solvers, and appropriate\nerror control in solving the subproblems lead to a linear running time in the\ninput sizes compared to the superlinear time for the traditional methods. The\nimproved running time immediately offers acceleration for several applications.\nAs an example, we demonstrate how the proposed algorithm can be used to\naccelerate canonical correlation analysis, which is a fundamental statistical\ntool for learning of a low-dimensional representation of high-dimensional\nobjects. Numerical experiments on real-world data sets confirm that our\napproach yields significant improvements over the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 21:05:42 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Mai", "Vien V.", ""], ["Johansson", "Mikael", ""]]}, {"id": "1903.08752", "submitter": "Nirupam Gupta", "authors": "Nirupam Gupta and Nitin H. Vaidya", "title": "Byzantine Fault Tolerant Distributed Linear Regression", "comments": "Manuscript revised by adding; a new improved filtering technique, and\n  convergence analysis with noise", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of Byzantine fault tolerance in distributed\nlinear regression in a multi-agent system. However, the proposed algorithms are\ngiven for a more general class of distributed optimization problems, of which\ndistributed linear regression is a special case. The system comprises of a\nserver and multiple agents, where each agent is holding a certain number of\ndata points and responses that satisfy a linear relationship (could be noisy).\nThe objective of the server is to determine this relationship, given that some\nof the agents in the system (up to a known number) are Byzantine faulty (aka.\nactively adversarial). We show that the server can achieve this objective, in a\ndeterministic manner, by robustifying the original distributed gradient descent\nmethod using norm based filters, namely 'norm filtering' and 'norm-cap\nfiltering', incurring an additional log-linear computation cost in each\niteration. The proposed algorithms improve upon the existing methods on three\nlevels: i) no assumptions are required on the probability distribution of data\npoints, ii) system can be partially asynchronous, and iii) the computational\noverhead (in order to handle Byzantine faulty agents) is log-linear in number\nof agents and linear in dimension of data points. The proposed algorithms\ndiffer from each other in the assumptions made for their correctness, and the\ngradient filter they use.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 21:37:42 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 15:05:46 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Gupta", "Nirupam", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "1903.08756", "submitter": "Aitor Arronte Alvarez", "authors": "Aitor Arronte-Alvarez, Francisco G\\'omez-Martin", "title": "Distributed Vector Representations of Folksong Motifs", "comments": "MCM 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a distributed vector representation model for learning\nfolksong motifs. A skip-gram version of word2vec with negative sampling is used\nto represent high quality embeddings. Motifs from the Essen Folksong collection\nare compared based on their cosine similarity. A new evaluation method for\ntesting the quality of the embeddings based on a melodic similarity task is\npresented to show how the vector space can represent complex contextual\nfeatures, and how it can be utilized for the study of folksong variation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 21:52:13 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Arronte-Alvarez", "Aitor", ""], ["G\u00f3mez-Martin", "Francisco", ""]]}, {"id": "1903.08778", "submitter": "Matt Jordan", "authors": "Matt Jordan, Justin Lewis, Alexandros G. Dimakis", "title": "Provable Certificates for Adversarial Examples: Fitting a Ball in the\n  Union of Polytopes", "comments": "Code can be found here:\n  https://github.com/revbucket/geometric-certificates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for computing exact pointwise robustness of deep\nneural networks for all convex $\\ell_p$ norms. Our algorithm, GeoCert, finds\nthe largest $\\ell_p$ ball centered at an input point $x_0$, within which the\noutput class of a given neural network with ReLU nonlinearities remains\nunchanged. We relate the problem of computing pointwise robustness of these\nnetworks to that of computing the maximum norm ball with a fixed center that\ncan be contained in a non-convex polytope. This is a challenging problem in\ngeneral, however we show that there exists an efficient algorithm to compute\nthis for polyhedral complices. Further we show that piecewise linear neural\nnetworks partition the input space into a polyhedral complex. Our algorithm has\nthe ability to almost immediately output a nontrivial lower bound to the\npointwise robustness which is iteratively improved until it ultimately becomes\ntight. We empirically show that our approach generates distance lower bounds\nthat are tighter compared to prior work, under moderate time constraints.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 23:29:02 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 00:35:59 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Jordan", "Matt", ""], ["Lewis", "Justin", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1903.08789", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh, Dianne P. O'Leary", "title": "Interpreting Neural Networks Using Flip Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been criticized for their lack of easy interpretation,\nwhich undermines confidence in their use for important applications. Here, we\nintroduce a novel technique, interpreting a trained neural network by\ninvestigating its flip points. A flip point is any point that lies on the\nboundary between two output classes: e.g. for a neural network with a binary\nyes/no output, a flip point is any input that generates equal scores for \"yes\"\nand \"no\". The flip point closest to a given input is of particular importance,\nand this point is the solution to a well-posed optimization problem. This paper\ngives an overview of the uses of flip points and how they are computed. Through\nresults on standard datasets, we demonstrate how flip points can be used to\nprovide detailed interpretation of the output produced by a neural network.\nMoreover, for a given input, flip points enable us to measure confidence in the\ncorrectness of outputs much more effectively than softmax score. They also\nidentify influential features of the inputs, identify bias, and find changes in\nthe input that change the output of the model. We show that distance between an\ninput and the closest flip point identifies the most influential points in the\ntraining data. Using principal component analysis (PCA) and rank-revealing QR\nfactorization (RR-QR), the set of directions from each training input to its\nclosest flip point provides explanations of how a trained neural network\nprocesses an entire dataset: what features are most important for\nclassification into a given class, which features are most responsible for\nparticular misclassifications, how an adversary might fool the network, etc.\nAlthough we investigate flip points for neural networks, their usefulness is\nactually model-agnostic.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 01:03:42 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""], ["O'Leary", "Dianne P.", ""]]}, {"id": "1903.08792", "submitter": "Richard Cheng", "authors": "Richard Cheng, Gabor Orosz, Richard M. Murray, Joel W. Burdick", "title": "End-to-End Safe Reinforcement Learning through Barrier Functions for\n  Safety-Critical Continuous Control Tasks", "comments": "Published in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms have found limited success beyond\nsimulated applications, and one main reason is the absence of safety guarantees\nduring the learning process. Real world systems would realistically fail or\nbreak before an optimal controller can be learned. To address this issue, we\npropose a controller architecture that combines (1) a model-free RL-based\ncontroller with (2) model-based controllers utilizing control barrier functions\n(CBFs) and (3) on-line learning of the unknown system dynamics, in order to\nensure safety during learning. Our general framework leverages the success of\nRL algorithms to learn high-performance controllers, while the CBF-based\ncontrollers both guarantee safety and guide the learning process by\nconstraining the set of explorable polices. We utilize Gaussian Processes (GPs)\nto model the system dynamics and its uncertainties.\n  Our novel controller synthesis algorithm, RL-CBF, guarantees safety with high\nprobability during the learning process, regardless of the RL algorithm used,\nand demonstrates greater policy exploration efficiency. We test our algorithm\non (1) control of an inverted pendulum and (2) autonomous car-following with\nwireless vehicle-to-vehicle communication, and show that our algorithm attains\nmuch greater sample efficiency in learning than other state-of-the-art\nalgorithms and maintains safety during the entire learning process.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 01:29:14 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Cheng", "Richard", ""], ["Orosz", "Gabor", ""], ["Murray", "Richard M.", ""], ["Burdick", "Joel W.", ""]]}, {"id": "1903.08801", "submitter": "Tao Wang", "authors": "Tao Wang", "title": "A Unified Analytical Framework for Trustable Machine Learning and\n  Automation Running with Blockchain", "comments": "10 pages, IEEE Big Data Workshops, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional machine learning algorithms use data from databases that are\nmutable, and therefore the data cannot be fully trusted. Also, the machine\nlearning process is difficult to automate. This paper proposes building a\ntrustable machine learning system by using blockchain technology, which can\nstore data in a permanent and immutable way. In addition, smart contracts are\nused to automate the machine learning process. This paper makes three\ncontributions. First, it establishes a link between machine learning technology\nand blockchain technology. Previously, machine learning and blockchain have\nbeen considered two independent technologies without an obvious link. Second,\nit proposes a unified analytical framework for trustable machine learning by\nusing blockchain technology. This unified framework solves both the\ntrustability and automation issues in machine learning. Third, it enables a\ncomputer to translate core machine learning implementation from a single thread\non a single machine to multiple threads on multiple machines running with\nblockchain by using a unified approach. The paper uses association rule mining\nas an example to demonstrate how trustable machine learning can be implemented\nwith blockchain, and it shows how this approach can be used to analyze opioid\nprescriptions to help combat the opioid crisis.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 02:17:08 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Wang", "Tao", ""]]}, {"id": "1903.08828", "submitter": "Anqi Qiu DR", "authors": "Caoqiang Liu, Hui Ji, Anqi Qiu", "title": "Convolutional Neural Network on Semi-Regular Triangulated Meshes and its\n  Application to Brain Image Data", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a convolution neural network (CNN) on semi-regular triangulated\nmeshes whose vertices have 6 neighbours. The key blocks of the proposed CNN,\nincluding convolution and down-sampling, are directly defined in a vertex\ndomain. By exploiting the ordering property of semi-regular meshes, the\nconvolution is defined on a vertex domain with strong motivation from the\nspatial definition of classic convolution. Moreover, the down-sampling of a\nsemi-regular mesh embedded in a 3D Euclidean space can achieve a down-sampling\nrate of 4, 16, 64, etc. We demonstrated the use of this vertex-based graph CNN\nfor the classification of mild cognitive impairment (MCI) and Alzheimer's\ndisease (AD) based on 3169 MRI scans of the Alzheimer's Disease Neuroimaging\nInitiative (ADNI). We compared the performance of the vertex-based graph CNN\nwith that of the spectral graph CNN.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 04:49:36 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 06:37:44 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 01:47:59 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Liu", "Caoqiang", ""], ["Ji", "Hui", ""], ["Qiu", "Anqi", ""]]}, {"id": "1903.08829", "submitter": "Arash Ali Amini", "authors": "Arash A. Amini, Marina Paez, Lizhen Lin and Zahra S. Razaee", "title": "Exact slice sampler for Hierarchical Dirichlet Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an exact slice sampler for Hierarchical Dirichlet process (HDP)\nand its associated mixture models (Teh et al., 2006). Although there are\nexisting MCMC algorithms for sampling from the HDP, a slice sampler has been\nmissing from the literature. Slice sampling is well-known for its desirable\nproperties including its fast mixing and its natural potential for\nparallelization. On the other hand, the hierarchical nature of HDPs poses\nchallenges to adopting a full-fledged slice sampler that automatically\ntruncates all the infinite measures involved without ad-hoc modifications. In\nthis work, we adopt the powerful idea of Bayesian variable augmentation to\naddress this challenge. By introducing new latent variables, we obtain a full\nfactorization of the joint distribution that is suitable for slice sampling.\nOur algorithm has several appealing features such as (1) fast mixing; (2)\nremaining exact while allowing natural truncation of the underlying\ninfinite-dimensional measures, as in (Kalli et al., 2011), resulting in updates\nof only a finite number of necessary atoms and weights in each iteration; and\n(3) being naturally suited to parallel implementations. The underlying\nprinciple for joint factorization of the full likelihood is simple and can be\napplied to many other settings, such as designing sampling algorithms for\ngeneral dependent Dirichlet process (DDP) models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 04:51:22 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Amini", "Arash A.", ""], ["Paez", "Marina", ""], ["Lin", "Lizhen", ""], ["Razaee", "Zahra S.", ""]]}, {"id": "1903.08850", "submitter": "Aditya Grover", "authors": "Aditya Grover, Eric Wang, Aaron Zweig, Stefano Ermon", "title": "Stochastic Optimization of Sorting Networks via Continuous Relaxations", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sorting input objects is an important step in many machine learning\npipelines. However, the sorting operator is non-differentiable with respect to\nits inputs, which prohibits end-to-end gradient-based optimization. In this\nwork, we propose NeuralSort, a general-purpose continuous relaxation of the\noutput of the sorting operator from permutation matrices to the set of unimodal\nrow-stochastic matrices, where every row sums to one and has a distinct arg\nmax. This relaxation permits straight-through optimization of any computational\ngraph involve a sorting operation. Further, we use this relaxation to enable\ngradient-based stochastic optimization over the combinatorially large space of\npermutations by deriving a reparameterized gradient estimator for the\nPlackett-Luce family of distributions over permutations. We demonstrate the\nusefulness of our framework on three tasks that require learning semantic\norderings of high-dimensional objects, including a fully differentiable,\nparameterized extension of the k-nearest neighbors algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 07:05:44 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 07:56:18 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Grover", "Aditya", ""], ["Wang", "Eric", ""], ["Zweig", "Aaron", ""], ["Ermon", "Stefano", ""]]}, {"id": "1903.08857", "submitter": "Vipul Gupta", "authors": "Vipul Gupta, Swanand Kadhe, Thomas Courtade, Michael W. Mahoney,\n  Kannan Ramchandran", "title": "OverSketched Newton: Fast Convex Optimization for Serverless Systems", "comments": "37 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent developments in serverless systems for large-scale\ncomputation as well as improvements in scalable randomized matrix algorithms,\nwe develop OverSketched Newton, a randomized Hessian-based optimization\nalgorithm to solve large-scale convex optimization problems in serverless\nsystems. OverSketched Newton leverages matrix sketching ideas from Randomized\nNumerical Linear Algebra to compute the Hessian approximately. These sketching\nmethods lead to inbuilt resiliency against stragglers that are a characteristic\nof serverless architectures. Depending on whether the problem is strongly\nconvex or not, we propose different iteration updates using the approximate\nHessian. For both cases, we establish convergence guarantees for OverSketched\nNewton and empirically validate our results by solving large-scale supervised\nlearning problems on real-world datasets. Experiments demonstrate a reduction\nof ~50% in total running time on AWS Lambda, compared to state-of-the-art\ndistributed optimization schemes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 07:33:11 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 17:22:45 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 08:26:33 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Gupta", "Vipul", ""], ["Kadhe", "Swanand", ""], ["Courtade", "Thomas", ""], ["Mahoney", "Michael W.", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1903.08858", "submitter": "Fuad Noman", "authors": "Chun-Ren Phang, Chee-Ming Ting, Fuad Noman, Hernando Ombao", "title": "Classification of EEG-Based Brain Connectivity Networks in Schizophrenia\n  Using a Multi-Domain Connectome Convolutional Neural Network", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": "10.1109/JBHI.2019.2941222", "report-no": null, "categories": "cs.LG cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exploit altered patterns in brain functional connectivity as features for\nautomatic discriminative analysis of neuropsychiatric patients. Deep learning\nmethods have been introduced to functional network classification only very\nrecently for fMRI, and the proposed architectures essentially focused on a\nsingle type of connectivity measure. We propose a deep convolutional neural\nnetwork (CNN) framework for classification of electroencephalogram\n(EEG)-derived brain connectome in schizophrenia (SZ). To capture complementary\naspects of disrupted connectivity in SZ, we explore combination of various\nconnectivity features consisting of time and frequency-domain metrics of\neffective connectivity based on vector autoregressive model and partial\ndirected coherence, and complex network measures of network topology. We design\na novel multi-domain connectome CNN (MDC-CNN) based on a parallel ensemble of\n1D and 2D CNNs to integrate the features from various domains and dimensions\nusing different fusion strategies. Hierarchical latent representations learned\nby the multiple convolutional layers from EEG connectivity reveal apparent\ngroup differences between SZ and healthy controls (HC). Results on a large\nresting-state EEG dataset show that the proposed CNNs significantly outperform\ntraditional support vector machine classifiers. The MDC-CNN with combined\nconnectivity features further improves performance over single-domain CNNs\nusing individual features, achieving remarkable accuracy of $93.06\\%$ with a\ndecision-level fusion. The proposed MDC-CNN by integrating information from\ndiverse brain connectivity descriptors is able to accurately discriminate SZ\nfrom HC. The new framework is potentially useful for developing diagnostic\ntools for SZ and other disorders.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 07:35:54 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Phang", "Chun-Ren", ""], ["Ting", "Chee-Ming", ""], ["Noman", "Fuad", ""], ["Ombao", "Hernando", ""]]}, {"id": "1903.08863", "submitter": "Bertrand Girard", "authors": "Eduardo Sanchez (IRIT), Mathieu Serrurier (IRIT), Mathias Ortner", "title": "Learning Disentangled Representations of Satellite Image Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate how to learn a suitable representation of\nsatellite image time series in an unsupervised manner by leveraging large\namounts of unlabeled data. Additionally , we aim to disentangle the\nrepresentation of time series into two representations: a shared representation\nthat captures the common information between the images of a time series and an\nexclusive representation that contains the specific information of each image\nof the time series. To address these issues, we propose a model that combines a\nnovel component called cross-domain autoencoders with the variational\nautoencoder (VAE) and generative ad-versarial network (GAN) methods. In order\nto learn disentangled representations of time series, our model learns the\nmultimodal image-to-image translation task. We train our model using satellite\nimage time series from the Sentinel-2 mission. Several experiments are carried\nout to evaluate the obtained representations. We show that these disentangled\nrepresentations can be very useful to perform multiple tasks such as image\nclassification, image retrieval, image segmentation and change detection.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 07:55:11 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Sanchez", "Eduardo", "", "IRIT"], ["Serrurier", "Mathieu", "", "IRIT"], ["Ortner", "Mathias", ""]]}, {"id": "1903.08864", "submitter": "Tomas Iesmantas", "authors": "Tomas Iesmantas, Robertas Alzbutas", "title": "Convolutional neural network for detection and classification of\n  seizures in clinical data", "comments": "Med Biol Eng Comput (2020)", "journal-ref": null, "doi": "10.1007/s11517-020-02208-7", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epileptic seizure detection and classification in clinical\nelectroencephalogram data still is a challenge, and only low sensitivity with a\nhigh rate of false positives has been achieved with commercially available\nseizure detection tools, which usually are patient non-specific. Epilepsy\npatients suffer from severe detrimental effects like physical injury or\ndepression due to unpredictable seizures. However, even in hospitals due to the\nhigh rate of false positives, the seizure alert systems are of poor help for\npatients as tools of seizure detection are mostly trained on unrealistically\nclean data, containing little noise and obtained under controlled laboratory\nconditions, where patient groups are homogeneous, e.g. in terms of age or type\nof seizures. In this study authors present the approach for detection and\nclassification of a seizure using clinical data of electroencephalograms and a\nconvolutional neural network trained on features of brain synchronisation and\npower spectrum. Various deep learning methods were applied, and the network was\ntrained on a very heterogeneous clinical electroencephalogram dataset. In\ntotal, eight different types of seizures were considered, and the patients were\nof various ages, health conditions and they were observed under clinical\nconditions. Despite this, the classifier presented in this paper achieved\nsensitivity and specificity equal to 0.68 and 0.67, accordingly, which is a\nsignificant improvement as compared to the known results for clinical data.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 07:57:36 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 13:58:01 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Iesmantas", "Tomas", ""], ["Alzbutas", "Robertas", ""]]}, {"id": "1903.08871", "submitter": "Xiwei Tang", "authors": "Xiwei Tang, Xuan Bi and Annie Qu", "title": "Individualized Multilayer Tensor Learning with An Application in Imaging\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is motivated by multimodality breast cancer imaging data, which is\nquite challenging in that the signals of discrete tumor-associated\nmicrovesicles (TMVs) are randomly distributed with heterogeneous patterns. This\nimposes a significant challenge for conventional imaging regression and\ndimension reduction models assuming a homogeneous feature structure. We develop\nan innovative multilayer tensor learning method to incorporate heterogeneity to\na higher-order tensor decomposition and predict disease status effectively\nthrough utilizing subject-wise imaging features and multimodality information.\nSpecifically, we construct a multilayer decomposition which leverages an\nindividualized imaging layer in addition to a modality-specific tensor\nstructure. One major advantage of our approach is that we are able to\nefficiently capture the heterogeneous spatial features of signals that are not\ncharacterized by a population structure as well as integrating multimodality\ninformation simultaneously. To achieve scalable computing, we develop a new\nbi-level block improvement algorithm. In theory, we investigate both the\nalgorithm convergence property, tensor signal recovery error bound and\nasymptotic consistency for prediction model estimation. We also apply the\nproposed method for simulated and human breast cancer imaging data. Numerical\nresults demonstrate that the proposed method outperforms other existing\ncompeting methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 08:18:08 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Tang", "Xiwei", ""], ["Bi", "Xuan", ""], ["Qu", "Annie", ""]]}, {"id": "1903.08889", "submitter": "Uriel Singer", "authors": "Uriel Singer and Ido Guy and Kira Radinsky", "title": "Node Embedding over Temporal Graphs", "comments": null, "journal-ref": "IJCAI 2019 Pages 4605-4612", "doi": "10.24963/ijcai.2019/640", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we present a method for node embedding in temporal graphs. We\npropose an algorithm that learns the evolution of a temporal graph's nodes and\nedges over time and incorporates this dynamics in a temporal node embedding\nframework for different graph prediction tasks. We present a joint loss\nfunction that creates a temporal embedding of a node by learning to combine its\nhistorical temporal embeddings, such that it optimizes per given task (e.g.,\nlink prediction). The algorithm is initialized using static node embeddings,\nwhich are then aligned over the representations of a node at different time\npoints, and eventually adapted for the given task in a joint optimization. We\nevaluate the effectiveness of our approach over a variety of temporal graphs\nfor the two fundamental tasks of temporal link prediction and multi-label node\nclassification, comparing to competitive baselines and algorithmic\nalternatives. Our algorithm shows performance improvements across many of the\ndatasets and baselines and is found particularly effective for graphs that are\nless cohesive, with a lower clustering coefficient.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 09:15:09 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 20:30:58 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 17:58:06 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Singer", "Uriel", ""], ["Guy", "Ido", ""], ["Radinsky", "Kira", ""]]}, {"id": "1903.08894", "submitter": "Joshua Achiam", "authors": "Joshua Achiam, Ethan Knight, Pieter Abbeel", "title": "Towards Characterizing Divergence in Deep Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-Learning (DQL), a family of temporal difference algorithms for\ncontrol, employs three techniques collectively known as the `deadly triad' in\nreinforcement learning: bootstrapping, off-policy learning, and function\napproximation. Prior work has demonstrated that together these can lead to\ndivergence in Q-learning algorithms, but the conditions under which divergence\noccurs are not well-understood. In this note, we give a simple analysis based\non a linear approximation to the Q-value updates, which we believe provides\ninsight into divergence under the deadly triad. The central point in our\nanalysis is to consider when the leading order approximation to the deep-Q\nupdate is or is not a contraction in the sup norm. Based on this analysis, we\ndevelop an algorithm which permits stable deep Q-learning for continuous\ncontrol without any of the tricks conventionally used (such as target networks,\nadaptive gradient optimizers, or using multiple Q functions). We demonstrate\nthat our algorithm performs above or near state-of-the-art on standard MuJoCo\nbenchmarks from the OpenAI Gym.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 09:42:41 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Achiam", "Joshua", ""], ["Knight", "Ethan", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1903.08901", "submitter": "Anton Martinsson", "authors": "Z. Trstanova, A. Martinsson, C. Matthews, S. Jimenez, B. Leimkuhler,\n  T. Van Delft, M. Wilkinson", "title": "Transferability of Operational Status Classification Models Among\n  Different Wind Turbine Typesq", "comments": "9 pages", "journal-ref": null, "doi": "10.1088/1742-6596/1222/1/012041", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A detailed understanding of wind turbine performance status classification\ncan improve operations and maintenance in the wind energy industry. Due to\ndifferent engineering properties of wind turbines, the standard supervised\nlearning models used for classification do not generalize across data sets\nobtained from different wind sites. We propose two methods to deal with the\ntransferability of the trained models: first, data normalization in the form of\npower curve alignment, and second, a robust method based on convolutional\nneural networks and feature-space extension. We demonstrate the success of our\nmethods on real-world data sets with industrial applications.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 09:57:30 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Trstanova", "Z.", ""], ["Martinsson", "A.", ""], ["Matthews", "C.", ""], ["Jimenez", "S.", ""], ["Leimkuhler", "B.", ""], ["Van Delft", "T.", ""], ["Wilkinson", "M.", ""]]}, {"id": "1903.08912", "submitter": "Shyam A", "authors": "Shyam A, Vignesh Ravichandran, Preejith S.P, Jayaraj Joseph and\n  Mohanasankar Sivaprakasam", "title": "PPGnet: Deep Network for Device Independent Heart Rate Estimation from\n  Photoplethysmogram", "comments": "Under review in EMBC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photoplethysmogram (PPG) is increasingly used to provide monitoring of the\ncardiovascular system under ambulatory conditions. Wearable devices like\nsmartwatches use PPG to allow long term unobtrusive monitoring of heart rate in\nfree living conditions. PPG based heart rate measurement is unfortunately\nhighly susceptible to motion artifacts, particularly when measured from the\nwrist. Traditional machine learning and deep learning approaches rely on\ntri-axial accelerometer data along with PPG to perform heart rate estimation.\nThe conventional learning based approaches have not addressed the need for\ndevice-specific modeling due to differences in hardware design among PPG\ndevices. In this paper, we propose a novel end to end deep learning model to\nperform heart rate estimation using 8 second length input PPG signal. We\nevaluate the proposed model on the IEEE SPC 2015 dataset, achieving a mean\nabsolute error of 3.36+-4.1BPM for HR estimation on 12 subjects without\nrequiring patient specific training. We also studied the feasibility of\napplying transfer learning along with sparse retraining from a comprehensive in\nhouse PPG dataset for heart rate estimation across PPG devices with different\nhardware design.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 10:30:47 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["A", "Shyam", ""], ["Ravichandran", "Vignesh", ""], ["P", "Preejith S.", ""], ["Joseph", "Jayaraj", ""], ["Sivaprakasam", "Mohanasankar", ""]]}, {"id": "1903.08950", "submitter": "Pavol Harar", "authors": "Pavol Harar, Roswitha Bammer, Anna Breger, Monika D\\\"orfler and Zdenek\n  Smekal", "title": "Improving Machine Hearing on Limited Data Sets", "comments": "13 pages, 3 figures, 2 tables. Repository for reproducibility:\n  https://gitlab.com/hararticles/gs-ms-mt/. Keywords: audio, CNN, limited data,\n  Mel scattering, mel-spectrogram, augmented target loss function. Rewritten\n  and restructured after peer revision. Recomputed and added new experiments\n  and visualizations. Changed the presentation of the results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) architectures have originated and\nrevolutionized machine learning for images. In order to take advantage of CNNs\nin predictive modeling with audio data, standard FFT-based signal processing\nmethods are often applied to convert the raw audio waveforms into an image-like\nrepresentations (e.g. spectrograms). Even though conventional images and\nspectrograms differ in their feature properties, this kind of pre-processing\nreduces the amount of training data necessary for successful training. In this\ncontribution we investigate how input and target representations interplay with\nthe amount of available training data in a music information retrieval setting.\nWe compare the standard mel-spectrogram inputs with a newly proposed\nrepresentation, called Mel scattering. Furthermore, we investigate the impact\nof additional target data representations by using an augmented target loss\nfunction which incorporates unused available information. We observe that all\nproposed methods outperform the standard mel-transform representation when\nusing a limited data set and discuss their strengths and limitations. The\nsource code for reproducibility of our experiments as well as intermediate\nresults and model checkpoints are available in an online repository.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 12:29:44 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 10:26:37 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 13:20:13 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Harar", "Pavol", ""], ["Bammer", "Roswitha", ""], ["Breger", "Anna", ""], ["D\u00f6rfler", "Monika", ""], ["Smekal", "Zdenek", ""]]}, {"id": "1903.08960", "submitter": "Lukas Hoyer", "authors": "Lukas Hoyer, Patrick Kesper, Anna Khoreva and Volker Fischer", "title": "Short-Term Prediction and Multi-Camera Fusion on Semantic Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An environment representation (ER) is a substantial part of every autonomous\nsystem. It introduces a common interface between perception and other system\ncomponents, such as decision making, and allows downstream algorithms to deal\nwith abstracted data without knowledge of the used sensor. In this work, we\npropose and evaluate a novel architecture that generates an egocentric,\ngrid-based, predictive, and semantically-interpretable ER. In particular, we\nprovide a proof of concept for the spatio-temporal fusion of multiple camera\nsequences and short-term prediction in such an ER. Our design utilizes a strong\nsemantic segmentation network together with depth and egomotion estimates to\nfirst extract semantic information from multiple camera streams and then\ntransform these separately into egocentric temporally-aligned bird's-eye view\ngrids. A deep encoder-decoder network is trained to fuse a stack of these grids\ninto a unified semantic grid representation and to predict the dynamics of its\nsurrounding. We evaluate this representation on real-world sequences of the\nCityscapes dataset and show that our architecture can make accurate predictions\nin complex sensor fusion scenarios and significantly outperforms a model-driven\nbaseline in a category-based evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 12:49:31 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 18:31:06 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Hoyer", "Lukas", ""], ["Kesper", "Patrick", ""], ["Khoreva", "Anna", ""], ["Fischer", "Volker", ""]]}, {"id": "1903.08970", "submitter": "Alex Bird", "authors": "Alex Bird, Christopher K. I. Williams, Christopher Hawthorne", "title": "Multi-Task Time Series Analysis applied to Drug Response Modelling", "comments": "To appear in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series models such as dynamical systems are frequently fitted to a\ncohort of data, ignoring variation between individual entities such as\npatients. In this paper we show how these models can be personalised to an\nindividual level while retaining statistical power, via use of multi-task\nlearning (MTL). To our knowledge this is a novel development of MTL which\napplies to time series both with and without control inputs. The modelling\nframework is demonstrated on a physiological drug response problem which\nresults in improved predictive accuracy and uncertainty estimation over\nexisting state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 13:03:55 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Bird", "Alex", ""], ["Williams", "Christopher K. I.", ""], ["Hawthorne", "Christopher", ""]]}, {"id": "1903.08977", "submitter": "Martin Keller-Ressel", "authors": "Martin Keller-Ressel, Stephanie Nargang", "title": "Hydra: A method for strain-minimizing hyperbolic embedding of network-\n  and distance-based data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce hydra (hyperbolic distance recovery and approximation), a new\nmethod for embedding network- or distance-based data into hyperbolic space. We\nshow mathematically that hydra satisfies a certain optimality guarantee: It\nminimizes the `hyperbolic strain' between original and embedded data points.\nMoreover, it recovers points exactly, when they are located on a hyperbolic\nsubmanifold of the feature space. Testing on real network data we show that the\nembedding quality of hydra is competitive with existing hyperbolic embedding\nmethods, but achieved at substantially shorter computation time. An extended\nmethod, termed hydra+, outperforms existing methods in both computation time\nand embedding quality.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 13:16:01 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 13:20:41 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Keller-Ressel", "Martin", ""], ["Nargang", "Stephanie", ""]]}, {"id": "1903.08998", "submitter": "Panagiotis Tsakanikas", "authors": "Panagiotis Tsakanikas, Lemonia Christina Fengou, Evanthia Manthou,\n  Alexandra Lianou, Efstathios Z. Panagou, George John E. Nychas", "title": "A unified spectra analysis workflow for the assessment of microbial\n  contamination of ready to eat green salads: Comparative study and application\n  of non-invasive sensors", "comments": null, "journal-ref": "Computers and Electronics in Agriculture, 2018", "doi": "10.1016/j.compag.2018.10.025", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study provides a comparative assessment of non-invasive sensors\nas means of estimating the microbial contamination and time-on-shelf (i.e.\nstorage time) of leafy green vegetables, using a novel unified spectra analysis\nworkflow. Two fresh ready-to-eat green salads were used in the context of this\nstudy for the purpose of evaluating the efficiency and practical application of\nthe presented workflow: rocket and baby spinach salads. The employed analysis\nworkflow consisted of robust data normalization, powerful feature selection\nbased on random forests regression, and selection of the number of partial\nleast squares regression coefficients in the training process by estimating the\nknee-point on the explained variance plot. Training processes were based on\nmicrobiological and spectral data derived during storage of green salad samples\nat isothermal conditions (4, 8 and 12C), whereas testing was performed on data\nduring storage under dynamic temperature conditions (simulating real-life\ntemperature fluctuations in the food supply chain). Since an increasing\ninterest in the use of non-invasive sensors in food quality assessment has been\nmade evident in recent years, the unified spectra analysis workflow described\nherein, by being based on the creation/usage of limited sized featured sets,\ncould be very useful in food-specific low-cost sensor development.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 13:45:08 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 10:40:29 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Tsakanikas", "Panagiotis", ""], ["Fengou", "Lemonia Christina", ""], ["Manthou", "Evanthia", ""], ["Lianou", "Alexandra", ""], ["Panagou", "Efstathios Z.", ""], ["Nychas", "George John E.", ""]]}, {"id": "1903.09003", "submitter": "Jean Daunizeau", "authors": "Jean Daunizeau", "title": "Variational Bayesian modelling of mixed-effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is concerned with an accurate and computationally efficient\nvariational bayesian treatment of mixed-effects modelling. We focus on group\nstudies, i.e. empirical studies that report multiple measurements acquired in\nmultiple subjects. When approached from a bayesian perspective, such\nmixed-effects models typically rely upon a hierarchical generative model of the\ndata, whereby both within- and between-subject effects contribute to the\noverall observed variance. The ensuing VB scheme can be used to assess\nstatistical significance at the group level and/or to capture inter-individual\ndifferences. Alternatively, it can be seen as an adaptive regularization\nprocedure, which iteratively learns the corresponding within-subject priors\nfrom estimates of the group distribution of effects of interest (cf. so-called\n\"empirical bayes\" approaches). We outline the mathematical derivation of the\nensuing VB scheme, whose open-source implementation is available as part the\nVBA toolbox.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 13:50:07 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Daunizeau", "Jean", ""]]}, {"id": "1903.09022", "submitter": "Jinhuan Wang", "authors": "Qi Xuan, Jinhuan Wang, Minghao Zhao, Junkun Yuan, Chenbo Fu, Zhongyuan\n  Ruan, and Guanrong Chen", "title": "Subgraph Networks with Application to Structural Feature Space Expansion", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": "10.1109/TKDE.2019.2957755", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world networks exhibit prominent hierarchical and modular structures,\nwith various subgraphs as building blocks. Most existing studies simply\nconsider distinct subgraphs as motifs and use only their numbers to\ncharacterize the underlying network. Although such statistics can be used to\ndescribe a network model, or even to design some network algorithms, the role\nof subgraphs in such applications can be further explored so as to improve the\nresults. In this paper, the concept of subgraph network (SGN) is introduced and\nthen applied to network models, with algorithms designed for constructing the\n1st-order and 2nd-order SGNs, which can be easily extended to build\nhigher-order ones. Furthermore, these SGNs are used to expand the structural\nfeature space of the underlying network, beneficial for network classification.\nNumerical experiments demonstrate that the network classification model based\non the structural features of the original network together with the 1st-order\nand 2nd-order SGNs always performs the best as compared to the models based\nonly on one or two of such networks. In other words, the structural features of\nSGNs can complement that of the original network for better network\nclassification, regardless of the feature extraction method used, such as the\nhandcrafted, network embedding and kernel-based methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:21:35 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 08:22:05 GMT"}, {"version": "v3", "created": "Sun, 15 Dec 2019 10:20:31 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Xuan", "Qi", ""], ["Wang", "Jinhuan", ""], ["Zhao", "Minghao", ""], ["Yuan", "Junkun", ""], ["Fu", "Chenbo", ""], ["Ruan", "Zhongyuan", ""], ["Chen", "Guanrong", ""]]}, {"id": "1903.09029", "submitter": "Leo Duan", "authors": "Leo L Duan", "title": "Latent Simplex Position Model: High Dimensional Multi-view Clustering\n  with Uncertainty Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensional data often contain multiple facets, and several clustering\npatterns can co-exist under different variable subspaces, also known as the\nviews. While multi-view clustering algorithms were proposed, the uncertainty\nquantification remains difficult --- a particular challenge is in the high\ncomplexity of estimating the cluster assignment probability under each view,\nand sharing information among views. In this article, we propose an approximate\nBayes approach --- treating the similarity matrices generated over the views as\nrough first-stage estimates for the co-assignment probabilities; in its\nKullback-Leibler neighborhood, we obtain a refined low-rank matrix, formed by\nthe pairwise product of simplex coordinates. Interestingly, each simplex\ncoordinate directly encodes the cluster assignment uncertainty. For multi-view\nclustering, we let each view draw a parameterization from a few candidates,\nleading to dimension reduction. With high model flexibility, the estimation can\nbe efficiently carried out as a continuous optimization problem, hence enjoys\ngradient-based computation. The theory establishes the connection of this model\nto a random partition distribution under multiple views. Compared to\nsingle-view clustering approaches, substantially more interpretable results are\nobtained when clustering brains from a human traumatic brain injury study,\nusing high-dimensional gene expression data.\n  KEY WORDS: Co-regularized Clustering, Consensus, PAC-Bayes, Random Cluster\nGraph, Variable Selection\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:37:17 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 21:21:33 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Duan", "Leo L", ""]]}, {"id": "1903.09030", "submitter": "Juan Maro\\~nas", "authors": "Juan Maro\\~nas, Roberto Paredes, Daniel Ramos", "title": "Generative Models For Deep Learning with Very Scarce Data", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-13469-3_3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The goal of this paper is to deal with a data scarcity scenario where deep\nlearning techniques use to fail. We compare the use of two well established\ntechniques, Restricted Boltzmann Machines and Variational Auto-encoders, as\ngenerative models in order to increase the training set in a classification\nframework. Essentially, we rely on Markov Chain Monte Carlo (MCMC) algorithms\nfor generating new samples. We show that generalization can be improved\ncomparing this methodology to other state-of-the-art techniques, e.g.\nsemi-supervised learning with ladder networks. Furthermore, we show that RBM is\nbetter than VAE generating new samples for training a classifier with good\ngeneralization capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:38:45 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Maro\u00f1as", "Juan", ""], ["Paredes", "Roberto", ""], ["Ramos", "Daniel", ""]]}, {"id": "1903.09033", "submitter": "Siamak Ravanbakhsh", "authors": "Devon Graham, Junhao Wang, Siamak Ravanbakhsh", "title": "Equivariant Entity-Relationship Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relational model is a ubiquitous representation of big-data, in part due\nto its extensive use in databases. In this paper, we propose the Equivariant\nEntity-Relationship Network (EERN), which is a Multilayer Perceptron\nequivariant to the symmetry transformations of the Entity-Relationship model.\nTo this end, we identify the most expressive family of linear maps that are\nexactly equivariant to entity relationship symmetries, and further show that\nthey subsume recently introduced equivariant maps for sets, exchangeable\ntensors, and graphs. The proposed feed-forward layer has linear complexity in\nthe data and can be used for both inductive and transductive reasoning about\nrelational databases, including database embedding, and the prediction of\nmissing records. This provides a principled theoretical foundation for the\napplication of deep learning to one of the most abundant forms of data.\nEmpirically, EERN outperforms different variants of coupled matrix tensor\nfactorization in both synthetic and real-data experiments.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 14:42:14 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 13:53:27 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 01:44:07 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 19:33:06 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Graham", "Devon", ""], ["Wang", "Junhao", ""], ["Ravanbakhsh", "Siamak", ""]]}, {"id": "1903.09056", "submitter": "Taiyao Wang", "authors": "Taiyao Wang and Ioannis Ch. Paschalidis", "title": "Prescriptive Cluster-Dependent Support Vector Machines with an\n  Application to Reducing Hospital Readmissions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We augment linear Support Vector Machine (SVM) classifiers by adding three\nimportant features: (i) we introduce a regularization constraint to induce a\nsparse classifier; (ii) we devise a method that partitions the positive class\ninto clusters and selects a sparse SVM classifier for each cluster; and (iii)\nwe develop a method to optimize the values of controllable variables in order\nto reduce the number of data points which are predicted to have an undesirable\noutcome, which, in our setting, coincides with being in the positive class. The\nlatter feature leads to personalized prescriptions/recommendations. We apply\nour methods to the problem of predicting and preventing hospital readmissions\nwithin 30-days from discharge for patients that underwent a general surgical\nprocedure. To that end, we leverage a large dataset containing over 2.28\nmillion patients who had surgeries in the period 2011--2014 in the U.S. The\ndataset has been collected as part of the American College of Surgeons National\nSurgical Quality Improvement Program (NSQIP).\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 15:24:38 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Wang", "Taiyao", ""], ["Paschalidis", "Ioannis Ch.", ""]]}, {"id": "1903.09084", "submitter": "Joseph Geumlek", "authors": "Joseph Geumlek, Kamalika Chaudhuri", "title": "Profile-Based Privacy for Locally Private Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy has emerged as a gold standard in privacy-preserving\ndata analysis. A popular variant is local differential privacy, where the data\nholder is the trusted curator. A major barrier, however, towards a wider\nadoption of this model is that it offers a poor privacy-utility tradeoff.\n  In this work, we address this problem by introducing a new variant of local\nprivacy called profile-based privacy. The central idea is that the problem\nsetting comes with a graph G of data generating distributions, whose edges\nencode sensitive pairs of distributions that should be made indistinguishable.\nThis provides higher utility because unlike local differential privacy, we no\nlonger need to make every pair of private values in the domain\nindistinguishable, and instead only protect the identity of the underlying\ndistribution. We establish privacy properties of the profile-based privacy\ndefinition, such as post-processing invariance and graceful composition.\nFinally, we provide mechanisms that are private in this framework, and show via\nsimulations that they achieve higher utility than the corresponding local\ndifferential privacy mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 03:06:14 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 15:50:22 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Geumlek", "Joseph", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1903.09094", "submitter": "Nimish Awalgaonkar", "authors": "Nimish Awalgaonkar, Ilias Bilionis, Xiaoqi Liu, Panagiota Karava,\n  Athanasios Tzempelikos", "title": "Learning Personalized Thermal Preferences via Bayesian Active Learning\n  with Unimodality Constraints", "comments": "39 pages, 11 figures. References are updated. Typos are corrected.\n  Changed \"room temperatures\" to \"indoor air temperatures\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thermal preferences vary from person to person and may change over time. The\nmain objective of this paper is to sequentially pose intelligent queries to\noccupants in order to optimally learn the indoor air temperature values which\nmaximize their satisfaction. Our central hypothesis is that an occupant's\npreference relation over indoor air temperature can be described using a scalar\nfunction of these temperatures, which we call the \"occupant's thermal utility\nfunction\". Information about an occupant's preference over these temperatures\nis available to us through their response to thermal preference queries :\n\"prefer warmer,\" \"prefer cooler\" and \"satisfied\" which we interpret as\nstatements about the derivative of their utility function, i.e. the utility\nfunction is \"increasing\", \"decreasing\" and \"constant\" respectively. We model\nthis hidden utility function using a Gaussian process prior with built-in\nunimodality constraint, i.e., the utility function has a unique maximum, and we\ntrain this model using Bayesian inference. This permits an expected improvement\nbased selection of next preference query to pose to the occupant, which takes\ninto account both exploration (sampling from areas of high uncertainty) and\nexploitation (sampling from areas which are likely to offer an improvement over\ncurrent best observation). We use this framework to sequentially design\nexperiments and illustrate its benefits by showing that it requires drastically\nfewer observations to learn the maximally preferred temperature values as\ncompared to other methods. This framework is an important step towards the\ndevelopment of intelligent HVAC systems which would be able to respond to\noccupants' personalized thermal comfort needs. In order to encourage the use of\nour PE framework and ensure reproducibility in results, we publish an\nimplementation of our work named GPPrefElicit as an open-source package in\nPython.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 16:23:35 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 15:13:21 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Awalgaonkar", "Nimish", ""], ["Bilionis", "Ilias", ""], ["Liu", "Xiaoqi", ""], ["Karava", "Panagiota", ""], ["Tzempelikos", "Athanasios", ""]]}, {"id": "1903.09097", "submitter": "Lukas Folle", "authors": "Lukas Folle, Sulaiman Vesal, Nishant Ravikumar, Andreas Maier", "title": "Dilated deeply supervised networks for hippocampus segmentation in MRI", "comments": "BVM 2019 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tissue loss in the hippocampi has been heavily correlated with the\nprogression of Alzheimer's Disease (AD). The shape and structure of the\nhippocampus are important factors in terms of early AD diagnosis and prognosis\nby clinicians. However, manual segmentation of such subcortical structures in\nMR studies is a challenging and subjective task. In this paper, we investigate\nvariants of the well known 3D U-Net, a type of convolution neural network (CNN)\nfor semantic segmentation tasks. We propose an alternative form of the 3D\nU-Net, which uses dilated convolutions and deep supervision to incorporate\nmulti-scale information into the model. The proposed method is evaluated on the\ntask of hippocampus head and body segmentation in an MRI dataset, provided as\npart of the MICCAI 2018 segmentation decathlon challenge. The experimental\nresults show that our approach outperforms other conventional methods in terms\nof different segmentation accuracy metrics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 15:14:27 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Folle", "Lukas", ""], ["Vesal", "Sulaiman", ""], ["Ravikumar", "Nishant", ""], ["Maier", "Andreas", ""]]}, {"id": "1903.09101", "submitter": "Oliver Gordon Mr", "authors": "O. Gordon, P. D'Hondt, L. Knijff, S. Freeney, F. Junqueira, P.\n  Moriarty, I. Swart", "title": "Scanning Probe State Recognition With Multi-Class Neural Network\n  Ensembles", "comments": "Initial submission to APL", "journal-ref": null, "doi": "10.1063/1.5099590", "report-no": null, "categories": "cs.LG cond-mat.mes-hall physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the largest obstacles facing scanning probe microscopy is the constant\nneed to correct flaws in the scanning probe in situ. This is currently a\nmanual, time-consuming process that would benefit greatly from automation. Here\nwe introduce a convolutional neural network protocol that enables automated\nrecognition of a variety of desirable and undesirable scanning probe tip states\non both metal and non-metal surfaces. By combining the best performing models\ninto majority voting ensembles, we find that the desirable states of H:Si(100)\ncan be distinguished with a mean precision of 0.89 and an average\nreceiver-operator-characteristic curve area of 0.95. More generally, high and\nlow-quality tips can be distinguished with a mean precision of 0.96 and near\nperfect area-under-curve of 0.98. With trivial modifications, we also\nsuccessfully automatically identify undesirable, non-surface-specific states on\nsurfaces of Au(111) and Cu(111). In these cases we find mean precisions of 0.95\nand 0.75 and area-under-curves of 0.98 and 0.94, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 16:30:10 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Gordon", "O.", ""], ["D'Hondt", "P.", ""], ["Knijff", "L.", ""], ["Freeney", "S.", ""], ["Junqueira", "F.", ""], ["Moriarty", "P.", ""], ["Swart", "I.", ""]]}, {"id": "1903.09109", "submitter": "Changjian Shui", "authors": "Changjian Shui, Mahdieh Abbasi, Louis-\\'Emile Robitaille, Boyu Wang,\n  Christian Gagn\\'e", "title": "A Principled Approach for Learning Task Similarity in Multitask Learning", "comments": null, "journal-ref": "IJCAI, 2019", "doi": "10.24963/ijcai.2019/478", "report-no": "3446--3452", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning aims at solving a set of related tasks simultaneously, by\nexploiting the shared knowledge for improving the performance on individual\ntasks. Hence, an important aspect of multitask learning is to understand the\nsimilarities within a set of tasks. Previous works have incorporated this\nsimilarity information explicitly (e.g., weighted loss for each task) or\nimplicitly (e.g., adversarial loss for feature adaptation), for achieving good\nempirical performances. However, the theoretical motivations for adding task\nsimilarity knowledge are often missing or incomplete. In this paper, we give a\ndifferent perspective from a theoretical point of view to understand this\npractice. We first provide an upper bound on the generalization error of\nmultitask learning, showing the benefit of explicit and implicit task\nsimilarity knowledge. We systematically derive the bounds based on two distinct\ntask similarity metrics: H divergence and Wasserstein distance. From these\ntheoretical results, we revisit the Adversarial Multi-task Neural Network,\nproposing a new training algorithm to learn the task relation coefficients and\nneural network parameters iteratively. We assess our new algorithm empirically\non several benchmarks, showing not only that we find interesting and robust\ntask relations, but that the proposed approach outperforms the baselines,\nreaffirming the benefits of theoretical insight in algorithm design.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 16:59:53 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 20:24:48 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Shui", "Changjian", ""], ["Abbasi", "Mahdieh", ""], ["Robitaille", "Louis-\u00c9mile", ""], ["Wang", "Boyu", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "1903.09122", "submitter": "Anastasios Tsiamis", "authors": "Anastasios Tsiamis and George J. Pappas", "title": "Finite Sample Analysis of Stochastic System Identification", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the finite sample complexity of stochastic system\nidentification using modern tools from machine learning and statistics. An\nunknown discrete-time linear system evolves over time under Gaussian noise\nwithout external inputs. The objective is to recover the system parameters as\nwell as the Kalman filter gain, given a single trajectory of output\nmeasurements over a finite horizon of length $N$. Based on a subspace\nidentification algorithm and a finite number of $N$ output samples, we provide\nnon-asymptotic high-probability upper bounds for the system parameter\nestimation errors. Our analysis uses recent results from random matrix theory,\nself-normalized martingales and SVD robustness, in order to show that with high\nprobability the estimation errors decrease with a rate of $1/\\sqrt{N}$. Our\nnon-asymptotic bounds not only agree with classical asymptotic results, but are\nalso valid even when the system is marginally stable.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 17:30:42 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Tsiamis", "Anastasios", ""], ["Pappas", "George J.", ""]]}, {"id": "1903.09132", "submitter": "Branislav Kveton", "authors": "Branislav Kveton, Csaba Szepesvari, Mohammad Ghavamzadeh, and Craig\n  Boutilier", "title": "Perturbed-History Exploration in Stochastic Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new online algorithm for minimizing the cumulative regret in\nstochastic linear bandits. The key idea is to build a perturbed history, which\nmixes the history of observed rewards with a pseudo-history of randomly\ngenerated i.i.d. pseudo-rewards. Our algorithm, perturbed-history exploration\nin a linear bandit (LinPHE), estimates a linear model from its perturbed\nhistory and pulls the arm with the highest value under that model. We prove a\n$\\tilde{O}(d \\sqrt{n})$ gap-free bound on the expected $n$-round regret of\nLinPHE, where $d$ is the number of features. Our analysis relies on novel\nconcentration and anti-concentration bounds on the weighted sum of Bernoulli\nrandom variables. To show the generality of our design, we extend LinPHE to a\nlogistic reward model. We evaluate both algorithms empirically and show that\nthey are practical.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 17:45:11 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Kveton", "Branislav", ""], ["Szepesvari", "Csaba", ""], ["Ghavamzadeh", "Mohammad", ""], ["Boutilier", "Craig", ""]]}, {"id": "1903.09136", "submitter": "Eike Petersen", "authors": "Eike Petersen, Christian Hoffmann, Philipp Rostalski", "title": "On Approximate Nonlinear Gaussian Message Passing On Factor Graphs", "comments": null, "journal-ref": "2018 IEEE Statistical Signal Processing Workshop (SSP)", "doi": "10.1109/SSP.2018.8450699", "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor graphs have recently gained increasing attention as a unified\nframework for representing and constructing algorithms for signal processing,\nestimation, and control. One capability that does not seem to be well explored\nwithin the factor graph tool kit is the ability to handle deterministic\nnonlinear transformations, such as those occurring in nonlinear filtering and\nsmoothing problems, using tabulated message passing rules. In this\ncontribution, we provide general forward (filtering) and backward (smoothing)\napproximate Gaussian message passing rules for deterministic nonlinear\ntransformation nodes in arbitrary factor graphs fulfilling a Markov property,\nbased on numerical quadrature procedures for the forward pass and a\nRauch-Tung-Striebel-type approximation of the backward pass. These message\npassing rules can be employed for deriving many algorithms for solving\nnonlinear problems using factor graphs, as is illustrated by the proposition of\na nonlinear modified Bryson-Frazier (MBF) smoother based on the presented\nmessage passing rules.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 17:48:06 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Petersen", "Eike", ""], ["Hoffmann", "Christian", ""], ["Rostalski", "Philipp", ""]]}, {"id": "1903.09139", "submitter": "Anant Sahai", "authors": "Vidya Muthukumar and Kailas Vodrahalli and Vignesh Subramanian and\n  Anant Sahai", "title": "Harmless interpolation of noisy data in regression", "comments": "52 pages, expanded version of the paper presented at ITA in San Diego\n  in Feb 2019, ISIT in Paris in July 2019, at Simons in July, and as a plenary\n  at ITW in Visby in August 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A continuing mystery in understanding the empirical success of deep neural\nnetworks is their ability to achieve zero training error and generalize well,\neven when the training data is noisy and there are more parameters than data\npoints. We investigate this overparameterized regime in linear regression,\nwhere all solutions that minimize training error interpolate the data,\nincluding noise. We characterize the fundamental generalization (mean-squared)\nerror of any interpolating solution in the presence of noise, and show that\nthis error decays to zero with the number of features. Thus,\noverparameterization can be explicitly beneficial in ensuring harmless\ninterpolation of noise. We discuss two root causes for poor generalization that\nare complementary in nature -- signal \"bleeding\" into a large number of alias\nfeatures, and overfitting of noise by parsimonious feature selectors. For the\nsparse linear model with noise, we provide a hybrid interpolating scheme that\nmitigates both these issues and achieves order-optimal MSE over all possible\ninterpolating solutions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 17:51:12 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 15:41:59 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Muthukumar", "Vidya", ""], ["Vodrahalli", "Kailas", ""], ["Subramanian", "Vignesh", ""], ["Sahai", "Anant", ""]]}, {"id": "1903.09171", "submitter": "Unai Garciarena", "authors": "Unai Garciarena, Alexander Mendiburu, and Roberto Santana", "title": "Towards automatic construction of multi-network models for heterogeneous\n  multi-task learning", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning, as it is understood nowadays, consists of using one\nsingle model to carry out several similar tasks. From classifying hand-written\ncharacters of different alphabets to figuring out how to play several Atari\ngames using reinforcement learning, multi-task models have been able to widen\ntheir performance range across different tasks, although these tasks are\nusually of a similar nature. In this work, we attempt to widen this range even\nfurther, by including heterogeneous tasks in a single learning procedure. To do\nso, we firstly formally define a multi-network model, identifying the necessary\ncomponents and characteristics to allow different adaptations of said model\ndepending on the tasks it is required to fulfill. Secondly, employing the\nformal definition as a starting point, we develop an illustrative model example\nconsisting of three different tasks (classification, regression and data\nsampling). The performance of this model implementation is then analyzed,\nshowing its capabilities. Motivated by the results of the analysis, we\nenumerate a set of open challenges and future research lines over which the\nfull potential of the proposed model definition can be exploited.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 18:07:02 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Garciarena", "Unai", ""], ["Mendiburu", "Alexander", ""], ["Santana", "Roberto", ""]]}, {"id": "1903.09215", "submitter": "Adam Oberman", "authors": "Adam M. Oberman, Chris Finlay, Alexander Iannantuono, Tiago Salvador", "title": "Calibrated Top-1 Uncertainty estimates for classification by score based\n  models", "comments": "12 pages, 5 figures, 6 tables (major revision, new benchmark allows\n  us to show model calibration is better)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the accuracy of modern deep learning models has significantly improved\nin recent years, the ability of these models to generate uncertainty estimates\nhas not progressed to the same degree. Uncertainty methods are designed to\nprovide an estimate of class probabilities when predicting class assignment.\n  While there are a number of proposed methods for estimating uncertainty, they\nall suffer from a lack of calibration: predicted probabilities can be off from\nempirical ones by a few percent or more. By restricting the scope of our\npredictions to only the probability of Top-1 error, we can decrease the\ncalibration error of existing methods to less than one percent. As a result,\nthe scores of the methods also improve significantly over benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 19:48:45 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 16:37:47 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 18:43:16 GMT"}, {"version": "v4", "created": "Tue, 16 Jun 2020 13:02:58 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Oberman", "Adam M.", ""], ["Finlay", "Chris", ""], ["Iannantuono", "Alexander", ""], ["Salvador", "Tiago", ""]]}, {"id": "1903.09231", "submitter": "Rina Panigrahy", "authors": "Surbhi Goel, Rina Panigrahy", "title": "Recovering the Lowest Layer of Deep Networks with High Threshold\n  Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Giving provable guarantees for learning neural networks is a core challenge\nof machine learning theory. Most prior work gives parameter recovery guarantees\nfor one hidden layer networks, however, the networks used in practice have\nmultiple non-linear layers. In this work, we show how we can strengthen such\nresults to deeper networks -- we address the problem of uncovering the lowest\nlayer in a deep neural network under the assumption that the lowest layer uses\na high threshold before applying the activation, the upper network can be\nmodeled as a well-behaved polynomial and the input distribution is Gaussian.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 20:41:58 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 01:00:13 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Goel", "Surbhi", ""], ["Panigrahy", "Rina", ""]]}, {"id": "1903.09235", "submitter": "Taiyao Wang", "authors": "Taiyao Wang, Ioannis Ch. Paschalidis", "title": "Convergence of Parameter Estimates for Regularized Mixed Linear\n  Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider {\\em Mixed Linear Regression (MLR)}, where training data have\nbeen generated from a mixture of distinct linear models (or clusters) and we\nseek to identify the corresponding coefficient vectors. We introduce a {\\em\nMixed Integer Programming (MIP)} formulation for MLR subject to regularization\nconstraints on the coefficient vectors. We establish that as the number of\ntraining samples grows large, the MIP solution converges to the true\ncoefficient vectors in the absence of noise. Subject to slightly stronger\nassumptions, we also establish that the MIP identifies the clusters from which\nthe training samples were generated. In the special case where training data\ncome from a single cluster, we establish that the corresponding MIP yields a\nsolution that converges to the true coefficient vector even when training data\nare perturbed by (martingale difference) noise. We provide a counterexample\nindicating that in the presence of noise, the MIP may fail to produce the true\ncoefficient vectors for more than one clusters. We also provide numerical\nresults testing the MIP solutions in synthetic examples with noise.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 20:44:20 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 15:30:59 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Taiyao", ""], ["Paschalidis", "Ioannis Ch.", ""]]}, {"id": "1903.09239", "submitter": "Alice Schoenauer Sebag", "authors": "Alice Schoenauer-Sebag, Louise Heinrich, Marc Schoenauer, Michele\n  Sebag, Lani F. Wu, Steve J. Altschuler", "title": "Multi-Domain Adversarial Learning", "comments": "Accepted at ICLR'19", "journal-ref": "ICLR 2019-Seventh annual International Conference on Learning\n  Representations", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-domain learning (MDL) aims at obtaining a model with minimal average\nrisk across multiple domains. Our empirical motivation is automated microscopy\ndata, where cultured cells are imaged after being exposed to known and unknown\nchemical perturbations, and each dataset displays significant experimental\nbias. This paper presents a multi-domain adversarial learning approach, MuLANN,\nto leverage multiple datasets with overlapping but distinct class sets, in a\nsemi-supervised setting. Our contributions include: i) a bound on the average-\nand worst-domain risk in MDL, obtained using the H-divergence; ii) a new loss\nto accommodate semi-supervised multi-domain learning and domain adaptation;\niii) the experimental validation of the approach, improving on the state of the\nart on two standard image benchmarks, and a novel bioimage dataset, Cell.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 21:18:21 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Schoenauer-Sebag", "Alice", ""], ["Heinrich", "Louise", ""], ["Schoenauer", "Marc", ""], ["Sebag", "Michele", ""], ["Wu", "Lani F.", ""], ["Altschuler", "Steve J.", ""]]}, {"id": "1903.09243", "submitter": "Matthew Walter", "authors": "Siddharth Patki and Andrea F. Daniele and Matthew R. Walter and Thomas\n  M. Howard", "title": "Inferring Compact Representations for Efficient Natural Language\n  Understanding of Robot Instructions", "comments": "Accepted to ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The speed and accuracy with which robots are able to interpret natural\nlanguage is fundamental to realizing effective human-robot interaction. A great\ndeal of attention has been paid to developing models and approximate inference\nalgorithms that improve the efficiency of language understanding. However,\nexisting methods still attempt to reason over a representation of the\nenvironment that is flat and unnecessarily detailed, which limits scalability.\nAn open problem is then to develop methods capable of producing the most\ncompact environment model sufficient for accurate and efficient natural\nlanguage understanding. We propose a model that leverages environment-related\ninformation encoded within instructions to identify the subset of observations\nand perceptual classifiers necessary to perceive a succinct,\ninstruction-specific environment representation. The framework uses three\nprobabilistic graphical models trained from a corpus of annotated instructions\nto infer salient scene semantics, perceptual classifiers, and grounded symbols.\nExperimental results on two robots operating in different environments\ndemonstrate that by exploiting the content and the structure of the\ninstructions, our method learns compact environment representations that\nsignificantly improve the efficiency of natural language symbol grounding.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 21:38:20 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Patki", "Siddharth", ""], ["Daniele", "Andrea F.", ""], ["Walter", "Matthew R.", ""], ["Howard", "Thomas M.", ""]]}, {"id": "1903.09244", "submitter": "Sam Shleifer", "authors": "Sam Shleifer", "title": "Low Resource Text Classification with ULMFit and Backtranslation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer vision, virtually every state-of-the-art deep learning system is\ntrained with data augmentation. In text classification, however, data\naugmentation is less widely practiced because it must be performed before\ntraining and risks introducing label noise. We augment the IMDB movie reviews\ndataset with examples generated by two families of techniques: random token\nperturbations introduced by Wei and Zou [2019] and backtranslation --\ntranslating to a second language then back to English. In low resource\nenvironments, backtranslation generates significant improvement on top of the\nstate of-the-art ULMFit model. A ULMFit model pretrained on wikitext103 and\nthen fine-tuned on only 50 IMDB examples and 500 synthetic examples generated\nby backtranslation achieves 80.6% accuracy, an 8.1% improvement over the\naugmentation-free baseline with only 9 minutes of additional training time.\nRandom token perturbations do not yield any improvements but incur equivalent\ncomputational cost. The benefits of training with backtranslated examples\ndecreases with the size of the available training data. On the full dataset,\nneither augmentation technique improves upon ULMFit's state of the art\nperformance. We address this by using backtranslations as a form of test time\naugmentation as well as ensembling ULMFit with other models, and achieve small\nimprovements.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 21:40:09 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 18:48:16 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Shleifer", "Sam", ""]]}, {"id": "1903.09245", "submitter": "Soheil Khorram", "authors": "Soheil Khorram, Melvin G McInnis, Emily Mower Provost", "title": "Trainable Time Warping: Aligning Time-Series in the Continuous-Time\n  Domain", "comments": "ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  DTW calculates the similarity or alignment between two signals, subject to\ntemporal warping. However, its computational complexity grows exponentially\nwith the number of time-series. Although there have been algorithms developed\nthat are linear in the number of time-series, they are generally quadratic in\ntime-series length. The exception is generalized time warping (GTW), which has\nlinear computational cost. Yet, it can only identify simple time warping\nfunctions. There is a need for a new fast, high-quality multisequence alignment\nalgorithm. We introduce trainable time warping (TTW), whose complexity is\nlinear in both the number and the length of time-series. TTW performs alignment\nin the continuous-time domain using a sinc convolutional kernel and a\ngradient-based optimization technique. We compare TTW and GTW on 85 UCR\ndatasets in time-series averaging and classification. TTW outperforms GTW on\n67.1% of the datasets for the averaging tasks, and 61.2% of the datasets for\nthe classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 21:42:19 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Khorram", "Soheil", ""], ["McInnis", "Melvin G", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1903.09255", "submitter": "Yan Zhang", "authors": "Yan Zhang, Michael M. Zavlanos", "title": "Distributed off-Policy Actor-Critic Reinforcement Learning with Policy\n  Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a distributed off-policy actor critic method to\nsolve multi-agent reinforcement learning problems. Specifically, we assume that\nall agents keep local estimates of the global optimal policy parameter and\nupdate their local value function estimates independently. Then, we introduce\nan additional consensus step to let all the agents asymptotically achieve\nagreement on the global optimal policy function. The convergence analysis of\nthe proposed algorithm is provided and the effectiveness of the proposed\nalgorithm is validated using a distributed resource allocation example.\nCompared to relevant distributed actor critic methods, here the agents do not\nshare information about their local tasks, but instead they coordinate to\nestimate the global policy function.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 22:04:16 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Zhang", "Yan", ""], ["Zavlanos", "Michael M.", ""]]}, {"id": "1903.09267", "submitter": "Houshang Darabi", "authors": "Ashkan Sharabiani, Adam Bress, William Galanter, Rezvan Nazempour, and\n  Houshang Darabi", "title": "A Computer-Aided System for Determining the Application Range of a\n  Warfarin Clinical Dosing Algorithm Using Support Vector Machines with a\n  Polynomial Kernel Function", "comments": "6 pages, 8 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the optimal initial dose for warfarin is a critically important\ntask. Several factors have an impact on the therapeutic dose for individual\npatients, such as patients' physical attributes (Age, Height, etc.), medication\nprofile, co-morbidities, and metabolic genotypes (CYP2C9 and VKORC1). These\nwide range factors influencing therapeutic dose, create a complex environment\nfor clinicians to determine the optimal initial dose. Using a sample of 4,237\npatients, we have proposed a companion classification model to one of the most\npopular dosing algorithms (International Warfarin Pharmacogenetics Consortium\n(IWPC) clinical model), which identifies the appropriate cohort of patients for\napplying this model. The proposed model functions as a clinical decision\nsupport system which assists clinicians in dosing. We have developed a\nclassification model using Support Vector Machines, with a polynomial kernel\nfunction to determine if applying the dose prediction model is appropriate for\na given patient. The IWPC clinical model will only be used if the patient is\nclassified as \"Safe for model\". By using the proposed methodology, the dosing\nmode's prediction accuracy increases by 15 percent in terms of Root Mean\nSquared Error and 17 percent in terms of Mean Absolute Error in dose estimates\nof patients classified as \"Safe for model\".\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 23:05:38 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Sharabiani", "Ashkan", ""], ["Bress", "Adam", ""], ["Galanter", "William", ""], ["Nazempour", "Rezvan", ""], ["Darabi", "Houshang", ""]]}, {"id": "1903.09270", "submitter": "Marcos Martinez-Romero PhD", "authors": "Marcos Mart\\'inez-Romero, Martin J. O'Connor, Attila L. Egyedi, Debra\n  Willrett, Josef Hardi, John Graybeal, Mark A. Musen", "title": "Using association rule mining and ontologies to generate metadata\n  recommendations from multiple biomedical databases", "comments": null, "journal-ref": null, "doi": "10.1093/database/baz059", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metadata-the machine-readable descriptions of the data-are increasingly seen\nas crucial for describing the vast array of biomedical datasets that are\ncurrently being deposited in public repositories. While most public\nrepositories have firm requirements that metadata must accompany submitted\ndatasets, the quality of those metadata is generally very poor. A key problem\nis that the typical metadata acquisition process is onerous and time consuming,\nwith little interactive guidance or assistance provided to users. Secondary\nproblems include the lack of validation and sparse use of standardized terms or\nontologies when authoring metadata. There is a pressing need for improvements\nto the metadata acquisition process that will help users to enter metadata\nquickly and accurately. In this paper we outline a recommendation system for\nmetadata that aims to address this challenge. Our approach uses association\nrule mining to uncover hidden associations among metadata values and to\nrepresent them in the form of association rules. These rules are then used to\npresent users with real-time recommendations when authoring metadata. The\nnovelties of our method are that it is able to combine analyses of metadata\nfrom multiple repositories when generating recommendations and can enhance\nthose recommendations by aligning them with ontology terms. We implemented our\napproach as a service integrated into the CEDAR Workbench metadata authoring\nplatform, and evaluated it using metadata from two public biomedical\nrepositories: US-based National Center for Biotechnology Information (NCBI)\nBioSample and European Bioinformatics Institute (EBI) BioSamples. The results\nshow that our approach is able to use analyses of previous entered metadata\ncoupled with ontology-based mappings to present users with accurate\nrecommendations when authoring metadata.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 23:50:21 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Mart\u00ednez-Romero", "Marcos", ""], ["O'Connor", "Martin J.", ""], ["Egyedi", "Attila L.", ""], ["Willrett", "Debra", ""], ["Hardi", "Josef", ""], ["Graybeal", "John", ""], ["Musen", "Mark A.", ""]]}, {"id": "1903.09284", "submitter": "Waheed Bajwa", "authors": "Mohsen Ghassemi, Zahra Shakeri, Anand D. Sarwate, and Waheed U. Bajwa", "title": "Learning Mixtures of Separable Dictionaries for Tensor Data: Analysis\n  and Algorithms", "comments": "18 pages, 4 figures, 3 tables; Published in IEEE Trans. Signal\n  Processing", "journal-ref": "IEEE Trans. Signal Processing, vol. 68, pp. 33-48, 2020", "doi": "10.1109/TSP.2019.2952046", "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the problem of learning sparse representations of tensor\ndata using structured dictionary learning. It proposes learning a mixture of\nseparable dictionaries to better capture the structure of tensor data by\ngeneralizing the separable dictionary learning model. Two different approaches\nfor learning mixture of separable dictionaries are explored and sufficient\nconditions for local identifiability of the underlying dictionary are derived\nin each case. Moreover, computational algorithms are developed to solve the\nproblem of learning mixture of separable dictionaries in both batch and online\nsettings. Numerical experiments are used to show the usefulness of the proposed\nmodel and the efficacy of the developed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 01:04:50 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 03:24:57 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ghassemi", "Mohsen", ""], ["Shakeri", "Zahra", ""], ["Sarwate", "Anand D.", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1903.09295", "submitter": "'Stephen' Zhen Gou", "authors": "Stephen Zhen Gou, Yuyang Liu", "title": "DQN with model-based exploration: efficient learning on environments\n  with sparse rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Deep Q-Networks (DQN) with model-based exploration, an algorithm\ncombining both model-free and model-based approaches that explores better and\nlearns environments with sparse rewards more efficiently. DQN is a\ngeneral-purpose, model-free algorithm and has been proven to perform well in a\nvariety of tasks including Atari 2600 games since it's first proposed by Minh\net el. However, like many other reinforcement learning (RL) algorithms, DQN\nsuffers from poor sample efficiency when rewards are sparse in an environment.\nAs a result, most of the transitions stored in the replay memory have no\ninformative reward signal, and provide limited value to the convergence and\ntraining of the Q-Network. However, one insight is that these transitions can\nbe used to learn the dynamics of the environment as a supervised learning\nproblem. The transitions also provide information of the distribution of\nvisited states. Our algorithm utilizes these two observations to perform a\none-step planning during exploration to pick an action that leads to states\nleast likely to be seen, thus improving the performance of exploration. We\ndemonstrate our agent's performance in two classic environments with sparse\nrewards in OpenAI gym: Mountain Car and Lunar Lander.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 01:41:50 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Gou", "Stephen Zhen", ""], ["Liu", "Yuyang", ""]]}, {"id": "1903.09296", "submitter": "Dianbo Liu Dr", "authors": "Li Huang and Dianbo Liu", "title": "Patient Clustering Improves Efficiency of Federated Machine Learning to\n  predict mortality and hospital stay time using distributed Electronic Medical\n  Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic medical records (EMRs) supports the development of machine\nlearning algorithms for predicting disease incidence, patient response to\ntreatment, and other healthcare events. But insofar most algorithms have been\ncentralized, taking little account of the decentralized, non-identically\nindependently distributed (non-IID), and privacy-sensitive characteristics of\nEMRs that can complicate data collection, sharing and learning. To address this\nchallenge, we introduced a community-based federated machine learning (CBFL)\nalgorithm and evaluated it on non-IID ICU EMRs. Our algorithm clustered the\ndistributed data into clinically meaningful communities that captured similar\ndiagnoses and geological locations, and learnt one model for each community.\nThroughout the learning process, the data was kept local on hospitals, while\nlocally-computed results were aggregated on a server. Evaluation results show\nthat CBFL outperformed the baseline FL algorithm in terms of Area Under the\nReceiver Operating Characteristic Curve (ROC AUC), Area Under the\nPrecision-Recall Curve (PR AUC), and communication cost between hospitals and\nthe server. Furthermore, communities' performance difference could be explained\nby how dissimilar one community was to others.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 01:49:30 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Huang", "Li", ""], ["Liu", "Dianbo", ""]]}, {"id": "1903.09321", "submitter": "Edgar Dobriban", "authors": "Edgar Dobriban, Yue Sheng", "title": "WONDER: Weighted one-shot distributed ridge regression in high\n  dimensions", "comments": "Gave the name \"Wonder\" to the algorithm, updated title, added\n  algorithm for general non-isotropic design", "journal-ref": null, "doi": null, "report-no": "Journal of Machine Learning Research 21(66) p. 1-52 2020. Short\n  version at ICML 2020", "categories": "math.ST cs.DC cs.LG stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many areas, practitioners need to analyze large datasets that challenge\nconventional single-machine computing. To scale up data analysis, distributed\nand parallel computing approaches are increasingly needed.\n  Here we study a fundamental and highly important problem in this area: How to\ndo ridge regression in a distributed computing environment? Ridge regression is\nan extremely popular method for supervised learning, and has several optimality\nproperties, thus it is important to study. We study one-shot methods that\nconstruct weighted combinations of ridge regression estimators computed on each\nmachine. By analyzing the mean squared error in a high dimensional\nrandom-effects model where each predictor has a small effect, we discover\nseveral new phenomena.\n  1. Infinite-worker limit: The distributed estimator works well for very large\nnumbers of machines, a phenomenon we call \"infinite-worker limit\".\n  2. Optimal weights: The optimal weights for combining local estimators sum to\nmore than unity, due to the downward bias of ridge. Thus, all averaging methods\nare suboptimal.\n  We also propose a new Weighted ONe-shot DistributEd Ridge regression (WONDER)\nalgorithm. We test WONDER in simulation studies and using the Million Song\nDataset as an example. There it can save at least 100x in computation time,\nwhile nearly preserving test accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 02:26:29 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 20:25:58 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Dobriban", "Edgar", ""], ["Sheng", "Yue", ""]]}, {"id": "1903.09326", "submitter": "Xinghua Yao", "authors": "Xinghua Yao, Qiang Cheng, Guo-Qiang Zhang", "title": "A Novel Independent RNN Approach to Classification of Seizures against\n  Non-seizures", "comments": "10 pages, 2 figures, submitted to AMIA symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current clinical practices, electroencephalograms (EEG) are reviewed and\nanalyzed by trained neurologists to provide supports for therapeutic decisions.\nManual reviews can be laborious and error prone. Automatic and accurate\nseizure/non-seizure classification methods are desirable. A critical challenge\nis that seizure morphologies exhibit considerable variabilities. In order to\ncapture essential seizure features, this paper leverages an emerging deep\nlearning model, the independently recurrent neural network (IndRNN), to\nconstruct a new approach for the seizure/non-seizure classification. This new\napproach gradually expands the time scales, thereby extracting temporal and\nspatial features from the local time duration to the entire record. Evaluations\nare conducted with cross-validation experiments across subjects over the noisy\ndata of CHB-MIT. Experimental results demonstrate that the proposed approach\noutperforms the current state-of-the-art methods. In addition, we explore how\nthe segment length affects the classification performance. Thirteen different\nsegment lengths are assessed, showing that the classification performance\nvaries over the segment lengths, and the maximal fluctuating margin is more\nthan 4%. Thus, the segment length is an important factor influencing the\nclassification performance.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 02:34:18 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Yao", "Xinghua", ""], ["Cheng", "Qiang", ""], ["Zhang", "Guo-Qiang", ""]]}, {"id": "1903.09338", "submitter": "Andrew Silva", "authors": "Andrew Silva, Taylor Killian, Ivan Dario Jimenez Rodriguez, Sung-Hyun\n  Son, Matthew Gombolay", "title": "Optimization Methods for Interpretable Differentiable Decision Trees in\n  Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics 2020, 1855-1865", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees are ubiquitous in machine learning for their ease of use and\ninterpretability. Yet, these models are not typically employed in reinforcement\nlearning as they cannot be updated online via stochastic gradient descent. We\novercome this limitation by allowing for a gradient update over the entire tree\nthat improves sample complexity affords interpretable policy extraction. First,\nwe include theoretical motivation on the need for policy-gradient learning by\nexamining the properties of gradient descent over differentiable decision\ntrees. Second, we demonstrate that our approach equals or outperforms a neural\nnetwork on all domains and can learn discrete decision trees online with\naverage rewards up to 7x higher than a batch-trained decision tree. Third, we\nconduct a user study to quantify the interpretability of a decision tree, rule\nlist, and a neural network with statistically significant results ($p <\n0.001$).\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:19:26 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 19:51:44 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 02:19:53 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 20:54:54 GMT"}, {"version": "v5", "created": "Thu, 25 Jun 2020 22:27:49 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Silva", "Andrew", ""], ["Killian", "Taylor", ""], ["Rodriguez", "Ivan Dario Jimenez", ""], ["Son", "Sung-Hyun", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1903.09341", "submitter": "Kazuyoshi Yoshii", "authors": "Kazuki Shimada, Yoshiaki Bando, Masato Mimura, Katsutoshi Itoyama,\n  Kazuyoshi Yoshii, Tatsuya Kawahara", "title": "Unsupervised Speech Enhancement Based on Multichannel NMF-Informed\n  Beamforming for Noise-Robust Automatic Speech Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/TASLP.2019.2907015", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes multichannel speech enhancement for improving automatic\nspeech recognition (ASR) in noisy environments. Recently, the minimum variance\ndistortionless response (MVDR) beamforming has widely been used because it\nworks well if the steering vector of speech and the spatial covariance matrix\n(SCM) of noise are given. To estimating such spatial information, conventional\nstudies take a supervised approach that classifies each time-frequency (TF) bin\ninto noise or speech by training a deep neural network (DNN). The performance\nof ASR, however, is degraded in an unknown noisy environment. To solve this\nproblem, we take an unsupervised approach that decomposes each TF bin into the\nsum of speech and noise by using multichannel nonnegative matrix factorization\n(MNMF). This enables us to accurately estimate the SCMs of speech and noise not\nfrom observed noisy mixtures but from separated speech and noise components. In\nthis paper we propose online MVDR beamforming by effectively initializing and\nincrementally updating the parameters of MNMF. Another main contribution is to\ncomprehensively investigate the performances of ASR obtained by various types\nof spatial filters, i.e., time-invariant and variant versions of MVDR\nbeamformers and those of rank-1 and full-rank multichannel Wiener filters, in\ncombination with MNMF. The experimental results showed that the proposed method\noutperformed the state-of-the-art DNN-based beamforming method in unknown\nenvironments that did not match training data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:36:43 GMT"}, {"version": "v2", "created": "Sun, 31 Mar 2019 14:53:47 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Shimada", "Kazuki", ""], ["Bando", "Yoshiaki", ""], ["Mimura", "Masato", ""], ["Itoyama", "Katsutoshi", ""], ["Yoshii", "Kazuyoshi", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "1903.09343", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Scott Anthony Sisson", "title": "The Binary Space Partitioning-Tree Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mondrian process represents an elegant and powerful approach for space\npartition modelling. However, as it restricts the partitions to be\naxis-aligned, its modelling flexibility is limited. In this work, we propose a\nself-consistent Binary Space Partitioning (BSP)-Tree process to generalize the\nMondrian process. The BSP-Tree process is an almost surely right continuous\nMarkov jump process that allows uniformly distributed oblique cuts in a\ntwo-dimensional convex polygon. The BSP-Tree process can also be extended using\na non-uniform probability measure to generate direction differentiated cuts.\nThe process is also self-consistent, maintaining distributional invariance\nunder a restricted subdomain. We use Conditional-Sequential Monte Carlo for\ninference using the tree structure as the high-dimensional variable. The\nBSP-Tree process's performance on synthetic data partitioning and relational\nmodelling demonstrates clear inferential improvements over the standard\nMondrian process and other related methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:38:00 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott Anthony", ""]]}, {"id": "1903.09348", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Scott Anthony Sisson", "title": "Binary Space Partitioning Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Binary Space Partitioning~(BSP)-Tree process is proposed to produce\nflexible 2-D partition structures which are originally used as a Bayesian\nnonparametric prior for relational modelling. It can hardly be applied to other\nlearning tasks such as regression trees because extending the BSP-Tree process\nto a higher dimensional space is nontrivial. This paper is the first attempt to\nextend the BSP-Tree process to a d-dimensional (d>2) space. We propose to\ngenerate a cutting hyperplane, which is assumed to be parallel to d-2\ndimensions, to cut each node in the d-dimensional BSP-tree. By designing a\nsubtle strategy to sample two free dimensions from d dimensions, the extended\nBSP-Tree process can inherit the essential self-consistency property from the\noriginal version. Based on the extended BSP-Tree process, an ensemble model,\nwhich is named the BSP-Forest, is further developed for regression tasks.\nThanks to the retained self-consistency property, we can thus significantly\nreduce the geometric calculations in the inference stage. Compared to its\ncounterpart, the Mondrian Forest, the BSP-Forest can achieve similar\nperformance with fewer cuts due to its flexibility. The BSP-Forest also\noutperforms other (Bayesian) regression forests on a number of real-world data\nsets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:48:48 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott Anthony", ""]]}, {"id": "1903.09366", "submitter": "Masanori Yamada", "authors": "Heecheol Kim, Masanori Yamada, Kosuke Miyoshi, Hiroshi Yamakawa", "title": "Macro Action Reinforcement Learning with Sequence Disentanglement using\n  Variational Autoencoder", "comments": "First and second authors equally contributed to this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One problem in the application of reinforcement learning to real-world\nproblems is the curse of dimensionality on the action space. Macro actions, a\nsequence of primitive actions, have been studied to diminish the dimensionality\nof the action space with regard to the time axis. However, previous studies\nrelied on humans defining macro actions or assumed macro actions as repetitions\nof the same primitive actions. We present Factorized Macro Action Reinforcement\nLearning (FaMARL) which autonomously learns disentangled factor representation\nof a sequence of actions to generate macro actions that can be directly applied\nto general reinforcement learning algorithms. FaMARL exhibits higher scores\nthan other reinforcement learning algorithms on environments that require an\nextensive amount of search.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 05:54:27 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 01:46:52 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kim", "Heecheol", ""], ["Yamada", "Masanori", ""], ["Miyoshi", "Kosuke", ""], ["Yamakawa", "Hiroshi", ""]]}, {"id": "1903.09374", "submitter": "Dongyang Zhao", "authors": "Dongyang Zhao, Liang Zhang, Bo Zhang, Lizhou Zheng, Yongjun Bao,\n  Weipeng Yan", "title": "Deep Hierarchical Reinforcement Learning Based Recommendations via\n  Multi-goals Abstraction", "comments": "submitted to SIGKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recommender system is an important form of intelligent application, which\nassists users to alleviate from information redundancy. Among the metrics used\nto evaluate a recommender system, the metric of conversion has become more and\nmore important. The majority of existing recommender systems perform poorly on\nthe metric of conversion due to its extremely sparse feedback signal. To tackle\nthis challenge, we propose a deep hierarchical reinforcement learning based\nrecommendation framework, which consists of two components, i.e., high-level\nagent and low-level agent. The high-level agent catches long-term sparse\nconversion signals, and automatically sets abstract goals for low-level agent,\nwhile the low-level agent follows the abstract goals and interacts with\nreal-time environment. To solve the inherent problem in hierarchical\nreinforcement learning, we propose a novel deep hierarchical reinforcement\nlearning algorithm via multi-goals abstraction (HRL-MG). Our proposed algorithm\ncontains three characteristics: 1) the high-level agent generates multiple\ngoals to guide the low-level agent in different stages, which reduces the\ndifficulty of approaching high-level goals; 2) different goals share the same\nstate encoder parameters, which increases the update frequency of the\nhigh-level agent and thus accelerates the convergence of our proposed\nalgorithm; 3) an appreciate benefit assignment function is designed to allocate\nrewards in each goal so as to coordinate different goals in a consistent\ndirection. We evaluate our proposed algorithm based on a real-world e-commerce\ndataset and validate its effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 06:43:49 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Zhao", "Dongyang", ""], ["Zhang", "Liang", ""], ["Zhang", "Bo", ""], ["Zheng", "Lizhou", ""], ["Bao", "Yongjun", ""], ["Yan", "Weipeng", ""]]}, {"id": "1903.09381", "submitter": "Yeping Hu", "authors": "Yeping Hu, Wei Zhan, Liting Sun, Masayoshi Tomizuka", "title": "Multi-modal Probabilistic Prediction of Interactive Behavior via an\n  Interpretable Model", "comments": "accepted by the 2019 IEEE Intelligent Vehicles Symposium (IV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For autonomous agents to successfully operate in real world, the ability to\nanticipate future motions of surrounding entities in the scene can greatly\nenhance their safety levels since potentially dangerous situations could be\navoided in advance. While impressive results have been shown on predicting each\nagent's behavior independently, we argue that it is not valid to consider road\nentities individually since transitions of vehicle states are highly coupled.\nMoreover, as the predicted horizon becomes longer, modeling prediction\nuncertainties and multi-modal distributions over future sequences will turn\ninto a more challenging task. In this paper, we address this challenge by\npresenting a multi-modal probabilistic prediction approach. The proposed method\nis based on a generative model and is capable of jointly predicting sequential\nmotions of each pair of interacting agents. Most importantly, our model is\ninterpretable, which can explain the underneath logic as well as obtain more\nreliability to use in real applications. A complicate real-world roundabout\nscenario is utilized to implement and examine the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 07:06:58 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 17:02:45 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hu", "Yeping", ""], ["Zhan", "Wei", ""], ["Sun", "Liting", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1903.09383", "submitter": "Dominic Kafka", "authors": "Dominic Kafka and Daniel Wilke", "title": "Gradient-only line searches: An Alternative to Probabilistic Line\n  Searches", "comments": "25 Pages, 12 Figures, to be submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Step sizes in neural network training are largely determined using\npredetermined rules such as fixed learning rates and learning rate schedules.\nThese require user input or expensive global optimization strategies to\ndetermine their functional form and associated hyperparameters. Line searches\nare capable of adaptively resolving learning rate schedules. However, due to\ndiscontinuities induced by mini-batch sub-sampling, they have largely fallen\nout of favour. Notwithstanding, probabilistic line searches, which use\nstatistical surrogates over a limited spatial domain, have recently\ndemonstrated viability in resolving learning rates for stochastic loss\nfunctions.\n  This paper introduces an alternative paradigm, Gradient-Only Line Searches\nthat are Inexact (GOLS-I), as an alternative strategy to automatically\ndetermine learning rates in stochastic loss functions over a range of 15 orders\nof magnitude without the use of surrogates. We show that GOLS-I is a\ncompetitive strategy to reliably determine step sizes, adding high value in\nterms of performance, while being easy to implement.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 07:14:00 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 13:40:12 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kafka", "Dominic", ""], ["Wilke", "Daniel", ""]]}, {"id": "1903.09395", "submitter": "Kurt Izak Cabanilla", "authors": "Kurt Izak Cabanilla and Kevin Thomas Go", "title": "Forecasting, Causality, and Impulse Response with Neural Vector\n  Autoregressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating nonlinearity is paramount to predicting the future states of a\ndynamical system, its response to shocks, and its underlying causal network.\nHowever, most existing methods for causality detection and impulse response,\nsuch as Vector Autoregression (VAR), assume linearity and are thus unable to\ncapture the complexity. Here, we introduce a vector autoencoder nonlinear\nautoregression neural network (VANAR) capable of both automatic time series\nfeature extraction for its inputs and functional form estimation. We evaluate\nVANAR in three ways: first in terms of pure forecast accuracy, second in terms\nof detecting the correct causality between variables, and lastly in terms of\nimpulse response where we model trajectories given external shocks. These tests\nwere performed on a simulated nonlinear chaotic system and an empirical system\nusing Philippine macroeconomic data. Results show that VANAR significantly\noutperforms VAR in the forecast and causality tests. VANAR has consistently\nsuperior accuracy even over state of the art models such as SARIMA and TBATS.\nFor the impulse response test, both models fail to predict the shocked\ntrajectories of the nonlinear chaotic system. VANAR was robust in its ability\nto model a wide variety of dynamics, from chaotic, high noise, and low data\nenvironments to macroeconomic systems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 08:15:35 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 07:45:26 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2019 07:23:35 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Cabanilla", "Kurt Izak", ""], ["Go", "Kevin Thomas", ""]]}, {"id": "1903.09412", "submitter": "Simon Wein", "authors": "Simon Wein, Ana Maria Tom\\'e, Markus Goldhacker, Mark W. Greenlee,\n  Elmar W. Lang", "title": "A constrained ICA-EMD Model for Group Level fMRI Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent component analysis (ICA), as a data driven method, has shown to\nbe a powerful tool for functional magnetic resonance imaging (fMRI) data\nanalysis. One drawback of this multivariate approach is, that it is not\ncompatible to the analysis of group data in general. Therefore various\ntechniques have been proposed in order to overcome this limitation of ICA. In\nthis paper a novel ICA-based work-flow for extracting resting state networks\nfrom fMRI group studies is proposed. An empirical mode decomposition (EMD) is\nused to generate reference signals in a data driven manner, which can be\nincorporated into a constrained version of ICA (cICA), what helps to eliminate\nthe inherent ambiguities of ICA. The results of the proposed workflow are then\ncompared to those obtained by a widely used group ICA approach for fMRI\nanalysis. In this paper it is demonstrated that intrinsic modes, extracted by\nEMD, are suitable to serve as references for cICA to obtain typical resting\nstate patterns, which are consistent over subjects. By introducing these\nreference signals into the ICA, our processing pipeline makes it transparent\nfor the user, how comparable activity patterns across subjects emerge. This\nadditionally allows adapting the trade-off between enforcing similarity across\nsubjects and preserving individual subject features.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 09:15:23 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Wein", "Simon", ""], ["Tom\u00e9", "Ana Maria", ""], ["Goldhacker", "Markus", ""], ["Greenlee", "Mark W.", ""], ["Lang", "Elmar W.", ""]]}, {"id": "1903.09415", "submitter": "Raphael Volz", "authors": "Maximilian Auer, Kai Osswald, Raphael Volz, Joerg Woidasky", "title": "Artificial intelligence-based process for metal scrap sorting", "comments": "8 pages, 3 figures, 1 table, peer-reviewed, accepted and presented", "journal-ref": "Bockreis, A. et al. (Hrsg.): 9. Wissenschaftskongress Abfall- und\n  Ressourcenwirtschaft. Innsbruck University Press, 2019, ISBN\n  978-3-903187-48-1, S. 17-22", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning offers remarkable benefits for improving workplaces and\nworking conditions amongst others in the recycling industry. Here e.g.\nhand-sorting of medium value scrap is labor intensive and requires experienced\nand skilled workers. On the one hand, they have to be highly concentrated for\nmaking proper readings and analyses of the material, but on the other hand,\nthis work is monotonous. Therefore, a machine learning approach is proposed for\na quick and reliable automated identification of alloys in the recycling\nindustry, while the mere scrap handling is regarded to be left in the hands of\nthe workers. To this end, a set of twelve tool and high-speed steels from the\nfield were selected to be identified by their spectrum induced by electric\narcs. For data acquisition, the optical emission spectrometer Thorlabs CCS 100\nwas used. Spectra have been post-processed to be fed into the supervised\nmachine learning algorithm. The development of the machine learning software is\nconducted according to the steps of the VDI 2221 standard method. For\nprogramming Python 3 as well as the python-library sklearn were used. By\nsystematic parameter variation, the appropriate machine learning algorithm was\nselected and validated. Subsequent validation steps showed that the automated\nidentification process using a machine learning approach and the optical\nemission spectrometry is applicable, reaching a maximum F1 score of 96.9 %.\nThis performance is as good as the performance of a highly trained worker using\nvisual grinding spark identification. The tests were based on a self-generated\nset of 600 spectra per single alloy (7,200 spectra in total) which were\nproduced using an industry workshop device.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 09:28:03 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Auer", "Maximilian", ""], ["Osswald", "Kai", ""], ["Volz", "Raphael", ""], ["Woidasky", "Joerg", ""]]}, {"id": "1903.09434", "submitter": "Celestine Mendler-D\\\"unner", "authors": "Alessandro De Palma, Celestine Mendler-D\\\"unner, Thomas Parnell,\n  Andreea Anghel, Haralampos Pozidis", "title": "Sampling Acquisition Functions for Batch Bayesian Optimization", "comments": "Presented at BNP@NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Acquisition Thompson Sampling (ATS), a novel technique for batch\nBayesian Optimization (BO) based on the idea of sampling multiple acquisition\nfunctions from a stochastic process. We define this process through the\ndependency of the acquisition functions on a set of model hyper-parameters. ATS\nis conceptually simple, straightforward to implement and, unlike other batch BO\nmethods, it can be employed to parallelize any sequential acquisition function\nor to make existing parallel methods scale further. We present experiments on a\nvariety of benchmark functions and on the hyper-parameter optimization of a\npopular gradient boosting tree algorithm. These demonstrate the advantages of\nATS with respect to classical parallel Thompson Sampling for BO, its\ncompetitiveness with two state-of-the-art batch BO methods, and its\neffectiveness if applied to existing parallel BO algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 10:25:55 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 18:31:47 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["De Palma", "Alessandro", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Parnell", "Thomas", ""], ["Anghel", "Andreea", ""], ["Pozidis", "Haralampos", ""]]}, {"id": "1903.09478", "submitter": "Cristina Fernandes", "authors": "Luis Roque, Cristina A. C. Fernandes and Tony Silva", "title": "Optimal Combination Forecasts on Retail Multi-Dimensional Sales Data", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data in the retail world are particularly rich in terms of\ndimensionality, and these dimensions can be aggregated in groups or\nhierarchies. Valuable information is nested in these complex structures, which\nhelps to predict the aggregated time series data. From a portfolio of brands\nunder HUUB's monitoring, we selected two to explore their sales behaviour,\nleveraging the grouping properties of their product structure. Using\nstatistical models, namely SARIMA, to forecast each level of the hierarchy, an\noptimal combination approach was used to generate more consistent forecasts in\nthe higher levels. Our results show that the proposed methods can indeed\ncapture nested information in the more granular series, helping to improve the\nforecast accuracy of the aggregated series. The Weighted Least Squares (WLS)\nmethod surpasses all other methods proposed in the study, including the Minimum\nTrace (MinT) reconciliation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 12:53:23 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Roque", "Luis", ""], ["Fernandes", "Cristina A. C.", ""], ["Silva", "Tony", ""]]}, {"id": "1903.09493", "submitter": "Elena Beretta", "authors": "Elena Beretta, Antonio Santangelo, Bruno Lepri, Antonio Vetr\\`o, Juan\n  Carlos De Martin", "title": "The invisible power of fairness. How machine learning shapes democracy", "comments": "12 pages, 1 figure, preprint version, submitted to The 32nd Canadian\n  Conference on Artificial Intelligence that will take place in Kingston,\n  Ontario, May 28 to May 31, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Many machine learning systems make extensive use of large amounts of data\nregarding human behaviors. Several researchers have found various\ndiscriminatory practices related to the use of human-related machine learning\nsystems, for example in the field of criminal justice, credit scoring and\nadvertising. Fair machine learning is therefore emerging as a new field of\nstudy to mitigate biases that are inadvertently incorporated into algorithms.\nData scientists and computer engineers are making various efforts to provide\ndefinitions of fairness. In this paper, we provide an overview of the most\nwidespread definitions of fairness in the field of machine learning, arguing\nthat the ideas highlighting each formalization are closely related to different\nideas of justice and to different interpretations of democracy embedded in our\nculture. This work intends to analyze the definitions of fairness that have\nbeen proposed to date to interpret the underlying criteria and to relate them\nto different ideas of democracy.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 13:24:41 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Beretta", "Elena", ""], ["Santangelo", "Antonio", ""], ["Lepri", "Bruno", ""], ["Vetr\u00f2", "Antonio", ""], ["De Martin", "Juan Carlos", ""]]}, {"id": "1903.09538", "submitter": "Hiroaki Adachi", "authors": "Hiroaki Adachi, Yoko Kawamura, Keiji Nakagawa, Ryoichi Horisaki, Issei\n  Sato, Satoko Yamaguchi, Katsuhito Fujiu, Kayo Waki, Hiroyuki Noji, Sadao Ota", "title": "Use of Ghost Cytometry to Differentiate Cells with Similar Gross\n  Morphologic Characteristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging flow cytometry shows significant potential for increasing our\nunderstanding of heterogeneous and complex life systems and is useful for\nbiomedical applications. Ghost cytometry is a recently proposed approach for\ndirectly analyzing compressively measured signals, thereby relieving the\ncomputational bottleneck observed in high-throughput cytometry based on\nmorphological information. While this image-free approach could distinguish\ndifferent cell types using the same fluorescence staining method, further\nstrict controls are sometimes required to clearly demonstrate that the\nclassification is based on detailed morphologic analysis. In this study, we\nshow that ghost cytometry can be used to classify cell populations of the same\ntype but with different fluorescence distributions in space, supporting the\nstrength of our image-free approach for morphologic cell analysis.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 14:50:37 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Adachi", "Hiroaki", ""], ["Kawamura", "Yoko", ""], ["Nakagawa", "Keiji", ""], ["Horisaki", "Ryoichi", ""], ["Sato", "Issei", ""], ["Yamaguchi", "Satoko", ""], ["Fujiu", "Katsuhito", ""], ["Waki", "Kayo", ""], ["Noji", "Hiroyuki", ""], ["Ota", "Sadao", ""]]}, {"id": "1903.09587", "submitter": "Connor McCurley", "authors": "Connor H. McCurley, James Bocinsky, Alina Zare", "title": "Comparison of Hand-held WEMI Target Detection Algorithms", "comments": "SPIE Defense + Commercial Sensing, 20 pages, 8 figures", "journal-ref": "Proc. SPIE 11012, Detection and Sensing of Mines, Explosive\n  Objects, and Obscured Targets XXIV, 110120U (10 May 2019)", "doi": "10.1117/12.2519454", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide-band Electromagnetic Induction Sensors (WEMI) have been used for a\nnumber of years in subsurface detection of explosive hazards. While WEMI\nsensors have proven effective at localizing objects exhibiting large magnetic\nresponses, detecting objects lacking or containing very low amounts of\nconductive materials can be challenging. In this paper, we compare a number of\ntarget detection algorithms in the literature in terms of detection\nperformance. In the comparison, methods are tested on two real-world data sets:\none containing relatively low amounts of ground noise pollution, and the other\ndemonstrating highly-magnetic soil interference. Results are quantitatively\nevaluated through receiver-operator characteristic (ROC) curves and are used to\nhighlight the strengths and weaknesses of the compared approaches in hand-held\nexplosive hazard detection.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 16:28:35 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["McCurley", "Connor H.", ""], ["Bocinsky", "James", ""], ["Zare", "Alina", ""]]}, {"id": "1903.09631", "submitter": "Parthe Pandit", "authors": "Parthe Pandit, Mojtaba Sahraee-Ardakan, Arash A. Amini, Sundeep\n  Rangan, Alyson K. Fletcher", "title": "High-Dimensional Bernoulli Autoregressive Process with Long-Range\n  Dependence", "comments": "To appear at AISTATS 2019 titled \"Sparse Multivariate Bernoulli\n  Processes in High Dimensions\"", "journal-ref": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019, Naha, Okinawa, Japan. PMLR:\n  Volume 89", "doi": null, "report-no": null, "categories": "math.ST cs.LG eess.SP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the parameters of a multivariate\nBernoulli process with auto-regressive feedback in the high-dimensional setting\nwhere the number of samples available is much less than the number of\nparameters. This problem arises in learning interconnections of networks of\ndynamical systems with spiking or binary-valued data. We allow the process to\ndepend on its past up to a lag $p$, for a general $p \\ge 1$, allowing for more\nrealistic modeling in many applications. We propose and analyze an\n$\\ell_1$-regularized maximum likelihood estimator (MLE) under the assumption\nthat the parameter tensor is approximately sparse. Rigorous analysis of such\nestimators is made challenging by the dependent and non-Gaussian nature of the\nprocess as well as the presence of the nonlinearities and multi-level feedback.\nWe derive precise upper bounds on the mean-squared estimation error in terms of\nthe number of samples, dimensions of the process, the lag $p$ and other key\nstatistical properties of the model. The ideas presented can be used in the\nhigh-dimensional analysis of regularized $M$-estimators for other sparse\nnonlinear and non-Gaussian processes with long-range dependence.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 06:06:27 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Pandit", "Parthe", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Amini", "Arash A.", ""], ["Rangan", "Sundeep", ""], ["Fletcher", "Alyson K.", ""]]}, {"id": "1903.09639", "submitter": "Varoon Mathur", "authors": "Cody Griffith, Varoon Mathur, Catherine Lin, Kevin Zhu", "title": "Understanding Childhood Vulnerability in The City of Surrey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the community conditions that best support universal access and\nimproved childhood outcomes allows ultimately to improve decision-making in the\nareas of planning and investment across the early stages of childhood\ndevelopment. Here we describe two different data-driven approaches to\nvisualizing the lived experiences of children throughout the City of Surrey,\ncombining data derived from both public and private sources. In one approach,\nwe find specifically that the Early Development Instrument measuring childhood\nvulnerabilities across varying domains can be used to cluster neighborhoods,\nand that census variables can help explain similarities between neighborhoods\nwithin these clusters. In our second approach, we use program registration data\nfrom the City of Surrey's Community and Recreation Services Division. We also\nfind a critical age of entry and exit for each program related to early\nchildhood development and beyond, and find that certain neighborhoods and\nrecreational programs have larger retention rates than others. This report\ndetails the journey of using data to tell the story of these neighborhoods, and\nprovides a lens to which community initiatives can be strategically crafted\nthrough their use.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:23:24 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Griffith", "Cody", ""], ["Mathur", "Varoon", ""], ["Lin", "Catherine", ""], ["Zhu", "Kevin", ""]]}, {"id": "1903.09644", "submitter": "Dreyer Fr\\'ed\\'eric", "authors": "Stefano Carrazza and Fr\\'ed\\'eric A. Dreyer", "title": "Jet grooming through reinforcement learning", "comments": "11 pages, 10 figures, code available at\n  https://github.com/JetsGame/GroomRL, updated to match published version", "journal-ref": "Phys. Rev. D 100, 014014 (2019)", "doi": "10.1103/PhysRevD.100.014014", "report-no": null, "categories": "hep-ph cs.LG hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel implementation of a reinforcement learning (RL)\nalgorithm which is designed to find an optimal jet grooming strategy, a\ncritical tool for collider experiments. The RL agent is trained with a reward\nfunction constructed to optimize the resulting jet properties, using both\nsignal and background samples in a simultaneous multi-level training. We show\nthat the grooming algorithm derived from the deep RL agent can match\nstate-of-the-art techniques used at the Large Hadron Collider, resulting in\nimproved mass resolution for boosted objects. Given a suitable reward function,\nthe agent learns how to train a policy which optimally removes soft wide-angle\nradiation, allowing for a modular grooming technique that can be applied in a\nwide range of contexts. These results are accessible through the corresponding\nGroomRL framework.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 18:00:00 GMT"}, {"version": "v2", "created": "Sun, 21 Jul 2019 17:53:08 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Carrazza", "Stefano", ""], ["Dreyer", "Fr\u00e9d\u00e9ric A.", ""]]}, {"id": "1903.09668", "submitter": "Yuexi Wang", "authors": "Yuexi Wang, Nicholas G. Polson, Vadim O. Sokolov", "title": "Scalable Data Augmentation for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable Data Augmentation (SDA) provides a framework for training deep\nlearning models using auxiliary hidden layers. Scalable MCMC is available for\nnetwork training and inference. SDA provides a number of computational\nadvantages over traditional algorithms, such as avoiding backtracking, local\nmodes and can perform optimization with stochastic gradient descent (SGD) in\nTensorFlow. Standard deep neural networks with logit, ReLU and SVM activation\nfunctions are straightforward to implement. To illustrate our architectures and\nmethodology, we use P\\'{o}lya-Gamma logit data augmentation for a number of\nstandard datasets. Finally, we conclude with directions for future research.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 18:28:20 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Wang", "Yuexi", ""], ["Polson", "Nicholas G.", ""], ["Sokolov", "Vadim O.", ""]]}, {"id": "1903.09688", "submitter": "Erik Derner", "authors": "Ji\\v{r}\\'i Kubal\\'ik, Jan \\v{Z}egklitz, Erik Derner and Robert\n  Babu\\v{s}ka", "title": "Symbolic Regression Methods for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms can be used to optimally solve dynamic\ndecision-making and control problems. With continuous-valued state and input\nvariables, reinforcement learning algorithms must rely on function\napproximators to represent the value function and policy mappings. Commonly\nused numerical approximators, such as neural networks or basis function\nexpansions, have two main drawbacks: they are black-box models offering no\ninsight in the mappings learned, and they require significant trial and error\ntuning of their meta-parameters. In this paper, we propose a new approach to\nconstructing smooth value functions by means of symbolic regression. We\nintroduce three off-line methods for finding value functions based on a state\ntransition model: symbolic value iteration, symbolic policy iteration, and a\ndirect solution of the Bellman equation. The methods are illustrated on four\nnonlinear control problems: velocity control under friction, one-link and\ntwo-link pendulum swing-up, and magnetic manipulation. The results show that\nthe value functions not only yield well-performing policies, but also are\ncompact, human-readable and mathematically tractable. This makes them\npotentially suitable for further analysis of the closed-loop system. A\ncomparison with alternative approaches using neural networks shows that our\nmethod constructs well-performing value functions with substantially fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 19:53:29 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Kubal\u00edk", "Ji\u0159\u00ed", ""], ["\u017degklitz", "Jan", ""], ["Derner", "Erik", ""], ["Babu\u0161ka", "Robert", ""]]}, {"id": "1903.09698", "submitter": "Keaton Hamm", "authors": "Keaton Hamm and Longxiu Huang", "title": "CUR Decompositions, Approximations, and Perturbations", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article discusses a useful tool in dimensionality reduction and low-rank\nmatrix approximation called the CUR decomposition. Various viewpoints of this\nmethod in the literature are synergized and are compared and contrasted;\nincluded in this is a new characterization of exact CUR decompositions. A novel\nperturbation analysis is performed on CUR approximations of noisy versions of\nlow-rank matrices, which compares them with the putative CUR decomposition of\nthe underlying low-rank part. Additionally, we give new column and row sampling\nresults which allow one to conclude that a CUR decomposition of a low-rank\nmatrix is attained with high probability. We then illustrate the stability of\nthese sampling methods under the perturbations studied before, and provide\nnumerical illustrations of the methods and bounds discussed.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 20:26:03 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 17:27:05 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Hamm", "Keaton", ""], ["Huang", "Longxiu", ""]]}, {"id": "1903.09730", "submitter": "Shounak Datta", "authors": "Sankha Subhra Mullick, Shounak Datta, Swagatam Das", "title": "Generative Adversarial Minority Oversampling", "comments": "Codes are available at https://github.com/SankhaSubhra/GAMO", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance is a long-standing problem relevant to a number of real-world\napplications of deep learning. Oversampling techniques, which are effective for\nhandling class imbalance in classical learning systems, can not be directly\napplied to end-to-end deep learning systems. We propose a three-player\nadversarial game between a convex generator, a multi-class classifier network,\nand a real/fake discriminator to perform oversampling in deep learning systems.\nThe convex generator generates new samples from the minority classes as convex\ncombinations of existing instances, aiming to fool both the discriminator as\nwell as the classifier into misclassifying the generated samples. Consequently,\nthe artificial samples are generated at critical locations near the peripheries\nof the classes. This, in turn, adjusts the classifier induced boundaries in a\nway which is more likely to reduce misclassification from the minority classes.\nExtensive experiments on multiple class imbalanced image datasets establish the\nefficacy of our proposal.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 23:13:14 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 03:13:19 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 18:05:57 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Mullick", "Sankha Subhra", ""], ["Datta", "Shounak", ""], ["Das", "Swagatam", ""]]}, {"id": "1903.09732", "submitter": "Paulo Mateus", "authors": "Samuel Arcadinho and Paulo Mateus", "title": "Time Series Imputation", "comments": "Master paper, draft to be submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series is a very active topic in the research community and\nmany machine learning tasks are being used in order to extract information from\nthis type of data. However, in real-world problems data has missing values,\nwhich may difficult the application of machine learning techniques to extract\ninformation. In this paper we focus on the task of imputation of time series.\nMany imputation methods for time series are based on regression methods.\nUnfortunately, these methods perform poorly when the variables are categorical.\nTo address this case, we propose a new imputation method based on Expectation\nMaximization over dynamic Bayesian networks. The approach is assessed with\nsynthetic and real data, and it outperforms several state-of-the art methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 23:39:53 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Arcadinho", "Samuel", ""], ["Mateus", "Paulo", ""]]}, {"id": "1903.09734", "submitter": "Kamyar Azizzadenesheli Ph.D.", "authors": "Kamyar Azizzadenesheli, Anqi Liu, Fanny Yang, Animashree Anandkumar", "title": "Regularized Learning for Domain Adaptation under Label Shifts", "comments": "International Conference on Learning Representations (ICLR) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Regularized Learning under Label shifts (RLLS), a principled and a\npractical domain-adaptation algorithm to correct for shifts in the label\ndistribution between a source and a target domain. We first estimate importance\nweights using labeled source data and unlabeled target data, and then train a\nclassifier on the weighted source samples. We derive a generalization bound for\nthe classifier on the target domain which is independent of the (ambient) data\ndimensions, and instead only depends on the complexity of the function class.\nTo the best of our knowledge, this is the first generalization bound for the\nlabel-shift problem where the labels in the target domain are not available.\nBased on this bound, we propose a regularized estimator for the small-sample\nregime which accounts for the uncertainty in the estimated weights. Experiments\non the CIFAR-10 and MNIST datasets show that RLLS improves classification\naccuracy, especially in the low sample and large-shift regimes, compared to\nprevious methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 23:46:24 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Azizzadenesheli", "Kamyar", ""], ["Liu", "Anqi", ""], ["Yang", "Fanny", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1903.09769", "submitter": "Tianyun Zhang", "authors": "Shaokai Ye, Xiaoyu Feng, Tianyun Zhang, Xiaolong Ma, Sheng Lin,\n  Zhengang Li, Kaidi Xu, Wujie Wen, Sijia Liu, Jian Tang, Makan Fardad, Xue\n  Lin, Yongpan Liu and Yanzhi Wang", "title": "Progressive DNN Compression: A Key to Achieve Ultra-High Weight Pruning\n  and Quantization Rates using ADMM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight pruning and weight quantization are two important categories of DNN\nmodel compression. Prior work on these techniques are mainly based on\nheuristics. A recent work developed a systematic frame-work of DNN weight\npruning using the advanced optimization technique ADMM (Alternating Direction\nMethods of Multipliers), achieving one of state-of-art in weight pruning\nresults. In this work, we first extend such one-shot ADMM-based framework to\nguarantee solution feasibility and provide fast convergence rate, and\ngeneralize to weight quantization as well. We have further developed a\nmulti-step, progressive DNN weight pruning and quantization framework, with\ndual benefits of (i) achieving further weight pruning/quantization thanks to\nthe special property of ADMM regularization, and (ii) reducing the search space\nwithin each step. Extensive experimental results demonstrate the superior\nperformance compared with prior work. Some highlights: (i) we achieve 246x,36x,\nand 8x weight pruning on LeNet-5, AlexNet, and ResNet-50 models, respectively,\nwith (almost) zero accuracy loss; (ii) even a significant 61x weight pruning in\nAlexNet (ImageNet) results in only minor degradation in actual accuracy\ncompared with prior work; (iii) we are among the first to derive notable weight\npruning results for ResNet and MobileNet models; (iv) we derive the first\nlossless, fully binarized (for all layers) LeNet-5 for MNIST and VGG-16 for\nCIFAR-10; and (v) we derive the first fully binarized (for all layers) ResNet\nfor ImageNet with reasonable accuracy loss.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 05:54:26 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 03:27:38 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Ye", "Shaokai", ""], ["Feng", "Xiaoyu", ""], ["Zhang", "Tianyun", ""], ["Ma", "Xiaolong", ""], ["Lin", "Sheng", ""], ["Li", "Zhengang", ""], ["Xu", "Kaidi", ""], ["Wen", "Wujie", ""], ["Liu", "Sijia", ""], ["Tang", "Jian", ""], ["Fardad", "Makan", ""], ["Lin", "Xue", ""], ["Liu", "Yongpan", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1903.09790", "submitter": "Bal\\'azs Csan\\'ad Cs\\'aji", "authors": "Bal\\'azs Csan\\'ad Cs\\'aji and Ambrus Tam\\'as", "title": "Semi-Parametric Uncertainty Bounds for Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies binary classification and aims at estimating the underlying\nregression function which is the conditional expectation of the class labels\ngiven the inputs. The regression function is the key component of the Bayes\noptimal classifier, moreover, besides providing optimal predictions, it can\nalso assess the risk of misclassification. We aim at building non-asymptotic\nconfidence regions for the regression function and suggest three kernel-based\nsemi-parametric resampling methods. We prove that all of them guarantee regions\nwith exact coverage probabilities and they are strongly consistent.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 10:19:20 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Cs\u00e1ji", "Bal\u00e1zs Csan\u00e1d", ""], ["Tam\u00e1s", "Ambrus", ""]]}, {"id": "1903.09795", "submitter": "Pankaj Malhotra", "authors": "Vishnu TV, Diksha, Pankaj Malhotra, Lovekesh Vig, and Gautam Shroff", "title": "Data-driven Prognostics with Predictive Uncertainty Estimation using\n  Ensemble of Deep Ordinal Regression Models", "comments": "Accepted at International Journal of Prognostics and Health\n  Management (IJPHM), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prognostics or Remaining Useful Life (RUL) Estimation from multi-sensor time\nseries data is useful to enable condition-based maintenance and ensure high\noperational availability of equipment. We propose a novel deep learning based\napproach for Prognostics with Uncertainty Quantification that is useful in\nscenarios where: (i) access to labeled failure data is scarce due to rarity of\nfailures (ii) future operational conditions are unobserved and (iii) inherent\nnoise is present in the sensor readings. All three scenarios mentioned are\nunavoidable sources of uncertainty in the RUL estimation process often\nresulting in unreliable RUL estimates. To address (i), we formulate RUL\nestimation as an Ordinal Regression (OR) problem, and propose LSTM-OR: deep\nLong Short Term Memory (LSTM) network based approach to learn the OR function.\nWe show that LSTM-OR naturally allows for incorporation of censored operational\ninstances in training along with the failed instances, leading to more robust\nlearning. To address (ii), we propose a simple yet effective approach to\nquantify predictive uncertainty in the RUL estimation models by training an\nensemble of LSTM-OR models. Through empirical evaluation on C-MAPSS turbofan\nengine benchmark datasets, we demonstrate that LSTM-OR is significantly better\nthan the commonly used deep metric regression based approaches for RUL\nestimation, especially when failed training instances are scarce. Further, our\nuncertainty quantification approach yields high quality predictive uncertainty\nestimates while also leading to improved RUL estimates compared to single best\nLSTM-OR models.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 10:40:30 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 09:19:44 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2019 13:09:03 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 12:10:28 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["TV", "Vishnu", ""], ["Diksha", "", ""], ["Malhotra", "Pankaj", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "1903.09799", "submitter": "Hao-Yun Chen", "authors": "Hao-Yun Chen, Jhao-Hong Liang, Shih-Chieh Chang, Jia-Yu Pan, Yu-Ting\n  Chen, Wei Wei, Da-Cheng Juan", "title": "Improving Adversarial Robustness via Guided Complement Entropy", "comments": "ICCV'19 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness has emerged as an important topic in deep learning as\ncarefully crafted attack samples can significantly disturb the performance of a\nmodel. Many recent methods have proposed to improve adversarial robustness by\nutilizing adversarial training or model distillation, which adds additional\nprocedures to model training. In this paper, we propose a new training paradigm\ncalled Guided Complement Entropy (GCE) that is capable of achieving\n\"adversarial defense for free,\" which involves no additional procedures in the\nprocess of improving adversarial robustness. In addition to maximizing model\nprobabilities on the ground-truth class like cross-entropy, we neutralize its\nprobabilities on the incorrect classes along with a \"guided\" term to balance\nbetween these two terms. We show in the experiments that our method achieves\nbetter model robustness with even better performance compared to the commonly\nused cross-entropy training objective. We also show that our method can be used\northogonal to adversarial training across well-known methods with noticeable\nrobustness gain. To the best of our knowledge, our approach is the first one\nthat improves model robustness without compromising performance.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 11:14:59 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 04:07:55 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 06:11:33 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Chen", "Hao-Yun", ""], ["Liang", "Jhao-Hong", ""], ["Chang", "Shih-Chieh", ""], ["Pan", "Jia-Yu", ""], ["Chen", "Yu-Ting", ""], ["Wei", "Wei", ""], ["Juan", "Da-Cheng", ""]]}, {"id": "1903.09807", "submitter": "Hyungjun Kim", "authors": "Hyungjun Kim, Yulhwa Kim, Sungju Ryu, and Jae-Joon Kim", "title": "BitSplit-Net: Multi-bit Deep Neural Network with Bitwise Activation\n  Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant computational cost and memory requirements for deep neural\nnetworks (DNNs) make it difficult to utilize DNNs in resource-constrained\nenvironments. Binary neural network (BNN), which uses binary weights and binary\nactivations, has been gaining interests for its hardware-friendly\ncharacteristics and minimal resource requirement. However, BNN usually suffers\nfrom accuracy degradation. In this paper, we introduce \"BitSplit-Net\", a neural\nnetwork which maintains the hardware-friendly characteristics of BNN while\nimproving accuracy by using multi-bit precision. In BitSplit-Net, each bit of\nmulti-bit activations propagates independently throughout the network before\nbeing merged at the end of the network. Thus, each bit path of the BitSplit-Net\nresembles BNN and hardware friendly features of BNN, such as bitwise binary\nactivation function, are preserved in our scheme. We demonstrate that the\nBitSplit version of LeNet-5, VGG-9, AlexNet, and ResNet-18 can be trained to\nhave similar classification accuracy at a lower computational cost compared to\nconventional multi-bit networks with low bit precision (<= 4-bit). We further\nevaluate BitSplit-Net on GPU with custom CUDA kernel, showing that BitSplit-Net\ncan achieve better hardware performance in comparison to conventional multi-bit\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 11:52:23 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Kim", "Hyungjun", ""], ["Kim", "Yulhwa", ""], ["Ryu", "Sungju", ""], ["Kim", "Jae-Joon", ""]]}, {"id": "1903.09848", "submitter": "Emmanouil Antonios Platanios", "authors": "Emmanouil Antonios Platanios and Otilia Stretcu and Graham Neubig and\n  Barnabas Poczos and Tom M. Mitchell", "title": "Competence-based Curriculum Learning for Neural Machine Translation", "comments": null, "journal-ref": "NAACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art NMT systems use large neural networks that are not\nonly slow to train, but also often require many heuristics and optimization\ntricks, such as specialized learning rate schedules and large batch sizes. This\nis undesirable as it requires extensive hyperparameter tuning. In this paper,\nwe propose a curriculum learning framework for NMT that reduces training time,\nreduces the need for specialized heuristics or large batch sizes, and results\nin overall better performance. Our framework consists of a principled way of\ndeciding which training samples are shown to the model at different times\nduring training, based on the estimated difficulty of a sample and the current\ncompetence of the model. Filtering training samples in this manner prevents the\nmodel from getting stuck in bad local optima, making it converge faster and\nreach a better solution than the common approach of uniformly sampling training\nexamples. Furthermore, the proposed method can be easily applied to existing\nNMT models by simply modifying their input data pipelines. We show that our\nframework can help improve the training time and the performance of both\nrecurrent neural network models and Transformers, achieving up to a 70%\ndecrease in training time, while at the same time obtaining accuracy\nimprovements of up to 2.2 BLEU.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 17:33:38 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 12:39:04 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Platanios", "Emmanouil Antonios", ""], ["Stretcu", "Otilia", ""], ["Neubig", "Graham", ""], ["Poczos", "Barnabas", ""], ["Mitchell", "Tom M.", ""]]}, {"id": "1903.09860", "submitter": "Yuzhe Ma", "authors": "Yuzhe Ma, Xiaojin Zhu, Justin Hsu", "title": "Data Poisoning against Differentially-Private Learners: Attacks and\n  Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning attacks aim to manipulate the model produced by a learning\nalgorithm by adversarially modifying the training set. We consider differential\nprivacy as a defensive measure against this type of attack. We show that such\nlearners are resistant to data poisoning attacks when the adversary is only\nable to poison a small number of items. However, this protection degrades as\nthe adversary poisons more data. To illustrate, we design attack algorithms\ntargeting objective and output perturbation learners, two standard approaches\nto differentially-private machine learning. Experiments show that our methods\nare effective when the attacker is allowed to poison sufficiently many training\nitems.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 18:20:47 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 17:31:41 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Ma", "Yuzhe", ""], ["Zhu", "Xiaojin", ""], ["Hsu", "Justin", ""]]}, {"id": "1903.09876", "submitter": "Hao Tang", "authors": "Hao Tang, Daniel R. Kim, Xiaohui Xie", "title": "Automated pulmonary nodule detection using 3D deep convolutional neural\n  networks", "comments": "2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection of pulmonary nodules in computed tomography (CT) images is\nessential for successful outcomes among lung cancer patients. Much attention\nhas been given to deep convolutional neural network (DCNN)-based approaches to\nthis task, but models have relied at least partly on 2D or 2.5D components for\ninherently 3D data. In this paper, we introduce a novel DCNN approach,\nconsisting of two stages, that is fully three-dimensional end-to-end and\nutilizes the state-of-the-art in object detection. First, nodule candidates are\nidentified with a U-Net-inspired 3D Faster R-CNN trained using online hard\nnegative mining. Second, false positive reduction is performed by 3D DCNN\nclassifiers trained on difficult examples produced during candidate screening.\nFinally, we introduce a method to ensemble models from both stages via\nconsensus to give the final predictions. By using this framework, we ranked\nfirst of 2887 teams in Season One of Alibaba's 2017 TianChi AI Competition for\nHealthcare.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 20:20:15 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Tang", "Hao", ""], ["Kim", "Daniel R.", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1903.09879", "submitter": "Hao Tang", "authors": "Hao Tang, Chupeng Zhang, Xiaohui Xie", "title": "Automatic Pulmonary Lobe Segmentation Using Deep Learning", "comments": "2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Pulmonary lobe segmentation is an important task for pulmonary disease\nrelated Computer Aided Diagnosis systems (CADs). Classical methods for lobe\nsegmentation rely on successful detection of fissures and other anatomical\ninformation such as the location of blood vessels and airways. With the success\nof deep learning in recent years, Deep Convolutional Neural Network (DCNN) has\nbeen widely applied to analyze medical images like Computed Tomography (CT) and\nMagnetic Resonance Imaging (MRI), which, however, requires a large number of\nground truth annotations. In this work, we release our manually labeled 50 CT\nscans which are randomly chosen from the LUNA16 dataset and explore the use of\ndeep learning on this task. We propose pre-processing CT image by cropping\nregion that is covered by the convex hull of the lungs in order to mitigate the\ninfluence of noise from outside the lungs. Moreover, we design a hybrid loss\nfunction with dice loss to tackle extreme class imbalance issue and focal loss\nto force model to focus on voxels that are hard to be discriminated. To\nvalidate the robustness and performance of our proposed framework trained with\na small number of training examples, we further tested our model on CT scans\nfrom an independent dataset. Experimental results show the robustness of the\nproposed approach, which consistently improves performance across different\ndatasets by a maximum of $5.87\\%$ as compared to a baseline model.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 20:31:45 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 18:04:51 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 06:41:19 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Tang", "Hao", ""], ["Zhang", "Chupeng", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1903.09880", "submitter": "Hao Tang", "authors": "Hao Tang, Xingwei Liu, Xiaohui Xie", "title": "An End-to-end Framework For Integrated Pulmonary Nodule Detection and\n  False Positive Reduction", "comments": "2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Pulmonary nodule detection using low-dose Computed Tomography (CT) is often\nthe first step in lung disease screening and diagnosis. Recently, algorithms\nbased on deep convolutional neural nets have shown great promise for automated\nnodule detection. Most of the existing deep learning nodule detection systems\nare constructed in two steps: a) nodule candidates screening and b) false\npositive reduction, using two different models trained separately. Although it\nis commonly adopted, the two-step approach not only imposes significant\nresource overhead on training two independent deep learning models, but also is\nsub-optimal because it prevents cross-talk between the two. In this work, we\npresent an end-to-end framework for nodule detection, integrating nodule\ncandidate screening and false positive reduction into one model, trained\njointly. We demonstrate that the end-to-end system improves the performance by\n3.88\\% over the two-step approach, while at the same time reducing model\ncomplexity by one third and cutting inference time by 3.6 fold. Code will be\nmade publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 20:38:51 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Tang", "Hao", ""], ["Liu", "Xingwei", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1903.09885", "submitter": "Xiao Li", "authors": "Xiao Li and Calin Belta", "title": "Temporal Logic Guided Safe Reinforcement Learning Using Control Barrier\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using reinforcement learning to learn control policies is a challenge when\nthe task is complex with potentially long horizons. Ensuring adequate but safe\nexploration is also crucial for controlling physical systems. In this paper, we\nuse temporal logic to facilitate specification and learning of complex tasks.\nWe combine temporal logic with control Lyapunov functions to improve\nexploration. We incorporate control barrier functions to safeguard the\nexploration and deployment process. We develop a flexible and learnable system\nthat allows users to specify task objectives and constraints in different forms\nand at various levels. The framework is also able to take advantage of known\nsystem dynamics and handle unknown environmental dynamics by integrating\nmodel-free learning with model-based planning.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 21:29:49 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Li", "Xiao", ""], ["Belta", "Calin", ""]]}, {"id": "1903.09900", "submitter": "Andrew Hundt", "authors": "Andrew Hundt, Varun Jain, Gregory D. Hager", "title": "sharpDARTS: Faster and More Accurate Differentiable Architecture Search", "comments": "9 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has been a source of dramatic improvements\nin neural network design, with recent results meeting or exceeding the\nperformance of hand-tuned architectures. However, our understanding of how to\nrepresent the search space for neural net architectures and how to search that\nspace efficiently are both still in their infancy.\n  We have performed an in-depth analysis to identify limitations in a widely\nused search space and a recent architecture search method, Differentiable\nArchitecture Search (DARTS). These findings led us to introduce novel network\nblocks with a more general, balanced, and consistent design; a better-optimized\nCosine Power Annealing learning rate schedule; and other improvements. Our\nresulting sharpDARTS search is 50% faster with a 20-30% relative improvement in\nfinal model error on CIFAR-10 when compared to DARTS. Our best single model run\nhas 1.93% (1.98+/-0.07) validation error on CIFAR-10 and 5.5% error (5.8+/-0.3)\non the recently released CIFAR-10.1 test set. To our knowledge, both are state\nof the art for models of similar size. This model also generalizes\ncompetitively to ImageNet at 25.1% top-1 (7.8% top-5) error.\n  We found improvements for existing search spaces but does DARTS generalize to\nnew domains? We propose Differentiable Hyperparameter Grid Search and the\nHyperCuboid search space, which are representations designed to leverage DARTS\nfor more general parameter optimization. Here we find that DARTS fails to\ngeneralize when compared against a human's one shot choice of models. We look\nback to the DARTS and sharpDARTS search spaces to understand why, and an\nablation study reveals an unusual generalization gap. We finally propose Max-W\nregularization to solve this problem, which proves significantly better than\nthe handmade design. Code will be made available.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 23:20:44 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Hundt", "Andrew", ""], ["Jain", "Varun", ""], ["Hager", "Gregory D.", ""]]}, {"id": "1903.09922", "submitter": "Nao Takano", "authors": "Nao Takano and Gita Alaghband", "title": "SRGAN: Training Dataset Matters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) in supervised settings can generate\nphoto-realistic corresponding output from low-definition input (SRGAN). Using\nthe architecture presented in the SRGAN original paper [2], we explore how\nselecting a dataset affects the outcome by using three different datasets to\nsee that SRGAN fundamentally learns objects, with their shape, color, and\ntexture, and redraws them in the output rather than merely attempting to\nsharpen edges. This is further underscored with our demonstration that once the\nnetwork learns the images of the dataset, it can generate a photo-like image\nwith even a slight hint of what it might look like for the original from a very\nblurry edged sketch. Given a set of inference images, the network trained with\nthe same dataset results in a better outcome over the one trained with\narbitrary set of images, and we report its significance numerically with\nFrechet Inception Distance score [22].\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 04:28:58 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Takano", "Nao", ""], ["Alaghband", "Gita", ""]]}, {"id": "1903.09940", "submitter": "Mayank Mishra", "authors": "Vinay Kyatham, Mayank Mishra, Tarun Kumar Yadav, Deepak Mishra,\n  Prathosh AP", "title": "Variational Inference with Latent Space Quantization for Adversarial\n  Resilience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their tremendous success in modelling high-dimensional data\nmanifolds, deep neural networks suffer from the threat of adversarial attacks -\nExistence of perceptually valid input-like samples obtained through careful\nperturbation that lead to degradation in the performance of the underlying\nmodel. Major concerns with existing defense mechanisms include\nnon-generalizability across different attacks, models and large inference time.\nIn this paper, we propose a generalized defense mechanism capitalizing on the\nexpressive power of regularized latent space based generative models. We design\nan adversarial filter, devoid of access to classifier and adversaries, which\nmakes it usable in tandem with any classifier. The basic idea is to learn a\nLipschitz constrained mapping from the data manifold, incorporating adversarial\nperturbations, to a quantized latent space and re-map it to the true data\nmanifold. Specifically, we simultaneously auto-encode the data manifold and its\nperturbations implicitly through the perturbations of the regularized and\nquantized generative latent space, realized using variational inference. We\ndemonstrate the efficacy of the proposed formulation in providing resilience\nagainst multiple attack types (black and white box) and methods, while being\nalmost real-time. Our experiments show that the proposed method surpasses the\nstate-of-the-art techniques in several cases.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 07:47:01 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 06:48:07 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Kyatham", "Vinay", ""], ["Mishra", "Mayank", ""], ["Yadav", "Tarun Kumar", ""], ["Mishra", "Deepak", ""], ["AP", "Prathosh", ""]]}, {"id": "1903.09941", "submitter": "Shweta Yadav Shweta", "authors": "Dhanachandra Ningthoujam, Shweta Yadav, Pushpak Bhattacharyya, Asif\n  Ekbal", "title": "Relation extraction between the clinical entities based on the shortest\n  dependency path based LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Owing to the exponential rise in the electronic medical records, information\nextraction in this domain is becoming an important area of research in recent\nyears. Relation extraction between the medical concepts such as medical\nproblem, treatment, and test etc. is also one of the most important tasks in\nthis area. In this paper, we present an efficient relation extraction system\nbased on the shortest dependency path (SDP) generated from the dependency\nparsed tree of the sentence. Instead of relying on many handcrafted features\nand the whole sequence of tokens present in a sentence, our system relies only\non the SDP between the target entities. For every pair of entities, the system\ntakes only the words in the SDP, their dependency labels, Part-of-Speech\ninformation and the types of the entities as the input. We develop a dependency\nparser for extracting dependency information. We perform our experiments on the\nbenchmark i2b2 dataset for clinical relation extraction challenge 2010.\nExperimental results show that our system outperforms the existing systems.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 07:54:57 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Ningthoujam", "Dhanachandra", ""], ["Yadav", "Shweta", ""], ["Bhattacharyya", "Pushpak", ""], ["Ekbal", "Asif", ""]]}, {"id": "1903.09942", "submitter": "Andrei Damian I", "authors": "Laurentiu Piciu, Andrei Damian, Nicolae Tapus, Andrei\n  Simion-Constantinescu, Bogdan Dumitrescu", "title": "Deep recommender engine based on efficient product embeddings neural\n  pipeline", "comments": "2018 17th RoEduNet Conference: Networking in Education and Research\n  (RoEduNet)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive analytics systems are currently one of the most important areas of\nresearch and development within the Artificial Intelligence domain and\nparticularly in Machine Learning. One of the \"holy grails\" of predictive\nanalytics is the research and development of the \"perfect\" recommendation\nsystem. In our paper, we propose an advanced pipeline model for the multi-task\nobjective of determining product complementarity, similarity and sales\nprediction using deep neural models applied to big-data sequential transaction\nsystems. Our highly parallelized hybrid model pipeline consists of both\nunsupervised and supervised models, used for the objectives of generating\nsemantic product embeddings and predicting sales, respectively. Our\nexperimentation and benchmarking processes have been done using pharma industry\nretail real-life transactional Big-Data streams.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 08:11:58 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 13:39:33 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Piciu", "Laurentiu", ""], ["Damian", "Andrei", ""], ["Tapus", "Nicolae", ""], ["Simion-Constantinescu", "Andrei", ""], ["Dumitrescu", "Bogdan", ""]]}, {"id": "1903.09973", "submitter": "Evgeny Ponomarev", "authors": "Julia Gusak, Maksym Kholiavchenko, Evgeny Ponomarev, Larisa Markeeva,\n  Ivan Oseledets, Andrzej Cichocki", "title": "MUSCO: Multi-Stage Compression of neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The low-rank tensor approximation is very promising for the compression of\ndeep neural networks. We propose a new simple and efficient iterative approach,\nwhich alternates low-rank factorization with a smart rank selection and\nfine-tuning. We demonstrate the efficiency of our method comparing to\nnon-iterative ones. Our approach improves the compression rate while\nmaintaining the accuracy for a variety of tasks.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 11:40:18 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 13:08:22 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 13:20:17 GMT"}, {"version": "v4", "created": "Fri, 15 Nov 2019 12:27:25 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Gusak", "Julia", ""], ["Kholiavchenko", "Maksym", ""], ["Ponomarev", "Evgeny", ""], ["Markeeva", "Larisa", ""], ["Oseledets", "Ivan", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1903.09999", "submitter": "Saravanan Thirumuruganathan", "authors": "Shohedul Hasan, Saravanan Thirumuruganathan, Jees Augustine, Nick\n  Koudas, Gautam Das", "title": "Multi-Attribute Selectivity Estimation Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selectivity estimation - the problem of estimating the result size of queries\n- is a fundamental problem in databases. Accurate estimation of query\nselectivity involving multiple correlated attributes is especially challenging.\nPoor cardinality estimates could result in the selection of bad plans by the\nquery optimizer. We investigate the feasibility of using deep learning based\napproaches for both point and range queries and propose two complementary\napproaches. Our first approach considers selectivity as an unsupervised deep\ndensity estimation problem. We successfully introduce techniques from neural\ndensity estimation for this purpose. The key idea is to decompose the joint\ndistribution into a set of tractable conditional probability distributions such\nthat they satisfy the autoregressive property. Our second approach formulates\nselectivity estimation as a supervised deep learning problem that predicts the\nselectivity of a given query. We also introduce and address a number of\npractical challenges arising when adapting deep learning for relational data.\nThese include query/data featurization, incorporating query workload\ninformation in a deep learning framework and the dynamic scenario where both\ndata and workload queries could be updated. Our extensive experiments with a\nspecial emphasis on queries with a large number of predicates and/or small\nresult sizes demonstrates that our proposed techniques provide fast and\naccurate selective estimates with minimal space overhead.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 15:21:04 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 20:43:56 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Hasan", "Shohedul", ""], ["Thirumuruganathan", "Saravanan", ""], ["Augustine", "Jees", ""], ["Koudas", "Nick", ""], ["Das", "Gautam", ""]]}, {"id": "1903.10000", "submitter": "Saravanan Thirumuruganathan", "authors": "Saravanan Thirumuruganathan, Shohedul Hasan, Nick Koudas, Gautam Das", "title": "Approximate Query Processing using Deep Generative Models", "comments": "Accepted to ICDE 2020 as \"Approximate Query Processing for Data\n  Exploration using Deep Generative Models\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is generated at an unprecedented rate surpassing our ability to analyze\nthem. The database community has pioneered many novel techniques for\nApproximate Query Processing (AQP) that could give approximate results in a\nfraction of time needed for computing exact results. In this work, we explore\nthe usage of deep learning (DL) for answering aggregate queries specifically\nfor interactive applications such as data exploration and visualization. We use\ndeep generative models, an unsupervised learning based approach, to learn the\ndata distribution faithfully such that aggregate queries could be answered\napproximately by generating samples from the learned model. The model is often\ncompact - few hundred KBs - so that arbitrary AQP queries could be answered on\nthe client side without contacting the database server. Our other contributions\ninclude identifying model bias and minimizing it through a rejection sampling\nbased approach and an algorithm to build model ensembles for AQP for improved\naccuracy. Our extensive experiments show that our proposed approach can provide\nanswers with high accuracy and low latency.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 15:21:19 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 20:38:25 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 20:05:13 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Thirumuruganathan", "Saravanan", ""], ["Hasan", "Shohedul", ""], ["Koudas", "Nick", ""], ["Das", "Gautam", ""]]}, {"id": "1903.10012", "submitter": "Maria Perez-Ortiz", "authors": "Maria Perez-Ortiz, Pedro A. Gutierrez, Peter Tino, Carlos\n  Casanova-Mateo, Sancho Salcedo-Sanz", "title": "A mixture of experts model for predicting persistent weather patterns", "comments": "Published in IEEE International Joint Conference on Neural Networks\n  (IJCNN) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weather and atmospheric patterns are often persistent. The simplest weather\nforecasting method is the so-called persistence model, which assumes that the\nfuture state of a system will be similar (or equal) to the present state.\nMachine learning (ML) models are widely used in different weather forecasting\napplications, but they need to be compared to the persistence model to analyse\nwhether they provide a competitive solution to the problem at hand. In this\npaper, we devise a new model for predicting low-visibility in airports using\nthe concepts of mixture of experts. Visibility level is coded as two different\nordered categorical variables: cloud height and runway visual height. The\nunderlying system in this application is stagnant approximately in 90% of the\ncases, and standard ML models fail to improve on the performance of the\npersistence model. Because of this, instead of trying to simply beat the\npersistence model using ML, we use this persistence as a baseline and learn an\nordinal neural network model that refines its results by focusing on learning\nweather fluctuations. The results show that the proposal outperforms\npersistence and other ordinal autoregressive models, especially for longer time\nhorizon predictions and for the runway visual height variable.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 16:17:07 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Perez-Ortiz", "Maria", ""], ["Gutierrez", "Pedro A.", ""], ["Tino", "Peter", ""], ["Casanova-Mateo", "Carlos", ""], ["Salcedo-Sanz", "Sancho", ""]]}, {"id": "1903.10022", "submitter": "Maria Perez-Ortiz", "authors": "Maria Perez-Ortiz, Peter Tino, Rafal Mantiuk, Cesar Hervas-Martinez", "title": "Exploiting Synthetically Generated Data with Semi-Supervised Learning\n  for Small and Imbalanced Datasets", "comments": "Published in the Thirty-Third AAAI Conference on Artificial\n  Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is rapidly gaining attention in machine learning. Synthetic\ndata can be generated by simple transformations or through the data\ndistribution. In the latter case, the main challenge is to estimate the label\nassociated to new synthetic patterns. This paper studies the effect of\ngenerating synthetic data by convex combination of patterns and the use of\nthese as unsupervised information in a semi-supervised learning framework with\nsupport vector machines, avoiding thus the need to label synthetic examples. We\nperform experiments on a total of 53 binary classification datasets. Our\nresults show that this type of data over-sampling supports the well-known\ncluster assumption in semi-supervised learning, showing outstanding results for\nsmall high-dimensional datasets and imbalanced learning problems.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 17:09:28 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Perez-Ortiz", "Maria", ""], ["Tino", "Peter", ""], ["Mantiuk", "Rafal", ""], ["Hervas-Martinez", "Cesar", ""]]}, {"id": "1903.10025", "submitter": "Yiwei Li", "authors": "Yiwei Li", "title": "Generalization of k-means Related Algorithms", "comments": "3 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article briefly introduced Arthur and Vassilvitshii's work on\n\\textbf{k-means++} algorithm and further generalized the center initialization\nprocess. It is found that choosing the most distant sample point from the\nnearest center as new center can mostly have the same effect as the center\ninitialization process in the \\textbf{k-means++} algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 17:34:29 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Li", "Yiwei", ""]]}, {"id": "1903.10033", "submitter": "Tommaso Dreossi", "authors": "Tommaso Dreossi, Shromona Ghosh, Alberto Sangiovanni-Vincentelli,\n  Sanjit A. Seshia", "title": "A Formalization of Robustness for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to lack robustness to small input\nperturbations. The process of generating the perturbations that expose the lack\nof robustness of neural networks is known as adversarial input generation. This\nprocess depends on the goals and capabilities of the adversary, In this paper,\nwe propose a unifying formalization of the adversarial input generation process\nfrom a formal methods perspective. We provide a definition of robustness that\nis general enough to capture different formulations. The expressiveness of our\nformalization is shown by modeling and comparing a variety of adversarial\nattack techniques.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 18:10:23 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Dreossi", "Tommaso", ""], ["Ghosh", "Shromona", ""], ["Sangiovanni-Vincentelli", "Alberto", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1903.10039", "submitter": "Swagatam Das", "authors": "Saptarshi Chakraborty and Swagatam Das", "title": "A Strongly Consistent Sparse $k$-means Clustering with Direct $l_1$\n  Penalization on Variable Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Lasso Weighted $k$-means ($LW$-$k$-means) algorithm as a\nsimple yet efficient sparse clustering procedure for high-dimensional data\nwhere the number of features ($p$) can be much larger compared to the number of\nobservations ($n$). In the $LW$-$k$-means algorithm, we introduce a lasso-based\npenalty term, directly on the feature weights to incorporate feature selection\nin the framework of sparse clustering. $LW$-$k$-means does not make any\ndistributional assumption of the given dataset and thus, induces a\nnon-parametric method for feature selection. We also analytically investigate\nthe convergence of the underlying optimization procedure in $LW$-$k$-means and\nestablish the strong consistency of our algorithm. $LW$-$k$-means is tested on\nseveral real-life and synthetic datasets and through detailed experimental\nanalysis, we find that the performance of the method is highly competitive\nagainst some state-of-the-art procedures for clustering and feature selection,\nnot only in terms of clustering accuracy but also with respect to computational\ntime.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 18:45:35 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Chakraborty", "Saptarshi", ""], ["Das", "Swagatam", ""]]}, {"id": "1903.10047", "submitter": "Kenta Oono", "authors": "Kenta Oono, Taiji Suzuki", "title": "Approximation and Non-parametric Estimation of ResNet-type Convolutional\n  Neural Networks", "comments": "8 pages + References 2 pages + Supplemental material 18 pages", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have been shown to achieve optimal\napproximation and estimation error rates (in minimax sense) in several function\nclasses. However, previous analyzed optimal CNNs are unrealistically wide and\ndifficult to obtain via optimization due to sparse constraints in important\nfunction classes, including the H\\\"older class. We show a ResNet-type CNN can\nattain the minimax optimal error rates in these classes in more plausible\nsituations -- it can be dense, and its width, channel size, and filter size are\nconstant with respect to sample size. The key idea is that we can replicate the\nlearning ability of Fully-connected neural networks (FNNs) by tailored CNNs, as\nlong as the FNNs have \\textit{block-sparse} structures. Our theory is general\nin a sense that we can automatically translate any approximation rate achieved\nby block-sparse FNNs into that by CNNs. As an application, we derive\napproximation and estimation error rates of the aformentioned type of CNNs for\nthe Barron and H\\\"older classes with the same strategy.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 19:42:39 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 12:22:39 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 13:23:30 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Oono", "Kenta", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1903.10077", "submitter": "Srivatsan Srinivasan", "authors": "Donghun Lee, Srivatsan Srinivasan, Finale Doshi-Velez", "title": "Truly Batch Apprenticeship Learning with Deep Successor Features", "comments": "10 pages, 3 figures, Under Conference Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel apprenticeship learning algorithm to learn an expert's\nunderlying reward structure in off-policy model-free \\emph{batch} settings.\nUnlike existing methods that require a dynamics model or additional data\nacquisition for on-policy evaluation, our algorithm requires only the batch\ndata of observed expert behavior. Such settings are common in real-world\ntasks---health care, finance or industrial processes ---where accurate\nsimulators do not exist or data acquisition is costly. To address challenges in\nbatch settings, we introduce Deep Successor Feature Networks(DSFN) that\nestimate feature expectations in an off-policy setting and a\ntransition-regularized imitation network that produces a near-expert initial\npolicy and an efficient feature representation. Our algorithm achieves superior\nresults in batch settings on both control benchmarks and a vital clinical task\nof sepsis management in the Intensive Care Unit.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 23:13:27 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Lee", "Donghun", ""], ["Srinivasan", "Srivatsan", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1903.10083", "submitter": "Veeranjaneyulu Sadhanala", "authors": "Veeranjaneyulu Sadhanala, Yu-Xiang Wang, Aaditya Ramdas, Ryan J.\n  Tibshirani", "title": "A Higher-Order Kolmogorov-Smirnov Test", "comments": "18 pages, AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension of the Kolmogorov-Smirnov (KS) two-sample test, which\ncan be more sensitive to differences in the tails. Our test statistic is an\nintegral probability metric (IPM) defined over a higher-order total variation\nball, recovering the original KS test as its simplest case. We give an exact\nrepresenter result for our IPM, which generalizes the fact that the original KS\ntest statistic can be expressed in equivalent variational and CDF forms. For\nsmall enough orders ($k \\leq 5$), we develop a linear-time algorithm for\ncomputing our higher-order KS test statistic; for all others ($k \\geq 6$), we\ngive a nearly linear-time approximation. We derive the asymptotic null\ndistribution for our test, and show that our nearly linear-time approximation\nshares the same asymptotic null. Lastly, we complement our theory with\nnumerical studies.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 23:42:54 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Sadhanala", "Veeranjaneyulu", ""], ["Wang", "Yu-Xiang", ""], ["Ramdas", "Aaditya", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "1903.10144", "submitter": "Hyunjae Kim", "authors": "Raehyun Kim, Hyunjae Kim, Janghyuk Lee, Jaewoo Kang", "title": "Predicting Multiple Demographic Attributes with Task Specific Embedding\n  Transformation and Attention Network", "comments": "SDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most companies utilize demographic information to develop their strategy in a\nmarket. However, such information is not available to most retail companies.\nSeveral studies have been conducted to predict the demographic attributes of\nusers from their transaction histories, but they have some limitations. First,\nthey focused on parameter sharing to predict all attributes but capturing\ntask-specific features is also important in multi-task learning. Second, they\nassumed that all transactions are equally important in predicting demographic\nattributes. However, some transactions are more useful than others for\npredicting a certain attribute. Furthermore, decision making process of models\ncannot be interpreted as they work in a black-box manner. To address the\nlimitations, we propose an Embedding Transformation Network with Attention\n(ETNA) model which shares representations at the bottom of the model structure\nand transforms them to task-specific representations using a simple linear\ntransformation method. In addition, we can obtain more informative transactions\nfor predicting certain attributes using the attention mechanism. The\nexperimental results show that our model outperforms the previous models on all\ntasks. In our qualitative analysis, we show the visualization of attention\nweights, which provides business managers with some useful insights.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 06:25:47 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Kim", "Raehyun", ""], ["Kim", "Hyunjae", ""], ["Lee", "Janghyuk", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1903.10145", "submitter": "Chunyuan Li", "authors": "Hao Fu, Chunyuan Li, Xiaodong Liu, Jianfeng Gao, Asli Celikyilmaz,\n  Lawrence Carin", "title": "Cyclical Annealing Schedule: A Simple Approach to Mitigating KL\n  Vanishing", "comments": "Published in NAACL 2019; The first two authors contribute equally;\n  Code: https://github.com/haofuml/cyclical_annealing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) with an auto-regressive decoder have been\napplied for many natural language processing (NLP) tasks. The VAE objective\nconsists of two terms, (i) reconstruction and (ii) KL regularization, balanced\nby a weighting hyper-parameter \\beta. One notorious training difficulty is that\nthe KL term tends to vanish. In this paper we study scheduling schemes for\n\\beta, and show that KL vanishing is caused by the lack of good latent codes in\ntraining the decoder at the beginning of optimization. To remedy this, we\npropose a cyclical annealing schedule, which repeats the process of increasing\n\\beta multiple times. This new procedure allows the progressive learning of\nmore meaningful latent codes, by leveraging the informative representations of\nprevious cycles as warm re-starts. The effectiveness of cyclical annealing is\nvalidated on a broad range of NLP tasks, including language modeling, dialog\nresponse generation and unsupervised language pre-training.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 06:28:24 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 06:50:06 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 21:43:02 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Fu", "Hao", ""], ["Li", "Chunyuan", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Celikyilmaz", "Asli", ""], ["Carin", "Lawrence", ""]]}, {"id": "1903.10170", "submitter": "Kangxue Yin", "authors": "Kangxue Yin, Zhiqin Chen, Hui Huang, Daniel Cohen-Or, Hao Zhang", "title": "LOGAN: Unpaired Shape Transform in Latent Overcomplete Space", "comments": "Download supplementary material here ->\n  https://kangxue.org/papers/logan_supp.pdf", "journal-ref": "ACM Transactions on Graphics(Proc. of SIGGRAPH Asia), 38(6),\n  198:1-198:13, 2019", "doi": "10.1145/3355089.3356494", "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce LOGAN, a deep neural network aimed at learning general-purpose\nshape transforms from unpaired domains. The network is trained on two sets of\nshapes, e.g., tables and chairs, while there is neither a pairing between\nshapes from the domains as supervision nor any point-wise correspondence\nbetween any shapes. Once trained, LOGAN takes a shape from one domain and\ntransforms it into the other. Our network consists of an autoencoder to encode\nshapes from the two input domains into a common latent space, where the latent\ncodes concatenate multi-scale shape features, resulting in an overcomplete\nrepresentation. The translator is based on a generative adversarial network\n(GAN), operating in the latent space, where an adversarial loss enforces\ncross-domain translation while a feature preservation loss ensures that the\nright shape features are preserved for a natural shape transform. We conduct\nablation studies to validate each of our key network designs and demonstrate\nsuperior capabilities in unpaired shape transforms on a variety of examples\nover baselines and state-of-the-art approaches. We show that LOGAN is able to\nlearn what shape features to preserve during shape translation, either local or\nnon-local, whether content or style, depending solely on the input domains for\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 08:20:48 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 05:37:33 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 01:06:02 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yin", "Kangxue", ""], ["Chen", "Zhiqin", ""], ["Huang", "Hui", ""], ["Cohen-Or", "Daniel", ""], ["Zhang", "Hao", ""]]}, {"id": "1903.10210", "submitter": "Alex Gilbert", "authors": "Yunhao Ba, Alex Ross Gilbert, Franklin Wang, Jinfa Yang, Rui Chen,\n  Yiqin Wang, Lei Yan, Boxin Shi, Achuta Kadambi", "title": "Deep Shape from Polarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes a first attempt to bring the Shape from Polarization (SfP)\nproblem to the realm of deep learning. The previous state-of-the-art methods\nfor SfP have been purely physics-based. We see value in these principled\nmodels, and blend these physical models as priors into a neural network\narchitecture. This proposed approach achieves results that exceed the previous\nstate-of-the-art on a challenging dataset we introduce. This dataset consists\nof polarization images taken over a range of object textures, paints, and\nlighting conditions. We report that our proposed method achieves the lowest\ntest error on each tested condition in our dataset, showing the value of\nblending data-driven and physics-driven approaches.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 09:55:08 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 05:36:22 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ba", "Yunhao", ""], ["Gilbert", "Alex Ross", ""], ["Wang", "Franklin", ""], ["Yang", "Jinfa", ""], ["Chen", "Rui", ""], ["Wang", "Yiqin", ""], ["Yan", "Lei", ""], ["Shi", "Boxin", ""], ["Kadambi", "Achuta", ""]]}, {"id": "1903.10219", "submitter": "Alexandre Araujo", "authors": "Alexandre Araujo, Laurent Meunier, Rafael Pinot, Benjamin Negrevergne", "title": "Robust Neural Networks using Randomized Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of defending a neural network against\nadversarial attacks crafted with different norms (in particular $\\ell_\\infty$\nand $\\ell_2$ bounded adversarial examples). It has been observed that defense\nmechanisms designed to protect against one type of attacks often offer poor\nperformance against the other. We show that $\\ell_\\infty$ defense mechanisms\ncannot offer good protection against $\\ell_2$ attacks and vice-versa, and we\nprovide both theoretical and empirical insights on this phenomenon. Then, we\ndiscuss various ways of combining existing defense mechanisms in order to train\nneural networks robust against both types of attacks. Our experiments show that\nthese new defense mechanisms offer better protection when attacked with both\nnorms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 10:10:50 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 10:00:15 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 12:04:14 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Araujo", "Alexandre", ""], ["Meunier", "Laurent", ""], ["Pinot", "Rafael", ""], ["Negrevergne", "Benjamin", ""]]}, {"id": "1903.10246", "submitter": "Pierre-Yves Oudeyer", "authors": "Pierre-Yves Oudeyer, George Kachergis, William Schueller", "title": "Computational and Robotic Models of Early Language Development: A Review", "comments": "to appear in International Handbook on Language Development, ed. J.\n  Horst and J. von Koss Torkildsen, Routledge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review computational and robotics models of early language learning and\ndevelopment. We first explain why and how these models are used to understand\nbetter how children learn language. We argue that they provide concrete\ntheories of language learning as a complex dynamic system, complementing\ntraditional methods in psychology and linguistics. We review different modeling\nformalisms, grounded in techniques from machine learning and artificial\nintelligence such as Bayesian and neural network approaches. We then discuss\ntheir role in understanding several key mechanisms of language development:\ncross-situational statistical learning, embodiment, situated social\ninteraction, intrinsically motivated learning, and cultural evolution. We\nconclude by discussing future challenges for research, including modeling of\nlarge-scale empirical data about language acquisition in real-world\nenvironments.\n  Keywords: Early language learning, Computational and robotic models, machine\nlearning, development, embodiment, social interaction, intrinsic motivation,\nself-organization, dynamical systems, complexity.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 11:28:36 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Oudeyer", "Pierre-Yves", ""], ["Kachergis", "George", ""], ["Schueller", "William", ""]]}, {"id": "1903.10304", "submitter": "Jui-Hsuan Kuo", "authors": "Fang-I Hsiao, Jui-Hsuan Kuo, Min Sun", "title": "Learning a Multi-Modal Policy via Imitating Demonstrations with Mixed\n  Behaviors", "comments": "10pages, 4 figures, NIPS 2018 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to train a multi-modal policy from mixed\ndemonstrations without their behavior labels. We develop a method to discover\nthe latent factors of variation in the demonstrations. Specifically, our method\nis based on the variational autoencoder with a categorical latent variable. The\nencoder infers discrete latent factors corresponding to different behaviors\nfrom demonstrations. The decoder, as a policy, performs the behaviors\naccordingly. Once learned, the policy is able to reproduce a specific behavior\nby simply conditioning on a categorical vector. We evaluate our method on three\ndifferent tasks, including a challenging task with high-dimensional visual\ninputs. Experimental results show that our approach is better than various\nbaseline methods and competitive with a multi-modal policy trained by ground\ntruth behavior labels.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 13:28:26 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Hsiao", "Fang-I", ""], ["Kuo", "Jui-Hsuan", ""], ["Sun", "Min", ""]]}, {"id": "1903.10328", "submitter": "Huy N. Chau", "authors": "Huy N. Chau, Miklos Rasonyi", "title": "Stochastic Gradient Hamiltonian Monte Carlo for Non-Convex Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) is a momentum version of\nstochastic gradient descent with properly injected Gaussian noise to find a\nglobal minimum. In this paper, non-asymptotic convergence analysis of SGHMC is\ngiven in the context of non-convex optimization, where subsampling techniques\nare used over an i.i.d dataset for gradient updates. Our results complement\nthose of [RRT17] and improve on those of [GGZ18].\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 13:51:17 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 22:19:47 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 06:27:04 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Chau", "Huy N.", ""], ["Rasonyi", "Miklos", ""]]}, {"id": "1903.10335", "submitter": "Duong Nguyen", "authors": "Duong Nguyen, Said Ouala, Lucas Drumetz, Ronan Fablet", "title": "EM-like Learning Chaotic Dynamics from Noisy and Partial Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of the governing equations of chaotic dynamical systems\nfrom data has recently emerged as a hot topic. While the seminal work by\nBrunton et al. reported proof-of-concepts for idealized observation setting for\nfully-observed systems, {\\em i.e.} large signal-to-noise ratios and\nhigh-frequency sampling of all system variables, we here address the learning\nof data-driven representations of chaotic dynamics for partially-observed\nsystems, including significant noise patterns and possibly lower and irregular\nsampling setting. Instead of considering training losses based on short-term\nprediction error like state-of-the-art learning-based schemes, we adopt a\nBayesian formulation and state this issue as a data assimilation problem with\nunknown model parameters. To solve for the joint inference of the hidden\ndynamics and of model parameters, we combine neural-network representations and\nstate-of-the-art assimilation schemes. Using iterative Expectation-Maximization\n(EM)-like procedures, the key feature of the proposed inference schemes is the\nderivation of the posterior of the hidden dynamics. Using a\nneural-network-based Ordinary Differential Equation (ODE) representation of\nthese dynamics, we investigate two strategies: their combination to Ensemble\nKalman Smoothers and Long Short-Term Memory (LSTM)-based variational\napproximations of the posterior. Through numerical experiments on the Lorenz-63\nsystem with different noise and time sampling settings, we demonstrate the\nability of the proposed schemes to recover and reproduce the hidden chaotic\ndynamics, including their Lyapunov characteristic exponents, when classic\nmachine learning approaches fail.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 14:01:22 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Nguyen", "Duong", ""], ["Ouala", "Said", ""], ["Drumetz", "Lucas", ""], ["Fablet", "Ronan", ""]]}, {"id": "1903.10343", "submitter": "Yassir Jedra", "authors": "Yassir Jedra and Alexandre Proutiere", "title": "Sample Complexity Lower Bounds for Linear System Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes problem-specific sample complexity lower bounds for\nlinear system identification problems. The sample complexity is defined in the\nPAC framework: it corresponds to the time it takes to identify the system\nparameters with prescribed accuracy and confidence levels. By problem-specific,\nwe mean that the lower bound explicitly depends on the system to be identified\n(which contrasts with minimax lower bounds), and hence really captures the\nidentification hardness specific to the system. We consider both uncontrolled\nand controlled systems. For uncontrolled systems, the lower bounds are valid\nfor any linear system, stable or not, and only depend of the system finite-time\ncontrollability gramian. A simplified lower bound depending on the spectrum of\nthe system only is also derived. In view of recent finitetime analysis of\nclassical estimation methods (e.g. ordinary least squares), our sample\ncomplexity lower bounds are tight for many systems. For controlled systems, our\nlower bounds are not as explicit as in the case of uncontrolled systems, but\ncould well provide interesting insights into the design of control policy with\nminimal sample complexity.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 14:06:27 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Jedra", "Yassir", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "1903.10346", "submitter": "Yao Qin", "authors": "Yao Qin, Nicholas Carlini, Ian Goodfellow, Garrison Cottrell and Colin\n  Raffel", "title": "Imperceptible, Robust, and Targeted Adversarial Examples for Automatic\n  Speech Recognition", "comments": "International Conference on Machine Learning (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are inputs to machine learning models designed by an\nadversary to cause an incorrect output. So far, adversarial examples have been\nstudied most extensively in the image domain. In this domain, adversarial\nexamples can be constructed by imperceptibly modifying images to cause\nmisclassification, and are practical in the physical world. In contrast,\ncurrent targeted adversarial examples applied to speech recognition systems\nhave neither of these properties: humans can easily identify the adversarial\nperturbations, and they are not effective when played over-the-air. This paper\nmakes advances on both of these fronts. First, we develop effectively\nimperceptible audio adversarial examples (verified through a human study) by\nleveraging the psychoacoustic principle of auditory masking, while retaining\n100% targeted success rate on arbitrary full-sentence targets. Next, we make\nprogress towards physical-world over-the-air audio adversarial examples by\nconstructing perturbations which remain effective even after applying realistic\nsimulated environmental distortions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 17:46:35 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 17:43:09 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Qin", "Yao", ""], ["Carlini", "Nicholas", ""], ["Goodfellow", "Ian", ""], ["Cottrell", "Garrison", ""], ["Raffel", "Colin", ""]]}, {"id": "1903.10391", "submitter": "Xiang Wu", "authors": "Xiang Wu, Ruiqi Guo, Sanjiv Kumar and David Simcha", "title": "Local Orthogonal Decomposition for Maximum Inner Product Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverted file and asymmetric distance computation (IVFADC) have been\nsuccessfully applied to approximate nearest neighbor search and subsequently\nmaximum inner product search. In such a framework, vector quantization is used\nfor coarse partitioning while product quantization is used for quantizing\nresiduals. In the original IVFADC as well as all of its variants, after\nresiduals are computed, the second production quantization step is completely\nindependent of the first vector quantization step. In this work, we seek to\nexploit the connection between these two steps when we perform non-exhaustive\nsearch. More specifically, we decompose a residual vector locally into two\northogonal components and perform uniform quantization and multiscale\nquantization to each component respectively. The proposed method, called local\northogonal decomposition, combined with multiscale quantization consistently\nachieves higher recall than previous methods under the same bitrates. We\nconduct comprehensive experiments on large scale datasets as well as detailed\nablation tests, demonstrating effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:13:27 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Wu", "Xiang", ""], ["Guo", "Ruiqi", ""], ["Kumar", "Sanjiv", ""], ["Simcha", "David", ""]]}, {"id": "1903.10396", "submitter": "Adam Oberman", "authors": "Chris Finlay, Aram-Alexandre Pooladian, and Adam M. Oberman", "title": "The LogBarrier adversarial attack: making effective use of decision\n  boundary information", "comments": "12 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks for image classification are small perturbations to\nimages that are designed to cause misclassification by a model. Adversarial\nattacks formally correspond to an optimization problem: find a minimum norm\nimage perturbation, constrained to cause misclassification. A number of\neffective attacks have been developed. However, to date, no gradient-based\nattacks have used best practices from the optimization literature to solve this\nconstrained minimization problem. We design a new untargeted attack, based on\nthese best practices, using the established logarithmic barrier method. On\naverage, our attack distance is similar or better than all state-of-the-art\nattacks on benchmark datasets (MNIST, CIFAR10, ImageNet-1K). In addition, our\nmethod performs significantly better on the most challenging images, those\nwhich normally require larger perturbations for misclassification. We employ\nthe LogBarrier attack on several adversarially defended models, and show that\nit adversarially perturbs all images more efficiently than other attacks: the\ndistance needed to perturb all images is significantly smaller with the\nLogBarrier attack than with other state-of-the-art attacks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:21:20 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Finlay", "Chris", ""], ["Pooladian", "Aram-Alexandre", ""], ["Oberman", "Adam M.", ""]]}, {"id": "1903.10399", "submitter": "Giulia Denevi", "authors": "Giulia Denevi, Carlo Ciliberto, Riccardo Grazzi, Massimiliano Pontil", "title": "Learning-to-Learn Stochastic Gradient Descent with Biased Regularization", "comments": "37 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning-to-learn: inferring a learning algorithm\nthat works well on tasks sampled from an unknown distribution. As class of\nalgorithms we consider Stochastic Gradient Descent on the true risk regularized\nby the square euclidean distance to a bias vector. We present an average excess\nrisk bound for such a learning algorithm. This result quantifies the potential\nbenefit of using a bias vector with respect to the unbiased case. We then\naddress the problem of estimating the bias from a sequence of tasks. We propose\na meta-algorithm which incrementally updates the bias, as new tasks are\nobserved. The low space and time complexity of this approach makes it appealing\nin practice. We provide guarantees on the learning ability of the\nmeta-algorithm. A key feature of our results is that, when the number of tasks\ngrows and their variance is relatively small, our learning-to-learn approach\nhas a significant advantage over learning each task in isolation by Stochastic\nGradient Descent without a bias term. We report on numerical experiments which\ndemonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:26:56 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Denevi", "Giulia", ""], ["Ciliberto", "Carlo", ""], ["Grazzi", "Riccardo", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1903.10404", "submitter": "Bharat Prakash", "authors": "Bharat Prakash, Mark Horton, Nicholas R. Waytowich, William David\n  Hairston, Tim Oates, Tinoosh Mohsenin", "title": "On the use of Deep Autoencoders for Efficient Embedded Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In autonomous embedded systems, it is often vital to reduce the amount of\nactions taken in the real world and energy required to learn a policy. Training\nreinforcement learning agents from high dimensional image representations can\nbe very expensive and time consuming. Autoencoders are deep neural network used\nto compress high dimensional data such as pixelated images into small latent\nrepresentations. This compression model is vital to efficiently learn policies,\nespecially when learning on embedded systems. We have implemented this model on\nthe NVIDIA Jetson TX2 embedded GPU, and evaluated the power consumption,\nthroughput, and energy consumption of the autoencoders for various CPU/GPU core\ncombinations, frequencies, and model parameters. Additionally, we have shown\nthe reconstructions generated by the autoencoder to analyze the quality of the\ngenerated compressed representation and also the performance of the\nreinforcement learning agent. Finally, we have presented an assessment of the\nviability of training these models on embedded systems and their usefulness in\ndeveloping autonomous policies. Using autoencoders, we were able to achieve 4-5\n$\\times$ improved performance compared to a baseline RL agent with a\nconvolutional feature extractor, while using less than 2W of power.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:38:37 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Prakash", "Bharat", ""], ["Horton", "Mark", ""], ["Waytowich", "Nicholas R.", ""], ["Hairston", "William David", ""], ["Oates", "Tim", ""], ["Mohsenin", "Tinoosh", ""]]}, {"id": "1903.10416", "submitter": "Siwei Feng", "authors": "Siwei Feng, Marco F. Duarte", "title": "Few-Shot Learning-Based Human Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning is a technique to learn a model with a very small amount of\nlabeled training data by transferring knowledge from relevant tasks. In this\npaper, we propose a few-shot learning method for wearable sensor based human\nactivity recognition, a technique that seeks high-level human activity\nknowledge from low-level sensor inputs. Due to the high costs to obtain human\ngenerated activity data and the ubiquitous similarities between activity modes,\nit can be more efficient to borrow information from existing activity\nrecognition models than to collect more data to train a new model from scratch\nwhen only a few data are available for model training. The proposed few-shot\nhuman activity recognition method leverages a deep learning model for feature\nextraction and classification while knowledge transfer is performed in the\nmanner of model parameter transfer. In order to alleviate negative transfer, we\npropose a metric to measure cross-domain class-wise relevance so that knowledge\nof higher relevance is assigned larger weights during knowledge transfer.\nPromising results in extensive experiments show the advantages of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:56:07 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Feng", "Siwei", ""], ["Duarte", "Marco F.", ""]]}, {"id": "1903.10433", "submitter": "Qitan Wu", "authors": "Qitian Wu, Hengrui Zhang, Xiaofeng Gao, Peng He, Paul Weng, Han Gao,\n  Guihai Chen", "title": "Dual Graph Attention Networks for Deep Latent Representation of\n  Multifaceted Social Effects in Recommender Systems", "comments": "Accepted by WWW2019 as a full paper with oral presentation", "journal-ref": null, "doi": "10.1145/3308558.3313442", "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social recommendation leverages social information to solve data sparsity and\ncold-start problems in traditional collaborative filtering methods. However,\nmost existing models assume that social effects from friend users are static\nand under the forms of constant weights or fixed constraints. To relax this\nstrong assumption, in this paper, we propose dual graph attention networks to\ncollaboratively learn representations for two-fold social effects, where one is\nmodeled by a user-specific attention weight and the other is modeled by a\ndynamic and context-aware attention weight. We also extend the social effects\nin user domain to item domain, so that information from related items can be\nleveraged to further alleviate the data sparsity problem. Furthermore,\nconsidering that different social effects in two domains could interact with\neach other and jointly influence user preferences for items, we propose a new\npolicy-based fusion strategy based on contextual multi-armed bandit to weigh\ninteractions of various social effects. Experiments on one benchmark dataset\nand a commercial dataset verify the efficacy of the key components in our\nmodel. The results show that our model achieves great improvement for\nrecommendation accuracy compared with other state-of-the-art social\nrecommendation methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 16:14:01 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Wu", "Qitian", ""], ["Zhang", "Hengrui", ""], ["Gao", "Xiaofeng", ""], ["He", "Peng", ""], ["Weng", "Paul", ""], ["Gao", "Han", ""], ["Chen", "Guihai", ""]]}, {"id": "1903.10446", "submitter": "Sushrut Thorat", "authors": "Sushrut Thorat, Marcel van Gerven, Marius Peelen", "title": "The functional role of cue-driven feature-based feedback in object\n  recognition", "comments": "4 pages, 4 figures, published at the Conference on Cognitive\n  Computational Neuroscience (CCN) 2018", "journal-ref": null, "doi": "10.32470/CCN.2018.1044-0", "report-no": null, "categories": "q-bio.NC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual object recognition is not a trivial task, especially when the objects\nare degraded or surrounded by clutter or presented briefly. External cues (such\nas verbal cues or visual context) can boost recognition performance in such\nconditions. In this work, we build an artificial neural network to model the\ninteraction between the object processing stream (OPS) and the cue. We study\nthe effects of varying neural and representational capacities of the OPS on the\nperformance boost provided by cue-driven feature-based feedback in the OPS. We\nobserve that the feedback provides performance boosts only if the\ncategory-specific features about the objects cannot be fully represented in the\nOPS. This representational limit is more dependent on task demands than neural\ncapacity. We also observe that the feedback scheme trained to maximise\nrecognition performance boost is not the same as tuning-based feedback, and\nactually performs better than tuning-based feedback.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 16:27:07 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Thorat", "Sushrut", ""], ["van Gerven", "Marcel", ""], ["Peelen", "Marius", ""]]}, {"id": "1903.10464", "submitter": "Martin Jullum PhD", "authors": "Kjersti Aas, Martin Jullum, Anders L{\\o}land", "title": "Explaining individual predictions when features are dependent: More\n  accurate approximations to Shapley values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining complex or seemingly simple machine learning models is an\nimportant practical problem. We want to explain individual predictions from a\ncomplex machine learning model by learning simple, interpretable explanations.\nShapley values is a game theoretic concept that can be used for this purpose.\nThe Shapley value framework has a series of desirable theoretical properties,\nand can in principle handle any predictive model. Kernel SHAP is a\ncomputationally efficient approximation to Shapley values in higher dimensions.\nLike several other existing methods, this approach assumes that the features\nare independent, which may give very wrong explanations. This is the case even\nif a simple linear model is used for predictions. In this paper, we extend the\nKernel SHAP method to handle dependent features. We provide several examples of\nlinear and non-linear models with various degrees of feature dependence, where\nour method gives more accurate approximations to the true Shapley values. We\nalso propose a method for aggregating individual Shapley values, such that the\nprediction can be explained by groups of dependent variables.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 16:57:11 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 08:07:18 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 13:31:18 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Aas", "Kjersti", ""], ["Jullum", "Martin", ""], ["L\u00f8land", "Anders", ""]]}, {"id": "1903.10484", "submitter": "Nicholas Carlini", "authors": "J\\\"orn-Henrik Jacobsen and Jens Behrmannn and Nicholas Carlini and\n  Florian Tram\\`er and Nicolas Papernot", "title": "Exploiting Excessive Invariance caused by Norm-Bounded Adversarial\n  Robustness", "comments": "Accepted at the ICLR 2019 SafeML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are malicious inputs crafted to cause a model to\nmisclassify them. Their most common instantiation, \"perturbation-based\"\nadversarial examples introduce changes to the input that leave its true label\nunchanged, yet result in a different model prediction. Conversely,\n\"invariance-based\" adversarial examples insert changes to the input that leave\nthe model's prediction unaffected despite the underlying input's label having\nchanged.\n  In this paper, we demonstrate that robustness to perturbation-based\nadversarial examples is not only insufficient for general robustness, but\nworse, it can also increase vulnerability of the model to invariance-based\nadversarial examples. In addition to analytical constructions, we empirically\nstudy vision classifiers with state-of-the-art robustness to perturbation-based\nadversaries constrained by an $\\ell_p$ norm. We mount attacks that exploit\nexcessive model invariance in directions relevant to the task, which are able\nto find adversarial examples within the $\\ell_p$ ball. In fact, we find that\nclassifiers trained to be $\\ell_p$-norm robust are more vulnerable to\ninvariance-based adversarial examples than their undefended counterparts.\n  Excessive invariance is not limited to models trained to be robust to\nperturbation-based $\\ell_p$-norm adversaries. In fact, we argue that the term\nadversarial example is used to capture a series of model limitations, some of\nwhich may not have been discovered yet. Accordingly, we call for a set of\nprecise definitions that taxonomize and address each of these shortcomings in\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 17:29:52 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Jacobsen", "J\u00f6rn-Henrik", ""], ["Behrmannn", "Jens", ""], ["Carlini", "Nicholas", ""], ["Tram\u00e8r", "Florian", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1903.10520", "submitter": "Siyuan Qiao", "authors": "Siyuan Qiao, Huiyu Wang, Chenxi Liu, Wei Shen, Alan Yuille", "title": "Micro-Batch Training with Batch-Channel Normalization and Weight\n  Standardization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) has become an out-of-box technique to improve deep\nnetwork training. However, its effectiveness is limited for micro-batch\ntraining, i.e., each GPU typically has only 1-2 images for training, which is\ninevitable for many computer vision tasks, e.g., object detection and semantic\nsegmentation, constrained by memory consumption. To address this issue, we\npropose Weight Standardization (WS) and Batch-Channel Normalization (BCN) to\nbring two success factors of BN into micro-batch training: 1) the smoothing\neffects on the loss landscape and 2) the ability to avoid harmful elimination\nsingularities along the training trajectory. WS standardizes the weights in\nconvolutional layers to smooth the loss landscape by reducing the Lipschitz\nconstants of the loss and the gradients; BCN combines batch and channel\nnormalizations and leverages estimated statistics of the activations in\nconvolutional layers to keep networks away from elimination singularities. We\nvalidate WS and BCN on comprehensive computer vision tasks, including image\nclassification, object detection, instance segmentation, video recognition and\nsemantic segmentation. All experimental results consistently show that WS and\nBCN improve micro-batch training significantly. Moreover, using WS and BCN with\nmicro-batch training is even able to match or outperform the performances of BN\nwith large-batch training.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 18:00:05 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 21:25:15 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Qiao", "Siyuan", ""], ["Wang", "Huiyu", ""], ["Liu", "Chenxi", ""], ["Shen", "Wei", ""], ["Yuille", "Alan", ""]]}, {"id": "1903.10534", "submitter": "Francisco Raposo", "authors": "Francisco Afonso Raposo and David Martins de Matos and Ricardo Ribeiro", "title": "Learning Embodied Semantics via Music and Dance Semiotic Correlations", "comments": "24 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music semantics is embodied, in the sense that meaning is biologically\nmediated by and grounded in the human body and brain. This embodied cognition\nperspective also explains why music structures modulate kinetic and\nsomatosensory perception. We leverage this aspect of cognition, by considering\ndance as a proxy for music perception, in a statistical computational model\nthat learns semiotic correlations between music audio and dance video. We\nevaluate the ability of this model to effectively capture underlying semantics\nin a cross-modal retrieval task. Quantitative results, validated with\nstatistical significance testing, strengthen the body of evidence for embodied\ncognition in music and show the model can recommend music audio for dance video\nqueries and vice-versa.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 18:09:03 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Raposo", "Francisco Afonso", ""], ["de Matos", "David Martins", ""], ["Ribeiro", "Ricardo", ""]]}, {"id": "1903.10536", "submitter": "Luke Kumar", "authors": "Luke Kumar and Russell Greiner", "title": "Gene Expression based Survival Prediction for Cancer Patients: A Topic\n  Modeling Approach", "comments": null, "journal-ref": "PLOS ONE 14 (2019) 1-30", "doi": "10.1371/journal.pone.0224446", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer is one of the leading cause of death, worldwide. Many believe that\ngenomic data will enable us to better predict the survival time of these\npatients, which will lead to better, more personalized treatment options and\npatient care. As standard survival prediction models have a hard time coping\nwith the high-dimensionality of such gene expression (GE) data, many projects\nuse some dimensionality reduction techniques to overcome this hurdle. We\nintroduce a novel methodology, inspired by topic modeling from the natural\nlanguage domain, to derive expressive features from the high-dimensional GE\ndata. There, a document is represented as a mixture over a relatively small\nnumber of topics, where each topic corresponds to a distribution over the\nwords; here, to accommodate the heterogeneity of a patient's cancer, we\nrepresent each patient (~document) as a mixture over cancer-topics, where each\ncancer-topic is a mixture over GE values (~words). This required some\nextensions to the standard LDA model eg: to accommodate the \"real-valued\"\nexpression values - leading to our novel \"discretized\" Latent Dirichlet\nAllocation (dLDA) procedure. We initially focus on the METABRIC dataset, which\ndescribes breast cancer patients using the r=49,576 GE values, from\nmicroarrays. Our results show that our approach provides survival estimates\nthat are more accurate than standard models, in terms of the standard\nConcordance measure. We then validate this approach by running it on the\nPan-kidney (KIPAN) dataset, over r=15,529 GE values - here using the mRNAseq\nmodality - and find that it again achieves excellent results. In both cases, we\nalso show that the resulting model is calibrated, using the recent\n\"D-calibrated\" measure. These successes, in two different cancer types and\nexpression modalities, demonstrates the generality, and the effectiveness, of\nthis approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 18:12:30 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 04:16:53 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kumar", "Luke", ""], ["Greiner", "Russell", ""]]}, {"id": "1903.10543", "submitter": "Muhamad Risqi U. Saputra", "authors": "Muhamad Risqi U. Saputra, Pedro P. B. de Gusmao, Sen Wang, Andrew\n  Markham, Niki Trigoni", "title": "Learning Monocular Visual Odometry through Geometry-Aware Curriculum\n  Learning", "comments": "accepted in IEEE ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the cognitive process of humans and animals, Curriculum Learning\n(CL) trains a model by gradually increasing the difficulty of the training\ndata. In this paper, we study whether CL can be applied to complex geometry\nproblems like estimating monocular Visual Odometry (VO). Unlike existing CL\napproaches, we present a novel CL strategy for learning the geometry of\nmonocular VO by gradually making the learning objective more difficult during\ntraining. To this end, we propose a novel geometry-aware objective function by\njointly optimizing relative and composite transformations over small windows\nvia bounded pose regression loss. A cascade optical flow network followed by\nrecurrent network with a differentiable windowed composition layer, termed\nCL-VO, is devised to learn the proposed objective. Evaluation on three\nreal-world datasets shows superior performance of CL-VO over state-of-the-art\nfeature-based and learning-based VO.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 18:26:06 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 21:22:03 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Saputra", "Muhamad Risqi U.", ""], ["de Gusmao", "Pedro P. B.", ""], ["Wang", "Sen", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1903.10545", "submitter": "Ahmad Beirami", "authors": "Yunqi Zhao, Igor Borovikov, Fernando de Mesentier Silva, Ahmad\n  Beirami, Jason Rupert, Caedmon Somers, Jesse Harder, John Kolen, Jervis\n  Pinto, Reza Pourabolghasem, James Pestrak, Harold Chaput, Mohsen Sardari,\n  Long Lin, Sundeep Narravula, Navid Aghdaie, Kazi Zaman", "title": "Winning Isn't Everything: Enhancing Game Development with Intelligent\n  Agents", "comments": "Accepted to IEEE Trans. Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there have been several high-profile achievements of agents\nlearning to play games against humans and beat them. In this paper, we study\nthe problem of training intelligent agents in service of game development.\nUnlike the agents built to \"beat the game\", our agents aim to produce\nhuman-like behavior to help with game evaluation and balancing. We discuss two\nfundamental metrics based on which we measure the human-likeness of agents,\nnamely skill and style, which are multi-faceted concepts with practical\nimplications outlined in this paper. We report four case studies in which the\nstyle and skill requirements inform the choice of algorithms and metrics used\nto train agents; ranging from A* search to state-of-the-art deep reinforcement\nlearning. We, further, show that the learning potential of state-of-the-art\ndeep RL models does not seamlessly transfer from the benchmark environments to\ntarget ones without heavily tuning their hyperparameters, leading to linear\nscaling of the engineering efforts and computational cost with the number of\ntarget domains.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 18:39:04 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 00:19:51 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 04:37:58 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 18:36:10 GMT"}, {"version": "v5", "created": "Tue, 28 Apr 2020 03:29:36 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Zhao", "Yunqi", ""], ["Borovikov", "Igor", ""], ["Silva", "Fernando de Mesentier", ""], ["Beirami", "Ahmad", ""], ["Rupert", "Jason", ""], ["Somers", "Caedmon", ""], ["Harder", "Jesse", ""], ["Kolen", "John", ""], ["Pinto", "Jervis", ""], ["Pourabolghasem", "Reza", ""], ["Pestrak", "James", ""], ["Chaput", "Harold", ""], ["Sardari", "Mohsen", ""], ["Lin", "Long", ""], ["Narravula", "Sundeep", ""], ["Aghdaie", "Navid", ""], ["Zaman", "Kazi", ""]]}, {"id": "1903.10556", "submitter": "Xin Zhang", "authors": "Zenna Tavares, Xin Zhang, Edgar Minaysan, Javier Burroni, Rajesh\n  Ranganath, Armando Solar Lezama", "title": "The Random Conditional Distribution for Higher-Order Probabilistic\n  Inference", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need to condition distributional properties such as expectation,\nvariance, and entropy arises in algorithmic fairness, model simplification,\nrobustness and many other areas. At face value however, distributional\nproperties are not random variables, and hence conditioning them is a semantic\nerror and type error in probabilistic programming languages. On the other hand,\ndistributional properties are contingent on other variables in the model,\nchange in value when we observe more information, and hence in a precise sense\nare random variables too. In order to capture the uncertain over distributional\nproperties, we introduce a probability construct -- the random conditional\ndistribution -- and incorporate it into a probabilistic programming language\nOmega. A random conditional distribution is a higher-order random variable\nwhose realizations are themselves conditional random variables. In Omega we\nextend distributional properties of random variables to random conditional\ndistributions, such that for example while the expectation a real valued random\nvariable is a real value, the expectation of a random conditional distribution\nis a distribution over expectations. As a consequence, it requires minimal\nsyntax to encode inference problems over distributional properties, which so\nfar have evaded treatment within probabilistic programming systems and\nprobabilistic modeling in general. We demonstrate our approach case studies in\nalgorithmic fairness and robustness.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 19:16:23 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Tavares", "Zenna", ""], ["Zhang", "Xin", ""], ["Minaysan", "Edgar", ""], ["Burroni", "Javier", ""], ["Ranganath", "Rajesh", ""], ["Lezama", "Armando Solar", ""]]}, {"id": "1903.10567", "submitter": "Dmitry Kopitkov", "authors": "Dmitry Kopitkov and Vadim Indelman", "title": "General Probabilistic Surface Optimization and Log Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we contribute a novel algorithm family, which generalizes many\nunsupervised techniques including unnormalized and energy models, and allows us\nto infer different statistical modalities (e.g. data likelihood and ratio\nbetween densities) from data samples. The proposed unsupervised technique,\nnamed Probabilistic Surface Optimization (PSO), views a model as a flexible\nsurface which can be pushed according to loss-specific virtual stochastic\nforces, where a dynamical equilibrium is achieved when the pointwise forces on\nthe surface become equal. Concretely, the surface is pushed up and down at\npoints sampled from two different distributions. The averaged up and down\nforces become functions of these two distribution densities and of force\nmagnitudes defined by the loss of a particular PSO instance. Upon convergence,\nthe force equilibrium imposes an optimized model to be equal to various\nstatistical functions depending on the used magnitude functions. Furthermore,\nthis dynamical-statistical equilibrium is extremely intuitive and useful,\nproviding many implications and possible usages in probabilistic inference. We\nconnect PSO to numerous existing statistical works which are also PSO\ninstances, and derive new PSO-based inference methods as demonstration of PSO\nexceptional usability. Likewise, based on the insights coming from the\nvirtual-force perspective we analyze PSO stability and propose new ways to\nimprove it. Finally, we present new instances of PSO, termed PSO-LDE, for data\nlog-density estimation and also provide a new NN block-diagonal architecture\nfor increased surface flexibility, which significantly improves estimation\naccuracy. Both PSO-LDE and the new architecture are combined together as a new\ndensity estimation technique. In our experiments we demonstrate this technique\nto be superior over state-of-the-art baselines in density estimation task for\nmultimodal 20D data.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 19:43:50 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 20:47:16 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 15:44:04 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 17:12:59 GMT"}, {"version": "v5", "created": "Fri, 31 Jul 2020 12:48:31 GMT"}, {"version": "v6", "created": "Thu, 20 Aug 2020 11:55:14 GMT"}, {"version": "v7", "created": "Fri, 25 Sep 2020 15:16:48 GMT"}, {"version": "v8", "created": "Wed, 13 Jan 2021 11:30:01 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Kopitkov", "Dmitry", ""], ["Indelman", "Vadim", ""]]}, {"id": "1903.10572", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Chin-Teng Lin and Jian Huang and Zhigang Zeng", "title": "On the Functional Equivalence of TSK Fuzzy Systems to Neural Networks,\n  Mixture of Experts, CART, and Stacking Ensemble Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy systems have achieved great success in numerous applications. However,\nthere are still many challenges in designing an optimal fuzzy system, e.g., how\nto efficiently optimize its parameters, how to balance the trade-off between\ncooperations and competitions among the rules, how to overcome the curse of\ndimensionality, how to increase its generalization ability, etc. Literature has\nshown that by making appropriate connections between fuzzy systems and other\nmachine learning approaches, good practices from other domains may be used to\nimprove the fuzzy systems, and vice versa. This paper gives an overview on the\nfunctional equivalence between Takagi-Sugeno-Kang fuzzy systems and four\nclassic machine learning approaches -- neural networks, mixture of experts,\nclassification and regression trees, and stacking ensemble regression -- for\nregression problems. We also point out some promising new research directions,\ninspired by the functional equivalence, that could lead to solutions to the\naforementioned problems. To our knowledge, this is so far the most\ncomprehensive overview on the connections between fuzzy systems and other\npopular machine learning approaches, and hopefully will stimulate more\nhybridization between different machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 19:52:17 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 17:18:14 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Wu", "Dongrui", ""], ["Lin", "Chin-Teng", ""], ["Huang", "Jian", ""], ["Zeng", "Zhigang", ""]]}, {"id": "1903.10578", "submitter": "David Hachuel", "authors": "David Hachuel, Akshay Jha, Deborah Estrin, Alfonso Martinez, Kyle\n  Staller, Christopher Velez", "title": "Augmenting Gastrointestinal Health: A Deep Learning Approach to Human\n  Stool Recognition and Characterization in Macroscopic Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose - Functional bowel diseases, including irritable bowel syndrome,\nchronic constipation, and chronic diarrhea, are some of the most common\ndiseases seen in clinical practice. Many patients describe a range of triggers\nfor altered bowel consistency and symptoms. However, characterization of the\nrelationship between symptom triggers using bowel diaries is hampered by poor\ncompliance and lack of objective stool consistency measurements. We sought to\ndevelop a stool detection and tracking system using computer vision and deep\nconvolutional neural networks (CNN) that could be used by patients, providers,\nand researchers in the assessment of chronic gastrointestinal (GI) disease.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 20:08:17 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Hachuel", "David", ""], ["Jha", "Akshay", ""], ["Estrin", "Deborah", ""], ["Martinez", "Alfonso", ""], ["Staller", "Kyle", ""], ["Velez", "Christopher", ""]]}, {"id": "1903.10584", "submitter": "Zachariah Carmichael", "authors": "Zachariah Carmichael, Hamed F.Langroudi, Char Khazanov, Jeffrey\n  Lillie, John L. Gustafson, Dhireesha Kudithipudi", "title": "Performance-Efficiency Trade-off of Low-Precision Numerical Formats in\n  Deep Neural Networks", "comments": "9 pages, Proceedings of the ACM Conference for Next Generation\n  Arithmetic (CoNGA) 2019", "journal-ref": null, "doi": "10.1145/3316279.3316282", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been demonstrated as effective prognostic\nmodels across various domains, e.g. natural language processing, computer\nvision, and genomics. However, modern-day DNNs demand high compute and memory\nstorage for executing any reasonably complex task. To optimize the inference\ntime and alleviate the power consumption of these networks, DNN accelerators\nwith low-precision representations of data and DNN parameters are being\nactively studied. An interesting research question is in how low-precision\nnetworks can be ported to edge-devices with similar performance as\nhigh-precision networks. In this work, we employ the fixed-point, floating\npoint, and posit numerical formats at $\\leq$8-bit precision within a DNN\naccelerator, Deep Positron, with exact multiply-and-accumulate (EMAC) units for\ninference. A unified analysis quantifies the trade-offs between overall network\nefficiency and performance across five classification tasks. Our results\nindicate that posits are a natural fit for DNN inference, outperforming at\n$\\leq$8-bit precision, and can be realized with competitive resource\nrequirements relative to those of floating point.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 20:21:45 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Carmichael", "Zachariah", ""], ["Langroudi", "Hamed F.", ""], ["Khazanov", "Char", ""], ["Lillie", "Jeffrey", ""], ["Gustafson", "John L.", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1903.10586", "submitter": "Yuchen Zhang", "authors": "Yuchen Zhang, Percy Liang", "title": "Defending against Whitebox Adversarial Attacks via Randomized\n  Discretization", "comments": "In proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial perturbations dramatically decrease the accuracy of\nstate-of-the-art image classifiers. In this paper, we propose and analyze a\nsimple and computationally efficient defense strategy: inject random Gaussian\nnoise, discretize each pixel, and then feed the result into any pre-trained\nclassifier. Theoretically, we show that our randomized discretization strategy\nreduces the KL divergence between original and adversarial inputs, leading to a\nlower bound on the classification accuracy of any classifier against any\n(potentially whitebox) $\\ell_\\infty$-bounded adversarial attack. Empirically,\nwe evaluate our defense on adversarial examples generated by a strong iterative\nPGD attack. On ImageNet, our defense is more robust than adversarially-trained\nnetworks and the winning defenses of the NIPS 2017 Adversarial Attacks &\nDefenses competition.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 20:24:47 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Zhang", "Yuchen", ""], ["Liang", "Percy", ""]]}, {"id": "1903.10588", "submitter": "Zonglin Yang", "authors": "Zonglin Yang, Xinggang Wang", "title": "Reducing the dilution: An analysis of the information sensitiveness of\n  capsule network with a practical improvement method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule network has shown various advantages over convolutional neural\nnetwork (CNN). It keeps more precise spatial information than CNN and uses\nequivariance instead of invariance during inference and highly potential to be\na new effective tool for visual tasks. However, the current capsule networks\nhave incompatible performance with CNN when facing datasets with background and\ncomplex target objects and are lacking in universal and efficient\nregularization method.\n  We analyze a main reason of the incompatible performance as the conflict\nbetween information sensitiveness of capsule network and unreasonably higher\nactivation value distribution of capsules in primary capsule layer.\nCorrespondingly, we propose a practical improvement method by restraining the\nactivation value of capsules in primary capsule layer to suppress\nnon-informative capsules and highlight discriminative capsules. In the\nexperiments, the method has achieved better performances on various mainstream\ndatasets. In addition, the proposed improvement methods can be seen as a\nsuitable, simple and efficient regularization method that can be generally used\nin capsule network.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 20:28:44 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 13:54:26 GMT"}, {"version": "v3", "created": "Thu, 2 May 2019 21:42:46 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Yang", "Zonglin", ""], ["Wang", "Xinggang", ""]]}, {"id": "1903.10598", "submitter": "Sina Aghaei", "authors": "Sina Aghaei, Mohammad Javad Azizi, Phebe Vayanos", "title": "Learning Optimal and Fair Decision Trees for Non-Discriminative\n  Decision-Making", "comments": "33rd AAAI Conference on Artificial Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, automated data-driven decision-making systems have enjoyed a\ntremendous success in a variety of fields (e.g., to make product\nrecommendations, or to guide the production of entertainment). More recently,\nthese algorithms are increasingly being used to assist socially sensitive\ndecision-making (e.g., to decide who to admit into a degree program or to\nprioritize individuals for public housing). Yet, these automated tools may\nresult in discriminative decision-making in the sense that they may treat\nindividuals unfairly or unequally based on membership to a category or a\nminority, resulting in disparate treatment or disparate impact and violating\nboth moral and ethical standards. This may happen when the training dataset is\nitself biased (e.g., if individuals belonging to a particular group have\nhistorically been discriminated upon). However, it may also happen when the\ntraining dataset is unbiased, if the errors made by the system affect\nindividuals belonging to a category or minority differently (e.g., if\nmisclassification rates for Blacks are higher than for Whites). In this paper,\nwe unify the definitions of unfairness across classification and regression. We\npropose a versatile mixed-integer optimization framework for learning optimal\nand fair decision trees and variants thereof to prevent disparate treatment\nand/or disparate impact as appropriate. This translates to a flexible schema\nfor designing fair and interpretable policies suitable for socially sensitive\ndecision-making. We conduct extensive computational studies that show that our\nframework improves the state-of-the-art in the field (which typically relies on\nheuristics) to yield non-discriminative decisions at lower cost to overall\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 21:16:39 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Aghaei", "Sina", ""], ["Azizi", "Mohammad Javad", ""], ["Vayanos", "Phebe", ""]]}, {"id": "1903.10601", "submitter": "Qian Wang", "authors": "Qian Wang, Penghui Bu, Toby P. Breckon", "title": "Unifying Unsupervised Domain Adaptation and Zero-Shot Visual Recognition", "comments": "International Joint Conference on Neural Networks 2019, Budapest", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation aims to transfer knowledge from a source\ndomain to a target domain so that the target domain data can be recognized\nwithout any explicit labelling information for this domain. One limitation of\nthe problem setting is that testing data, despite having no labels, from the\ntarget domain is needed during training, which prevents the trained model being\ndirectly applied to classify unseen test instances. We formulate a new\ncross-domain classification problem arising from real-world scenarios where\nlabelled data is available for a subset of classes (known classes) in the\ntarget domain, and we expect to recognize new samples belonging to any class\n(known and unseen classes) once the model is learned. This is a generalized\nzero-shot learning problem where the side information comes from the source\ndomain in the form of labelled samples instead of class-level semantic\nrepresentations commonly used in traditional zero-shot learning. We present a\nunified domain adaptation framework for both unsupervised and zero-shot\nlearning conditions. Our approach learns a joint subspace from source and\ntarget domains so that the projections of both data in the subspace can be\ndomain invariant and easily separable. We use the supervised locality\npreserving projection (SLPP) as the enabling technique and conduct experiments\nunder both unsupervised and zero-shot learning conditions, achieving\nstate-of-the-art results on three domain adaptation benchmark datasets:\nOffice-Caltech, Office31 and Office-Home.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 21:34:39 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 11:56:24 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wang", "Qian", ""], ["Bu", "Penghui", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1903.10614", "submitter": "Tao Chen", "authors": "Tao Chen", "title": "On Using Retrained and Incremental Machine Learning for Modeling\n  Performance of Adaptable Software: An Empirical Comparison", "comments": "preprint of the accepted paper for the 14th International Symposium\n  on Software Engineering for Adaptive and Self-Managing Systems (SEAMS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the ever-increasing complexity of adaptable software systems and their\ncommonly hidden internal information (e.g., software runs in the public cloud),\nmachine learning based performance modeling has gained momentum for evaluating,\nunderstanding and predicting software performance, which facilitates better\ninformed self-adaptations. As performance data accumulates during the run of\nthe software, updating the performance models becomes necessary. To this end,\nthere are two conventional modeling methods: the retrained modeling that always\ndiscard the old model and retrain a new one using all available data; or the\nincremental modeling that retains the existing model and tunes it using one\nnewly arrival data sample. Generally, literature on machine learning based\nperformance modeling for adaptable software chooses either of those methods\naccording to a general belief, but they provide insufficient evidences or\nreferences to justify their choice. This paper is the first to report on a\ncomprehensive empirical study that examines both modeling methods under\ndistinct domains of adaptable software, 5 performance indicators, 8 learning\nalgorithms and settings, covering a total of 1,360 different conditions. Our\nfindings challenge the general belief, which is shown to be only partially\ncorrect, and reveal some of the important, statistically significant factors\nthat are often overlooked in existing work, providing evidence-based insights\non the choice.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 22:10:32 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Chen", "Tao", ""]]}, {"id": "1903.10630", "submitter": "Budhaditya Deb", "authors": "Budhaditya Deb and Peter Bailey and Milad Shokouhi", "title": "Diversifying Reply Suggestions using a Matching-Conditional Variational\n  Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of diversifying automated reply suggestions for a\ncommercial instant-messaging (IM) system (Skype). Our conversation model is a\nstandard matching based information retrieval architecture, which consists of\ntwo parallel encoders to project messages and replies into a common feature\nrepresentation. During inference, we select replies from a fixed response set\nusing nearest neighbors in the feature space. To diversify responses, we\nformulate the model as a generative latent variable model with Conditional\nVariational Auto-Encoder (M-CVAE). We propose a constrained-sampling approach\nto make the variational inference in M-CVAE efficient for our production\nsystem. In offline experiments, M-CVAE consistently increased diversity by\n~30-40% without significant impact on relevance. This translated to a 5% gain\nin click-rate in our online production system.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 23:12:56 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Deb", "Budhaditya", ""], ["Bailey", "Peter", ""], ["Shokouhi", "Milad", ""]]}, {"id": "1903.10646", "submitter": "Yuan Gao", "authors": "Yuan Gao and Christian Kroer and Donald Goldfarb", "title": "Increasing Iterate Averaging for Solving Saddle-Point Problems", "comments": "Preprint. Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in machine learning and game theory can be formulated as\nsaddle-point problems, for which various first-order methods have been\ndeveloped and proven efficient in practice. Under the general convex-concave\nassumption, most first-order methods only guarantee an ergodic convergence\nrate, that is, the uniform averages of the iterates converge at a $O(1/T)$ rate\nin terms of the saddle-point residual. However, numerically, the iterates\nthemselves can often converge much faster than the uniform averages. This\nobservation motivates increasing averaging schemes that put more weight on\nlater iterates, in contrast to the usual uniform averaging. We show that such\nincreasing averaging schemes, applied to various first-order methods, are able\nto preserve the $O(1/T)$ convergence rate with no additional assumptions or\ncomputational overhead. Extensive numerical experiments on zero-sum game\nsolving, market equilibrium computation and image denoising demonstrate the\neffectiveness of the proposed schemes. In particular, the increasing averages\nconsistently outperform the uniform averages in all test problems by orders of\nmagnitude. When solving matrix and extensive-form games, increasing averages\nconsistently outperform the last iterates as well. For matrix games, a\nfirst-order method equipped with increasing averaging outperforms the highly\ncompetitive CFR$^+$ algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 01:00:53 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 02:04:31 GMT"}, {"version": "v3", "created": "Sat, 13 Jun 2020 18:59:52 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Gao", "Yuan", ""], ["Kroer", "Christian", ""], ["Goldfarb", "Donald", ""]]}, {"id": "1903.10654", "submitter": "Akifumi Wachi", "authors": "Akifumi Wachi", "title": "Failure-Scenario Maker for Rule-Based Agent using Multi-agent\n  Adversarial Reinforcement Learning and its Application to Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of adversarial reinforcement learning for multi-agent\ndomains including a rule-based agent. Rule-based algorithms are required in\nsafety-critical applications for them to work properly in a wide range of\nsituations. Hence, every effort is made to find failure scenarios during the\ndevelopment phase. However, as the software becomes complicated, finding\nfailure cases becomes difficult. Especially in multi-agent domains, such as\nautonomous driving environments, it is much harder to find useful failure\nscenarios that help us improve the algorithm. We propose a method for\nefficiently finding failure scenarios; this method trains the adversarial\nagents using multi-agent reinforcement learning such that the tested rule-based\nagent fails. We demonstrate the effectiveness of our proposed method using a\nsimple environment and autonomous driving simulator.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 02:15:59 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 06:39:52 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 01:00:19 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Wachi", "Akifumi", ""]]}, {"id": "1903.10663", "submitter": "ByungSoo Ko", "authors": "HeeJae Jun, Byungsoo Ko, Youngjoon Kim, Insik Kim, Jongtack Kim", "title": "Combination of Multiple Global Descriptors for Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies in image retrieval task have shown that ensembling different\nmodels and combining multiple global descriptors lead to performance\nimprovement. However, training different models for the ensemble is not only\ndifficult but also inefficient with respect to time and memory. In this paper,\nwe propose a novel framework that exploits multiple global descriptors to get\nan ensemble effect while it can be trained in an end-to-end manner. The\nproposed framework is flexible and expandable by the global descriptor, CNN\nbackbone, loss, and dataset. Moreover, we investigate the effectiveness of\ncombining multiple global descriptors with quantitative and qualitative\nanalysis. Our extensive experiments show that the combined descriptor\noutperforms a single global descriptor, as it can utilize different types of\nfeature properties. In the benchmark evaluation, the proposed framework\nachieves the state-of-the-art performance on the CARS196, CUB200-2011, In-shop\nClothes, and Stanford Online Products on image retrieval tasks. Our model\nimplementations and pretrained models are publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 03:38:38 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 05:33:04 GMT"}, {"version": "v3", "created": "Sat, 27 Jul 2019 05:28:41 GMT"}, {"version": "v4", "created": "Thu, 23 Apr 2020 06:20:02 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Jun", "HeeJae", ""], ["Ko", "Byungsoo", ""], ["Kim", "Youngjoon", ""], ["Kim", "Insik", ""], ["Kim", "Jongtack", ""]]}, {"id": "1903.10672", "submitter": "Md. Ariful Islam", "authors": "Abhishek Murthy, Himel Das, Md Ariful Islam", "title": "Robustness of Neural Networks to Parameter Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization, a commonly used technique to reduce the memory footprint of a\nneural network for edge computing, entails reducing the precision of the\nfloating-point representation used for the parameters of the network. The\nimpact of such rounding-off errors on the overall performance of the neural\nnetwork is estimated using testing, which is not exhaustive and thus cannot be\nused to guarantee the safety of the model. We present a framework based on\nSatisfiability Modulo Theory (SMT) solvers to quantify the robustness of neural\nnetworks to parameter perturbation. To this end, we introduce notions of local\nand global robustness that capture the deviation in the confidence of class\nassignments due to parameter quantization. The robustness notions are then cast\nas instances of SMT problems and solved automatically using solvers, such as\ndReal. We demonstrate our framework on two simple Multi-Layer Perceptrons (MLP)\nthat perform binary classification on a two-dimensional input. In addition to\nquantifying the robustness, we also show that Rectified Linear Unit activation\nresults in higher robustness than linear activations for our MLPs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 04:37:54 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Murthy", "Abhishek", ""], ["Das", "Himel", ""], ["Islam", "Md Ariful", ""]]}, {"id": "1903.10679", "submitter": "Yishen Wang", "authors": "Yayu Peng, Yishen Wang, Xiao Lu, Haifeng Li, Di Shi, Zhiwei Wang, Jie\n  Li", "title": "Short-term Load Forecasting at Different Aggregation Levels with\n  Predictability Analysis", "comments": "To appear in ISGT ASIA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term load forecasting (STLF) is essential for the reliable and economic\noperation of power systems. Though many STLF methods were proposed over the\npast decades, most of them focused on loads at high aggregation levels only.\nThus, low-aggregation load forecast still requires further research and\ndevelopment. Compared with the substation or city level loads, individual loads\nare typically more volatile and much more challenging to forecast. To further\naddress this issue, this paper first discusses the characteristics of\nsmall-and-medium enterprise (SME) and residential loads at different\naggregation levels and quantifies their predictability with approximate\nentropy. Various STLF techniques, from the conventional linear regression to\nstate-of-the-art deep learning, are implemented for a detailed comparative\nanalysis to verify the forecasting performances as well as the predictability\nusing an Irish smart meter dataset. In addition, the paper also investigates\nhow using data processing improves individual-level residential load\nforecasting with low predictability. Effectiveness of the discussed method is\nvalidated with numerical results.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 05:16:14 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Peng", "Yayu", ""], ["Wang", "Yishen", ""], ["Lu", "Xiao", ""], ["Li", "Haifeng", ""], ["Shi", "Di", ""], ["Wang", "Zhiwei", ""], ["Li", "Jie", ""]]}, {"id": "1903.10684", "submitter": "Yishen Wang", "authors": "Qicheng Chang, Yishen Wang, Xiao Lu, Di Shi, Haifeng Li, Jiajun Duan,\n  Zhiwei Wang", "title": "Probabilistic Load Forecasting via Point Forecast Feature Integration", "comments": "To appear in ISGT ASIA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term load forecasting is a critical element of power systems energy\nmanagement systems. In recent years, probabilistic load forecasting (PLF) has\ngained increased attention for its ability to provide uncertainty information\nthat helps to improve the reliability and economics of system operation\nperformances. This paper proposes a two-stage probabilistic load forecasting\nframework by integrating point forecast as a key probabilistic forecasting\nfeature into PLF. In the first stage, all related features are utilized to\ntrain a point forecast model and also obtain the feature importance. In the\nsecond stage the forecasting model is trained, taking into consideration point\nforecast features, as well as selected feature subsets. During the testing\nperiod of the forecast model, the final probabilistic load forecast results are\nleveraged to obtain both point forecasting and probabilistic forecasting.\nNumerical results obtained from ISO New England demand data demonstrate the\neffectiveness of the proposed approach in the hour-ahead load forecasting,\nwhich uses the gradient boosting regression for the point forecasting and\nquantile regression neural networks for the probabilistic forecasting.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 05:35:46 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Chang", "Qicheng", ""], ["Wang", "Yishen", ""], ["Lu", "Xiao", ""], ["Shi", "Di", ""], ["Li", "Haifeng", ""], ["Duan", "Jiajun", ""], ["Wang", "Zhiwei", ""]]}, {"id": "1903.10699", "submitter": "Mostafa Haghir Chehreghani", "authors": "Mostafa Haghir Chehreghani", "title": "Regression and Singular Value Decomposition in Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of real-world graphs are {\\em dynamic}, i.e., they change over time.\nHowever, while problems such as regression and Singular Value Decomposition\n(SVD) have been studied for {\\em static} graphs, they have not been\ninvestigated for {\\em dynamic} graphs, yet. In this paper, we introduce,\nmotivate and study regression and SVD over dynamic graphs. First, we present\nthe notion of {\\em update-efficient matrix embedding} that defines the\nconditions sufficient for a matrix embedding to be used for the dynamic graph\nregression problem (under $l_2$ norm). We prove that given an $n \\times m$\nupdate-efficient matrix embedding (e.g., adjacency matrix), after an update\noperation in the graph, the optimal solution of the graph regression problem\nfor the revised graph can be computed in $O(nm)$ time. We also study dynamic\ngraph regression under least absolute deviation. Then, we characterize a class\nof matrix embeddings that can be used to efficiently update SVD of a dynamic\ngraph. For adjacency matrix and Laplacian matrix, we study those graph update\noperations for which SVD (and low rank approximation) can be updated\nefficiently.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 06:17:49 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 08:11:23 GMT"}, {"version": "v3", "created": "Sat, 4 Jan 2020 07:47:02 GMT"}, {"version": "v4", "created": "Thu, 9 Apr 2020 20:25:15 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Chehreghani", "Mostafa Haghir", ""]]}, {"id": "1903.10703", "submitter": "Lonce Wyse", "authors": "Lonce Wyse, Muhammad Huzaifah", "title": "Conditioning a Recurrent Neural Network to synthesize musical instrument\n  transients", "comments": "Sound and Music Computing Conference. Malaga, Spain, May 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A recurrent Neural Network (RNN) is trained to predict sound samples based on\naudio input augmented by control parameter information for pitch, volume, and\ninstrument identification. During the generative phase following training,\naudio input is taken from the output of the previous time step, and the\nparameters are externally controlled allowing the network to be played as a\nmusical instrument. Building on an architecture developed in previous work, we\nfocus on the learning and synthesis of transients - the temporal response of\nthe network during the short time (tens of milliseconds) following the onset\nand offset of a control signal. We find that the network learns the particular\ntransient characteristics of two different synthetic instruments, and\nfurthermore shows some ability to interpolate between the characteristics of\nthe instruments used in training in response to novel parameter settings. We\nalso study the behaviour of the units in hidden layers of the RNN using various\nvisualisation techniques and find a variety of volume-specific response\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 06:33:35 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Wyse", "Lonce", ""], ["Huzaifah", "Muhammad", ""]]}, {"id": "1903.10709", "submitter": "Yuuki Yamanaka", "authors": "Yuki Yamanaka, Tomoharu Iwata, Hiroshi Takahashi, Masanori Yamada,\n  Sekitoshi Kanai", "title": "Autoencoding Binary Classifiers for Supervised Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Autoencoding Binary Classifiers (ABC), a novel supervised\nanomaly detector based on the Autoencoder (AE). There are two main approaches\nin anomaly detection: supervised and unsupervised. The supervised approach\naccurately detects the known anomalies included in training data, but it cannot\ndetect the unknown anomalies. Meanwhile, the unsupervised approach can detect\nboth known and unknown anomalies that are located away from normal data points.\nHowever, it does not detect known anomalies as accurately as the supervised\napproach. Furthermore, even if we have labeled normal data points and\nanomalies, the unsupervised approach cannot utilize these labels. The ABC is a\nprobabilistic binary classifier that effectively exploits the label\ninformation, where normal data points are modeled using the AE as a component.\nBy maximizing the likelihood, the AE in the proposed ABC is trained to minimize\nthe reconstruction error for normal data points, and to maximize it for known\nanomalies. Since our approach becomes able to reconstruct the normal data\npoints accurately and fails to reconstruct the known and unknown anomalies, it\ncan accurately discriminate both known and unknown anomalies from normal data\npoints. Experimental results show that the ABC achieves higher detection\nperformance than existing supervised and unsupervised methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 07:12:36 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Yamanaka", "Yuki", ""], ["Iwata", "Tomoharu", ""], ["Takahashi", "Hiroshi", ""], ["Yamada", "Masanori", ""], ["Kanai", "Sekitoshi", ""]]}, {"id": "1903.10713", "submitter": "Anshul Thakur", "authors": "Anshul Thakur, Daksh Thapar, Padmanabhan Rajan, Aditya Nigam", "title": "Multiscale CNN based Deep Metric Learning for Bioacoustic\n  Classification: Overcoming Training Data Scarcity Using Dynamic Triplet Loss", "comments": "Under Review at JASA. Primitive version of paper. We are still\n  working on getting better performances out of the comparative methods", "journal-ref": null, "doi": "10.1121/1.5118245", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes multiscale convolutional neural network (CNN)-based deep\nmetric learning for bioacoustic classification, under low training data\nconditions. The proposed CNN is characterized by the utilization of four\ndifferent filter sizes at each level to analyze input feature maps. This\nmultiscale nature helps in describing different bioacoustic events effectively:\nsmaller filters help in learning the finer details of bioacoustic events,\nwhereas, larger filters help in analyzing a larger context leading to global\ndetails. A dynamic triplet loss is employed in the proposed CNN architecture to\nlearn a transformation from the input space to the embedding space, where\nclassification is performed. The triplet loss helps in learning this\ntransformation by analyzing three examples, referred to as triplets, at a time\nwhere intra-class distance is minimized while maximizing the inter-class\nseparation by a dynamically increasing margin. The number of possible triplets\nincreases cubically with the dataset size, making triplet loss more suitable\nthan the softmax cross-entropy loss in low training data conditions.\nExperiments on three different publicly available datasets show that the\nproposed framework performs better than existing bioacoustic classification\nframeworks. Experimental results also confirm the superiority of the triplet\nloss over the cross-entropy loss in low training data conditions\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 07:16:38 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 05:48:22 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Thakur", "Anshul", ""], ["Thapar", "Daksh", ""], ["Rajan", "Padmanabhan", ""], ["Nigam", "Aditya", ""]]}, {"id": "1903.10726", "submitter": "Sourav Mishra", "authors": "Sourav Mishra, Toshihiko Yamasaki and Hideaki Imaizumi", "title": "Improving image classifiers for small datasets by learning rate\n  adaptations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our paper introduces an efficient combination of established techniques to\nimprove classifier performance, in terms of accuracy and training time. We\nachieve two-fold to ten-fold speedup in nearing state of the art accuracy, over\ndifferent model architectures, by dynamically tuning the learning rate. We find\nit especially beneficial in the case of a small dataset, where reliability of\nmachine reasoning is lower. We validate our approach by comparing our method\nversus vanilla training on CIFAR-10. We also demonstrate its practical\nviability by implementing on an unbalanced corpus of diagnostic images.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 08:22:01 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 17:15:30 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Mishra", "Sourav", ""], ["Yamasaki", "Toshihiko", ""], ["Imaizumi", "Hideaki", ""]]}, {"id": "1903.10735", "submitter": "Jacob Nilsson", "authors": "Jacob Nilsson and Fredrik Sandin and Jerker Delsing", "title": "Interoperability and machine-to-machine translation model with mappings\n  to machine learning tasks", "comments": "7 pages, 2 figures, 1 table, 1 listing. Submitted to the IEEE\n  International Conference on Industrial Informatics 2019, INDIN'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern large-scale automation systems integrate thousands to hundreds of\nthousands of physical sensors and actuators. Demands for more flexible\nreconfiguration of production systems and optimization across different\ninformation models, standards and legacy systems challenge current system\ninteroperability concepts. Automatic semantic translation across information\nmodels and standards is an increasingly important problem that needs to be\naddressed to fulfill these demands in a cost-efficient manner under constraints\nof human capacity and resources in relation to timing requirements and system\ncomplexity. Here we define a translator-based operational interoperability\nmodel for interacting cyber-physical systems in mathematical terms, which\nincludes system identification and ontology-based translation as special cases.\nWe present alternative mathematical definitions of the translator learning task\nand mappings to similar machine learning tasks and solutions based on recent\ndevelopments in machine learning. Possibilities to learn translators between\nartefacts without a common physical context, for example in simulations of\ndigital twins and across layers of the automation pyramid are briefly\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 08:43:38 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Nilsson", "Jacob", ""], ["Sandin", "Fredrik", ""], ["Delsing", "Jerker", ""]]}, {"id": "1903.10742", "submitter": "Zhengzhi Sun", "authors": "Zheng-Zhi Sun, Cheng Peng, Ding Liu, Shi-Ju Ran, and Gang Su", "title": "Generative Tensor Network Classification Model for Supervised Machine\n  Learning", "comments": "7 pages, 5 figures", "journal-ref": "Phys. Rev. B 101, 075135 (2020)", "doi": "10.1103/PhysRevB.101.075135", "report-no": null, "categories": "cs.LG cond-mat.str-el quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor network (TN) has recently triggered extensive interests in developing\nmachine-learning models in quantum many-body Hilbert space. Here we purpose a\ngenerative TN classification (GTNC) approach for supervised learning. The\nstrategy is to train the generative TN for each class of the samples to\nconstruct the classifiers. The classification is implemented by comparing the\ndistance in the many-body Hilbert space. The numerical experiments by GTNC show\nimpressive performance on the MNIST and Fashion-MNIST dataset. The testing\naccuracy is competitive to the state-of-the-art convolutional neural network\nwhile higher than the naive Bayes classifier (a generative classifier) and\nsupport vector machine. Moreover, GTNC is more efficient than the existing TN\nmodels that are in general discriminative. By investigating the distances in\nthe many-body Hilbert space, we find that (a) the samples are naturally\nclustering in such a space; and (b) bounding the bond dimensions of the TN's to\nfinite values corresponds to removing redundant information in the image\nrecognition. These two characters make GTNC an adaptive and universal model of\nexcellent performance.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 09:07:36 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Sun", "Zheng-Zhi", ""], ["Peng", "Cheng", ""], ["Liu", "Ding", ""], ["Ran", "Shi-Ju", ""], ["Su", "Gang", ""]]}, {"id": "1903.10794", "submitter": "Cheng Wang", "authors": "Cheng Wang, Mathias Niepert, Hui Li", "title": "RecSys-DAN: Discriminative Adversarial Networks for Cross-Domain\n  Recommender Systems", "comments": "10 pages, IEEE-TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sparsity and data imbalance are practical and challenging issues in\ncross-domain recommender systems. This paper addresses those problems by\nleveraging the concepts which derive from representation learning, adversarial\nlearning and transfer learning (particularly, domain adaptation). Although\nvarious transfer learning methods have shown promising performance in this\ncontext, our proposed novel method RecSys-DAN focuses on alleviating the\ncross-domain and within-domain data sparsity and data imbalance and learns\ntransferable latent representations for users, items and their interactions.\nDifferent from existing approaches, the proposed method transfers the latent\nrepresentations from a source domain to a target domain in an adversarial way.\nThe mapping functions in the target domain are learned by playing a min-max\ngame with an adversarial loss, aiming to generate domain indistinguishable\nrepresentations for a discriminator. Four neural architectural instances of\nResSys-DAN are proposed and explored. Empirical results on real-world Amazon\ndata show that, even without using labeled data (i.e., ratings) in the target\ndomain, RecSys-DAN achieves competitive performance as compared to the\nstate-of-the-art supervised methods. More importantly, RecSys-DAN is highly\nflexible to both unimodal and multimodal scenarios, and thus it is more robust\nto the cold-start recommendation which is difficult for previous methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 11:07:00 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 13:14:21 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Wang", "Cheng", ""], ["Niepert", "Mathias", ""], ["Li", "Hui", ""]]}, {"id": "1903.10826", "submitter": "Yujia Liu", "authors": "Yujia Liu, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard", "title": "A geometry-inspired decision-based attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have recently achieved tremendous success in image\nclassification. Recent studies have however shown that they are easily misled\ninto incorrect classification decisions by adversarial examples. Adversaries\ncan even craft attacks by querying the model in black-box settings, where no\ninformation about the model is released except its final decision. Such\ndecision-based attacks usually require lots of queries, while real-world image\nrecognition systems might actually restrict the number of queries. In this\npaper, we propose qFool, a novel decision-based attack algorithm that can\ngenerate adversarial examples using a small number of queries. The qFool method\ncan drastically reduce the number of queries compared to previous\ndecision-based attacks while reaching the same quality of adversarial examples.\nWe also enhance our method by constraining adversarial perturbations in\nlow-frequency subspace, which can make qFool even more computationally\nefficient. Altogether, we manage to fool commercial image recognition systems\nwith a small number of queries, which demonstrates the actual effectiveness of\nour new algorithm in practice.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 12:18:31 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Liu", "Yujia", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Frossard", "Pascal", ""]]}, {"id": "1903.10839", "submitter": "Hendrik Schreiber", "authors": "Hendrik Schreiber, Meinard M\\\"uller", "title": "Musical Tempo and Key Estimation using Convolutional Neural Networks\n  with Directional Filters", "comments": "Sound & Music Computing Conference (SMC), M\\'alaga, Spain, May 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article we explore how the different semantics of spectrograms' time\nand frequency axes can be exploited for musical tempo and key estimation using\nConvolutional Neural Networks (CNN). By addressing both tasks with the same\nnetwork architectures ranging from shallow, domain-specific approaches to deep\nvariants with directional filters, we show that axis-aligned architectures\nperform similarly well as common VGG-style networks developed for computer\nvision, while being less vulnerable to confounding factors and requiring fewer\nmodel parameters.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 12:43:09 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Schreiber", "Hendrik", ""], ["M\u00fcller", "Meinard", ""]]}, {"id": "1903.10841", "submitter": "Felix Fritzen", "authors": "Julian Li{\\ss}ner and Felix Fritzen", "title": "Data-Driven Microstructure Property Relations", "comments": "23 pages, 2 tables, 11 figures - EDIT 2019/04/01: recompiled in the\n  proper (A4) page format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An image based prediction of the effective heat conductivity for highly\nheterogeneous microstructured materials is presented. The synthetic materials\nunder consideration show different inclusion morphology, orientation, volume\nfraction and topology. The prediction of the effective property is made\nexclusively based on image data with the main emphasis being put on the 2-point\nspatial correlation function. This task is implemented using both unsupervised\nand supervised machine learning methods. First, a snapshot proper orthogonal\ndecomposition (POD) is used to analyze big sets of random microstructures and\nthereafter compress significant characteristics of the microstructure into a\nlow-dimensional feature vector. In order to manage the related amount of data\nand computations, three different incremental snapshot POD methods are\nproposed. In the second step, the obtained feature vector is used to predict\nthe effective material property by using feed forward neural networks.\nNumerical examples regarding the incremental basis identification and the\nprediction accuracy of the approach are presented. A Python code illustrating\nthe application of the surrogate is freely available.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 12:49:31 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 07:23:32 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Li\u00dfner", "Julian", ""], ["Fritzen", "Felix", ""]]}, {"id": "1903.10842", "submitter": "Yuchi Zhang", "authors": "Yuchi Zhang, Yongliang Wang, Liping Zhang, Zhiqiang Zhang, Kun Gai", "title": "Improve Diverse Text Generation by Self Labeling Conditional Variational\n  Auto Encoder", "comments": "Accepted as a conference paper in ICASSP 2019. But this copy is an\n  extended version of the submitted manuscript. With more theoretical analysis\n  and human evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversity plays a vital role in many text generating applications. In recent\nyears, Conditional Variational Auto Encoders (CVAE) have shown promising\nperformances for this task. However, they often encounter the so called\nKL-Vanishing problem. Previous works mitigated such problem by heuristic\nmethods such as strengthening the encoder or weakening the decoder while\noptimizing the CVAE objective function. Nevertheless, the optimizing direction\nof these methods are implicit and it is hard to find an appropriate degree to\nwhich these methods should be applied. In this paper, we propose an explicit\noptimizing objective to complement the CVAE to directly pull away from\nKL-vanishing. In fact, this objective term guides the encoder towards the \"best\nencoder\" of the decoder to enhance the expressiveness. A labeling network is\nintroduced to estimate the \"best encoder\". It provides a continuous label in\nthe latent space of CVAE to help build a close connection between latent\nvariables and targets. The whole proposed method is named Self Labeling\nCVAE~(SLCVAE). To accelerate the research of diverse text generation, we also\npropose a large native one-to-many dataset. Extensive experiments are conducted\non two tasks, which show that our method largely improves the generating\ndiversity while achieving comparable accuracy compared with state-of-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 12:53:26 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Zhang", "Yuchi", ""], ["Wang", "Yongliang", ""], ["Zhang", "Liping", ""], ["Zhang", "Zhiqiang", ""], ["Gai", "Kun", ""]]}, {"id": "1903.10862", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Feifei Liu and Chengyu Liu", "title": "Active Stacking for Heart Rate Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart rate estimation from electrocardiogram signals is very important for\nthe early detection of cardiovascular diseases. However, due to large\nindividual differences and varying electrocardiogram signal quality, there does\nnot exist a single reliable estimation algorithm that works well on all\nsubjects. Every algorithm may break down on certain subjects, resulting in a\nsignificant estimation error. Ensemble regression, which aggregates the outputs\nof multiple base estimators for more reliable and stable estimates, can be used\nto remedy this problem. Moreover, active learning can be used to optimally\nselect a few trials from a new subject to label, based on which a stacking\nensemble regression model can be trained to aggregate the base estimators. This\npaper proposes four active stacking approaches, and demonstrates that they all\nsignificantly outperform three common unsupervised ensemble regression\napproaches, and a supervised stacking approach which randomly selects some\ntrials to label. Remarkably, our active stacking approaches only need three or\nfour labeled trials from each subject to achieve an average root mean squared\nestimation error below three beats per minute, making them very convenient for\nreal-world applications. To our knowledge, this is the first research on active\nstacking, and its application to heart rate estimation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 13:26:34 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Wu", "Dongrui", ""], ["Liu", "Feifei", ""], ["Liu", "Chengyu", ""]]}, {"id": "1903.10867", "submitter": "Thai Dang Tran", "authors": "Tran-Thai Dang, Tien-Lam Pham, Hiori Kino, Takashi Miyake, and\n  Hieu-Chi Dam", "title": "Measuring the Similarity between Materials with an Emphasis on the\n  Materials Distinctiveness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we establish a basis for selecting similarity measures when\napplying machine learning techniques to solve materials science problems. This\nselection is considered with an emphasis on the distinctiveness between\nmaterials that reflect their nature well. We perform a case study with a\ndataset of rare-earth transition metal crystalline compounds represented using\nthe Orbital Field Matrix descriptor and the Coulomb Matrix descriptor. We\nperform predictions of the formation energies using k-nearest neighbors\nregression, ridge regression, and kernel ridge regression. Through detailed\nanalyses of the yield prediction accuracy, we examine the relationship between\nthe characteristics of the material representation and similarity measures, and\nthe complexity of the energy function they can capture. Empirical experiments\nand theoretical analysis reveal that similarity measures and kernels that\nminimize the loss of materials distinctiveness improve the prediction\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 12:55:01 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Dang", "Tran-Thai", ""], ["Pham", "Tien-Lam", ""], ["Kino", "Hiori", ""], ["Miyake", "Takashi", ""], ["Dam", "Hieu-Chi", ""]]}, {"id": "1903.10870", "submitter": "Ankit Sharma", "authors": "Ankit Sharma, Late C. A. Murthy", "title": "Algorithms and Improved bounds for online learning under finite\n  hypothesis class", "comments": "17 pages, 2 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning is the process of answering a sequence of questions based on\nthe correct answers to the previous questions. It is studied in many research\nareas such as game theory, information theory and machine learning. There are\ntwo main components of online learning framework. First, the learning algorithm\nalso known as the learner and second, the hypothesis class which is essentially\na set of functions which learner uses to predict answers to the questions.\nSometimes, this class contains some functions which have the capability to\nprovide correct answers to the entire sequence of questions. This case is\ncalled realizable case. And when hypothesis class does not contain such\nfunctions is called unrealizable case. The goal of the learner, in both the\ncases, is to make as few mistakes as that could have been made by most powerful\nfunctions in hypothesis class over the entire sequence of questions.\nPerformance of the learners is analysed by theoretical bounds on the number of\nmistakes made by them. This paper proposes three algorithms to improve the\nmistakes bound in the unrealizable case. Proposed algorithms perform highly\nbetter than the existing ones in the long run when most of the input sequences\npresented to the learner are likely to be realizable.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 06:52:26 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Sharma", "Ankit", ""], ["Murthy", "Late C. A.", ""]]}, {"id": "1903.10899", "submitter": "Udo Schilcher", "authors": "Jorge F. Schmidt, Udo Schilcher, Mahin K. Atiq, and Christian\n  Bettstetter", "title": "Interference Prediction in Wireless Networks: Stochastic Geometry meets\n  Recursive Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes and evaluates a technique to predict the level of\ninterference in wireless networks. We design a recursive predictor that\nestimates future interference values by filtering measured interference at a\ngiven location. The predictor's parameterization is done offline by translating\nthe autocorrelation of interference into an autoregressive moving average\n(ARMA) representation. This ARMA model is inserted into a steady-state Kalman\nfilter enabling nodes to predict with low computational effort. Results show a\ngood accuracy of predicted values versus true values for relevant time\nhorizons. Although the predictor is parameterized for Poisson-distributed\nnodes, Rayleigh fading, and fixed message lengths, a sensitivity analysis shows\nthat it also tends to work well in more general network scenarios. Numerical\nexamples for underlay device-to-device communications, a common wireless sensor\ntechnology, and coexistence scenarios of Wi-Fi and LTE illustrate its broad\napplicability. The predictor can be applied as part of interference management\nto improve medium access, scheduling, and radio resource allocation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 14:08:51 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 11:02:43 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 10:19:50 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Schmidt", "Jorge F.", ""], ["Schilcher", "Udo", ""], ["Atiq", "Mahin K.", ""], ["Bettstetter", "Christian", ""]]}, {"id": "1903.10909", "submitter": "Kun Wang", "authors": "Kun Wang, Jun He, and Lei Zhang", "title": "Attention-based Convolutional Neural Network for Weakly Labeled Human\n  Activities Recognition with Wearable Sensors", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": "10.1109/JSEN.2019.2917225", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike images or videos data which can be easily labeled by human being,\nsensor data annotation is a time-consuming process. However, traditional\nmethods of human activity recognition require a large amount of such strictly\nlabeled data for training classifiers. In this paper, we present an\nattention-based convolutional neural network for human recognition from weakly\nlabeled data. The proposed attention model can focus on labeled activity among\na long sequence of sensor data, and while filter out a large amount of\nbackground noise signals. In experiment on the weakly labeled dataset, we show\nthat our attention model outperforms classical deep learning methods in\naccuracy. Besides, we determine the specific locations of the labeled activity\nin a long sequence of weakly labeled data by converting the compatibility score\nwhich is generated from attention model to compatibility density. Our method\ngreatly facilitates the process of sensor data annotation, and makes data\ncollection more easy.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 05:47:31 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 04:50:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Wang", "Kun", ""], ["He", "Jun", ""], ["Zhang", "Lei", ""]]}, {"id": "1903.10920", "submitter": "Amir Rosenfeld", "authors": "Amir Rosenfeld, Richard Zemel, John K. Tsotsos", "title": "High-Level Perceptual Similarity is Enabled by Learning Diverse Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting human perceptual similarity is a challenging subject of ongoing\nresearch. The visual process underlying this aspect of human vision is thought\nto employ multiple different levels of visual analysis (shapes, objects,\ntexture, layout, color, etc). In this paper, we postulate that the perception\nof image similarity is not an explicitly learned capability, but rather one\nthat is a byproduct of learning others. This claim is supported by leveraging\nrepresentations learned from a diverse set of visual tasks and using them\njointly to predict perceptual similarity. This is done via simple feature\nconcatenation, without any further learning. Nevertheless, experiments\nperformed on the challenging Totally-Looks-Like (TLL) benchmark significantly\nsurpass recent baselines, closing much of the reported gap towards prediction\nof human perceptual similarity. We provide an analysis of these results and\ndiscuss them in a broader context of emergent visual capabilities and their\nimplications on the course of machine-vision research.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 14:32:02 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Rosenfeld", "Amir", ""], ["Zemel", "Richard", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1903.10926", "submitter": "Nguyen Q. Tran", "authors": "Nguyen Tran, Henrik Ambos and Alexander Jung", "title": "Classifying Partially Labeled Networked Data via Logistic Network Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the network Lasso to classify partially labeled data points which\nare characterized by high-dimensional feature vectors. In order to learn an\naccurate classifier from limited amounts of labeled data, we borrow statistical\nstrength, via an intrinsic network structure, across the dataset. The resulting\nlogistic network Lasso amounts to a regularized empirical risk minimization\nproblem using the total variation of a classifier as a regularizer. This\nminimization problem is a non-smooth convex optimization problem which we solve\nusing a primal-dual splitting method. This method is appealing for big data\napplications as it can be implemented as a highly scalable message passing\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 14:37:16 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Tran", "Nguyen", ""], ["Ambos", "Henrik", ""], ["Jung", "Alexander", ""]]}, {"id": "1903.10951", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Ye Yuan and Yihua Tan", "title": "Optimize TSK Fuzzy Systems for Regression Problems: Mini-Batch Gradient\n  Descent with Regularization, DropRule and AdaBound (MBGD-RDA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Takagi-Sugeno-Kang (TSK) fuzzy systems are very useful machine learning\nmodels for regression problems. However, to our knowledge, there has not\nexisted an efficient and effective training algorithm that ensures their\ngeneralization performance, and also enables them to deal with big data.\nInspired by the connections between TSK fuzzy systems and neural networks, we\nextend three powerful neural network optimization techniques, i.e., mini-batch\ngradient descent, regularization, and AdaBound, to TSK fuzzy systems, and also\npropose three novel techniques (DropRule, DropMF, and DropMembership)\nspecifically for training TSK fuzzy systems. Our final algorithm, mini-batch\ngradient descent with regularization, DropRule and AdaBound (MBGD-RDA), can\nachieve fast convergence in training TSK fuzzy systems, and also superior\ngeneralization performance in testing. It can be used for training TSK fuzzy\nsystems on datasets of any size; however, it is particularly useful for big\ndatasets, on which currently no other efficient training algorithms exist.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 15:16:24 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 11:37:38 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 01:45:17 GMT"}, {"version": "v4", "created": "Sun, 1 Dec 2019 04:58:47 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wu", "Dongrui", ""], ["Yuan", "Ye", ""], ["Tan", "Yihua", ""]]}, {"id": "1903.10956", "submitter": "Kun Yuan", "authors": "Kun Yuan, Sulaiman A. Alghunaim, Bicheng Ying, Ali H. Sayed", "title": "On the Influence of Bias-Correction on Distributed Stochastic\n  Optimization", "comments": "17 pages, 9 figure, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various bias-correction methods such as EXTRA, gradient tracking methods, and\nexact diffusion have been proposed recently to solve distributed {\\em\ndeterministic} optimization problems. These methods employ constant step-sizes\nand converge linearly to the {\\em exact} solution under proper conditions.\nHowever, their performance under stochastic and adaptive settings is less\nexplored. It is still unknown {\\em whether}, {\\em when} and {\\em why} these\nbias-correction methods can outperform their traditional counterparts (such as\nconsensus and diffusion) with noisy gradient and constant step-sizes.\n  This work studies the performance of exact diffusion under the stochastic and\nadaptive setting, and provides conditions under which exact diffusion has\nsuperior steady-state mean-square deviation (MSD) performance than traditional\nalgorithms without bias-correction. In particular, it is proven that this\nsuperiority is more evident over sparsely-connected network topologies such as\nlines, cycles, or grids. Conditions are also provided under which exact\ndiffusion method match or may even degrade the performance of traditional\nmethods. Simulations are provided to validate the theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 15:28:36 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 06:54:02 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Yuan", "Kun", ""], ["Alghunaim", "Sulaiman A.", ""], ["Ying", "Bicheng", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1903.10965", "submitter": "Liyang Han", "authors": "Liyang Han, Thomas Morstyn, Constance Crozier, Malcolm McCulloch", "title": "Improving the Scalability of a Prosumer Cooperative Game with K-Means\n  Clustering", "comments": "6 pages, 4 figures, 2 tables. Accepted to the 13th IEEE PES PowerTech\n  Conference, 23-27 June 2019, Milano, Italy", "journal-ref": "2019 IEEE Milan PowerTech, Milan, Italy, 2019, pp. 1-6", "doi": "10.1109/PTC.2019.8810558", "report-no": null, "categories": "cs.CE cs.GT cs.LG econ.GN math.OC q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the various market structures under peer-to-peer energy sharing, one\nmodel based on cooperative game theory provides clear incentives for prosumers\nto collaboratively schedule their energy resources. The computational\ncomplexity of this model, however, increases exponentially with the number of\nparticipants. To address this issue, this paper proposes the application of\nK-means clustering to the energy profiles following the grand coalition\noptimization. The cooperative model is run with the \"clustered players\" to\ncompute their payoff allocations, which are then further distributed among the\nprosumers within each cluster. Case studies show that the proposed method can\nsignificantly improve the scalability of the cooperative scheme while\nmaintaining a high level of financial incentives for the prosumers.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 15:44:16 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 13:13:16 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Han", "Liyang", ""], ["Morstyn", "Thomas", ""], ["Crozier", "Constance", ""], ["McCulloch", "Malcolm", ""]]}, {"id": "1903.10978", "submitter": "Magda Gregorova", "authors": "Magda Gregorova", "title": "Sparse Learning for Variable Selection with Structures and\n  Nonlinearities", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis we discuss machine learning methods performing automated\nvariable selection for learning sparse predictive models. There are multiple\nreasons for promoting sparsity in the predictive models. By relying on a\nlimited set of input variables the models naturally counteract the overfitting\nproblem ubiquitous in learning from finite sets of training points. Sparse\nmodels are cheaper to use for predictions, they usually require lower\ncomputational resources and by relying on smaller sets of inputs can possibly\nreduce costs for data collection and storage. Sparse models can also contribute\nto better understanding of the investigated phenomenons as they are easier to\ninterpret than full models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 16:07:18 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Gregorova", "Magda", ""]]}, {"id": "1903.10992", "submitter": "Marco Ancona", "authors": "Marco Ancona, Cengiz \\\"Oztireli, Markus Gross", "title": "Explaining Deep Neural Networks with a Polynomial Time Algorithm for\n  Shapley Values Approximation", "comments": "ICML 2019", "journal-ref": "PMLR 97 (2019) 272-281", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of explaining the behavior of deep neural networks has recently\ngained a lot of attention. While several attribution methods have been\nproposed, most come without strong theoretical foundations, which raises\nquestions about their reliability. On the other hand, the literature on\ncooperative game theory suggests Shapley values as a unique way of assigning\nrelevance scores such that certain desirable properties are satisfied.\nUnfortunately, the exact evaluation of Shapley values is prohibitively\nexpensive, exponential in the number of input features. In this work, by\nleveraging recent results on uncertainty propagation, we propose a novel,\npolynomial-time approximation of Shapley values in deep neural networks. We\nshow that our method produces significantly better approximations of Shapley\nvalues than existing state-of-the-art attribution methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 16:27:21 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 14:07:42 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 21:57:15 GMT"}, {"version": "v4", "created": "Fri, 21 Jun 2019 15:39:37 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Ancona", "Marco", ""], ["\u00d6ztireli", "Cengiz", ""], ["Gross", "Markus", ""]]}, {"id": "1903.11012", "submitter": "Devdhar Patel", "authors": "Devdhar Patel, Hananel Hazan, Daniel J. Saunders, Hava Siegelmann,\n  Robert Kozma", "title": "Improved robustness of reinforcement learning policies upon conversion\n  to spiking neuronal network platforms applied to ATARI games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Reinforcement Learning (RL) demonstrates excellent performance on tasks\nthat can be solved by trained policy. It plays a dominant role among\ncutting-edge machine learning approaches using multi-layer Neural networks\n(NNs). At the same time, Deep RL suffers from high sensitivity to noisy,\nincomplete, and misleading input data. Following biological intuition, we\ninvolve Spiking Neural Networks (SNNs) to address some deficiencies of deep RL\nsolutions. Previous studies in image classification domain demonstrated that\nstandard NNs (with ReLU nonlinearity) trained using supervised learning can be\nconverted to SNNs with negligible deterioration in performance. In this paper,\nwe extend those conversion results to the domain of Q-Learning NNs trained\nusing RL. We provide a proof of principle of the conversion of standard NN to\nSNN. In addition, we show that the SNN has improved robustness to occlusion in\nthe input image. Finally, we introduce results with converting full-scale Deep\nQ-network to SNN, paving the way for future research to robust Deep RL\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 16:53:09 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 22:36:43 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 14:46:13 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Patel", "Devdhar", ""], ["Hazan", "Hananel", ""], ["Saunders", "Daniel J.", ""], ["Siegelmann", "Hava", ""], ["Kozma", "Robert", ""]]}, {"id": "1903.11020", "submitter": "Shuo Zhou", "authors": "Shuo Zhou, Wenwen Li, Christopher R. Cox, and Haiping Lu", "title": "Domain Independent SVM for Transfer Learning in Brain Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Brain imaging data are important in brain sciences yet expensive to obtain,\nwith big volume (i.e., large p) but small sample size (i.e., small n). To\ntackle this problem, transfer learning is a promising direction that leverages\nsource data to improve performance on related, target data. Most transfer\nlearning methods focus on minimizing data distribution mismatch. However, a big\nchallenge in brain imaging is the large domain discrepancies in cognitive\nexperiment designs and subject-specific structures and functions. A recent\ntransfer learning approach minimizes domain dependence to learn common features\nacross domains, via the Hilbert-Schmidt Independence Criterion (HSIC). Inspired\nby this method, we propose a new Domain Independent Support Vector Machine\n(DI-SVM) for transfer learning in brain condition decoding. Specifically,\nDI-SVM simultaneously minimizes the SVM empirical risk and the dependence on\ndomain information via a simplified HSIC. We use public data to construct 13\ntransfer learning tasks in brain decoding, including three interesting\nmulti-source transfer tasks. Experiments show that DI-SVM's superior\nperformance over eight competing methods on these tasks, particularly an\nimprovement of more than 24% on multi-source transfer tasks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 17:04:44 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Zhou", "Shuo", ""], ["Li", "Wenwen", ""], ["Cox", "Christopher R.", ""], ["Lu", "Haiping", ""]]}, {"id": "1903.11024", "submitter": "Reem ALRashdi", "authors": "Reem ALRashdi and Simon O'Keefe", "title": "Deep Learning and Word Embeddings for Tweet Classification for Crisis\n  Response", "comments": "This paper has been accepted and presented in the 3rd National\n  Computing Colleges Conference (NC3) in Abha, Saudi Arabia on 9th October 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tradition tweet classification models for crisis response focus on\nconvolutional layers and domain-specific word embeddings. In this paper, we\nstudy the application of different neural networks with general-purpose and\ndomain-specific word embeddings to investigate their ability to improve the\nperformance of tweet classification models. We evaluate four tweet\nclassification models on CrisisNLP dataset and obtain comparable results which\nindicates that general-purpose word embedding such as GloVe can be used instead\nof domain-specific word embedding especially with Bi-LSTM where results\nreported the highest performance of 62.04% F1 score.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 17:10:07 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["ALRashdi", "Reem", ""], ["O'Keefe", "Simon", ""]]}, {"id": "1903.11027", "submitter": "Holger Caesar", "authors": "Holger Caesar, Varun Bankiti, Alex H. Lang, Sourabh Vora, Venice Erin\n  Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, Oscar Beijbom", "title": "nuScenes: A multimodal dataset for autonomous driving", "comments": "CVPR 2020 camera ready incl. supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust detection and tracking of objects is crucial for the deployment of\nautonomous vehicle technology. Image based benchmark datasets have driven\ndevelopment in computer vision tasks such as object detection, tracking and\nsegmentation of agents in the environment. Most autonomous vehicles, however,\ncarry a combination of cameras and range sensors such as lidar and radar. As\nmachine learning based methods for detection and tracking become more\nprevalent, there is a need to train and evaluate such methods on datasets\ncontaining range sensor data along with images. In this work we present\nnuTonomy scenes (nuScenes), the first dataset to carry the full autonomous\nvehicle sensor suite: 6 cameras, 5 radars and 1 lidar, all with full 360 degree\nfield of view. nuScenes comprises 1000 scenes, each 20s long and fully\nannotated with 3D bounding boxes for 23 classes and 8 attributes. It has 7x as\nmany annotations and 100x as many images as the pioneering KITTI dataset. We\ndefine novel 3D detection and tracking metrics. We also provide careful dataset\nanalysis as well as baselines for lidar and image based detection and tracking.\nData, development kit and more information are available online.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 17:19:56 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 10:06:43 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 09:01:24 GMT"}, {"version": "v4", "created": "Wed, 8 Jan 2020 10:30:05 GMT"}, {"version": "v5", "created": "Tue, 5 May 2020 09:13:24 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Caesar", "Holger", ""], ["Bankiti", "Varun", ""], ["Lang", "Alex H.", ""], ["Vora", "Sourabh", ""], ["Liong", "Venice Erin", ""], ["Xu", "Qiang", ""], ["Krishnan", "Anush", ""], ["Pan", "Yu", ""], ["Baldan", "Giancarlo", ""], ["Beijbom", "Oscar", ""]]}, {"id": "1903.11040", "submitter": "Pankaj Roy", "authors": "Pankaj Raj Roy and Guillaume-Alexandre Bilodeau", "title": "Adversarially Learned Abnormal Trajectory Classifier", "comments": "Accepted for the 16th Conference on Computer and Robot Vision (CRV)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of abnormal event detection from trajectory data. In\nthis paper, a new adversarial approach is proposed for building a deep neural\nnetwork binary classifier, trained in an unsupervised fashion, that can\ndistinguish normal from abnormal trajectory-based events without the need for\nsetting manual detection threshold. Inspired by the generative adversarial\nnetwork (GAN) framework, our GAN version is a discriminative one in which the\ndiscriminator is trained to distinguish normal and abnormal trajectory\nreconstruction errors given by a deep autoencoder. With urban traffic videos\nand their associated trajectories, our proposed method gives the best accuracy\nfor abnormal trajectory detection. In addition, our model can easily be\ngeneralized for abnormal trajectory-based event detection and can still yield\nthe best behavioural detection results as demonstrated on the CAVIAR dataset.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 17:39:06 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 23:24:57 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Roy", "Pankaj Raj", ""], ["Bilodeau", "Guillaume-Alexandre", ""]]}, {"id": "1903.11048", "submitter": "Kim Andrea Nicoli", "authors": "Kim Nicoli, Pan Kessel, Nils Strodthoff, Wojciech Samek, Klaus-Robert\n  M\\\"uller, Shinichi Nakajima", "title": "Comment on \"Solving Statistical Mechanics Using VANs\": Introducing\n  saVANt - VANs Enhanced by Importance and MCMC Sampling", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this comment on \"Solving Statistical Mechanics Using Variational\nAutoregressive Networks\" by Wu et al., we propose a subtle yet powerful\nmodification of their approach. We show that the inherent sampling error of\ntheir method can be corrected by using neural network-based MCMC or importance\nsampling which leads to asymptotically unbiased estimators for physical\nquantities. This modification is possible due to a singular property of VANs,\nnamely that they provide the exact sample probability. With these\nmodifications, we believe that their method could have a substantially greater\nimpact on various important fields of physics, including strongly-interacting\nfield theories and statistical physics.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 17:52:44 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Nicoli", "Kim", ""], ["Kessel", "Pan", ""], ["Strodthoff", "Nils", ""], ["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Nakajima", "Shinichi", ""]]}, {"id": "1903.11064", "submitter": "Weiya Fan", "authors": "TingTing Li, WeiYa Fan, YunSong Luo", "title": "A method on selecting reliable samples based on fuzziness in positive\n  and unlabeled learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional semi-supervised learning uses only labeled instances to train a\nclassifier and then this classifier is utilized to classify unlabeled\ninstances, while sometimes there are only positive instances which are elements\nof the target concept are available in the labeled set. Our research in this\npaper the design of learning algorithms from positive and unlabeled instances\nonly. Among all the semi-supervised positive and unlabeled learning methods, it\nis a fundamental step to extract useful information from unlabeled instances.\nIn this paper, we design a novel framework to take advantage of valid\ninformation in unlabeled instances. In essence, this framework mainly includes\nthat (1) selects reliable negative instances through the fuzziness of the\ninstances; (2) chooses new positive instances based on the fuzziness of the\ninstances to expand the initial positive set, and we named these new instances\nas reliable positive instances; (3) uses data editing technique to filter out\nnoise points with high fuzziness. The effectiveness of the presented algorithm\nis verified by comparative experiments on UCI dataset.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 14:27:26 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Li", "TingTing", ""], ["Fan", "WeiYa", ""], ["Luo", "YunSong", ""]]}, {"id": "1903.11101", "submitter": "Jared Dunnmon", "authors": "Jared Dunnmon, Alexander Ratner, Nishith Khandwala, Khaled Saab,\n  Matthew Markert, Hersh Sagreiya, Roger Goldman, Christopher Lee-Messer,\n  Matthew Lungren, Daniel Rubin, Christopher R\\'e", "title": "Cross-Modal Data Programming Enables Rapid Medical Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling training datasets has become a key barrier to building medical\nmachine learning models. One strategy is to generate training labels\nprogrammatically, for example by applying natural language processing pipelines\nto text reports associated with imaging studies. We propose cross-modal data\nprogramming, which generalizes this intuitive strategy in a\ntheoretically-grounded way that enables simpler, clinician-driven input,\nreduces required labeling time, and improves with additional unlabeled data. In\nthis approach, clinicians generate training labels for models defined over a\ntarget modality (e.g. images or time series) by writing rules over an auxiliary\nmodality (e.g. text reports). The resulting technical challenge consists of\nestimating the accuracies and correlations of these rules; we extend a recent\nunsupervised generative modeling technique to handle this cross-modal setting\nin a provably consistent way. Across four applications in radiography, computed\ntomography, and electroencephalography, and using only several hours of\nclinician time, our approach matches or exceeds the efficacy of\nphysician-months of hand-labeling with statistical significance, demonstrating\na fundamentally faster and more flexible way of building machine learning\nmodels in medicine.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 18:12:34 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Dunnmon", "Jared", ""], ["Ratner", "Alexander", ""], ["Khandwala", "Nishith", ""], ["Saab", "Khaled", ""], ["Markert", "Matthew", ""], ["Sagreiya", "Hersh", ""], ["Goldman", "Roger", ""], ["Lee-Messer", "Christopher", ""], ["Lungren", "Matthew", ""], ["Rubin", "Daniel", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1903.11107", "submitter": "Ahmed S. Zamzam", "authors": "Ahmed S. Zamzam, Bo Yang, Nicholas D. Sidiropoulos", "title": "Energy Storage Management via Deep Q-Networks", "comments": "IEEE PES-GM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy storage devices represent environmentally friendly candidates to cope\nwith volatile renewable energy generation. Motivated by the increase in\nprivately owned storage systems, this paper studies the problem of real-time\ncontrol of a storage unit co-located with a renewable energy generator and an\ninelastic load. Unlike many approaches in the literature, no distributional\nassumptions are being made on the renewable energy generation or the real-time\nprices. Building on the deep Q-networks algorithm, a reinforcement learning\napproach utilizing a neural network is devised where the storage unit\noperational constraints are respected. The neural network approximates the\naction-value function which dictates what action (charging, discharging, etc.)\nto take. Simulations indicate that near-optimal performance can be attained\nwith the proposed learning-based control policy for the storage units.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 18:42:01 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Zamzam", "Ahmed S.", ""], ["Yang", "Bo", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1903.11112", "submitter": "Oluwaseyi Feyisetan", "authors": "Oluwaseyi Feyisetan, Thomas Drake, Borja Balle, Tom Diethe", "title": "Privacy-preserving Active Learning on Sensitive Data for User Intent\n  Classification", "comments": "To appear at PAL: Privacy-Enhancing Artificial Intelligence and\n  Language Technologies as part of the AAAI Spring Symposium Series (AAAI-SSS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning holds promise of significantly reducing data annotation costs\nwhile maintaining reasonable model performance. However, it requires sending\ndata to annotators for labeling. This presents a possible privacy leak when the\ntraining set includes sensitive user data. In this paper, we describe an\napproach for carrying out privacy preserving active learning with quantifiable\nguarantees. We evaluate our approach by showing the tradeoff between privacy,\nutility and annotation budget on a binary classification task in a active\nlearning setting.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 18:48:43 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Feyisetan", "Oluwaseyi", ""], ["Drake", "Thomas", ""], ["Balle", "Borja", ""], ["Diethe", "Tom", ""]]}, {"id": "1903.11114", "submitter": "Felix M. Riese", "authors": "Felix M. Riese and Sina Keller", "title": "SuSi: Supervised Self-Organizing Maps for Regression and Classification\n  in Python", "comments": "An extended and peer-reviewed version exists at\n  doi:10.3390/rs12010007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many research fields, the sizes of the existing datasets vary widely.\nHence, there is a need for machine learning techniques which are well-suited\nfor these different datasets. One possible technique is the self-organizing map\n(SOM), a type of artificial neural network which is, so far, weakly represented\nin the field of machine learning. The SOM's unique characteristic is the\nneighborhood relationship of the output neurons. This relationship improves the\nability of generalization on small datasets. SOMs are mostly applied in\nunsupervised learning and few studies focus on using SOMs as supervised\nlearning approach. Furthermore, no appropriate SOM package is available with\nrespect to machine learning standards and in the widely used programming\nlanguage Python. In this paper, we introduce the freely available Supervised\nSelf-organizing maps (SuSi) Python package which performs supervised regression\nand classification. The implementation of SuSi is described with respect to the\nunderlying mathematics. Then, we present first evaluations of the SOM for\nregression and classification datasets from two different domains of geospatial\nimage analysis. Despite the early stage of its development, the SuSi framework\nperforms well and is characterized by only small performance differences\nbetween the training and the test datasets. A comparison of the SuSi framework\nwith existing Python and R packages demonstrates the importance of the SuSi\nframework. In future work, the SuSi framework will be extended, optimized and\nupgraded e.g. with tools to better understand and visualize the input data as\nwell as the handling of missing and incomplete data.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 18:52:45 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 17:09:17 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 13:06:43 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Riese", "Felix M.", ""], ["Keller", "Sina", ""]]}, {"id": "1903.11149", "submitter": "Felix Petersen", "authors": "Felix Petersen, Amit H. Bermano, Oliver Deussen, Daniel Cohen-Or", "title": "Pix2Vex: Image-to-Geometry Reconstruction using a Smooth Differentiable\n  Renderer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The long-coveted task of reconstructing 3D geometry from images is still a\nstanding problem. In this paper, we build on the power of neural networks and\nintroduce Pix2Vex, a network trained to convert camera-captured images into 3D\ngeometry. We present a novel differentiable renderer ($DR$) as a forward\nvalidation means during training. Our key insight is that $DR$s produce images\nof a particular appearance, different from typical input images. Hence, we\npropose adding an image-to-image translation component, converting between\nthese rendering styles. This translation closes the training loop, while\nallowing to use minimal supervision only, without needing any 3D model as\nground truth. Unlike state-of-the-art methods, our $DR$ is $C^\\infty$ smooth\nand thus does not display any discontinuities at occlusions or dis-occlusions.\nThrough our novel training scheme, our network can train on different types of\nimages, where previous work can typically only train on images of a similar\nappearance to those rendered by a $DR$.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 20:34:32 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 17:05:53 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Petersen", "Felix", ""], ["Bermano", "Amit H.", ""], ["Deussen", "Oliver", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "1903.11158", "submitter": "Jo\\~ao Antunes", "authors": "Jo\\~ao Antunes, Alexandre Bernardino, Asim Smailagic, Daniel Siewiorek", "title": "Weighted Multisource Tradaboost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an improved method for transfer learning that takes\ninto account the balance between target and source data. This method builds on\nthe state-of-the-art Multisource Tradaboost, but weighs the importance of each\ndatapoint taking into account the amount of target and source data available. A\ncomparative study is then presented exposing the performance of four transfer\nlearning methods as well as the proposed Weighted Multisource Tradaboost. The\nexperimental results show that the proposed method is able to outperform the\nbase method as the number of target samples increase. These results are\npromising in the sense that source-target ratio weighing may be a path to\nimprove current methods of transfer learning. However, against the asymptotic\nconjecture, all transfer learning methods tested in this work get outperformed\nby a no-transfer SVM for large number on target samples.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 21:22:08 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Antunes", "Jo\u00e3o", ""], ["Bernardino", "Alexandre", ""], ["Smailagic", "Asim", ""], ["Siewiorek", "Daniel", ""]]}, {"id": "1903.11166", "submitter": "Caleb Gannon", "authors": "Caleb Gannon and Rongguang Liang", "title": "Using machine learning to create high-efficiency freeform illumination\n  design tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a method for improving the efficiency and user experience of\nfreeform illumination design with machine learning. By utilizing orthogonal\npolynomials to interface with artificial neural networks, we are able to\ngeneralize relationships between freeform surface shapes and design parameters.\nThen, by training the network to generalize the relationship between high-level\ndesign goals and final performance, we were able to transform what is\ntraditionally a difficult and computationally intensive problem into a compact,\nuser friendly form. The potential of the proposed method is demonstrated\nthrough the design of uniform square patterns from off-axis positions and\nrectangular patterns of tuneable aspect ratios and distances from the target.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 18:47:14 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Gannon", "Caleb", ""], ["Liang", "Rongguang", ""]]}, {"id": "1903.11174", "submitter": "Rogerio Bonatti", "authors": "Wenshan Wang, Aayush Ahuja, Yanfu Zhang, Rogerio Bonatti, Sebastian\n  Scherer", "title": "Improved Generalization of Heading Direction Estimation for Aerial\n  Filming Using Semi-supervised Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the task of Autonomous aerial filming of a moving actor (e.g. a person or\na vehicle), it is crucial to have a good heading direction estimation for the\nactor from the visual input. However, the models obtained in other similar\ntasks, such as pedestrian collision risk analysis and human-robot interaction,\nare very difficult to generalize to the aerial filming task, because of the\ndifference in data distributions. Towards improving generalization with less\namount of labeled data, this paper presents a semi-supervised algorithm for\nheading direction estimation problem. We utilize temporal continuity as the\nunsupervised signal to regularize the model and achieve better generalization\nability. This semi-supervised algorithm is applied to both training and testing\nphases, which increases the testing performance by a large margin. We show that\nby leveraging unlabeled sequences, the amount of labeled data required can be\nsignificantly reduced. We also discuss several important details on improving\nthe performance by balancing labeled and unlabeled loss, and making good\ncombinations. Experimental results show that our approach robustly outputs the\nheading direction for different types of actor. The aesthetic value of the\nvideo is also improved in the aerial filming task.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 22:05:05 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Wang", "Wenshan", ""], ["Ahuja", "Aayush", ""], ["Zhang", "Yanfu", ""], ["Bonatti", "Rogerio", ""], ["Scherer", "Sebastian", ""]]}, {"id": "1903.11176", "submitter": "Rahul Gupta", "authors": "Taruna Agrawal, Rahul Gupta, Shrikanth Narayanan", "title": "On evaluating CNN representations for low resource medical image\n  classification", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have revolutionized performances in\nseveral machine learning tasks such as image classification, object tracking,\nand keyword spotting. However, given that they contain a large number of\nparameters, their direct applicability into low resource tasks is not\nstraightforward. In this work, we experiment with an application of CNN models\nto gastrointestinal landmark classification with only a few thousands of\ntraining samples through transfer learning. As in a standard transfer learning\napproach, we train CNNs on a large external corpus, followed by representation\nextraction for the medical images. Finally, a classifier is trained on these\nCNN representations. However, given that several variants of CNNs exist, the\nchoice of CNN is not obvious. To address this, we develop a novel metric that\ncan be used to predict test performances, given CNN representations on the\ntraining set. Not only we demonstrate the superiority of the CNN based transfer\nlearning approach against an assembly of knowledge driven features, but the\nproposed metric also carries an 87% correlation with the test set performances\nas obtained using various CNN representations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 22:05:58 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Agrawal", "Taruna", ""], ["Gupta", "Rahul", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1903.11178", "submitter": "Alexander Jung", "authors": "Alexander Jung and Nguyen Tran", "title": "Localized Linear Regression in Networked Data", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2019.2918933", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network Lasso (nLasso) has been proposed recently as an efficient\nlearning algorithm for massive networked data sets (big data over networks). It\nextends the well-known least absolute shrinkage and selection operator (Lasso)\nfrom learning sparse (generalized) linear models to network models. Efficient\nimplementations of the nLasso have been obtained using convex optimization\nmethods lending to scalable message passing protocols. In this paper, we\nanalyze the statistical properties of nLasso when applied to localized linear\nregression problems involving networked data. Our main result is a sufficient\ncondition on the network structure and available label information such that\nnLasso accurately learns a localized linear regression model from a few labeled\ndata points. We also provide an implementation of nLasso for localized linear\nregression by specializing a primaldual method for solving the convex\n(non-smooth) nLasso problem.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 22:17:10 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 08:21:53 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Jung", "Alexander", ""], ["Tran", "Nguyen", ""]]}, {"id": "1903.11202", "submitter": "Hongwei Dong", "authors": "Hongwei Dong and Liming Yang", "title": "Kernel based regression with robust loss function via iteratively\n  reweighted least squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Least squares kernel based methods have been widely used in regression\nproblems due to the simple implementation and good generalization performance.\nAmong them, least squares support vector regression (LS-SVR) and extreme\nlearning machine (ELM) are popular techniques. However, the noise sensitivity\nis a major bottleneck. To address this issue, a generalized loss function,\ncalled $\\ell_s$-loss, is proposed in this paper. With the support of novel loss\nfunction, two kernel based regressors are constructed by replacing the\n$\\ell_2$-loss in LS-SVR and ELM with the proposed $\\ell_s$-loss for better\nnoise robustness. Important properties of $\\ell_s$-loss, including robustness,\nasymmetry and asymptotic approximation behaviors, are verified theoretically.\nMoreover, iteratively reweighted least squares (IRLS) is utilized to optimize\nand interpret the proposed methods from a weighted viewpoint. The convergence\nof the proposal are proved, and detailed analyses of robustness are given.\nExperiments on both artificial and benchmark datasets confirm the validity of\nthe proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 00:40:18 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 03:57:26 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Dong", "Hongwei", ""], ["Yang", "Liming", ""]]}, {"id": "1903.11210", "submitter": "Junaid Malik", "authors": "Junaid Malik, Serkan Kiranyaz, Suchitra Kunhoth, Turker Ince, Somaya\n  Al-Maadeed, Ridha Hamila, Moncef Gabbouj", "title": "Colorectal cancer diagnosis from histology images: A comparative study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computer-aided diagnosis (CAD) based on histopathological imaging has\nprogressed rapidly in recent years with the rise of machine learning based\nmethodologies. Traditional approaches consist of training a classification\nmodel using features extracted from the images, based on textures or\nmorphological properties. Recently, deep-learning based methods have been\napplied directly to the raw (unprocessed) data. However, their usability is\nimpacted by the paucity of annotated data in the biomedical sector. In order to\nleverage the learning capabilities of deep Convolutional Neural Nets (CNNs)\nwithin the confines of limited labelled data, in this study we shall\ninvestigate the transfer learning approaches that aim to apply the knowledge\ngained from solving a source (e.g., non-medical) problem, to learn better\npredictive models for the target (e.g., biomedical) task. As an alternative, we\nshall further propose a new adaptive and compact CNN based architecture that\ncan be trained from scratch even on scarce and low-resolution data. Moreover,\nwe conduct quantitative comparative evaluations among the traditional methods,\ntransfer learning-based methods and the proposed adaptive approach for the\nparticular task of cancer detection and identification from scarce and\nlow-resolution histology images. Over the largest benchmark dataset formed for\nthis purpose, the proposed adaptive approach achieved a higher cancer detection\naccuracy with a significant gap, whereas the deep CNNs with transfer learning\nachieved a superior cancer identification.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 01:02:44 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 03:56:18 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Malik", "Junaid", ""], ["Kiranyaz", "Serkan", ""], ["Kunhoth", "Suchitra", ""], ["Ince", "Turker", ""], ["Al-Maadeed", "Somaya", ""], ["Hamila", "Ridha", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1903.11220", "submitter": "Lifeng Lai", "authors": "Erhan Bayraktar and Lifeng Lai", "title": "On the Adversarial Robustness of Multivariate Robust Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the adversarial robustness of multivariate\n$M$-Estimators. In the considered model, after observing the whole dataset, an\nadversary can modify all data points with the goal of maximizing inference\nerrors. We use adversarial influence function (AIF) to measure the asymptotic\nrate at which the adversary can change the inference result. We first\ncharacterize the adversary's optimal modification strategy and its\ncorresponding AIF. From the defender's perspective, we would like to design an\nestimator that has a small AIF. For the case of joint location and scale\nestimation problem, we characterize the optimal $M$-estimator that has the\nsmallest AIF. We further identify a tradeoff between robustness against\nadversarial modifications and robustness against outliers, and derive the\noptimal $M$-estimator that achieves the best tradeoff.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 01:54:16 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Bayraktar", "Erhan", ""], ["Lai", "Lifeng", ""]]}, {"id": "1903.11228", "submitter": "Zhiqin Chen", "authors": "Zhiqin Chen, Kangxue Yin, Matthew Fisher, Siddhartha Chaudhuri, Hao\n  Zhang", "title": "BAE-NET: Branched Autoencoder for Shape Co-Segmentation", "comments": "Accepted to ICCV 2019. Code: https://github.com/czq142857/BAE-NET\n  Supplementary material: https://www.sfu.ca/~zhiqinc/imseg/sup.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We treat shape co-segmentation as a representation learning problem and\nintroduce BAE-NET, a branched autoencoder network, for the task. The\nunsupervised BAE-NET is trained with a collection of un-segmented shapes, using\na shape reconstruction loss, without any ground-truth labels. Specifically, the\nnetwork takes an input shape and encodes it using a convolutional neural\nnetwork, whereas the decoder concatenates the resulting feature code with a\npoint coordinate and outputs a value indicating whether the point is\ninside/outside the shape. Importantly, the decoder is branched: each branch\nlearns a compact representation for one commonly recurring part of the shape\ncollection, e.g., airplane wings. By complementing the shape reconstruction\nloss with a label loss, BAE-NET is easily tuned for one-shot learning. We show\nunsupervised, weakly supervised, and one-shot learning results by BAE-NET,\ndemonstrating that using only a couple of exemplars, our network can generally\noutperform state-of-the-art supervised methods trained on hundreds of segmented\nshapes. Code is available at https://github.com/czq142857/BAE-NET.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 02:33:20 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 20:38:10 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Chen", "Zhiqin", ""], ["Yin", "Kangxue", ""], ["Fisher", "Matthew", ""], ["Chaudhuri", "Siddhartha", ""], ["Zhang", "Hao", ""]]}, {"id": "1903.11239", "submitter": "Andy Zeng", "authors": "Andy Zeng, Shuran Song, Johnny Lee, Alberto Rodriguez, Thomas\n  Funkhouser", "title": "TossingBot: Learning to Throw Arbitrary Objects with Residual Physics", "comments": "Summary Video: https://youtu.be/f5Zn2Up2RjQ Project webpage:\n  https://tossingbot.cs.princeton.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether a robot arm can learn to pick and throw arbitrary\nobjects into selected boxes quickly and accurately. Throwing has the potential\nto increase the physical reachability and picking speed of a robot arm.\nHowever, precisely throwing arbitrary objects in unstructured settings presents\nmany challenges: from acquiring reliable pre-throw conditions (e.g. initial\npose of object in manipulator) to handling varying object-centric properties\n(e.g. mass distribution, friction, shape) and dynamics (e.g. aerodynamics). In\nthis work, we propose an end-to-end formulation that jointly learns to infer\ncontrol parameters for grasping and throwing motion primitives from visual\nobservations (images of arbitrary objects in a bin) through trial and error.\nWithin this formulation, we investigate the synergies between grasping and\nthrowing (i.e., learning grasps that enable more accurate throws) and between\nsimulation and deep learning (i.e., using deep networks to predict residuals on\ntop of control parameters predicted by a physics simulator). The resulting\nsystem, TossingBot, is able to grasp and throw arbitrary objects into boxes\nlocated outside its maximum reach range at 500+ mean picks per hour (600+\ngrasps per hour with 85% throwing accuracy); and generalizes to new objects and\ntarget locations. Videos are available at https://tossingbot.cs.princeton.edu\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 04:04:28 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 19:16:12 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 15:59:12 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zeng", "Andy", ""], ["Song", "Shuran", ""], ["Lee", "Johnny", ""], ["Rodriguez", "Alberto", ""], ["Funkhouser", "Thomas", ""]]}, {"id": "1903.11240", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Eigenvalue and Generalized Eigenvalue Problems: Tutorial", "comments": "8 pages, Tutorial paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a tutorial for eigenvalue and generalized eigenvalue problems.\nWe first introduce eigenvalue problem, eigen-decomposition (spectral\ndecomposition), and generalized eigenvalue problem. Then, we mention the\noptimization problems which yield to the eigenvalue and generalized eigenvalue\nproblems. We also provide examples from machine learning, including principal\ncomponent analysis, kernel supervised principal component analysis, and Fisher\ndiscriminant analysis, which result in eigenvalue and generalized eigenvalue\nproblems. Finally, we introduce the solutions to both eigenvalue and\ngeneralized eigenvalue problems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 22:22:42 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1903.11241", "submitter": "Neil Lawrence", "authors": "Neil D. Lawrence", "title": "Data Science and Digital Systems: The 3Ds of Machine Learning Systems\n  Design", "comments": "Paper presented at the Stu Hunter Research Conference held at the\n  Villa Porro Pirelli in Induno Olona, Italy, from Sunday February 17th to\n  Wednesday February 20th, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning solutions, in particular those based on deep learning\nmethods, form an underpinning of the current revolution in \"artificial\nintelligence\" that has dominated popular press headlines and is having a\nsignificant influence on the wider tech agenda. Here we give an overview of the\n3Ds of ML systems design: Data, Design and Deployment. By considering the 3Ds\nwe can move towards \\emph{data first} design.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 13:27:37 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Lawrence", "Neil D.", ""]]}, {"id": "1903.11245", "submitter": "Mengnan Du", "authors": "Mengnan Du, Ninghao Liu, Fan Yang, Shuiwang Ji, Xia Hu", "title": "On Attribution of Recurrent Neural Network Predictions via Additive\n  Decomposition", "comments": "The 2019 Web Conference (WWW 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RNN models have achieved the state-of-the-art performance in a wide range of\ntext mining tasks. However, these models are often regarded as black-boxes and\nare criticized due to the lack of interpretability. In this paper, we enhance\nthe interpretability of RNNs by providing interpretable rationales for RNN\npredictions. Nevertheless, interpreting RNNs is a challenging problem. Firstly,\nunlike existing methods that rely on local approximation, we aim to provide\nrationales that are more faithful to the decision making process of RNN models.\nSecondly, a flexible interpretation method should be able to assign\ncontribution scores to text segments of varying lengths, instead of only to\nindividual words. To tackle these challenges, we propose a novel attribution\nmethod, called REAT, to provide interpretations to RNN predictions. REAT\ndecomposes the final prediction of a RNN into additive contribution of each\nword in the input text. This additive decomposition enables REAT to further\nobtain phrase-level attribution scores. In addition, REAT is generally\napplicable to various RNN architectures, including GRU, LSTM and their\nbidirectional versions. Experimental results demonstrate the faithfulness and\ninterpretability of the proposed attribution method. Comprehensive analysis\nshows that our attribution method could unveil the useful linguistic knowledge\ncaptured by RNNs. Some analysis further demonstrates our method could be\nutilized as a debugging tool to examine the vulnerability and failure reasons\nof RNNs, which may lead to several promising future directions to promote\ngeneralization ability of RNNs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 04:25:57 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Du", "Mengnan", ""], ["Liu", "Ninghao", ""], ["Yang", "Fan", ""], ["Ji", "Shuiwang", ""], ["Hu", "Xia", ""]]}, {"id": "1903.11253", "submitter": "Qun Liu", "authors": "Qun Liu, Supratik Mukhopadhyay, Yimin Zhu, Ravindra Gudishala, Sanaz\n  Saeidi, Alimire Nabijiang", "title": "Improving Route Choice Models by Incorporating Contextual Factors via\n  Knowledge Distillation", "comments": "Paper was accepted at the 2019 International Joint Conference on\n  Neural Networks (IJCNN 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Route Choice Models predict the route choices of travelers traversing an\nurban area. Most of the route choice models link route characteristics of\nalternative routes to those chosen by the drivers. The models play an important\nrole in prediction of traffic levels on different routes and thus assist in\ndevelopment of efficient traffic management strategies that result in\nminimizing traffic delay and maximizing effective utilization of transport\nsystem. High fidelity route choice models are required to predict traffic\nlevels with higher accuracy. Existing route choice models do not take into\naccount dynamic contextual conditions such as the occurrence of an accident,\nthe socio-cultural and economic background of drivers, other human behaviors,\nthe dynamic personal risk level, etc. As a result, they can only make\npredictions at an aggregate level and for a fixed set of contextual factors.\nFor higher fidelity, it is highly desirable to use a model that captures\nsignificance of subjective or contextual factors in route choice. This paper\npresents a novel approach for developing high-fidelity route choice models with\nincreased predictive power by augmenting existing aggregate level baseline\nmodels with information on drivers' responses to contextual factors obtained\nfrom Stated Choice Experiments carried out in an Immersive Virtual Environment\nthrough the use of knowledge distillation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 05:18:21 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Liu", "Qun", ""], ["Mukhopadhyay", "Supratik", ""], ["Zhu", "Yimin", ""], ["Gudishala", "Ravindra", ""], ["Saeidi", "Sanaz", ""], ["Nabijiang", "Alimire", ""]]}, {"id": "1903.11257", "submitter": "Subutai Ahmad", "authors": "Subutai Ahmad, Luiz Scheinkman", "title": "How Can We Be So Dense? The Benefits of Using Highly Sparse\n  Representations", "comments": "Replaced incorrect Fig 5B", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most artificial networks today rely on dense representations, whereas\nbiological networks rely on sparse representations. In this paper we show how\nsparse representations can be more robust to noise and interference, as long as\nthe underlying dimensionality is sufficiently high. A key intuition that we\ndevelop is that the ratio of the operable volume around a sparse vector divided\nby the volume of the representational space decreases exponentially with\ndimensionality. We then analyze computationally efficient sparse networks\ncontaining both sparse weights and activations. Simulations on MNIST and the\nGoogle Speech Command Dataset show that such networks demonstrate significantly\nimproved robustness and stability compared to dense networks, while maintaining\ncompetitive accuracy. We discuss the potential benefits of sparsity on\naccuracy, noise robustness, hyperparameter tuning, learning speed,\ncomputational efficiency, and power requirements.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 05:43:33 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 17:23:08 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Ahmad", "Subutai", ""], ["Scheinkman", "Luiz", ""]]}, {"id": "1903.11277", "submitter": "Masataro Asai", "authors": "Masataro Asai, Hiroshi Kajino", "title": "Towards Stable Symbol Grounding with Zero-Suppressed State AutoEncoder", "comments": "Accepted in 29th International Conference of Automated Planning and\n  Scheduling (ICAPS-2019), Planning and Learning track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While classical planning has been an active branch of AI, its applicability\nis limited to the tasks precisely modeled by humans. Fully automated high-level\nagents should be instead able to find a symbolic representation of an unknown\nenvironment without supervision, otherwise it exhibits the knowledge\nacquisition bottleneck. Meanwhile, Latplan (Asai and Fukunaga 2018) partially\nresolves the bottleneck with a neural network called State AutoEncoder (SAE).\nSAE obtains the propositional representation of the image-based puzzle domains\nwith unsupervised learning, generates a state space and performs classical\nplanning. In this paper, we identify the problematic, stochastic behavior of\nthe SAE-produced propositions as a new sub-problem of symbol grounding problem,\nthe symbol stability problem. Informally, symbols are stable when their\nreferents (e.g. propositional values) do not change against small perturbation\nof the observation, and unstable symbols are harmful for symbolic reasoning. We\nanalyze the problem in Latplan both formally and empirically, and propose\n\"Zero-Suppressed SAE\", an enhancement that stabilizes the propositions using\nthe idea of closed-world assumption as a prior for NN optimization. We show\nthat it finds the more stable propositions and the more compact\nrepresentations, resulting in an improved success rate of Latplan. It is robust\nagainst various hyperparameters and eases the tuning effort, and also provides\na weight pruning capability as a side effect.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 07:46:02 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Asai", "Masataro", ""], ["Kajino", "Hiroshi", ""]]}, {"id": "1903.11279", "submitter": "Huasha Zhao Mr", "authors": "Xiaojing Liu, Feiyu Gao, Qiong Zhang, Huasha Zhao", "title": "Graph Convolution for Multimodal Information Extraction from Visually\n  Rich Documents", "comments": "naacl'19 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visually rich documents (VRDs) are ubiquitous in daily business and life.\nExamples are purchase receipts, insurance policy documents, custom declaration\nforms and so on. In VRDs, visual and layout information is critical for\ndocument understanding, and texts in such documents cannot be serialized into\nthe one-dimensional sequence without losing information. Classic information\nextraction models such as BiLSTM-CRF typically operate on text sequences and do\nnot incorporate visual features. In this paper, we introduce a graph\nconvolution based model to combine textual and visual information presented in\nVRDs. Graph embeddings are trained to summarize the context of a text segment\nin the document, and further combined with text embeddings for entity\nextraction. Extensive experiments have been conducted to show that our method\noutperforms BiLSTM-CRF baselines by significant margins, on two real-world\ndatasets. Additionally, ablation studies are also performed to evaluate the\neffectiveness of each component of our model.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 07:47:12 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Liu", "Xiaojing", ""], ["Gao", "Feiyu", ""], ["Zhang", "Qiong", ""], ["Zhao", "Huasha", ""]]}, {"id": "1903.11329", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Wendelin Boehmer, Shimon Whiteson", "title": "Generalized Off-Policy Actor-Critic", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new objective, the counterfactual objective, unifying existing\nobjectives for off-policy policy gradient algorithms in the continuing\nreinforcement learning (RL) setting. Compared to the commonly used excursion\nobjective, which can be misleading about the performance of the target policy\nwhen deployed, our new objective better predicts such performance. We prove the\nGeneralized Off-Policy Policy Gradient Theorem to compute the policy gradient\nof the counterfactual objective and use an emphatic approach to get an unbiased\nsample from this policy gradient, yielding the Generalized Off-Policy\nActor-Critic (Geoff-PAC) algorithm. We demonstrate the merits of Geoff-PAC over\nexisting algorithms in Mujoco robot simulation tasks, the first empirical\nsuccess of emphatic algorithms in prevailing deep RL benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 10:17:13 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 10:45:48 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 23:26:22 GMT"}, {"version": "v4", "created": "Mon, 17 Jun 2019 20:55:53 GMT"}, {"version": "v5", "created": "Fri, 13 Sep 2019 15:32:03 GMT"}, {"version": "v6", "created": "Mon, 16 Sep 2019 20:41:03 GMT"}, {"version": "v7", "created": "Mon, 14 Oct 2019 20:22:42 GMT"}, {"version": "v8", "created": "Mon, 28 Oct 2019 09:58:44 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhang", "Shangtong", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1903.11331", "submitter": "Alexandra Gessner", "authors": "Alexandra Gessner, Javier Gonzalez, Maren Mahsereci", "title": "Active Multi-Information Source Bayesian Quadrature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian quadrature (BQ) is a sample-efficient probabilistic numerical method\nto solve integrals of expensive-to-evaluate black-box functions, yet so\nfar,active BQ learning schemes focus merely on the integrand itself as\ninformation source, and do not allow for information transfer from cheaper,\nrelated functions. Here, we set the scene for active learning in BQ when\nmultiple related information sources of variable cost (in input and source) are\naccessible. This setting arises for example when evaluating the integrand\nrequires a complex simulation to be run that can be approximated by simulating\nat lower levels of sophistication and at lesser expense. We construct\nmeaningful cost-sensitive multi-source acquisition rates as an extension to\ncommon utility functions from vanilla BQ (VBQ),and discuss pitfalls that arise\nfrom blindly generalizing. Furthermore, we show that the VBQ acquisition policy\nis a corner-case of all considered cost-sensitive acquisition schemes, which\ncollapse onto one single de-generate policy in the case of one source and\nconstant cost. In proof-of-concept experiments we scrutinize the behavior of\nour generalized acquisition functions. On an epidemiological model, we\ndemonstrate that active multi-source BQ (AMS-BQ) allocates budget more\nefficiently than VBQ for learning the integral to a good accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 10:17:50 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 13:58:58 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 11:37:22 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Gessner", "Alexandra", ""], ["Gonzalez", "Javier", ""], ["Mahsereci", "Maren", ""]]}, {"id": "1903.11334", "submitter": "Yuebing Zhang", "authors": "Yuebing Zhang and Duoqian Miao and Jiaqi Wang", "title": "Hierarchical Attention Generative Adversarial Networks for Cross-domain\n  Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain sentiment classification (CDSC) is an importance task in domain\nadaptation and sentiment classification. Due to the domain discrepancy, a\nsentiment classifier trained on source domain data may not works well on target\ndomain data. In recent years, many researchers have used deep neural network\nmodels for cross-domain sentiment classification task, many of which use\nGradient Reversal Layer (GRL) to design an adversarial network structure to\ntrain a domain-shared sentiment classifier. Different from those methods, we\nproposed Hierarchical Attention Generative Adversarial Networks (HAGAN) which\nalternately trains a generator and a discriminator in order to produce a\ndocument representation which is sentiment-distinguishable but\ndomain-indistinguishable. Besides, the HAGAN model applies Bidirectional Gated\nRecurrent Unit (Bi-GRU) to encode the contextual information of a word and a\nsentence into the document representation. In addition, the HAGAN model use\nhierarchical attention mechanism to optimize the document representation and\nautomatically capture the pivots and non-pivots. The experiments on Amazon\nreview dataset show the effectiveness of HAGAN.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 10:22:55 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Zhang", "Yuebing", ""], ["Miao", "Duoqian", ""], ["Wang", "Jiaqi", ""]]}, {"id": "1903.11359", "submitter": "Francesco Croce", "authors": "Francesco Croce, Jonas Rauber, Matthias Hein", "title": "Scaling up the randomized gradient-free adversarial attack reveals\n  overestimation of robustness using established attacks", "comments": "Accepted at International Journal of Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks are highly non-robust against adversarial\nmanipulation. A significant amount of work has been invested in techniques to\ncompute lower bounds on robustness through formal guarantees and to build\nprovably robust models. However, it is still difficult to get guarantees for\nlarger networks or robustness against larger perturbations. Thus attack\nstrategies are needed to provide tight upper bounds on the actual robustness.\nWe significantly improve the randomized gradient-free attack for ReLU networks\n[9], in particular by scaling it up to large networks. We show that our attack\nachieves similar or significantly smaller robust accuracy than state-of-the-art\nattacks like PGD or the one of Carlini and Wagner, thus revealing an\noverestimation of the robustness by these state-of-the-art methods. Our attack\nis not based on a gradient descent scheme and in this sense gradient-free,\nwhich makes it less sensitive to the choice of hyperparameters as no careful\nselection of the stepsize is required.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 11:41:27 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 17:04:43 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Croce", "Francesco", ""], ["Rauber", "Jonas", ""], ["Hein", "Matthias", ""]]}, {"id": "1903.11373", "submitter": "Dalit Engelhardt", "authors": "Dalit Engelhardt", "title": "Dynamic Control of Stochastic Evolution: A Deep Reinforcement Learning\n  Approach to Adaptively Targeting Emergent Drug Resistance", "comments": null, "journal-ref": "Journal of Machine Learning Research 21(203): 1-30, 2020", "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge in controlling stochastic systems in which low-probability\nevents can set the system on catastrophic trajectories is to develop a robust\nability to respond to such events without significantly compromising the\noptimality of the baseline control policy. This paper presents CelluDose, a\nstochastic simulation-trained deep reinforcement learning adaptive feedback\ncontrol prototype for automated precision drug dosing targeting stochastic and\nheterogeneous cell proliferation. Drug resistance can emerge from random and\nvariable mutations in targeted cell populations; in the absence of an\nappropriate dosing policy, emergent resistant subpopulations can proliferate\nand lead to treatment failure. Dynamic feedback dosage control holds promise in\ncombatting this phenomenon, but the application of traditional control\napproaches to such systems is fraught with challenges due to the complexity of\ncell dynamics, uncertainty in model parameters, and the need in medical\napplications for a robust controller that can be trusted to properly handle\nunexpected outcomes. Here, training on a sample biological scenario identified\nsingle-drug and combination therapy policies that exhibit a 100% success rate\nat suppressing cell proliferation and responding to diverse system\nperturbations while establishing low-dose no-event baselines. These policies\nwere found to be highly robust to variations in a key model parameter subject\nto significant uncertainty and unpredictable dynamical changes.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 12:25:48 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 22:21:53 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Engelhardt", "Dalit", ""]]}, {"id": "1903.11385", "submitter": "Shuai Ma", "authors": "Shuai Ma, Jiahui Dai, Songtao Lu, Hang Li, Han Zhang, Chun Du, and\n  Shiyin Li", "title": "Signal Demodulation with Machine Learning Methods for Physical Layer\n  Visible Light Communications: Prototype Platform, Open Dataset and Algorithms", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2019.2903375", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the design and implementation of machine\nlearning (ML) based demodulation methods in the physical layer of visible light\ncommunication (VLC) systems. We build a flexible hardware prototype of an\nend-to-end VLC system, from which the received signals are collected as the\nreal data. The dataset is available online, which contains eight types of\nmodulated signals. Then, we propose three ML demodulators based on\nconvolutional neural network (CNN), deep belief network (DBN), and adaptive\nboosting (AdaBoost), respectively. Specifically, the CNN based demodulator\nconverts the modulated signals to images and recognizes the signals by the\nimage classification. The proposed DBN based demodulator contains three\nrestricted Boltzmann machines (RBMs) to extract the modulation features. The\nAdaBoost method includes a strong classifier that is constructed by the weak\nclassifiers with the k-nearest neighbor (KNN) algorithm. These three\ndemodulators are trained and tested by our online open dataset. Experimental\nresults show that the demodulation accuracy of the three data-driven\ndemodulators drops as the transmission distance increases. A higher modulation\norder negatively influences the accuracy for a given transmission distance.\nAmong the three ML methods, the AdaBoost modulator achieves the best\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 11:38:10 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Ma", "Shuai", ""], ["Dai", "Jiahui", ""], ["Lu", "Songtao", ""], ["Li", "Hang", ""], ["Zhang", "Han", ""], ["Du", "Chun", ""], ["Li", "Shiyin", ""]]}, {"id": "1903.11399", "submitter": "Iikka Virkkunen", "authors": "Iikka Virkkunen, Tuomas Koskinen, Oskari Jessen-Juhler and Jari\n  Rinta-Aho", "title": "Augmented Ultrasonic Data for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flaw detection in non-destructive testing, especially in complex signals like\nultrasonic data, has thus far relied heavily on the expertise and judgement of\ntrained human inspectors. While automated systems have been used for a long\ntime, these have mostly been limited to using simple decision automation, such\nas signal amplitude threshold. The recent advances in various machine learning\nalgorithms have solved many similarly difficult classification problems, that\nhave previously been considered intractable. For non-destructive testing,\nencouraging results have already been reported in the open literature, but the\nuse of machine learning is still very limited in NDT applications in the field.\nKey issue hindering their use, is the limited availability of representative\nflawed data-sets to be used for training. In the present paper, we develop\nmodern, very deep convolutional network to detect flaws from phased-array\nultrasonic data. We make extensive use of data augmentation to enhance the\ninitially limited raw data and to aid learning. The data augmentation utilizes\nvirtual flaws - a technique, that has successfully been used in training human\ninspectors and is soon to be used in nuclear inspection qualification. The\nresults from the machine learning classifier are compared to human performance.\nWe show, that using sophisticated data augmentation, modern deep learning\nnetworks can be trained to achieve superhuman performance by significant\nmargin.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 09:03:37 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Virkkunen", "Iikka", ""], ["Koskinen", "Tuomas", ""], ["Jessen-Juhler", "Oskari", ""], ["Rinta-Aho", "Jari", ""]]}, {"id": "1903.11406", "submitter": "Hung Nghiep Tran", "authors": "Hung Nghiep Tran, Atsuhiro Takasu", "title": "Analyzing Knowledge Graph Embedding Methods from a Multi-Embedding\n  Interaction Perspective", "comments": "DSI4 at EDBT/ICDT 2019. Source code is available on github at\n  https://github.com/tranhungnghiep/AnalyzingKGEmbeddings", "journal-ref": "Data Science for Industry 4.0 at EDBT/ICDT 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graph is a popular format for representing knowledge, with many\napplications to semantic search engines, question-answering systems, and\nrecommender systems. Real-world knowledge graphs are usually incomplete, so\nknowledge graph embedding methods, such as Canonical decomposition/Parallel\nfactorization (CP), DistMult, and ComplEx, have been proposed to address this\nissue. These methods represent entities and relations as embedding vectors in\nsemantic space and predict the links between them. The embedding vectors\nthemselves contain rich semantic information and can be used in other\napplications such as data analysis. However, mechanisms in these models and the\nembedding vectors themselves vary greatly, making it difficult to understand\nand compare them. Given this lack of understanding, we risk using them\nineffectively or incorrectly, particularly for complicated models, such as CP,\nwith two role-based embedding vectors, or the state-of-the-art ComplEx model,\nwith complex-valued embedding vectors. In this paper, we propose a\nmulti-embedding interaction mechanism as a new approach to uniting and\ngeneralizing these models. We derive them theoretically via this mechanism and\nprovide empirical analyses and comparisons between them. We also propose a new\nmulti-embedding model based on quaternion algebra and show that it achieves\npromising results using popular benchmarks. Source code is available on github\nat https://github.com/tranhungnghiep/AnalyzingKGEmbeddings\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:09:16 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 04:34:16 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 19:58:51 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Tran", "Hung Nghiep", ""], ["Takasu", "Atsuhiro", ""]]}, {"id": "1903.11412", "submitter": "Xiaohang Zhan", "authors": "Xiaohang Zhan, Xingang Pan, Ziwei Liu, Dahua Lin, Chen Change Loy", "title": "Self-Supervised Learning via Conditional Motion Propagation", "comments": "In CVPR 2019. More details at the project page:\n  http://mmlab.ie.cuhk.edu.hk/projects/CMP/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent agent naturally learns from motion. Various self-supervised\nalgorithms have leveraged motion cues to learn effective visual\nrepresentations. The hurdle here is that motion is both ambiguous and complex,\nrendering previous works either suffer from degraded learning efficacy, or\nresort to strong assumptions on object motions. In this work, we design a new\nlearning-from-motion paradigm to bridge these gaps. Instead of explicitly\nmodeling the motion probabilities, we design the pretext task as a conditional\nmotion propagation problem. Given an input image and several sparse flow\nguidance vectors on it, our framework seeks to recover the full-image motion.\nCompared to other alternatives, our framework has several appealing properties:\n(1) Using sparse flow guidance during training resolves the inherent motion\nambiguity, and thus easing feature learning. (2) Solving the pretext task of\nconditional motion propagation encourages the emergence of kinematically-sound\nrepresentations that poss greater expressive power. Extensive experiments\ndemonstrate that our framework learns structural and coherent features; and\nachieves state-of-the-art self-supervision performance on several downstream\ntasks including semantic segmentation, instance segmentation, and human\nparsing. Furthermore, our framework is successfully extended to several useful\napplications such as semi-automatic pixel-level annotation. Project page:\n\"http://mmlab.ie.cuhk.edu.hk/projects/CMP/\".\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:24:46 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 12:08:58 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 03:52:57 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Zhan", "Xiaohang", ""], ["Pan", "Xingang", ""], ["Liu", "Ziwei", ""], ["Lin", "Dahua", ""], ["Loy", "Chen Change", ""]]}, {"id": "1903.11420", "submitter": "Alicja Gosiewska", "authors": "Alicja Gosiewska and Przemyslaw Biecek", "title": "Do Not Trust Additive Explanations", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (XAI)has received a great deal of\nattention recently. Explainability is being presented as a remedy for the\ndistrust of complex and opaque models. Model agnostic methods such as LIME,\nSHAP, or Break Down promise instance-level interpretability for any complex\nmachine learning model. But how faithful are these additive explanations? Can\nwe rely on additive explanations for non-additive models?\n  In this paper, we (1) examine the behavior of the most popular instance-level\nexplanations under the presence of interactions, (2) introduce a new method\nthat detects interactions for instance-level explanations, (3) perform a large\nscale benchmark to see how frequently additive explanations may be misleading.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:37:30 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 06:20:49 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 15:19:18 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Gosiewska", "Alicja", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "1903.11421", "submitter": "Richard Jiang", "authors": "Ziping Jiang, Paul L. Chazot, M. Emre Celebi, Danny Crookes and\n  Richard Jiang", "title": "Social Behavioral Phenotyping of Drosophila with a2D-3D Hybrid CNN\n  Framework", "comments": null, "journal-ref": "IEEE Access 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioural phenotyping of Drosophila is an important means in biological and\nmedical research to identify genetic, pathologic or psychologic impact on\nanimal behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:41:17 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Jiang", "Ziping", ""], ["Chazot", "Paul L.", ""], ["Celebi", "M. Emre", ""], ["Crookes", "Danny", ""], ["Jiang", "Richard", ""]]}, {"id": "1903.11431", "submitter": "Bihan Wen Dr", "authors": "Bihan Wen, Saiprasad Ravishankar, Luke Pfister and Yoram Bresler", "title": "Transform Learning for Magnetic Resonance Image Reconstruction: From\n  Model-based Learning to Building Neural Networks", "comments": "Accepted to IEEE Signal Processing Magazine, Special Issue on\n  Computational MRI: Compressed Sensing and Beyond", "journal-ref": null, "doi": "10.1109/MSP.2019.2951469", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance imaging (MRI) is widely used in clinical practice, but it\nhas been traditionally limited by its slow data acquisition. Recent advances in\ncompressed sensing (CS) techniques for MRI reduce acquisition time while\nmaintaining high image quality. Whereas classical CS assumes the images are\nsparse in known analytical dictionaries or transform domains, methods using\nlearned image models for reconstruction have become popular. The model could be\npre-learned from datasets, or learned simultaneously with the reconstruction,\ni.e., blind CS (BCS). Besides the well-known synthesis dictionary model, recent\nadvances in transform learning (TL) provide an efficient alternative framework\nfor sparse modeling in MRI. TL-based methods enjoy numerous advantages\nincluding exact sparse coding, transform update, and clustering solutions,\ncheap computation, and convergence guarantees, and provide high-quality results\nin MRI compared to popular competing methods. This paper provides a review of\nsome recent works in MRI reconstruction from limited data, with focus on the\nrecent TL-based methods. A unified framework for incorporating various TL-based\nmodels is presented. We discuss the connections between transform learning and\nconvolutional or filter bank models and corresponding multi-layer extensions,\nwith connections to deep learning. Finally, we discuss recent trends in MRI,\nopen problems, and future directions for the field.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 03:13:18 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 13:26:01 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Wen", "Bihan", ""], ["Ravishankar", "Saiprasad", ""], ["Pfister", "Luke", ""], ["Bresler", "Yoram", ""]]}, {"id": "1903.11436", "submitter": "Alexey Zaytsev", "authors": "Evgenya Romanenkova, Alexey Zaytsev, Nikita Klyuchnikov, Arseniy\n  Gruzdev, Ksenia Antipova, Leyla Ismailova, Evgeny Burnaev, Artyom Semenikhin,\n  Vitaliy Koryabkin, Igor Simon, Dmitry Koroteev", "title": "Real-time data-driven detection of the rock type alteration during a\n  directional drilling", "comments": null, "journal-ref": null, "doi": "10.1109/LGRS.2019.2959845", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the directional drilling, a bit may sometimes go to a nonproductive\nrock layer due to the gap about 20m between the bit and high-fidelity rock type\nsensors. The only way to detect the lithotype changes in time is the usage of\nMeasurements While Drilling (MWD) data. However, there are no general\nmathematical modeling approaches that both well reconstruct the rock type based\non MWD data and correspond to specifics of the oil and gas industry. In this\narticle, we present a data-driven procedure that utilizes MWD data for quick\ndetection of changes in rock type. We propose the approach that combines\ntraditional machine learning based on the solution of the rock type\nclassification problem with change detection procedures rarely used before in\nthe Oil\\&Gas industry. The data come from a newly developed oilfield in the\nnorth of western Siberia. The results suggest that we can detect a significant\npart of changes in rock type reducing the change detection delay from $20$ to\n$1.8$ meters and the number of false-positive alarms from $43$ to $6$ per well.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:04:32 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 09:59:39 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Romanenkova", "Evgenya", ""], ["Zaytsev", "Alexey", ""], ["Klyuchnikov", "Nikita", ""], ["Gruzdev", "Arseniy", ""], ["Antipova", "Ksenia", ""], ["Ismailova", "Leyla", ""], ["Burnaev", "Evgeny", ""], ["Semenikhin", "Artyom", ""], ["Koryabkin", "Vitaliy", ""], ["Simon", "Igor", ""], ["Koroteev", "Dmitry", ""]]}, {"id": "1903.11451", "submitter": "Nino Antulov-Fantulin", "authors": "Johannes Beck, Roberta Huang, David Lindner, Tian Guo, Ce Zhang, Dirk\n  Helbing, Nino Antulov-Fantulin", "title": "Sensing Social Media Signals for Cryptocurrency News", "comments": "full version of the paper, that is accepted at ACM WWW '19\n  Conference, MSM'19 Workshop", "journal-ref": null, "doi": "10.1145/3308560.3316706", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to track and monitor relevant and important news in real-time is\nof crucial interest in multiple industrial sectors. In this work, we focus on\nthe set of cryptocurrency news, which recently became of emerging interest to\nthe general and financial audience. In order to track relevant news in\nreal-time, we (i) match news from the web with tweets from social media, (ii)\ntrack their intraday tweet activity and (iii) explore different machine\nlearning models for predicting the number of the article mentions on Twitter\nwithin the first 24 hours after its publication. We compare several machine\nlearning models, such as linear extrapolation, linear and random forest\nautoregressive models, and a sequence-to-sequence neural network. We find that\nthe random forest autoregressive model behaves comparably to more complex\nmodels in the majority of tasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:27:22 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Beck", "Johannes", ""], ["Huang", "Roberta", ""], ["Lindner", "David", ""], ["Guo", "Tian", ""], ["Zhang", "Ce", ""], ["Helbing", "Dirk", ""], ["Antulov-Fantulin", "Nino", ""]]}, {"id": "1903.11454", "submitter": "Milena \\v{C}uki\\'c Dr", "authors": "Milena Cukic Radenkovic", "title": "Machine learning approaches in Detecting the Depression from\n  Resting-state Electroencephalogram (EEG): A Review Study", "comments": "31 pages, 4 Figures. arXiv admin note: text overlap with\n  arXiv:1803.05985 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aimed at reviewing several different approaches present\ntoday in the search for more accurate diagnostic and treatment management in\nmental healthcare. Our focus is on mood disorders, and in particular on the\nmajor depressive disorder (MDD). We are reviewing and discussing findings based\non neuroimaging studies (MRI and fMRI) first to get the impression of the body\nof knowledge about the anatomical and functional differences in depression.\nThen, we are focusing on less expensive data-driven approach, applicable for\neveryday clinical practice, in particular, those based on\nelectroencephalographic (EEG) recordings. Among those studies utilizing EEG, we\nare discussing a group of applications used for detecting of depression based\non the resting state EEG (detection studies) and interventional studies (using\nstimulus in their protocols or aiming to predict the outcome of therapy). We\nconclude with a discussion and review of guidelines to improve the reliability\nof developed models that could serve improvement of diagnostic of depression in\npsychiatry.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 14:45:43 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Radenkovic", "Milena Cukic", ""]]}, {"id": "1903.11460", "submitter": "Chengjing Wang", "authors": "Peipei Tang, Chengjing Wang, Defeng Sun, and Kim-Chuan Toh", "title": "A sparse semismooth Newton based proximal majorization-minimization\n  algorithm for nonconvex square-root-loss regression problems", "comments": "34 pages, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider high-dimensional nonconvex square-root-loss\nregression problems and introduce a proximal majorization-minimization (PMM)\nalgorithm for these problems. Our key idea for making the proposed PMM to be\nefficient is to develop a sparse semismooth Newton method to solve the\ncorresponding subproblems. By using the Kurdyka-{\\L}ojasiewicz property\nexhibited in the underlining problems, we prove that the PMM algorithm\nconverges to a d-stationary point. We also analyze the oracle property of the\ninitial subproblem used in our algorithm. Extensive numerical experiments are\npresented to demonstrate the high efficiency of the proposed PMM algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:51:35 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 12:03:39 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 05:59:27 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Tang", "Peipei", ""], ["Wang", "Chengjing", ""], ["Sun", "Defeng", ""], ["Toh", "Kim-Chuan", ""]]}, {"id": "1903.11482", "submitter": "Ingo Steinwart", "authors": "Ingo Steinwart", "title": "A Sober Look at Neural Network Initializations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initializing the weights and the biases is a key part of the training process\nof a neural network. Unlike the subsequent optimization phase, however, the\ninitialization phase has gained only limited attention in the literature. In\nthis paper we discuss some consequences of commonly used initialization\nstrategies for vanilla DNNs with ReLU activations. Based on these insights we\nthen develop an alternative initialization strategy. Finally, we present some\nlarge scale experiments assessing the quality of the new initialization\nstrategy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 15:22:37 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 18:04:14 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Steinwart", "Ingo", ""]]}, {"id": "1903.11483", "submitter": "Erik Derner", "authors": "Erik Derner, Ji\\v{r}\\'i Kubal\\'ik, Nicola Ancona and Robert\n  Babu\\v{s}ka", "title": "Constructing Parsimonious Analytic Models for Dynamic Systems via\n  Symbolic Regression", "comments": null, "journal-ref": "Applied Soft Computing, Volume 94, September 2020, 106432", "doi": "10.1016/j.asoc.2020.106432", "report-no": null, "categories": "cs.LG cs.NE cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing mathematical models of dynamic systems is central to many\ndisciplines of engineering and science. Models facilitate simulations, analysis\nof the system's behavior, decision making and design of automatic control\nalgorithms. Even inherently model-free control techniques such as reinforcement\nlearning (RL) have been shown to benefit from the use of models, typically\nlearned online. Any model construction method must address the tradeoff between\nthe accuracy of the model and its complexity, which is difficult to strike. In\nthis paper, we propose to employ symbolic regression (SR) to construct\nparsimonious process models described by analytic equations. We have equipped\nour method with two different state-of-the-art SR algorithms which\nautomatically search for equations that fit the measured data: Single Node\nGenetic Programming (SNGP) and Multi-Gene Genetic Programming (MGGP). In\naddition to the standard problem formulation in the state-space domain, we show\nhow the method can also be applied to input-output models of the NARX\n(nonlinear autoregressive with exogenous input) type. We present the approach\non three simulated examples with up to 14-dimensional state space: an inverted\npendulum, a mobile robot, and a bipedal walking robot. A comparison with deep\nneural networks and local linear regression shows that SR in most cases\noutperforms these commonly used alternative methods. We demonstrate on a real\npendulum system that the analytic model found enables a RL controller to\nsuccessfully perform the swing-up task, based on a model constructed from only\n100 data samples.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 15:22:38 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 09:17:27 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Derner", "Erik", ""], ["Kubal\u00edk", "Ji\u0159\u00ed", ""], ["Ancona", "Nicola", ""], ["Babu\u0161ka", "Robert", ""]]}, {"id": "1903.11508", "submitter": "Steffen Eger", "authors": "Steffen Eger and G\\\"ozde G\\\"ul \\c{S}ahin and Andreas R\\\"uckl\\'e and\n  Ji-Ung Lee and Claudia Schulz and Mohsen Mesgar and Krishnkant Swarnkar and\n  Edwin Simpson and Iryna Gurevych", "title": "Text Processing Like Humans Do: Visually Attacking and Shielding NLP\n  Systems", "comments": "Accepted as long paper at NAACL-2019; fixed one ungrammatical\n  sentence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual modifications to text are often used to obfuscate offensive comments\nin social media (e.g., \"!d10t\") or as a writing style (\"1337\" in \"leet speak\"),\namong other scenarios. We consider this as a new type of adversarial attack in\nNLP, a setting to which humans are very robust, as our experiments with both\nsimple and more difficult visual input perturbations demonstrate. We then\ninvestigate the impact of visual adversarial attacks on current NLP systems on\ncharacter-, word-, and sentence-level tasks, showing that both neural and\nnon-neural models are, in contrast to humans, extremely sensitive to such\nattacks, suffering performance decreases of up to 82\\%. We then explore three\nshielding methods---visual character embeddings, adversarial training, and\nrule-based recovery---which substantially improve the robustness of the models.\nHowever, the shielding methods still fall behind performances achieved in\nnon-attack scenarios, which demonstrates the difficulty of dealing with visual\nattacks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 16:01:18 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 12:20:04 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Eger", "Steffen", ""], ["\u015eahin", "G\u00f6zde G\u00fcl", ""], ["R\u00fcckl\u00e9", "Andreas", ""], ["Lee", "Ji-Ung", ""], ["Schulz", "Claudia", ""], ["Mesgar", "Mohsen", ""], ["Swarnkar", "Krishnkant", ""], ["Simpson", "Edwin", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1903.11524", "submitter": "Dmytro Korenkevych", "authors": "Dmytro Korenkevych, A. Rupam Mahmood, Gautham Vasan, James Bergstra", "title": "Autoregressive Policies for Continuous Control Deep Reinforcement\n  Learning", "comments": "Submitted to 28th International Joint Conference on Artificial\n  Intelligence (IJCAI 2019). Video: https://youtu.be/NCpyXBNqNmw Code:\n  https://github.com/dkorenkevych/arp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms rely on exploration to discover new\nbehaviors, which is typically achieved by following a stochastic policy. In\ncontinuous control tasks, policies with a Gaussian distribution have been\nwidely adopted. Gaussian exploration however does not result in smooth\ntrajectories that generally correspond to safe and rewarding behaviors in\npractical tasks. In addition, Gaussian policies do not result in an effective\nexploration of an environment and become increasingly inefficient as the action\nrate increases. This contributes to a low sample efficiency often observed in\nlearning continuous control tasks. We introduce a family of stationary\nautoregressive (AR) stochastic processes to facilitate exploration in\ncontinuous control domains. We show that proposed processes possess two\ndesirable features: subsequent process observations are temporally coherent\nwith continuously adjustable degree of coherence, and the process stationary\ndistribution is standard normal. We derive an autoregressive policy (ARP) that\nimplements such processes maintaining the standard agent-environment interface.\nWe show how ARPs can be easily used with the existing off-the-shelf learning\nalgorithms. Empirically we demonstrate that using ARPs results in improved\nexploration and sample efficiency in both simulated and real world domains,\nand, furthermore, provides smooth exploration trajectories that enable safe\noperation of robotic hardware.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 16:22:48 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Korenkevych", "Dmytro", ""], ["Mahmood", "A. Rupam", ""], ["Vasan", "Gautham", ""], ["Bergstra", "James", ""]]}, {"id": "1903.11551", "submitter": "Mark Stamp", "authors": "Niket Bhodia, Pratikkumar Prajapati, Fabio Di Troia, Mark Stamp", "title": "Transfer Learning for Image-Based Malware Classification", "comments": "3rd International Workshop on Formal Methods for Security Engineering\n  (ForSE 2019), in conjunction with the 5th International Conference on\n  Information Systems Security and Privacy (ICISSP 2019), Prague, Czech\n  Republic, February 23-25, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of malware detection and\nclassification based on image analysis. We convert executable files to images\nand apply image recognition using deep learning (DL) models. To train these\nmodels, we employ transfer learning based on existing DL models that have been\npre-trained on massive image datasets. We carry out various experiments with\nthis technique and compare its performance to that of an extremely simple\nmachine learning technique, namely, k-nearest neighbors (\\kNN). For our k-NN\nexperiments, we use features extracted directly from executables, rather than\nimage analysis. While our image-based DL technique performs well in the\nexperiments, surprisingly, it is outperformed by k-NN. We show that DL models\nare better able to generalize the data, in the sense that they outperform k-NN\nin simulated zero-day experiments.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 02:15:53 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Bhodia", "Niket", ""], ["Prajapati", "Pratikkumar", ""], ["Di Troia", "Fabio", ""], ["Stamp", "Mark", ""]]}, {"id": "1903.11570", "submitter": "No\\'e Tits", "authors": "No\\'e Tits, Fengna Wang, Kevin El Haddad, Vincent Pagel, Thierry\n  Dutoit", "title": "Visualization and Interpretation of Latent Spaces for Controlling\n  Expressive Speech Synthesis through Audio Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Text-to-Speech has experienced huge improvements last years\nbenefiting from deep learning techniques. Producing realistic speech becomes\npossible now. As a consequence, the research on the control of the\nexpressiveness, allowing to generate speech in different styles or manners, has\nattracted increasing attention lately. Systems able to control style have been\ndeveloped and show impressive results. However the control parameters often\nconsist of latent variables and remain complex to interpret. In this paper, we\nanalyze and compare different latent spaces and obtain an interpretation of\ntheir influence on expressive speech. This will enable the possibility to build\ncontrollable speech synthesis systems with an understandable behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 17:33:33 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Tits", "No\u00e9", ""], ["Wang", "Fengna", ""], ["Haddad", "Kevin El", ""], ["Pagel", "Vincent", ""], ["Dutoit", "Thierry", ""]]}, {"id": "1903.11576", "submitter": "Shiqian Ma", "authors": "Shixiang Chen, Shiqian Ma, Lingzhou Xue, Hui Zou", "title": "An Alternating Manifold Proximal Gradient Method for Sparse PCA and\n  Sparse CCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse principal component analysis (PCA) and sparse canonical correlation\nanalysis (CCA) are two essential techniques from high-dimensional statistics\nand machine learning for analyzing large-scale data. Both problems can be\nformulated as an optimization problem with nonsmooth objective and nonconvex\nconstraints. Since non-smoothness and nonconvexity bring numerical\ndifficulties, most algorithms suggested in the literature either solve some\nrelaxations or are heuristic and lack convergence guarantees. In this paper, we\npropose a new alternating manifold proximal gradient method to solve these two\nhigh-dimensional problems and provide a unified convergence analysis. Numerical\nexperiment results are reported to demonstrate the advantages of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 17:44:00 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Chen", "Shixiang", ""], ["Ma", "Shiqian", ""], ["Xue", "Lingzhou", ""], ["Zou", "Hui", ""]]}, {"id": "1903.11593", "submitter": "Stephen Baek", "authors": "Stephen Baek, Yusen He, Bryan G. Allen, John M. Buatti, Brian J.\n  Smith, Ling Tong, Zhiyu Sun, Jia Wu, Maximilian Diehn, Billy W. Loo, Kristin\n  A. Plichta, Steven N. Seyedin, Maggie Gannon, Katherine R. Cabel, Yusung Kim,\n  Xiaodong Wu", "title": "Deep segmentation networks predict survival of non-small cell lung\n  cancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-small-cell lung cancer (NSCLC) represents approximately 80-85% of lung\ncancer diagnoses and is the leading cause of cancer-related death worldwide.\nRecent studies indicate that image-based radiomics features from positron\nemission tomography-computed tomography (PET/CT) images have predictive power\non NSCLC outcomes. To this end, easily calculated functional features such as\nthe maximum and the mean of standard uptake value (SUV) and total lesion\nglycolysis (TLG) are most commonly used for NSCLC prognostication, but their\nprognostic value remains controversial. Meanwhile, convolutional neural\nnetworks (CNN) are rapidly emerging as a new premise for cancer image analysis,\nwith significantly enhanced predictive power compared to other hand-crafted\nradiomics features. Here we show that CNN trained to perform the tumor\nsegmentation task, with no other information than physician contours, identify\na rich set of survival-related image features with remarkable prognostic value.\nIn a retrospective study on 96 NSCLC patients before stereotactic-body\nradiotherapy (SBRT), we found that the CNN segmentation algorithm (U-Net)\ntrained for tumor segmentation in PET/CT images, contained features having\nstrong correlation with 2- and 5-year overall and disease-specific survivals.\nThe U-net algorithm has not seen any other clinical information (e.g. survival,\nage, smoking history) than the images and the corresponding tumor contours\nprovided by physicians. Furthermore, through visualization of the U-Net, we\nalso found convincing evidence that the regions of progression appear to match\nwith the regions where the U-Net features identified patterns that predicted\nhigher likelihood of death. We anticipate our findings will be a starting point\nfor more sophisticated non-intrusive patient specific cancer prognosis\ndetermination.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 19:55:44 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 22:42:56 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Baek", "Stephen", ""], ["He", "Yusen", ""], ["Allen", "Bryan G.", ""], ["Buatti", "John M.", ""], ["Smith", "Brian J.", ""], ["Tong", "Ling", ""], ["Sun", "Zhiyu", ""], ["Wu", "Jia", ""], ["Diehn", "Maximilian", ""], ["Loo", "Billy W.", ""], ["Plichta", "Kristin A.", ""], ["Seyedin", "Steven N.", ""], ["Gannon", "Maggie", ""], ["Cabel", "Katherine R.", ""], ["Kim", "Yusung", ""], ["Wu", "Xiaodong", ""]]}, {"id": "1903.11626", "submitter": "Junghoon Seo", "authors": "Beomsu Kim, Junghoon Seo, Taegyun Jeon", "title": "Bridging Adversarial Robustness and Gradient Interpretability", "comments": "Accepted at the 2019 ICLR Workshop on Safe Machine Learning:\n  Specification, Robustness, and Assurance (SafeML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a training scheme designed to counter adversarial\nattacks by augmenting the training dataset with adversarial examples.\nSurprisingly, several studies have observed that loss gradients from\nadversarially trained DNNs are visually more interpretable than those from\nstandard DNNs. Although this phenomenon is interesting, there are only few\nworks that have offered an explanation. In this paper, we attempted to bridge\nthis gap between adversarial robustness and gradient interpretability. To this\nend, we identified that loss gradients from adversarially trained DNNs align\nbetter with human perception because adversarial training restricts gradients\ncloser to the image manifold. We then demonstrated that adversarial training\ncauses loss gradients to be quantitatively meaningful. Finally, we showed that\nunder the adversarial training framework, there exists an empirical trade-off\nbetween test accuracy and loss gradient interpretability and proposed two\npotential approaches to resolving this trade-off.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 18:06:06 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 07:35:00 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Kim", "Beomsu", ""], ["Seo", "Junghoon", ""], ["Jeon", "Taegyun", ""]]}, {"id": "1903.11672", "submitter": "Mimansa Jaiswal", "authors": "Mimansa Jaiswal, Zakaria Aldeneh, Cristian-Paul Bara, Yuanhang Luo,\n  Mihai Burzo, Rada Mihalcea, Emily Mower Provost", "title": "MuSE-ing on the Impact of Utterance Ordering On Crowdsourced Emotion\n  Annotations", "comments": "5 pages, ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.HC cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition algorithms rely on data annotated with high quality\nlabels. However, emotion expression and perception are inherently subjective.\nThere is generally not a single annotation that can be unambiguously declared\n\"correct\". As a result, annotations are colored by the manner in which they\nwere collected. In this paper, we conduct crowdsourcing experiments to\ninvestigate this impact on both the annotations themselves and on the\nperformance of these algorithms. We focus on one critical question: the effect\nof context. We present a new emotion dataset, Multimodal Stressed Emotion\n(MuSE), and annotate the dataset using two conditions: randomized, in which\nannotators are presented with clips in random order, and contextualized, in\nwhich annotators are presented with clips in order. We find that contextual\nlabeling schemes result in annotations that are more similar to a speaker's own\nself-reported labels and that labels generated from randomized schemes are most\neasily predictable by automated systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 19:49:00 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Jaiswal", "Mimansa", ""], ["Aldeneh", "Zakaria", ""], ["Bara", "Cristian-Paul", ""], ["Luo", "Yuanhang", ""], ["Burzo", "Mihai", ""], ["Mihalcea", "Rada", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1903.11673", "submitter": "Ozan Ozdenizci", "authors": "Ozan Ozdenizci, Ye Wang, Toshiaki Koike-Akino, Deniz Erdogmus", "title": "Adversarial Deep Learning in EEG Biometrics", "comments": "Accepted for publication by IEEE Signal Processing Letters", "journal-ref": "IEEE Signal Processing Letters, 2019", "doi": "10.1109/LSP.2019.2906826", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods for person identification based on\nelectroencephalographic (EEG) brain activity encounters the problem of\nexploiting the temporally correlated structures or recording session specific\nvariability within EEG. Furthermore, recent methods have mostly trained and\nevaluated based on single session EEG data. We address this problem from an\ninvariant representation learning perspective. We propose an adversarial\ninference approach to extend such deep learning models to learn\nsession-invariant person-discriminative representations that can provide\nrobustness in terms of longitudinal usability. Using adversarial learning\nwithin a deep convolutional network, we empirically assess and show\nimprovements with our approach based on longitudinally collected EEG data for\nperson identification from half-second EEG epochs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 19:50:24 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Ozdenizci", "Ozan", ""], ["Wang", "Ye", ""], ["Koike-Akino", "Toshiaki", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "1903.11680", "submitter": "Samet Oymak", "authors": "Mingchen Li, Mahdi Soltanolkotabi, Samet Oymak", "title": "Gradient Descent with Early Stopping is Provably Robust to Label Noise\n  for Overparameterized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks are typically trained in an over-parameterized regime\nwhere the parameters of the model far exceed the size of the training data.\nSuch neural networks in principle have the capacity to (over)fit any set of\nlabels including pure noise. Despite this, somewhat paradoxically, neural\nnetwork models trained via first-order methods continue to predict well on yet\nunseen test data. This paper takes a step towards demystifying this phenomena.\nUnder a rich dataset model, we show that gradient descent is provably robust to\nnoise/corruption on a constant fraction of the labels despite\noverparameterization. In particular, we prove that: (i) In the first few\niterations where the updates are still in the vicinity of the initialization\ngradient descent only fits to the correct labels essentially ignoring the noisy\nlabels. (ii) to start to overfit to the noisy labels network must stray rather\nfar from from the initialization which can only occur after many more\niterations. Together, these results show that gradient descent with early\nstopping is provably robust to label noise and shed light on the empirical\nrobustness of deep networks as well as commonly adopted heuristics to prevent\noverfitting.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 20:00:15 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 19:57:05 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2019 23:48:05 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Li", "Mingchen", ""], ["Soltanolkotabi", "Mahdi", ""], ["Oymak", "Samet", ""]]}, {"id": "1903.11683", "submitter": "Vasileios Tzoumas", "authors": "Vasileios Tzoumas, Pasquale Antonante, Luca Carlone", "title": "Outlier-Robust Spatial Perception: Hardness, General-Purpose Algorithms,\n  and Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.RO cs.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial perception is the backbone of many robotics applications, and spans a\nbroad range of research problems, including localization and mapping, point\ncloud alignment, and relative pose estimation from camera images. Robust\nspatial perception is jeopardized by the presence of incorrect data\nassociation, and in general, outliers. Although techniques to handle outliers\ndo exist, they can fail in unpredictable manners (e.g., RANSAC, robust\nestimators), or can have exponential runtime (e.g., branch-and-bound). In this\npaper, we advance the state of the art in outlier rejection by making three\ncontributions. First, we show that even a simple linear instance of outlier\nrejection is inapproximable: in the worst-case one cannot design a\nquasi-polynomial time algorithm that computes an approximate solution\nefficiently. Our second contribution is to provide the first per-instance\nsub-optimality bounds to assess the approximation quality of a given outlier\nrejection outcome. Our third contribution is to propose a simple\ngeneral-purpose algorithm, named adaptive trimming, to remove outliers. Our\nalgorithm leverages recently-proposed global solvers that are able to solve\noutlier-free problems, and iteratively removes measurements with large errors.\nWe demonstrate the proposed algorithm on three spatial perception problems: 3D\nregistration, two-view geometry, and SLAM. The results show that our algorithm\noutperforms several state-of-the-art methods across applications while being a\ngeneral-purpose method.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 20:12:37 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 19:46:50 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Tzoumas", "Vasileios", ""], ["Antonante", "Pasquale", ""], ["Carlone", "Luca", ""]]}, {"id": "1903.11688", "submitter": "Joseph Clements", "authors": "Joseph Clements, Yuzhe Yang, Ankur Sharma, Hongxin Hu, Yingjie Lao", "title": "Rallying Adversarial Techniques against Deep Learning for Network\n  Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence and the increasing need for\npowerful defensive measures in the domain of network security, have led to the\nadoption of deep learning approaches for use in network intrusion detection\nsystems. These methods have achieved superior performance against conventional\nnetwork attacks, which enable the deployment of practical security systems to\nunique and dynamic sectors. Adversarial machine learning, unfortunately, has\nrecently shown that deep learning models are inherently vulnerable to\nadversarial modifications on their input data. Because of this susceptibility,\nthe deep learning models deployed to power a network defense could in fact be\nthe weakest entry point for compromising a network system. In this paper, we\nshow that by modifying on average as little as 1.38 of the input features, an\nadversary can generate malicious inputs which effectively fool a deep learning\nbased NIDS. Therefore, when designing such systems, it is crucial to consider\nthe performance from not only the conventional network security perspective but\nalso the adversarial machine learning domain.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 20:33:55 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Clements", "Joseph", ""], ["Yang", "Yuzhe", ""], ["Sharma", "Ankur", ""], ["Hu", "Hongxin", ""], ["Lao", "Yingjie", ""]]}, {"id": "1903.11690", "submitter": "Emanuel Laude", "authors": "Emanuel Laude and Tao Wu and Daniel Cremers", "title": "Optimization of Inf-Convolution Regularized Nonconvex Composite Problems", "comments": "Accepted as a Conference Paper to International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2019, Naha", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider nonconvex composite problems that involve\ninf-convolution with a Legendre function, which gives rise to an anisotropic\ngeneralization of the proximal mapping and Moreau-envelope. In a convex setting\nsuch problems can be solved via alternating minimization of a splitting\nformulation, where the consensus constraint is penalized with a Legendre\nfunction. In contrast, for nonconvex models it is in general unclear that this\napproach yields stationary points to the infimal convolution problem. To this\nend we analytically investigate local regularity properties of the\nMoreau-envelope function under prox-regularity, which allows us to establish\nthe equivalence between stationary points of the splitting model and the\noriginal inf-convolution model. We apply our theory to characterize stationary\npoints of the penalty objective, which is minimized by the elastic averaging\nSGD (EASGD) method for distributed training. Numerically, we demonstrate the\npractical relevance of the proposed approach on the important task of\ndistributed training of deep neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 20:37:17 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Laude", "Emanuel", ""], ["Wu", "Tao", ""], ["Cremers", "Daniel", ""]]}, {"id": "1903.11691", "submitter": "Pietro Verzelli", "authors": "Pietro Verzelli and Cesare Alippi and Lorenzo Livi", "title": "Echo State Networks with Self-Normalizing Activations on the\n  Hyper-Sphere", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-019-50158-4", "report-no": null, "categories": "cs.NE cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the various architectures of Recurrent Neural Networks, Echo State\nNetworks (ESNs) emerged due to their simplified and inexpensive training\nprocedure. These networks are known to be sensitive to the setting of\nhyper-parameters, which critically affect their behaviour. Results show that\ntheir performance is usually maximized in a narrow region of hyper-parameter\nspace called edge of chaos. Finding such a region requires searching in\nhyper-parameter space in a sensible way: hyper-parameter configurations\nmarginally outside such a region might yield networks exhibiting fully\ndeveloped chaos, hence producing unreliable computations. The performance gain\ndue to optimizing hyper-parameters can be studied by considering the\nmemory--nonlinearity trade-off, i.e., the fact that increasing the nonlinear\nbehavior of the network degrades its ability to remember past inputs, and\nvice-versa. In this paper, we propose a model of ESNs that eliminates critical\ndependence on hyper-parameters, resulting in networks that provably cannot\nenter a chaotic regime and, at the same time, denotes nonlinear behaviour in\nphase space characterised by a large memory of past inputs, comparable to the\none of linear networks. Our contribution is supported by experiments\ncorroborating our theoretical findings, showing that the proposed model\ndisplays dynamics that are rich-enough to approximate many common nonlinear\nsystems used for benchmarking.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 20:37:40 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 16:06:55 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Verzelli", "Pietro", ""], ["Alippi", "Cesare", ""], ["Livi", "Lorenzo", ""]]}, {"id": "1903.11696", "submitter": "Carel F.W. Peeters", "authors": "Carel F.W. Peeters, Caroline \\\"Ubelh\\\"or, Steven W. Mes, Roland\n  Martens, Thomas Koopman, Pim de Graaf, Floris H.P. van Velden, Ronald\n  Boellaard, Jonas A. Castelijns, Dennis E. te Beest, Martijn W. Heymans, Mark\n  A. van de Wiel", "title": "Stable prediction with radiomics data", "comments": "52 pages: 14 pages Main Text and 38 pages of Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV q-bio.QM stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Radiomics refers to the high-throughput mining of quantitative\nfeatures from radiographic images. It is a promising field in that it may\nprovide a non-invasive solution for screening and classification. Standard\nmachine learning classification and feature selection techniques, however, tend\nto display inferior performance in terms of (the stability of) predictive\nperformance. This is due to the heavy multicollinearity present in radiomic\ndata. We set out to provide an easy-to-use approach that deals with this\nproblem.\n  Results: We developed a four-step approach that projects the original\nhigh-dimensional feature space onto a lower-dimensional latent-feature space,\nwhile retaining most of the covariation in the data. It consists of (i)\npenalized maximum likelihood estimation of a redundancy filtered correlation\nmatrix. The resulting matrix (ii) is the input for a maximum likelihood factor\nanalysis procedure. This two-stage maximum-likelihood approach can be used to\n(iii) produce a compact set of stable features that (iv) can be directly used\nin any (regression-based) classifier or predictor. It outperforms other\nclassification (and feature selection) techniques in both external and internal\nvalidation settings regarding survival in squamous cell cancers.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 20:45:58 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Peeters", "Carel F. W.", ""], ["\u00dcbelh\u00f6r", "Caroline", ""], ["Mes", "Steven W.", ""], ["Martens", "Roland", ""], ["Koopman", "Thomas", ""], ["de Graaf", "Pim", ""], ["van Velden", "Floris H. P.", ""], ["Boellaard", "Ronald", ""], ["Castelijns", "Jonas A.", ""], ["Beest", "Dennis E. te", ""], ["Heymans", "Martijn W.", ""], ["van de Wiel", "Mark A.", ""]]}, {"id": "1903.11701", "submitter": "Debasmit Das", "authors": "Debasmit Das and C. S. George Lee", "title": "Zero-shot Image Recognition Using Relational Matching, Adaptation and\n  Calibration", "comments": "International Joint Conference on Neural Networks (IJCNN) 2019.\n  Copyright 2019 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) for image classification focuses on recognizing\nnovel categories that have no labeled data available for training. The learning\nis generally carried out with the help of mid-level semantic descriptors\nassociated with each class. This semantic-descriptor space is generally shared\nby both seen and unseen categories. However, ZSL suffers from hubness, domain\ndiscrepancy and biased-ness towards seen classes. To tackle these problems, we\npropose a three-step approach to zero-shot learning. Firstly, a mapping is\nlearned from the semantic-descriptor space to the image-feature space. This\nmapping learns to minimize both one-to-one and pairwise distances between\nsemantic embeddings and the image features of the corresponding classes.\nSecondly, we propose test-time domain adaptation to adapt the semantic\nembedding of the unseen classes to the test data. This is achieved by finding\ncorrespondences between the semantic descriptors and the image features.\nThirdly, we propose scaled calibration on the classification scores of the seen\nclasses. This is necessary because the ZSL model is biased towards seen classes\nas the unseen classes are not used in the training. Finally, to validate the\nproposed three-step approach, we performed experiments on four benchmark\ndatasets where the proposed method outperformed previous results. We also\nstudied and analyzed the performance of each component of our proposed ZSL\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 21:07:00 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Das", "Debasmit", ""], ["Lee", "C. S. George", ""]]}, {"id": "1903.11703", "submitter": "Minh Tu Hoang", "authors": "Minh Tu Hoang, Brosnan Yuen, Xiaodai Dong, Tao Lu, Robert Westendorp,\n  and Kishore Reddy", "title": "Recurrent Neural Networks For Accurate RSSI Indoor Localization", "comments": "Received signal strength indicator (RSSI), WiFi indoor localization,\n  recurrent neuron network (RNN), long shortterm memory (LSTM),\n  fingerprint-based localization", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes recurrent neuron networks (RNNs) for a fingerprinting\nindoor localization using WiFi. Instead of locating user's position one at a\ntime as in the cases of conventional algorithms, our RNN solution aims at\ntrajectory positioning and takes into account the relation among the received\nsignal strength indicator (RSSI) measurements in a trajectory. Furthermore, a\nweighted average filter is proposed for both input RSSI data and sequential\noutput locations to enhance the accuracy among the temporal fluctuations of\nRSSI. The results using different types of RNN including vanilla RNN, long\nshort-term memory (LSTM), gated recurrent unit (GRU) and bidirectional LSTM\n(BiLSTM) are presented. On-site experiments demonstrate that the proposed\nstructure achieves an average localization error of $0.75$ m with $80\\%$ of the\nerrors under $1$ m, which outperforms the conventional KNN algorithms and\nprobabilistic algorithms by approximately $30\\%$ under the same test\nenvironment.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 21:14:12 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 19:08:32 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Hoang", "Minh Tu", ""], ["Yuen", "Brosnan", ""], ["Dong", "Xiaodai", ""], ["Lu", "Tao", ""], ["Westendorp", "Robert", ""], ["Reddy", "Kishore", ""]]}, {"id": "1903.11719", "submitter": "Aria Khademi", "authors": "Aria Khademi, Sanghack Lee, David Foley, Vasant Honavar", "title": "Fairness in Algorithmic Decision Making: An Excursion Through the Lens\n  of Causality", "comments": "7 pages, 2 figures, 2 tables.To appear in Proceedings of the\n  International Conference on World Wide Web (WWW), 2019", "journal-ref": null, "doi": "10.1145/3308558.3313559", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As virtually all aspects of our lives are increasingly impacted by\nalgorithmic decision making systems, it is incumbent upon us as a society to\nensure such systems do not become instruments of unfair discrimination on the\nbasis of gender, race, ethnicity, religion, etc. We consider the problem of\ndetermining whether the decisions made by such systems are discriminatory,\nthrough the lens of causal models. We introduce two definitions of group\nfairness grounded in causality: fair on average causal effect (FACE), and fair\non average causal effect on the treated (FACT). We use the Rubin-Neyman\npotential outcomes framework for the analysis of cause-effect relationships to\nrobustly estimate FACE and FACT. We demonstrate the effectiveness of our\nproposed approach on synthetic data. Our analyses of two real-world data sets,\nthe Adult income data set from the UCI repository (with gender as the protected\nattribute), and the NYC Stop and Frisk data set (with race as the protected\nattribute), show that the evidence of discrimination obtained by FACE and FACT,\nor lack thereof, is often in agreement with the findings from other studies. We\nfurther show that FACT, being somewhat more nuanced compared to FACE, can yield\nfindings of discrimination that differ from those obtained using FACE.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 22:27:22 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Khademi", "Aria", ""], ["Lee", "Sanghack", ""], ["Foley", "David", ""], ["Honavar", "Vasant", ""]]}, {"id": "1903.11726", "submitter": "Ervin Sejdic", "authors": "Zhenwei Zhang and Ervin Sejdic", "title": "Radiological images and machine learning: trends, perspectives, and\n  prospects", "comments": "13 figures", "journal-ref": "Computers in Biology and Medicine (2019)", "doi": "10.1016/j.compbiomed.2019.02.017", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of machine learning to radiological images is an increasingly\nactive research area that is expected to grow in the next five to ten years.\nRecent advances in machine learning have the potential to recognize and\nclassify complex patterns from different radiological imaging modalities such\nas x-rays, computed tomography, magnetic resonance imaging and positron\nemission tomography imaging. In many applications, machine learning based\nsystems have shown comparable performance to human decision-making. The\napplications of machine learning are the key ingredients of future clinical\ndecision making and monitoring systems. This review covers the fundamental\nconcepts behind various machine learning techniques and their applications in\nseveral radiological imaging areas, such as medical image segmentation, brain\nfunction studies and neurological disease diagnosis, as well as computer-aided\nsystems, image registration, and content-based image retrieval systems.\nSynchronistically, we will briefly discuss current challenges and future\ndirections regarding the application of machine learning in radiological\nimaging. By giving insight on how take advantage of machine learning powered\napplications, we expect that clinicians can prevent and diagnose diseases more\naccurately and efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 23:11:15 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Zhang", "Zhenwei", ""], ["Sejdic", "Ervin", ""]]}, {"id": "1903.11734", "submitter": "Chao Shang", "authors": "Chao Shang and Fengqi You", "title": "A Posteriori Probabilistic Bounds of Convex Scenario Programs with\n  Validation Tests", "comments": null, "journal-ref": "IEEE Transactions on Automatic Control (2021)", "doi": "10.1109/TAC.2020.3024273", "report-no": null, "categories": "math.OC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario programs have established themselves as efficient tools towards\ndecision-making under uncertainty. To assess the quality of scenario-based\nsolutions a posteriori, validation tests based on Bernoulli trials have been\nwidely adopted in practice. However, to reach a theoretically reliable\njudgement of risk, one typically needs to collect massive validation samples.\nIn this work, we propose new a posteriori bounds for convex scenario programs\nwith validation tests, which are dependent on both realizations of support\nconstraints and performance on out-of-sample validation data. The proposed\nbounds enjoy wide generality in that many existing theoretical results can be\nincorporated as particular cases. To facilitate practical use, a systematic\napproach for parameterizing a posteriori probability bounds is also developed,\nwhich is shown to possess a variety of desirable properties allowing for easy\nimplementations and clear interpretations. By synthesizing comprehensive\ninformation about support constraints and validation tests, improved risk\nevaluation can be achieved for randomized solutions in comparison with existing\na posteriori bounds. Case studies on controller design of aircraft lateral\nmotion are presented to validate the effectiveness of the proposed a posteriori\nbounds.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 23:53:36 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 14:46:17 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 12:43:52 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Shang", "Chao", ""], ["You", "Fengqi", ""]]}, {"id": "1903.11748", "submitter": "Lei Lin", "authors": "Lei Lin, Beilei Xu, Wencheng Wu, Trevor Richardson, Edgar A. Bernal", "title": "Medical Time Series Classification with Hierarchical Attention-based\n  Temporal Convolutional Networks: A Case Study of Myotonic Dystrophy Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Myotonia, which refers to delayed muscle relaxation after contraction, is the\nmain symptom of myotonic dystrophy patients. We propose a hierarchical\nattention-based temporal convolutional network (HA-TCN) for myotonic dystrohpy\ndiagnosis from handgrip time series data, and introduce mechanisms that enable\nmodel explainability. We compare the performance of the HA-TCN model against\nthat of benchmark TCN models, LSTM models with and without attention\nmechanisms, and SVM approaches with handcrafted features. In terms of\nclassification accuracy and F1 score, we found all deep learning models have\nsimilar levels of performance, and they all outperform SVM. Further, the HA-TCN\nmodel outperforms its TCN counterpart with regards to computational efficiency\nregardless of network depth, and in terms of performance particularly when the\nnumber of hidden layers is small. Lastly, HA-TCN models can consistently\nidentify relevant time series segments in the relaxation phase of the handgrip\ntime series, and exhibit increased robustness to noise when compared to\nattention-based LSTM models.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 01:14:31 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Lin", "Lei", ""], ["Xu", "Beilei", ""], ["Wu", "Wencheng", ""], ["Richardson", "Trevor", ""], ["Bernal", "Edgar A.", ""]]}, {"id": "1903.11774", "submitter": "Quan Vuong", "authors": "Quan Vuong, Sharad Vikram, Hao Su, Sicun Gao, Henrik I. Christensen", "title": "How to pick the domain randomization parameters for sim-to-real transfer\n  of reinforcement learning policies?", "comments": "2-page extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, reinforcement learning (RL) algorithms have demonstrated remarkable\nsuccess in learning complicated behaviors from minimally processed input.\nHowever, most of this success is limited to simulation. While there are\npromising successes in applying RL algorithms directly on real systems, their\nperformance on more complex systems remains bottle-necked by the relative data\ninefficiency of RL algorithms. Domain randomization is a promising direction of\nresearch that has demonstrated impressive results using RL algorithms to\ncontrol real robots. At a high level, domain randomization works by training a\npolicy on a distribution of environmental conditions in simulation. If the\nenvironments are diverse enough, then the policy trained on this distribution\nwill plausibly generalize to the real world. A human-specified design choice in\ndomain randomization is the form and parameters of the distribution of\nsimulated environments. It is unclear how to the best pick the form and\nparameters of this distribution and prior work uses hand-tuned distributions.\nThis extended abstract demonstrates that the choice of the distribution plays a\nmajor role in the performance of the trained policies in the real world and\nthat the parameter of this distribution can be optimized to maximize the\nperformance of the trained policies in the real world\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 03:24:44 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Vuong", "Quan", ""], ["Vikram", "Sharad", ""], ["Su", "Hao", ""], ["Gao", "Sicun", ""], ["Christensen", "Henrik I.", ""]]}, {"id": "1903.11775", "submitter": "Hamid Tizhoosh", "authors": "Sara Ross-Howe and H.R. Tizhoosh", "title": "Atrial Fibrillation Detection Using Deep Features and Convolutional\n  Networks", "comments": "Accepted for publication in the IEEE-EMBS International Conference on\n  Biomedical and Health Informatics (BHI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atrial fibrillation is a cardiac arrhythmia that affects an estimated 33.5\nmillion people globally and is the potential cause of 1 in 3 strokes in people\nover the age of 60. Detection and diagnosis of atrial fibrillation (AFIB) is\ndone noninvasively in the clinical environment through the evaluation of\nelectrocardiograms (ECGs). Early research into automated methods for the\ndetection of AFIB in ECG signals focused on traditional bio-medical signal\nanalysis to extract important features for use in statistical classification\nmodels. Artificial intelligence models have more recently been used that employ\nconvolutional and/or recurrent network architectures. In this work, significant\ntime and frequency domain characteristics of the ECG signal are extracted by\napplying the short-time Fourier trans-form and then visually representing the\ninformation in a spectrogram. Two different classification approaches were\ninvestigated that utilized deep features in the spectrograms construct-ed from\nECG segments. The first approach used a pretrained DenseNet model to extract\nfeatures that were then classified using Support Vector Machines, and the\nsecond approach used the spectrograms as direct input into a convolutional\nnetwork. Both approaches were evaluated against the MIT-BIH AFIB dataset, where\nthe convolutional network approach achieved a classification accuracy of\n93.16%. While these results do not surpass established automated atrial\nfibrillation detection methods, they are promising and warrant further\ninvestigation given they did not require any noise prefiltering, hand-crafted\nfeatures, nor a reliance on beat detection.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 03:30:25 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Ross-Howe", "Sara", ""], ["Tizhoosh", "H. R.", ""]]}, {"id": "1903.11780", "submitter": "Sherjil Ozair", "authors": "Sherjil Ozair, Corey Lynch, Yoshua Bengio, Aaron van den Oord, Sergey\n  Levine, Pierre Sermanet", "title": "Wasserstein Dependency Measure for Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual information maximization has emerged as a powerful learning objective\nfor unsupervised representation learning obtaining state-of-the-art performance\nin applications such as object recognition, speech recognition, and\nreinforcement learning. However, such approaches are fundamentally limited\nsince a tight lower bound of mutual information requires sample size\nexponential in the mutual information. This limits the applicability of these\napproaches for prediction tasks with high mutual information, such as in video\nunderstanding or reinforcement learning. In these settings, such techniques are\nprone to overfit, both in theory and in practice, and capture only a few of the\nrelevant factors of variation. This leads to incomplete representations that\nare not optimal for downstream tasks. In this work, we empirically demonstrate\nthat mutual information-based representation learning approaches do fail to\nlearn complete representations on a number of designed and real-world tasks. To\nmitigate these problems we introduce the Wasserstein dependency measure, which\nlearns more complete representations by using the Wasserstein distance instead\nof the KL divergence in the mutual information estimator. We show that a\npractical approximation to this theoretically motivated solution, constructed\nusing Lipschitz constraint techniques from the GAN literature, achieves\nsubstantially improved results on tasks where incomplete representations are a\nmajor challenge.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 03:51:17 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Ozair", "Sherjil", ""], ["Lynch", "Corey", ""], ["Bengio", "Yoshua", ""], ["Oord", "Aaron van den", ""], ["Levine", "Sergey", ""], ["Sermanet", "Pierre", ""]]}, {"id": "1903.11788", "submitter": "Denis Derkach", "authors": "Denis Derkach, Nikita Kazeev, Fedor Ratnikov, Andrey Ustyuzhanin,\n  Alexandra Volokhova", "title": "Cherenkov Detectors Fast Simulation Using Neural Networks", "comments": "In proceedings of 10th International Workshop on Ring Imaging\n  Cherenkov Detectors", "journal-ref": null, "doi": "10.1016/j.nima.2019.01.031", "report-no": null, "categories": "hep-ex cs.LG physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a way to simulate Cherenkov detector response using a generative\nadversarial neural network to bypass low-level details. This network is trained\nto reproduce high level features of the simulated detector events based on\ninput observables of incident particles. This allows the dramatic increase of\nsimulation speed. We demonstrate that this approach provides simulation\nprecision which is consistent with the baseline and discuss possible\nimplications of these results.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 05:18:11 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Derkach", "Denis", ""], ["Kazeev", "Nikita", ""], ["Ratnikov", "Fedor", ""], ["Ustyuzhanin", "Andrey", ""], ["Volokhova", "Alexandra", ""]]}, {"id": "1903.11789", "submitter": "Evan N. Feinberg", "authors": "Evan N. Feinberg, Robert Sheridan, Elizabeth Joshi, Vijay S. Pande,\n  Alan C. Cheng", "title": "Step Change Improvement in ADMET Prediction with PotentialNet Deep\n  Featurization", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Absorption, Distribution, Metabolism, Elimination, and Toxicity (ADMET)\nproperties of drug candidates are estimated to account for up to 50% of all\nclinical trial failures. Predicting ADMET properties has therefore been of\ngreat interest to the cheminformatics and medicinal chemistry communities in\nrecent decades. Traditional cheminformatics approaches, whether the learner is\na random forest or a deep neural network, leverage fixed fingerprint feature\nrepresentations of molecules. In contrast, in this paper, we learn the features\nmost relevant to each chemical task at hand by representing each molecule\nexplicitly as a graph, where each node is an atom and each edge is a bond. By\napplying graph convolutions to this explicit molecular representation, we\nachieve, to our knowledge, unprecedented accuracy in prediction of ADMET\nproperties. By challenging our methodology with rigorous cross-validation\nprocedures and prospective analyses, we show that deep featurization better\nenables molecular predictors to not only interpolate but also extrapolate to\nnew regions of chemical space.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 05:18:28 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Feinberg", "Evan N.", ""], ["Sheridan", "Robert", ""], ["Joshi", "Elizabeth", ""], ["Pande", "Vijay S.", ""], ["Cheng", "Alan C.", ""]]}, {"id": "1903.11834", "submitter": "Chen Xueying", "authors": "Xueying Chen, Rong Zhang, Pingkun Yan", "title": "Feature Fusion Encoder Decoder Network For Automatic Liver Lesion\n  Segmentation", "comments": "4 pages, 2 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Liver lesion segmentation is a difficult yet critical task for medical image\nanalysis. Recently, deep learning based image segmentation methods have\nachieved promising performance, which can be divided into three categories: 2D,\n2.5D and 3D, based on the dimensionality of the models. However, 2.5D and 3D\nmethods can have very high complexity and 2D methods may not perform\nsatisfactorily. To obtain competitive performance with low complexity, in this\npaper, we propose a Feature-fusion Encoder-Decoder Network (FED-Net) based 2D\nsegmentation model to tackle the challenging problem of liver lesion\nsegmentation from CT images. Our feature fusion method is based on the\nattention mechanism, which fuses high-level features carrying semantic\ninformation with low-level features having image details. Additionally, to\ncompensate for the information loss during the upsampling process, a dense\nupsampling convolution and a residual convolutional structure are proposed. We\ntested our method on the dataset of MICCAI 2017 Liver Tumor Segmentation (LiTS)\nChallenge and achieved competitive results compared with other state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 08:39:49 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Chen", "Xueying", ""], ["Zhang", "Rong", ""], ["Yan", "Pingkun", ""]]}, {"id": "1903.11835", "submitter": "Nils Kriege", "authors": "Nils M. Kriege, Fredrik D. Johansson, Christopher Morris", "title": "A Survey on Graph Kernels", "comments": null, "journal-ref": "Applied Network Science 5 (2020)", "doi": "10.1007/s41109-019-0195-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph kernels have become an established and widely-used technique for\nsolving classification tasks on graphs. This survey gives a comprehensive\noverview of techniques for kernel-based graph classification developed in the\npast 15 years. We describe and categorize graph kernels based on properties\ninherent to their design, such as the nature of their extracted graph features,\ntheir method of computation and their applicability to problems in practice. In\nan extensive experimental evaluation, we study the classification accuracy of a\nlarge suite of graph kernels on established benchmarks as well as new datasets.\nWe compare the performance of popular kernels with several baseline methods and\nstudy the effect of applying a Gaussian RBF kernel to the metric induced by a\ngraph kernel. In doing so, we find that simple baselines become competitive\nafter this transformation on some datasets. Moreover, we study the extent to\nwhich existing graph kernels agree in their predictions (and prediction errors)\nand obtain a data-driven categorization of kernels as result. Finally, based on\nour experimental results, we derive a practitioner's guide to kernel-based\ngraph classification.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 08:44:21 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 13:08:07 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Kriege", "Nils M.", ""], ["Johansson", "Fredrik D.", ""], ["Morris", "Christopher", ""]]}, {"id": "1903.11900", "submitter": "Riccardo Volpi", "authors": "Riccardo Volpi, Vittorio Murino", "title": "Addressing Model Vulnerability to Distributional Shifts over Image\n  Transformation Sets", "comments": "ICCV 2019 (camera ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are concerned with the vulnerability of computer vision models to\ndistributional shifts. We formulate a combinatorial optimization problem that\nallows evaluating the regions in the image space where a given model is more\nvulnerable, in terms of image transformations applied to the input, and face it\nwith standard search algorithms. We further embed this idea in a training\nprocedure, where we define new data augmentation rules according to the image\ntransformations that the current model is most vulnerable to, over iterations.\nAn empirical evaluation on classification and semantic segmentation problems\nsuggests that the devised algorithm allows to train models that are more robust\nagainst content-preserving image manipulations and, in general, against\ndistributional shifts.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 11:24:38 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 09:51:24 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Volpi", "Riccardo", ""], ["Murino", "Vittorio", ""]]}, {"id": "1903.11907", "submitter": "Jonathan Schwarz", "authors": "Alexandre Galashov, Jonathan Schwarz, Hyunjik Kim, Marta Garnelo,\n  David Saxton, Pushmeet Kohli, S.M. Ali Eslami, Yee Whye Teh", "title": "Meta-Learning surrogate models for sequential decision making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a unified probabilistic framework for solving sequential\ndecision making problems ranging from Bayesian optimisation to contextual\nbandits and reinforcement learning. This is accomplished by a probabilistic\nmodel-based approach that explains observed data while capturing predictive\nuncertainty during the decision making process. Crucially, this probabilistic\nmodel is chosen to be a Meta-Learning system that allows learning from a\ndistribution of related problems, allowing data efficient adaptation to a\ntarget task. As a suitable instantiation of this framework, we explore the use\nof Neural processes due to statistical and computational desiderata. We apply\nour framework to a broad range of problem domains, such as control problems,\nrecommender systems and adversarial attacks on RL agents, demonstrating an\nefficient and general black-box learning approach.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 11:57:54 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 11:38:15 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Galashov", "Alexandre", ""], ["Schwarz", "Jonathan", ""], ["Kim", "Hyunjik", ""], ["Garnelo", "Marta", ""], ["Saxton", "David", ""], ["Kohli", "Pushmeet", ""], ["Eslami", "S. M. Ali", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1903.11919", "submitter": "Wu Xing", "authors": "Tao Zhang, Xing Wu, Meng Lin, Jizhong Han, Songlin Hu", "title": "Imbalanced Sentiment Classification Enhanced with Discourse Marker", "comments": "12 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced data commonly exists in real world, espacially in\nsentiment-related corpus, making it difficult to train a classifier to\ndistinguish latent sentiment in text data. We observe that humans often express\ntransitional emotion between two adjacent discourses with discourse markers\nlike \"but\", \"though\", \"while\", etc, and the head discourse and the tail\ndiscourse 3 usually indicate opposite emotional tendencies. Based on this\nobservation, we propose a novel plug-and-play method, which first samples\ndiscourses according to transitional discourse markers and then validates\nsentimental polarities with the help of a pretrained attention-based model. Our\nmethod increases sample diversity in the first place, can serve as a upstream\npreprocessing part in data augmentation. We conduct experiments on three public\nsentiment datasets, with several frequently used algorithms. Results show that\nour method is found to be consistently effective, even in highly imbalanced\nscenario, and easily be integrated with oversampling method to boost the\nperformance on imbalanced sentiment classification.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 12:38:58 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Zhang", "Tao", ""], ["Wu", "Xing", ""], ["Lin", "Meng", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "1903.11941", "submitter": "Nameer Al Khafaf", "authors": "Nameer Al Khafaf, Mahdi Jalili and Peter Sokolowski", "title": "Application of Deep Learning Long Short-Term Memory in Energy Demand\n  Forecasting", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-20257-6_3", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The smart metering infrastructure has changed how electricity is measured in\nboth residential and industrial application. The large amount of data collected\nby smart meter per day provides a huge potential for analytics to support the\noperation of a smart grid, an example of which is energy demand forecasting.\nShort term energy forecasting can be used by utilities to assess if any\nforecasted peak energy demand would have an adverse effect on the power system\ntransmission and distribution infrastructure. It can also help in load\nscheduling and demand side management. Many techniques have been proposed to\nforecast time series including Support Vector Machine, Artificial Neural\nNetwork and Deep Learning. In this work we use Long Short Term Memory\narchitecture to forecast 3-day ahead energy demand across each month in the\nyear. The results show that 3-day ahead demand can be accurately forecasted\nwith a Mean Absolute Percentage Error of 3.15%. In addition to that, the paper\nproposes way to quantify the time as a feature to be used in the training phase\nwhich is shown to affect the network performance.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 00:06:34 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Khafaf", "Nameer Al", ""], ["Jalili", "Mahdi", ""], ["Sokolowski", "Peter", ""]]}, {"id": "1903.11960", "submitter": "Luca Franceschi", "authors": "Luca Franceschi, Mathias Niepert, Massimiliano Pontil, Xiao He", "title": "Learning Discrete Structures for Graph Neural Networks", "comments": "ICML 2019, code at https://github.com/lucfra/LDS - Revision of Sec. 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are a popular class of machine learning models\nwhose major advantage is their ability to incorporate a sparse and discrete\ndependency structure between data points. Unfortunately, GNNs can only be used\nwhen such a graph-structure is available. In practice, however, real-world\ngraphs are often noisy and incomplete or might not be available at all. With\nthis work, we propose to jointly learn the graph structure and the parameters\nof graph convolutional networks (GCNs) by approximately solving a bilevel\nprogram that learns a discrete probability distribution on the edges of the\ngraph. This allows one to apply GCNs not only in scenarios where the given\ngraph is incomplete or corrupted but also in those where a graph is not\navailable. We conduct a series of experiments that analyze the behavior of the\nproposed method and demonstrate that it outperforms related methods by a\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 13:30:24 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 09:53:04 GMT"}, {"version": "v3", "created": "Fri, 17 May 2019 09:43:48 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2020 09:44:16 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Franceschi", "Luca", ""], ["Niepert", "Mathias", ""], ["Pontil", "Massimiliano", ""], ["He", "Xiao", ""]]}, {"id": "1903.11971", "submitter": "Xin-She Yang", "authors": "Si Chen, Guo-Hua Peng, Xing-Shi He, Xin-She Yang", "title": "The Global Convergence Analysis of the Bat Algorithm Using a Markovian\n  Framework and Dynamical System Theory", "comments": "17 pages, 3 figures", "journal-ref": "Expert Systems with Applications, vol. 114, 173--182 (2018)", "doi": "10.1016/j.eswa.2018.07.036", "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bat algorithm (BA) has been shown to be effective to solve a wider range\nof optimization problems. However, there is not much theoretical analysis\nconcerning its convergence and stability. In order to prove the convergence of\nthe bat algorithm, we have built a Markov model for the algorithm and proved\nthat the state sequence of the bat population forms a finite homogeneous Markov\nchain, satisfying the global convergence criteria. Then, we prove that the bat\nalgorithm can have global convergence. In addition, in order to enhance the\nconvergence performance of the algorithm, we have designed an updated model\nusing the dynamical system theory in terms of a dynamic matrix, and the\nparameter ranges for the algorithm stability are then obtained. We then use\nsome benchmark functions to demonstrate that BA can indeed achieve global\noptimality efficiently for these functions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:33:37 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Chen", "Si", ""], ["Peng", "Guo-Hua", ""], ["He", "Xing-Shi", ""], ["Yang", "Xin-She", ""]]}, {"id": "1903.11981", "submitter": "Rinu Boney", "authors": "Rinu Boney, Norman Di Palo, Mathias Berglund, Alexander Ilin, Juho\n  Kannala, Antti Rasmus, Harri Valpola", "title": "Regularizing Trajectory Optimization with Denoising Autoencoders", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory optimization using a learned model of the environment is one of\nthe core elements of model-based reinforcement learning. This procedure often\nsuffers from exploiting inaccuracies of the learned model. We propose to\nregularize trajectory optimization by means of a denoising autoencoder that is\ntrained on the same trajectories as the model of the environment. We show that\nthe proposed regularization leads to improved planning with both gradient-based\nand gradient-free optimizers. We also demonstrate that using regularized\ntrajectory optimization leads to rapid initial learning in a set of popular\nmotor control tasks, which suggests that the proposed approach can be a useful\ntool for improving sample efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:02:04 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 08:19:48 GMT"}, {"version": "v3", "created": "Wed, 25 Dec 2019 18:08:24 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Boney", "Rinu", ""], ["Di Palo", "Norman", ""], ["Berglund", "Mathias", ""], ["Ilin", "Alexander", ""], ["Kannala", "Juho", ""], ["Rasmus", "Antti", ""], ["Valpola", "Harri", ""]]}, {"id": "1903.11983", "submitter": "Adil \\c{C}oban", "authors": "\\.Ilhan Tar{\\i}mer, Adil \\c{C}oban and Arif Emre Kocaman", "title": "Sentiment Analysis on IMDB Movie Comments and Twitter Data by Machine\n  Learning and Vector Space Techniques", "comments": "8 pages, submitted to CIEA2018 (http://iciea.cumhuriyet.edu.tr/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study's goal is to create a model of sentiment analysis on a 2000 rows\nIMDB movie comments and 3200 Twitter data by using machine learning and vector\nspace techniques; positive or negative preliminary information about the text\nis to provide. In the study, a vector space was created in the KNIME Analytics\nplatform, and a classification study was performed on this vector space by\nDecision Trees, Na\\\"ive Bayes and Support Vector Machines classification\nalgorithms. The conclusions obtained were compared in terms of each algorithms.\nThe classification results for IMDB movie comments are obtained as 94,00%,\n73,20%, and 85,50% by Decision Tree, Naive Bayes and SVM algorithms. The\nclassification results for Twitter data set are presented as 82,76%, 75,44% and\n72,50% by Decision Tree, Naive Bayes SVM algorithms as well. It is seen that\nthe best classification results presented in both data sets are which\ncalculated by SVM algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 09:25:10 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Tar\u0131mer", "\u0130lhan", ""], ["\u00c7oban", "Adil", ""], ["Kocaman", "Arif Emre", ""]]}, {"id": "1903.11990", "submitter": "Simone Scardapane", "authors": "Michele Cirillo, Simone Scardapane, Steven Van Vaerenbergh, Aurelio\n  Uncini", "title": "On the Stability and Generalization of Learning with Kernel Activation\n  Functions", "comments": "Submitted as a brief paper to IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this brief we investigate the generalization properties of a\nrecently-proposed class of non-parametric activation functions, the kernel\nactivation functions (KAFs). KAFs introduce additional parameters in the\nlearning process in order to adapt nonlinearities individually on a per-neuron\nbasis, exploiting a cheap kernel expansion of every activation value. While\nthis increase in flexibility has been shown to provide significant improvements\nin practice, a theoretical proof for its generalization capability has not been\naddressed yet in the literature. Here, we leverage recent literature on the\nstability properties of non-convex models trained via stochastic gradient\ndescent (SGD). By indirectly proving two key smoothness properties of the\nmodels under consideration, we prove that neural networks endowed with KAFs\ngeneralize well when trained with SGD for a finite number of steps.\nInterestingly, our analysis provides a guideline for selecting one of the\nhyper-parameters of the model, the bandwidth of the scalar Gaussian kernel. A\nshort experimental evaluation validates the proof.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:13:16 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Cirillo", "Michele", ""], ["Scardapane", "Simone", ""], ["Van Vaerenbergh", "Steven", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1903.11991", "submitter": "Maximus Mutschler", "authors": "Maximus Mutschler and Andreas Zell", "title": "Parabolic Approximation Line Search for DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in current optimization research for deep learning is to\nautomatically find optimal step sizes for each update step. The optimal step\nsize is closely related to the shape of the loss in the update step direction.\nHowever, this shape has not yet been examined in detail. This work shows\nempirically that the batch loss over lines in negative gradient direction is\nmostly convex locally and well suited for one-dimensional parabolic\napproximations. By exploiting this parabolic property we introduce a simple and\nrobust line search approach, which performs loss-shape dependent update steps.\nOur approach combines well-known methods such as parabolic approximation, line\nsearch and conjugate gradient, to perform efficiently. It surpasses other step\nsize estimating methods and competes with common optimization methods on a\nlarge variety of experiments without the need of hand-designed step size\nschedules. Thus, it is of interest for objectives where step-size schedules are\nunknown or do not perform well. Our extensive evaluation includes multiple\ncomprehensive hyperparameter grid searches on several datasets and\narchitectures. Finally, we provide a general investigation of exact line\nsearches in the context of batch losses and exact losses, including their\nrelation to our line search approach.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:13:21 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 10:03:30 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 11:17:22 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 14:06:03 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Mutschler", "Maximus", ""], ["Zell", "Andreas", ""]]}, {"id": "1903.12008", "submitter": "Debjit Paul", "authors": "Debjit Paul, Mittul Singh, Michael A. Hedderich and Dietrich Klakow", "title": "Handling Noisy Labels for Robustly Learning from Self-Training Data for\n  Low-Resource Sequence Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of effectively self-training neural\nnetworks in a low-resource setting. Self-training is frequently used to\nautomatically increase the amount of training data. However, in a low-resource\nscenario, it is less effective due to unreliable annotations created using\nself-labeling of unlabeled data. We propose to combine self-training with noise\nhandling on the self-labeled data. Directly estimating noise on the combined\nclean training set and self-labeled data can lead to corruption of the clean\ndata and hence, performs worse. Thus, we propose the Clean and Noisy Label\nNeural Network which trains on clean and noisy self-labeled data simultaneously\nby explicitly modelling clean and noisy labels separately. In our experiments\non Chunking and NER, this approach performs more robustly than the baselines.\nComplementary to this explicit approach, noise can also be handled implicitly\nwith the help of an auxiliary learning task. To such a complementary approach,\nour method is more beneficial than other baseline methods and together provides\nthe best performance overall.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:33:50 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Paul", "Debjit", ""], ["Singh", "Mittul", ""], ["Hedderich", "Michael A.", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1903.12017", "submitter": "Robert Schwarzenberg", "authors": "Robert Schwarzenberg, David Harbecke, Vivien Macketanz, Eleftherios\n  Avramidis, Sebastian M\\\"oller", "title": "Train, Sort, Explain: Learning to Diagnose Translation Models", "comments": "NAACL-HLT 2019: Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating translation models is a trade-off between effort and detail. On\nthe one end of the spectrum there are automatic count-based methods such as\nBLEU, on the other end linguistic evaluations by humans, which arguably are\nmore informative but also require a disproportionately high effort. To narrow\nthe spectrum, we propose a general approach on how to automatically expose\nsystematic differences between human and machine translations to human experts.\nInspired by adversarial settings, we train a neural text classifier to\ndistinguish human from machine translations. A classifier that performs and\ngeneralizes well after training should recognize systematic differences between\nthe two classes, which we uncover with neural explainability methods. Our\nproof-of-concept implementation, DiaMaT, is open source. Applied to a dataset\ntranslated by a state-of-the-art neural Transformer model, DiaMaT achieves a\nclassification accuracy of 75% and exposes meaningful differences between\nhumans and the Transformer, amidst the current discussion about human parity.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:45:42 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Schwarzenberg", "Robert", ""], ["Harbecke", "David", ""], ["Macketanz", "Vivien", ""], ["Avramidis", "Eleftherios", ""], ["M\u00f6ller", "Sebastian", ""]]}, {"id": "1903.12019", "submitter": "Conghui Zheng", "authors": "Conghui Zheng, Li Pan and Peng Wu", "title": "Multimodal Deep Network Embedding with Integrated Structure and\n  Attribute Information", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding is the process of learning low-dimensional representations\nfor nodes in a network, while preserving node features. Existing studies only\nleverage network structure information and focus on preserving structural\nfeatures. However, nodes in real-world networks often have a rich set of\nattributes providing extra semantic information. It has been demonstrated that\nboth structural and attribute features are important for network analysis\ntasks. To preserve both features, we investigate the problem of integrating\nstructure and attribute information to perform network embedding and propose a\nMultimodal Deep Network Embedding (MDNE) method. MDNE captures the non-linear\nnetwork structures and the complex interactions among structures and\nattributes, using a deep model consisting of multiple layers of non-linear\nfunctions. Since structures and attributes are two different types of\ninformation, a multimodal learning method is adopted to pre-process them and\nhelp the model to better capture the correlations between node structure and\nattribute information. We employ both structural proximity and attribute\nproximity in the loss function to preserve the respective features and the\nrepresentations are obtained by minimizing the loss function. Results of\nextensive experiments on four real-world datasets show that the proposed method\nperforms significantly better than baselines on a variety of tasks, which\ndemonstrate the effectiveness and generality of our method.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:47:33 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Zheng", "Conghui", ""], ["Pan", "Li", ""], ["Wu", "Peng", ""]]}, {"id": "1903.12021", "submitter": "Marco Gherardi", "authors": "Pietro Rotondo and Marco Cosentino Lagomarsino and Marco Gherardi", "title": "Counting the learnable functions of structured data", "comments": null, "journal-ref": "Phys. Rev. Research 2, 023169 (2020)", "doi": "10.1103/PhysRevResearch.2.023169", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cover's function counting theorem is a milestone in the theory of artificial\nneural networks. It provides an answer to the fundamental question of\ndetermining how many binary assignments (dichotomies) of $p$ points in $n$\ndimensions can be linearly realized. Regrettably, it has proved hard to extend\nthe same approach to more advanced problems than the classification of points.\nIn particular, an emerging necessity is to find methods to deal with structured\ndata, and specifically with non-pointlike patterns. A prominent case is that of\ninvariant recognition, whereby identification of a stimulus is insensitive to\nirrelevant transformations on the inputs (such as rotations or changes in\nperspective in an image). An object is therefore represented by an extended\nperceptual manifold, consisting of inputs that are classified similarly. Here,\nwe develop a function counting theory for structured data of this kind, by\nextending Cover's combinatorial technique, and we derive analytical expressions\nfor the average number of dichotomies of generically correlated sets of\npatterns. As an application, we obtain a closed formula for the capacity of a\nbinary classifier trained to distinguish general polytopes of any dimension.\nThese results may help extend our theoretical understanding of generalization,\nfeature extraction, and invariant object recognition by neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:49:40 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Rotondo", "Pietro", ""], ["Lagomarsino", "Marco Cosentino", ""], ["Gherardi", "Marco", ""]]}, {"id": "1903.12069", "submitter": "Dominik Heider", "authors": "Sebastian Sp\\\"anig, Agnes Emberger-Klein, Jan-Peter Sowa, Ali Canbay,\n  Klaus Menrad, Dominik Heider", "title": "The Virtual Doctor: An Interactive Artificial Intelligence based on Deep\n  Learning for Non-Invasive Prediction of Diabetes", "comments": "16 pages, 4 figues", "journal-ref": "Artificial Intelligence in Medicine 2019", "doi": "10.1016/j.artmed.2019.101706", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) will pave the way to a new era in medicine.\nHowever, currently available AI systems do not interact with a patient, e.g.,\nfor anamnesis, and thus are only used by the physicians for predictions in\ndiagnosis or prognosis. However, these systems are widely used, e.g., in\ndiabetes or cancer prediction. In the current study, we developed an AI that is\nable to interact with a patient (virtual doctor) by using a speech recognition\nand speech synthesis system and thus can autonomously interact with the\npatient, which is particularly important for, e.g., rural areas, where the\navailability of primary medical care is strongly limited by low population\ndensities. As a proof-of-concept, the system is able to predict type 2 diabetes\nmellitus (T2DM) based on non-invasive sensors and deep neural networks.\nMoreover, the system provides an easy-to-interpret probability estimation for\nT2DM for a given patient. Besides the development of the AI, we further\nanalyzed the acceptance of young people for AI in healthcare to estimate the\nimpact of such system in the future.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 13:41:46 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Sp\u00e4nig", "Sebastian", ""], ["Emberger-Klein", "Agnes", ""], ["Sowa", "Jan-Peter", ""], ["Canbay", "Ali", ""], ["Menrad", "Klaus", ""], ["Heider", "Dominik", ""]]}, {"id": "1903.12070", "submitter": "Snehanshu Banerjee", "authors": "Snehanshu Banerjee, Mansoureh Jeihani, Danny D. Brown, and Samira\n  Ahangari", "title": "Comprehensive Analysis of Dynamic Message Sign Impact on Driver\n  Behavior: A Random Forest Approach", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the potential effects of different Dynamic Message\nSigns (DMSs) on driver behavior using a full-scale high-fidelity driving\nsimulator. Different DMSs are categorized by their content, structure, and type\nof messages. A random forest algorithm is used for three separate behavioral\nanalyses; a route diversion analysis, a route choice analysis and a compliance\nanalysis; to identify the potential and relative influences of different DMSs\non these aspects of driver behavior. A total of 390 simulation runs are\nconducted using a sample of 65 participants from diverse socioeconomic\nbackgrounds. Results obtained suggest that DMSs displaying lane closure and\ndelay information with advisory messages are most influential with regards to\ndiversion while color-coded DMSs and DMSs with avoid route advice are the top\ncontributors impacting route choice decisions and DMS compliance. In this\nfirst-of-a-kind study, based on the responses to the pre and post simulation\nsurveys as well as results obtained from the analysis of\ndriving-simulation-session data, the authors found that color-blind-friendly,\ncolor-coded DMSs are more effective than alphanumeric DMSs - especially in\nscenarios that demand high compliance from drivers. The increased effectiveness\nmay be attributed to reduced comprehension time and ease with which such DMSs\nare understood by a greater percentage of road users.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 02:10:28 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Banerjee", "Snehanshu", ""], ["Jeihani", "Mansoureh", ""], ["Brown", "Danny D.", ""], ["Ahangari", "Samira", ""]]}, {"id": "1903.12071", "submitter": "Ariel Rosenfeld", "authors": "Ariel Rosenfeld, David Benrimoh, Caitrin Armstrong, Nykan Mirchi,\n  Timothe Langlois-Therrien, Colleen Rollins, Myriam Tanguay-Sela, Joseph\n  Mehltretter, Robert Fratila, Sonia Israel, Emily Snook, Kelly Perlman, Akiva\n  Kleinerman, Bechara Saab, Mark Thoburn, Cheryl Gabbay and Amit\n  Yaniv-Rosenfeld", "title": "Big Data Analytics and AI in Mental Healthcare", "comments": "Chapter in the \"Big Data in Healthcare\" book (Elsevier) [exp. 2019]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental health conditions cause a great deal of distress or impairment;\ndepression alone will affect 11% of the world's population. The application of\nArtificial Intelligence (AI) and big-data technologies to mental health has\ngreat potential for personalizing treatment selection, prognosticating,\nmonitoring for relapse, detecting and helping to prevent mental health\nconditions before they reach clinical-level symptomatology, and even delivering\nsome treatments. However, unlike similar applications in other fields of\nmedicine, there are several unique challenges in mental health applications\nwhich currently pose barriers towards the implementation of these technologies.\nSpecifically, there are very few widely used or validated biomarkers in mental\nhealth, leading to a heavy reliance on patient and clinician derived\nquestionnaire data as well as interpretation of new signals such as digital\nphenotyping. In addition, diagnosis also lacks the same objective 'gold\nstandard' as in other conditions such as oncology, where clinicians and\nresearchers can often rely on pathological analysis for confirmation of\ndiagnosis. In this chapter we discuss the major opportunities, limitations and\ntechniques used for improving mental healthcare through AI and big-data. We\nexplore both the computational, clinical and ethical considerations and best\npractices as well as lay out the major researcher directions for the near\nfuture.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 20:47:29 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Rosenfeld", "Ariel", ""], ["Benrimoh", "David", ""], ["Armstrong", "Caitrin", ""], ["Mirchi", "Nykan", ""], ["Langlois-Therrien", "Timothe", ""], ["Rollins", "Colleen", ""], ["Tanguay-Sela", "Myriam", ""], ["Mehltretter", "Joseph", ""], ["Fratila", "Robert", ""], ["Israel", "Sonia", ""], ["Snook", "Emily", ""], ["Perlman", "Kelly", ""], ["Kleinerman", "Akiva", ""], ["Saab", "Bechara", ""], ["Thoburn", "Mark", ""], ["Gabbay", "Cheryl", ""], ["Yaniv-Rosenfeld", "Amit", ""]]}, {"id": "1903.12074", "submitter": "William La Cava", "authors": "William La Cava, Christopher Bauer, Jason H. Moore, Sarah A\n  Pendergrass", "title": "Interpretation of machine learning predictions for patient outcomes in\n  electronic health records", "comments": "10 pages, 5 figures, submitted to AMIA Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records are an increasingly important resource for\nunderstanding the interactions between patient health, environment, and\nclinical decisions. In this paper we report an empirical study of predictive\nmodeling of several patient outcomes using three state-of-the-art machine\nlearning methods. Our primary goal is to validate the models by interpreting\nthe importance of predictors in the final models. Central to interpretation is\nthe use of feature importance scores, which vary depending on the underlying\nmethodology. In order to assess feature importance, we compared univariate\nstatistical tests, information-theoretic measures, permutation testing, and\nnormalized coefficients from multivariate logistic regression models. In\ngeneral we found poor correlation between methods in their assessment of\nfeature importance, even when their performance is comparable and relatively\ngood. However, permutation tests applied to random forest and gradient boosting\nmodels showed the most agreement, and the importance scores matched the\nclinical interpretation most frequently.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 19:05:37 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["La Cava", "William", ""], ["Bauer", "Christopher", ""], ["Moore", "Jason H.", ""], ["Pendergrass", "Sarah A", ""]]}, {"id": "1903.12080", "submitter": "Carl Chalmers", "authors": "C. Chalmers, P.Fergus, C. Aday Curbelo Montanez, S.Sikdar, F.Ball and\n  B. Kendall", "title": "Detecting Activities of Daily Living and Routine Behaviours in Dementia\n  Patients Living Alone Using Smart Meter Load Disaggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of an ageing population is a significant public health concern.\nThis has led to an increase in the number of people living with progressive\nneurodegenerative disorders like dementia. Consequently, the strain this is\nplaces on health and social care services means providing 24-hour monitoring is\nnot sustainable. Technological intervention is being considered, however no\nsolution exists to non-intrusively monitor the independent living needs of\npatients with dementia. As a result many patients hit crisis point before\nintervention and support is provided. In parallel, patient care relies on\nfeedback from informal carers about significant behavioural changes. Yet, not\nall people have a social support network and early intervention in dementia\ncare is often missed. The smart meter rollout has the potential to change this.\nUsing machine learning and signal processing techniques, a home energy supply\ncan be disaggregated to detect which home appliances are turned on and off.\nThis will allow Activities of Daily Living (ADLs) to be assessed, such as\neating and drinking, and observed changes in routine to be detected for early\nintervention. The primary aim is to help reduce deterioration and enable\npatients to stay in their homes for longer. A Support Vector Machine (SVM) and\nRandom Decision Forest classifier are modelled using data from three test\nhomes. The trained models are then used to monitor two patients with dementia\nduring a six-month clinical trial undertaken in partnership with Mersey Care\nNHS Foundation Trust. In the case of load disaggregation for appliance\ndetection, the SVM achieved (AUC=0.86074, Sen=0.756 and Spec=0.92838). While\nthe Decision Forest achieved (AUC=0.9429, Sen=0.9634 and Spec=0.9634). ADLs are\nalso analysed to identify the behavioural patterns of the occupant while\ndetecting alterations in routine.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 11:54:19 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Chalmers", "C.", ""], ["Fergus", "P.", ""], ["Montanez", "C. Aday Curbelo", ""], ["Sikdar", "S.", ""], ["Ball", "F.", ""], ["Kendall", "B.", ""]]}, {"id": "1903.12087", "submitter": "Jean-Marc Valin", "authors": "Jean-Marc Valin, Jan Skoglund", "title": "A Real-Time Wideband Neural Vocoder at 1.6 kb/s Using LPCNet", "comments": "Accepted for Interspeech 2019, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural speech synthesis algorithms are a promising new approach for coding\nspeech at very low bitrate. They have so far demonstrated quality that far\nexceeds traditional vocoders, at the cost of very high complexity. In this\nwork, we present a low-bitrate neural vocoder based on the LPCNet model. The\nuse of linear prediction and sparse recurrent networks makes it possible to\nachieve real-time operation on general-purpose hardware. We demonstrate that\nLPCNet operating at 1.6 kb/s achieves significantly higher quality than MELP\nand that uncompressed LPCNet can exceed the quality of a waveform codec\noperating at low bitrate. This opens the way for new codec designs based on\nneural synthesis models.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 16:09:58 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 02:14:53 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Valin", "Jean-Marc", ""], ["Skoglund", "Jan", ""]]}, {"id": "1903.12090", "submitter": "Fabrizio Sebastiani", "authors": "Alejandro Moreo Fern\\'andez, Andrea Esuli, Fabrizio Sebastiani", "title": "Learning to Weight for Text Classification", "comments": "To appear in IEEE Transactions on Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In information retrieval (IR) and related tasks, term weighting approaches\ntypically consider the frequency of the term in the document and in the\ncollection in order to compute a score reflecting the importance of the term\nfor the document. In tasks characterized by the presence of training data (such\nas text classification) it seems logical that the term weighting function\nshould take into account the distribution (as estimated from training data) of\nthe term across the classes of interest. Although `supervised term weighting'\napproaches that use this intuition have been described before, they have failed\nto show consistent improvements. In this article we analyse the possible\nreasons for this failure, and call consolidated assumptions into question.\nFollowing this criticism we propose a novel supervised term weighting approach\nthat, instead of relying on any predefined formula, learns a term weighting\nfunction optimised on the training set of interest; we dub this approach\n\\emph{Learning to Weight} (LTW). The experiments that we run on several\nwell-known benchmarks, and using different learning methods, show that our\nmethod outperforms previous term weighting approaches in text classification.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 16:13:35 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Fern\u00e1ndez", "Alejandro Moreo", ""], ["Esuli", "Andrea", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1903.12092", "submitter": "Lanhua You", "authors": "Lanhua You, Wu Guo, Lirong Dai, Jun Du", "title": "Deep Neural Network Embeddings with Gating Mechanisms for\n  Text-Independent Speaker Verification", "comments": "5 pages, 3 figures, submitted to INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, gating mechanisms are applied in deep neural network (DNN)\ntraining for x-vector-based text-independent speaker verification. First, a\ngated convolution neural network (GCNN) is employed for modeling the\nframe-level embedding layers. Compared with the time-delay DNN (TDNN), the GCNN\ncan obtain more expressive frame-level representations through carefully\ndesigned memory cell and gating mechanisms. Moreover, we propose a novel\ngated-attention statistics pooling strategy in which the attention scores are\nshared with the output gate. The gated-attention statistics pooling combines\nboth gating and attention mechanisms into one framework; therefore, we can\ncapture more useful information in the temporal pooling layer. Experiments are\ncarried out using the NIST SRE16 and SRE18 evaluation datasets. The results\ndemonstrate the effectiveness of the GCNN and show that the proposed\ngated-attention statistics pooling can further improve the performance.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 16:15:11 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 15:28:32 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["You", "Lanhua", ""], ["Guo", "Wu", ""], ["Dai", "Lirong", ""], ["Du", "Jun", ""]]}, {"id": "1903.12094", "submitter": "John Gideon", "authors": "John Gideon, Melvin G McInnis, Emily Mower Provost", "title": "Improving Cross-Corpus Speech Emotion Recognition with Adversarial\n  Discriminative Domain Generalization (ADDoG)", "comments": null, "journal-ref": null, "doi": "10.1109/TAFFC.2019.2916092", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech emotion recognition provides computers with critical context\nto enable user understanding. While methods trained and tested within the same\ndataset have been shown successful, they often fail when applied to unseen\ndatasets. To address this, recent work has focused on adversarial methods to\nfind more generalized representations of emotional speech. However, many of\nthese methods have issues converging, and only involve datasets collected in\nlaboratory conditions. In this paper, we introduce Adversarial Discriminative\nDomain Generalization (ADDoG), which follows an easier to train \"meet in the\nmiddle\" approach. The model iteratively moves representations learned for each\ndataset closer to one another, improving cross-dataset generalization. We also\nintroduce Multiclass ADDoG, or MADDoG, which is able to extend the proposed\nmethod to more than two datasets, simultaneously. Our results show consistent\nconvergence for the introduced methods, with significantly improved results\nwhen not using labels from the target dataset. We also show how, in most cases,\nADDoG and MADDoG can be used to improve upon baseline state-of-the-art methods\nwhen target dataset labels are added and in-the-wild data are considered. Even\nthough our experiments focus on cross-corpus speech emotion, these methods\ncould be used to remove unwanted factors of variation in other settings.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 16:19:20 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 13:59:26 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Gideon", "John", ""], ["McInnis", "Melvin G", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1903.12101", "submitter": "Ashwinkumar Ganesan", "authors": "Ashwinkumar Ganesan, Pooja Parameshwarappa, Akshay Peshave, Zhiyuan\n  Chen, Tim Oates", "title": "Extending Signature-based Intrusion Detection Systems WithBayesian\n  Abductive Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolving cybersecurity threats are a persistent challenge for\nsystemadministrators and security experts as new malwares are continu-ally\nreleased. Attackers may look for vulnerabilities in commercialproducts or\nexecute sophisticated reconnaissance campaigns tounderstand a targets network\nand gather information on securityproducts like firewalls and intrusion\ndetection / prevention systems(network or host-based). Many new attacks tend to\nbe modificationsof existing ones. In such a scenario, rule-based systems fail\nto detectthe attack, even though there are minor differences in conditions\n/attributes between rules to identify the new and existing attack. Todetect\nthese differences the IDS must be able to isolate the subset ofconditions that\nare true and predict the likely conditions (differentfrom the original) that\nmust be observed. In this paper, we proposeaprobabilistic abductive\nreasoningapproach that augments an exist-ing rule-based IDS (snort [29]) to\ndetect these evolved attacks by (a)Predicting rule conditions that are likely\nto occur (based on existingrules) and (b) able to generate new snort rules when\nprovided withseed rule (i.e. a starting rule) to reduce the burden on experts\ntoconstantly update them. We demonstrate the effectiveness of theapproach by\ngenerating new rules from the snort 2012 rules set andtesting it on the MACCDC\n2012 dataset [6].\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 16:38:09 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Ganesan", "Ashwinkumar", ""], ["Parameshwarappa", "Pooja", ""], ["Peshave", "Akshay", ""], ["Chen", "Zhiyuan", ""], ["Oates", "Tim", ""]]}, {"id": "1903.12110", "submitter": "Fabrizio Sebastiani", "authors": "Andrea Esuli, Alejandro Moreo, Fabrizio Sebastiani", "title": "Building Automated Survey Coders via Interactive Machine Learning", "comments": "To appear in the International Journal of Market Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software systems trained via machine learning to automatically classify\nopen-ended answers (a.k.a. verbatims) are by now a reality. Still, their\nadoption in the survey coding industry has been less widespread than it might\nhave been. Among the factors that have hindered a more massive takeup of this\ntechnology are the effort involved in manually coding a sufficient amount of\ntraining data, the fact that small studies do not seem to justify this effort,\nand the fact that the process needs to be repeated anew when brand new coding\ntasks arise. In this paper we will argue for an approach to building verbatim\nclassifiers that we will call \"Interactive Learning\", and that addresses all\nthe above problems. We will show that, for the same amount of training effort,\ninteractive learning delivers much better coding accuracy than standard\n\"non-interactive\" learning. This is especially true when the amount of data we\nare willing to manually code is small, which makes this approach attractive\nalso for small-scale studies. Interactive learning also lends itself to reusing\npreviously trained classifiers for dealing with new (albeit related) coding\ntasks. Interactive learning also integrates better in the daily workflow of the\nsurvey specialist, and delivers a better user experience overall.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 16:51:17 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Esuli", "Andrea", ""], ["Moreo", "Alejandro", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1903.12125", "submitter": "Haoyu Wang", "authors": "Haoyu Wang, Yawen Guan and Brian J Reich", "title": "Nearest-Neighbor Neural Networks for Geostatistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kriging is the predominant method used for spatial prediction, but relies on\nthe assumption that predictions are linear combinations of the observations.\nKriging often also relies on additional assumptions such as normality and\nstationarity. We propose a more flexible spatial prediction method based on the\nNearest-Neighbor Neural Network (4N) process that embeds deep learning into a\ngeostatistical model. We show that the 4N process is a valid stochastic process\nand propose a series of new ways to construct features to be used as inputs to\nthe deep learning model based on neighboring information. Our model framework\noutperforms some existing state-of-art geostatistical modelling methods for\nsimulated non-Gaussian data and is applied to a massive forestry dataset.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 17:10:59 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Wang", "Haoyu", ""], ["Guan", "Yawen", ""], ["Reich", "Brian J", ""]]}, {"id": "1903.12127", "submitter": "Emilia Apostolova PhD", "authors": "Tony Wang, Tim Tschampel, Emilia Apostolova and Tom Velez", "title": "Using Latent Class Analysis to Identify ARDS Sub-phenotypes for Enhanced\n  Machine Learning Predictive Performance", "comments": "Work in progress, preliminary results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we utilize Machine Learning for early recognition of patients\nat high risk of acute respiratory distress syndrome (ARDS), which is critical\nfor successful prevention strategies for this devastating syndrome. The\ndifficulty in early ARDS recognition stems from its complex and heterogenous\nnature. In this study, we integrate knowledge of the heterogeneity of ARDS\npatients into predictive model building. Using MIMIC-III data, we first apply\nlatent class analysis (LCA) to identify homogeneous sub-groups in the ARDS\npopulation, and then build predictive models on the partitioned data. The\nresults indicate that significantly improved performances of prediction can be\nobtained for two of the three identified sub-phenotypes of ARDS. Experiments\nsuggests that identifying sub-phenotypes is beneficial for building predictive\nmodel for ARDS.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 17:12:35 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Wang", "Tony", ""], ["Tschampel", "Tim", ""], ["Apostolova", "Emilia", ""], ["Velez", "Tom", ""]]}, {"id": "1903.12136", "submitter": "Raphael Tang", "authors": "Raphael Tang, Yao Lu, Linqing Liu, Lili Mou, Olga Vechtomova, Jimmy\n  Lin", "title": "Distilling Task-Specific Knowledge from BERT into Simple Neural Networks", "comments": "8 pages, 2 figures; first three authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the natural language processing literature, neural networks are becoming\nincreasingly deeper and complex. The recent poster child of this trend is the\ndeep language representation model, which includes BERT, ELMo, and GPT. These\ndevelopments have led to the conviction that previous-generation, shallower\nneural networks for language understanding are obsolete. In this paper,\nhowever, we demonstrate that rudimentary, lightweight neural networks can still\nbe made competitive without architecture changes, external training data, or\nadditional input features. We propose to distill knowledge from BERT, a\nstate-of-the-art language representation model, into a single-layer BiLSTM, as\nwell as its siamese counterpart for sentence-pair tasks. Across multiple\ndatasets in paraphrasing, natural language inference, and sentiment\nclassification, we achieve comparable results with ELMo, while using roughly\n100 times fewer parameters and 15 times less inference time.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 17:23:50 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Tang", "Raphael", ""], ["Lu", "Yao", ""], ["Liu", "Linqing", ""], ["Mou", "Lili", ""], ["Vechtomova", "Olga", ""], ["Lin", "Jimmy", ""]]}, {"id": "1903.12141", "submitter": "Xinshao Wang Dr", "authors": "Xinshao Wang, Yang Hua, Elyor Kodirov, Neil M. Robertson", "title": "IMAE for Noise-Robust Learning: Mean Absolute Error Does Not Treat\n  Examples Equally and Gradient Magnitude's Variance Matters", "comments": "Updated Version. IMAE for Noise-Robust Learning: Mean Absolute Error\n  Does Not Treat Examples Equally and Gradient Magnitude's Variance Matters\n  Code:\n  \\url{https://github.com/XinshaoAmosWang/Improving-Mean-Absolute-Error-against-CCE}.\n  Please feel free to contact for discussions or implementation problems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study robust deep learning against abnormal training data\nfrom the perspective of example weighting built in empirical loss functions,\ni.e., gradient magnitude with respect to logits, an angle that is not\nthoroughly studied so far. Consequently, we have two key findings: (1) Mean\nAbsolute Error (MAE) Does Not Treat Examples Equally. We present new\nobservations and insightful analysis about MAE, which is theoretically proved\nto be noise-robust. First, we reveal its underfitting problem in practice.\nSecond, we analyse that MAE's noise-robustness is from emphasising on uncertain\nexamples instead of treating training samples equally, as claimed in prior\nwork. (2) The Variance of Gradient Magnitude Matters. We propose an effective\nand simple solution to enhance MAE's fitting ability while preserving its\nnoise-robustness. Without changing MAE's overall weighting scheme, i.e., what\nexamples get higher weights, we simply change its weighting variance\nnon-linearly so that the impact ratio between two examples are adjusted. Our\nsolution is termed Improved MAE (IMAE). We prove IMAE's effectiveness using\nextensive experiments: image classification under clean labels, synthetic label\nnoise, and real-world unknown noise. We conclude IMAE is superior to CCE, the\nmost popular loss for training DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 17:27:05 GMT"}, {"version": "v2", "created": "Sun, 31 Mar 2019 12:23:00 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 10:30:04 GMT"}, {"version": "v4", "created": "Tue, 13 Aug 2019 21:51:20 GMT"}, {"version": "v5", "created": "Fri, 18 Oct 2019 15:44:53 GMT"}, {"version": "v6", "created": "Tue, 17 Dec 2019 13:02:56 GMT"}, {"version": "v7", "created": "Sat, 11 Jan 2020 23:44:10 GMT"}, {"version": "v8", "created": "Mon, 27 Jan 2020 11:59:02 GMT"}, {"version": "v9", "created": "Sun, 15 Nov 2020 09:38:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wang", "Xinshao", ""], ["Hua", "Yang", ""], ["Kodirov", "Elyor", ""], ["Robertson", "Neil M.", ""]]}, {"id": "1903.12220", "submitter": "Maithra Raghu", "authors": "Maithra Raghu, Katy Blumer, Greg Corrado, Jon Kleinberg, Ziad\n  Obermeyer, Sendhil Mullainathan", "title": "The Algorithmic Automation Problem: Prediction, Triage, and Human Effort", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a wide array of areas, algorithms are matching and surpassing the\nperformance of human experts, leading to consideration of the roles of human\njudgment and algorithmic prediction in these domains. The discussion around\nthese developments, however, has implicitly equated the specific task of\nprediction with the general task of automation. We argue here that automation\nis broader than just a comparison of human versus algorithmic performance on a\ntask; it also involves the decision of which instances of the task to give to\nthe algorithm in the first place. We develop a general framework that poses\nthis latter decision as an optimization problem, and we show how basic\nheuristics for this optimization problem can lead to performance gains even on\nheavily-studied applications of AI in medicine. Our framework also serves to\nhighlight how effective automation depends crucially on estimating both\nalgorithmic and human error on an instance-by-instance basis, and our results\nshow how improvements in these error estimation problems can yield significant\ngains for automation as well.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 18:53:58 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Raghu", "Maithra", ""], ["Blumer", "Katy", ""], ["Corrado", "Greg", ""], ["Kleinberg", "Jon", ""], ["Obermeyer", "Ziad", ""], ["Mullainathan", "Sendhil", ""]]}, {"id": "1903.12235", "submitter": "Ozan Ozdenizci", "authors": "Ozan Ozdenizci, Deniz Erdogmus", "title": "Information Theoretic Feature Transformation Learning for Brain\n  Interfaces", "comments": "Accepted for publication by IEEE Transactions on Biomedical\n  Engineering", "journal-ref": "IEEE Transactions on Biomedical Engineering, 2019", "doi": "10.1109/TBME.2019.2908099", "report-no": null, "categories": "cs.LG cs.HC cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: A variety of pattern analysis techniques for model training in\nbrain interfaces exploit neural feature dimensionality reduction based on\nfeature ranking and selection heuristics. In the light of broad evidence\ndemonstrating the potential sub-optimality of ranking based feature selection\nby any criterion, we propose to extend this focus with an information theoretic\nlearning driven feature transformation concept. Methods: We present a maximum\nmutual information linear transformation (MMI-LinT), and a nonlinear\ntransformation (MMI-NonLinT) framework derived by a general definition of the\nfeature transformation learning problem. Empirical assessments are performed\nbased on electroencephalographic (EEG) data recorded during a four class motor\nimagery brain-computer interface (BCI) task. Exploiting state-of-the-art\nmethods for initial feature vector construction, we compare the proposed\napproaches with conventional feature selection based dimensionality reduction\ntechniques which are widely used in brain interfaces. Furthermore, for the\nmulti-class problem, we present and exploit a hierarchical graphical model\nbased BCI decoding system. Results: Both binary and multi-class decoding\nanalyses demonstrate significantly better performances with the proposed\nmethods. Conclusion: Information theoretic feature transformations are capable\nof tackling potential confounders of conventional approaches in various\nsettings. Significance: We argue that this concept provides significant\ninsights to extend the focus on feature selection heuristics to a broader\ndefinition of feature transformation learning in brain interfaces.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 19:41:05 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 17:10:57 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Ozdenizci", "Ozan", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "1903.12248", "submitter": "Mayank Mishra", "authors": "Prathosh A. P., Varun Srivastava, Mayank Mishra", "title": "Adversarial Approximate Inference for Speech to Electroglottograph\n  Conversion", "comments": "Submitted to IEEE/ACM Transactions on Audio, Speech and Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech produced by human vocal apparatus conveys substantial non-semantic\ninformation including the gender of the speaker, voice quality, affective\nstate, abnormalities in the vocal apparatus etc. Such information is attributed\nto the properties of the voice source signal, which is usually estimated from\nthe speech signal. However, most of the source estimation techniques depend\nheavily on the goodness of the model assumptions and are prone to noise. A\npopular alternative is to indirectly obtain the source information through the\nElectroglottographic (EGG) signal that measures the electrical admittance\naround the vocal folds using dedicated hardware. In this paper, we address the\nproblem of estimating the EGG signal directly from the speech signal, devoid of\nany hardware. Sampling from the intractable conditional distribution of the EGG\nsignal given the speech signal is accomplished through optimization of an\nevidence lower bound. This is constructed via minimization of the KL-divergence\nbetween the true and the approximated posteriors of a latent variable learned\nusing a deep neural auto-encoder that serves an informative prior. We\ndemonstrate the efficacy of the method at generating the EGG signal by\nconducting several experiments on datasets comprising multiple speakers, voice\nqualities, noise settings and speech pathologies. The proposed method is\nevaluated on many benchmark metrics and is found to agree with the gold\nstandard while proving better than the state-of-the-art algorithms on a few\ntasks such as epoch extraction.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 20:30:17 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 20:04:52 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["P.", "Prathosh A.", ""], ["Srivastava", "Varun", ""], ["Mishra", "Mayank", ""]]}, {"id": "1903.12258", "submitter": "Rosdyana Mangir Irawan Kusuma", "authors": "Rosdyana Mangir Irawan Kusuma, Trang-Thi Ho, Wei-Chun Kao, Yu-Yen Ou\n  and Kai-Lung Hua", "title": "Using Deep Learning Neural Networks and Candlestick Chart Representation\n  to Predict Stock Market", "comments": "conference,13 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock market prediction is still a challenging problem because there are many\nfactors effect to the stock market price such as company news and performance,\nindustry performance, investor sentiment, social media sentiment and economic\nfactors. This work explores the predictability in the stock market using Deep\nConvolutional Network and candlestick charts. The outcome is utilized to design\na decision support framework that can be used by traders to provide suggested\nindications of future stock price direction. We perform this work using various\ntypes of neural networks like convolutional neural network, residual network\nand visual geometry group network. From stock market historical data, we\nconverted it to candlestick charts. Finally, these candlestick charts will be\nfeed as input for training a Convolutional Neural Network model. This\nConvolutional Neural Network model will help us to analyze the patterns inside\nthe candlestick chart and predict the future movements of stock market. The\neffectiveness of our method is evaluated in stock market prediction with a\npromising results 92.2% and 92.1% accuracy for Taiwan and Indonesian stock\nmarket dataset respectively. The constructed model have been implemented as a\nweb-based system freely available at http://140.138.155.216/deepcandle/ for\npredicting stock market using candlestick chart and deep learning neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 03:47:40 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Kusuma", "Rosdyana Mangir Irawan", ""], ["Ho", "Trang-Thi", ""], ["Kao", "Wei-Chun", ""], ["Ou", "Yu-Yen", ""], ["Hua", "Kai-Lung", ""]]}, {"id": "1903.12261", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks, Thomas Dietterich", "title": "Benchmarking Neural Network Robustness to Common Corruptions and\n  Perturbations", "comments": "ICLR 2019 camera-ready; datasets available at\n  https://github.com/hendrycks/robustness ; this article supersedes\n  arXiv:1807.01697", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we establish rigorous benchmarks for image classifier\nrobustness. Our first benchmark, ImageNet-C, standardizes and expands the\ncorruption robustness topic, while showing which classifiers are preferable in\nsafety-critical applications. Then we propose a new dataset called ImageNet-P\nwhich enables researchers to benchmark a classifier's robustness to common\nperturbations. Unlike recent robustness research, this benchmark evaluates\nperformance on common corruptions and perturbations not worst-case adversarial\nperturbations. We find that there are negligible changes in relative corruption\nrobustness from AlexNet classifiers to ResNet classifiers. Afterward we\ndiscover ways to enhance corruption and perturbation robustness. We even find\nthat a bypassed adversarial defense provides substantial common perturbation\nrobustness. Together our benchmarks may aid future work toward networks that\nrobustly generalize.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 20:56:37 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Hendrycks", "Dan", ""], ["Dietterich", "Thomas", ""]]}, {"id": "1903.12262", "submitter": "Negar Rostamzadeh", "authors": "Misha Benjamin, Paul Gagnon, Negar Rostamzadeh, Chris Pal, Yoshua\n  Bengio, Alex Shee", "title": "Towards Standardization of Data Licenses: The Montreal Data License", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a taxonomy for the licensing of data in the fields of\nartificial intelligence and machine learning. The paper's goal is to build\ntowards a common framework for data licensing akin to the licensing of open\nsource software. Increased transparency and resolving conceptual ambiguities in\nexisting licensing language are two noted benefits of the approach proposed in\nthe paper. In parallel, such benefits may help foster fairer and more efficient\nmarkets for data through bringing about clearer tools and concepts that better\ndefine how data can be used in the fields of AI and ML. The paper's approach is\nsummarized in a new family of data license language - \\textit{the Montreal Data\nLicense (MDL)}. Alongside this new license, the authors and their collaborators\nhave developed a web-based tool to generate license language espousing the\ntaxonomies articulated in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 00:28:59 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Benjamin", "Misha", ""], ["Gagnon", "Paul", ""], ["Rostamzadeh", "Negar", ""], ["Pal", "Chris", ""], ["Bengio", "Yoshua", ""], ["Shee", "Alex", ""]]}, {"id": "1903.12264", "submitter": "Timur Osadchiy", "authors": "Timur Osadchiy, Ivan Poliakov, Patrick Olivier, Maisie Rowland, Emma\n  Foster", "title": "Validation of a recommender system for prompting omitted foods in online\n  dietary assessment surveys", "comments": null, "journal-ref": "PervasiveHealth 2019 Proceedings of the 13th EAI International\n  Conference on Pervasive Computing Technologies for Healthcare", "doi": "10.1145/3329189.3329191", "report-no": "ISBN: 978-1-4503-6126-2", "categories": "cs.CY cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recall assistance methods are among the key aspects that improve the accuracy\nof online dietary assessment surveys. These methods still mainly rely on\nexperience of trained interviewers with nutritional background, but data driven\napproaches could improve cost-efficiency and scalability of automated dietary\nassessment. We evaluated the effectiveness of a recommender algorithm developed\nfor an online dietary assessment system called Intake24, that automates the\nmultiple-pass 24-hour recall method. The recommender builds a model of eating\nbehavior from recalls collected in past surveys. Based on foods they have\nalready selected, the model is used to remind respondents of associated foods\nthat they may have omitted to report. The performance of prompts generated by\nthe model was compared to that of prompts hand-coded by nutritionists in two\ndietary studies. The results of our studies demonstrate that the recommender\nsystem is able to capture a higher number of foods omitted by respondents of\nonline dietary surveys than prompts hand-coded by nutritionists. However, the\nconsiderably lower precision of generated prompts indicates an opportunity for\nfurther improvement of the system.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 16:42:54 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Osadchiy", "Timur", ""], ["Poliakov", "Ivan", ""], ["Olivier", "Patrick", ""], ["Rowland", "Maisie", ""], ["Foster", "Emma", ""]]}, {"id": "1903.12266", "submitter": "Maciej Zamorski", "authors": "Maciej Zamorski, Adrian Zdobylak, Maciej Zi\\k{e}ba, Jerzy\n  \\'Swi\\k{a}tek", "title": "Generative Adversarial Networks: recent developments", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In traditional generative modeling, good data representation is very often a\nbase for a good machine learning model. It can be linked to good\nrepresentations encoding more explanatory factors that are hidden in the\noriginal data. With the invention of Generative Adversarial Networks (GANs), a\nsubclass of generative models that are able to learn representations in an\nunsupervised and semi-supervised fashion, we are now able to adversarially\nlearn good mappings from a simple prior distribution to a target data\ndistribution. This paper presents an overview of recent developments in GANs\nwith a focus on learning latent space representations.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 18:10:35 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Zamorski", "Maciej", ""], ["Zdobylak", "Adrian", ""], ["Zi\u0119ba", "Maciej", ""], ["\u015awi\u0105tek", "Jerzy", ""]]}, {"id": "1903.12286", "submitter": "Maciej Mikulski", "authors": "Maciej Mikulski and Jaroslaw Duda", "title": "Toroidal AutoEncoder", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enforcing distributions of latent variables in neural networks is an active\nsubject. It is vital in all kinds of generative models, where we want to be\nable to interpolate between points in the latent space, or sample from it.\nModern generative AutoEncoders (AE) like WAE, SWAE, CWAE add a regularizer to\nthe standard (deterministic) AE, which allows to enforce Gaussian distribution\nin the latent space. Enforcing different distributions, especially\ntopologically nontrivial, might bring some new interesting possibilities, but\nthis subject seems unexplored so far.\n  This article proposes a new approach to enforce uniform distribution on\nd-dimensional torus. We introduce a circular spring loss, which enforces\nminibatch points to be equally spaced and satisfy cyclic boundary conditions.\n  As example of application we propose multiple-path morphing. Minimal distance\ngeodesic between two points in uniform distribution on latent space of angles\nbecomes a line, however, torus topology allows us to choose such lines in\nalternative ways, going through different edges of $[-\\pi,\\pi]^d$.\n  Further applications to explore can be for example trying to learn real-life\ntopologically nontrivial spaces of features, like rotations to automatically\nrecognize 2D rotation of an object in picture by training on relative angles,\nor even 3D rotations by additionally using spherical features - this way\nmorphing should be close to object rotation.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 21:48:46 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Mikulski", "Maciej", ""], ["Duda", "Jaroslaw", ""]]}, {"id": "1903.12287", "submitter": "Adam Lerer", "authors": "Adam Lerer, Ledell Wu, Jiajun Shen, Timothee Lacroix, Luca Wehrstedt,\n  Abhijit Bose, Alex Peysakhovich", "title": "PyTorch-BigGraph: A Large-scale Graph Embedding System", "comments": null, "journal-ref": "Proceedings of The Conference on Systems and Machine Learning,\n  2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding methods produce unsupervised node features from graphs that\ncan then be used for a variety of machine learning tasks. Modern graphs,\nparticularly in industrial applications, contain billions of nodes and\ntrillions of edges, which exceeds the capability of existing embedding systems.\nWe present PyTorch-BigGraph (PBG), an embedding system that incorporates\nseveral modifications to traditional multi-relation embedding systems that\nallow it to scale to graphs with billions of nodes and trillions of edges. PBG\nuses graph partitioning to train arbitrarily large embeddings on either a\nsingle machine or in a distributed environment. We demonstrate comparable\nperformance with existing embedding systems on common benchmarks, while\nallowing for scaling to arbitrarily large graphs and parallelization on\nmultiple machines. We train and evaluate embeddings on several large social\nnetwork graphs as well as the full Freebase dataset, which contains over 100\nmillion nodes and 2 billion edges.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 21:51:09 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 16:48:00 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 15:41:25 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Lerer", "Adam", ""], ["Wu", "Ledell", ""], ["Shen", "Jiajun", ""], ["Lacroix", "Timothee", ""], ["Wehrstedt", "Luca", ""], ["Bose", "Abhijit", ""], ["Peysakhovich", "Alex", ""]]}, {"id": "1903.12297", "submitter": "Jean Feng", "authors": "Jean Feng, Noah Simon", "title": "An analysis of the cost of hyper-parameter selection via split-sample\n  validation, with applications to penalized regression", "comments": null, "journal-ref": null, "doi": "10.5705/ss.202017.0310", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the regression setting, given a set of hyper-parameters, a\nmodel-estimation procedure constructs a model from training data. The optimal\nhyper-parameters that minimize generalization error of the model are usually\nunknown. In practice they are often estimated using split-sample validation. Up\nto now, there is an open question regarding how the generalization error of the\nselected model grows with the number of hyper-parameters to be estimated. To\nanswer this question, we establish finite-sample oracle inequalities for\nselection based on a single training/test split and based on cross-validation.\nWe show that if the model-estimation procedures are smoothly parameterized by\nthe hyper-parameters, the error incurred from tuning hyper-parameters shrinks\nat nearly a parametric rate. Hence for semi- and non-parametric\nmodel-estimation procedures with a fixed number of hyper-parameters, this\nadditional error is negligible. For parametric model-estimation procedures,\nadding a hyper-parameter is roughly equivalent to adding a parameter to the\nmodel itself. In addition, we specialize these ideas for penalized regression\nproblems with multiple penalty parameters. We establish that the fitted models\nare Lipschitz in the penalty parameters and thus our oracle inequalities apply.\nThis result encourages development of regularization methods with many penalty\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 23:04:43 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Feng", "Jean", ""], ["Simon", "Noah", ""]]}, {"id": "1903.12322", "submitter": "Liam Hodgkinson", "authors": "Liam Hodgkinson, Robert Salomone, Fred Roosta", "title": "Implicit Langevin Algorithms for Sampling From Log-concave Densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For sampling from a log-concave density, we study implicit integrators\nresulting from $\\theta$-method discretization of the overdamped Langevin\ndiffusion stochastic differential equation. Theoretical and algorithmic\nproperties of the resulting sampling methods for $ \\theta \\in [0,1] $ and a\nrange of step sizes are established. Our results generalize and extend prior\nworks in several directions. In particular, for $\\theta\\ge1/2$, we prove\ngeometric ergodicity and stability of the resulting methods for all step sizes.\nWe show that obtaining subsequent samples amounts to solving a strongly-convex\noptimization problem, which is readily achievable using one of numerous\nexisting methods. Numerical examples supporting our theoretical analysis are\nalso presented.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 02:13:16 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 07:31:46 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Hodgkinson", "Liam", ""], ["Salomone", "Robert", ""], ["Roosta", "Fred", ""]]}, {"id": "1903.12328", "submitter": "Joseph West", "authors": "Joseph West, Frederic Maire, Cameron Browne and Simon Denman", "title": "Improved Reinforcement Learning with Curriculum", "comments": "Draft prior to submission to IEEE Trans on Games. Changed paper\n  slightly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans tend to learn complex abstract concepts faster if examples are\npresented in a structured manner. For instance, when learning how to play a\nboard game, usually one of the first concepts learned is how the game ends,\ni.e. the actions that lead to a terminal state (win, lose or draw). The\nadvantage of learning end-games first is that once the actions which lead to a\nterminal state are understood, it becomes possible to incrementally learn the\nconsequences of actions that are further away from a terminal state - we call\nthis an end-game-first curriculum. Currently the state-of-the-art machine\nlearning player for general board games, AlphaZero by Google DeepMind, does not\nemploy a structured training curriculum; instead learning from the entire game\nat all times. By employing an end-game-first training curriculum to train an\nAlphaZero inspired player, we empirically show that the rate of learning of an\nartificial player can be improved during the early stages of training when\ncompared to a player not using a training curriculum.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 02:27:54 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 04:23:54 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["West", "Joseph", ""], ["Maire", "Frederic", ""], ["Browne", "Cameron", ""], ["Denman", "Simon", ""]]}, {"id": "1903.12330", "submitter": "Abhishek Ramdas Nair", "authors": "P. Kumar, A. R. Nair, O. Chatterjee, T. Paul, A. Ghosh, S.\n  Chakrabartty, C. S. Thakur", "title": "Neuromorphic In-Memory Computing Framework using Memtransistor Cross-bar\n  based Support Vector Machines", "comments": "4 pages, 5 figures, MWSCAS 2019", "journal-ref": "2019 IEEE 62nd International Midwest Symposium on Circuits and\n  Systems (MWSCAS)", "doi": "10.1109/MWSCAS.2019.8885180", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a novel framework for designing support vector machines\n(SVMs), which does not impose restriction on the SVM kernel to be\npositive-definite and allows the user to define memory constraint in terms of\nfixed template vectors. This makes the framework scalable and enables its\nimplementation for low-power, high-density and memory constrained embedded\napplication. An efficient hardware implementation of the same is also\ndiscussed, which utilizes novel low power memtransistor based cross-bar\narchitecture, and is robust to device mismatch and randomness. We used\nmemtransistor measurement data, and showed that the designed SVMs can achieve\nclassification accuracy comparable to traditional SVMs on both synthetic and\nreal-world benchmark datasets. This framework would be beneficial for design of\nSVM based wake-up systems for internet of things (IoTs) and edge devices where\nmemtransistors can be used to optimize system's energy-efficiency and perform\nin-memory matrix-vector multiplication (MVM).\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 02:38:07 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 16:09:35 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Kumar", "P.", ""], ["Nair", "A. R.", ""], ["Chatterjee", "O.", ""], ["Paul", "T.", ""], ["Ghosh", "A.", ""], ["Chakrabartty", "S.", ""], ["Thakur", "C. S.", ""]]}, {"id": "1903.12340", "submitter": "Song-Kyoo Amang Kim Ph.D.", "authors": "Song-Kyoo Kim, Chan Yeob Yeun, Ernesto Damiani, Nai-Wei Lo", "title": "A Machine Learning Framework for Biometric Authentication using\n  Electrocardiogram", "comments": "This paper has been published in the IEEE Access", "journal-ref": "IEEE Access 7 (2019), pp. 94858-94868", "doi": "10.1109/ACCESS.2019.2927079", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a framework for how to appropriately adopt and adjust\nMachine Learning (ML) techniques used to construct Electrocardiogram (ECG)\nbased biometric authentication schemes. The proposed framework can help\ninvestigators and developers on ECG based biometric authentication mechanisms\ndefine the boundaries of required datasets and get training data with good\nquality. To determine the boundaries of datasets, use case analysis is adopted.\nBased on various application scenarios on ECG based authentication, three\ndistinct use cases (or authentication categories) are developed. With more\nqualified training data given to corresponding machine learning schemes, the\nprecision on ML-based ECG biometric authentication mechanisms is increased in\nconsequence. ECG time slicing technique with the R-peak anchoring is utilized\nin this framework to acquire ML training data with good quality. In the\nproposed framework four new measure metrics are introduced to evaluate the\nquality of ML training and testing data. In addition, a Matlab toolbox,\ncontaining all proposed mechanisms, metrics and sample data with demonstrations\nusing various ML techniques, is developed and made publicly available for\nfurther investigation. For developing ML-based ECG biometric authentication,\nthe proposed framework can guide researchers to prepare the proper ML setups\nand the ML training datasets along with three identified user case scenarios.\nFor researchers adopting ML techniques to design new schemes in other research\ndomains, the proposed framework is still useful for generating ML-based\ntraining and testing datasets with good quality and utilizing new measure\nmetrics.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 03:27:13 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 15:26:27 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 05:53:01 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kim", "Song-Kyoo", ""], ["Yeun", "Chan Yeob", ""], ["Damiani", "Ernesto", ""], ["Lo", "Nai-Wei", ""]]}, {"id": "1903.12344", "submitter": "Liang Zhao", "authors": "Liang Zhao and Wei Xu", "title": "Learning Good Representation via Continuous Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present our scientific discovery that good representation\ncan be learned via continuous attention during the interaction between\nUnsupervised Learning(UL) and Reinforcement Learning(RL) modules driven by\nintrinsic motivation. Specifically, we designed intrinsic rewards generated\nfrom UL modules for driving the RL agent to focus on objects for a period of\ntime and to learn good representations of objects for later object recognition\ntask. We evaluate our proposed algorithm in both with and without extrinsic\nreward settings. Experiments with end-to-end training in simulated environments\nwith applications to few-shot object recognition demonstrated the effectiveness\nof the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 03:43:36 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 03:35:15 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Zhao", "Liang", ""], ["Xu", "Wei", ""]]}, {"id": "1903.12347", "submitter": "Neil Borle", "authors": "Neil C. Borle, Edmond A. Ryan, Russell Greiner", "title": "The Challenge of Predicting Meal-to-meal Blood Glucose Concentrations\n  for Patients with Type I Diabetes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients with Type I Diabetes (T1D) must take insulin injections to prevent\nthe serious long term effects of hyperglycemia - high blood glucose (BG).\nPatients must also be careful not to inject too much insulin because this could\ninduce hypoglycemia (low BG), which can potentially be fatal. Patients\ntherefore follow a \"regimen\" that determines how much insulin to inject at\ncertain times. Current methods for managing this disease require adjusting the\npatient's regimen over time based on the disease's behavior (recorded in the\npatient's diabetes diary). If we can accurately predict a patient's future BG\nvalues from his/her current features (e.g., predicting today's lunch BG value\ngiven today's diabetes diary entry for breakfast, including insulin injections,\nand perhaps earlier entries), then it is relatively easy to produce an\neffective regimen. This study explores the challenges of BG modeling by\napplying several machine learning algorithms and various data preprocessing\nvariations (corresponding to 312 [learner, preprocessed-dataset] combinations),\nto a new T1D dataset containing 29 601 entries from 47 different patients. Our\nmost accurate predictor is a weighted ensemble of two Gaussian Process\nRegression models, which achieved an errL1 loss of 2.70 mmol/L (48.65 mg/dl).\nThis was an unexpectedly poor result given that one can obtain an errL1 of 2.91\nmmol/L (52.43 mg/dl) using the naive approach of simply predicting the\npatient's average BG. For each of data-variant/model combination we report\nseveral evaluation metrics, including glucose-specific metrics, and find\nsimilarly disappointing results (the best model was only incrementally better\nthan the simplest measure). These results suggest that the diabetes diary data\nthat is typically collected may not be sufficient to produce accurate BG\nprediction models; additional data may be necessary to build accurate BG\nprediction models.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 03:51:22 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Borle", "Neil C.", ""], ["Ryan", "Edmond A.", ""], ["Greiner", "Russell", ""]]}, {"id": "1903.12366", "submitter": "Zehra Sura", "authors": "Zehra Sura, Tong Chen, and Hyojin Sung", "title": "Using Structured Input and Modularity for Improved Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for utilizing the known structure of input data to make\nlearning more efficient. Our work is in the domain of programming languages,\nand we use deep neural networks to do program analysis. Computer programs\ninclude a lot of structural information (such as loop nests, conditional\nblocks, and data scopes), which is pertinent to program analysis. In this case,\nthe neural network has to learn to recognize the structure, and also learn the\ntarget function for the problem. However, the structural information in this\ndomain is readily accessible to software with the availability of compiler\ntools and parsers for well-defined programming languages.\n  Our method for utilizing the known structure of input data includes: (1)\npre-processing the input data to expose relevant structures, and (2)\nconstructing neural networks by incorporating the structure of the input data\nas an integral part of the network design. The method has the effect of\nmodularizing the neural network which helps break down complexity, and results\nin more efficient training of the overall network. We apply this method to an\nexample code analysis problem, and show that it can achieve higher accuracy\nwith a smaller network size and fewer training examples. Further, the method is\nrobust, performing equally well on input data with different distributions.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 06:30:32 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Sura", "Zehra", ""], ["Chen", "Tong", ""], ["Sung", "Hyojin", ""]]}, {"id": "1903.12370", "submitter": "Mitch Hill", "authors": "Erik Nijkamp, Mitch Hill, Tian Han, Song-Chun Zhu, Ying Nian Wu", "title": "On the Anatomy of MCMC-Based Maximum Likelihood Learning of Energy-Based\n  Models", "comments": "Code available at: https://github.com/point0bar1/ebm-anatomy", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the effects of Markov chain Monte Carlo (MCMC)\nsampling in unsupervised Maximum Likelihood (ML) learning. Our attention is\nrestricted to the family of unnormalized probability densities for which the\nnegative log density (or energy function) is a ConvNet. We find that many of\nthe techniques used to stabilize training in previous studies are not\nnecessary. ML learning with a ConvNet potential requires only a few\nhyper-parameters and no regularization. Using this minimal framework, we\nidentify a variety of ML learning outcomes that depend solely on the\nimplementation of MCMC sampling.\n  On one hand, we show that it is easy to train an energy-based model which can\nsample realistic images with short-run Langevin. ML can be effective and stable\neven when MCMC samples have much higher energy than true steady-state samples\nthroughout training. Based on this insight, we introduce an ML method with\npurely noise-initialized MCMC, high-quality short-run synthesis, and the same\nbudget as ML with informative MCMC initialization such as CD or PCD. Unlike\nprevious models, our energy model can obtain realistic high-diversity samples\nfrom a noise signal after training.\n  On the other hand, ConvNet potentials learned with non-convergent MCMC do not\nhave a valid steady-state and cannot be considered approximate unnormalized\ndensities of the training data because long-run MCMC samples differ greatly\nfrom observed images. We show that it is much harder to train a ConvNet\npotential to learn a steady-state over realistic images. To our knowledge,\nlong-run MCMC samples of all previous models lose the realism of short-run\nsamples. With correct tuning of Langevin noise, we train the first ConvNet\npotentials for which long-run and steady-state MCMC samples are realistic\nimages.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 06:45:03 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 00:14:15 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 08:09:22 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2019 20:16:29 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Nijkamp", "Erik", ""], ["Hill", "Mitch", ""], ["Han", "Tian", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1903.12384", "submitter": "Andreas Heinecke", "authors": "Andreas Heinecke, Wen-Liang Hwang", "title": "Deep Representation with ReLU Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deep feedforward neural networks with rectified linear units from\na signal processing perspective. In this view, such representations mark the\ntransition from using a single (data-driven) linear representation to utilizing\na large collection of affine linear representations tailored to particular\nregions of the signal space. This paper provides a precise description of the\nindividual affine linear representations and corresponding domain regions that\nthe (data-driven) neural network associates to each signal of the input space.\nIn particular, we describe atomic decompositions of the representations and,\nbased on estimating their Lipschitz regularity, suggest some conditions that\ncan stabilize learning independent of the network depth. Such an analysis may\npromote further theoretical insight from both the signal processing and machine\nlearning communities.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 08:12:39 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Heinecke", "Andreas", ""], ["Hwang", "Wen-Liang", ""]]}, {"id": "1903.12394", "submitter": "Laura von Rueden", "authors": "Laura von Rueden, Sebastian Mayer, Katharina Beckh, Bogdan Georgiev,\n  Sven Giesselbach, Raoul Heese, Birgit Kirsch, Julius Pfrommer, Annika Pick,\n  Rajkumar Ramamurthy, Michal Walczak, Jochen Garcke, Christian Bauckhage,\n  Jannis Schuecker", "title": "Informed Machine Learning -- A Taxonomy and Survey of Integrating\n  Knowledge into Learning Systems", "comments": "Accepted at IEEE Transactions on Knowledge and Data Engineering:\n  https://ieeexplore.ieee.org/document/9429985", "journal-ref": null, "doi": "10.1109/TKDE.2021.3079836", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite its great success, machine learning can have its limits when dealing\nwith insufficient training data. A potential solution is the additional\nintegration of prior knowledge into the training process which leads to the\nnotion of informed machine learning. In this paper, we present a structured\noverview of various approaches in this field. We provide a definition and\npropose a concept for informed machine learning which illustrates its building\nblocks and distinguishes it from conventional machine learning. We introduce a\ntaxonomy that serves as a classification framework for informed machine\nlearning approaches. It considers the source of knowledge, its representation,\nand its integration into the machine learning pipeline. Based on this taxonomy,\nwe survey related research and describe how different knowledge representations\nsuch as algebraic equations, logic rules, or simulation results can be used in\nlearning systems. This evaluation of numerous papers on the basis of our\ntaxonomy uncovers key methods in the field of informed machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 08:37:40 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 21:10:43 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 07:34:41 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["von Rueden", "Laura", ""], ["Mayer", "Sebastian", ""], ["Beckh", "Katharina", ""], ["Georgiev", "Bogdan", ""], ["Giesselbach", "Sven", ""], ["Heese", "Raoul", ""], ["Kirsch", "Birgit", ""], ["Pfrommer", "Julius", ""], ["Pick", "Annika", ""], ["Ramamurthy", "Rajkumar", ""], ["Walczak", "Michal", ""], ["Garcke", "Jochen", ""], ["Bauckhage", "Christian", ""], ["Schuecker", "Jannis", ""]]}, {"id": "1903.12416", "submitter": "Zal\\'an Borsos", "authors": "Zal\\'an Borsos, Sebastian Curi, Kfir Y. Levy, Andreas Krause", "title": "Online Variance Reduction with Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive importance sampling for stochastic optimization is a promising\napproach that offers improved convergence through variance reduction. In this\nwork, we propose a new framework for variance reduction that enables the use of\nmixtures over predefined sampling distributions, which can naturally encode\nprior knowledge about the data. While these sampling distributions are fixed,\nthe mixture weights are adapted during the optimization process. We propose\nVRM, a novel and efficient adaptive scheme that asymptotically recovers the\nbest mixture weights in hindsight and can also accommodate sampling\ndistributions over sets of points. We empirically demonstrate the versatility\nof VRM in a range of applications.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 09:41:57 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Borsos", "Zal\u00e1n", ""], ["Curi", "Sebastian", ""], ["Levy", "Kfir Y.", ""], ["Krause", "Andreas", ""]]}, {"id": "1903.12422", "submitter": "Zixing Zhang", "authors": "Zixing Zhang, Jing Han, Kun Qian, Christoph Janott, Yanan Guo, Bjoern\n  Schuller", "title": "Snore-GANs: Improving Automatic Snore Sound Classification with\n  Synthesized Data", "comments": "accepted by IEEE JBHI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the frontier issues that severely hamper the development of automatic\nsnore sound classification (ASSC) associates to the lack of sufficient\nsupervised training data. To cope with this problem, we propose a novel data\naugmentation approach based on semi-supervised conditional Generative\nAdversarial Networks (scGANs), which aims to automatically learn a mapping\nstrategy from a random noise space to original data distribution. The proposed\napproach has the capability of well synthesizing 'realistic' high-dimensional\ndata, while requiring no additional annotation process. To handle the mode\ncollapse problem of GANs, we further introduce an ensemble strategy to enhance\nthe diversity of the generated data. The systematic experiments conducted on a\nwidely used Munich-Passau snore sound corpus demonstrate that the scGANs-based\nsystems can remarkably outperform other classic data augmentation systems, and\nare also competitive to other recently reported systems for ASSC.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 09:52:37 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Zhang", "Zixing", ""], ["Han", "Jing", ""], ["Qian", "Kun", ""], ["Janott", "Christoph", ""], ["Guo", "Yanan", ""], ["Schuller", "Bjoern", ""]]}, {"id": "1903.12424", "submitter": "Zixing Zhang", "authors": "Zixing Zhang, Bingwen Wu, Bjoern Schuller", "title": "Attention-Augmented End-to-End Multi-Task Learning for Emotion\n  Prediction from Speech", "comments": "accepted by ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the increasing research interest in end-to-end learning systems for\nspeech emotion recognition, conventional systems either suffer from the\noverfitting due in part to the limited training data, or do not explicitly\nconsider the different contributions of automatically learnt representations\nfor a specific task. In this contribution, we propose a novel end-to-end\nframework which is enhanced by learning other auxiliary tasks and an attention\nmechanism. That is, we jointly train an end-to-end network with several\ndifferent but related emotion prediction tasks, i.e., arousal, valence, and\ndominance predictions, to extract more robust representations shared among\nvarious tasks than traditional systems with the hope that it is able to relieve\nthe overfitting problem. Meanwhile, an attention layer is implemented on top of\nthe layers for each task, with the aim to capture the contribution distribution\nof different segment parts for each individual task. To evaluate the\neffectiveness of the proposed system, we conducted a set of experiments on the\nwidely used database IEMOCAP. The empirical results show that the proposed\nsystems significantly outperform corresponding baseline systems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 09:57:45 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Zhang", "Zixing", ""], ["Wu", "Bingwen", ""], ["Schuller", "Bjoern", ""]]}, {"id": "1903.12436", "submitter": "Partha Ghosh", "authors": "Partha Ghosh, Mehdi S. M. Sajjadi, Antonio Vergari, Michael Black,\n  Bernhard Sch\\\"olkopf", "title": "From Variational to Deterministic Autoencoders", "comments": "Partha Ghosh and Mehdi S. M. Sajjadi contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAEs) provide a theoretically-backed and popular\nframework for deep generative models. However, learning a VAE from data poses\nstill unanswered theoretical questions and considerable practical challenges.\nIn this work, we propose an alternative framework for generative modeling that\nis simpler, easier to train, and deterministic, yet has many of the advantages\nof VAEs. We observe that sampling a stochastic encoder in a Gaussian VAE can be\ninterpreted as simply injecting noise into the input of a deterministic\ndecoder. We investigate how substituting this kind of stochasticity, with other\nexplicit and implicit regularization schemes, can lead to an equally smooth and\nmeaningful latent space without forcing it to conform to an arbitrarily chosen\nprior. To retrieve a generative mechanism to sample new data, we introduce an\nex-post density estimation step that can be readily applied also to existing\nVAEs, improving their sample quality. We show, in a rigorous empirical study,\nthat the proposed regularized deterministic autoencoders are able to generate\nsamples that are comparable to, or better than, those of VAEs and more powerful\nalternatives when applied to images as well as to structured data such as\nmolecules. \\footnote{An implementation is available at:\n\\url{https://github.com/ParthaEth/Regularized_autoencoders-RAE-}}\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 10:31:55 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 13:00:21 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 22:35:33 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 09:18:24 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Ghosh", "Partha", ""], ["Sajjadi", "Mehdi S. M.", ""], ["Vergari", "Antonio", ""], ["Black", "Michael", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1903.12483", "submitter": "Saulo Martiello Mastelini", "authors": "Saulo Martiello Mastelini, Sylvio Barbon Jr., Andr\\'e Carlos Ponce de\n  Leon Ferreira de Carvalho", "title": "Online Multi-target regression trees with stacked leaf models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the current challenges in machine learning is how to deal with data\ncoming at increasing rates in data streams. New predictive learning strategies\nare needed to cope with the high throughput data and concept drift. One of the\ndata stream mining tasks where new learning strategies are needed is\nmulti-target regression, due to its applicability in a high number of real\nworld problems. While reliable and effective learning strategies have been\nproposed for batch multi-target regression, few have been proposed for\nmulti-target online learning in data streams. Besides, most of the existing\nsolutions do not consider the occurrence of inter-target correlations when\nmaking predictions. In this work, we propose a novel online learning strategy\nfor multi-target regression in data streams. The proposed strategy extends\nexisting online decision tree learning algorithm to explore inter-target\ndependencies while making predictions. For such, the proposed strategy, called\nStacked Single-target Hoeffding Tree (SST-HT), uses the inter-target\ndependencies as an additional information source to enhance predictive\naccuracy. Throughout an extensive experimental setup, we evaluate our proposal\nagainst state-of-the-art decision tree-based algorithms for online multi-target\nregression. According to the experimental results, SST-HT presents superior\npredictive accuracy, with a small increase in the processing time and memory\nrequirements.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 12:42:03 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 12:21:44 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 19:50:03 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 17:59:39 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Mastelini", "Saulo Martiello", ""], ["Barbon", "Sylvio", "Jr."], ["de Carvalho", "Andr\u00e9 Carlos Ponce de Leon Ferreira", ""]]}, {"id": "1903.12489", "submitter": "Elnaz Soleimani", "authors": "Elnaz Soleimani, Ehsan Nazerfard", "title": "Cross-Subject Transfer Learning in Human Activity Recognition Systems\n  using Generative Adversarial Networks", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": "10.1016/j.neucom.2020.10.056", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application of intelligent systems especially in smart homes and\nhealth-related topics has been drawing more attention in the last decades.\nTraining Human Activity Recognition (HAR) models -- as a major module --\nrequires a fair amount of labeled data. Despite training with large datasets,\nmost of the existing models will face a dramatic performance drop when they are\ntested against unseen data from new users. Moreover, recording enough data for\neach new user is unviable due to the limitations and challenges of working with\nhuman users. Transfer learning techniques aim to transfer the knowledge which\nhas been learned from the source domain (subject) to the target domain in order\nto decrease the models' performance loss in the target domain. This paper\npresents a novel method of adversarial knowledge transfer named SA-GAN stands\nfor Subject Adaptor GAN which utilizes Generative Adversarial Network framework\nto perform cross-subject transfer learning in the domain of wearable\nsensor-based Human Activity Recognition. SA-GAN outperformed other\nstate-of-the-art methods in more than 66% of experiments and showed the second\nbest performance in the remaining 25% of experiments. In some cases, it reached\nup to 90% of the accuracy which can be obtained by supervised training over the\nsame domain data.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 12:50:04 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Soleimani", "Elnaz", ""], ["Nazerfard", "Ehsan", ""]]}, {"id": "1903.12495", "submitter": "Deepak Thukral", "authors": "Deepak Thukral, Darvesh Punia", "title": "Crowd Sourced Data Analysis: Mapping of Programming Concepts to\n  Syntactical Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since programming concepts do not match their syntactic representations, code\nsearch is a very tedious task. For instance in Java or C, array doesn't match\n[], so using \"array\" as a query, one cannot find what they are looking for.\nOften developers have to search code whether to understand any code, or to\nreuse some part of that code, or just to read it, without natural language\nsearching, developers have to often scroll back and forth or use variable names\nas their queries. In our work, we have used Stackoverflow (SO) question and\nanswers to make a mapping of programming concepts with their respective natural\nlanguage keywords, and then tag these natural language terms to every line of\ncode, which can further we used in searching using natural language keywords.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 15:13:20 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Thukral", "Deepak", ""], ["Punia", "Darvesh", ""]]}, {"id": "1903.12514", "submitter": "Behzad Salami", "authors": "Behzad Salami, Osman S. Unsal, Adrian Cristal Kestelman", "title": "Evaluating Built-in ECC of FPGA on-chip Memories for the Mitigation of\n  Undervolting Faults", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": "10.1109/EMPDP.2019.8671543", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voltage underscaling below the nominal level is an effective solution for\nimproving energy efficiency in digital circuits, e.g., Field Programmable Gate\nArrays (FPGAs). However, further undervolting below a safe voltage level and\nwithout accompanying frequency scaling leads to timing related faults,\npotentially undermining the energy savings. Through experimental voltage\nunderscaling studies on commercial FPGAs, we observed that the rate of these\nfaults exponentially increases for on-chip memories, or Block RAMs (BRAMs). To\nmitigate these faults, we evaluated the efficiency of the built-in\nError-Correction Code (ECC) and observed that more than 90% of the faults are\ncorrectable and further 7% are detectable (but not correctable). This\nefficiency is the result of the single-bit type of these faults, which are then\neffectively covered by the Single-Error Correction and Double-Error Detection\n(SECDED) design of the built-in ECC. Finally, motivated by the above\nexperimental observations, we evaluated an FPGA-based Neural Network (NN)\naccelerator under low-voltage operations, while built-in ECC is leveraged to\nmitigate undervolting faults and thus, prevent NN significant accuracy loss. In\nconsequence, we achieve 40% of the BRAM power saving through undervolting below\nthe minimum safe voltage level, with a negligible NN accuracy loss, thanks to\nthe substantial fault coverage by the built-in ECC.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 13:28:22 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Salami", "Behzad", ""], ["Unsal", "Osman S.", ""], ["Kestelman", "Adrian Cristal", ""]]}, {"id": "1903.12519", "submitter": "Matthew Mirman", "authors": "Matthew Mirman, Gagandeep Singh, Martin Vechev", "title": "A Provable Defense for Deep Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a training system, which can provably defend significantly larger\nneural networks than previously possible, including ResNet-34 and DenseNet-100.\nOur approach is based on differentiable abstract interpretation and introduces\ntwo novel concepts: (i) abstract layers for fine-tuning the precision and\nscalability of the abstraction, (ii) a flexible domain specific language (DSL)\nfor describing training objectives that combine abstract and concrete losses\nwith arbitrary specifications. Our training method is implemented in the DiffAI\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 13:35:31 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 14:50:42 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mirman", "Matthew", ""], ["Singh", "Gagandeep", ""], ["Vechev", "Martin", ""]]}, {"id": "1903.12536", "submitter": "Vignesh R", "authors": "Vignesh Ravichandran, Balamurali Murugesan, Sharath M\n  Shankaranarayana, Keerthi Ram, Preejith S.P, Jayaraj Joseph and Mohanasankar\n  Sivaprakasam", "title": "Deep Network for Capacitive ECG Denoising", "comments": "Accepted IEEE MEMEA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous monitoring of cardiac health under free living condition is\ncrucial to provide effective care for patients undergoing post operative\nrecovery and individuals with high cardiac risk like the elderly. Capacitive\nElectrocardiogram (cECG) is one such technology which allows comfortable and\nlong term monitoring through its ability to measure biopotential in conditions\nwithout having skin contact. cECG monitoring can be done using many household\nobjects like chairs, beds and even car seats allowing for seamless monitoring\nof individuals. This method is unfortunately highly susceptible to motion\nartifacts which greatly limits its usage in clinical practice. The current use\nof cECG systems has been limited to performing rhythmic analysis. In this paper\nwe propose a novel end-to-end deep learning architecture to perform the task of\ndenoising capacitive ECG. The proposed network is trained using motion\ncorrupted three channel cECG and a reference LEAD I ECG collected on\nindividuals while driving a car. Further, we also propose a novel joint loss\nfunction to apply loss on both signal and frequency domain. We conduct\nextensive rhythmic analysis on the model predictions and the ground truth. We\nfurther evaluate the signal denoising using Mean Square Error(MSE) and Cross\nCorrelation between model predictions and ground truth. We report MSE of 0.167\nand Cross Correlation of 0.476. The reported results highlight the feasibility\nof performing morphological analysis using the filtered cECG. The proposed\napproach can allow for continuous and comprehensive monitoring of the\nindividuals in free living conditions.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 14:23:01 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Ravichandran", "Vignesh", ""], ["Murugesan", "Balamurali", ""], ["Shankaranarayana", "Sharath M", ""], ["Ram", "Keerthi", ""], ["P", "Preejith S.", ""], ["Joseph", "Jayaraj", ""], ["Sivaprakasam", "Mohanasankar", ""]]}, {"id": "1903.12546", "submitter": "Yo-Seb Jeon", "authors": "Yo-Seb Jeon, Namyoon Lee, H. Vincent Poor", "title": "Robust Data Detection for MIMO Systems with One-Bit ADCs: A\n  Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of one-bit analog-to-digital converters (ADCs) at a receiver is a\npower-efficient solution for future wireless systems operating with a large\nsignal bandwidth and/or a massive number of receive radio frequency chains.\nThis solution, however, induces a high channel estimation error and therefore\nmakes it difficult to perform the optimal data detection that requires perfect\nknowledge of likelihood functions at the receiver. In this paper, we propose a\nlikelihood function learning method for multiple-input multiple-output (MIMO)\nsystems with one-bit ADCs using a reinforcement learning approach. The key idea\nis to exploit input-output samples obtained from data detection, to compensate\nthe mismatch in the likelihood function. The underlying difficulty of this idea\nis a label uncertainty in the samples caused by a data detection error. To\nresolve this problem, we define a Markov decision process (MDP) to maximize the\naccuracy of the likelihood function learned from the samples. We then develop a\nreinforcement learning algorithm that efficiently finds the optimal policy by\napproximating the transition function and the optimal state of the MDP.\nSimulation results demonstrate that the proposed method provides significant\nperformance gains for the optimal data detection methods that suffer from the\nmismatch in the likelihood function.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 14:36:52 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Jeon", "Yo-Seb", ""], ["Lee", "Namyoon", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1903.12549", "submitter": "Alireza Koochali", "authors": "Alireza Koochali, Peter Schichtel, Sheraz Ahmed and Andreas Dengel", "title": "Probabilistic Forecasting of Sensory Data with Generative Adversarial\n  Networks - ForGAN", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2019.2915544", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is one of the challenging problems for humankind.\nTraditional forecasting methods using mean regression models have severe\nshortcomings in reflecting real-world fluctuations. While new probabilistic\nmethods rush to rescue, they fight with technical difficulties like quantile\ncrossing or selecting a prior distribution. To meld the different strengths of\nthese fields while avoiding their weaknesses as well as to push the boundary of\nthe state-of-the-art, we introduce ForGAN - one step ahead probabilistic\nforecasting with generative adversarial networks. ForGAN utilizes the power of\nthe conditional generative adversarial network to learn the data generating\ndistribution and compute probabilistic forecasts from it. We argue how to\nevaluate ForGAN in opposition to regression methods. To investigate\nprobabilistic forecasting of ForGAN, we create a new dataset and demonstrate\nour method abilities on it. This dataset will be made publicly available for\ncomparison. Furthermore, we test ForGAN on two publicly available datasets,\nnamely Mackey-Glass dataset and Internet traffic dataset (A5M) where the\nimpressive performance of ForGAN demonstrate its high capability in forecasting\nfuture values.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 14:39:00 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Koochali", "Alireza", ""], ["Schichtel", "Peter", ""], ["Ahmed", "Sheraz", ""], ["Dengel", "Andreas", ""]]}, {"id": "1903.12561", "submitter": "Kaidi Xu", "authors": "Shaokai Ye, Kaidi Xu, Sijia Liu, Jan-Henrik Lambrechts, Huan Zhang,\n  Aojun Zhou, Kaisheng Ma, Yanzhi Wang, Xue Lin", "title": "Adversarial Robustness vs Model Compression, or Both?", "comments": "Accepted by ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that deep neural networks (DNNs) are vulnerable to\nadversarial attacks, which are implemented by adding crafted perturbations onto\nbenign examples. Min-max robust optimization based adversarial training can\nprovide a notion of security against adversarial attacks. However, adversarial\nrobustness requires a significantly larger capacity of the network than that\nfor the natural training with only benign examples. This paper proposes a\nframework of concurrent adversarial training and weight pruning that enables\nmodel compression while still preserving the adversarial robustness and\nessentially tackles the dilemma of adversarial training. Furthermore, this work\nstudies two hypotheses about weight pruning in the conventional setting and\nfinds that weight pruning is essential for reducing the network model size in\nthe adversarial setting, training a small model from scratch even with\ninherited initialization from the large model cannot achieve both adversarial\nrobustness and high standard accuracy. Code is available at\nhttps://github.com/yeshaokai/Robustness-Aware-Pruning-ADMM.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 15:06:41 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 19:43:19 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 01:20:16 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 17:43:19 GMT"}, {"version": "v5", "created": "Tue, 22 Jun 2021 15:16:04 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ye", "Shaokai", ""], ["Xu", "Kaidi", ""], ["Liu", "Sijia", ""], ["Lambrechts", "Jan-Henrik", ""], ["Zhang", "Huan", ""], ["Zhou", "Aojun", ""], ["Ma", "Kaisheng", ""], ["Wang", "Yanzhi", ""], ["Lin", "Xue", ""]]}, {"id": "1903.12575", "submitter": "Luana Ruiz", "authors": "Luana Ruiz, Fernando Gama, Antonio G. Marques, Alejandro Ribeiro", "title": "Invariance-Preserving Localized Activation Functions for Graph Neural\n  Networks", "comments": "Accepted at TSP", "journal-ref": null, "doi": "10.1109/TSP.2019.2955832", "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph signals are signals with an irregular structure that can be described\nby a graph. Graph neural networks (GNNs) are information processing\narchitectures tailored to these graph signals and made of stacked layers that\ncompose graph convolutional filters with nonlinear activation functions. Graph\nconvolutions endow GNNs with invariance to permutations of the graph nodes'\nlabels. In this paper, we consider the design of trainable nonlinear activation\nfunctions that take into consideration the structure of the graph. This is\naccomplished by using graph median filters and graph max filters, which mimic\nlinear graph convolutions and are shown to retain the permutation invariance of\nGNNs. We also discuss modifications to the backpropagation algorithm necessary\nto train local activation functions. The advantages of localized activation\nfunction architectures are demonstrated in four numerical experiments: source\nlocalization on synthetic graphs, authorship attribution of 19th century\nnovels, movie recommender systems and scientific article classification. In all\ncases, localized activation functions are shown to improve model capacity.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 15:35:01 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 18:59:05 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Ruiz", "Luana", ""], ["Gama", "Fernando", ""], ["Marques", "Antonio G.", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1903.12577", "submitter": "Sebastijan Dumancic", "authors": "Sebastijan Dumancic, Tias Guns, Wannes Meert, Hendrik Blockeel", "title": "Learning Relational Representations with Auto-encoding Logic Programs", "comments": "8 pages,4 figures, paper + supplement, published at IJCAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods capable of handling relational data have proliferated\nover the last years. In contrast to traditional relational learning methods\nthat leverage first-order logic for representing such data, these deep learning\nmethods aim at re-representing symbolic relational data in Euclidean spaces.\nThey offer better scalability, but can only numerically approximate relational\nstructures and are less flexible in terms of reasoning tasks supported. This\npaper introduces a novel framework for relational representation learning that\ncombines the best of both worlds. This framework, inspired by the auto-encoding\nprinciple, uses first-order logic as a data representation language, and the\nmapping between the original and latent representation is done by means of\nlogic programs instead of neural networks. We show how learning can be cast as\na constraint optimisation problem for which existing solvers can be used. The\nuse of logic as a representation language makes the proposed framework more\naccurate (as the representation is exact, rather than approximate), more\nflexible, and more interpretable than deep learning methods. We experimentally\nshow that these latent representations are indeed beneficial in relational\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 15:38:02 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 16:32:33 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Dumancic", "Sebastijan", ""], ["Guns", "Tias", ""], ["Meert", "Wannes", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1903.12584", "submitter": "Erik Drysdale", "authors": "Erik Drysdale, Yingwei Peng, Timothy P. Hanna, Paul Nguyen, Anna\n  Goldenberg", "title": "The False Positive Control Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high dimensional settings where a small number of regressors are expected\nto be important, the Lasso estimator can be used to obtain a sparse solution\nvector with the expectation that most of the non-zero coefficients are\nassociated with true signals. While several approaches have been developed to\ncontrol the inclusion of false predictors with the Lasso, these approaches are\nlimited by relying on asymptotic theory, having to empirically estimate terms\nbased on theoretical quantities, assuming a continuous response class with\nGaussian noise and design matrices, or high computation costs. In this paper we\nshow how: (1) an existing model (the SQRT-Lasso) can be recast as a method of\ncontrolling the number of expected false positives, (2) how a similar estimator\ncan used for all other generalized linear model classes, and (3) this approach\ncan be fit with existing fast Lasso optimization solvers. Our justification for\nfalse positive control using randomly weighted self-normalized sum theory is to\nour knowledge novel. Moreover, our estimator's properties hold in finite\nsamples up to some approximation error which we find in practical settings to\nbe negligible under a strict mutual incoherence condition.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 15:50:43 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Drysdale", "Erik", ""], ["Peng", "Yingwei", ""], ["Hanna", "Timothy P.", ""], ["Nguyen", "Paul", ""], ["Goldenberg", "Anna", ""]]}, {"id": "1903.12600", "submitter": "Marek Rychlik", "authors": "Marek Rychlik", "title": "A proof of convergence of multi-class logistic regression network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the special type of a neural network known under two\nnames. In the statistics and machine learning community it is known as a\nmulti-class logistic regression neural network. In the neural network\ncommunity, it is simply the soft-max layer. The importance is underscored by\nits role in deep learning: as the last layer, whose autput is actually the\nclassification of the input patterns, such as images. Our exposition focuses on\nmathematically rigorous derivation of the key equation expressing the gradient.\nThe fringe benefit of our approach is a fully vectorized expression, which is a\nbasis of an efficient implementation. The second result of this paper is the\npositivity of the second derivative of the cross-entropy loss function as\nfunction of the weights. This result proves that optimization methods based on\nconvexity may be used to train this network. As a corollary, we demonstrate\nthat no $L^2$-regularizer is needed to guarantee convergence of gradient\ndescent.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 16:26:52 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 02:37:27 GMT"}, {"version": "v3", "created": "Sat, 6 Apr 2019 22:30:38 GMT"}, {"version": "v4", "created": "Wed, 27 Jan 2021 19:40:40 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Rychlik", "Marek", ""]]}, {"id": "1903.12648", "submitter": "Kibok Lee", "authors": "Kibok Lee, Kimin Lee, Jinwoo Shin, Honglak Lee", "title": "Overcoming Catastrophic Forgetting with Unlabeled Data in the Wild", "comments": "ICCV 2019; v3 updated Figure 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning with deep neural networks is well-known to suffer from\ncatastrophic forgetting: the performance on previous tasks drastically degrades\nwhen learning a new task. To alleviate this effect, we propose to leverage a\nlarge stream of unlabeled data easily obtainable in the wild. In particular, we\ndesign a novel class-incremental learning scheme with (a) a new distillation\nloss, termed global distillation, (b) a learning strategy to avoid overfitting\nto the most recent task, and (c) a confidence-based sampling method to\neffectively leverage unlabeled external data. Our experimental results on\nvarious datasets, including CIFAR and ImageNet, demonstrate the superiority of\nthe proposed methods over prior methods, particularly when a stream of\nunlabeled data is accessible: our method shows up to 15.8% higher accuracy and\n46.5% less forgetting compared to the state-of-the-art method. The code is\navailable at https://github.com/kibok90/iccv2019-inc.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 17:48:15 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 08:43:25 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 17:17:50 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Lee", "Kibok", ""], ["Lee", "Kimin", ""], ["Shin", "Jinwoo", ""], ["Lee", "Honglak", ""]]}, {"id": "1903.12650", "submitter": "Masafumi Yamazaki", "authors": "Masafumi Yamazaki, Akihiko Kasagi, Akihiro Tabuchi, Takumi Honda,\n  Masahiro Miwa, Naoto Fukumoto, Tsuguchika Tabaru, Atsushi Ike, Kohta\n  Nakashima", "title": "Yet Another Accelerated SGD: ResNet-50 Training on ImageNet in 74.7\n  seconds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a strong demand for algorithms that can execute machine\nlearning as faster as possible and the speed of deep learning has accelerated\nby 30 times only in the past two years. Distributed deep learning using the\nlarge mini-batch is a key technology to address the demand and is a great\nchallenge as it is difficult to achieve high scalability on large clusters\nwithout compromising accuracy. In this paper, we introduce optimization methods\nwhich we applied to this challenge. We achieved the training time of 74.7\nseconds using 2,048 GPUs on ABCI cluster applying these methods. The training\nthroughput is over 1.73 million images/sec and the top-1 validation accuracy is\n75.08%.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 17:55:31 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Yamazaki", "Masafumi", ""], ["Kasagi", "Akihiko", ""], ["Tabuchi", "Akihiro", ""], ["Honda", "Takumi", ""], ["Miwa", "Masahiro", ""], ["Fukumoto", "Naoto", ""], ["Tabaru", "Tsuguchika", ""], ["Ike", "Atsushi", ""], ["Nakashima", "Kohta", ""]]}]